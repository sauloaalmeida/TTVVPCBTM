@ARTICLE{1702862,
  author={Misra, J. and Chandy, K.M.},
  journal={IEEE Transactions on Software Engineering}, 
  title={Proofs of Networks of Processes}, 
  year={1981},
  volume={SE-7},
  number={4},
  pages={417-426},
  abstract={We present a proof method for networks of processes in which component processes communicate exclusively through messages. We show how to construct proofs of invariant properties which hold at all times during network computation, and terminal properties which hold upon termination of network computation, if network computation terminates. The proof method is based upon specifying a process by a pair of assertions, analogous to pre-and post-conditions in sequential program proving. The correctness of network specification is proven by applying inference rules to the specifications of component processes. Several examples are proved using this technique.},
  keywords={},
  doi={10.1109/TSE.1981.230844},
  ISSN={1939-3520},
  month={July},}
@ARTICLE{1095588,
  author={Walton, R.},
  journal={IEEE Transactions on Communications}, 
  title={Rationale for a Queueable Object Distributed Interprocess Communication System}, 
  year={1982},
  volume={30},
  number={6},
  pages={1417-1426},
  abstract={We consider the problem of designing an interprocess communication system usable as a base for writing real-time operating and applications systems in a distributed environment where processes may be connected by anything from shared virtual memory to radios. By requiring an interface that minimizes the code an application program must devote to communications, a facility of substantially higher level than basic message passing becomes necessary. This is largely a consequence of four major performance problems with interprocess communication in a distributed environment: system reliability, server congestion, throughput, and response time. We summarize these problems, and introduce an interprocess communication system based on two mechanisms: queueable objects and connectable objects. We briefly review our experience with a limited implementation of queueable objects.},
  keywords={},
  doi={10.1109/TCOM.1982.1095588},
  ISSN={1558-0857},
  month={June},}
@ARTICLE{1676079,
  author={Holzmann},
  journal={IEEE Transactions on Computers}, 
  title={A Theory for Protocol Validation}, 
  year={1982},
  volume={C-31},
  number={8},
  pages={730-738},
  abstract={This paper introduces a simple algebra for the validation of communication protocols in message passing systems. The behavior of each process participating in a communication is first modeled in a finite state machine. The symbol sequences that can be accepted by these machines are then expressed in "protocol expressions," which are defined as regular expressions extended with two new operators: division and multiplication. The interactions of the machines can be analyzed by combining protocol expressions via multiplication and algebraically manipulating the terms.},
  keywords={},
  doi={10.1109/TC.1982.1676079},
  ISSN={1557-9956},
  month={Aug},}
@ARTICLE{1676124,
  author={Marsan and Balbo and Conte and Gregoretti},
  journal={IEEE Transactions on Computers}, 
  title={Modeling Bus Contention and Memory Interference in a Multiprocessor System}, 
  year={1983},
  volume={C-32},
  number={1},
  pages={60-72},
  abstract={Stochastic models of contention for shared resources in an experimental multiprocessor prototype are presented and are validated with simulation and measurement results. Three modeling techniques are used (stochastic Petri nets, Markov chains, and queueing networks) that represent the system operations as Markovian stochastic processes. Each technique is best suited to a specific stage of the analysis. An integrated use of these techniques represents a very powerful tool for the performance analysis of multiprocessor systems and provides ways of investigating several extensions of the prototype architecture. Simulation results and measurements performed on the hardware prototype validate the analysis and show that the accuracy of the analytical results is excellent.},
  keywords={},
  doi={10.1109/TC.1983.1676124},
  ISSN={1557-9956},
  month={Jan},}
@ARTICLE{5010246,
  author={Lam, Simon S. and Shankar, A. Udaya},
  journal={IEEE Transactions on Software Engineering}, 
  title={Protocol Verification via Projections}, 
  year={1984},
  volume={SE-10},
  number={4},
  pages={325-342},
  abstract={The method of projections is a new approach to reduce the complexity of analyzing nontrivial communication protocols. A protocol system consists of a network of protocol entities and communication channels. Protocol entities interact by exchanging messages through channels; messages in transit may be lost, duplicated as well as reordered. Our method is intended for protocols with several distinguishable functions. We show how to construct image protocols for each function. An image protocol is specified just like a real protocol. An image protocol system is said to be faithful if it preserves all safety and liveness properties of the original protocol system concerning the projected function. An image protocol is smaller than the original protocol and can typically be more easily analyzed. Two protocol examples are employed herein to illustrate our method. An application of this method to verify a version of the high-level data link control (HDLC) protocol is described in a companion paper.},
  keywords={},
  doi={10.1109/TSE.1984.5010246},
  ISSN={1939-3520},
  month={July},}
@ARTICLE{6312922,
  author={Mancini, Luigi},
  journal={IEEE Transactions on Software Engineering}, 
  title={Modular redundancy in a message passing system}, 
  year={1986},
  volume={SE-12},
  number={1},
  pages={79-86},
  abstract={Modular redundancy in the form of replicated computations in a concurrent programming model consisting of communicating sequential processes is investigated. Some conditions are given which must always be verified to ensure correctness in the presence of nondeterminism. Then some implementations which satisfy the given conditions are proposed. This approach permits redundant systems to be robust with respect to failures in redundant processors, and also permits the use of software fault tolerance techniques such as N-version programming. The concurrent programming model which has been chosen is based on a set of active entities, i.e. processes, each running in a local protected environment. The processes interact using message passing only.},
  keywords={},
  doi={10.1109/TSE.1986.6312922},
  ISSN={1939-3520},
  month={Jan},}
@INPROCEEDINGS{1158567,
  author={Trimble, G.},
  booktitle={Proceedings of the 1987 5th International Symposium on Unmanned Untethered Submersible Technology}, 
  title={A multiprocessor system for AUV applications}, 
  year={1987},
  volume={5},
  number={},
  pages={208-219},
  abstract={Autonomous Underwater Vehicles (AUV's) require high processing throughput and fault tolerance combined with low power and volume. High throughput is directly related to mission complexity and the degree of vehicle autonomy. Complex acoustic and optical sensors must be interpreted in real time and decisions based on uncertain data must be formulated and executed. Unexpected occurrances including environmental anomalies and enemy threats force immediate action and revised tactical mission planning. The development of the Autonomous Command and Control Demonstration (ACCD) system as a component development of the Autonomus Underwater Vehicle (AUV) program by Lockheed Advanced Marine Systems (AMS) has estimated peak rates greater than 100 MIPS are required for Command and Control processing. The processing itself will be a combination of signal, algorithmic and symbolic processing. Both deterministic and probabalistic algorithms will require computation. For vehicle operations in a fully autonomous mode, any component failures must be corrected by an automated fault tolerant system. The AUV software architecture, developed as part of a detailed analysis, established the performance requirements for the Command and Control hardware. The characteristics of various hardware architectures such as distributed, common memory, data flow, systolic, and connection type systems were established and assessed to determine the hardware best suited to the software structure. A heterogeneous hypercube was found to be optimum. The hypercube is reconfigurable for fault tolerance, is flexible, and can achieve high throughputs with low power and without special cooling systems. AMS will use a commercially-available hypercube as the basis of their Command and Control Architecture for an Unmanned Underwater Vehicle. This hypercube has a 32 bit architecture, extremely high message passing capability and will have image processing accelerators working in conjunction with standard cube nodes. Both symbolic and algorithmic processing will take place on the standard nodes. In this paper, system requirements, software hierarchy, computer architecture analysis and the resulting hypercube design will be discussed in detail.},
  keywords={},
  doi={10.1109/UUST.1987.1158567},
  ISSN={},
  month={June},}
@ARTICLE{1702310,
  author={Nehmer, J. and Haban, D. and Mattern, F. and Wybranietz, D. and Rombach, H.D.},
  journal={IEEE Transactions on Software Engineering}, 
  title={Key Concepts of the INCAS Multicomputer Project}, 
  year={1987},
  volume={SE-13},
  number={8},
  pages={913-923},
  abstract={This paper gives an overview of the INCAS (INCremental Architecture for distributed Systems) multicomputer project, which aims at the development of a comprehensive methodology for the design and implementation of locally distributed systems. A structuring concept for distributed operating systems has been developed and integrated into the system implementation language LADY. The concurrent high-level programming language CSSA, based on the actor model, has been designed for the implementation of distributed applications. A substantial effort in the INCAS project is directed towards the development of a distributed test methodology. An experimental system has been implemented on a network of ten MC68000 microcomputers. Preliminary experience with the methodology has been gained from a small number of prototype applications.},
  keywords={},
  doi={10.1109/TSE.1987.233510},
  ISSN={1939-3520},
  month={Aug},}
@ARTICLE{5009515,
  author={Coulas, Michael F. and MacEwen, Glenn H. and Marquis, Genevieve},
  journal={IEEE Transactions on Computers}, 
  title={RNet: A Hard Real-Time Distributed Programming System}, 
  year={1987},
  volume={C-36},
  number={8},
  pages={917-932},
  abstract={RNet is a high-level programming system for building and executing distributed hard real-time programs. The main objective in developing RNet is to investigate how high-level programming concepts and tools can be used to simplify the real-time programming task. A distributed real-time program in RNet consists of a configuration specification that outlines the structure and real-time properties of the program, and a set of program modules written in a high-level programming language. The RNet configuration system performs a static feasibility analysis of the specifications and handles the construction, distribution, and execution of the program. A debugging and timing analysis system, currently under development and not described here, will be used to measure the real-time characteristics of network resources and the application program, and to perform a validation of the specifications via simulation. The distributed RNet kernel provides run-time support for message-passing and real-time scheduling. The RNet programming model, based on message ports having associated deadlines, provides the programmer with a direct means of expressing a variety of real-time behavioral effects in a way that can be validated. In particular, timing constraints can be used to obtain reliable event synchronization. Some properties that are considered desirable in a high-level distributed real-time programming system are identified. These address issues such as program moduilarity and reconfigurability, timing constraint specification, validation and enforcement, real-time event handling, I/O and exception handling, logical and physical structure specification, and program analysis. The degree to which RNet succeeds in possessing these properties is discussed.},
  keywords={},
  doi={10.1109/TC.1987.5009515},
  ISSN={1557-9956},
  month={Aug},}
@INPROCEEDINGS{7272397,
  author={Chiu, Lin and Liu, Ming T.},
  booktitle={1987 IEEE Third International Conference on Data Engineering}, 
  title={An optimistic concurrency control mechanism without freezing for distributed database systems}, 
  year={1987},
  volume={},
  number={},
  pages={322-329},
  abstract={Optimistic concurrency control mechanisms have the tendency of freezing the system in order to validate a transaction at the end of the transaction's execution phase. This paper presents an optimistic concurrency control that does not freeze the database system. According to the property of conflicting transactions, concurrency control is divided into two counterparts. While one part is exercised at the data object, which responds instantly to consistency violation, the other part is exercised by messages flowing between transactions as background tasks. The whole system need not stop during the time concurrency control is exercising, nor during the time the system is restoring its state when consistency is violated. This makes the mechanism more attractive, since a higher degree of parallelism is provided between consistency control and transaction execution. An object-based model is used to present the mechanism in a distributed database system, in which communication relies heavily on message passing.},
  keywords={},
  doi={10.1109/ICDE.1987.7272397},
  ISSN={},
  month={Feb},}
@INPROCEEDINGS{105457,
  author={Leu, P.-J. and Bhargava, B.},
  booktitle={Proceedings. Fourth International Conference on Data Engineering}, 
  title={Concurrent robust checkpointing and recovery in distributed systems}, 
  year={1988},
  volume={},
  number={},
  pages={154-163},
  abstract={A checkpoint/rollback algorithm is presented for multiple processes in a distributed system that uses message passing for communication. Each process in the system can initiate the algorithm autonomously. If only one instance of the algorithm is being executed, the algorithm will force the minimal number of additional processes other than the initiator to make checkpoints (or roll back). The contributions of this research are as follows: (1) the concurrent execution of the algorithm for different global checkpointing instances and rollback instances initiated by several processes is allowed. Deadlocks or livelocks among different global checkpointing instances and rollback instances will not occur; (2) the algorithm is resilient to multiple process failures, and handles network partitioning in a pessimistic way, and (3) the algorithm does not require that messages be received in the order in which they are sent.},
  keywords={},
  doi={10.1109/ICDE.1988.105457},
  ISSN={},
  month={Feb},}
@ARTICLE{1993,
  author={Carlton, M. and Van Roy, P.},
  journal={IEEE Software}, 
  title={A distributed Prolog system with AND parallelism}, 
  year={1988},
  volume={5},
  number={1},
  pages={43-51},
  abstract={Design details and benchmark results are given for a Prolog interpreter that can be executed across a network by using message passing to implement AND-parallelism. The system is simple and easy to use, yet significantly speeds up existing programs. The system hardware is a group of Sun 3/50 workstations connected to a 10-Mb/s Ethernet. The number of machines actually used by the system is determined when it is initialized. The benchmark programs to test the system are a Prolog compiler, a recursive Fibonacci program, an implementation of the standard quicksort algorithm, and a simple chess program.},
  keywords={},
  doi={10.1109/52.1993},
  ISSN={1937-4194},
  month={Jan},}
@INPROCEEDINGS{8095,
  author={Casey, T.A. and Vinter, S.T. and Weber, D.G. and Varadarajan, R. and Rosenthal, D.},
  booktitle={Proceedings. 1988 IEEE Symposium on Security and Privacy}, 
  title={A secure distributed operating system}, 
  year={1988},
  volume={},
  number={},
  pages={27-38},
  abstract={Some issues in distributed system security are discussed in the context of the design of a secure distributed operating system (SDOS). The design is targeted for an A1 rating. Some developments in formal verification methods are reported. Distributed system security is contrasted with single-host and network security, and described in the context of the Trusted Network Interpretation. Problems unique to distributed system security are discussed. An argument is made for implementing security features in higher layers, corresponding roughly to the session through application layers of the OSI model. A security policy based on message-passing rather than reads and writes is described. The SDOS design is summarized.},
  keywords={},
  doi={10.1109/SECPRI.1988.8095},
  ISSN={},
  month={April},}
@INPROCEEDINGS{11802,
  author={Haban, D. and Weigel, W.},
  booktitle={[1988] Proceedings of the Twenty-First Annual Hawaii International Conference on System Sciences. Volume II: Software track}, 
  title={Global events and global breakpoints in distributed systems}, 
  year={1988},
  volume={2},
  number={},
  pages={166-175},
  abstract={A solution to the problem of setting breakpoints in distributed systems is described. It is shown what kind of breakpoints are possible, how to detect those breakpoints, and how to halt the system in a consistent state. The communication among the processes may be asynchronous with an arbitrary ordering of messages. The algorithms select between simultaneous events and those ordered according to L. Lamport's happened-before relation (1978). The mechanisms for definition and detection of global breakpoints are implemented in the distributed debugging system DTM (distributed test methodology).},
  keywords={},
  doi={10.1109/HICSS.1988.11802},
  ISSN={},
  month={Jan},}
@INPROCEEDINGS{11744,
  author={Biswas, P. and Su, S.-C. and Wright, D.},
  booktitle={[1988] Proceedings of the Twenty-First Annual Hawaii International Conference on System Sciences. Volume I: Architecture Track}, 
  title={A multi-transputer architecture for parallel logic programs}, 
  year={1988},
  volume={1},
  number={},
  pages={70-79},
  abstract={An overview is presented of a scalable, 16-Transputer, mesh-connected architecture that supports a novel message-passing abstract machine model specifically designed for efficient parallel execution of logic programs. An execution model has been developed that is based on message-passing with completely distributed control, with memory references localized to each processor. A demand-driven OR-parallel execution scheme is introduced, which in combination with restricted-AND-parallel execution provides a convenient framework for harnessing explosive parallelism in nonannotated logic programs. The execution mechanism, which is based on the concepts of late binding and selective copying of the uninstantiated variables, eliminates the necessity of long chains for dereferencing, trail stack, and overhead related to backtracking. The implementation of the abstract machine on the multi-transputer testbed, using Occam, is described.},
  keywords={},
  doi={10.1109/HICSS.1988.11744},
  ISSN={},
  month={Jan},}
@INPROCEEDINGS{13341,
  author={Signorini, J.},
  booktitle={Proceedings of the International Workshop on Artificial Intelligence for Industrial Applications}, 
  title={A routing model for the NCR GAPP}, 
  year={1988},
  volume={},
  number={},
  pages={517-521},
  abstract={A routing model for the NCR Geometric Arithmetic Parallel Processor (GAPP) is described. The objective is to permit virtual reconfigurations of the array of processing elements (PEs) and nonlocal connections between arbitrarily distant PEs. The main feature of the model is the multiplexing of two instruction sets, over an additional pin, controlling either the SIMD (single-instruction, multiple-data-stream) machine or the set of router-cells organized as a hypercube network. A description is given of which structural changes are applied to the GAPP SIMD machine to support the routing scheme, and the operations concurrently executed by the router-cells for receiving, delivering or forwarding messages. A functional description of a semantic network which was designed expressly to test the routing model is given together with examples of its use.},
  keywords={},
  doi={10.1109/AIIA.1988.13341},
  ISSN={},
  month={May},}
@INPROCEEDINGS{25791,
  author={Bhargava, B. and Riedl, J.},
  booktitle={Proceedings [1988] Seventh Symposium on Reliable Distributed Systems}, 
  title={Implementation of RAID}, 
  year={1988},
  volume={},
  number={},
  pages={157-166},
  abstract={RAID is a robust and adaptable distributed system for transaction processing. It is a message-passing system, with server processes on each site. A high-level, layered communications package provides a clean, location independent interface between servers. RAID processes concurrent updates and retrievals on multiple sites. The servers manage concurrent processing, consistent replicated copies during site failures or network partitionings, and atomic distributed commitment. The latest version of the communications package is able to deliver messages in a high-performance configuration in which several servers are linked into a single process. RAID provides the infrastructure to investigate experimentally various methods for supporting reliable distributed-transaction processing. Experiments on handling site failure with partial replication, checkpointing, and alternative communications methods have been performed. Measurements on various aspects of RAID transaction processing performance are presented.},
  keywords={},
  doi={10.1109/RELDIS.1988.25791},
  ISSN={},
  month={Oct},}
@INPROCEEDINGS{25649,
  author={Chandra, S.J. and Patel, J.H.},
  booktitle={Proceedings 1988 IEEE International Conference on Computer Design: VLSI}, 
  title={Test generation in a parallel processing environment}, 
  year={1988},
  volume={},
  number={},
  pages={11-14},
  abstract={The availability of low-cost, high-performance, general-purpose parallel machines has made parallel processing viable for the development of CAD (computer-aided design) applications. The authors identify the key issues that surface when an attempt is made to parallelize the test-generation process. They illustrate how different test-generation strategies can be mapped onto different classes of parallel machines, including loosely coupled distributed systems, distributed-memory systems with message-passing architectures, and tightly coupled multiprocessor systems with shared global memory. Parallel test generation using a single heuristic and using multiple heuristics is considered. The performance of these mapping strategies is predicted by using uniprocessor turnaround times and an estimate of the communication delays.},
  keywords={},
  doi={10.1109/ICCD.1988.25649},
  ISSN={},
  month={Oct},}
@INPROCEEDINGS{26688,
  author={Scholten, J. and Jansen, P.G.},
  booktitle={[1988] Proceedings. Workshop on the Future Trends of Distributed Computing Systems in the 1990s}, 
  title={TUMULT, the Twente University multiprocessor}, 
  year={1988},
  volume={},
  number={},
  pages={111-118},
  abstract={TUMULT, (Twente University multiprocessor) is described. Its aim is the design and implementation of a modular extendable multiprocessor system. Up to 15 processing elements are connected through an interprocessor communication network, using message-passing for the exchange of data. The hardware is controlled by a distributed real-time operating system, written in modular Pascal and Modula-2. Each processing element can contain one or more processor (M680X0), memory boards, and I/O interfaces, all connected through a VME bus, which acts as a local bus. The network offers a fully connected communication service with error detection and recovery. In the version realized, the transfer rate is 20 Mbyte/s.},
  keywords={},
  doi={10.1109/FTDCS.1988.26688},
  ISSN={},
  month={Sep.},}
@INPROCEEDINGS{47433,
  author={Guarino, D.R. and Kruger, R.P. and Sayre, S. and Sos, T. and Turner, C.J. and Winter, C.L.},
  booktitle={Proceedings., 2nd Symposium on the Frontiers of Massively Parallel Computation}, 
  title={DARPA sensor national testbed: hardware and software architecture}, 
  year={1988},
  volume={},
  number={},
  pages={295-301},
  abstract={A heterogeneous network of parallel computers developed for complex distributed-processing applications is described. Network computers include a Connection Machine, a Butterfly multiprocessor, a WARP systolic array, and a Symbolics and several SUN workstations. An Ethernet and a high-bandwidth APTEC bus support data transfers. Distributed applications are built from individual processes executing on computers in the network. A powerful asynchronous communication facility is built upon the multiple computer operating systems to provide uniform message passing, global memory variables, and remote process execution services to processes. An executive controller and the LISP+ functional language provide a method of integrating distributed processes into an application with transparent control of network resources and communications. Additional applications can be rapidly built from existing processing to support experiments in distributed and parallel applications.},
  keywords={},
  doi={10.1109/FMPC.1988.47433},
  ISSN={},
  month={Oct},}
@INPROCEEDINGS{72252,
  author={Gabber, E.},
  booktitle={[1988] Proceedings. The Third Israel Conference on Computer Systems and Software Engineering}, 
  title={Parallel programming using the MMX operating system and its processor}, 
  year={1988},
  volume={},
  number={},
  pages={122-132},
  abstract={MMX (multiprocessor multitasking executive) is a small yet powerful operating system for shared memory multiprocessors. The MMX parallel processor is a small shared bus multiprocessor assembled from several commercial processor boards. Together, MMX and its parallel processor provide a flexible and powerful testbed for parallel software development. The author describes MMX design principles, its structure and services. Parallel programming techniques with MMX are demonstrated with special emphasis on work distribution. The author concludes with some MMX timing and speedup measurements of several parallel programs.},
  keywords={},
  doi={10.1109/ICCSSE.1988.72252},
  ISSN={},
  month={June},}
@INPROCEEDINGS{101781,
  author={Ni, L.M. and Salam, F.M.A. and Tzen, T.H. and Sun, X. and Guo, S.},
  booktitle={Proceedings of the 32nd Midwest Symposium on Circuits and Systems,}, 
  title={PowerCube-a software package for solving load flow problems}, 
  year={1989},
  volume={},
  number={},
  pages={1-4 vol.1},
  abstract={PowerCube is a homotopy-based parallel program package for computing all the solutions of the load flow equations of power systems. This package adapts the most rigorous mathematical techniques for tracing homotopy curves, checks for the possibility of curve-merging, and selects a convenient dynamic time-step to execute its computation. It also uses a minimal number of homotopy curves, based on a deficient system, for the load flow of power systems. The package runs on a 64-node Ncube multicomputer, and can be easily ported to other message-passing multicomputers. It is user friendly and the authors believe that it will be valuable for solving load flow problems.},
  keywords={},
  doi={10.1109/MWSCAS.1989.101781},
  ISSN={},
  month={Aug},}
@ARTICLE{21122,
  author={Meyer, F.J. and Pradhan, D.K.},
  journal={IEEE Transactions on Computers}, 
  title={Dynamic testing strategy for distributed systems}, 
  year={1989},
  volume={38},
  number={3},
  pages={356-365},
  abstract={Fault diagnosis is treated as two distinct processes: fault discovery and dissemination of diagnostic information. Previous research determined what level of self-diagnosability a given set of test in a homogeneous system achieves, using a model in which only node failures occur and test coverage is complete. Adopting the same model, a new methodology is presented that minimizes the overhead associated with periodic testing, thus lowering testing overhead. The method diagnoses up to c-.1 faults (c is the connectivity of the system topology). The savings in testing is valid when processor failure rates are low. Environments are also examined with high processor failure rates. It is shown that adopting the proposed methodology for such systems results in greater reliability, while maintaining the same effective processing power.},
  keywords={},
  doi={10.1109/12.21122},
  ISSN={1557-9956},
  month={March},}
@ARTICLE{24723,
  author={Lai, M.-Y. and Wilkinson, W.K. and Lanin, V.},
  journal={IEEE Transactions on Software Engineering}, 
  title={On distributing JASMIN's optimistic multiversioning page manager}, 
  year={1989},
  volume={15},
  number={6},
  pages={696-704},
  abstract={JASMIN is a functionally distributed database system running on multiple microcomputers that communicate with each other by message passing. The software modules in JASMIN can be cloned and distributed across computer boundaries. One important module is the intelligent store, a page manager that includes transaction-management facilities. It provides an optimistic, multiversioning concurrency control scheme. This scheme allows read-only transactions to run almost without conflict checking; this is important in some real-time database applications like telephone switching and routing services. The initial implementation of the intelligent store deals with centralized database only. Experiences in modifying the JASMIN intelligent store module to handle distributed databases are described. Design principles and system implementation techniques in the following areas are explored; process structure, data structures and synchronization on data structures. The process structure is aimed to provide high throughput and the data structures are designed to facilitate fast response time.},
  keywords={},
  doi={10.1109/32.24723},
  ISSN={1939-3520},
  month={June},}
@ARTICLE{24726,
  author={Bhargava, B. and Riedl, J.},
  journal={IEEE Transactions on Software Engineering}, 
  title={The Raid distributed database system}, 
  year={1989},
  volume={15},
  number={6},
  pages={726-736},
  abstract={Raid, a robust and adaptable distributed database system for transaction processing, is described. Raid is a message-passing system, with server processes on each site. The servers manage concurrent processing, consistent replicated copies during site failures and atomic distributed commitment. A high-level, layered communications package provides a clean, location-independent interface between servers. The latest design of the communications package delivers messages via shared memory in a high-performance configuration in which several servers are linked into a single process. Raid provides the infrastructure to experimentally investigate various methods for supporting reliable distributed transaction processing. Measurements on transaction processing time and server CPU time are presented. Data and conclusions of experiments in three categories are also presented: communications software, consistent replicated copy control during site failures, and concurrent distributed checkpointing. A software tool for the evaluation of transaction processing algorithms in an operating system kernel is proposed.},
  keywords={},
  doi={10.1109/32.24726},
  ISSN={1939-3520},
  month={June},}
@ARTICLE{24706,
  author={Lenders, P.M.},
  journal={IEEE Transactions on Software Engineering}, 
  title={Distributed computing with single read-single write variables}, 
  year={1989},
  volume={15},
  number={5},
  pages={569-574},
  abstract={Single-read-single-write (SRSW) variables are presented for synchronous and asynchronous communication between processes. The operational semantics of the instruction accessing these variables is quite simple: a SRSW variable can be written if it is free, and, once written, it becomes busy. A SRSW variable can be read when busy, and, once read, it becomes free. A process attempting to read a free SRSW variable or write a busy SRSW variable is put in a wait state until the state of the variable changes. The advantages of SRSW variables are multiple. The syntax of a regular sequential language can be used without any change, other than the introduction of a new SRSW data type. Parallel programs tend to be concise and easy to prove correct. The message passing paradigm can be very easily modeled with SRSW variables.},
  keywords={},
  doi={10.1109/32.24706},
  ISSN={1939-3520},
  month={May},}
@INPROCEEDINGS{37957,
  author={Peng, W. and Purushothaman, S.},
  booktitle={[1989] Proceedings. The 9th International Conference on Distributed Computing Systems}, 
  title={Analysis of communicating processes for non-progress}, 
  year={1989},
  volume={},
  number={},
  pages={280-287},
  abstract={The problem of testing two processes (specified as finite-state machines) communicating asynchronously with each other using send and receive commands over a set of message types is considered for two forms of nonprogress: deadlock and unspecified reception. Since the nonprogress problem is undecidable, a dataflow approach is used to obtain sufficient conditions under which the two processes are free of deadlock and unspecified reception. The approximation analysis is based on weakening the receive operation. Polynomial time algorithms are presented to perform the analysis. This problem arises in the context of dataflow analysis of the processes that communicate by message passing and in the context of showing correctness of protocol specifications. Diagrams are provided for some networks that can be certified to be free of unspecified receptions using the algorithms. The problem of testing for deadlock in more than two processes still remains open.},
  keywords={},
  doi={10.1109/ICDCS.1989.37957},
  ISSN={},
  month={June},}
@INPROCEEDINGS{37994,
  author={Yau, S.S. and Chen, K.W.I.},
  booktitle={[1989] Proceedings. The 9th International Conference on Distributed Computing Systems}, 
  title={An approach to verification of communication in distributed computing system software}, 
  year={1989},
  volume={},
  number={},
  pages={603-610},
  abstract={An approach is presented for verifying the communication among modules in distributed computing system software. This approach is based on the inductive assertion method. The inference rules used in this approach are derived for verifying the partial correctness of communicating sequential modules. In this approach, the virtual circuits are used for synchronous message-passing. The advantage of this approach is that proofs of the satisfaction and noninterference are not needed, since no assumptions about the effects of receiving messages are made in the sequential proofs and the uses of shared auxiliary variables and universal assertions are carefully controlled during the process verification. Without these proofs, the user only needs to deal with the individual modules instead of the entire distributed computing system. The technique for detecting the deadlock of a program is given.},
  keywords={},
  doi={10.1109/ICDCS.1989.37994},
  ISSN={},
  month={June},}
@INPROCEEDINGS{37949,
  author={Ostroff, J.S.},
  booktitle={[1989] Proceedings. The 9th International Conference on Distributed Computing Systems}, 
  title={Verifying finite state real-time discrete event processes}, 
  year={1989},
  volume={},
  number={},
  pages={207-216},
  abstract={Decision procedures are presented for checking a small but useful class of properties for any finite-state system consisting of real-time discrete-event processes. A timed transition model (TTM) is used for representing real-time discrete-event processes, and real-time temporal logic (RTTL) is the assertion language in which the property to be verified is stated. The relationship of TTMs to other formalisms is summarized along with a complete definition of TTMs and an overview of RTTL. The construction of reachability graphs is discussed, two different procedures are presented for constructing reachability graphs, and the corresponding decision procedures are given.},
  keywords={},
  doi={10.1109/ICDCS.1989.37949},
  ISSN={},
  month={June},}
@ARTICLE{41331,
  author={Bevier, W.R.},
  journal={IEEE Transactions on Software Engineering}, 
  title={Kit: a study in operating system verification}, 
  year={1989},
  volume={15},
  number={11},
  pages={1382-1396},
  abstract={The author reviews Kit, a small multitasking operating system kernel written in the machine language of a uniprocessor von Neumann computer. The kernel is proved to implement on this shared computer a fixed number of conceptually distributed communicating processes. In addition to implementing processes, the kernel provides the following verified services: process scheduling, error handling, message passing, and an interface to asynchronous devices. As a by-product of the correctness proof, security-related results such as the protection of the kernel from tasks and the inability of tasks to enter supervisor mode are proved. The problem is stated in the Boyer-Moore logic, and the proof is mechanically checked with the Boyer-Moore theorem prover.},
  keywords={},
  doi={10.1109/32.41331},
  ISSN={1939-3520},
  month={Nov},}
@ARTICLE{43525,
  author={Singhal, M.},
  journal={Computer}, 
  title={Deadlock detection in distributed systems}, 
  year={1989},
  volume={22},
  number={11},
  pages={37-48},
  abstract={The author describes a series of deadlock detection techniques based on centralized, hierarchical, and distributed control organizations. The point of view is that of practical implications. An up-to-date and comprehensive survey of deadlock detection algorithms is presented, their merits and drawbacks are discussed, and their performances (delays as well as message complexity) are compared. Related issues such as correctness of the algorithms, performance of the algorithms, and deadlock resolution, which require further research are examined.},
  keywords={},
  doi={10.1109/2.43525},
  ISSN={1558-0814},
  month={Nov},}
@INPROCEEDINGS{65052,
  author={Tankoano, J. and Derniame, J.C.},
  booktitle={[1989] Proceedings of the Thirteenth Annual International Computer Software & Applications Conference}, 
  title={Structure design of distributed systems using interpreted Petri nets}, 
  year={1989},
  volume={},
  number={},
  pages={41-51},
  abstract={An approach is presented to internal structure design of distributed systems in the field of process control. Starting from an IPN (interpreted Petri net) specifying the external behavior of a system, the approach (based on a set of decomposition rules) allows a systematic construction of structure specification, thus making unnecessary the consistency verification usually employed in top-down design methods. It is shown that the decomposition rules presented allow systematic construction of the internal structure of distributed systems. These rules free the designer from specifying intermodule cooperation and from verifying consistency between the external behavior and the internal structure specification.},
  keywords={},
  doi={10.1109/CMPSAC.1989.65052},
  ISSN={},
  month={Sep.},}
@INPROCEEDINGS{77001,
  author={Mueller-Thuns, R.B. and Saab, D.G. and Damiano, R.F. and Abraham, J.A.},
  booktitle={1989 IEEE International Conference on Computer-Aided Design. Digest of Technical Papers}, 
  title={Portable parallel logic and fault simulation}, 
  year={1989},
  volume={},
  number={},
  pages={506-509},
  abstract={Consideration is given to the use of general-purpose multiprocessors for various simulation tasks. The aims of the work are to define a general framework for the parallel simulation of digital systems and to develop and evaluate tools for logic and fault simulation that have a good cost-performance ratio. Specifically, a novel partitioning approach is introduced and used as the basis for the parallel logic and fault simulation of synchronous gate-level designs. Performance experiments with prototype implementations on a message passing and a shared memory machine give promising results, in particular for fault simulation.},
  keywords={},
  doi={10.1109/ICCAD.1989.77001},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{111340,
  author={McManus, J.W.},
  booktitle={9th IEEE/AIAA/NASA Conference on Digital Avionics Systems}, 
  title={A concurrent distributed system for aircraft tactical decision generation}, 
  year={1990},
  volume={},
  number={},
  pages={505-512},
  abstract={A research program investigating the use of artificial intelligence (AI) techniques to aid in the development of a tactical decision generator (TDG) for within visual range (WVR) air combat engagements is discussed. The application of AI programming and problem-solving methods in the development and implementation of a concurrent version of the computerized logic for air-to-air warfare simulations (CLAWS) program, a second-generation TDG, is presented. Concurrent computing environments and programming approaches are discussed, and the design and performance of prototype concurrent TDG system (Cube CLAWS) are presented. It is concluded that the Cube CLAWS has provided a useful testbed to evaluate the development of a distributed blackboard system. The project has shown that the complexity of developing specialized software on a distributed, message-passing architecture such as the Hypercube is not overwhelming, and that reasonable speedups and processor efficiency can be achieved by a distributed blackboard system.},
  keywords={},
  doi={10.1109/DASC.1990.111340},
  ISSN={},
  month={Oct},}
@INPROCEEDINGS{114084,
  author={Huisman, L.M. and Daoud, R.},
  booktitle={Proceedings. International Test Conference 1990}, 
  title={Fault simulation of logic designs on parallel processors with distributed memory}, 
  year={1990},
  volume={},
  number={},
  pages={690-697},
  abstract={The authors describe a novel parallelization technique for fault simulation that is suited for message-passing-based parallel processors. The problem is parallelized by first casting it in data-flow form and then constructing a data-flow emulator for message-passing systems. By letting the number of nodes in the parallel processor grow linearly with C, the size of the design, the fault simulation time on a mesh-connected processor grows only as C/sup r+ delta -0.5/, rather than as C/sup 1+ delta /, as on a uniprocessor; r is Rent's exponent and is less than 1.0 and typically on the order of 0.7, and delta is a small positive constant on the order of 0.5 or less. The algorithm has been implemented and exercised on the IBM VICTOR multiprocessor. The performance has been measured for several logic designs as a function of the number of nodes in the parallel processor.},
  keywords={},
  doi={10.1109/TEST.1990.114084},
  ISSN={},
  month={Sep.},}
@INPROCEEDINGS{114201,
  author={Mellor, J. and Karatzas, N. and Touman, M.},
  booktitle={International Conference on Integrated Broadband Services and Networks, 1990.}, 
  title={Broadband network simulation using parallel transputer technology}, 
  year={1990},
  volume={},
  number={},
  pages={324-328},
  abstract={An array of transputers has been used as the simulation engine in the modelling of broadband ATM networks. A message passing system has been developed for the control and operation of the simulation. The proposed system, called ATM Network Emulator Simulator Hybrid System, can be used by network developers as a flexible verification tool for testing prototypes produced for various parts of a broadband network.},
  keywords={},
  doi={},
  ISSN={},
  month={},}
@INPROCEEDINGS{113769,
  author={Goldman, K.J. and Lynch, N.A.},
  booktitle={[1990] Proceedings. Fifth Annual IEEE Symposium on Logic in Computer Science}, 
  title={Modelling shared state in a shared action model}, 
  year={1990},
  volume={},
  number={},
  pages={450-463},
  abstract={The I/O automation model of N.A. Lynch and M.R. Tuttle (1987) is extended to allow modeling of shared memory systems, as well as systems that include both shared memory and shared action communication. A full range of types of atomic accesses to shared memory is allowed, from basic reads and writes to read-modify-write. The extended model supports system description, verification, and analysis. As an example, E.W. Dijkstra's (1965) classical shared memory mutual exclusion algorithm is presented and proven correct.},
  keywords={},
  doi={10.1109/LICS.1990.113769},
  ISSN={},
  month={June},}
@INPROCEEDINGS{117978,
  author={Chu, S.-C.},
  booktitle={IEEE Proceedings on Southeastcon}, 
  title={Alternate fault diagnosis strategy in a distributed environment}, 
  year={1990},
  volume={},
  number={},
  pages={1036-1041 vol.3},
  abstract={All approach that uses a hardware device to perform fault diagnosis in a fully distributed multiprocessor system is proposed. Both the complexities of the diagnostic hardcore and interprocessor communication are reduced. Fault diagnosis in a fully distributed system with permanent faults is considered. Standard notation, definitions, and a framework for discussion are provided. A brief description of the general fault diagnosis process follows. The structure of the diagnostic hardware for each component in the system, called a component diagnosis element (CDE), is defined. The input dependency of each CDE is presented along with a discussion of how this diagnosis device carries out fault diagnosis in a distributed environment. The necessary conditions are provided for a class of fully distributed systems where faulty processors can be diagnosed independently within each processor provided that the number of faulty processors does not exceed a set limit.},
  keywords={},
  doi={10.1109/SECON.1990.117978},
  ISSN={},
  month={April},}
@INPROCEEDINGS{128728,
  author={Griffeth, N. and Weinrib, A.},
  booktitle={[1990] Proceedings 11th Real-Time Systems Symposium}, 
  title={Scalability of a distributed real-time resource counter}, 
  year={1990},
  volume={},
  number={},
  pages={51-59},
  abstract={The authors address the topic of how to meet a real-time constraint as the load on a distributed system increases, without increasing the capacity of the individual processors. The application studied is a real-time resource counter with a probabilistic correctness criterion, and is motivated by the problem of implementing resource management in the telephone network. They introduce a model that combines distributed computing, real-time constraints, probabilistic correctness, and large system size; to the authors' knowledge, no previous work addresses this combination.},
  keywords={},
  doi={10.1109/REAL.1990.128728},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{130088,
  author={Azmy, Y.Y.},
  booktitle={Supercomputing '90:Proceedings of the 1990 ACM/IEEE Conference on Supercomputing}, 
  title={On the adequacy of message-passing parallel supercomputers for solving neutron transport problems}, 
  year={1990},
  volume={},
  number={},
  pages={693-699},
  abstract={A coarse-grained, static-scheduling parallelization of the standard iterative scheme used for solving the discrete-ordinates approximation of the neutron transport equation is described. The parallel algorithm is based on a decomposition of the angular domain along the discrete ordinates, thus naturally producing a set of completely uncoupled systems of equations in each iteration. Implementation of the parallel code on the Intel iPSC/2 hypercube, and solutions to test problems are presented as evidence of the high speedup and efficiency of the parallel code. The performance of the parallel code on the iPSC/2 is analyzed, and a model for the CPU time as a function of the problem size and the number of participating processors is developed and validated against measured CPU times. It is concluded that parallel computers with a few hundred processors are capable of producing large speedups at very high efficiencies in very large three-dimensional problems.},
  keywords={},
  doi={10.1109/SUPERC.1990.130088},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{134520,
  author={Lenoski, D. and Laudon, J. and Gharachorloo, K. and Gupta, A. and Hennessy, J.},
  booktitle={[1990] Proceedings. The 17th Annual International Symposium on Computer Architecture}, 
  title={The directory-based cache coherence protocol for the DASH multiprocessor}, 
  year={1990},
  volume={},
  number={},
  pages={148-159},
  abstract={DASH is a scalable shared-memory multiprocessor whose architecture consists of powerful processing nodes, each with a portion of the shared-memory, connected to a scalable interconnection network. A key feature of DASH is its distributed direction-based cache coherence protocol. Unlike traditional snoopy coherence protocols, the DASH protocol does not rely on broadcast; instead it uses point-to-point messages sent between the processors and memories to keep caches consistent. Furthermore, the DASH system does not contain any single serialization or control point. While these features provide the basis for scalability, they also force a reevaluation of many fundamental issues involved in the design of a protocol. These include the issues of correctness, performance, and protocol complexity. The design of the DASH coherence protocol is presented and discussed from the viewpoint of how it addresses the above issues. Also discussed is a strategy for verifying the correctness of the protocol. A brief comparison of the protocol with the IEEE Scalable Coherent Interface protocol is made.},
  keywords={},
  doi={10.1109/ISCA.1990.134520},
  ISSN={},
  month={May},}
@INPROCEEDINGS{555359,
  author={Huisman, L. and Daoud, R. and Nair, I.},
  booktitle={Proceedings of the Fifth Distributed Memory Computing Conference, 1990.}, 
  title={Fault Simulation on Message Passing}, 
  year={1990},
  volume={},
  number={},
  pages={33-41},
  abstract={},
  keywords={},
  doi={10.1109/DMCC.1990.555359},
  ISSN={},
  month={April},}
@ARTICLE{44366,
  author={De Vries, R.C.},
  journal={IEEE Transactions on Software Engineering}, 
  title={Reducing null messages in Misra's distributed discrete event simulation method}, 
  year={1990},
  volume={16},
  number={1},
  pages={82-91},
  abstract={Consideration is given to the implementation of distributed discrete-event simulation (DDES) using what has been commonly called the Misra approach, after one of its inventors. A major problem with DDES is that deadlock can occur. Therefore, DDES algorithms must either avoid deadlock in the first place, or detect the existence of deadlock when it does occur and eliminate it. J. Misra (1986) proposes the use of null messages as one way to circumvent the deadlock problem. However the number of null messages can become quite large. Methods are presented for reducing the number of null messages through the prediction of channel times. A framework is presented on the basis of which distributed discrete-event simulation can be built for applications that can be decomposed into feedforward and feedback networks.},
  keywords={},
  doi={10.1109/32.44366},
  ISSN={1939-3520},
  month={Jan},}
@ARTICLE{53600,
  author={Dandamudi, S.P. and Eager, D.L.},
  journal={IEEE Transactions on Computers}, 
  title={Hierarchical interconnection networks for multicomputer systems}, 
  year={1990},
  volume={39},
  number={6},
  pages={786-797},
  abstract={A performance analysis of a class of hierarchical interconnection networks is presented. The analysis includes both static analysis (i.e. queueing delays are neglected) and queueing analysis. In both cases, the hierarchical networks are shown to have better cost-benefit ratios. The queueing analysis is also validated by several simulation experiments. The impact of two performance enhancement schemes-replication of links and improved routing algorithms-on hierarchical interconnection network performance is also presented.},
  keywords={},
  doi={10.1109/12.53600},
  ISSN={1557-9956},
  month={June},}
@ARTICLE{54837,
  author={Balasubramanian, V. and Banerjee, P.},
  journal={IEEE Transactions on Computers}, 
  title={Compiler-assisted synthesis of algorithm-based checking in multiprocessors}, 
  year={1990},
  volume={39},
  number={4},
  pages={436-446},
  abstract={The task of synthesizing algorithm-based checking techniques for general applications is investigated. The problem is approached at the compiler level by identifying linear transformations in Fortran DO loops and restructuring program statements to convert nonlinear transformations to linear ones. System-level checks based on this property are proposed. The approach is demonstrated with example problems of matrix multiplication and the LINPACK routine: DGEFA.},
  keywords={},
  doi={10.1109/12.54837},
  ISSN={1557-9956},
  month={April},}
@ARTICLE{54839,
  author={Wu, K.-L. and Fuchs, W.K.},
  journal={IEEE Transactions on Computers}, 
  title={Recoverable distributed shared virtual memory}, 
  year={1990},
  volume={39},
  number={4},
  pages={460-469},
  abstract={The problem of rollback recovery in distributed shared virtual environments, in which the shared memory is implemented in software in a loosely coupled distributed multicomputer system, is examined. A user-transparent checkpointing recovery scheme and a new twin-page disk storage management technique are presented for implementing recoverable distributed shared virtual memory. The checkpointing scheme can be integrated with the memory coherence protocol for managing the shared virtual memory. The twin-page disk design allows checkpointing to proceed in an incremental fashion without an explicit undo at the time of recovery. The recoverable distributed shared virtual memory allows the system to restart computation from a checkpoint without a global restart.},
  keywords={},
  doi={10.1109/12.54839},
  ISSN={1557-9956},
  month={April},}
@INPROCEEDINGS{77144,
  author={Al-Jaber, H. and Rotenstreich, S.},
  booktitle={Proceedings. PARBASE-90: International Conference on Databases, Parallel Architectures, and Their Applications}, 
  title={Fault tolerance of message delivery with cascading copies}, 
  year={1990},
  volume={},
  number={},
  pages={221-230},
  abstract={The authors present a fault-tolerance algorithm that guarantees the delivery of a message to its destination despite faults in one or more nodes in a system of loosely coupled processors. This algorithm is distinguished by not using the extra hardware or checkpoint facilities that are common to many algorithms of its type. Instead, it maintains an appropriate number of copies of the message in the nodes through which the message passes. In the case of a fault, the algorithm locates a copy of the message closest to the destination and resumes delivery of the message from this location. Failure detection and recovery are automatic and transparent to the users. The algorithm can be implemented on diskless systems, such as specialized real-time systems or parallel processing systems that use interconnection networks (e.g. a hypercube).},
  keywords={},
  doi={10.1109/PARBSE.1990.77144},
  ISSN={},
  month={March},}
@INPROCEEDINGS{82143,
  author={Whitson, G. and Wu, C. and Ermongkonchai, A. and Weber, J.},
  booktitle={Proceedings of the 1990 Symposium on Applied Computing}, 
  title={A backpropagation system for hypercubes}, 
  year={1990},
  volume={},
  number={},
  pages={71-77},
  abstract={A backpropagation system for a hypercube which will select one of two implementations, depending on the size of the application, is described. One algorithm executes quickly at the cost of storage. The other optimizes storage at the cost of execution. Both algorithms have considerable message passing. The system is menu driven and has a set of tools to allow the user to determine the correct initial weight matrix W more accurately when the standard guess does not work. This set of tools is especially appropriate for an interactive supercomputer such as an Intel Hypercube. Although the system has been designed to work for a wide range of applications, the authors are especially interested in using it with very large artificial neural systems to do protein identification and classification.},
  keywords={},
  doi={10.1109/SOAC.1990.82143},
  ISSN={},
  month={April},}
@ARTICLE{80128,
  author={Banerjee, P. and Jones, M.H. and Sargent, J.S.},
  journal={IEEE Transactions on Parallel and Distributed Systems}, 
  title={Parallel simulated annealing algorithms for cell placement on hypercube multiprocessors}, 
  year={1990},
  volume={1},
  number={1},
  pages={91-106},
  abstract={A discussion is presented of two ways of mapping the cells in a two-dimensional area of a chip onto processors in an n-dimensional hypercube such that both small and large cell moves can be applied. Two types of move are allowed: cell exchanges and cell displacements. The computation of the cost function in parallel among all the processors in the hypercube is described, along with a distributed data structure that needs to be stored in the hypercube to support such a parallel cost evaluation. A novel tree broadcasting strategy is presented for the hypercube that is used extensively in the algorithm for updating cell locations in the parallel environment. A dynamic parallel annealing schedule is proposed that estimates the errors due to interacting parallel moves and adapts the rate of synchronization automatically. Two novel approaches in controlling error in parallel algorithms are described: heuristic cell coloring and adaptive sequence control. The performance on an Intel iPSC-2/D4/MX hypercube is reported.},
  keywords={},
  doi={10.1109/71.80128},
  ISSN={1558-2183},
  month={Jan},}
@INPROCEEDINGS{89277,
  author={Fowler, J. and Zwaenepoel, W.},
  booktitle={Proceedings.,10th International Conference on Distributed Computing Systems}, 
  title={Causal distributed breakpoints}, 
  year={1990},
  volume={},
  number={},
  pages={134-141},
  abstract={The authors define a causal distributed breakpoint, which is initiated by a sequential breakpoint in one process of a distributed computation and restores each process in the computation to its earliest state that reflects all events that happened before the breakpoint. An algorithm for finding the causal distributed breakpoint, given a sequential breakpoint in one of the processes, is presented. Approximately consistent checkpoint sets are used for efficiently restoring each process to its state in a causal distributed breakpoint. Causal distributed breakpoints assume deterministic processes that communicate solely by messages. The dependencies that arise from communication between processes are logged. Dependency logging and approximately consistent checkpoint sets are implemented on a network of SUN workstations running the V-System. Overhead on the message-passing primitives varies between 1% and 14% for dependency logging. Execution time overhead for a 200*200 Gaussian elimination is less than 4% and generates a dependency log of 288 kbytes.},
  keywords={},
  doi={10.1109/ICDCS.1990.89277},
  ISSN={},
  month={May},}
@INPROCEEDINGS{89181,
  author={Xu, J. and Hwang, K.},
  booktitle={Sixth Conference on Artificial Intelligence for Applications}, 
  title={A simulated annealing method for mapping production systems onto multicomputers}, 
  year={1990},
  volume={},
  number={},
  pages={130-136 vol.1},
  abstract={A methodology for mapping rule-based expert systems onto a message-passing multicomputer is presented. The method is based on static load balancing using simulated annealing to achieve a nearly optimal allocation of multiple production rules to processor nodes. The goal is to balance the initial load distribution and to avoid serious communication overhead among processor nodes at run time. A formal model is developed and a cost function is defined in the annealing process. Heuristic swap functions and cooling policies which ensure the efficiency and quality of the annealing process are given. A software load-balancing package is implemented on a SUN 3/280 workstation to carry out the benchmark experiments. The overhead associated with this mapping method is O(m ln m), where m is the number of production rules in the system. The Monkey and Bananas expert system with 24 rules is mapped onto an 8-node hypercube. Experimental results verify the effectiveness of the mapping method. The method can be applied in practical parallel production systems and to achieve scalability in performance.},
  keywords={},
  doi={10.1109/CAIA.1990.89181},
  ISSN={},
  month={May},}
@INPROCEEDINGS{175670,
  author={Schill, A. and Blakowski, G.},
  booktitle={SBT/IEEE International Symposium on Telecommunications}, 
  title={Configuration management for distributed object-oriented applications}, 
  year={1990},
  volume={},
  number={},
  pages={577-581},
  abstract={A separate configuration language with associated management mechanisms has been developed. The approach supports the initial structure and placement description of a distributed object-oriented application as well as dynamic configuration changes. Moreover, configuration conditions can be stated and are checked against an actual configuration. The authors describe the configuration language, the configuration management algorithms, and the integration with the underlying object-oriented system. A first prototype of this approach has been implemented in C++ in VAX stations using the compiler construction tools Lex and Yacc.},
  keywords={},
  doi={10.1109/ITS.1990.175670},
  ISSN={},
  month={Sep.},}
@INPROCEEDINGS{138248,
  author={Herlihy, M.},
  booktitle={[1990] Proceedings. Workshop on the Management of Replicated Data}, 
  title={Type-specific replication algorithms for multiprocessors}, 
  year={1990},
  volume={},
  number={},
  pages={70-74},
  abstract={The use of replication for enhancement of the availability of data in multiprocessor systems is discussed. The author explores theoretical aspects of the extent to which it is possible to exploit the semantics of data to make replication more effective. Some of the literature is surveyed, and some opinions about appropriate models and interesting open questions are presented. In particular, linearizability as an appropriate correctness criterion for concurrent objects, wait-free synchronization, and synchronous and asynchronous message-passing models are discussed.},
  keywords={},
  doi={10.1109/MRD.1990.138248},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{113814,
  author={Millard, B.R. and Miller, D.S. and Wu, C.},
  booktitle={[1991 Proceedings] Tenth Annual International Phoenix Conference on Computers and Communications}, 
  title={Support for Ada intertask communication in a message-based distributed operating system}, 
  year={1991},
  volume={},
  number={},
  pages={219-225},
  abstract={The application environment and hardware base this paper addresses are Ada applications running on a testbed of modern networked multiprocessor workstations. The authors address the question of how an operating system's communication facilities should be designed to best support Ada intertask communication running on this hardware. Ada has directives specifically designed to support parallel operation of tasks by facilitating communication and synchronization between them. Support for these directives using the communication facilities of the BIGSAM distributed operating system is presented. The BIGSAM kernel provides message based communication for the processes that run on it, a mechanism that is well matched to the Ada intertask communication primitives. The authors analyze the distributed operating system message passing functionality required to support the intertask communication and synchronization primitives on which the Ada rendezvous is based.},
  keywords={},
  doi={10.1109/PCCC.1991.113814},
  ISSN={},
  month={March},}
@INPROCEEDINGS{113832,
  author={Valenzano, A. and Sisto, R. and Ciminiera, L.},
  booktitle={[1991 Proceedings] Tenth Annual International Phoenix Conference on Computers and Communications}, 
  title={Derivation of executable code from formal protocol specifications written in LOTOS}, 
  year={1991},
  volume={},
  number={},
  pages={346-352},
  abstract={A novel tool for generating implementation prototypes of communication protocols and concurrent systems specified using the ISO LOTOS language is presented. LOTOS specifications are analyzed and translated into C functions that are executed by cooperating processes in the UNIX environment. The set of LOTOS process definitions is first translated into a suitable number of extended finite state machines (EFSMs). The proposed method makes it possible to circumvent the problem of deriving unbounded EFSMs and to obtain a sort of control on the process number/size tradeoff at the same time. The problem of implementing the LOTOS multi-way rendezvous mechanism for process synchronization is solved by an algorithm based on message passing. An example of prototype derivation is also introduced showing the form of C code generated by translating a simple specification.},
  keywords={},
  doi={10.1109/PCCC.1991.113832},
  ISSN={},
  month={March},}
@INPROCEEDINGS{140034,
  author={Xu, M.Q. and Turner, S.J.},
  booktitle={1991 Second International Specialist Seminar on the Design and Application of Parallel Digital Processors}, 
  title={Parallelization of a predator-prey simulation using time warp}, 
  year={1991},
  volume={},
  number={},
  pages={137-141},
  abstract={It has long been considered that the predator-prey simulation can only be tackled by time-driven simulation because unpredictable interactions may only be detected by exhaustive testing. The authors describe the parallelization of this application using a 'Simulation Testbed' developed within the Parallel Systems Group at Exeter University. Mapping a simulation onto a message-passing parallel architecture is particularly difficult when it involves interactions between moving objects (such as predators and prey). The main problems which arise in the parallelization of this type of simulation using the 'Time Warp' mechanism are discussed.},
  keywords={},
  doi={},
  ISSN={},
  month={April},}
@INPROCEEDINGS{143878,
  author={Ahmad, I. and Samadzadeh, M.H.},
  booktitle={[Proceedings] 1991 Symposium on Applied Computing}, 
  title={Software metrics for parallel programs}, 
  year={1991},
  volume={},
  number={},
  pages={223-},
  abstract={Software engineering has several fields one which is the study of static measurements of programs as indicators of their maintainability, reliability and clarity. There is a need to develop parallel software metrics. There are several ways to explore the feasibility and plausibility of parallel software metrics. One way is by proposing new metrics exclusively developed for parallel software. Another way is by applying the existing software metrics, originally proposed for sequential programs and analyzing their applicability. The authors have adopted both ways. The test suite for the study is a compendium of parallel programs. The compendium contains over 30 programs ranging in length from 500 to 14000 lines. All programs in the compendium were written in C on Intel's iPSC/1 or iPSC/2 parallel computers.},
  keywords={},
  doi={10.1109/SOAC.1991.143878},
  ISSN={},
  month={April},}
@INPROCEEDINGS{145412,
  author={Koutny, M. and Mancini, L.V. and Pappalardo, G.},
  booktitle={[1991] Proceedings Tenth Symposium on Reliable Distributed Systems}, 
  title={Formalising replicated distributed processing}, 
  year={1991},
  volume={},
  number={},
  pages={108-117},
  abstract={The authors present a novel formal approach to proving the correctness of distributed systems of replicated processes that communicate by message passing. The notion of correctness introduced is based on the consistency of the replicated system with its nonreplicated counterpart. The formal framework of CSP (communicating sequential processes) allows the proof of partial correctness and deadlock-freedom properties of the systems of replicated processes. The authors also discuss how a replicated process may be implemented by N-base copies, a majority of which are non-faulty, and point out the necessity of coordinating the copies and the requirements they should satisfy.},
  keywords={},
  doi={10.1109/RELDIS.1991.145412},
  ISSN={},
  month={Sep.},}
@INPROCEEDINGS{148661,
  author={Ananda, A.L. and Tay, B.H. and Koh, E.K.},
  booktitle={[1991] Proceedings. 11th International Conference on Distributed Computing Systems}, 
  title={ASTRA-an asynchronous remote procedure call facility}, 
  year={1991},
  volume={},
  number={},
  pages={172-179},
  abstract={A transport-independent asynchronous RPC (remote procedure call) mechanism (ASTRA) that combines the advantages of both RPC and message-passing IPC (interprocess communication) has been designed and implemented. ASTRA calls do not block the caller (client) and the replies can be received as and when they are needed, thus allowing the client execution to proceed locally in parallel with the server invocation. All the calls are received and executed by the server in the order called by the client. ASTRA is unique among other asynchronous RPC systems in allowing its users to explicitly specify whether low-latency or high-throughput is required for a call, and in providing highly optimized lightweight intramachine calls. ASTRA is built within the framework of the SHILPA distributed computing environment.},
  keywords={},
  doi={10.1109/ICDCS.1991.148661},
  ISSN={},
  month={May},}
@INPROCEEDINGS{633130,
  author={Zhiwei Xu},
  booktitle={The Sixth Distributed Memory Computing Conference, 1991. Proceedings}, 
  title={Structured Parallel Programming on Multicomputers}, 
  year={1991},
  volume={},
  number={},
  pages={218-221},
  abstract={},
  keywords={},
  doi={10.1109/DMCC.1991.633130},
  ISSN={},
  month={April},}
@ARTICLE{84214,
  author={Heath, M.T. and Etheridge, J.A.},
  journal={IEEE Software}, 
  title={Visualizing the performance of parallel programs}, 
  year={1991},
  volume={8},
  number={5},
  pages={29-39},
  abstract={ParaGraph, a software tool that provides a detailed, dynamic, graphical animation of the behavior of message-passing parallel programs and graphical summaries of their performance, is presented. ParaGraph animates trace information from actual runs to depict behavior and obtain the performance summaries. It provides twenty-five perspectives on the same data, lending insight that might otherwise be missed. ParaGraph's features are described, its use is explained, its software design is briefly discussed, and its displays are examined in some detail. Future work on ParaGraph is indicated.},
  keywords={},
  doi={10.1109/52.84214},
  ISSN={1937-4194},
  month={Sep.},}
@ARTICLE{86104,
  author={Krothapalli, V.P. and Sadayappan, P.},
  journal={IEEE Transactions on Parallel and Distributed Systems}, 
  title={Removal of redundant dependences in DOACROSS loops with constant dependences}, 
  year={1991},
  volume={2},
  number={3},
  pages={281-289},
  abstract={An efficient algorithm to remove redundant dependences in simple loops with constant dependences is presented. Dependences constrain the parallel execution of programs and are typically enforced by synchronization instructions. The synchronization instructions represent a significant part of the overhead in the parallel execution of a program. Some program dependences are redundant because they are covered by other dependences. It is shown that unlike with single loops, in the case of nested loops, a particular dependence may be redundant at some iterations but not redundant at others, so that the redundancy of a dependence may not be uniform over the entire iteration space. A sufficient condition for the uniformity of redundancy in a doubly nested loop is developed.},
  keywords={},
  doi={10.1109/71.86104},
  ISSN={1558-2183},
  month={July},}
@INPROCEEDINGS{206417,
  author={Mueller-Thuns, R.B. and Saab, D.G. and Abraham, J.A.},
  booktitle={Proceedings of the European Conference on Design Automation.}, 
  title={Parallel switch-level simulation for VLSI}, 
  year={1991},
  volume={},
  number={},
  pages={324-328},
  abstract={Switch-level simulation is widely used in the design verification process of Very Large Scale Integrated (VLSI) MOS circuits. In this paper, the authors present methods for accelerating switch-level simulation by mapping it onto general purpose parallel computers. Their target machines are medium-grain multiprocessors (shared memory or message passing machines) and they only consider model parallel computation, where the model of the design to be simulated is partitioned among processors. Efficient strategies are introduced for circuit partitioning as well as the corresponding simulation algorithms. In the authors' approach, they try to minimize the total number of synchronizations between processors, as well as ensure portability and scalability. A preprocessor and simulator were implemented and good performance was obtained for a set of benchmarks. The problem of tight coupling between processors that evaluate a strongly connected component in the circuit in a distributed fashion is highlighted.},
  keywords={},
  doi={10.1109/EDAC.1991.206417},
  ISSN={},
  month={Feb},}
@INPROCEEDINGS{240608,
  author={Ramos, C. and Oliveira, E.},
  booktitle={Fifth International Conference on Advanced Robotics 'Robots in Unstructured Environments}, 
  title={The generation of efficient high level plans and the robot world representation in a cooperative community of robotic agents}, 
  year={1991},
  volume={},
  number={},
  pages={477-481 vol.1},
  abstract={Deals with the following main topics: the view of a robotic cell as a community of intelligent systems; the efficient generation of high-level plans to assemble parts of real objects; and the translation from perception outputs (obtained by computer vision) to symbolic relationships. In the approach, the robotic multi-agent community has six members: the user, the object models, the object identifier, the world descriptor, the high level planner and the low level executor. The distributed artificial intelligence is the framework and the communication between different agents is supported by message passing primitives.},
  keywords={},
  doi={10.1109/ICAR.1991.240608},
  ISSN={},
  month={June},}
@INPROCEEDINGS{170235,
  author={Tamai, T.},
  booktitle={[1991] Proceedings The Fifteenth Annual International Computer Software & Applications Conference}, 
  title={Formal and informal approaches for validation}, 
  year={1991},
  volume={},
  number={},
  pages={534-535},
  abstract={The author considers applying conventional approaches to validate OOS (object-oriented systems) and then investigates new aspects caused by the properties of OOS. He also focuses on two issues, each representing a typical property of the static aspect and the dynamic aspect. The issues examined are abstraction hierarchy consistency and concurrent behavior correctness.},
  keywords={},
  doi={10.1109/CMPSAC.1991.170235},
  ISSN={},
  month={Sep.},}
@INPROCEEDINGS{185128,
  author={Chienhua Chen and Agrawal, D.P. and Burke, J.R.},
  booktitle={[1991] Proceedings. Fourth CSI/IEEE International Symposium on VLSI Design}, 
  title={A class of hierarchical networks for VLSI/WSI based multicomputers}, 
  year={1991},
  volume={},
  number={},
  pages={267-272},
  abstract={A class of hierarchical networks is proposed for multicomputer implementation using VLSI and wafer scale integration (VLSI/WSI). These networks, called DBCube, connect clusters of cube topology based nodes with a De Bruijn graph. The nodes are identical and can be easily extended to a larger size. The cube topology for local communication allows easy embedding of parallel algorithms and the De Bruijn graph provides shortest distance among different clusters. The authors compare the DBCube with other networks in terms of topological properties. They compute the silicon area requirement of DBCube. The DBCube topology is such that testing of the network before metallization make it easily configurable to DBCube of smaller size. Potential extension of the DBCube is also addressed.},
  keywords={},
  doi={10.1109/ISVD.1991.185128},
  ISSN={},
  month={Jan},}
@INPROCEEDINGS{185095,
  author={Sivaramakrishnan, V. and Seth, S.C. and Agrawal, P.},
  booktitle={[1991] Proceedings. Fourth CSI/IEEE International Symposium on VLSI Design}, 
  title={Parallel test pattern generation using Boolean satisfiability}, 
  year={1991},
  volume={},
  number={},
  pages={69-74},
  abstract={Recently, Larrabee proposed a sequential test generation algorithm for combinational circuits based on Boolean satisfiability and presented results on benchmark circuits in support of the viability of this approach. Parallel implementations of test generation algorithms are attractive in view of the known difficulty (NP-completeness) of the problem. This paper suggests parallel versions of Larrabee's algorithm, suitable for implementation on shared-memory and message-passing multicomputers.},
  keywords={},
  doi={10.1109/ISVD.1991.185095},
  ISSN={},
  month={Jan},}
@INPROCEEDINGS{257409,
  author={Bechennec, J.-L. and Germain, C. and Neri, V.},
  booktitle={[1991] Proceedings, Advanced Computer Technology, Reliable Systems and Applications}, 
  title={An efficient hardwired router for a 3D-mesh interconnection network}, 
  year={1991},
  volume={},
  number={},
  pages={353-357},
  abstract={A routing circuit for massively parallel message-passing architectures is presented. This circuit meets the area requirements of a monochip processing element and is time-efficient. It implements a new routing algorithm, forced routing. It is shown that the forced routing algorithm may be hardwired in less than a 10 mm/sup 2/ circuit in a CMOS 1.2 mu m process. Several design choices are discussed and tested for the arbiter, which is the most critical part of the circuit.},
  keywords={},
  doi={10.1109/CMPEUR.1991.257409},
  ISSN={},
  month={May},}
@ARTICLE{149963,
  author={Hsu, J.-M. and Banerjee, P.},
  journal={IEEE Transactions on Parallel and Distributed Systems}, 
  title={Performance measurement and trace driven simulation of parallel CAD and numeric applications on a hypercube multicomputer}, 
  year={1992},
  volume={3},
  number={4},
  pages={451-464},
  abstract={The performance evaluation, workload characterization, and trace-driven simulation of a hypercube multicomputer running realistic workloads are presented. Eleven representative parallel applications were selected as benchmarks. Software monitoring techniques were then used to collect execution traces. Based on the measurement results, both the computation and communication behavior of these parallel programs were investigated. The various time interval distributions were modeled by statistical functions which were verified by a nonlinear regression technique using the empirical data. The temporal and spatial localities of message destinations were also studied. A model for the temporal locality of message length was introduced and used to analyze the communication traces. A trace-drive simulation environment, which uses the communication patterns of the parallel programs as inputs, was developed to study the behavior of the communication hardware under real workload. Simulation results on DMA and link utilizations are reported.},
  keywords={},
  doi={10.1109/71.149963},
  ISSN={1558-2183},
  month={July},}
@INPROCEEDINGS{152135,
  author={Etzkorn, G.},
  booktitle={1992 International Workshop on Configurable Distributed Systems}, 
  title={Change programming in distributed systems}, 
  year={1992},
  volume={},
  number={},
  pages={140-151},
  abstract={Distributed programs consist of multiple processes that cooperate by message passing to fulfil some global task. An interesting extension is the provision of dynamic changes for distributed programs as a means to establish evolutionary systems. The author models the development of distributable programs using the configuration programming approach (J. Kramer, 1990), that is developed further in the Esprit II project REX on reconfigurable and extensible parallel and distributed systems. A key principle of this approach is the separation of the functional description of individual process behaviour from the description of system structure viewed as a set of processes and their interconnections. The author presents fundamentals of the distributed system model followed by an explanation of programming notation, as used for the distinct levels of configuration and process programming. He describes two distinct views of reconfiguration states. Then all important notions according to a change programming approach are introduced. He shows a detailed example and briefly discusses some correctness aspects. The author also evaluates the proposed model against that of J. Kramer, J. Magee (1990) and an outline of future research work is given.},
  keywords={},
  doi={},
  ISSN={},
  month={May},}
@ARTICLE{156157,
  author={Willis, J.C. and Siewiorek, D.P.},
  journal={IEEE Design & Test of Computers}, 
  title={Optimizing VHDL compilation for parallel simulation}, 
  year={1992},
  volume={9},
  number={3},
  pages={42-53},
  abstract={Auriga, an experimental simulator that utilizes five compilation techniques to reduce runtime complexity and promote concurrency in the simulation of VHDL models is described. Auriga is designed to translate a model using any VHDL construct into an optimized, parallel simulation. Auriga's distributed simulation uses a message-passing network to simulate a single VHDL model. The authors present results obtained with seven benchmark models to illustrate the compiler's aggressive optimization techniques: temporal analysis, waveform propagation, input desensitization, concurrent evaluation, and statement compaction.},
  keywords={},
  doi={10.1109/54.156157},
  ISSN={1558-1918},
  month={Sep.},}
@ARTICLE{159039,
  author={Yang, S.-M. and Kim, K.H.},
  journal={IEEE Transactions on Parallel and Distributed Systems}, 
  title={Implementation of the conversation scheme in message-based distributed computer systems}, 
  year={1992},
  volume={3},
  number={5},
  pages={555-572},
  abstract={Several different approaches for implementing conversations in message-based distributed computer systems (DCSs) are discussed. Two different exit control strategies (synchronous and asynchronous) and three different approaches to execution of the conversation acceptance test (centralized, decentralized, and semicentralized) are examined and compared in terms of system performance and implementation cost. An efficient approach to run-time management of recovery information based on an extension of the recovery cache scheme is also discussed. The two major types of conversation structures, name-linked recovery block and abstract data type conversations, are examined to analyze which execution approaches are the most efficient for each conversation structure. As a case study, an unmanned vehicle system is used to illustrate how the approaches can be used in a realistic real-time application.},
  keywords={},
  doi={10.1109/71.159039},
  ISSN={1558-2183},
  month={Sep.},}
@INPROCEEDINGS{246261,
  author={Schaefer, M.T.L. and Klein, W.U.},
  booktitle={Proceedings EURO-DAC '92: European Design Automation Conference}, 
  title={Correctness verification of concurrent controller specifications}, 
  year={1992},
  volume={},
  number={},
  pages={80-85},
  abstract={An integrated design concept that focuses on the correctness of concurrent controllers is presented. This approach is based on the specification of concurrent tasks with the aid of structured flow charts. A new formal proceeding for the verification of the correct behavior is introduced. Algorithms reduce the verification process to a polynomial amount of computational effort. The method can be applied even for the design of large systems.},
  keywords={},
  doi={10.1109/EURDAC.1992.246261},
  ISSN={},
  month={Sep.},}
@INPROCEEDINGS{202424,
  author={Harden, J. and Reese, D. and To, F. and Linder, D. and Borchert, C. and Jones, G.},
  booktitle={Proceedings IEEE Southeastcon '92}, 
  title={A performance monitor for the MSPARC multicomputer}, 
  year={1992},
  volume={},
  number={},
  pages={724-729 vol.2},
  abstract={A hybrid performance monitor developed for MSPARC, a mesh-connected, message-passing multicomputer, is described. The development of the hybrid performance monitor was a cross-disciplinary enterprise requiring custom hardware and a range of software support including monitor code, driver interfaces, probe history acquisition and processing, graphical display, and application probe injection. Programmable hardware was designed to unobtrusively collect events on each node and maintain their accurate chronological order. This distributed collection system was coupled by its independent network to a central monitor where data selection and presentation techniques played an important role in the visualization of the parallel system's execution.},
  keywords={},
  doi={10.1109/SECON.1992.202424},
  ISSN={},
  month={April},}
@INPROCEEDINGS{217509,
  author={Hurfin, M. and Plouzeau, N. and Raynal, M.},
  booktitle={Proceedings of the Third Workshop on Future Trends of Distributed Computing Systems}, 
  title={EREBUS: a debugger for asynchronous distributed computing systems}, 
  year={1992},
  volume={},
  number={},
  pages={93-98},
  abstract={This paper addresses the problem of debugging distributed programs executed on distributed memory parallel computers with message-passing interprocess communication. The main issues of debugging such programs are exposed. Principles for designing and implementing a debugger for programs specified in the Estelle language are presented. All the described solutions have been implemented in a distributed debugger called EREBUS.},
  keywords={},
  doi={10.1109/FTDCS.1992.217509},
  ISSN={},
  month={April},}
@INPROCEEDINGS{217480,
  author={Sheu, S.-M. and Ho, J.-M. and Juang, J.Y.},
  booktitle={Proceedings of the Third Workshop on Future Trends of Distributed Computing Systems}, 
  title={Decomposition of object-oriented programs for fault tolerant computing in distributed environment}, 
  year={1992},
  volume={},
  number={},
  pages={304-310},
  abstract={This paper describes a program decomposition scheme that decomposes a C++ program into a set of concurrent tasks to support fault tolerant computing in distributed environments. This scheme consists of a C++ analyzer for program decomposition and a set of mechanisms to perform run-time object backup and error recovery. The analyzer uses a weighted-object approach to decompose an object into a set of concurrent tasks or combines a set of objects into a single task. The analyzer guarantees that the resulting decomposition will not violate system resource constraints. A reliable message passing protocol is also generated by the program analyzer for remote object references. Run time supports for fault tolerant computing based on the decomposed objects are discussed, which consist of an interface, a reliable message passing mechanism and a recovery mechanism. The message passing mechanism updates backup storage whenever a message is passed to avoid Domino effect.},
  keywords={},
  doi={10.1109/FTDCS.1992.217480},
  ISSN={},
  month={April},}
@INPROCEEDINGS{217571,
  author={Lutfiyya, H. and Sun, A. and McMillin, B.},
  booktitle={[1992] Proceedings. The Sixteenth Annual International Computer Software and Applications Conference}, 
  title={Fault-tolerant concurrent branch and bound algorithms derived from program verification}, 
  year={1992},
  volume={},
  number={},
  pages={182-187},
  abstract={One approach for providing fault tolerance is through examining the behavior and properties of the application and deriving executable assertions that detect faults. This paper focuses on transforming the assertions of a verification proof of a program to executable assertions. These executable assertions may be embedded in the program to create a fault-tolerant program. It is also shown how the natural redundancy of the program variables can be used to reduce the number of executable assertions needed. While this approach has been applied to the sequential programming environment, the distributed programming environment presents special challenges. The authors discuss the application of concurrent programming axiomatic proof systems to generate executable assertions in a distributed environment using distributed branch and bound as a model problem.},
  keywords={},
  doi={10.1109/CMPSAC.1992.217571},
  ISSN={},
  month={Sep.},}
@INPROCEEDINGS{217490,
  author={Chih-Cheng Lien and Chien-Chiao Yang},
  booktitle={Proceedings of the Third Workshop on Future Trends of Distributed Computing Systems}, 
  title={Reduction of useless services with timing constraints}, 
  year={1992},
  volume={},
  number={},
  pages={226-231},
  abstract={A distributed computing system consists of objects and messages which are transmitted between objects. An object can request other objects to do some services by passing messages through a communication system. Usually, the services are done if the message transmission on the communication system is reliable. However, in some applications with timing constraints, a service may be of no value if it violates some constraints. The authors thus can allow the object to send the constraint within the message to avoid this useless service. In validating the satisfaction of a service for a constraint, using the current elapsed time and using the predicted elapsed time are discussed. The relative accuracy of the prediction in several types of message transmissions is also explained.},
  keywords={},
  doi={10.1109/FTDCS.1992.217490},
  ISSN={},
  month={April},}
@INPROCEEDINGS{222967,
  author={Bogineni, K. and Dowd, P.W.},
  booktitle={Proceedings Sixth International Parallel Processing Symposium}, 
  title={Performance analysis of two address space allocation schemes for an optically interconnected distributed shared memory system}, 
  year={1992},
  volume={},
  number={},
  pages={562-566},
  abstract={An Optically Interconnected Distributed Shared Memory (OIDSM) system is introduced and analyzed. Distributed shared memory systems place a heavy traffic requirement on the interconnection network. Complex memory allocation schemes have been introduced to reduce the network load. The photonic network of the system introduced in this paper alleviates the traffic load concern, and enables the development of a fixed memory allocation scheme with a significant reduction in complexity. The photonic network employs wavelength division multiple access (WDMA), creating multiple channels on a single optical fiber. This paper analyzes the performance of two memory allocation schemes through mean value analysis of a closed queueing network. The performance model is validated through simulation.},
  keywords={},
  doi={10.1109/IPPS.1992.222967},
  ISSN={},
  month={March},}
@INPROCEEDINGS{227689,
  author={Johnson, T. and Davis, T.},
  booktitle={Proceedings ICCI `92: Fourth International Conference on Computing and Information}, 
  title={Space efficient parallel buddy memory management}, 
  year={1992},
  volume={},
  number={},
  pages={128-132},
  abstract={Shared memory multiprocessor systems need efficient dynamic storage allocators, both for system purposes and to support parallel programs. Memory managers are often based on the buddy system, which provides fast allocation and release. Previous parallel buddy memory managers made no attempt to coordinate the allocation, splitting and release of blocks, and as a result needlessly fragment memory. The authors present fast, and simple parallel buddy memory manager that is also as space efficient as a serial buddy memory manager. They test their algorithms using memory allocation/deallocation traces their collected from a parallel sparse matrix algorithm.},
  keywords={},
  doi={10.1109/ICCI.1992.227689},
  ISSN={},
  month={May},}
@INPROCEEDINGS{227783,
  author={Bose, S. and Agrawal, P.},
  booktitle={[1992] Proceedings 29th ACM/IEEE Design Automation Conference}, 
  title={Concurrent fault simulation of logic gates and memory blocks on message passing multicomputers}, 
  year={1992},
  volume={},
  number={},
  pages={332-335},
  abstract={The authors present a concurrent fault simulation algorithm. The pipelined algorithm is suitable for implementation on memory limited hardware accelerators and message passing multicomputers or specialized hardware. The architecture of the system and the data structures and algorithms for some of the crucial parts of the fault simulation algorithm are outlined. For pipelined architectures, fault simulation is illustrated for circuits modeled at mixed functional and gate levels. The results indicate an order of magnitude speed up compared to a production quality simulator running on a SUN SPARC2.},
  keywords={},
  doi={10.1109/DAC.1992.227783},
  ISSN={0738-100X},
  month={June},}
@INPROCEEDINGS{232692,
  author={Stramm, B. and Berman, F.},
  booktitle={Proceedings Scalable High Performance Computing Conference SHPCC-92.}, 
  title={Predicting the performance of large programs on scalable multicomputers}, 
  year={1992},
  volume={},
  number={},
  pages={22-29},
  abstract={The paper introduces the retargetable program-sensitive (RPS) model which predicts the performance of static, data-independent parallel programs mapped to message-passing multicomputers. It shows that the model accurately predicts the performance of mapped programs by comparing RPS predictions to actual execution times in the Poker parallel programming environment. The paper also previews plans for further verification of the model on the NCube2 and other multicomputers.},
  keywords={},
  doi={10.1109/SHPCC.1992.232692},
  ISSN={},
  month={April},}
@INPROCEEDINGS{235023,
  author={Kearns, P. and Camp, T. and Ahuja, M.},
  booktitle={[1992] Proceedings of the 12th International Conference on Distributed Computing Systems}, 
  title={An implementation of flush channels based on a verification methodology}, 
  year={1992},
  volume={},
  number={},
  pages={336-343},
  abstract={Flush channels generalize more conventional asynchronous message passing protocols. A distributed system that uses flush channels allows a programmer the flexibility of specifying the delivery order of each message in relation to other messages transmitted on the channel. An implementation technique that follows directly from a verification methodology for flush channels is presented. A relatively formal argument in support of the technique is included.},
  keywords={},
  doi={10.1109/ICDCS.1992.235023},
  ISSN={},
  month={June},}
@INPROCEEDINGS{235132,
  author={Wang, Y.-M. and Fuchs, W.K.},
  booktitle={[1992] Proceedings 11th Symposium on Reliable Distributed Systems}, 
  title={Optimistic message logging for independent checkpointing in message-passing systems}, 
  year={1992},
  volume={},
  number={},
  pages={147-154},
  abstract={Message-passing systems with a communication protocol transparent to the applications typically require message logging to ensure consistency between checkpoints. A periodic independent checkpointing scheme with optimistic logging to reduce performance degradation during normal execution while keeping the recovery cost acceptable is described. Both time and space overhead for message logging can be reduced by detecting messages that need not be logged. A checkpoint space reclamation algorithm is presented to reclaim all checkpoints which are not useful for any possible future recovery. Communication trace-driven simulation for several hypercube programs is used to evaluate the techniques.},
  keywords={},
  doi={10.1109/RELDIS.1992.235132},
  ISSN={},
  month={Oct},}
@INPROCEEDINGS{235131,
  author={Silva, L.M.E. and Silva, J.G.},
  booktitle={[1992] Proceedings 11th Symposium on Reliable Distributed Systems}, 
  title={Global checkpointing for distributed programs}, 
  year={1992},
  volume={},
  number={},
  pages={155-162},
  abstract={A novel algorithm for checkpointing and rollback recovery in distributed systems is presented. Processes belonging to the same program must take periodically a nonblocking coordinated global checkpoint, but only a minimum overhead is imposed during normal computation. Messages can be delivered out of order, and the processes are not required to be deterministic. The nonblocking structure is an important characteristic for avoiding laying a heavy burden on the application programs. The method also includes the damage assessment phase, unlike previous schemes that either assume that an error is detected immediately after it occurs (fail-stop) or simply ignore the damage caused by imperfect detection mechanisms. A possible way to evaluate the error detection latency, which enables one to assess the damage made and avoid the propagation of errors, is presented.},
  keywords={},
  doi={10.1109/RELDIS.1992.235131},
  ISSN={},
  month={Oct},}
@INPROCEEDINGS{242610,
  author={Ladin, R. and Mazer, M.S. and Wolman, A.},
  booktitle={[1992 Proceedings] Second Workshop on the Management of Replicated Data}, 
  title={Replicating the procedure call abstraction}, 
  year={1992},
  volume={},
  number={},
  pages={86-89},
  abstract={The authors recommend replicating the procedure call abstraction as a method for constructing highly available distributed programs. In order to make highly available systems much more widespread than they are today, one must make it easier for application developers to incorporate replication into one's systems. Given that remote procedure call has proven to be a useful abstraction in building distributed programs, replicated procedure call seems to be an appropriate method for introducing high availability while hiding the complexities of replication. The authors argue that the simplicity and familiarity of the procedure call mechanism makes it an excellent model for introducing replication, and they discuss different choices one can make in designing a replicated procedure call system.},
  keywords={},
  doi={10.1109/MRD.1992.242610},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{243616,
  author={Jalote, P.},
  booktitle={[1992] Digest of Papers. FTCS-22: The Twenty-Second International Symposium on Fault-Tolerant Computing}, 
  title={Dynamic reconfiguration of CSP programs for fault tolerance}, 
  year={1992},
  volume={},
  number={},
  pages={50-56},
  abstract={In a distributed computation being performed by a network of communicating processes, failure of a process due to the failure of its host node can cause the entire computation to be aborted. The author proposes a scheme to make a distributed program resilient to the failure of one of its constituent processes. The distributed computation is completed despite the failure of a process. The scheme is for CSP programs and allows nondeterminism within a process. In CSP, the process name is used in input/output commands. Since synchronous communication is used, if a process specified in the input/output command of a process P does not execute a matching output/input command, P might get blocked. In the proposed scheme, if a process fails, another process starts executing on a backup node from the last checkpoint (CP) of the failed process. Programmed exception handling is used to ensure proper recovery and fault tolerance.},
  keywords={},
  doi={10.1109/FTCS.1992.243616},
  ISSN={},
  month={July},}
@INPROCEEDINGS{243599,
  author={Wang, Y.-M. and Fuchs, W.K.},
  booktitle={[1992] Digest of Papers. FTCS-22: The Twenty-Second International Symposium on Fault-Tolerant Computing}, 
  title={Scheduling message processing for reducing rollback propagation}, 
  year={1992},
  volume={},
  number={},
  pages={204-211},
  abstract={The authors show that the probability of rollback propagation in a message-passing system can often be greatly reduced by reordering the processing of messages. Also, rollback propagation was measured for several parallel programs. A scheduling algorithm for message processing and its implementation for reducing rollback propagation are described. The algorithm incorporates a user-transparent prioritized scheme based on the run-time communication and checkpointing history. Communication trace-driven simulation for several parallel programs written in the Chare Kernel language demonstrated that the probability of rollback propagation can be reduced at the cost of slight additional performance degradation.},
  keywords={},
  doi={10.1109/FTCS.1992.243599},
  ISSN={},
  month={July},}
@INPROCEEDINGS{242744,
  author={Xu, C. and Lau, F.C.M.},
  booktitle={[1992] Proceedings of the Fourth IEEE Symposium on Parallel and Distributed Processing}, 
  title={Distributed termination detection of loosely synchronized computations}, 
  year={1992},
  volume={},
  number={},
  pages={196-203},
  abstract={An efficient algorithm for termination detection of loosely synchronized computations is proposed. The proposed algorithm is fully symmetric in that all processes are syntactically identical and can detect global termination simultaneously. It is better in terms of the delay for termination detection than other related algorithms, and is optimal in a number of regular structures. For the hypercube structure of any dimension, the proposed algorithm takes two iteration steps to detect termination after global termination has occurred. In the chain, ring, mesh and torus structures, the improvement is about 50% over its principal competitor. The proposed algorithm requires that the graph be edge-colored and that the color-diameter be known to the processes in advance.},
  keywords={},
  doi={10.1109/SPDP.1992.242744},
  ISSN={},
  month={Dec},}
@ARTICLE{180625,
  author={Islam, N. and Campbell, R.H.},
  journal={IEEE Transactions on Parallel and Distributed Systems}, 
  title={Design considerations for shared memory multiprocessor message systems}, 
  year={1992},
  volume={3},
  number={6},
  pages={702-711},
  abstract={The comparative performance is studied of different message passing system designs experimentally on a shared memory Encore Multimax multiprocessor. The systems are measured both by benchmarks and by running example parallel applications. To act as a control, the shared memory machine results are compared with the performance of the benchmarks and applications on the Intel iPSC/2 running the NX/2 operating system. The design alternatives considered are buffering, buffer organization, reference and value semantics, synchronization, coordination strategy and the location of the system in user or kernel space. The results include measurements of the effects of the design alternatives, memory caching, message sizes and copying.},
  keywords={},
  doi={10.1109/71.180625},
  ISSN={1558-2183},
  month={Nov},}
@INPROCEEDINGS{183172,
  author={Chaumette, S.},
  booktitle={Proceedings of the Twenty-Fifth Hawaii International Conference on System Sciences}, 
  title={A software environment for programming distributed memory machines}, 
  year={1992},
  volume={i},
  number={},
  pages={257-266 vol.1},
  abstract={For efficiency, multiprocessor local memory machines work mostly on the message passing principle, and therefore are programmed using the framework of communicating sequential processes. This programming should be easy to do, and this ease obviously requires an adequate software environment. One such environment, ADAM, is the main topic of the paper. Especially important and time consuming in the development cycle of a distributed application is the debugging phase. Therefore among the tools provided by the ADAM environment, those dedicated to debugging have been emphasized. The most interesting are: a centralized simulator-debugger at the level of the language; a tool based upon traces that enables to see the communication that took place during an execution. The most original part of this work consists of debugging mechanisms dedicated to communication.},
  keywords={},
  doi={10.1109/HICSS.1992.183172},
  ISSN={},
  month={Jan},}
@INPROCEEDINGS{279371,
  author={Ramkumar and Banerjee},
  booktitle={1992 IEEE/ACM International Conference on Computer-Aided Design}, 
  title={Portable parallel test generation for sequential circuits}, 
  year={1992},
  volume={},
  number={},
  pages={220-223},
  abstract={A parallel test generation algorithm, ProperTEST, for sequential circuits that is portable across a range of MIMD parallel architectures is discussed. It uses prioritized execution to ensure consistent speedups as the number of processors is increased. This consistency is achieved without loss of fault coverage with increase in the number of processors. This also permits the use of parallel processing to improve the fault coverage when the execution time is bounded. Results on ISCAS 89 benchmark programs are provided on a shared memory machine, a message passing machine, and a network of workstations. ProperTEST was run unchanged on these different architectures.},
  keywords={},
  doi={10.1109/ICCAD.1992.279371},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{759225,
  author={Cohen, D. and Finn, G. and Felderman, R. and DeSchon, A.},
  booktitle={IEEE Workshop on the Architecture and Implementation of High Performance Communication Subsystems}, 
  title={The Atomic Lan}, 
  year={1992},
  volume={},
  number={},
  pages={0_27-0_32},
  abstract={ATOMIC is an inexpensive O(gigabit) speed LAN built by USCASL it is based upon MOSAIC technology developed for fine-grain, message-passing, massively parallel computation. Each MOSAIC processor is capable of routing variable length packets, while providing added value through simultaneous computing and buffering. ATOMIC scales linearly, with a small interface cost. Each ATOMIC channel has a data carrying capacity of 640Mb/s. A prototype ATOMIC LAN has been constructed along with host interfaces and software that provides full TCP/IP compatibility. Using ATOMIC, 1,500 byte packets have been exchanged between hosts at a rate of more than WM. Other tests have demonstrated throughput of 2.6 million packets per second between two hosts. This paper describes the architecture and performance of ATOMIC.},
  keywords={},
  doi={10.1109/HPCS.1992.759225},
  ISSN={},
  month={Feb},}
@INPROCEEDINGS{393314,
  author={Tai, S.-E. and Bhattacharya, D.},
  booktitle={Proceedings of 1993 IEEE International Conference on Computer Design ICCD'93}, 
  title={Pipelined fault simulation on parallel machines using the circuit flow graph}, 
  year={1993},
  volume={},
  number={},
  pages={564-567},
  abstract={A new technique to parallelize fault simulation for combinational digital circuits, suitable for message passing based parallel processors, is described. Speedup is achieved via combined use of data flow analysis and pipeline-like communication between processors. Unlike previous algorithms based on fault partitioning only, this approach uses both circuit and fault partitioning, and is both memory- and time-efficient with increasing number of processors.},
  keywords={},
  doi={10.1109/ICCD.1993.393314},
  ISSN={},
  month={Oct},}
@INPROCEEDINGS{394126,
  author={Wang, Y.-M.},
  booktitle={1993 IEEE International Symposium on Circuits and Systems}, 
  title={Reducing message logging overhead for log-based recovery}, 
  year={1993},
  volume={},
  number={},
  pages={1925-1928 vol.3},
  abstract={Checkpointing and rollback recovery is essential for long-running parallel applications. In the case of a transient fault or system crash, the affected application programs can recover from a consistent set of checkpoints saved earlier instead of restarting from the very beginning. For applications requiring transparent fault tolerance, log-based recovery can usually achieve a better recoverable state at the cost of message logging in addition to checkpointing. A simple scheme for reducing message logging overhead based on local dependency information is presented. Communication trace-driven simulation for several parallel applications is used to evaluate the benefits of the proposed scheme for real applications.},
  keywords={},
  doi={10.1109/ISCAS.1993.394126},
  ISSN={},
  month={May},}
@INPROCEEDINGS{395472,
  author={Medina, R.},
  booktitle={Proceedings of 1993 5th IEEE Symposium on Parallel and Distributed Processing}, 
  title={Incremental garbage collection for causal relationship computation in distributed systems}, 
  year={1993},
  volume={},
  number={},
  pages={650-655},
  abstract={Many distributed applications require the knowledge of the causality relation induced by the computation. Reconstructing this relation appears to be an interesting tool for such applications, but a vector of size S - where S is the number of processes - must be attached to each event to achieve this reconstruction. This induces a large overhead in secondary memory. After defining special events of the computation - some kind of checkpoints - we propose two algorithms that discard unnecessary data for the causal relationship reconstruction. The first algorithm acts on-the-fly while the second acts during reconstruction.},
  keywords={},
  doi={10.1109/SPDP.1993.395472},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{395528,
  author={Aiello, R. and Pagani, E. and Rossi, G.P.},
  booktitle={Proceedings of 1993 5th IEEE Symposium on Parallel and Distributed Processing}, 
  title={An efficient algorithm for group communication}, 
  year={1993},
  volume={},
  number={},
  pages={226-232},
  abstract={We present an algorithm for reliable group communication that guarantees atomicity and total ordering in message delivery. The algorithm has been designed to operate with general omission failures on top of any datagram subnetwork. It allows one to operate within large groups of processes without loss of efficiency and is suitable for an easy implementation. Processes decide in at most 2fk + 2 protocol rounds after sending O(fkn) messages, where fk is the amount of time required t detect f consecutive coordinator failures, and n is the group cardinality. This paper provides the correctness analysis of the algorithm and discusses the performance of our initial implementation.},
  keywords={},
  doi={10.1109/SPDP.1993.395528},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{395549,
  author={Duato, J.},
  booktitle={Proceedings of 1993 5th IEEE Symposium on Parallel and Distributed Processing}, 
  title={A new theory of deadlock-free adaptive multicast routing in wormhole networks}, 
  year={1993},
  volume={},
  number={},
  pages={64-71},
  abstract={A theory for the design of deadlock-free adaptive routing algorithms for wormhole networks has been proposed previously. This theory supplies the sufficient conditions for an adaptive routing algorithm to be deadlock-free, even when there are cyclic dependencies between channels. Also, two design methodologies have been proposed. Multicast communication refers to the delivery of the same message from one source node to an arbitrary number of destination nodes. Two multicast wormhole routing methods have been presented previously for multicomputers with 2D-mesh and hypercube topologies. This paper develops the theoretical background for the design of deadlock-free adaptive multicast routing algorithms for wormhole networks. Some basic definitions and two theorems are proposed, developing conditions to verify that an adaptive multicast routing algorithm is deadlock-free, even when there are cyclic dependencies between channels. As an example, the multicast routing algorithms presented previously are extended, so that they can take advantage of the alternative paths offered by the network.},
  keywords={},
  doi={10.1109/SPDP.1993.395549},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{393488,
  author={Hooman, J.},
  booktitle={1993 Proceedings Real-Time Systems Symposium}, 
  title={Specification and verification of a distributed real-time arbitration protocol}, 
  year={1993},
  volume={},
  number={},
  pages={284-293},
  abstract={To specify and verify distributed real-time systems, we use a formalism based on Hoare triples. The framework has been adapted to deal with safety as well as liveness properties, and a compositional proof method has been formulated. The formalism is applied to a distributed real-time arbitration protocol in which concurrent modules compete to get control over a common bus.},
  keywords={},
  doi={10.1109/REAL.1993.393488},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{393471,
  author={Wang, Y.-M. and Fuchs, W.K.},
  booktitle={Proceedings of 1993 IEEE 12th Symposium on Reliable Distributed Systems}, 
  title={Lazy checkpoint coordination for bounding rollback propagation}, 
  year={1993},
  volume={},
  number={},
  pages={78-85},
  abstract={The technique of lazy checkpoint coordination, which preserves process autonomy while employing communication-induced checkpoint coordination for bounding rollback propagation is proposed. The notion of laziness is introduced to control the coordination frequency and allow a flexible tradeoff between the cost of checkpoint coordination and the average rollback distance. Worst-case overhead analysis provides a means for estimating the extra checkpoint overhead. Communication trace-driven simulation for several parallel programs is used to evaluate the benefits of the proposed scheme.},
  keywords={},
  doi={10.1109/RELDIS.1993.393471},
  ISSN={},
  month={Oct},}

@INPROCEEDINGS{398779,
  author={Min, Y.-L. and Min, Y.},
  booktitle={Proceedings of 1993 IEEE 2nd Asian Test Symposium (ATS)}, 
  title={A distributed message routing algorithm for fault-tolerant hypercube systems}, 
  year={1993},
  volume={},
  number={},
  pages={55-58},
  abstract={A distributed message routing algorithm for faulty hypercube systems is described. To improve the efficiency, the algorithm adopts a heuristic backtracking strategy and each node provides an array to record its all neighbors faulty link information to avoid unnecessary searching for the known faulty links. Furthermore, the faulty link information is dynamically accumulated and the technique of heuristically searching for optimal link is used. The algorithm routes messages through the minimum feasible path between the sender and receiver if at least one such path exists, and takes the optimal path with higher probability when many faulty links exist in the faulty hypercube.},
  keywords={},
  doi={10.1109/ATS.1993.398779},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{465694,
  author={Wells, B.E. and Jackson, D.J. and Carroll, C.C.},
  booktitle={Proceedings of Southeastcon '93}, 
  title={A parallel task allocation methodology for non-buffered message-passing environments}, 
  year={1993},
  volume={},
  number={},
  pages={8 p.-},
  abstract={The performance of large-scale real-world applications may be enhanced by more efficient utilization of today's powerful parallel computing hardware. The authors describe a novel MIMD (multiple instruction, multiple data) static task allocation methodology created to achieve this goal for a wide range of real-time and deterministic systems. The method performs automatic assignment, mapping, and scheduling of the executable tasks to the available set of processors, assuming synchronous nonbuffered (lock-step) communication between the sending and receiving processors and an arbitrary static message-passing topology. The algorithm incorporates a set of list-based heuristics and graph-theoretical procedures designed to balance computational load with communication requirements. The effectiveness of the method has been verified by applying it to a large number of randomly generated task systems that span a wide range of inherent concurrency as well as to a task system of a real-world simulation of the Space Shuttle main rocket engine.},
  keywords={},
  doi={10.1109/SECON.1993.465694},
  ISSN={},
  month={April},}
@INPROCEEDINGS{465780,
  author={Shiva, S. and Virmani, R.},
  booktitle={Proceedings of Southeastcon '93}, 
  title={Implementation of reliable and efficient remote procedure calls}, 
  year={1993},
  volume={},
  number={},
  pages={5 p.-},
  abstract={A new mechanism for RPC (remote procedure calls) execution is introduced, and test results are provided. The key advantages of the new mechanism are: (1) it offers an RPC mechanism with increased fault tolerance; (2) the chances of occurrence of message orphans are greatly reduced; (3) the network communication with the servers and the execution of the procedures remotely in the server nodes go on approximately in parallel; (4) detection of communication errors is easy and feasible; and (5) the mechanism is transparent to the user.},
  keywords={},
  doi={10.1109/SECON.1993.465780},
  ISSN={},
  month={April},}
@INPROCEEDINGS{627319,
  author={Janssens, B. and Fuchs, W.K.},
  booktitle={FTCS-23 The Twenty-Third International Symposium on Fault-Tolerant Computing}, 
  title={Relaxing consistency in recoverable distributed shared memory}, 
  year={1993},
  volume={},
  number={},
  pages={155-163},
  abstract={Relaxed memory consistency models tolerate increased memory access latency in both hardware and software distributed shared memory systems. In recoverable systems, relaxing consistency has the added benefit of reducing the number of checkpoints needed to avoid rollback propagation. The authors introduce new checkpointing algorithms that take advantage of relaxed consistency to reduce the performance overhead of checkpointing. They also introduce a scheme based on lazy relaxed consistency that reduces both checkpointing overhead and the overhead of avoiding error propagation in systems with error latency. They use multiprocessor address traces to evaluate the relaxed consistency approach to checkpointing with distributed shared memory.},
  keywords={},
  doi={10.1109/FTCS.1993.627319},
  ISSN={0731-3071},
  month={June},}
@INPROCEEDINGS{344483,
  author={Samadzadeh, M. and Hsiao, T.-H.},
  booktitle={Proceedings of Phoenix Conference on Computers and Communications}, 
  title={An interactive parallel program slicer for the hypercube}, 
  year={1993},
  volume={},
  number={},
  pages={66-72},
  abstract={Program slicing is an approach used in the debugging process. The authors report on the development of an interactive parallel program slicer (PPS) for distributed-memory parallel programs on the iPSC/2 Hypercube System. PPS focuses on the csend and crecv commands of the iPSC/2 Hypercube System. An extended slicing criterion is developed for applying program slicing to distributed-memory parallel programs. The design approach of the static-slicing-based PPS is discussed. Some basic rules for applying PPS to iPSC/2 Hypercube System programs are introduced. An example is also presented.},
  keywords={},
  doi={10.1109/PCCC.1993.344483},
  ISSN={},
  month={March},}
@INPROCEEDINGS{627350,
  author={Buskens, R.W. and Bianchini, R.P.},
  booktitle={FTCS-23 The Twenty-Third International Symposium on Fault-Tolerant Computing}, 
  title={Distributed on-line diagnosis in the presence of arbitrary faults}, 
  year={1993},
  volume={},
  number={},
  pages={470-479},
  abstract={This paper introduces a new fault model for system-level diagnosis and a class of online distributed diagnosis algorithms that operate correctly in the presence of fault nodes that disseminate arbitrarily corrupted diagnostic information. The fault model addresses the practical issue of designing an internode test to cover diagnosis algorithm operation. Since an explicit test to detect arbitrary failures is not practical, evidence of a node's faulty behavior is provided by examining diagnositic messages exchanged by the node. In many practical systems, algorithm overhead using the new fault model is only twice that required for algorithms using the PMC fault model. The key results include a description of the new fault model, the specification of a class of online distributed diagnosis algorithms that use this fault model, and proofs of their correctness.},
  keywords={},
  doi={10.1109/FTCS.1993.627350},
  ISSN={0731-3071},
  month={June},}
@ARTICLE{250114,
  author={Duato, J.},
  journal={IEEE Transactions on Parallel and Distributed Systems}, 
  title={A new theory of deadlock-free adaptive routing in wormhole networks}, 
  year={1993},
  volume={4},
  number={12},
  pages={1320-1331},
  abstract={The theoretical background for the design of deadlock-free adaptive routing algorithms for wormhole networks is developed. The author proposes some basic definitions and two theorems. These create the conditions to verify that an adaptive algorithm is deadlock-free, even when there are cycles in the channel dependency graph. Two design methodologies are also proposed. The first supplies algorithms with a high degree of freedom, without increasing the number of physical channels. The second methodology is intended for the design of fault-tolerant algorithms. Some examples are given to show the application of the methodologies. Simulations show the performance improvement that can be achieved by designing the routing algorithms with the new theory.},
  keywords={},
  doi={10.1109/71.250114},
  ISSN={1558-2183},
  month={Dec},}
@ARTICLE{207232,
  author={Wilde, N. and Matthews, P. and Huitt, R.},
  journal={IEEE Software}, 
  title={Maintaining object-oriented software}, 
  year={1993},
  volume={10},
  number={1},
  pages={75-80},
  abstract={The maintenance requirements of object-oriented software, including the ability to make changes easily and an in-depth understanding of the software's structure and behavior, are discussed. The problems encountered by a maintainer trying to understand object-oriented software by reading and statically analyzing it are described. The problems caused by dynamic binding, polymorphism, and cooperating object classes in object-oriented software maintenance are reviewed.},
  keywords={},
  doi={10.1109/52.207232},
  ISSN={1937-4194},
  month={Jan},}
@ARTICLE{238037,
  author={Peterson, L. and Marrisson, S.},
  journal={IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems}, 
  title={The design and implementation of a concurrent circuit simulation program for multicomputers}, 
  year={1993},
  volume={12},
  number={7},
  pages={1004-1014},
  abstract={The development and implementation of a concurrent circuit simulation program, CONCISE, for MOS circuits, which is targeted for multicomputers (that is, message-passing, concurrent computers), is described. The objective is to design a program that uses hundreds of processing nodes efficiently. Implementation issues which are of importance for the performance on a concurrent computer are discussed. The waveform relaxation method with full-window techniques and Jacobi iterations is used because of its simple scheduler and limited demands on the message-passing network of the multicomputer. To speed up convergence, time windows are placed at transitions in the input waveforms, and dynamic window splitting at the nonconvergence time point is used. Results of experiments performed on a 192-node multicomputer showing that CONCISE can efficiently exploit hundreds of nodes are presented. For large and medium-size problems the speedup is almost two orders of magnitude. It is shown that CONCISE can efficiently handle very large problems with 12000 circuit nodes.},
  keywords={},
  doi={10.1109/43.238037},
  ISSN={1937-4151},
  month={July},}
@INPROCEEDINGS{696872,
  author={Wills, D.S. and Grossglauser, M.},
  booktitle={LEOS 1993 Summer Topical Meeting Digest on Optical Microwave Interactions/Visible Semiconductor Lasers/Impact of Fiber Nonlinearities on Lightwave Systems/Hybrid Optoelectronic Integration and Packagi}, 
  title={A Three-dimensional Optical Interconnection Network For Fine-grain Parallel Architectures}, 
  year={1993},
  volume={},
  number={},
  pages={H21-H22},
  abstract={Fine-grain, message-passing architectures offer high performance for high-throughput parallel applications such as image processing (e.g., filtering, edge detection, convolution), object recognition, and data compression. Reduced local memory requirements of these applications allow multiple high performance (50 MIPS/node) processing nodes to be integrated on a single chip. },
  keywords={},
  doi={10.1109/LEOSST.1993.696872},
  ISSN={},
  month={July},}
@INPROCEEDINGS{515658,
  author={Toomey, W.},
  booktitle={Proceedings of IEEE Singapore International Conference on Networks/International Conference on Information Engineering '93}, 
  title={TRUMP-a fast reliable transport protocol for distributed systems}, 
  year={1993},
  volume={2},
  number={},
  pages={601-605 vol.2},
  abstract={Traditional transport protocols such as TCP and TP4 were not designed to be used in distributed systems; they also fail to support the high speeds and low error rates of current high speed networks such as FDDI. Various protocols, such as VMTP, RRDP, NET-BLT and XTP have suggested ways of supporting distributed systems and/or high speed networks. However, none of them have fully supported both distributed systems and high-speed networks. This paper outlines the structure of TRUMP, a transport protocol that meets most of the requirements for high speed networks and distributed systems, except for multicast, which is still being designed.},
  keywords={},
  doi={10.1109/SICON.1993.515658},
  ISSN={},
  month={Sep.},}
@INPROCEEDINGS{344201,
  author={Beauquier, J. and Delaet, S.},
  booktitle={1993 4th Workshop on Future Trends of Distributed Computing Systems}, 
  title={Classes of self-stabilizing protocols}, 
  year={1993},
  volume={},
  number={},
  pages={361-365},
  abstract={Self-stabilization is an abstraction of fault tolerance for transient malfunctions. Intuitively, a self-stabilizing system is a system which can be started from any possible state. The authors here explore the possibility of transforming an arbitrary distributed protocol into a self-stabilizing one. It is proved that some conditions are sufficient for this transformation to be feasible. These conditions lead to a classification of distributed protocols according to the complexity for performing their transformation.},
  keywords={},
  doi={10.1109/FTDCS.1993.344201},
  ISSN={},
  month={Sep.},}
@INPROCEEDINGS{336371,
  author={Saiz, O.J. and Tyrrell, A.M.},
  booktitle={1993 Euromicro Workshop on Parallel and Distributed Processing}, 
  title={Analysis tool for parallel systems}, 
  year={1993},
  volume={},
  number={},
  pages={499-505},
  abstract={This paper describes a system for the creation of the traces of programs consisting of sets of parallel processes that communicate via message passing. The system uses a communicating sequential process (CSP) model to represent the program from which the traces are created. The system is based around the X-windows environment. The generated trace set is useful as a static testing tool for the detection of faults within a design, such as deadlocks or incorrect communication structures.},
  keywords={},
  doi={10.1109/EMPDP.1993.336371},
  ISSN={},
  month={Jan},}
@INPROCEEDINGS{289729,
  author={Carter, J.B. and Cox, A.L. and Dwarkadas, S. and Elnozahy, E.N. and Johnson, D.B. and Keleher, P. and Rodrigues, S. and Yu, W. and Zwaenepoel, W.},
  booktitle={Digest of Papers. Compcon Spring}, 
  title={Network multicomputing using recoverable distributed shared memory}, 
  year={1993},
  volume={},
  number={},
  pages={519-527},
  abstract={A network multicomputer is a multiprocessor in which the processors are connected by general-purpose networking technology, in contrast to current distributed memory multiprocessors where a dedicated special-purpose interconnect is used. The advent of high-speed general-purpose networks provides the impetus for a new look at the network multiprocessor model, by removing the bottleneck of current slow networks. However, major software issues remain unsolved. It is pointed out that a convenient machine abstraction must be developed that hides from the application programmer low-level details such as message passing or machine failures. Use is made of distributed shared memory as a programming abstraction, and rollback recovery through consistent checkpointing to provide fault tolerance. Measurements of the authors' implementations of distributed shared memory and consistent checkpointing show that these abstractions can be implemented efficiently.},
  keywords={},
  doi={10.1109/CMPCON.1993.289729},
  ISSN={},
  month={Feb},}
@INPROCEEDINGS{290909,
  author={Emmitt, J.},
  booktitle={Proceedings of the IEEE 1993 National Aerospace and Electronics Conference-NAECON 1993}, 
  title={32-bit PI-bus versus 32-bit Futurebus+ performance comparison}, 
  year={1993},
  volume={},
  number={},
  pages={157-164 vol.1},
  abstract={This paper presents a performance analysis of the JIAWG 32-bit Parallel Intermodule (PI) Bus versus a 32-bit Futurebus+ Standard backplane bus. Performance was measured in terms of bus throughput and latency, using a test scenario representative of a real-time, avionics application. The test scenario communications mix was constructed using Rate Monotonic Scheduling (RMS) theory. Behavioral VHDL models of both buses were used to execute the test scenario in a VHDL simulation environment. Simulation results were used to test whether critical deadlines were met for a given bus utilization (throughput) level. PI-Bus performance using the datagram, short-header, non-acknowledged format was compared to Futurebus+ performance using compelled mode, both with and without the message-passing protocol defined in IEEE Futurebus+ 896.1.},
  keywords={},
  doi={10.1109/NAECON.1993.290909},
  ISSN={},
  month={May},}
@INPROCEEDINGS{289653,
  author={Babb, R. and Choudhary, A. and Meadows, L. and Nakamoto, S. and Schuster, V.J.},
  booktitle={Digest of Papers. Compcon Spring}, 
  title={Retargetable high performance Fortran compiler challenges}, 
  year={1993},
  volume={},
  number={},
  pages={137-146},
  abstract={The authors establish the need for a retargetable high performance Fortran (HPF) compilation system, discuss the various parallel systems, describe some of the technical compiler requirements needed to create a retargetable HPF compiler, and touch upon some of the issues related to compiler development such as tools and debugging. It is noted that HPF brings with it the promise of the first widely accepted portable data-parallel programming model for application developers. However, HPF presents a number of challenges for software development tool suppliers desiring to build effective HPF compilers targeting a wide variety of high-performance computing multiple-instruction multiple-data (MIMD) systems. These targets may include the massively parallel processor MIMD sytems, high-end shared-memory systems, or even clusters of workstations cooperating over a network.},
  keywords={},
  doi={10.1109/CMPCON.1993.289653},
  ISSN={},
  month={Feb},}
@INPROCEEDINGS{287711,
  author={Rothermel, K.},
  booktitle={[1993] Proceedings. The 13th International Conference on Distributed Computing Systems}, 
  title={An open commit protocol preserving consistency in the presence of commission failures}, 
  year={1993},
  volume={},
  number={},
  pages={168-177},
  abstract={Most of the proposed commit protocols assume that all participants of a transaction are sane, i.e., they only fail with omission failures and eventually recover. Unfortunately, this assumption is not realistic for open distributed systems (ODSs), which can be divided into a trusted and a nontrusted domain. While nodes in the trusted domain are assumed to be sane, nontrusted nodes may fail permanently and with commission failures. The open commit protocols presented are based on a model for consistency checking. The protocol also tolerates any number of commission failures in the nontrusted domain of an ODS. It guarantees that the trusted participants of a transaction terminate in a way that preserves consistency in the trusted domain, which generally does not mean that all trusted participants have to terminate consistently. The protocol groups those trusted participants that have to terminate consistently to maintain data consistency, and ensures that in each group the participants terminate in the same way. The advantages of the protocol are a simplified commit processing and a reduced message complexity. The message complexity of this protocol exceeds that of traditional two-phase commit protocols by no more than two messages for most practical cases.},
  keywords={},
  doi={10.1109/ICDCS.1993.287711},
  ISSN={},
  month={May},}
@INPROCEEDINGS{284045,
  author={Beguelin, A.L.},
  booktitle={[1993] Proceedings of the Twenty-sixth Hawaii International Conference on System Sciences}, 
  title={Xab: a tool for monitoring PVM programs}, 
  year={1993},
  volume={ii},
  number={},
  pages={102-103 vol.2},
  abstract={Xab is a run time monitoring tool for parallel virtual machine (PVM) programs. Xab gives the user direct feedback as to what PVM functions his or her program is performing. In its most simple form, this feedback is displayed in a window. The approach of real time monitoring is particularly apropos in a heterogeneous multiprogramming environment. Differences in computation and communication speeds here are due both to heterogeneity and external CPU and network loads. Monitoring can help give the user insight into how a program is behaving in such an environment. Xab is a continuing research project. The author discusses several related research projects, the current version of Xab, and the future development of the Xab tool.},
  keywords={},
  doi={10.1109/HICSS.1993.284045},
  ISSN={},
  month={Jan},}
@INPROCEEDINGS{284110,
  author={Chiola, G. and Ferscha, A.},
  booktitle={[1993] Proceedings of the Twenty-sixth Hawaii International Conference on System Sciences}, 
  title={Exploiting timed Petri net properties for distributed simulation partitioning}, 
  year={1993},
  volume={ii},
  number={},
  pages={194-203 vol.2},
  abstract={The authors develop a distributed simulation mechanism based on the optimistic strategy (Time Warp) to study timed transition Petri net (TTPN) models. The approach addresses the problem of partitioning the simulation model into logical processes to be run concurrently on individual processing nodes in a distributed memory multiprocessor system. They propose a partitioning such that several transitions together with all their input places are simulated by a single logical process, to avoid the substantial overhead induced by a distributed conflict resolution protocol in a message passing environment. Subnets are constructed from the topological description of the TTPN so that conflict resolution always occurs internally to a logical process, thus involving no communication overhead. Additional aggregation of conflict sets into larger logical simulation processes may increase the balancing of the distributed simulation without decreasing its inherent parallelism if some conditions are verified on the TTPN model structure.},
  keywords={},
  doi={10.1109/HICSS.1993.284110},
  ISSN={},
  month={Jan},}
@INPROCEEDINGS{284121,
  author={Young, Y.-H. and Sikorski, K.},
  booktitle={[1993] Proceedings of the Twenty-sixth Hawaii International Conference on System Sciences}, 
  title={Performance evaluation of network programming environments}, 
  year={1993},
  volume={ii},
  number={},
  pages={106-107 vol.2},
  abstract={Benchmark tests of distributed/parallel software systems such as EXPRESS, ISIS, LINDA, PVM, and TCGMSG programming environments on a system of IBM/RS6000 520 workstations connected via a 16-Mb token ring network are presented. The authors compare message passing times as a function of the size of a message, and execution times of two applications. The applications, the Monte Carlo simulation and Jacobi iterative algorithms, were selected from TCGMSG as test cases to compare the scalability and the overhead of each package in terms of the performance. The results indicate that packages using the TCP/IP network protocol enjoy better performance than those using the UDP/IP network protocol, although UDP/IP is faster than TCP/IP in terms of transfer rates. Also, those packages using indirect communication have more overhead than those using direct communication. The porting experiences strongly indicate that library support for global operations is very useful in a distributed/parallel environment.},
  keywords={},
  doi={10.1109/HICSS.1993.284121},
  ISSN={},
  month={Jan},}
@INPROCEEDINGS{284087,
  author={Knopp, J.},
  booktitle={[1993] Proceedings of the Twenty-sixth Hawaii International Conference on System Sciences}, 
  title={Touching analysis: avoiding runtime checking in future-based parallel languages}, 
  year={1993},
  volume={ii},
  number={},
  pages={407-416 vol.2},
  abstract={In languages with futures there is no static distinction between data computed locally and data calculated by other processes. Hence, before values are really used an automatic accessibility check must be done. If the data are not yet computed the execution is suspended. Such checks must be done even when all data objects are presented. It is shown how to infer at compile time the locations where these checks can be suppressed. The method works by abstract interpretation. The algorithm applies for both functional and nonfunctional Lisp. It has been implemented in Common Lisp and covers the analysis of most Lisp constructs. The benchmarks are promising. The semantics of implicit waiting in future-based languages are presented. The relationship to strictness analysis and type inference is stressed.},
  keywords={},
  doi={10.1109/HICSS.1993.284087},
  ISSN={},
  month={Jan},}
@INPROCEEDINGS{263119,
  author={Appel, B. and Kantz, H. and Koza, C.},
  booktitle={[1993] Proceedings of the IEEE Workshop on Real-Time Applications}, 
  title={Implications of fault management and replica determinism on the real-time execution scheme of VOTRICS}, 
  year={1993},
  volume={},
  number={},
  pages={39-43},
  abstract={The fault tolerant architecture VOTRICS focuses on the use of n-modular active replication of hardware. Hardware and link failures are detected by voting mechanisms realized in software. The use of active replication and the mechanisms for activities such as fault management, recovery, or keeping correct replicas synchronized (even in the presence of faults) have influences on the chosen system model and the timing behaviour of the system. The authors address these points and their implications on the underlying real-time execution scheme of VOTRICS. VOTRICS is a highly flexible message passing architecture for hardware fault tolerance. It covers different degrees of redundancy for improving the reliability, safety and availability of various applications. Typical applications are railway signalling systems or telecommunication systems.},
  keywords={},
  doi={10.1109/RTA.1993.263119},
  ISSN={},
  month={May},}
@INPROCEEDINGS{588726,
  author={Lewis, M.J. and Cline, R.E.},
  booktitle={Proceedings 1993 IEEE Workshop on Advances in Parallel and Distributed Systems}, 
  title={PVM communication performance in a switched FDDI heterogeneous distributed computing environment}, 
  year={1993},
  volume={},
  number={},
  pages={13-19},
  abstract={The Parallel Virtual Machine (PVM) message passing system developed at Oak Ridge National Laboratories has gained widespread acceptance and usage in the parallel programming community. The authors describe the results of performance tests of PVM in a switched FDDI heterogeneous distributed computing environment. They aim to provide insight into how parallel programs, particularly those employing PVM for intertask communication, will perform in distributed systems of the future.},
  keywords={},
  doi={10.1109/APADS.1993.588726},
  ISSN={},
  month={Oct},}
@INPROCEEDINGS{315540,
  author={Getov, V.S. and Hockney, R.W. and Hey, A.J.G.},
  booktitle={Proceedings of Workshop on Programming Models for Massively Parallel Computers}, 
  title={Performance analysis of distributed applications by suitability functions}, 
  year={1993},
  volume={},
  number={},
  pages={191-197},
  abstract={A simple programming model of distributed-memory message-passing computer systems is first applied to describe the couple architecture/application by two sets of parameters. The node timing formula is then derived on the basis of scalar, vector and communication components. A set of suitability functions, extracted from the performance formulae, are defined. These functions are applied as an example to the performance analysis of the 1-dimensional FFT benchmark from the GENESIS benchmark suite. The suitability functions could also be useful for comparative performance analysis of both existing distributed-memory systems and new architectures under development.},
  keywords={},
  doi={10.1109/PMMP.1993.315540},
  ISSN={},
  month={Sep.},}
@INPROCEEDINGS{319941,
  author={Saha, D. and Dutta, S.K.},
  booktitle={Proceedings of TENCON '93. IEEE Region 10 International Conference on Computers, Communications and Automation}, 
  title={Specification of deterministic execution timing schema for parallel programs on a multiprocessor}, 
  year={1993},
  volume={1},
  number={},
  pages={114-116 vol.1},
  abstract={To guarantee the correctness of hard real-time software systems, it is necessary to have a priori knowledge of the deterministic execution times of the system components. Timing schema are formulae based on source program elements to calculate the execution time of programs. Deterministic timing schema or formulae are proposed in this paper for predicting the best and worst case execution times of parallel and distributed programs. The total execution time is computed from the schema provided for a variety of parallel program constructs for shared variable interactions through critical sections and, general semaphores for distributed message passing and remote procedure calls. As an initial attempt to validate the proposition, we have conducted a series of experiments on a shared memory multiprocessor (tightly coupled) system. In one of such experiments involving simplest process structures, where no process interactions occur except to synchronize the initiation and termination of processes, the timing schema based approach has been shown to exhibit safe and reasonably tight predictions. The representative implementations that obey the schema and the methods of incorporating some of the underlying hardware contentions and indeterminacies have also been studied. Predictable timing behaviour in concurrent systems is indeed a possibility using the schema approach.},
  keywords={},
  doi={10.1109/TENCON.1993.319941},
  ISSN={},
  month={Oct},}
@INPROCEEDINGS{336416,
  author={De Bosschere, K.O.M. and Van Campenhout, J.M.},
  booktitle={1993 Euromicro Workshop on Parallel and Distributed Processing}, 
  title={Some low-level issues in the implementation of a shared blackboard}, 
  year={1993},
  volume={},
  number={},
  pages={88-95},
  abstract={Recently, several Linda-like parallel extensions of programming languages have been developed. A Linda-based extension consists roughly of a number of sequential agents (processes) communicating with each other by means of a shared associative tuple space or blackboard. The Linda communication paradigm is deemed useful and powerful. The main difficulty in implementing this type of communication is the design of an efficient architecture for the shared blackboard. The challenge is to design a blackboard that can be accessed simultaneously by as many agents as possible, thereby preserving its integrity and correct behavior. This paper describes the architecture of a scalable and efficient implementation of a blackboard for Multi-Prolog, a blackboard-based parallel Prolog.},
  keywords={},
  doi={10.1109/EMPDP.1993.336416},
  ISSN={},
  month={Jan},}
@INPROCEEDINGS{315519,
  author={Fuyau Lin},
  booktitle={Proceedings of 1993 IEEE 7th International Workshop on Software Specification and Design}, 
  title={Design and validation of a message-passing system}, 
  year={1993},
  volume={},
  number={},
  pages={10-19},
  abstract={The paper describes a case study for designing and validating the core of a message-passing communication system. The approach is based on the use of the Petri Net Workbench, the protocol validation language, PROMELA, and its simulator/validator, SPIN. By using these tools, a protocol and underlying hardware for communicating between two heterogeneous computer systems is designed and validated. A reachability analysis is performed which includes a check for live- and dead-lock system states.},
  keywords={},
  doi={10.1109/IWSSD.1993.315519},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{1263541,
  author={Netzer, R.H.B. and Xu, J.},
  booktitle={Supercomputing '93:Proceedings of the 1993 ACM/IEEE Conference on Supercomputing}, 
  title={Adaptive message logging for incremental replay of message-passing programs}, 
  year={1993},
  volume={},
  number={},
  pages={840-849},
  abstract={This paper presents an adaptive message logging algorithm that keeps time and space costs low by logging only a fraction of the messages. The algorithm dynamically tracks dependences among messages to determine which cause domino effects and must be traced. The domino effect can force a replay to start arbitrarily far back in the execution, and domino-free replay allows any part of the execution to be quickly reexecuted. Experiments on an iPSC/860 hypercube indicate that our algorithm logs only 1-10% of the messages, a one to two order of magnitude reduction over past schemes which log every message. The experiments also show that the resulting logs provide a small bound on the amount of reexecution needed to satisfy any replay request. The new logging algorithm thus reduces the overhead of message logging while bounding the response time to replay requests.},
  keywords={},
  doi={10.1145/169627.169850},
  ISSN={1063-9535},
  month={Nov},}
@INPROCEEDINGS{4134111,
  author={Cohen, Danny and Finn, Gregory},
  booktitle={1993 International Conference on Parallel Processing - ICPP'93}, 
  title={ATOMIC: A Low-Cost, Very-High-Speed, Local Communication Architecture}, 
  year={1993},
  volume={1},
  number={},
  pages={39-46},
  abstract={ATOMIC1 is an inexpensive O(gigabit) speed LAN built by USC/ISI. It is based upon Mosaic technol ogy developed for fine-grain, message-passing, massively parallel computation. Each Mosaic processor is capable of routing variable length packets, while providing added value through simultaneous computing and buffering. ATOMIC adds a general routing capability to the native Mosaic wormhole routing through store-and-forward. ATOMIC scales linearly, with a small interface cost. Each ATOMIC channel has a data carrying capacity of 500Mbls. A prototype ATOMIC LAN has been con structed along with host interfaces and software that pro vides full TCP/IP compatibility. Using ATOMIC, 1J00 byte packets have been exchanged between hosts at an aggregate transfer rate of more than lGbls. Other tests have demonstrated throughput of 5.25 million packets per second over a single Mosaic channel. This paper describes the architecture and performance of ATOMIC.},
  keywords={},
  doi={10.1109/ICPP.1993.43},
  ISSN={0190-3918},
  month={Aug},}
@INPROCEEDINGS{4134254,
  author={Copty, Nawal and Ranka, Sanjay and Fox, Geoffrey and Shankar, Ravi},
  booktitle={1993 International Conference on Parallel Processing - ICPP'93}, 
  title={Solving the Region Growing Problem on the Connection Machine}, 
  year={1993},
  volume={3},
  number={},
  pages={102-105},
  abstract={This paper presents a parallel algorithm for solving the region growing problem based on the split and merge approach. The algorithm was implemented on the CM-2 and the CM-5 in the data parallel and message passing models. The performance of these implementations is examined and compared.},
  keywords={},
  doi={10.1109/ICPP.1993.166},
  ISSN={0190-3918},
  month={Aug},}
@INPROCEEDINGS{390479,
  author={Evans, E.},
  booktitle={Fifth Annual Conference on AI, and Planning in High Autonomy Systems}, 
  title={FSATS: an object-based approach to distributed interactive simulation for C3I test and training}, 
  year={1994},
  volume={},
  number={},
  pages={281-286},
  abstract={FSATS is a tool designed to support both testing and training for C3I systems. It provides the capabilities for collecting C3I tactical message traffic, reducing it for later evaluation, and interactively simulating C3I units. FSATS hardware consists of a variable number of LAN-based processors, and its software may be distributed among these processors in a range of possible configurations. The software is developed using an object-oriented model, where application-level functions are implemented as distinct object classes. FSATS interactively simulates C3I units by modelling each type as a set of logic tables and state data. Each such model is implemented by an object class. Object interaction is mapped onto a FSATS-provided message-delivery service. Objects invoke operations on each other by sending request messages, and the results may be returned in response messages, FSATS's object interaction model will probably migrate in the future toward compliance with industry standards, in order to take advantage of third-party software.},
  keywords={},
  doi={10.1109/AIHAS.1994.390479},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{411541,
  author={Gannon, J.A. and Williams, K.J. and Andersland, M.S. and Casavant, T.L.},
  booktitle={Proceedings of 1994 33rd IEEE Conference on Decision and Control}, 
  title={Trace recovery: a distributed computing application for perturbation tracking}, 
  year={1994},
  volume={3},
  number={},
  pages={2621-2626 vol.3},
  abstract={Execution monitoring plays a central role in most software development tools for parallel and distributed computer systems. However, such monitoring may induce delays that corrupt event timing. In this paper we introduce a perturbation analyses-like algorithm that, given a safe timed Petri net model of the monitored software, can recover the uncorrupted event timings, i.e., those that would have been observed had the delays not been present. Monitoring conditions sufficient to ensure correct operation of the algorithm, and examples illustrating the algorithm's applicability to message-passing systems are also presented. This is part of a larger effort aimed at identifying cost-effective software alternatives to hardware monitoring.},
  keywords={},
  doi={10.1109/CDC.1994.411541},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{465257,
  author={Leung, K.R.P.H. and Yim, C.F.S.},
  booktitle={Proceedings of 1st Asia-Pacific Software Engineering Conference}, 
  title={Reversing concurrent systems into formal specifications}, 
  year={1994},
  volume={},
  number={},
  pages={229-234},
  abstract={Many distributed systems are developed in traditional artistic manner. They neither have formal specifications nor the implementation are able to be reasoned or formally verified. As the number and importance of distributed systems are growing rapidly, we expect that there will be a demand of reversing these distributed systems back to formal descriptions in order to verify its correctness or to do maintenance. We discuss our experience in reversing process migration systems implemented in parallel C into CSP specifications. We reverse the program by mapping the corresponding semantic units from parallel C to CSP in step-wise reversion manner. We also discuss the problems we encountered.},
  keywords={},
  doi={10.1109/APSEC.1994.465257},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{592537,
  author={Dierstein, A. and Hayer, R. and Rauber, T.},
  booktitle={Proceedings. Second Euromicro Workshop on Parallel and Distributed Processing}, 
  title={A Branch-and-bound Algorithm For Array Distributions}, 
  year={1994},
  volume={},
  number={},
  pages={528-535},
  abstract={},
  keywords={},
  doi={10.1109/EMPDP.1994.592537},
  ISSN={},
  month={Jan},}
@INPROCEEDINGS{494488,
  author={Bauch, N. and Maehle, E.},
  booktitle={Proceedings of IEEE Workshop on Fault-Tolerant Parallel and Distributed Systems}, 
  title={Reconfiguration in octagonal mesh-based multicomputer systems with distributed checkpointing}, 
  year={1994},
  volume={},
  number={},
  pages={169-180},
  abstract={In the field of large multicomputer systems fault tolerance is no longer negligible. For the implementation of fault tolerance in mesh-based systems dynamic redundancy is a suitable approach. One major problem is the reconfiguration of the interconnection network after a fault. This paper presents two reconfiguration schemes for octagonal mesh-based multicomputer systems that are closely related to the distributed checkpointing approach. One scheme is able to reconfigure a 2D-mesh as an application graph in an octagonal 2D-mesh as a machine graph after a single fault, provided the checkpoints are organized as a meander. This reconfiguration can be done with a dilation of 2 and a congestion of 2. The other algorithm reconfigures any application graph in an octagonal mesh as machine graph that was originally embedded with the congestion of 1 under the assumption that the checkpoints are organized as a spiral and only single faults occur. In this case the dilation is increased by a factor of 2 for a square mesh and by a factor of 4 for a rectangular one, while the congestion is 3 in both cases. Also, some practical experiences with a sample implementation of the first reconfiguration scheme and a scheme for more general application graphs on the DAMP multicomputer system are reported.},
  keywords={},
  doi={10.1109/FTPDS.1994.494488},
  ISSN={},
  month={June},}
@INPROCEEDINGS{367044,
  author={Nardelli, E. and D'Amico, C. and Santacroce, M.},
  booktitle={Proceedings of the First International Conference on Massively Parallel Computing Systems (MPCS) The Challenges of General-Purpose and Special-Purpose Computing}, 
  title={A model for performance evaluation of message passing architectures in spatial data processing}, 
  year={1994},
  volume={},
  number={},
  pages={460-470},
  abstract={We give a first formulation of a model for evaluating performances of a message passing architecture parallel machine in the context of spatial data processing. We consider 2-dimensional data of the type 'region' and analyze operations of union and intersection between them. On the basis of the characteristics of manipulation algorithms and of the architecture we individuate as the best way of implementing them, we propose and validate through experiments a model able to estimate time required to execute union or intersection operations between two regions of arbitrary shape as a function of a small number of parameters describing input data. Though derived on a specific machine, the model obtained is of general validity, since only the values of numerical constants are dependant by the machine used. Such a model is the first necessary step in tackling the issue of query optimization for spatial data in a parallel environment. The work is a part of a more general research programme aiming at studying the best approach to take advantage from parallel architectures for spatial data processing.},
  keywords={},
  doi={10.1109/MPCS.1994.367044},
  ISSN={},
  month={May},}
@INPROCEEDINGS{367183,
  author={Aktouf, C. and Benkahla, O. and Robach, C.},
  booktitle={Proceedings of the International Symposium on Parallel Architectures, Algorithms and Networks (ISPAN)}, 
  title={Distributed validation of massively parallel machines}, 
  year={1994},
  volume={},
  number={},
  pages={326-333},
  abstract={In this paper, a distributed algorithm for validating message passing-machines is presented and evaluated. Our approach is based on adaptive distributed diagnosis of multiprocessor systems in a user environment where a full self-diagnosis is not needed. We analyze the algorithm performance using a model based on an open queueing network.},
  keywords={},
  doi={10.1109/ISPAN.1994.367183},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{367089,
  author={Elleuch, A. and Muntean, T.},
  booktitle={Proceedings of the First International Conference on Massively Parallel Computing Systems (MPCS) The Challenges of General-Purpose and Special-Purpose Computing}, 
  title={Process migration protocols for massively parallel systems}, 
  year={1994},
  volume={},
  number={},
  pages={84-95},
  abstract={Process migration is known as the run time relocation of a process within a network of processors. This capability is mainly used for efficient management of resources in a distributed system. This paper deals with the construction of process migration mechanisms for Massively Parallel Systems (MPS). In particular, we are interested in the correction of communications in presence of migration. Many distributed systems have proposed mechanisms for process migration where different approaches are used to ensure transparency and correctness of the delivery of messages. In MPS, more than achieving correctness and transparency, the emphasis is put also on supporting scalability of the machine architecture, and on efficiency by minimising the overhead introduced by the use of the migration mechanisms at run-time. According to these criteria we propose three migration protocols for correct message passing mechanisms.},
  keywords={},
  doi={10.1109/MPCS.1994.367089},
  ISSN={},
  month={May},}
@INPROCEEDINGS{367167,
  author={Dang Van Hung},
  booktitle={Proceedings of the International Symposium on Parallel Architectures, Algorithms and Networks (ISPAN)}, 
  title={An algorithm for maintaining consistent view of processes in distributed systems}, 
  year={1994},
  volume={},
  number={},
  pages={33-40},
  abstract={In the paper, the problem of determining the global properties of distributed systems is addressed. At each moment during the execution of a system, every process has its knowledge about the system. By message passing the processes can exchange their knowledge. We present a general algorithm for a process to synthesize the knowledge that it obtains, and to maintain its consistent view about the system. Depending on different interpretations the algorithm can be used for distributed snapshots, for verification and design of stabilizing protocols, etc.},
  keywords={},
  doi={10.1109/ISPAN.1994.367167},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{369206,
  author={Yang, Y.},
  booktitle={Proceedings of TENCON'94 - 1994 IEEE Region 10's 9th Annual International Conference on: 'Frontiers of Computer Technology'}, 
  title={Tool interfaces for software development: models, experiments and evaluation}, 
  year={1994},
  volume={},
  number={},
  pages={776-780 vol.2},
  abstract={For the last decade, research into integrated software development environments has been one of the focuses in the software engineering community. The key objective of this paper is to classify the existing tool interfacing/integration models for software development. They are termed the uncoupled, tightly-coupled, and loosely-coupled paradigms. Our experiments with these paradigms are also briefly described so as to evaluate the advantages and disadvantages of each paradigm. Based on this paper a clear view of tool interfaces for software development is presented.},
  keywords={},
  doi={10.1109/TENCON.1994.369206},
  ISSN={},
  month={Aug},}
@INPROCEEDINGS{374132,
  author={Xiao Liu and Wilcox, G.L.},
  booktitle={Proceedings of 1994 IEEE International Conference on Neural Networks (ICNN'94)}, 
  title={Benchmarking of the CM-5 and the Cray machines with a very large backpropagation neural network}, 
  year={1994},
  volume={1},
  number={},
  pages={22-27 vol.1},
  abstract={In this paper, we present a new, efficient implementation of the backpropagation algorithm (BP) on the CM-5 by fully taking advantage of its Control Network to avoid explicit message-passing. The nodes in the input and output layers are evenly distributed to all processors: all nodes in the hidden layer(s) are replicated in each processor, and all weights are distributed to all processors corresponding to the nodes. We have implemented this algorithm on the CM-5 in the MIMD mode using the C programming language. For a case study of protein tertiary structure prediction, we obtained performance of 76 million weight updates per second (WUPS) with the machine partitioned for 512 processors without vector units. Experiments using different sized partitions indicated an almost linear relationship between the computation time and the number of processors, indicating good parallelization. We have also implemented the backpropagation algorithm on the Cray machines using the C programming language. The Cray-2 implementation yields performance of 10 million WUPS; the Cray X-MP EA implementation yields 18 million WUPS; and the Cray Y-MP M92 implementation yields 40 million WUPS.},
  keywords={},
  doi={10.1109/ICNN.1994.374132},
  ISSN={},
  month={June},}
@INPROCEEDINGS{376991,
  author={Medeiros, P.D. and Cunha, J.C.},
  booktitle={Proceedings Scalable Parallel Libraries Conference}, 
  title={Is enhancing the functionality of process grouping abstractions in parallel programming libraries desirable and feasible?}, 
  year={1994},
  volume={},
  number={},
  pages={185-190},
  abstract={Recent research has shown an increasing interest in accommodating within a single environment two forms of exploitation of parallelism. This includes parallelism within a single homogeneous machine and parallelism across a network of possibly heterogeneous machines. From our point of view, current programming systems for this kind of environment lack structuring abstractions for cooperative computing. In fact, although support for process grouping is provided, it does not address issues of distinct event orderings such, as uniform message delivery and causality (in the "happens before" sense of Lamport, 1978), which are fundamental for the preservation of consistent views among the involved cooperating processes. We argue that support for causality and consistency in the process views of parallel computations, as related to process grouping abstractions, are fundamental devices for understanding and building concurrent systems with asynchronous components with distributed memory (and local states). A better user understanding of parallel computations concerning their correctness, dynamic behavior, and performance, needs specific support from the system regarding such aspects. The above ideas are being integrated in a virtual machine environment called DVM-that we are designing and implementing.},
  keywords={},
  doi={10.1109/SPLC.1994.376991},
  ISSN={},
  month={Oct},}
@INPROCEEDINGS{376999,
  author={Nupairoj, N. and Ni, L.M.},
  booktitle={Proceedings Scalable Parallel Libraries Conference}, 
  title={Performance evaluation of some MPI implementations on workstation clusters}, 
  year={1994},
  volume={},
  number={},
  pages={98-105},
  abstract={Message Passing Interface (MPI) is an attempt to standardize the communication library for distributed-memory computing systems. Since the release of the recent MPI specification, several MPI implementations have been made publicly available. Different implementations employ different approaches, and thus, the performance of each implementation may vary. Since the performance of communication is extremely crucial to message-passing based applications, selecting an appropriate MPI implementation becomes critical. Our study is intended to provide a guideline on how to perform such a task on workstation clusters which are known to be an economical and effective platform in high performance computing. We investigate several MPI aspects including its functionalities and performance. Our results also point out the strength and weakness of each implementation on our experimental system.},
  keywords={},
  doi={10.1109/SPLC.1994.376999},
  ISSN={},
  month={Oct},}
@INPROCEEDINGS{376995,
  author={West, J.E. and Stephens, M.M. and Turcotte, L.H.},
  booktitle={Proceedings Scalable Parallel Libraries Conference}, 
  title={Adaptation of volume visualization techniques to MIMD architectures using MPI}, 
  year={1994},
  volume={},
  number={},
  pages={147-156},
  abstract={This paper presents a divide-and-conquer approach to developing visualization software for scientific analysis of high resolution, volume datasets on, distributed memory parallel computers. A direct volume rendering method is discussed and the design of the parallel implementation of the original sequential algorithm is highlighted. For this algorithm, the data, once distributed, remains in place regardless of the viewer's location, and no interprocessor communication is required during scene generation. The software was developed using an early version of the Message Passing Interface (MPI), and the MPI features used in this application are discussed. Finally, test results indicating the performance of our parallel implementation on an nCUBE 2 are presented and analyzed.},
  keywords={},
  doi={10.1109/SPLC.1994.376995},
  ISSN={},
  month={Oct},}
@INPROCEEDINGS{344370,
  author={Lin, F.J.},
  booktitle={Proceedings of ICNP - 1994 International Conference on Network Protocols}, 
  title={Specification and validation of communications in client/server models}, 
  year={1994},
  volume={},
  number={},
  pages={108-116},
  abstract={Errors such as deadlock and race conditions are very common yet extremely difficult to debug in the communications design of client/server models based on remote procedure calls and multi-threading. This paper presents an effective approach to detecting these errors. It shows how to apply the specification and validation techniques used in protocol engineering to discover those errors in the early stages of a client/server software development. The work is based on the protocol specification and validation tool PROMELA/SPIN. PROMELA is extended to a new language called PROMELA-C/S for additional expressive power of specifying client/server communications. A PROMELA-C/S translator is built to convert PROMELA-C/S to PROMELA for validation using SPIN. The paper also reports the results of some specification and validation trials using PROMELA-C/S, its translator, and SPIN.},
  keywords={},
  doi={10.1109/ICNP.1994.344370},
  ISSN={},
  month={Oct},}
@INPROCEEDINGS{344304,
  author={Castagnera, K. and Cheng, D. and Fatoohi, R. and Hook, E. and Kramer, B. and Manning, C. and Musch, J. and Niggley, C. and Saphir, W. and Sheppard, D. and Smith, M. and Stockdale, I. and Welch, S. and Williams, R. and Yip, D.},
  booktitle={Supercomputing '94:Proceedings of the 1994 ACM/IEEE Conference on Supercomputing}, 
  title={NAS experiences with a prototype cluster of workstations}, 
  year={1994},
  volume={},
  number={},
  pages={410-419},
  abstract={This paper discusses the year-long activity at NAS to implement a large, loose cluster of workstations from the existing Silicon Graphics, Inc. (SGI) pool of systems. Issues related to establishing a loosely coupled cluster of workstations are presented. Included are steps needed to resolve system management issues intended to provided reasonable cycle recovery from these systems without disrupting the primary system users. Performance evaluation tests were run based on the NAS Parallel Benchmarks (NPB) and other codes, including OVERFLOW-PVM, a full-fledged computational fluid dynamics (CFD) application. This paper summarizes the activities related to the prototype cluster and identifies areas that need improvement, development, and research in order to make workstation clusters a viable computing environment for solving aeroscience problems.},
  keywords={},
  doi={10.1109/SUPERC.1994.344304},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{336910,
  author={Janakiraman, G. and Tamir, Y.},
  booktitle={Proceedings of IEEE 13th Symposium on Reliable Distributed Systems}, 
  title={Coordinated checkpointing-rollback error recovery for distributed shared memory multicomputers}, 
  year={1994},
  volume={},
  number={},
  pages={42-51},
  abstract={Most recovery schemes that have been proposed for Distributed Shared Memory (DSM) systems require unnecessarily high checkpointing frequency and checkpoint traffic, which are sensitive to the frequency of interprocess communication in the applications. For message-passing systems, low overhead error recovery based on coordinated checkpointing allows the frequency of checkpointing to be determined only by the reliability requirements of the application. Efficient adaptation of this approach to DSM multicomputers is complicated by the absence of explicit messages in DSM systems, the presence of a shared and partially replicated address space, and the presence of a distributed coherency directory. We present solutions to these issues, and propose an error recovery scheme based on coordinated checkpointing and rollback for DSM multicomputers. Our performance evaluation based on trace-driven simulations indicates that this scheme incurs less checkpoint traffic than recovery schemes previously proposed for DSM systems.},
  keywords={},
  doi={10.1109/RELDIS.1994.336910},
  ISSN={},
  month={Oct},}
@INPROCEEDINGS{336911,
  author={Janssens, B. and Fuchs, W.K.},
  booktitle={Proceedings of IEEE 13th Symposium on Reliable Distributed Systems}, 
  title={Reducing interprocessor dependence in recoverable distributed shared memory}, 
  year={1994},
  volume={},
  number={},
  pages={34-41},
  abstract={Checkpointing techniques in parallel systems use dependency tracking and/or message logging to ensure that a system rolls back to a consistent state. Traditional dependency tracking in distributed shared memory (DSM) systems is expensive because of high communication frequency. In this paper we show that, if designed correctly, a DSM system only needs to consider dependencies due to the transfer of blocks of data, resulting in reduced dependency tracking overhead and reduced potential for rollback propagation. We develop an ownership timestamp scheme to tolerate the loss of block state information and develop a passive server model of execution where interactions between processors are considered atomic. With our scheme, dependencies are significantly reduced compared to the traditional message-passing model.},
  keywords={},
  doi={10.1109/RELDIS.1994.336911},
  ISSN={},
  month={Oct},}
@INPROCEEDINGS{336913,
  author={Line, J.C. and Ghosh, S.},
  booktitle={Proceedings of IEEE 13th Symposium on Reliable Distributed Systems}, 
  title={A methodology for constructing a stabilizing crash-tolerant application}, 
  year={1994},
  volume={},
  number={},
  pages={12-21},
  abstract={This paper is an exercise to construct a stabilizing mutual-exclusion protocol that withstands a single crash-failure. We begin with a collection of distributed processes arranged in a ring. The resulting protocol is stabilized by construction. Stabilizing protocols converge to a correct behavior regardless of their initial state. A faulty process is automatically removed from the system and, after repair, automatically integrated into the system. Our technique can be generalized to different systems by substituting appropriate protocols for various components.},
  keywords={},
  doi={10.1109/RELDIS.1994.336913},
  ISSN={},
  month={Oct},}
@INPROCEEDINGS{296662,
  author={Heath, M.T. and Raghaven, P.},
  booktitle={Proceedings of IEEE Scalable High Performance Computing Conference}, 
  title={Performance of a fully parallel sparse solver}, 
  year={1994},
  volume={},
  number={},
  pages={334-341},
  abstract={The performance of a fully parallel direct solver for large sparse symmetric positive definite systems of linear equations is demonstrated. The solver is designed for distributed-memory message-passing parallel computer systems, particularly massively parallel machines. All phases of the computation, including symbolic processing as well as numeric factorization and triangular solution, are performed in parallel. A parallel Cartesian nested dissection algorithm is used to compute a fill-reducing ordering for the matrix and an appropriate partitioning of the problem across the processors. The separator tree resulting from nested dissection is used to identify and exploit large-grain parallelism in the remaining steps of the computation. The parallel performance of the solver is reported for a series of test problems on the Thinking Machines CM-5. The parallel efficiency and scalability of the solver, as well as the relative importance of the various phases of the computation, are investigated empirically.},
  keywords={},
  doi={10.1109/SHPCC.1994.296662},
  ISSN={},
  month={May},}
@INPROCEEDINGS{296680,
  author={Cote, J. and Thomas, S.J.},
  booktitle={Proceedings of IEEE Scalable High Performance Computing Conference}, 
  title={Parallel semi-Lagrangian advection on the sphere using PVM}, 
  year={1994},
  volume={},
  number={},
  pages={470-477},
  abstract={Numerical methods for solving the advection problem in spherical geometry are examined in conjunction with techniques for solving the shallow-water equations on the sphere. Eulerian methods are restricted by the Courant-Friedrichs-Lewy (CFL) condition and the semi-Lagrangian method is an alternative approach for taking longer time steps. Recent progress in the development of distributed MIMD parallel algorithms for semi-Lagrangian advection is discussed. A parallel message-passing implementation of advection on the sphere based on PVM is described. Parallel performance results on an Intel iPSC/860 are presented and it is established that the code is scalable for reasonable sub-grid dimensions on each processor.},
  keywords={},
  doi={10.1109/SHPCC.1994.296680},
  ISSN={},
  month={May},}
@INPROCEEDINGS{296710,
  author={Damodaran-Kamal, S.K. and Francioni, J.M.},
  booktitle={Proceedings of IEEE Scalable High Performance Computing Conference}, 
  title={mdb: a semantic race detection tool for PVM}, 
  year={1994},
  volume={},
  number={},
  pages={702-709},
  abstract={Nondeterminism, intended or otherwise, makes debugging message passing parallel programs a difficult task. In this paper, we present an on-the-fly debugging tool, mdb (Message-passing DeBugger), for debugging programs written for the PVM (Parallel Virtual Machine), that is effective in detecting the presence of races. mdb uses a new class of expressions, called semantic expressions, to specify races. These expressions capture the program semantics related to a receive operation and are used to detect unwanted races at run-time. mdb also has the ability to invoke sequential debuggers, making it useful in detecting errors unrelated to races as well. Replay debugging support by mdb provides for deterministic replay of erroneous executions. The current implementation of mdb works for C as well as for Fortran programs.},
  keywords={},
  doi={10.1109/SHPCC.1994.296710},
  ISSN={},
  month={May},}
@ARTICLE{295890,
  author={Akella, V. and Gopalakrishnan, G.},
  journal={IEEE Transactions on Software Engineering}, 
  title={Specification and validation of control-intensive IC's in hopCP}, 
  year={1994},
  volume={20},
  number={6},
  pages={405-423},
  abstract={Control-intensive IC's pose a significant challenge to the users of formal methods in designing hardware. These IC's have to support a wide variety of requirements including synchronous and asynchronous operations, polling and interrupt driven modes of operation, multiple concurrent threads of execution, nontrivial computational requirements, and programmability. We illustrate the use of formal methods in the design of a control-intensive IC called the "Intel 8251" Universal Synchronous/Asynchronous Receiver/Transmitter (USART), using our hardware description language "hopCP". A feature of hopCP is that it supports communication via asynchronous ports in addition to synchronous message passing. Asynchronous ports are distributed shared variables writable by exactly one process. We show the usefulness of this combination of communication constructs. We outline algorithms to determine safe usages of asynchronous ports, and also to discover other static properties of the specification. We discuss a compiled-code concurrent functional simulator called CFSIM, as well as the use of concurrent testers for driving CFSIM. The use of a semantically well-specified and simple language, and the associated analysis/simulation tools helps conquer the complexity of specifying and validating control-intensive IC's.},
  keywords={},
  doi={10.1109/32.295890},
  ISSN={1939-3520},
  month={June},}
@INPROCEEDINGS{292564,
  author={Ye Huang and Hughes, M.},
  booktitle={Proceedings of 11th IEEE Workshop on Real-Time Operating Systems and Software}, 
  title={Using SDL in embedded systems design: a tool for generating real-time OS pSOS based embedded systems applications software}, 
  year={1994},
  volume={},
  number={},
  pages={39-43},
  abstract={We present an efficient method using the Specification and Description Language (SDL) for designing and implementing real-lime embedded systems. We also discuss the implementation of a companion kernel for an SDL based Design Tool (SDT) CASE tool environment to generate real-time OS based pSOS multitasking application software by applying defined mapping translation rules. Since SDL is a formal specification and description language, with the CASE environment SDT support, the major part of a system can be analyzed, simulated, verified, and validated at early stages during system development. The concurrency due to the multiple concurrent state machines in a system is preserved in target run-time environment. Because the SDL described system uses message-passing, a distributed version can be relatively easy to derive from. To emphasize the proposed method using SDL without dramatically compromising the memory and response time (speed), we show the results obtained from pSOS implementation of an AccessControl system. We also outline some areas that we are continuing to work on.},
  keywords={},
  doi={10.1109/RTOSS.1994.292564},
  ISSN={},
  month={May},}
@INPROCEEDINGS{289921,
  author={Atkinson, R.M. and Hawkins, P.G. and Hills, P.R. and Woollons, D.J. and Clearwaters, W.A.},
  booktitle={Proceedings of 2nd International Workshop on Configurable Distributed Systems}, 
  title={Application management in a distributed, object-oriented condition monitoring and maintenance planning system}, 
  year={1994},
  volume={},
  number={},
  pages={207-},
  abstract={Summary form only given. The authors address the problem of the management of distributed condition monitoring applications. The MARIA research project has developed a toolkit for the design, debugging, implementation and reconfiguration of an application, together with run-time support for inter-object message passing. In a MARIA application all system components from data acquisition, through diagnostic KBS to maintenance scheduling are treated as objects, their internal structure being hidden behind a standardised, message-based interface. This allows a separation between the structure of the monitoring system and the implementation of its component objects, thus promoting the re-use of standard components and the facility for replacing any object with an updated version with an identical interface. The toolkit consists of the Workbench, the Instancer and the run-time system written using Objective-C, X-Windows and remote procedure calls. The Workbench provides graphical facilities for the development and validation of an application specification. Application management facilities are provided by the Instancer, also a graphical tool, which takes an application specification from the Workbench and uses it to create, reconfigure or shut down an instance of that application on the chosen hardware.},
  keywords={},
  doi={10.1109/IWCDS.1994.289921},
  ISSN={},
  month={March},}
@INPROCEEDINGS{284424,
  author={Mehra, P. and Gower, M. and Bass, M.A.},
  booktitle={Proceedings of International Workshop on Modeling, Analysis and Simulation of Computer and Telecommunication Systems}, 
  title={Automated modeling of message-passing programs}, 
  year={1994},
  volume={},
  number={},
  pages={187-192},
  abstract={We present a system for automated modeling of message-passing programs. Its models preserve the parallel program's structure, especially the syntactic boundaries surrounding communication calls. Our grammar-driven approach uses the program's parse trees to derive a regular expression that describes all possible execution traces at the chosen level of modeling; that expression is used for automatic extraction of timing information from traces of scaled-down runs. We consider "intelligent regression" techniques for discovering the numerical attributes of our models: run times of sequential blocks; lengths and destinations of messages; and loop bounds. Regression produces formulae expressing these attributes in terms of problem and system sizes. The model is then used for predicting the performance of large-scale runs. We illustrate our approach with a program that simultaneously solves multiple tridiagonal linear systems an the iPSC/860.},
  keywords={},
  doi={10.1109/MASCOT.1994.284424},
  ISSN={},
  month={Jan},}
@INPROCEEDINGS{284425,
  author={Sarukkai, S.R.},
  booktitle={Proceedings of International Workshop on Modeling, Analysis and Simulation of Computer and Telecommunication Systems}, 
  title={Scalability analysis tools for SPMD message-passing parallel programs}, 
  year={1994},
  volume={},
  number={},
  pages={180-186},
  abstract={Tools to study the scalability of parallel programs, as number of processors (p) executing the program and problem size (n) being solved are increased, are a critical component of performance debugging environments for parallel programs. Simulations and scalability metrics have been used to address this issue. Simulation can accurately predict the execution time of a program for a specific (n,p) pair. However, it suffers from the drawback that one needs to simulate the program for each (n,p) pair of interest. On the other hand, while scalability metrics express the program performance as functions of n and p, they have been targeted to specific applications and there are no tools to automatically obtain simple first order scalability trends for generic parallel programs. We address the issue of automatically obtaining scalability trends for a class of data-independent message passing SPMD parallel programs. We validate our approach by considering example parallel programs executed on the Intel iPSC/860 hypercube. We show that insight into the scalability of the program can be obtained, using this approach.},
  keywords={},
  doi={10.1109/MASCOT.1994.284425},
  ISSN={},
  month={Jan},}
@ARTICLE{282609,
  author={Tel, G. and Korach, E. and Zaks, S.},
  journal={IEEE/ACM Transactions on Networking}, 
  title={Synchronizing ABD networks}, 
  year={1994},
  volume={2},
  number={1},
  pages={66-69},
  abstract={Chou et al. (1990) presented two synchronizer algorithms for ABD networks. One of their synchronizers has a round time of three, and the other has a round time of only two but requires an additional bit in every message of the simulated algorithm. The authors show that ABD synchronization can be improved by using information that can be obtained, without exchanging more messages, during the initialization of the synchronizers. The authors first contribution is a synchronizer with a round time of two that does not require an additional bit in basic messages. The second result refutes the common belief that a round time of two is the best achievable for this type of synchronizer. They show that in some network topologies a smaller round time is achievable by making the local time of simulation of the pulses dependent on the arrival time of messages received during initialization. The correctness of the synchronizers is shown by modeling this class of synchronizers as functions, and using these functions lower bounds on the round time can also be easily obtained. The authors show that their synchronizers are optimal, i.e., further reduction of the round time by the same means is not possible.},
  keywords={},
  doi={10.1109/90.282609},
  ISSN={1558-2566},
  month={Feb},}
@INPROCEEDINGS{340261,
  author={Chenghang Huang and McKinley, P.K.},
  booktitle={Proceedings of 3rd IEEE International Symposium on High Performance Distributed Computing}, 
  title={Design and implementation of global reduction operations across ATM networks}, 
  year={1994},
  volume={},
  number={},
  pages={43-50},
  abstract={The paper presents the results of an investigation into the efficient implementation of reduction operations for cluster-based parallel computing across asynchronous transfer mode (ATM) local area networks. The study combines graph theoretical analysis with experimentation on an ATM network. Different reduction algorithms are analyzed in terms of the amount of message traffic produced and the number of message-passing steps required. This analysis, which indicates how to take advantage of switch-based interconnects and hardware multicast communication, is applied to the development of both N/1 and N/K reduction protocols. Performance measurements from implementations on a three-switch ATM testbed are presented to support the analytical results.},
  keywords={},
  doi={10.1109/HPDC.1994.340261},
  ISSN={},
  month={Aug},}
@ARTICLE{262587,
  author={Linder, D.H. and Harden, J.C.},
  journal={IEEE Transactions on Parallel and Distributed Systems}, 
  title={Access graphs: a model for investigating memory consistency}, 
  year={1994},
  volume={5},
  number={1},
  pages={39-52},
  abstract={Computer architectures supporting shared memory continue to increase in complexity as designers seek to improve memory performance. This is especially true of proposals for massively parallel systems with distributed, yet shared, memory. The need to maintain a reasonably simple memory model for programmers, in spite of enhancements like caches and access pipelining, is responsible for many of the complications. We develop a novel graph model, access graphs, for visualizing processor/memory interaction. Access graphs symbolically represent the causal relationships between load, store, and synchronization events. The focus is on two classes of access graphs: pseudo and real. A pseudo access graph describes an execution in terms of abstract events familiar to the programmer. If the pseudo access graph is acyclic, then memory consistency is preserved during the execution. A real access graph describes an execution in terms of physical events known to the hardware designer. A real access graph must be acyclic since hardware cannot violate causality. Memory consistency can be verified for a given computer system by proving that for any acyclic real access graph describing a program's execution on that computer, an acyclic pseudo access graph can be derived describing the same execution.},
  keywords={},
  doi={10.1109/71.262587},
  ISSN={1558-2183},
  month={Jan},}
@INPROCEEDINGS{302417,
  author={Cheng-Ru Young and Ge-Ming Chiu},
  booktitle={14th International Conference on Distributed Computing Systems}, 
  title={A crash recovery technique in distributed computing systems}, 
  year={1994},
  volume={},
  number={},
  pages={235-242},
  abstract={In this paper we propose a new mechanism for implementing checkpoint/rollback-recovery in a distributed computing system. A logical-ring structure is introduced for the maintenance of recovery-related information. Message processing order of a process is maintained by all other processes on its associated ring. It requires no time-consuming operations of writing order information into stable storage. As a result, fail-free overhead is small. When failures occur, only failed processes have to roll back to their latest checkpoints. Surviving processes continue execution without being blocked. Output commit is fast as it needs no synchronization before a message is sent to the outside world.},
  keywords={},
  doi={10.1109/ICDCS.1994.302417},
  ISSN={},
  month={June},}
@INPROCEEDINGS{302416,
  author={Hong Va Leong and Agrawal, D.},
  booktitle={14th International Conference on Distributed Computing Systems}, 
  title={Using message semantics to reduce rollback in optimistic message logging recovery schemes}, 
  year={1994},
  volume={},
  number={},
  pages={227-234},
  abstract={Recovery from failures can be achieved through asynchronous checkpointing and optimistic message logging. These schemes have low overheads during failure-free operations. Central to these protocols is the determination of a maximal consistent global state, which is recoverable. Message semantics is not exploited in most existing recovery protocols to determine the recoverable state. We propose to identify messages that are not influential in a computation through message semantics. These messages can be logically removed from the computation without changing its meaning or result. We show that considering these messages in the recoverable state computation gives rise to recoverable states that dominate the recoverable state defined under conventional model. We then develop an algorithm for identifying these messages. This technique can also be applied to ensure a more timely commitment for output in a distributed computation.},
  keywords={},
  doi={10.1109/ICDCS.1994.302416},
  ISSN={},
  month={June},}
@INPROCEEDINGS{302445,
  author={Gannon, J.A. and Williams, K.J. and Andersland, M.S. and Lummp, J.E. and Gasavant, T.L.},
  booktitle={14th International Conference on Distributed Computing Systems}, 
  title={Using perturbation tracking to compensate for intrusion in message-passing systems}, 
  year={1994},
  volume={},
  number={},
  pages={414-421},
  abstract={Execution monitoring plays a central role in most software development tools for parallel and distributed computer systems. However, such monitoring may induce delays that corrupt event timing. If this corruption can be quantified, it may be possible to determine the intrusion-free behavior. In this paper, we describe an algorithm that, given a safe timed Petri net model of the monitored software, can determine the uncorrupted timestamp values, i.e. those that would have been observed had the delays not been present. Monitoring conditions sufficient to ensure correct operation of the algorithm, and examples illustrating the algorithm's applicability to message-passing systems are also presented. This work is part of a larger effort aimed at identifying cost-effective software alternatives to custom hardware monitoring.},
  keywords={},
  doi={10.1109/ICDCS.1994.302445},
  ISSN={},
  month={June},}
@INPROCEEDINGS{302444,
  author={Netzer, R.H.B. and Subramanian, S. and Jian Xu},
  booktitle={14th International Conference on Distributed Computing Systems}, 
  title={Critical-path-based message logging for incremental replay of message-passing programs}, 
  year={1994},
  volume={},
  number={},
  pages={404-413},
  abstract={Debugging long-running, nondeterministic message-passing parallel programs requires incremental replay, the ability to exactly replay selected parts of an execution. To support incremental replay, we must log enough messages and checkpoint processes often enough to allow any requested replay to complete quickly. We present an adaptive tracing strategy to keep the message-logging overhead down. We let the user specify a bound on the maximum time any replay request is allowed to take. Our algorithm tracks what each process's critical path will be during a replay and logs enough messages to ensure the critical path will never exceed the bound. Overhead is kept low by not logging messages that can be recomputed during a replay. Experiments indicate that we log about 0.1-5% of the messages while still providing a reasonable bound on any replay.},
  keywords={},
  doi={10.1109/ICDCS.1994.302444},
  ISSN={},
  month={June},}
@INPROCEEDINGS{576451,
  author={Sarkar, S. and Boyer, K.L.},
  booktitle={Proceedings of 12th International Conference on Pattern Recognition}, 
  title={Using perceptual inference networks to manage vision processes}, 
  year={1994},
  volume={1},
  number={},
  pages={808-810 vol.1},
  abstract={The aim is to generate a hierarchical description of the scene using preattentive and attentive modules. The preattentive module provides evidence in terms of primitive organizations like parallelism, continuity, closure, and strands. The attentive organization integrates this preattentive evidence to hypothesize more complex organizations such as parallelograms, circles, ellipses, and ribbons. This attentive part is realized by the perceptual inference network (PIN) which is a form of Bayesian network. The output set of hypotheses of the PIN is large and redundant. A set of lines is described as a parallelogram and/or ellipse and/or circle. There is considerable ambiguity in such a description. The strategy is to use special-purpose modules to resolve the ambiguous hypotheses and to generate a comprehensive scene description. These special purpose modules tend to be computationally expensive and have limited applicability. Therefore, we want to apply them only when and where we expect the greatest amount of information gain per unit computational resource.},
  keywords={},
  doi={10.1109/ICPR.1994.576451},
  ISSN={},
  month={Oct},}
@ARTICLE{310675,
  author={Stoller, S.},
  journal={IEEE Transactions on Software Engineering}, 
  title={Addendum to "Proof rules for flush channels"}, 
  year={1994},
  volume={20},
  number={8},
  pages={664-},
  abstract={The logic presented in a previous paper, see ibid., vol. 19, no.4, p.366-78 (1993) for processes that communicate using flush channels is inadequate for reasoning about processes that send multiple identical messages along a channel. A modification to the logic and proof system that remedies this deficiency is described herein.},
  keywords={},
  doi={10.1109/32.310675},
  ISSN={1939-3520},
  month={Aug},}
@ARTICLE{311574,
  author={Plank, J.S. and Kai Li},
  journal={IEEE Parallel & Distributed Technology: Systems & Applications}, 
  title={ickp: a consistent checkpointer for multicomputers}, 
  year={1994},
  volume={2},
  number={2},
  pages={62-67},
  abstract={There has been much research on checkpointing algorithms for parallel and distributed systems; but surprisingly few implementations for uniprocessors, multiprocessors, and distributed systems, and none at all for multicomputers. We discuss ickp, our consistent checkpointer for the Intel iPSC/860, which is the first general-purpose checkpointer for a multicomputer. It is a checkpointing library that may be invoked asynchronously from the host processor, at a periodic interval, or by a library call. It implements three consistent checkpointing algorithms, two optimizations to reduce checkpoint time and overhead, and recovery.},
  keywords={},
  doi={10.1109/88.311574},
  ISSN={1558-1861},
  month={Summer},}
@INPROCEEDINGS{494470,
  author={Yi-Min Wang and Fuchs, W.K.},
  booktitle={Proceedings of IEEE Workshop on Fault-Tolerant Parallel and Distributed Systems}, 
  title={Optimal message log reclamation for uncoordinated checkpointing}, 
  year={1994},
  volume={},
  number={},
  pages={24-29},
  abstract={An algorithm is presented for identifying all garbage message logs in systems requiring message logging to record in-transit messages. The approach is based on a previously derived method for identifying garbage checkpoints by means of recovery line transformation and decomposition.},
  keywords={},
  doi={10.1109/FTPDS.1994.494470},
  ISSN={},
  month={June},}
@INPROCEEDINGS{315630,
  author={Elnozahy, E.N. and Zwaenepoel, W.},
  booktitle={Proceedings of IEEE 24th International Symposium on Fault- Tolerant Computing}, 
  title={On the use and implementation of message logging}, 
  year={1994},
  volume={},
  number={},
  pages={298-307},
  abstract={We present a number of experiments showing that for compute-intensive applications executing in parallel on clusters of workstations, message logging has higher failure-free overhead than coordinated checkpointing. Message logging protocols, however, result in much shorter output latency than coordinated checkpointing. Therefore, message logging should be used for applications involving substantial interactions with the outside world, while coordinated checkpointing should be used otherwise. We also present an unorthodox message logging design that uses coordinated checkpointing with message logging, departing from the conventional approaches that use independent checkpointing. This combination of message logging and coordinated checkpointing offers several advantages, including improved failure-free performance, bounded recovery time, simplified garbage collection, and reduced complexity. Meanwhile, the new protocols retain the advantages of the conventional message logging protocols with respect to output commit. Finally, we discuss three "lessons learned" from an implementation of various message logging protocols.},
  keywords={},
  doi={10.1109/FTCS.1994.315630},
  ISSN={},
  month={June},}
@INPROCEEDINGS{344326,
  author={Mraz, R.},
  booktitle={Supercomputing '94:Proceedings of the 1994 ACM/IEEE Conference on Supercomputing}, 
  title={Reducing the variance of point to point transfers in the IBM 9076 parallel computer}, 
  year={1994},
  volume={},
  number={},
  pages={620-629},
  abstract={Commodity workstations have adapted to standard UNIX like environments to allow scientists to efficiently develop and port applications across systems. UNIX based environments, such as IBM's AIX, furnishes such an operating environment while providing efficient uni-processor utilization for user code execution. When these machines are interconnected with a low latency (user space) communication mechanism, large variances in point to point communication times for identical parallel programs are typically found. It is our contention that a large part of this variance is introduced by operating system support functionality that can delay point to point user space communications. We are able to experimentally measure this effect by monitoring the change in time of circulating a token through parallel processors connected in a virtual ring configuration. This paper proposed some solutions and then experimentally validates their ability to reduce point to point message passing variance for the IBM 9076 (SP1) machines.},
  keywords={},
  doi={10.1109/SUPERC.1994.344326},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{323189,
  author={Parasuram, Y. and Stabler, E. and Shiu-Kai Chin},
  booktitle={1994 Proceedings of the Twenty-Seventh Hawaii International Conference on System Sciences}, 
  title={Parallel implementation of BDD algorithms using a distributed shared memory}, 
  year={1994},
  volume={1},
  number={},
  pages={16-25},
  abstract={Binary Decision Diagrams (BDDs) are used extensively in VLSI CAD for verification, synthesis, logic minimization and testing. Parallel algorithms for Boolean Function Manipulation using BDDs have been proposed and implemented on a Connection Machine (CM-5). Abstractions have been developed to support the design of these algorithms using the message passing model of parallel programming. A Distributed Shared Memory (DSM) has been built for sharing date. Fine grained load balancing is achieved using a Distributed Stack. Experimental results are shown for the DSM and the BDD algorithms. These results demonstrate the feasibility of using parallel computing for irregular and memory intensive CAD applications such as the BDD algorithms. Improvements to the current implementation are identified for future work.},
  keywords={},
  doi={10.1109/HICSS.1994.323189},
  ISSN={},
  month={Jan},}
@INPROCEEDINGS{323224,
  author={Mattson},
  booktitle={1994 Proceedings of the Twenty-Seventh Hawaii International Conference on System Sciences}, 
  title={Programming environments for parallel computing: a comparison of CPS, Linda, P4, PVM, POSYBL, and TCGMSG}, 
  year={1994},
  volume={2},
  number={},
  pages={586-594},
  abstract={Six portable parallel programming environments are compared. Results for two-node communication benchmarks are reported for each environment. Results for the more complicated four-node communications tests are reported for all of the environments except CPS. In every case, the benchmarks were run on an isolated Ethernet network of identical SPARCstation 1 workstations to assure reproducibility. Earlier reports based on this work omitted any opinions about the utility of these environments; in essence, the communication times were left to speak for themselves. In this paper, these opinions are included; they are useful to consider since they are based on a unique experience/spl minus/the experience of running two programs written with six different programming environments.},
  keywords={},
  doi={10.1109/HICSS.1994.323224},
  ISSN={},
  month={Jan},}
@INPROCEEDINGS{5727760,
  author={Ahmad, I. and Yu-Kwong Kwok, Yu-Kwong Kwok},
  booktitle={1994 Internatonal Conference on Parallel Processing Vol. 2}, 
  title={A New Approach to Scheduling Parallel Programs Using Task Duplication}, 
  year={1994},
  volume={2},
  number={},
  pages={47-51},
  abstract={In this paper, we explore the problem of scheduling parallel programs using task duplication for message-passing multicomputers. Task duplication means scheduling a parallel program by redundantly executing some of the tasks on which other tasks of the program critically depend. This can reduce the start times of tasks waiting for messages from tasks residing in other processors. There have been a few scheduling algorithms using task duplication. We discuss two such previously reported algorithms and describe their differences, limitations and suitability for different environments. A new algorithm is proposed which outperforms both of these algorithms, and is more efficient for low as well as high values of communication-to-computation ratios. The algorithm takes into account arbitrary computation and communication costs. All three algorithms are tested by scheduling some of the commonly encountered graph structures.},
  keywords={},
  doi={10.1109/ICPP.1994.37},
  ISSN={},
  month={Aug},}
@INPROCEEDINGS{5727844,
  author={Salim Hariri, Salim Hariri and Rajesh Yadav, Rajesh Yadav and Balaji Thiagarajan, Balaji Thiagarajan and Sung-Yong Park, Sung-Yong Park and Mahesh Subramanyan, Mahesh Subramanyan and Rajashekar Reddy, Rajashekar Reddy and Fox, G.C.},
  booktitle={1994 International Conference on Parallel Processing Vol. 3}, 
  title={A Concurrent Multi Target Tracker: Benchmarking and Portability}, 
  year={1994},
  volume={3},
  number={},
  pages={123-126},
  abstract={With the current advances in computing and network technology and software, the gap between parallel and distributed computing environment is gradually becoming narrower. Consequently, parallel programs run on parallel as well as distributed systems. However, programming and porting complex applications to such environment is challenging task and not well understood. In this paper, we use a concurrent multi target tracker as a running example to analyze and evaluate performance of two different parallel implementations on parallel and distributed systems. We have benchmarked both these implementations on different architectures that vary from a network of worksta-tions(SUN, IBM RS6000) to parallel computers (CM5, iPSC 860) using different parallel/distributed message passing tools(PVM, p4, EXPRESS).},
  keywords={},
  doi={10.1109/ICPP.1994.20},
  ISSN={0190-3918},
  month={Aug},}
@INPROCEEDINGS{386544,
  author={Sterling, T.L. and Savarese, D.F. and Merkey, P.R. and Gardner, J.P.},
  booktitle={Proceedings of 1995 1st IEEE Symposium on High Performance Computer Architecture}, 
  title={An initial evaluation of the Convex SPP-1000 for earth and space science applications}, 
  year={1995},
  volume={},
  number={},
  pages={176-185},
  abstract={The Convex SPP-1000, the most recent SPC, is distinguished by a true global shared memory capability based on the first commercial version of directory based cache coherence mechanisms and SCI protocol. The system was evaluated at NASA/GSFC in the Beta-test environment using three classes of operational experiments targeting earth and space science applications. A multiple program workload tested job-stream level parallelism. Synthetic programs measured overhead costs of barrier, fork-join, and message passing synchronization primitives. An efficient tree-code version of an N-body simulation revealed scaling properties and measured the overall efficiency. This paper presents the results of this study and provides the earliest published evaluation of this new scalable architecture.},
  keywords={},
  doi={10.1109/HPCA.1995.386544},
  ISSN={},
  month={Jan},}
@INPROCEEDINGS{386534,
  author={Kontothanassis, L.I. and Scott, M.L.},
  booktitle={Proceedings of 1995 1st IEEE Symposium on High Performance Computer Architecture}, 
  title={Software cache coherence for large scale multiprocessors}, 
  year={1995},
  volume={},
  number={},
  pages={286-295},
  abstract={Shared memory is an appealing abstraction for parallel programming. It must be implemented with caches in order to perform well, however and caches require a coherence mechanism to ensure that processors reference current data. Hardware coherence mechanisms for large-scale machines are complex and costly, but existing software mechanisms for message-passing machines have not provided a performance-competitive solution. We claim that an intermediate hardware option-memory-mapped network interfaces that support a global physical address space-can provide most of the performance benefits of hardware cache coherence. We present a software coherence protocol that runs on this class of machines and greatly narrows the performance gap between hardware and software coherence. We compare the performance of the protocol to that of existing software and hardware alternatives and evaluate the tradeoffs among various cache-write policies. We also observe that simple program changes can greatly improve performance. For the programs in our test suite and with the changes in place, software coherence is often faster and never more than 55% slower than hardware coherence.},
  keywords={},
  doi={10.1109/HPCA.1995.386534},
  ISSN={},
  month={Jan},}
@INPROCEEDINGS{389166,
  author={Gianuzzi, V. and Merani, F.},
  booktitle={Proceedings Euromicro Workshop on Parallel and Distributed Processing}, 
  title={Using PVM to implement a distributed dependable simulation system}, 
  year={1995},
  volume={},
  number={},
  pages={529-535},
  abstract={In the past decade, the use of distributed algorithms to model simulations is considerably increased, in order to gain speedup over traditional sequential simulations. Also, there has been much interest in using inexpensive, powerful workstation nets, with high speed interconnection, instead of expensive parallel computers. In this paper, we briefly present the kernel of a distributed system (PV/sup 2/M) implemented on top of PVM routines, where synchronization is based on the concept of Virtual Time. Special emphasis is given to the fault tolerant mechanisms provided in it. PV/sup 2/M implements a checkpoint-restart mechanism, with respect to processes located on non master hosts, in such a way as to be 1-resilient with respect to failures occurring to these hosts.},
  keywords={},
  doi={10.1109/EMPDP.1995.389166},
  ISSN={},
  month={Jan},}
@INPROCEEDINGS{389179,
  author={Guarracino, M.R. and Perla, F.},
  booktitle={Proceedings Euromicro Workshop on Parallel and Distributed Processing}, 
  title={A parallel modified block Lanczos' algorithm for distributed memory architectures}, 
  year={1995},
  volume={},
  number={},
  pages={424-431},
  abstract={In this paper we propose a parallel block Lanczos algorithm suitable for MIMD distributed memory message passing architectures. We first consider a direct parallelization of the classic block Lanczos algorithm and we evaluate its performance. Then, after a discussion of these results, we reorganize the block algorithm obtaining a modified version that has a better behaviour with respect to the performance in the considered computing environment. We assume a unidirectional ring as connection topology and a block column wrap-around matrices distribution. We have chosen this approach to improve load-balancing, to eliminate the intersection of messages and to decrease communication. The two parallel block Lanczos algorithms have been tested on a Convex Meta Series, a cluster of HP Series 9000 workstations, running the PVM communication system.},
  keywords={},
  doi={10.1109/EMPDP.1995.389179},
  ISSN={},
  month={Jan},}
@INPROCEEDINGS{389178,
  author={Dapuzzo, M. and Lapegna, M.},
  booktitle={Proceedings Euromicro Workshop on Parallel and Distributed Processing}, 
  title={A parallel row projection solver for large sparse linear systems}, 
  year={1995},
  volume={},
  number={},
  pages={432-441},
  abstract={In this paper we present a parallel iterative solver for large and sparse nonsymmetric linear systems. The solver is based on a row-projection algorithm, derived from the symmetrized block version of the Kaczmarz method with Conjugate Gradient acceleration. A comparison with some Krylov subspace methods shows the remarkable robustness of this algorithm when applied to systems with eigenvalues arbitrarily distributed in the complex plane. The parallel version of the algorithm was developed for MIMD distributed memory machines and it is based on a row partitioning approach which allows to compute each iteration as a simultaneous set of independent least squares problems. Moreover, we propose a data distribution strategy leading to a scalable communication scheme. The algorithm has been tested both on a system Intel iPSC/860 and on the Intel Touchstone DELTA System, running the Intel NX message passing environment.},
  keywords={},
  doi={10.1109/EMPDP.1995.389178},
  ISSN={},
  month={Jan},}
@INPROCEEDINGS{389130,
  author={Miguel, J. and Arruabarrena, A. and Izu, C. and Beivide, R.},
  booktitle={Proceedings Euromicro Workshop on Parallel and Distributed Processing}, 
  title={Parallel simulation of message routing networks}, 
  year={1995},
  volume={},
  number={},
  pages={138-145},
  abstract={An implementation of a conservative parallel simulator with deadlock avoidance is presented. Its performance when working with a realistic model of a message routing network is evaluated and contrasted against a sequential simulator. Different factors that improve the performance of the parallel simulation are discussed, focusing in the model under study and the available computer: a network of transputers. These factors are the load of the model being simulated, the grain size of the simulator and the simulator ability to exploit the lookahead property of the model.},
  keywords={},
  doi={10.1109/EMPDP.1995.389130},
  ISSN={},
  month={Jan},}
@INPROCEEDINGS{393582,
  author={Butler, J.M.},
  booktitle={Proceedings of Simulation Symposium}, 
  title={Quantum modeling of distributed object computing}, 
  year={1995},
  volume={},
  number={},
  pages={175-184},
  abstract={Distributed object computing is gaining rapid notice in the computer engineering community. However, few tools exist for the design and modeling of distributed object systems. Clearly, large scale and mission critical systems are most affected by this deficiency. To attain a level of tractability in large scale design and verification, dynamic models are essential. The paper introduces two modeling components. The LCN model supports the definition of real-world network topologies and multicomputer systems. The DCO model provides a system-independent method of representing complex, object oriented computing structures. These components are assigned random variables that provide a basis for dynamic behavior. By mapping DCO software onto LCN hardware, the complete OSM (Object System Mapping) model is created. It is shown that OSM systems can model all modes of distributed object behavior found in the current state of Object Request Broker (ORB) technology while under the constraints of modern network structures. The paper concludes with a qualitative analysis of these behaviors and sets the foundation for a distributed object simulation facility.},
  keywords={},
  doi={10.1109/SIMSYM.1995.393582},
  ISSN={},
  month={April},}
@INPROCEEDINGS{395924,
  author={Bruck, J. and Dolev, D. and Ching-Tien Ho and Orni, R. and Strong, R.},
  booktitle={Proceedings of 9th International Parallel Processing Symposium}, 
  title={PCODE: an efficient and reliable collective communication protocol for unreliable broadcast domain}, 
  year={1995},
  volume={},
  number={},
  pages={130-139},
  abstract={Existing programming environments for clusters are typically built on top of a point-to-point communication layer (send and receive) over local area networks (LANs) and, as a result, suffer from poor performance in the collective communication part. For example, a broadcast that is implemented using a TCP/IP protocol (which is a point-to-point protocol) over a LAN is obviously an efficient as it is not utilizing the fact that the LAN is a broadcast medium. We have observed that the main difference between a distributed computing paradigm and a message passing parallel computing paradigm is that, in a distributed environment the activity of every processor is independent while in a parallel environment the collection of the user-communication layers in the processors can be modeled as a single global program. We have formalized the requirements by defining the notion of a correct global program. This notion provides a precise specification, of the interface between the transport layer and the user-communication. Layer. We have developed PCODE, a new communication protocol that is driven by a global program, and proved its correctness. We have implemented the PCODE protocol on a collection of IBM RS/6000 workstations and on a collection of Silicon Graphics Indigo workstations, both communicating via UDP broadcast. The experimental results we obtained indicate that the performance advantage of PCODE over the current point-to-point approach (TCP) can be as high as an order of magnitude on a cluster of 16 workstations.},
  keywords={},
  doi={10.1109/IPPS.1995.395924},
  ISSN={},
  month={April},}
@INPROCEEDINGS{401335,
  author={Sreenivas, M.V. and Bhalla, S.},
  booktitle={Proceedings the First Aizu International Symposium on Parallel Algorithms/Architecture Synthesis}, 
  title={Garbage collection in message passing distributed systems}, 
  year={1995},
  volume={},
  number={},
  pages={213-218},
  abstract={Distributed systems use optimistic message logging for recovery from transient process failures. Such a recovery is facilitated by asynchronous message logging and check-pointing. It is also supported by garbage collection which requires identifying messages in stable storage that are no longer needed for the process of recovery. For this purpose, it is necessary to keep track of message dependencies between process states. A model to keep track of state dependencies using dependency graphs has been proposed.},
  keywords={},
  doi={10.1109/AISPAS.1995.401335},
  ISSN={},
  month={March},}
@INPROCEEDINGS{404296,
  author={Xiao, Z. and Gomes, F. and Unger, B. and Cleary, J.},
  booktitle={Proceedings 9th Workshop on Parallel and Distributed Simulation (ACM/IEEE)}, 
  title={A fast asynchronous GVT algorithm for shared memory multiprocessor architectures}, 
  year={1995},
  volume={},
  number={},
  pages={203-208},
  abstract={The computation of Global Virtual Time is of fundamental importance in Time Warp based Parallel Discrete Event Simulation Systems. Shared memory multiprocessor architectures can support interprocess communication with much smaller overheads than distributed memory systems. This paper presents a new, completely asynchronous, Gvt algorithm which provides very fast and accurate Gvt estimation with significantly lower overhead than previous approaches. The algorithm presented is able to support more efficient memory management, termination, and other global control mechanisms. The Gvt algorithm described enables any Time Warp entity to compute Gvt at any time without slowing down other entities, in particular those executing on the critical path. Experimental results are presented for a shared memory Time Warp system that employs a two tiered distributed memory management scheme. The proof of the correctness and the accuracy of the algorithm are also presented. Finally, some suggestions on possible further optimization of the implementation are given.},
  keywords={},
  doi={10.1109/PADS.1995.404296},
  ISSN={},
  month={June},}
@ARTICLE{406962,
  author={Mani Chandy, K. and Foster, I.},
  journal={IEEE Transactions on Parallel and Distributed Systems}, 
  title={A notation for deterministic cooperating processes}, 
  year={1995},
  volume={6},
  number={8},
  pages={863-871},
  abstract={This paper proposes extensions of sequential programming languages for parallel programming that have the following features: 1) Dynamic Structures: The process structure is dynamic. Processes and variables can be created and deleted. 2) Paradigm Integration: The programming notation supports shared memory and message passing models. 3) Determinism: Demonstrating that a program is deterministic-all executions with the same input produce the same output-is straightforward, Programs can be written so that compilers can verify that the programs are deterministic. Nondeterministic constructs can be introduced in a sequence of refinement steps to obtain greater efficiency if required. The ideas have been incorporated in an extension of Fortran, but the underlying sequential imperative language is not central to the ideas described here. A compiler for the Fortran extension, called Fortran M, is available by anonymous ftp From Argonne National Laboratory. Fortran M has been used for a variety of parallel applications.},
  keywords={},
  doi={10.1109/71.406962},
  ISSN={1558-2183},
  month={Aug},}
@INPROCEEDINGS{466971,
  author={Suri, G. and Jannsens, B. and Fuchs, W.K.},
  booktitle={Twenty-Fifth International Symposium on Fault-Tolerant Computing. Digest of Papers}, 
  title={Reduced overhead logging for rollback recovery in distributed shared memory}, 
  year={1995},
  volume={},
  number={},
  pages={279-288},
  abstract={Rollback techniques that use message logging and deterministic replay can be used in parallel systems to recover a failed node without involving other nodes. Distributed shared memory (DSM) systems cannot directly apply message-passing logging techniques because they use inherently nondeterministic asynchronous communication. This paper presents new logging schemes that reduce the typically high overhead for logging in DSM. Our algorithm for sequentially consistent systems tracks rather than logs accesses to shared memory. In an extension of this method to lazy release consistency, the per-access overhead of tracking has been completely eliminated. Measurements with parallel applications show a significant reduction in failure-free overhead.},
  keywords={},
  doi={10.1109/FTCS.1995.466971},
  ISSN={},
  month={June},}
@INPROCEEDINGS{468934,
  author={Petri, S. and Bumpus, P. and Bearden, D. and Coleman, G.},
  booktitle={1995 IEEE Aerospace Applications Conference. Proceedings}, 
  title={Application of function-to-platform mapping to space-based surveillance system architectural design}, 
  year={1995},
  volume={2},
  number={},
  pages={265-276 vol.2},
  abstract={An end-to-end integrated simulation of a space-based surveillance system, sponsored by the Air Force Brilliant Eyes (BE) System Program Office (SPO), was developed at the National Test Facility (NTF) and Nichols Research Corporation (NRC), Colorado Springs, Colorado. The simulation, called BESim, is sufficiently flexible and adaptable to be rapidly reconfigured to model various baseline architectural concepts and assess resulting system performance and resource allocation. The architecture independence is accomplished through "mappable" functions in an object-oriented framework. The feature, termed function-to-platform mapping (FPM) allows the user to distribute functions to various locations in the system. Subsequent impacts to system performance, communications and data-processing requirements, can be measured. FPM also allows functional component distribution through dynamic reconfiguration. This paper describes the FPM development philosophy and examples of FPM application to space-based surveillance system architectural design through analysis of communications load and message handling.},
  keywords={},
  doi={10.1109/AERO.1995.468934},
  ISSN={},
  month={Feb},}
@INPROCEEDINGS{472182,
  author={Jelly, I.E. and Croll, P.R. and Gorton, I. and Birkinshaw, C.I.},
  booktitle={Proceedings 1st International Conference on Algorithms and Architectures for Parallel Processing}, 
  title={Representation of client-server behaviour within parallel software designs}, 
  year={1995},
  volume={1},
  number={},
  pages={173-176 vol.1},
  abstract={Parallel software design techniques based on client-server process models have been proposed to support the development of deadlock free systems. Deadlock freedom can be guaranteed where no client-server cycles occur in process graphs. Hierarchical composition rules are presented which allow the designer more freedom, including the use of cycles at a higher level. The incorporation of these design rules into a software development methodology, PARSE, is described. When PARSE is used in this manner, it provides the parallel software engineer with a powerful software development framework and permits direct design verification.},
  keywords={},
  doi={10.1109/ICAPP.1995.472182},
  ISSN={},
  month={April},}
@INPROCEEDINGS{472176,
  author={Gee, D. and Hong Shen},
  booktitle={Proceedings 1st International Conference on Algorithms and Architectures for Parallel Processing}, 
  title={X-cube: a variation of cube-connected-cycles network with lower average routing steps}, 
  year={1995},
  volume={1},
  number={},
  pages={112-120 vol.1},
  abstract={A fundamental and important research area in parallel computing is the design of high-performance interconnection networks for connecting the processors in parallel computers. This paper presents a new interconnection network, the X-cube, a variant of the Cube-Connected-Cycles (CCC), which has the same degree, and same diameter in the worst case as the CCC of the same size and a decreased number of routing steps in the average case. Associated with this network is a construction algorithm which illustrates the way of building the network, and a routing algorithm that describes the method of passing messages in the network. The proposed network is validated and its performance is evaluated experimentally through implementation of the above algorithms. A number of comparisons are made between this network and three existing networks, mesh, Hypercube, and the CCC.},
  keywords={},
  doi={10.1109/ICAPP.1995.472176},
  ISSN={},
  month={April},}
@INPROCEEDINGS{472453,
  author={Zhou, H. and Geist, A.},
  booktitle={Proceedings International Phoenix Conference on Computers and Communications}, 
  title={"Receiver makes right" data conversion in PVM}, 
  year={1995},
  volume={},
  number={},
  pages={458-464},
  abstract={Using a receiver makes it right (RMR) data conversion technique in PVM significantly improves the message-passing performance in heterogeneous environments. The improvements are due to two factors: (1). RMR reduces the need for conversions in a heterogeneous environment; (2). At most each message is converted, only once compared to twice for XDR used in public version of PVM, and our conversion routines are streamlined and are several times faster than the XDR routines. The drawback to RMR is the potential need for a large number of conversion routines. We demonstrate that only a small number of routines are required because many vendors use the IEEE standard for data representation. Given this fact, RMR may emerge as a promising technique in distributed computing.},
  keywords={},
  doi={10.1109/PCCC.1995.472453},
  ISSN={},
  month={March},}
@INPROCEEDINGS{476822,
  author={Fillo, M. and Keckler, S.W. and Dally, W.J. and Carter, N.P. and Chang, A. and Gurevich, Y. and Lee, W.S.},
  booktitle={Proceedings of the 28th Annual International Symposium on Microarchitecture}, 
  title={The M-Machine multicomputer}, 
  year={1995},
  volume={},
  number={},
  pages={146-156},
  abstract={The M-Machine is an experimental multicomputer being developed to test architectural concepts motivated by the constraints of modern semiconductor technology and the demands of programming systems. The M-Machine computing nodes are connected with a 3-D mesh network; each node is a multithreaded processor incorporating 12 function units, on-chip cache, and local memory. The multiple function units are used to exploit both instruction-level and thread-level parallelism. A user accessible message passing system yields fast communication and synchronization between nodes. Rapid access to remote memory is provided transparently to the user with a combination of hardware and software mechanisms. This paper presents the architecture of the M-Machine and describes how its mechanisms attempt to maximize both single thread performance and overall system throughput. The architecture is complete and the MAP chip, which will serve as the M-Machine processing node, is currently being implemented.},
  keywords={},
  doi={10.1109/MICRO.1995.476822},
  ISSN={1072-4451},
  month={Nov},}
@INPROCEEDINGS{483307,
  author={Dowd, P.W. and Srinidhi, S.M. and Pellegrino, F.A. and Carrozzi, T.M. and Guglielmi, D.L. and Claus, R.},
  booktitle={Proceedings of MILCOM '95}, 
  title={Impact of transport protocols and message passing libraries on cluster-based computing performance}, 
  year={1995},
  volume={1},
  number={},
  pages={246-251 vol.1},
  abstract={This paper provides an experimental assessment of the impact of the underlying networking in a cluster-based computing environment. The assessment is quantified through application level benchmarking, process level communication, and networkfile I/O. Two testbeds are considered-one small cluster of SUN workstations and another larger cluster composed of 32 high-end IBM RS/6000 platforms. The cluster machines have Ethernet, FDDI, Fiber Channel and ATM network interface cards installed. This provides a consistent testbed since the processors and operating system are identical for this suite of experiments. A major issue to be examined is ATM-based local area networks. In particular a primary goal of this work is to assess the suitability of an ATM-based network to support interprocess communication and remote file I/O systems for distributed computing.},
  keywords={},
  doi={10.1109/MILCOM.1995.483307},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{492674,
  author={Galil, Z. and Mayer, A. and Moti Yung},
  booktitle={Proceedings of IEEE 36th Annual Foundations of Computer Science}, 
  title={Resolving message complexity of Byzantine Agreement and beyond}, 
  year={1995},
  volume={},
  number={},
  pages={724-733},
  abstract={Byzantine Agreement among processors is a basic primitive in distributed computing. It comes in a number of basic fault models: "Crash", "Omission" and "Malicious" adversarial behaviors. The message complexity of the primitive has been known for the strong failure models of Malicious and Omission adversary since the early 80's, while the question for the more benign Crash failure model has been open. We show how to solve agreement in the presence of crash failures using O(n) messages which is optimal, thus settling a thirteen year old open problem. Our solution has almost linear time and our new algorithmic techniques have further implications: a family of "early stopping" agreement protocols with improved message-complexity; and a new solution to "Checkpoint" yielding a substantial improvement of the protocol for distributed work performance under adaptive parallelism in a network of workstations.},
  keywords={},
  doi={10.1109/SFCS.1995.492674},
  ISSN={0272-5428},
  month={Oct},}
@INPROCEEDINGS{526217,
  author={Cabillic, G. and Muller, G. and Puaut, I.},
  booktitle={Proceedings. 14th Symposium on Reliable Distributed Systems}, 
  title={The performance of consistent checkpointing in distributed shared memory systems}, 
  year={1995},
  volume={},
  number={},
  pages={96-105},
  abstract={This paper presents the design and implementation of a consistent checkpointing scheme for distributed shared memory (DSM) systems. Our approach relies on the integration of checkpoints within synchronization barriers already existing in applications; this avoids the need to introduce an additional synchronization mechanism. The main advantage of our checkpointing mechanism is that performance degradation arises only when a checkpoint is being taken; hence, the programmer can adjust the trade-off between the cost of checkpointing and the cost of longer rollbacks by adjusting the time between two successive checkpoints. The paper compares several implementations of the proposed consistent checkpointing mechanism (incremental, non-blocking, and pre-flushing) on the Intel Paragon multicomputer for several parallel scientific applications. Performance measures show that a careful optimization of the checkpointing protocol can reduce the time overhead of checkpointing from 8% to 0.04% of the application duration for a 6 mn checkpointing interval.},
  keywords={},
  doi={10.1109/RELDIS.1995.526217},
  ISSN={1060-9857},
  month={Sep.},}
@INPROCEEDINGS{526544,
  author={Kamkar, M. and Krajina, P.},
  booktitle={Proceedings of International Conference on Software Maintenance}, 
  title={Dynamic slicing of distributed programs}, 
  year={1995},
  volume={},
  number={},
  pages={222-229},
  abstract={As software applications grow larger and become more complex, program maintenance activities such as adding new functionality, debugging, and testing consume an increasing amount of available resources for software development. This is especially true for distributed systems communicating via message passing. In order to cope with this increased complexity, programmers need effective computer supported methods for decomposition and dependence analysis of programs. Program slicing is one method for such decomposition and dependence analysis. A program slice with respect to a specified variable at some program point consists of those parts of the program which potentially affect the value of that variable at the particular program point. A static slice is valid for all possible executions of a program while a dynamic slice considers only a particular execution of a program. In this paper we present a technique for dynamic slicing of distributed programs which computes accurate slices. We introduce the notion of distributed dynamic dependence graph (DDDG) which represents control, data and communication dependences in a distributed program. This graph is built at run time and used to compute dynamic slices of the program. A distributed dynamic slicer for ANSI-C programming language has been implemented on a parallel MIMD computer of type Parsytec GC/Powerplus with 128 PowerPC processors.},
  keywords={},
  doi={10.1109/ICSM.1995.526544},
  ISSN={1063-6773},
  month={Oct},}
@INPROCEEDINGS{528801,
  author={Maturana, G. and Ball, J.L. and Gee, J. and Iyer, A. and O'Connor, J.M.},
  booktitle={Proceedings of ICCD '95 International Conference on Computer Design. VLSI in Computers and Processors}, 
  title={Incas: a cycle accurate model of UltraSPARC}, 
  year={1995},
  volume={},
  number={},
  pages={130-135},
  abstract={This paper describes a cycle accurate model of the UltraSPARC processor. The model is written in C++, and is built on top of a powerful programming framework with a built-in message-passing mechanism and a timing discipline for simulating concurrent modules. The goal was to help verify the processor by cross checking the RTL model at run time, as well as to provide accurate performance estimates. Because of Incas' much faster execution rate than the RTL, it was also used to model the UItraSPARC module in RTL simulations of the full system, for compiler and library tuning, and for diagnostics development.},
  keywords={},
  doi={10.1109/ICCD.1995.528801},
  ISSN={1063-6404},
  month={Oct},}
@INPROCEEDINGS{496687,
  author={Dakroury, Y. and Elloy, J.P.},
  booktitle={Proceedings 1995 INRIA/IEEE Symposium on Emerging Technologies and Factory Automation. ETFA'95}, 
  title={Specification and validation of a distributed transaction processing facility for the MMS applications}, 
  year={1995},
  volume={2},
  number={},
  pages={465-473 vol.2},
  abstract={We introduce a specification of a distributed transaction processing facility for the Manufacturing Message Specification (MMS) which is an application service element of the Manufacturing Automation Protocol (MAP) standardized by the International Standard Organization (ISO) to support messaging communication to and from programmable devices in a computer integrated manufacturing (CIM) environment. The proposed facility permits the organization of a distributed transaction in terms of a set of MMS services encapsulated together to perform the manufacturing or the production tasks. The services provided by the transaction processing (TP) standard, presented by the ISO, are used as well as new services are defined to guarantee the coherent behavior of the MMS distributed transactions. This guarantee is based on the satisfaction of the Atomicity, Consistency, Isolation, and Durability (ACID) properties defined by the ISO. The distributed transaction processing facility is specified as finite state automata represented by Nutt evaluation networks notations. A validation technique based on the Calculus of Communicating Systems (CCS) introduced by Milner is used to prove the coherent behavior of the transactions.},
  keywords={},
  doi={10.1109/ETFA.1995.496687},
  ISSN={},
  month={Oct},}
@INPROCEEDINGS{500027,
  author={Chengchang Huang and Yih Huang and McKinley, P.K.},
  booktitle={Proceedings of 15th International Conference on Distributed Computing Systems}, 
  title={A thread-based interface for collective communication on ATM networks}, 
  year={1995},
  volume={},
  number={},
  pages={254-261},
  abstract={This paper presents the results of an investigation of collective communication operations for distributed computing across asynchronous transfer mode (ATM) networks. Several collective operations have been implemented and studied on a three-switch ATM network testbed at Michigan State University. The methods use virtual topologies constructed from ATM virtual channels. A particular type of virtual topology is described that efficiently implements several collective operations through the use of hardware-supported ATM multicast channels. Performance measurements are presented that illustrate how a thread-based software design can take advantage of such underlying hardware features.},
  keywords={},
  doi={10.1109/ICDCS.1995.500027},
  ISSN={1063-6927},
  month={May},}
@INPROCEEDINGS{512613,
  author={Corno, F. and Prinetto, P. and Rebaudengo, M. and Reorda, M.S. and Veiluva, E.},
  booktitle={Proceedings 13th IEEE VLSI Test Symposium}, 
  title={A portable ATPG tool for parallel and distributed systems}, 
  year={1995},
  volume={},
  number={},
  pages={29-34},
  abstract={The use of parallel architectures for the solution of CPU and memory critical problems in the electronic CAD area has been limited up to now by several factors, like the lack of efficient algorithms the reduced portability of the code, and the cost of the hardware. However, portable message-passing libraries are now available, and the same code runs on high-cost supercomputers, as well as on common workstation networks. The paper presents an effective ATPG system for large sequential circuits developed using the PVM library and based on a genetic algorithm. The tool, named GATTO has been run on a DEC Alpha AXP farm and on a CM-5. Experimental results are provided.},
  keywords={},
  doi={10.1109/VTEST.1995.512613},
  ISSN={1093-0167},
  month={April},}
@INPROCEEDINGS{518582,
  author={Kordon, F. and Kaim, W.E.},
  booktitle={Proceedings Sixth IEEE International Workshop on Rapid System Prototyping. Shortening the Path from Specification to Prototype}, 
  title={H-COSTAM: a hierarchical communicating state-machine model for generic prototyping}, 
  year={1995},
  volume={},
  number={},
  pages={131-138},
  abstract={This paper presents a methodology that aims at the specification, verification and prototyping of large distributed systems. This methodology relies on H-COSTAM: a high level representation that supports hierarchy and focuses on message passing communication mechanisms. In order to enable validation based on a formal representation, a translation procedure to Petri net is proposed. We also show this can fit discrete application domains. Translation from discrete high level formalism into H-COSTAM is possible. We present an example with Estelle.},
  keywords={},
  doi={10.1109/IWRSP.1995.518582},
  ISSN={1074-6005},
  month={June},}

@ARTICLE{372788,
  author={Kafura, D. and Mukherji, M. and Washabaugh, D.M.},
  journal={IEEE Transactions on Parallel and Distributed Systems}, 
  title={Concurrent and distributed garbage collection of active objects}, 
  year={1995},
  volume={6},
  number={4},
  pages={337-350},
  abstract={This paper shows how to perform concurrent and distributed automatic garbage collection of objects possessing their own thread of control. The relevance of garbage collection and active objects to distributed applications is briefly discussed and the specific model of active objects used in the paper is explained. The collector is comprised of independent local collectors, one per node, and a distributed global collector. The mutator (application), the local collectors and the global collector run concurrently. An important part of this paper is the detailed presentation of the algorithms necessary to achieve correct concurrent operation among the collectors and between the collectors and the mutator. The collector builds on previous algorithms for taking snapshots in distributed systems and for detecting termination.},
  keywords={},
  doi={10.1109/71.372788},
  ISSN={1558-2183},
  month={April},}
@INPROCEEDINGS{375457,
  author={Garg, V.K. and Chase, C. and Mitchell, J.R. and Kilgore, R.},
  booktitle={Proceedings of the Twenty-Eighth Annual Hawaii International Conference on System Sciences}, 
  title={Detecting conjunctive channel predicates in a distributed programming environment}, 
  year={1995},
  volume={2},
  number={},
  pages={232-241 vol.2},
  abstract={Previous work in efficient detection of global predicates was restricted to predicates that could be specified as a Boolean formula of local predicates. Many properties in distributed systems, however, use the state of channels. In this paper, we introduce the concept of a 'channel predicate' and provide an efficient algorithm to detect any Boolean formula of local and channel predicates. We define a property called 'monotonicity' for channel predicates. Monotonicity is crucial for the efficient detection of global predicates. Many problems studied earlier, such as detection of termination and computation of global virtual time, are special cases of the problem considered in this paper. The message complexity of our algorithm is bounded by the number of messages used by the program.},
  keywords={},
  doi={10.1109/HICSS.1995.375457},
  ISSN={},
  month={Jan},}
@INPROCEEDINGS{375448,
  author={Wirtz, G.},
  booktitle={Proceedings of the Twenty-Eighth Annual Hawaii International Conference on System Sciences}, 
  title={Modularization, re-use and testing for parallel message-passing programs}, 
  year={1995},
  volume={2},
  number={},
  pages={299-308 vol.2},
  abstract={The advantages of modularization which are well-known in sequential programming should also be exploited when designing and developing parallel programs. We investigate the requirements for such a concept in the context of an explicit, imperative message-passing programming language for the distributed memory paradigm. The language is a hybrid one in the sense that all parallel aspects are specified by means of graphical constructs whereas sequential parts are formulated in a slightly restricted ANSI-C.},
  keywords={},
  doi={10.1109/HICSS.1995.375448},
  ISSN={},
  month={Jan},}
@INPROCEEDINGS{375343,
  author={Lupo, J.A.},
  booktitle={Proceedings of the Twenty-Eighth Annual Hawaii International Conference on System Sciences}, 
  title={Benchmarking UHGROMOS}, 
  year={1995},
  volume={5},
  number={},
  pages={132-141 vol.5},
  abstract={Porting of the parallel Fortran preprocessor, Pfortran, to Intel Corporation and IBM Corporation massively parallel processor machines is presented. The machines include the Intel iPSC/860, the Caltech Intel DELTA, the Intel Paragon, and the IBM SP1. The UHGROMOS molecular dynamics program, a version of GROMOS ported to parallel machines through the use of Pfortran, was used as a test application. Benchmark and parallel performance analysis results},
  keywords={},
  doi={10.1109/HICSS.1995.375343},
  ISSN={},
  month={Jan},}
@INPROCEEDINGS{375414,
  author={Wu, K.Y. and Ng, P.K.H. and Jia, X.D. and Chen, R.M.M. and Layfield, A.M.},
  booktitle={Proceedings of the Twenty-Eighth Annual Hawaii International Conference on System Sciences}, 
  title={Performance tuning of a multiprocessor sparse matrix equation solver}, 
  year={1995},
  volume={1},
  number={},
  pages={4-13 vol.1},
  abstract={Solving a system of linear simultaneous equations representing an electrical circuit is one of the most time consuming tasks for large scale circuit simulations. In order to facilitate a multiprocessor implementation of the circuit simulation program SPICE, a decomposition algorithm is employed to partition the sparse matrix equation of an overall circuit into a number of sub-circuit equations for parallel processing. In this paper, various implementation and performance tuning issues of a parallel direct method matrix equation solving routine is reported. This routine is written in such a manner that the data structure is compatible with SPICE Version 3Cl. The speed-up obtained for the simulation of several test circuits on a message passing multiprocessor system built on Transputers will be reported.},
  keywords={},
  doi={10.1109/HICSS.1995.375414},
  ISSN={},
  month={Jan},}
@INPROCEEDINGS{518715,
  author={Yadav, R. and Reddy, R. and Hariri, S.},
  booktitle={Proceedings of the Fourth IEEE International Symposium on High Performance Distributed Computing}, 
  title={A multithreaded message passing environment for ATM LAN/WAN}, 
  year={1995},
  volume={},
  number={},
  pages={238-245},
  abstract={Large scale High Performance Computing and Communication (HPCC) applications (e.g. Video-on-Demand, and HPDC) would require storage and processing capabilities which are beyond existing single computer systems. The current advances in networking technology (e.g. ATM) have made high performance network computing an attractive computing environment for such applications. However, using only high speed network is not sufficient to achieve high performance distributed computing environment unless some hardware and software problems have been resolved. These problems include the limited communication bandwidth available to the application, high overhead associated with context switching, redundant data copying during protocol processing and lack of support to overlap computation and communication at application level. In this paper, we propose a multithreaded message passing system for parallel/distributed processing that we refer to as NYNET communication system (NCS). NCS, being developed for NYNET (ATM wide area network testbed), is built on top of an ATM application programmer interface (API). The multithreaded environment allows applications to overlap computations and communications and provides a modular approach to support efficiently HPDC applications with different quality of service (QOS) requirements.},
  keywords={},
  doi={10.1109/HPDC.1995.518715},
  ISSN={1082-8907},
  month={Aug},}
@ARTICLE{342126,
  author={Bala, V. and Bruck, J. and Cypher, R. and Elustondo, P. and Ho, A. and Ching-Tien Ho and Kipnis, S. and Snir, M.},
  journal={IEEE Transactions on Parallel and Distributed Systems}, 
  title={CCL: a portable and tunable collective communication library for scalable parallel computers}, 
  year={1995},
  volume={6},
  number={2},
  pages={154-164},
  abstract={A collective communication library for parallel computers includes frequently used operations such as broadcast, reduce, scatter, gather, concatenate, synchronize, and shift. Such a library provides users with a convenient programming interface, efficient communication operations, and the advantage of portability. A library of this nature, the Collective Communication Library (CCL), intended for the line of scalable parallel computer products by IBM, has been designed. CCL is part of the parallel application programming interface of the recently announced IBM 9076 Scalable POWERparallel System 1 (SP1). In this paper, we examine several issues related to the functionality, correctness, and performance of a portable collective communication library while focusing on three novel aspects in the design and implementation of CCL: 1) the introduction of process groups, 2) the definition of semantics that ensures correctness, and 3) the design of new and tunable algorithms based on a realistic point-to-point communication model.},
  keywords={},
  doi={10.1109/71.342126},
  ISSN={1558-2183},
  month={Feb},}
@INPROCEEDINGS{524825,
  author={Qiang Gao and Groz, R. and von Bochmann, G. and Dargham, J. and Htite, E.H.},
  booktitle={Proceedings of International Conference on Network Protocols}, 
  title={Validation of distributed algorithms and protocols}, 
  year={1995},
  volume={},
  number={},
  pages={110-117},
  abstract={The use of formal description techniques allows the partial automation of the design, the validation, and the implementation of communication protocols and distributed algorithms. In this paper, we present a methodology for validation of distributed algorithms and protocols, and our experiences of using the Estelle language, and a simulation and validation tool, called Veda, to simulate and validate complex distributed algorithms for the distributed implementation of multi-rendezvous. Some design errors in published distributed rendezvous algorithms were found. We obtain from these experiences heuristic guidelines for trouble shooting of distributed algorithms.},
  keywords={},
  doi={10.1109/ICNP.1995.524825},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{530663,
  author={Beck, J. and Siewiorek, D.},
  booktitle={Proceedings.Seventh IEEE Symposium on Parallel and Distributed Processing}, 
  title={Automated processor specification and task allocation for embedded multicomputer systems: The packing-based approaches}, 
  year={1995},
  volume={},
  number={},
  pages={44-51},
  abstract={This paper considers the coupled design problems of processor specification and task allocation for embedded multicomputer systems. A packing-based representation is proposed that allows the problems to be solved concurrently. An algorithm based on this representation is described that utilizes a new heuristic packing technique coupled with an incremental design advisor. This algorithm, named IDAT, was benchmarked against three baseline algorithms on a combination of real and synthetic test cases with respect to two figures of merit: hardware cost and run-time. The real test cases are based on commercially developed automotive electronic applications and the baseline algorithms represent a mixture of search, heuristic and simulated annealing approaches. For all test cases, the IDAT algorithm was found to generate near-optimal solutions with up to three orders of magnitude improvement in run-time compared to the baseline algorithms.},
  keywords={},
  doi={10.1109/SPDP.1995.530663},
  ISSN={1063-6374},
  month={Oct},}
@INPROCEEDINGS{530730,
  author={Cypher, R. and Leu, E.},
  booktitle={Proceedings.Seventh IEEE Symposium on Parallel and Distributed Processing}, 
  title={Efficient race detection for message-passing programs with nonblocking sends and receives}, 
  year={1995},
  volume={},
  number={},
  pages={534-541},
  abstract={This paper presents an algorithm for performing on-the-fly race detection for parallel message-passing programs. The algorithm reads a trace of the communication events in a message-passing parallel program and either finds a specific race condition or reports that the traced program is race-free. It supports a rich message-passing model, including blocking and non-blocking sends and receives, synchronous and asynchronous sends, receive selectivity by source and/or tag value, and arbitrary amounts of system buffering of messages. It runs in polynomial time and is very efficient for most types of executions. A key feature of the race detection algorithm is its use of several new types of logical clocks for determining ordering relations. It is likely that these logical clocks will also be useful in other settings.},
  keywords={},
  doi={10.1109/SPDP.1995.530730},
  ISSN={1063-6374},
  month={Oct},}
@INPROCEEDINGS{530728,
  author={Wei Kang Huang and Xiaotao Chen and Bhuyan, L. and Lombardi, F.},
  booktitle={Proceedings.Seventh IEEE Symposium on Parallel and Distributed Processing}, 
  title={Accurate communication models for task scheduling in multicomputers}, 
  year={1995},
  volume={},
  number={},
  pages={524-529},
  abstract={Models for computations and message-passing communications are very important for scheduling applications onto multicomputer systems and estimating the parallel execution time. This paper presents new models for communication, scheduling and estimating the execution time. In the proposed models, it is assumed that each processor in the multicomputer system has a router. The processor can only receive data from and send data to the router sequentially while the router can receive data from and send data to the routers of other processors in parallel. The execution time of a given application on a given machine can be then accurately estimated by using the proposed models. The input parameters to the proposed models are determined by measuring some parameters experimentally. Experimental results on the nCUBE2 machine are given to show the correctness of the proposed models.},
  keywords={},
  doi={10.1109/SPDP.1995.530728},
  ISSN={1063-6374},
  month={Oct},}
@INPROCEEDINGS{530706,
  author={Tao Yang and Ibarra, O.H.},
  booktitle={Proceedings.Seventh IEEE Symposium on Parallel and Distributed Processing}, 
  title={On symbolic scheduling and parallel complexity of loops}, 
  year={1995},
  volume={},
  number={},
  pages={360-367},
  abstract={We first consider the symbolic scheduling and performance prediction of a partitioned single loop on message passing architectures with non zero communication and a sufficient number of processors. The loop body contains a set of coarse grain tasks whose computational weights change during the course of the iterations. Using the macro dataflow task: model and software pipelining techniques, we develop an algorithm for computing a heuristic schedule, and provide analytic and experimental results on the correctness and asymptotic performance of this schedule. Using this result, we can show the impact of partitioning on the performance of parallelization. While this result is effective for a class of loops, there are many other methods proposed for loop parallelization. An interesting fundamental question is whether every instance of a nested loop can be efficiently executed, We present some positive and negative results on this issue.},
  keywords={},
  doi={10.1109/SPDP.1995.530706},
  ISSN={1063-6374},
  month={Oct},}
@INPROCEEDINGS{537949,
  author={Zelek, J.S.},
  booktitle={1995 IEEE International Conference on Systems, Man and Cybernetics. Intelligent Systems for the 21st Century}, 
  title={Dynamic path planning}, 
  year={1995},
  volume={2},
  number={},
  pages={1285-1290 vol.2},
  abstract={Path planning is dynamic when the path is continually recomputed as more information becomes available. A computational framework for dynamic path planning is proposed which has the ability to provide navigational directions during the computation of the plan. Path planning is performed using a potential field approach. We use a specific type of potential function-a harmonic function-which has no local minima. The implementation is parallel and consists of a collection of communicating processes, across a network of SPARC & SGI workstations using a message passing software package called PVM. The computation of the plan is performed independently of the execution of the plan. A hierarchical coarse-to-fine procedure is used to guarantee a correct control strategy at the expense of accuracy. We have successfully navigated a Nomad robot around our lab space with no a priori map in real-time. The result of the described approach is a parallel implementation which permits dynamic path planning using available processor resources.},
  keywords={},
  doi={10.1109/ICSMC.1995.537949},
  ISSN={},
  month={Oct},}
@INPROCEEDINGS{540159,
  author={Fatoohi, R.},
  booktitle={Proceedings of Fourth International Conference on Computer Communications and Networks - IC3N'95}, 
  title={Performance evaluation of communication networks for distributed computing}, 
  year={1995},
  volume={},
  number={},
  pages={456-459},
  abstract={We present performance results for several high-speed networks in distributed computing environments. These networks are: HiPPI, ATM, Fibre Channel, IBM Allnode switch, FDDI, and Ethernet. These networks are parts of two testbeds: DaVinci-a cluster of 16 SGI R8000 workstations at NASA Ames-and LACE-a cluster of 96 IBM RS6000 workstations at NASA Lewis. Also, an IBM SP2 machine is considered for comparison. Several communication tests are performed and the results are presented for two programming levels: BSD socket programming interface using the program ttcp and PVM message passing library. These results show that the emerging network technologies can achieve reasonable performance under certain conditions. However, the achievable performance is still far behind the theoretical peak rates.},
  keywords={},
  doi={10.1109/ICCCN.1995.540159},
  ISSN={},
  month={Sep.},}
@INPROCEEDINGS{538520,
  author={Arularasan, R. and Saratchandran, P. and Sundararajan, N.},
  booktitle={1995 IEEE International Conference on Systems, Man and Cybernetics. Intelligent Systems for the 21st Century}, 
  title={An analysis of network parallelism of backpropagation neural networks on a transputer array}, 
  year={1995},
  volume={5},
  number={},
  pages={4597-4602 vol.5},
  abstract={This paper presents the development of a theoretical model for parallel implementation of backpropagation (BP) neural networks using the "network parallelism" paradigm. The case where the number of nodes in each layer is equally distributed among the processors is considered. The model is developed for a homogeneous array of message passing processors with only local memory. The developed model predicts the training time for a given neural network without having to set up the hardware and run the experiments. The accuracy of the model is verified by comparing the predicted training time using the theoretical model with the actual experimental values for the case of an array of T805 transputers connected in a ring topology for benchmark neural network problems like the Encoder and Nettalk.},
  keywords={},
  doi={10.1109/ICSMC.1995.538520},
  ISSN={},
  month={Oct},}
@ARTICLE{382324,
  author={Yi-Min Wang and Pi-Yu Chung and In-Jen Lin and Fuchs, W.K.},
  journal={IEEE Transactions on Parallel and Distributed Systems}, 
  title={Checkpoint space reclamation for uncoordinated checkpointing in message-passing systems}, 
  year={1995},
  volume={6},
  number={5},
  pages={546-554},
  abstract={Uncoordinated checkpointing allows process autonomy and general nondeterministic execution, but suffers from potential domino effects and the associated space overhead. Previous to this research, checkpoint space reclamation had been based on the notion of obsolete checkpoints; as a result, a potentially unbounded number of nonobsolete checkpoints may have to be retained on stable storage. In this paper, we derive a necessary and sufficient condition for identifying all garbage checkpoints. By using the approach of recovery line transformation and decomposition, we develop an optimal checkpoint space reclamation algorithm and show that the space overhead for uncoordinated checkpointing is in fact bounded by N(N+1)/2 checkpoints where N is the number of processes.},
  keywords={},
  doi={10.1109/71.382324},
  ISSN={1558-2183},
  month={May},}
@INPROCEEDINGS{1383205,
  author={Jayasimha, D.N. and Hayder, M.E. and Pillay, S.K.},
  booktitle={Supercomputing '95:Proceedings of the 1995 ACM/IEEE Conference on Supercomputing}, 
  title={Parallelizing Navier-Stokes Computations on a Variety of Architectural Platforms}, 
  year={1995},
  volume={},
  number={},
  pages={68-68},
  abstract={We study the computational, communication, and scalability characteristics of a Computational Fluid Dynamics application, which solves the time accurate flow field of a jet using the compressible Navier-Stokes equations, on a variety of parallel architectural platforms. The platforms chosen for this study are a cluster of workstations (the LACE experimental testbed at NASA Lewis), a shared memory multiprocessor (the Cray YMP), distributed memory multiprocessors with different topologies — the IBM SP and the Cray T3D. We investigate the impact of various networks, connecting the cluster of workstations, on the performance of the application and the overheads induced by popular message passing libraries used for parallelization. The work also highlights the importance of matching the memory bandwidth to the processor speed for good single processor performance. By studying the performance of an application on a variety of architectures, we are able to point out the strengths and weaknesses of each of the example computing platforms},
  keywords={},
  doi={},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{546194,
  author={Botorog, G.H. and Kuchen, H.},
  booktitle={Proceedings of 5th IEEE International Symposium on High Performance Distributed Computing}, 
  title={Skil: an imperative language with algorithmic skeletons for efficient distributed programming}, 
  year={1996},
  volume={},
  number={},
  pages={243-252},
  abstract={We present Skil, an imperative language enhanced with higher order functions and currying, as well as with a polymorphic type system. The high level of Skil allows the integration of algorithmic skeletons, i.e. of higher order functions representing parallel computation patterns. At the same time, the language can be efficiently implemented. After describing a series of skeletons which work with distributed arrays, we give two examples of parallel programs implemented on the basis of skeletons, namely shortest paths in graphs and Gaussian elimination. Run time measurements show that we approach the efficiency of message passing C up to a factor between 1 and 2.5.},
  keywords={},
  doi={10.1109/HPDC.1996.546194},
  ISSN={1082-8907},
  month={Aug},}
@INPROCEEDINGS{546213,
  author={Silva, L.M. and Silva, J.G. and Chapple, S.},
  booktitle={Proceedings of 5th IEEE International Symposium on High Performance Distributed Computing}, 
  title={Portable transparent checkpointing for distributed shared memory}, 
  year={1996},
  volume={},
  number={},
  pages={422-431},
  abstract={We present a checkpointing mechanism for a DSM system that, in spite of being invisible to the programmer, is quite efficient and portable. It is efficient because it is nonblocking, coordinated and thus domino-effect free. It offers some portability because it is built on top of MPI and uses only the services offered by MPI and a POSIX compliant local file system. As far as we know, this is the first real implementation of such a scheme for DSM. Along with the description of the algorithms used, we present experimental results obtained in a cluster of workstations, and discuss many insights that came out of the implementation effort. We hope that our research shows that efficient, transparent and portable checkpointing is viable for DSM systems.},
  keywords={},
  doi={10.1109/HPDC.1996.546213},
  ISSN={1082-8907},
  month={Aug},}
@INPROCEEDINGS{546217,
  author={Sung-Yong Park and Hariri, S. and Yoonhee Kim and Harris, J.S. and Yadav, R.},
  booktitle={Proceedings of 5th IEEE International Symposium on High Performance Distributed Computing}, 
  title={NYNET Communication System (NCS): a multithreaded message passing tool over ATM network}, 
  year={1996},
  volume={},
  number={},
  pages={460-469},
  abstract={Current advances in processor technology, and the rapid development of high speed networking technology, such as ATM, have made high performance network computing an attractive computing environment for large-scale high performance distributed computing (HPDC) applications. However, due to the communications overhead at the host-network interface, most of the HPDC applications are not getting the full benefit of high speed communication networks. This overhead can be attributed to the high cost of operating system calls, context switching, the use of inefficient communication protocols, and the coupling of data and control paths. We present an architecture and implementation for a low-latency, high-throughput message passing tool, that we refer to as the NYNET (ATM wide area network testbed in New York state) Communication System (NCS), which can support a variety of HPDC applications with different Quality of Services (QOS) requirements. NCS uses multithreading to provide efficient techniques that overlap computation and communication. NCS uses read/write trap routines to bypass traditional operating system calls. This reduces latency and avoids using inefficient communication protocols. By separating data and control paths, NCS eliminates unnecessary control transfers. This optimizes the data path and improves performance. Benchmarking results show that the performance of NCS is at least a factor of two better than the performance of corresponding p4 and PVM primitives.},
  keywords={},
  doi={10.1109/HPDC.1996.546217},
  ISSN={1082-8907},
  month={Aug},}
@INPROCEEDINGS{560771,
  author={Schroeder, M. and de Almeida Mora, I. and Pereira, L.M.},
  booktitle={Proceedings Eighth IEEE International Conference on Tools with Artificial Intelligence}, 
  title={A deliberative and reactive diagnosis agent based on logic programming}, 
  year={1996},
  volume={},
  number={},
  pages={436-437},
  abstract={We briefly overview the architecture of a diagnosis agent. We employ logic and logic programming to specify and implement the agent: the knowledge base uses extended logic programming to specify the agent's behaviour and its knowledge about the system to be diagnosed. The inference machine, which provides algorithms to compute diagnoses, as well as the reactive layer that realises a meta interpreter for the agent behaviour are implemented in PVM-Prolog, that enhances standard Prolog by message passing facilities.},
  keywords={},
  doi={10.1109/TAI.1996.560771},
  ISSN={1082-3409},
  month={Nov},}
@ARTICLE{481662,
  author={Zhiwei Xu and Hwang, K.},
  journal={IEEE Parallel & Distributed Technology: Systems & Applications}, 
  title={Modeling communication overhead: MPI and MPL performance on the IBM SP2}, 
  year={1996},
  volume={4},
  number={1},
  pages={9-24},
  abstract={The authors use timing experiments on the IBM SP2 to develop an overhead-quantifying method for evaluating communication performance on message-passing multicomputers. Massively parallel processor (MPP) designers and users can apply this method to reveal architectural bottlenecks and to trade off between computations and communications for parallel applications optimization. This article presents a systematic method to estimate the communication overheads of three message-passing operations (point-to-point communication, collective communication and collective computation) on MPPs. We validated this method by a performance study of the Message-Passing Interface (MPI) and the IBM Message-Passing Library (MPL) on the IBM SP2 at the Maui High-Performance Computing Center. We measured overheads of the three communication operations for various combinations of machine size and message length. We used the collected timing data to derive the overhead expressions. For a given MPP, the timing measurements need to be performed only once.},
  keywords={},
  doi={10.1109/88.481662},
  ISSN={1558-1861},
  month={Spring},}
@ARTICLE{485843,
  author={Amza, C. and Cox, A.L. and Dwarkadas, S. and Keleher, P. and Honghui Lu and Rajamony, R. and Weimin Yu and Zwaenepoel, W.},
  journal={Computer}, 
  title={TreadMarks: shared memory computing on networks of workstations}, 
  year={1996},
  volume={29},
  number={2},
  pages={18-28},
  abstract={Shared memory facilitates the transition from sequential to parallel processing. Since most data structures can be retained, simply adding synchronization achieves correct, efficient programs for many applications. We discuss our experience with parallel computing on networks of workstations using the TreadMarks distributed shared memory system. DSM allows processes to assume a globally shared virtual memory even though they execute on nodes that do not physically share memory. We illustrate a DSM system consisting of N networked workstations, each with its own memory. The DSM software provides the abstraction of a globally shared memory, in which each processor can access any data item without the programmer having to worry about where the data is or how to obtain its value.},
  keywords={},
  doi={10.1109/2.485843},
  ISSN={1558-0814},
  month={Feb},}
@INPROCEEDINGS{493618,
  author={Beedubail, G. and Karmarkar, A. and Gurijala, H. and Marti, W. and Pooch, U.},
  booktitle={Conference Proceedings of the 1996 IEEE Fifteenth Annual International Phoenix Conference on Computers and Communications}, 
  title={Fault tolerant objects in distributed systems using hot replication}, 
  year={1996},
  volume={},
  number={},
  pages={89-95},
  abstract={This paper presents a new algorithm for supporting fault tolerant objects in distributed systems. The fault tolerance provided by the algorithm is fully user transparent. The algorithm uses a variation of object replication scheme, which we call the Hot Replication Scheme. The algorithm supports nested object invocations. The chief advantages of the scheme are: a) No action is needed in the case of failure of a secondary replica, b) The time to recover from a primary failure is minimal, c) Separation of replication protocol and reliable communication protocol. To recover from a primary failure the system need to (detect the failure and) select one of the secondaries to become the primary. The designated secondary can become primary once it has made sure that its current state is equivalent to the state of the failed primary (it can do so by processing outstanding requests, if any). This is in contrast with the checkpointing and rollback recovery scheme, where the recovery time can be substantial. Our algorithm exploits the general features and concepts associated with the notion of the objects and object interactions to its advantage.},
  keywords={},
  doi={10.1109/PCCC.1996.493618},
  ISSN={},
  month={March},}
@INPROCEEDINGS{492150,
  author={Kempf, G. and Caremoli, C. and Damm, G. and Wei-Ying Thang and van der Steen, A.},
  booktitle={Proceedings of the 29th Annual Simulation Symposium}, 
  title={Simulation of scientific programs on parallel architectures with MIMESIS environment}, 
  year={1996},
  volume={},
  number={},
  pages={36-43},
  abstract={The paper presents how a scientific application written using an SPMD programming model with message passing can be modeled and simulated. This description is based on the counting of basic operations and the recognition of known kernels. A Fortran analyzer was built to automatically generate a model of such an application for the simulation tool of the MIMESIS project, developed at EDF (Electricite de France). Models of distributed memory computers, taking advantage of this description, were implemented with the prototype of the project. The approach was validated with two EDF codes, for which the simulations gave good results.},
  keywords={},
  doi={10.1109/SIMSYM.1996.492150},
  ISSN={1080-241X},
  month={April},}
@INPROCEEDINGS{495456,
  author={Garnatz, T. and Haack, U. and Sander, M. and Schroder-Preikschat, W.},
  booktitle={Proceedings of HICSS-29: 29th Hawaii International Conference on System Sciences}, 
  title={Experiences made with the design and development of a message-passing kernel for a dual-processor-node parallel computer}, 
  year={1996},
  volume={1},
  number={},
  pages={131-140 vol.1},
  abstract={This paper presents the experiences made with the design and implementation of the Peace message-passing kernel. Peace is the object-oriented parallel operating system developed for the Manna parallel computer. Manna is a dual-processor-node distributed-memory machine using crossbar technology for node interconnection. Performance figures of the Peace kernel configurations are presented and their implications with respect to communication latency hiding are discussed.},
  keywords={},
  doi={10.1109/HICSS.1996.495456},
  ISSN={},
  month={Jan},}
@INPROCEEDINGS{495476,
  author={Sarukkai, S.R. and Beers, A.},
  booktitle={Proceedings of HICSS-29: 29th Hawaii International Conference on System Sciences}, 
  title={Monitoring data-structure evolution in distributed message-passing programs}, 
  year={1996},
  volume={1},
  number={},
  pages={310-319 vol.1},
  abstract={Monitoring the evolution of data structures in parallel and distributed programs, is critical for debugging its semantics and performance. However, the current state-of-art in tracking and presenting data-structure information on parallel and distributed environments is cumbersome and does not scale. We present a methodology and tool that automatically tracks memory bindings (not the actual contents) of dynamic data-structures of message-passing C programs, and inter-processor data-structure movement, using PVM on distributed environments. With the help of a number of examples we show that in addition to determining the impact of memory allocation overheads on program performance, graphical views can help in debugging many memory access errors. Traditional debuggers in distributed environments rely on existing sequential debuggers on each machine and simply provide an interface for querying and controlling each processor's debugging session. However, to quickly locate the processor and to explain reasons for the error, we resort to run-time checking and trace based visualizations of memory access behavior across all processors. In an effort to reduce trace file size, only updates of pointer values and memory management functions are captured.},
  keywords={},
  doi={10.1109/HICSS.1996.495476},
  ISSN={},
  month={Jan},}
@INPROCEEDINGS{500570,
  author={Clematis, A. and Gianuzzi, V.},
  booktitle={Proceedings of 4th Euromicro Workshop on Parallel and Distributed Processing}, 
  title={CPVM-extending PVM for consistent checkpointing}, 
  year={1996},
  volume={},
  number={},
  pages={67-74},
  abstract={This paper presents CPVM, a library that provides the user with a support to implement non-blocking, global checkpoint-restart algorithms for applications written using PVM thereby achieving fault-tolerance. A salient feature of CPVM is the way in which, solely on the basis of a simple set of new PVM primitives, it provides several advanced facilities useful to solve different problems. CPVM can also be used as a platform to implement different algorithms to detect stable properties such as deadlocks and termination, and to support job-swapping and migration in an environment where there previously was none.},
  keywords={},
  doi={10.1109/EMPDP.1996.500570},
  ISSN={},
  month={Jan},}
@INPROCEEDINGS{500584,
  author={Kamkar, M. and Krajina, P. and Fritzson, P.},
  booktitle={Proceedings of 4th Euromicro Workshop on Parallel and Distributed Processing}, 
  title={Dynamic slicing of parallel message-passing programs}, 
  year={1996},
  volume={},
  number={},
  pages={170-177},
  abstract={As software applications grow larger and more complex, program maintenance activities such as adding new functionality, debugging and testing consume an increasing amount of available resources for software development. This is especially true for distributed systems communicating via message-passing. In order to cope with this increased complexity, programmers need effective computer-supported methods for decomposition and dependence analysis of programs, to understand dependencies between different parts of software systems and to find the sources of errors. Program slicing is one method for such decomposition and dependence analysis. A program slice with respect to a specified variable at some program point consists of those parts of the program which may directly or indirectly affect the value of that variable at the particular program point. In this paper, we present an algorithm for dynamic slicing of distributed/parallel programs and some results from an implementation for a parallel MIMD computer.},
  keywords={},
  doi={10.1109/EMPDP.1996.500584},
  ISSN={},
  month={Jan},}
@INPROCEEDINGS{500590,
  author={Miguel, J. and Arruabarrena, A. and Beivide, R. and Fortes, J.A.B.},
  booktitle={Proceedings of 4th Euromicro Workshop on Parallel and Distributed Processing}, 
  title={An empirical evaluation of techniques for parallel discrete-event simulation of interconnnection networks}, 
  year={1996},
  volume={},
  number={},
  pages={219-226},
  abstract={Three parallel discrete-event simulators-synchronous, conservative and optimistic-implemented on an Intel Paragon multicomputer are comparatively evaluated. Parallelism is achieved by model decomposition, distributing the simulation among a set of collaborative logical processes. The three simulators differ in the way those processes synchronize to obey causal restrictions in the simulation of events. Message passing network models are used to study these simulation alternatives. A set of experiments are carried out to understand how model parameters influence simulator performance. Experimental evidence leads to the conclusion that the optimistic simulator is not a viable tool for the analysis of this kind of models. The opposite conclusion applies to the other two: if the workload assigned to each logical process is above a certain threshold then the synchronization overhead is comparatively low and the simulators perform and scale well up to a large number of processors. The performance threshold is influenced by some parameters of the simulated model (size of the network, load level and message length), as well as by the number of processors used by the simulators.},
  keywords={},
  doi={10.1109/EMPDP.1996.500590},
  ISSN={},
  month={Jan},}
@INPROCEEDINGS{500581,
  author={Moure, J.C. and Franco, D. and Heymann, E. and Luque, E.},
  booktitle={Proceedings of 4th Euromicro Workshop on Parallel and Distributed Processing}, 
  title={TransCom: a communication microkernel for transputers}, 
  year={1996},
  volume={},
  number={},
  pages={147-153},
  abstract={If parallel computers have to become general purpose tools, it is necessary to develop services that make transparent its internal characteristics and make parallel programming easier. Trying to fulfil this goal and to have a platform for the test and evaluation of mechanisms for a parallel architecture, a microkernel called TransCom has been designed for a distributed-memory multiprocessor. The microkernel includes services to virtualise the communication network, which provides a parallel programming model based on message passing. It has been designed in two steps: a tiny system core called TransRouter providing simple functions for data transport and routing, but without protocol services, and a basic set of communication primitives, on top of the TransRouter and including its own communication protocols, to make up the TransCom. Concurrently with the development of the microkernel, some studies and simulations have been undertaken in order to virtualise the "processor resource" through the load distribution among the processors.},
  keywords={},
  doi={10.1109/EMPDP.1996.500581},
  ISSN={},
  month={Jan},}
@INPROCEEDINGS{500986,
  author={Heidelberger, P. and Nicol, D.},
  booktitle={Proceedings of MASCOTS '96 - 4th International Workshop on Modeling, Analysis and Simulation of Computer and Telecommunication Systems}, 
  title={Building parallel simulations from serial simulators}, 
  year={1996},
  volume={},
  number={},
  pages={2-4},
  abstract={In order for parallel discrete event simulation (PDES) to have practical impact, PDES tools must hide the complexities of time synchronisation from users and provide capabilities approaching those of industrial quality serial simulators. Typically, PDES tools have been started from scratch thereby requiring a modeler to learn a new and unfamiliar modeling tool. This note describes a parallel simulation tool, the Utilitarian Parallel Simulator, U.P.S. that is distinguished from the above mentioned tools in that it is built on top of an existing, industrial quality serial simulator, CSIM. U.P.S. extends the standard CSIM modeling language by providing a simple and natural mechanism for submodels running on different processors to communicate with one another. The user need not be concerned with time synchronisation, save for specifying which algorithm to use, nor need the user make calls to a low level interprocessor communications library (e.g. a message-passing library such as MPI). U.P.S. was implemented without making any changes to the existing CSIM simulation engine. As such, it implements conservative time synchronisation algorithms. As CSIM has been ported to many uniprocessor platforms, and since U.P.S. is implemented using the MPI standard, U.P.S. is potentially portable to many multiple processor systems. It has been tested and run on two such platforms: the IBM SP2 and the Intel Paragon.},
  keywords={},
  doi={10.1109/MASCOT.1996.500986},
  ISSN={},
  month={Feb},}
@INPROCEEDINGS{501015,
  author={Wylie, B.J.N. and Endo, A.},
  booktitle={Proceedings of MASCOTS '96 - 4th International Workshop on Modeling, Analysis and Simulation of Computer and Telecommunication Systems}, 
  title={The Annai/PMA performance monitor and analyzer}, 
  year={1996},
  volume={},
  number={},
  pages={186-191},
  abstract={The Annai integrated tool environment helps exploit the inherent power of distributed-memory parallel computers with standardized languages and convenient programming support. Portable application development is supported in High Performance Fortran and/or with explicit message-passing, using MPI as the machine interface. Integration within a unified tool environment allows the performance monitor and analyzer (PMA) component to interact with source code browsers and the loaded executable on the same terms as when using the parallel debugger. Data distribution and other program information furnished by the parallelization support and compilation systems is also exploited for additional insight. Powerful, directed analysis and interactive graphical summaries address scalability, while detailed charts of the time-varying behavior of individual processes and communication events can also be browsed when desired, always retaining essential reference to the original program source code.},
  keywords={},
  doi={10.1109/MASCOT.1996.501015},
  ISSN={},
  month={Feb},}
@ARTICLE{506695,
  author={Ge-Ming Chiu and Cheng-Ru Young},
  journal={IEEE Transactions on Parallel and Distributed Systems}, 
  title={Efficient rollback-recovery technique in distributed computing systems}, 
  year={1996},
  volume={7},
  number={6},
  pages={565-577},
  abstract={We propose an approach for implementing rollback recovery in a distributed computing system. A concept of logical ring is introduced for the maintenance of information required for consistent recovery from a system crash. Message processing order of a process is kept by all other processes on its logical ring. Transmission of data messages are accompanied by the circulation of the associated order messages on the ring. The sizes of the order messages are small. In addition, redundant transmission of order information is avoided, thereby reducing the communication overhead incurred during failure free operation. Furthermore, updating of the order information and garbage collection task are simplified in the proposed mechanism. Our approach does not require information about message processing order be written to stable storage; in fact, the time consuming operations of saving information in stable storage are confined to the checkpointing activities. When failures occur, a surviving process need roll back only if some preceding order information is totally lost, which is relatively unlikely considering the ever growing speed of communication networks. It is shown that a system can recover correctly as long as there exists at least one surviving process.},
  keywords={},
  doi={10.1109/71.506695},
  ISSN={1558-2183},
  month={June},}
@INPROCEEDINGS{508110,
  author={Rinard, M.C.},
  booktitle={Proceedings of International Conference on Parallel Processing}, 
  title={An integrated synchronization and consistency protocol for the implementation of a high-level parallel programming language}, 
  year={1996},
  volume={},
  number={},
  pages={549-553},
  abstract={This paper presents experimental results that characterize the performance of the integrated synchronization and consistency protocol used in the implementation of Jade, an implicitly parallel language for coarse-grain parallel computation. The consistency protocol tags each replica of shared data with a version number. The synchronization algorithm computes the correct version numbers of the replicas of shared data that the computation will access. Because the protocol piggybacks the version number information on the synchronization messages, it generates fewer messages than standard update and invalidate protocols. This paper characterizes the performance impact of the consistency protocol by presenting experimental results for several Jade applications running on the iPSC/860 under several different Jade implementations.},
  keywords={},
  doi={10.1109/IPPS.1996.508110},
  ISSN={},
  month={April},}
@INPROCEEDINGS{507908,
  author={Kanthadai, S. and Welch, J.L.},
  booktitle={Proceedings of 16th International Conference on Distributed Computing Systems}, 
  title={Implementation of recoverable distributed shared memory by logging writes}, 
  year={1996},
  volume={},
  number={},
  pages={116-123},
  abstract={Distributed shared memory, by avoiding the programming complexities of message passing, has become a convenient model to work with. But the benefits given by these systems can possibly be achieved only if the whole system behaves like a failure-free system. Many algorithms that have been proposed for implementing a reliable DSM require the processes to take check points whenever there is a data transfer, thus resulting in a heavy overhead during failure-free execution. We present an algorithm to provide recoverable DSM for sequential consistency where the checkpoint interval can be tailored to balance the cost of checkpointing versus the savings in recovery obtained by taking check points often. Unlike previous recovery techniques that use logging, both the logging and the message overheads are reduced. It can tolerate up to n faults, where n is the number of processes, and can be used in an environment where the cost of synchronizing the checkpoints is substantially high.},
  keywords={},
  doi={10.1109/ICDCS.1996.507908},
  ISSN={},
  month={May},}
@INPROCEEDINGS{508154,
  author={Cong Fu and Tao Yang},
  booktitle={Proceedings of International Conference on Parallel Processing}, 
  title={Efficient run-time support for irregular task computations with mixed granularities}, 
  year={1996},
  volume={},
  number={},
  pages={823-830},
  abstract={Many irregular scientific computing problems can be modeled by directed acyclic task graphs (DAGs). We present an efficient run-time system for executing general asynchronous DAG schedules on distributed memory machines. Our solution tightly integrates the run-time scheme with a fast communication mechanism to eliminate unnecessary overhead in message buffering and copying, and takes advantage of task dependence properties to ensure the correctness of execution. We demonstrate the applications of this scheme in sparse LU and Cholesky factorizations for which actual speedups have been hard to obtain in the literature because parallelism in these problems is irregular and limited. Our experiments on Meiko CS-2 show the promising results of our approach in exploiting irregular task parallelism with mixed granularities.},
  keywords={},
  doi={10.1109/IPPS.1996.508154},
  ISSN={},
  month={April},}
@INPROCEEDINGS{508061,
  author={Arabe, J.N.C. and Beguelin, A. and Lowekamp, B. and Seligman, E. and Starkey, M. and Stephan, P.},
  booktitle={Proceedings of International Conference on Parallel Processing}, 
  title={Dome: parallel programming in a distributed computing environment}, 
  year={1996},
  volume={},
  number={},
  pages={218-224},
  abstract={The Distributed object migration environment (Dome) addresses three major issues of distributed parallel programming: ease of use, load balancing, and fault tolerance. Dome provides process control, data distribution, communication, and synchronization for Dome programs running in a heterogeneous distributed computing environment. The parallel programmer writes a C++ program using Dome objects which are automatically partitioned and distributed over a network of computers. Dome incorporates a load balancing facility that automatically adjusts the mapping of objects to machines at runtime, exhibiting significant performance gains over standard message passing programs executing in an imbalanced system. Dome also provides checkpointing of program state in an architecture independent manner allowing Dome programs to be checkpointed on one architecture and restarted on another.},
  keywords={},
  doi={10.1109/IPPS.1996.508061},
  ISSN={},
  month={April},}
@INPROCEEDINGS{508066,
  author={Abandah, G.A. and Davidson, E.S.},
  booktitle={Proceedings of International Conference on Parallel Processing}, 
  title={Modeling the communication performance of the IBM SP2}, 
  year={1996},
  volume={},
  number={},
  pages={249-257},
  abstract={The objective of this paper is to develop models that characterize the communication performance of a message-passing multicomputer by taking the IBM SP2 as a case study. The paper evaluates and models the three aspects of the communication performance: scheduling overhead, message-passing time, and synchronization overhead. Performance models are developed for the basic communication patterns, enabling the estimation of the communication times of a message-passing application. Such estimates facilitate activities such as application tuning, selection of the best available implementation technique, and performance comparisons among different multicomputers.},
  keywords={},
  doi={10.1109/IPPS.1996.508066},
  ISSN={},
  month={April},}
@INPROCEEDINGS{507882,
  author={Moller, F.},
  booktitle={Proceedings of 11th Annual Conference on Computer Assurance. COMPASS '96}, 
  title={The specification of an asynchronous router}, 
  year={1996},
  volume={},
  number={},
  pages={142-148},
  abstract={We describe the application of three formal design tools to a case study in the design of a distributed system. The case study in question involves the specification of an asynchronous message router; the three design tools are process algebra (specifically Milner's Calculus of Communicating Systems CCS), the modal /spl mu/ calculus and the Edinburgh Concurrency Workbench (CWB). We demonstrate how an informally presented specification can be formalised within the language of the modal /spl mu/ calculus, allowing for a rigorous mathematical analysis of the correctness of our proposed implementation. For modest sized versions of the router, this correctness proof has been carried out using the CWB.},
  keywords={},
  doi={10.1109/CMPASS.1996.507882},
  ISSN={},
  month={June},}
@INPROCEEDINGS{508004,
  author={Romanovsky, A. and Jie Xu and Randell, B.},
  booktitle={Proceedings of 16th International Conference on Distributed Computing Systems}, 
  title={Exception handling and resolution in distributed object-oriented systems}, 
  year={1996},
  volume={},
  number={},
  pages={545-552},
  abstract={We address the problem of how to handle exceptions in distributed object-oriented systems. In a distributed computing environment exceptions may be raised simultaneously and thus need to be treated in a coordinated manner. We take two kinds of concurrency into account: 1) several objects are designed collectively and invoked concurrently to achieve a global goal, and 2) concurrent objects or object groups that are designed independently compete for the same system resources. We propose a new distributed algorithm for resolving concurrent exceptions and show that the algorithm works correctly even in complex nested situations, and is an improvement over previous proposals in that it requires only O(N/sup 2/) messages, and is fully object-oriented.},
  keywords={},
  doi={10.1109/ICDCS.1996.508004},
  ISSN={},
  month={May},}
@INPROCEEDINGS{508106,
  author={Stellner, G.},
  booktitle={Proceedings of International Conference on Parallel Processing}, 
  title={CoCheck: checkpointing and process migration for MPI}, 
  year={1996},
  volume={},
  number={},
  pages={526-531},
  abstract={Checkpointing of parallel applications can be used as the core technology to provide process migration. Both checkpointing and migration, are an important issue for parallel applications on networks of workstations. The CoCheck environment which we present in this paper introduces a new approach to provide checkpointing and migration for parallel applications. CoCheck sits on top of the message passing library and achieves consistency at a level above the message passing system. It uses an existing single process checkpointer which is available for a wide range of systems. Hence, CoCheck can be easily adapted to both, different message passing systems and new machines.},
  keywords={},
  doi={10.1109/IPPS.1996.508106},
  ISSN={},
  month={April},}
@INPROCEEDINGS{508190,
  author={Dowd, P.W. and Carrozzi, T.M. and Pellegrino, F.A. and Xin Chen, A.},
  booktitle={Proceedings of International Conference on Parallel Processing}, 
  title={Native ATM application programmer interface testbed for cluster-based computing}, 
  year={1996},
  volume={},
  number={},
  pages={843-849},
  abstract={This paper investigates the use of ATM for cluster based computing. The need for a native ATM API is discussed as well as the performance of message passing libraries (MPL) that are written to use such an API to exploit the advantages of a high-speed network for cluster-based computing. The MPLs offer a standard interface, such as PVM or MPI, and interoperate with existing TCP/IP and UDP/IP based versions in addition to the ATM API environment. The interoperability extensions made to two MPLs, MPI and Prowess, are described with a hybrid environment of both ATM and TCP-based legacy network technology. The native ATM API is described in this paper which supports cluster based computing that may be geographically distributed. Furthermore, this API provides a reliable transport interface to the MPL which has been optimized for an ATM environment. The transport protocol is a low-state design that optimizes the performance based on the available bandwidth, buffer constraints, propagation delay characteristics, and security requirements of a particular connection, and will rapidly evolve if the connection characteristics change.},
  keywords={},
  doi={10.1109/IPPS.1996.508190},
  ISSN={},
  month={April},}
@INPROCEEDINGS{509529,
  author={Balakrishnan, S. and Ozguner, F.},
  booktitle={Proceedings Real-Time Technology and Applications}, 
  title={Providing message delivery guarantees in pipelined flit-buffered multiprocessor networks}, 
  year={1996},
  volume={},
  number={},
  pages={120-129},
  abstract={Real-time applications when mapped to distributed memory multiprocessors produce periodic messages with an associated deadline and priority. Real-time extensions to wormhole routing (WR) with multiple virtual channels (VCs), suffer from unbounded priority inversion, rendering the global priority order ineffective. We propose a new flow control mechanism called Preemptive Pipelined Circuit Switching for Real-Time messages (PPCS-RT). To bound the priority inversion, we extend the model to PPCS-RTph, with preemption history stack for each VC. For the PPCS-RTph model, we describe a simple feasibility test and validate the test through flit level simulations. To improve the percentage of feasible messages, and average link utilization of the feasible message set, we also evaluate an enhanced PPCS-RTph model with additional architectural features.},
  keywords={},
  doi={10.1109/RTTAS.1996.509529},
  ISSN={},
  month={June},}
@INPROCEEDINGS{508990,
  author={Asogawa, M.},
  booktitle={Proceedings Second International Symposium on Parallel Architectures, Algorithms, and Networks (I-SPAN'96)}, 
  title={Parallel tertiary structure search on the Cenju-S parallel machine}, 
  year={1996},
  volume={},
  number={},
  pages={256-261},
  abstract={The author parallelized a tertiary structure search algorithm on a distributed memory parallel computer, Cenju-S, utilizing a standard message passing interface (MPI) parallel library. For parallelization scheme, a master-workers model is used. The author analyzed the total performance by utilizing a M/M/1 queueing model and Jackson's model, and clearly explained the actual turn around times. Tertiary structure search is a computationally intensive task. When test sequences are distributed to all processors, a single key sequence can be tested independently. Thus high parallelization results are anticipated. Since database is allocated on a master processor, worker processors should acquire test sequences from the master processor. Sometimes a worker should wait until other workers obtain test sequences from the master processor. By this waiting, the total performance will saturate when the number of processors proceeds certain level.},
  keywords={},
  doi={10.1109/ISPAN.1996.508990},
  ISSN={1087-4089},
  month={June},}
@INPROCEEDINGS{509039,
  author={Xiong Jianxin and Wang Dingxing},
  booktitle={Proceedings Second International Symposium on Parallel Architectures, Algorithms, and Networks (I-SPAN'96)}, 
  title={Analyzing nondeterminacy of message passing programs}, 
  year={1996},
  volume={},
  number={},
  pages={547-549},
  abstract={Nondeterminacy is an important issue of testing and debugging parallel programs. For a message passing program the inter-process communication is the main cause of nondeterminacy. From a event-based view, the execution of a message passing parallel program can be modeled as partially ordered set of events. The nondeterminacy is reflected in the partially ordered set. In this paper, we present a method to analyze the messagewise nondeterminacy of a message passing program based on the execution trace which preserves the partial order relations.},
  keywords={},
  doi={10.1109/ISPAN.1996.509039},
  ISSN={1087-4089},
  month={June},}
@INPROCEEDINGS{509041,
  author={Rong Zeng and Xiang Jun Dong and Ming Fa Zhu},
  booktitle={Proceedings Second International Symposium on Parallel Architectures, Algorithms, and Networks (I-SPAN'96)}, 
  title={Wormhole routing and its chip design}, 
  year={1996},
  volume={},
  number={},
  pages={553-555},
  abstract={Wormhole routing is a key technique in the design of Dawning 1000 which is the first MPP system made in China. In this paper, wormhole routing is introduced, and an algorithm based on wormhole routing, a chip architecture and its logic design are also described. Finally, an interconnection constructed by the wormhole routing chips is put forward for Dawning 1000 which indicates this kind of chip has a correct function and fast rate with reliability.},
  keywords={},
  doi={10.1109/ISPAN.1996.509041},
  ISSN={1087-4089},
  month={June},}
@INPROCEEDINGS{517591,
  author={Wentong Cai and Hang, A. and Varman, P.},
  booktitle={Proceedings of 1996 International Conference on Parallel and Distributed Systems}, 
  title={Benchmarking IBM SP1 system for SPMD programming}, 
  year={1996},
  volume={},
  number={},
  pages={430-437},
  abstract={The IBM SP1 is the first member of the IBM Scalable POWERparallel series, a distributed memory parallel computer based on RISC System/6000 processing element. In this paper, the benchmarking exercise of two message passing libraries, MPL and PVM, on the IBM SP1 for SPMD programming is described. We will discuss the benchmarks used in our experiment, and present the results we obtained. Our results indicate that to achieve performance improvement and to reduce the communication overhead, the use of the high performance switch is essential on the IBM SP1 machine.},
  keywords={},
  doi={10.1109/ICPADS.1996.517591},
  ISSN={},
  month={June},}
@INPROCEEDINGS{517592,
  author={Tanaka, K. and Takizawa, M.},
  booktitle={Proceedings of 1996 International Conference on Parallel and Distributed Systems}, 
  title={Distributed checkpointing based on influential messages}, 
  year={1996},
  volume={},
  number={},
  pages={440-447},
  abstract={In distributed applications, a group of multiple objects are cooperated to achieve some objectives. The computation on the objects are based on the massage passing, i.e. remote procedure call. The objects may suffer from different kinds of faults. In the presence of the object faults, the states of the objects in the system have to be kept consistent. If some object o is faulty, o is rolled back to the checkpoint and objects which have received messages from o are also required to be rolled back. In this paper, we define influential messages whose receivers are required to be rolled back from the application point of view if the senders are rolled back on the basis of the message semantics. By using the influential messages, we would like to define a significant checkpoint which denotes a consistent global state of the system but might be inconsistent from the traditional definition. We would like to present protocols for taking the significant checkpoint and for rolling back the objects by using the influential messages.},
  keywords={},
  doi={10.1109/ICPADS.1996.517592},
  ISSN={},
  month={June},}
@INPROCEEDINGS{534108,
  author={Chul-Eui Hong and Bum-Sik Lee and Gi-Won On and Dong-Hae Chi},
  booktitle={Proceedings. Second MPI Developer's Conference}, 
  title={Replay for debugging MPI parallel programs}, 
  year={1996},
  volume={},
  number={},
  pages={156-160},
  abstract={The cyclic debugging approach often fails for parallel programs because parallel programs reveal nondeterministic characteristics due to message race conditions. This paper addresses the execution replay algorithm for debugging MPI parallel programs. The lexical analyzer identifies the MPI events which affect nondeterministic executions, and then an execution is controlled in order to make it equivalent to a reference execution by keeping their orders of events in two executions identical. The proposed replay system uses the logical time stamping algorithm and the derived data types provided by MPI standard. It also presents the method of how to replay the blocking and nonblocking message passing events. The proposed replay system was applied to the bitonic-merge sort and other parallel programs. We found that re-execution has reproducible behavior and the replay system is useful to find the communication errors.},
  keywords={},
  doi={10.1109/MPIDC.1996.534108},
  ISSN={},
  month={July},}
@INPROCEEDINGS{534111,
  author={McMahon, T.P. and Skjellum, A.},
  booktitle={Proceedings. Second MPI Developer's Conference}, 
  title={eMPI/eMPICH: embedding MPI}, 
  year={1996},
  volume={},
  number={},
  pages={180-184},
  abstract={This paper discusses efforts toward providing embeddable versions of MPI for use in memory-constrained systems. Two design paradigms were followed: top-down, which removed certain functionality from a full MPI implementation, and bottom-up, which began with a six function MPI implementation and added functionality to create a sequence of embeddable libraries. A comparison between these two approaches is presented along with a discussion of more hardware-specific issues.},
  keywords={},
  doi={10.1109/MPIDC.1996.534111},
  ISSN={},
  month={July},}
@INPROCEEDINGS{534109,
  author={Markus, S. and Kim, S.B. and Pantazopoulos, K. and Ocken, A.L. and Houstis, E.N. and Wu, P. and Weerawarana, S. and Maharry, D.},
  booktitle={Proceedings. Second MPI Developer's Conference}, 
  title={Performance evaluation of MPI implementations and MPI based Parallel ELLPACK solvers}, 
  year={1996},
  volume={},
  number={},
  pages={162-169},
  abstract={We are concerned with the parallelization of finite element mesh generation and its decomposition, and the parallel solution of sparse algebraic equations which are obtained from the parallel discretization of second order elliptic partial differential equations (PDEs) using finite difference and finite element techniques. For this we use the Parallel ELLPACK (//ELLPACK) problem solving environment (PSE) which supports PDE computations on several MIMD platforms. We have considered the ITPACK library of stationary iterative solvers which we have parallelized and integrated into the //ELLPACK PSE. This Parallel ITPACK package has been implemented using the MPI, PVM, PICL, PARMACS, nCUBE Vertex and Intel NX message passing communication libraries. It performs very efficiently on a variety of hardware and communication platforms. To study the efficiency of three MPI library implementations, the performance of the Parallel ITPACK solvers was measured on several distributed memory architectures and on clusters of workstations for a testbed of elliptic boundary value PDE problems. We present a comparison of these MPI library implementations with PVM and the native communication libraries, based on their performance on these tests. Moreover we have implemented in MPI, a parallel mesh generator that concurrently produces a semi-optimal partitioning of the mesh to support various domain decomposition solution strategies across the above platforms.},
  keywords={},
  doi={10.1109/MPIDC.1996.534109},
  ISSN={},
  month={July},}
@INPROCEEDINGS{534114,
  author={Deshpande, V. and Sawyer, W. and Walker, D.W.},
  booktitle={Proceedings. Second MPI Developer's Conference}, 
  title={An MPI implementation of the BLACS}, 
  year={1996},
  volume={},
  number={},
  pages={195-198},
  abstract={An MPI implementation of the Basic Linear Communication Subprograms (BLACS) is presented. A wide spectrum of MPI functionality has been used to implement BLACS as succinctly as possible, thus making the implementation concise, but still yielding good performance. We discuss some of the implementation details and present performance results for several parallel architectures with different MPI libraries. Finally we gather our experiences in using MPI, and make some suggestions for the future functionality.},
  keywords={},
  doi={10.1109/MPIDC.1996.534114},
  ISSN={},
  month={July},}
@INPROCEEDINGS{534115,
  author={Frost, R.},
  booktitle={Proceedings. Second MPI Developer's Conference}, 
  title={MPICH performance characteristics and considerations}, 
  year={1996},
  volume={},
  number={},
  pages={199-202},
  abstract={A study of the Argonne National Laboratory/Mississippi State University "MPICH" implementation of MPI is presented. The performance of point-to-point communications on clusters, MPPs, networks of workstations, and SMPs is given. Performance strategies for a range of application and architecture characteristics are discussed. Experiences installing MPICH on these architectures are also discussed.},
  keywords={},
  doi={10.1109/MPIDC.1996.534115},
  ISSN={},
  month={July},}
@INPROCEEDINGS{534100,
  author={Kale, R.P. and Fleharty, M.E. and Alsing, P.M.},
  booktitle={Proceedings. Second MPI Developer's Conference}, 
  title={Parallel molecular dynamics visualization using MPI with MPE graphics}, 
  year={1996},
  volume={},
  number={},
  pages={104-110},
  abstract={Presents an MPI (Message Passing Interface) implementation of a molecular dynamics (MD) simulation using force decomposition as a parallelization strategy. In contrast to atom decomposition and spatial decomposition techniques, this method affords ease of load balancing and performs well for an intermediate number of atoms, even for irregular geometries. The interactions between the atoms are calculated in a separate module. Periodic boundary conditions are used to simulate an infinitely replicated confined region in space. The main thrust of our research efforts is currently directed towards in situ visualization of the MD simulations. This is accomplished using simple X-Windows calls available through the MPE (MPI Extensions) extension to the MPI routines. Our implementation using MPI with MPE graphics makes the algorithm portable. The code has been tested on a range of platforms, including clusters of workstations as well as the the IBM SP2 at the Maul High-Performance Supercomputing Center (MHPCC) and the IBM SP1 at the Albuquerque Resource Center of the University of New Mexico. We have also adapted our code to interact with a high-end graphics computer (SGI Onyx) using the OpenGL graphics library, which allows for real-time manipulation of 3D objects. The communication between the MD simulation and the graphics renderer was achieved with the use of sockets. The use of sockets allows the parallel MD simulation to run independently of the application used for graphics rendering.},
  keywords={},
  doi={10.1109/MPIDC.1996.534100},
  ISSN={},
  month={July},}
@INPROCEEDINGS{534112,
  author={Govindan, V. and Park, Y. and Li, X. and Crear, S. and Johnson, O.},
  booktitle={Proceedings. Second MPI Developer's Conference}, 
  title={An overview of a MPI profiling environment for the NEC Cenju-3}, 
  year={1996},
  volume={},
  number={},
  pages={185-188},
  abstract={This paper describes an ongoing effort to provide a profiling environment for MPI applications running on the NEC Cenju-3, an MPP research prototype. Highlights of these efforts include automatic management of dynamic trace buffers, efficient post-processing, and user-driven visualization support. Modern virtual memory support found in the Cenju-3 operating system provides automatic management of dynamic trace buffers. Parallelization provides post-processing efficiency. Researchers from an NSF Grand Challenge Application Group are guiding the development of the visualization tool.},
  keywords={},
  doi={10.1109/MPIDC.1996.534112},
  ISSN={},
  month={July},}
@INPROCEEDINGS{534110,
  author={Worley, P.H.},
  booktitle={Proceedings. Second MPI Developer's Conference}, 
  title={MPI performance evaluation and characterization using a compact application benchmark code}, 
  year={1996},
  volume={},
  number={},
  pages={170-177},
  abstract={In this paper the parallel benchmark code PSTSWM is used to evaluate the performance of the vendor-supplied implementations of the MPI message-passing standard on the Intel Paragon, IBM SP2, and Cray Research T3D. This study is meant to complement the performance evaluation of individual MPI commands by providing information on the practical significance of MPI performance on the execution of a communication-intensive application code. In particular three performance questions are addressed: how important is the communication protocol in determining performance when using MPI, how does MPI performance compare with that of the native communication library, and how efficient are the collective communication routines.},
  keywords={},
  doi={10.1109/MPIDC.1996.534110},
  ISSN={},
  month={July},}
@INPROCEEDINGS{534097,
  author={Kafura, D. and Huang, L.},
  booktitle={Proceedings. Second MPI Developer's Conference}, 
  title={Collective communication and communicators in mpi++}, 
  year={1996},
  volume={},
  number={},
  pages={79-86},
  abstract={The paper describes the current version of mpi++, a C++ language binding for MPI, that includes all of the collective services, and services for contexts, groups and communicators as described in Chapter 4 and 5 of the MPI standard. The code for mpi++ has been tested on a Sun Sparc workstation and an Intel Paragon. Segments of a mpi++ program implementing a parallel algorithm is introduced to illustrate the Collective class hierarchy. The paper also shows how mpi++ deals with other collective operations (e.g., reduction), attribute caching, groups,and communicators. The class hierarchy of mpi++ is presented and briefly explained.},
  keywords={},
  doi={10.1109/MPIDC.1996.534097},
  ISSN={},
  month={July},}
@INPROCEEDINGS{534116,
  author={Loos, T. and Bramley, R.},
  booktitle={Proceedings. Second MPI Developer's Conference}, 
  title={MPI performance on the SGI Power Challenge}, 
  year={1996},
  volume={},
  number={},
  pages={203-206},
  abstract={The widely implemented MPI standard defines primitives for point-to-point and collective inter-processor communication (IPC), and synchronization based on message passing. The main reason to use a message passing standard is to ease the development, porting, and execution of applications on the variety of parallel computers that can support the paradigm, including shared memory, distributed memory, and shared memory array multiprocessors. The paper concentrates on the SGI Power Challenge, a shared memory multiprocessor with comparison results provided for the distributed memory Intel Paragon. Memory and communications tests written in C++ using messages of double precision arrays show both memory and MPI blocking IPC performance on the Power Challenge degrade once total message sizes grow larger than the second level cache. Comparing the MPI and memory performance curves indicate Power Challenge native MPI point-to-point communication is implemented using memory copying. A model of blocking IPC for the SGI Power Challenge was developed and validated with performance results for use as part of a cost function in a graph partitioning algorithm. A new measure of communications efficiency and overhead, the ratio of IPC time to memory copy time, is used to compare relative IPC performance. Comparison between the Power Challenge and the Paragon show that the Paragon is more efficient for small messages, but the Power Challenge is better on large messages. Power Challenge observations do not correspond well with Paragon results, indicating shared memory multiprocessor results should not be used to predict distributed memory multiprocessor performance. This suggests that relative performance of parallel algorithms should not judged based on one type of machine.},
  keywords={},
  doi={10.1109/MPIDC.1996.534116},
  ISSN={},
  month={July},}
@INPROCEEDINGS{534089,
  author={Foster, I. and Geisler, J. and Tuecke, S.},
  booktitle={Proceedings. Second MPI Developer's Conference}, 
  title={MPI on the I-WAY: a wide-area, multimethod implementation of the Message Passing Interface}, 
  year={1996},
  volume={},
  number={},
  pages={10-17},
  abstract={High-speed wide-area networks enable innovative applications that integrate geographically distributed computing, database, graphics, and networking resources. The Message Passing Interface (MPI) can be used as a portable, high-performance programming model for such systems. However, the wide-area environment introduces challenging problems for the MPI implementor, because of the heterogeneity of both the underlying physical infrastructure and the authentication and software environment at different sites. We describe an MPI implementation that incorporates solutions to these problems. This implementation, which was developed for the I-WAY distributed-computing experiment, was constructed by layering MPICH on the Nexus multithreaded runtime system. Nexus provides automatic configuration mechanisms that can be used to select and configure authentication, process creation, and communication mechanisms in heterogeneous systems.},
  keywords={},
  doi={10.1109/MPIDC.1996.534089},
  ISSN={},
  month={July},}
@ARTICLE{536935,
  author={van Reeuwijk, K. and Denissen, W. and Sips, H.J. and Paalvast, E.M.R.M.},
  journal={IEEE Transactions on Parallel and Distributed Systems}, 
  title={An implementation framework for HPF distributed arrays on message-passing parallel computer systems}, 
  year={1996},
  volume={7},
  number={9},
  pages={897-914},
  abstract={Data parallel languages, like High Performance Fortran (HPF), support the notion of distributed arrays. However, the implementation of such distributed array structures and their access on message passing computers is not straightforward. This holds especially for distributed arrays that are aligned to each other and given a block-cyclic distribution. In this paper, an implementation framework is presented for HPF distributed arrays on message passing computers. Methods are presented for efficient (in space and time) local index enumeration, local storage, and communication. Techniques for local set enumeration provide the basis for constructing local iteration sets and communication sets. It is shown that both local set enumeration and local storage schemes can be derived from the same equation. Local set enumeration and local storage schemes are shown to be orthogonal, i.e., they can be freely combined. Moreover, for linear access sequences generated by our enumeration methods, the local address calculations can be moved out of the enumeration loop, yielding efficient local memory address generation. The local set enumeration methods are implemented by using a relatively simple general transformation rule for absorbing ownership tests. This transformation rule can be repeatedly applied to absorb multiple ownership tests. Performance figures are presented for local iteration overhead, a simple communication pattern, and storage efficiency.},
  keywords={},
  doi={10.1109/71.536935},
  ISSN={1558-2183},
  month={Sep.},}
@ARTICLE{537304,
  author={Tong-Yee Lee and Raghavendra, C.S. and Nicholas, J.B.},
  journal={IEEE Transactions on Visualization and Computer Graphics}, 
  title={Image composition schemes for sort-last polygon rendering on 2D mesh multicomputers}, 
  year={1996},
  volume={2},
  number={3},
  pages={202-217},
  abstract={In a sort-last polygon rendering system, the efficiency of image composition is very important for achieving fast rendering. In this paper, the implementation of a sort-last rendering system on a general purpose multicomputer system is described. A two-phase sort-last-full image composition scheme is described first, and then many variants of it are presented for 2D mesh message-passing multicomputers, such as the Intel Delta and Paragon. All the proposed schemes are analyzed and experimentally evaluated on Caltech's Intel Delta machine for our sort-last parallel polygon renderer. Experimental results show that sort-last-sparse strategies are better suited than sort-last-full schemes for software implementation on a general purpose multicomputer system. Further, interleaved composition regions perform better than coherent regions. In a large multicomputer system. Performance can be improved by carefully scheduling the tasks of rendering and communication. Using 512 processors to render our test scenes, the peak rendering rate achieved on a 282,144 triangle dataset is dose to 4.6 million triangles per second which is comparable to the speed of current state-of-the-art graphics workstations.},
  keywords={},
  doi={10.1109/2945.537304},
  ISSN={1941-0506},
  month={Sep.},}
@INPROCEEDINGS{538597,
  author={JaJa},
  booktitle={1996 Proceedings ICPP Workshop on Challenges for Parallel Processing}, 
  title={On combining technology and theory in search of a parallel computation model}, 
  year={1996},
  volume={},
  number={},
  pages={115-123},
  abstract={A fundamental problem in parallel computing is to design high-level, architecture independent, algorithms that execute efficiently on general purpose parallel machines. The aim is to be able to achieve portability and high performance simultaneously. A key to accomplishing this is the existence of a computation model that can bridge the gap between the high level programming models and the underlying hardware models. There are currently two factors that make this fundamental problem more tractable. The first is the emergence of a dominant parallel architecture consisting of a number of powerful microprocessors interconnected by either a proprietary interconnect, or a standard off-the-shelf interconnect (such as an ATM switch). The second factor is the emergence of standards, such as the message passing standard MPI, for which efficient implementations are either available or about to appear on most machines. Our recent work has exploited these two developments by developing a methodology based on (1) a simple computation model for the current MIMD platforms that incorporates communication cost into the complexity of the algorithms, and (2) a SPMD programming model that makes effective use of communication primitives. We describe our approach for validating the computation model based on extensive experimentation and the development of benchmarks, and discuss its extension to the emerging clusters of Symmetric Multiprocessors (SMPs) architecture.},
  keywords={},
  doi={10.1109/ICPPW.1996.538597},
  ISSN={1530-2016},
  month={Aug},}
@ARTICLE{542297,
  author={Fidge, C.},
  journal={IEEE Software}, 
  title={Fundamentals of distributed system observation}, 
  year={1996},
  volume={13},
  number={6},
  pages={77-83},
  abstract={It's difficult to determine event order in distributed systems because of the observability problem. The author discusses this problem and evaluates different strategies for determining arrival order. The author analyzed four time stamping methods to determine their effectiveness in contending with observability problems. Although he focuses on distributed systems, the concepts also apply to any system exhibiting concurrency-the appearance of two or more events occurring simultaneously-including multiprocessor machines and uniprocessor multitasking. Events in this context may be the execution of single machine instructions or entire procedures; the level of granularity is unimportant. To define event order, the author uses the idea of causality-the ability of one event to affect another-because it allows us to reason independent of any particular time frame.},
  keywords={},
  doi={10.1109/52.542297},
  ISSN={1937-4194},
  month={Nov},}
@ARTICLE{544433,
  author={Hedberg, Sara},
  journal={IEEE Parallel & Distributed Technology: Systems & Applications}, 
  title={Industry spotlight: Personal privacy: An endangered species in the information age?}, 
  year={1996},
  volume={4},
  number={4},
  pages={4-7},
  abstract={The recent Lexis-Nexis flap made me curious about my own digital privacy. For those of you who haven't heard about this hullabaloo, in mid-September there was a flurry of angry email messages flying around the Internet discussing the news that personal information about you could be purchased from the company by just about anyone with a credit card. Many were outraged at the loss of their privacy, and Lexis-Nexis was flooded with requests from netizens demanding removal of their personal data from the database.},
  keywords={},
  doi={10.1109/88.544433},
  ISSN={1558-1861},
  month={Winter},}
@ARTICLE{546611,
  author={Adve, S.V. and Gharachorloo, K.},
  journal={Computer}, 
  title={Shared memory consistency models: a tutorial}, 
  year={1996},
  volume={29},
  number={12},
  pages={66-76},
  abstract={The memory consistency model of a system affects performance, programmability, and portability. We aim to describe memory consistency models in a way that most computer professionals would understand. This is important if the performance-enhancing features being incorporated by system designers are to be correctly and widely used by programmers. Our focus is consistency models proposed for hardware-based shared memory systems. Most of these models emphasize the system optimizations they support, and we retain this system-centric emphasis. We also describe an alternative, programmer-centric view of relaxed consistency models that describes them in terms of program behavior, not system optimizations.},
  keywords={},
  doi={10.1109/2.546611},
  ISSN={1558-0814},
  month={Dec},}
@INPROCEEDINGS{561320,
  author={Alur, R. and Henzinger, T.A.},
  booktitle={Proceedings 11th Annual IEEE Symposium on Logic in Computer Science}, 
  title={Reactive modules}, 
  year={1996},
  volume={},
  number={},
  pages={207-218},
  abstract={We present a formal model for concurrent systems. The model represents synchronous and asynchronous components in a uniform framework that supports compositional (assume-guarantee) and hierarchical (stepwise refinement) reasoning. While synchronous models are based on a notion of atomic computation step, and asynchronous models remove that notion by introducing stuttering, our model is based on a flexible notion of what constitutes a computation step: by applying an abstraction operator to a system, arbitrarily many consecutive steps can be collapsed into a single step. The abstraction operator, which may turn an asynchronous system into a synchronous one, allows us to describe systems at various levels of temporal detail. For describing systems at various levels of spatial detail, we use a hiding operator that may turn a synchronous system into an asynchronous one. We illustrate the model with diverse examples from synchronous circuits, asynchronous shared-memory programs, and synchronous message passing.},
  keywords={},
  doi={10.1109/LICS.1996.561320},
  ISSN={1043-6871},
  month={July},}
@INPROCEEDINGS{562884,
  author={Jinsong Ouyang and Maheshwari, P.},
  booktitle={Proceedings of 1996 IEEE Second International Conference on Algorithms and Architectures for Parallel Processing, ICA/sup 3/PP '96}, 
  title={Architecture and implementation of Libra-a library for reliable distributed applications}, 
  year={1996},
  volume={},
  number={},
  pages={263-270},
  abstract={This paper describes the architecture and implementation of Libra, a library for implementing efficient reliable distributed applications. Libra is designed to provide fault-tolerance transparency and a simple easy to use high-level message passing interface so that the development of reliable distributed applications can be significantly simplified. Fault-tolerance is based on distributed consistent checkpointing and rollback-recovery integrated with a user-level network communication protocol. By employing novel mechanisms, Libra minimises communication overhead for taking a consistent distributed checkpoint and catching messages in transit. With efficient implementation techniques, the prototype of Libra has been implemented on a network of Sun workstations and supports reliable distributed computing at low run-time cost. The simplicity and efficiency of Libra make it a promising approach to construct reliable distributed applications.},
  keywords={},
  doi={10.1109/ICAPP.1996.562884},
  ISSN={},
  month={June},}
@INPROCEEDINGS{565836,
  author={Bhalla, S. and Sreenivas, M.V.},
  booktitle={Proceedings of 3rd International Conference on High Performance Computing (HiPC)}, 
  title={Independent node and process recovery in message passing distributed systems}, 
  year={1996},
  volume={},
  number={},
  pages={283-288},
  abstract={Consistent recovery from process failures is an essential component of reliable distributed systems. Many existing recovery techniques use asynchronous message logging and checkpoints. Most of the present approaches depend on logged states of non-fail processes for recovery. A model of recovery based on the current active states of processes has been proposed. The algorithm considers recoverable state of the failed process and current states of the non-failed processes. Each process recovers to a consistent system state independently.},
  keywords={},
  doi={10.1109/HIPC.1996.565836},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{565796,
  author={Muthukrishnan, P.K. and Bryant, B.R. and Zwarico, A.E.},
  booktitle={Proceedings of 3rd International Conference on High Performance Computing (HiPC)}, 
  title={Compiling object-oriented programs for distributed execution}, 
  year={1996},
  volume={},
  number={},
  pages={49-54},
  abstract={Techniques based on formal semantics are discussed for automatically generating parallelizing compilers for object-oriented programming languages. The denotational semantics of object-oriented programming languages are used to derive the control and data dependencies that exist within programs and this information may then be used to produce parallel object code by a compiler. This approach also easily facilitates proving the correctness of transformations performed on the source programs. Furthermore, since compilers may be automatically generated from denotational semantics specifications, the implementation of these parallelization techniques will be automatic and hence language independent.},
  keywords={},
  doi={10.1109/HIPC.1996.565796},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{1392882,
  author={Blackford, L.S. and Choi, J. and Cleary, A. and Demmel, J. and Dhillon, I. and Dongarra, J. and Hammarling, S. and Henry, G. and Petitet, A. and Stanley, K. and Walker, D. and Whaley, R.C.},
  booktitle={Supercomputing '96:Proceedings of the 1996 ACM/IEEE Conference on Supercomputing}, 
  title={ScaLAPACK: A Portable Linear Algebra Library for Distributed Memory Computers - Design Issues and Performance}, 
  year={1996},
  volume={},
  number={},
  pages={5-5},
  abstract={This paper outlines the content and performance of ScaLAPACK, a collection of mathematical software for linear algebra computations on distributed memory computers. The importance of developing standards for computational and message passing interfaces is discussed. We present the different components and building blocks of ScaLAPACK, and indicate the difficulties inherent in producing correct codes for networks of heterogeneous processors. Finally, this paper briefly describes future directions for the ScaLAPACK library and concludes by suggesting alternative approaches to mathematical libraries, explaining how ScaLAPACK could be integrated into efficient and user-friendly distributed systems.},
  keywords={},
  doi={10.1109/SUPERC.1996.183513},
  ISSN={},
  month={Jan},}
@INPROCEEDINGS{1392908,
  author={Ogawa, H. and Matsuoka, S.},
  booktitle={Supercomputing '96:Proceedings of the 1996 ACM/IEEE Conference on Supercomputing}, 
  title={OMPI: Optimizing MPI Programs using Partial Evaluation}, 
  year={1996},
  volume={},
  number={},
  pages={37-37},
  abstract={MPI is gaining acceptance as a standard for message-passing in high-performance computing, due to its powerful and flexible support of various communication styles. However, the complexity of its API poses significant software overhead, and as a result, applicability of MPI has been restricted to rather regular, coarse-grained computations. Our OMPI (Optimizing MPI) system removes much of the excess overhead by employing partial evaluation techniques, which exploit static information of MPI calls. Because partial evaluation alone is insufficient, we also utilize template functions for further optimization. To validate the effectiveness for our OMPI system, we performed baseline as well as more extensive benchmarks on a set of application cores with different communication characteristics, on the 64-node Fujitsu AP1000 MPP. Benchmarks show that OMPI improves execution efficiency by as much as factor of two for communication-intensive application core with minimal code increase. It also performs significantly better than previous dynamic optimization technique.},
  keywords={},
  doi={10.1109/SUPERC.1996.183539},
  ISSN={},
  month={Jan},}
@INPROCEEDINGS{1392919,
  author={Hoisie, A. and Goedecker, S. and Hutter, J.},
  booktitle={Supercomputing '96:Proceedings of the 1996 ACM/IEEE Conference on Supercomputing}, 
  title={Electronic Structure of Materials using Self-Interaction Corrected Density Functional Theory}, 
  year={1996},
  volume={},
  number={},
  pages={49-49},
  abstract={We have developed an highly efficient electronic structure code, for parallel computers using message passing. The algorithm takes advantage of the natural parallelism in quantum chemistry problems to obtain very high performance even on a large number of processors. Most of the terms which scale cubically with respect to the number of atoms have been eliminated allowing the treatment of very large systems. It uses one of the most precise versions of Density Functional Theory, namely Self-Interaction Corrected Density Functional Theory. On a 6 processor Silicon Graphics Symmetric Multiprocessor based on the MIPs R8000 microprocessor, we obtain a performance of 6.3 Gflops per million dollar.},
  keywords={},
  doi={10.1109/SUPERC.1996.183550},
  ISSN={},
  month={Jan},}
@ARTICLE{628398,
  author={Yi-Min Wang and Yennun Huang and Kintala, C.},
  journal={IEEE Transactions on Computers}, 
  title={Progressive retry for software failure recovery in message-passing applications}, 
  year={1997},
  volume={46},
  number={10},
  pages={1137-1141},
  abstract={A method of execution retry for bypassing software faults in message-passing applications is described in this paper. Based on the techniques of checkpointing and message logging, we demonstrate the use of message replaying and message reordering as two mechanisms for achieving localized and fast recovery. The approach gradually increases the rollback distance and the number of affected processes when a previous retry fails, and is therefore named progressive retry. Examples from telecommunications software systems and performance measurements from an application-level implementation are described to illustrate the benefits of the scheme.},
  keywords={},
  doi={10.1109/12.628398},
  ISSN={1557-9956},
  month={Oct},}
@INPROCEEDINGS{625081,
  author={Shah, V. and Bhattacharya, S.},
  booktitle={Proceedings Twenty-First Annual International Computer Software and Applications Conference (COMPSAC'97)}, 
  title={Fault propagation analysis based variable length checkpoint placement for fault-tolerant parallel and distributed systems}, 
  year={1997},
  volume={},
  number={},
  pages={612-615},
  abstract={The paper proposes optimal checkpoint placement strategies using failure propagation analysis in a distributed rollback recovery system. The authors' previously proposed idea of failure propagation analysis (FPA) based checkpoint placement strategy is enhanced by incorporating link failures, task grouping/allocation, and loop stabilization aspects. Owing to the empirical observation that a large number of faults occur around message communication instructions, the checkpoint placement strategy places more checkpoints around message send/receive regions of the code. Allocation of tasks (or, threads) onto different processors can lead to varied communication patterns, which in turn can affect the FPA process and the checkpoint placement strategies. Thus, another key contribution of our research is to show the cyclic relationship between checkpointing and task allocation, as well as recursion in parallel or distributed programs. The proposed ideas and FPA approaches are illustrated using a typical parallel algorithm-the fast Fourier transform (FFT).},
  keywords={},
  doi={10.1109/CMPSAC.1997.625081},
  ISSN={0730-3157},
  month={Aug},}
@INPROCEEDINGS{625091,
  author={Kumar, D. and Iyengar, S.S.},
  booktitle={Proceedings Twenty-First Annual International Computer Software and Applications Conference (COMPSAC'97)}, 
  title={A semiformal correctness proof of a network broadcast algorithm}, 
  year={1997},
  volume={},
  number={},
  pages={668-671},
  abstract={In past years, a large number of published distributed algorithms have been shown to be incorrect. Unfortunately, designers of distributed algorithms typically use informal correctness proofs, which tend to be unreliable. Formal correctness proofs offer a much higher degree of reliability, but they are not popular among algorithm designers because they are too mathematical and they typically assume synchronous message communication or some other abstract notation, and are therefore not easily applicable to the asynchronous message passing environment, the environment commonly assumed by many algorithm designers. To address this problem, we have developed a semiformal correctness proof method for the asynchronous message passing environment, using ideas from well known formal correctness proof methods. We illustrate part of the proof method by proving the safety property of a simple network broadcast algorithm.},
  keywords={},
  doi={10.1109/CMPSAC.1997.625091},
  ISSN={0730-3157},
  month={Aug},}
@INPROCEEDINGS{618097,
  author={Zhongqi Jing and Smith, S. and Jain, M. and Zalrai, A.},
  booktitle={Proceedings of the IEEE 1997 National Aerospace and Electronics Conference. NAECON 1997}, 
  title={Migration of legacy WSR-8D algorithms and product generators to the open system RPG}, 
  year={1997},
  volume={1},
  number={},
  pages={318-324 vol.1},
  abstract={A substantial part of the current Weather Surveillance Radar-1988 Doppler (WSR-88D) Radar Product Generation (RPG) software consists of the product generation and meteorological algorithms, which were implemented through about 50 tasks. These tasks, written in FORTRAN with CONCURRENT extensions and running under the CONCURRENT 05/32 operating system (OS), can not be directly compiled and run under a UNIX OS. Intertask communication is implemented through using shared memory segments, requiring all tasks to be running on the same computer hardware. Tasks must fit into a predefined data flow network and are controlled by a central control module. This makes the system sensitive to task failure and difficult to be. Dynamically reconfigured (redistributing the tasks among hosts, adding new tasks and so on). These tasks contain sophisticated algorithms and lengthy code. The authors decided to take a direct porting approach to migrate these tasks to the Open System RPG (ORPG). The porting approach is unique in that only a single version of the source code is maintained. The ported version uses the original RPG code without any change for all subroutines except the main subroutine, which is replaced by a new version. A preprocessor is developed to convert the CONCURRENT FORTRAN code to a standard FORTRAN code, that can be compiled on a UNIX machine. This converted version is used only temporarily at compile time. A set of supporting functions, emulating the current RPG API, is developed to provide data flow and processing control support. All inter-process data exchanges are implemented through message passing in the supporting functions. "Wrapped" by the new supporting functions, the tasks turn into independent, data driven and dynamically relocatable components that can be used in a distributed environment.},
  keywords={},
  doi={10.1109/NAECON.1997.618097},
  ISSN={},
  month={July},}
@ARTICLE{615441,
  author={Morin, C. and Puaut, I.},
  journal={IEEE Transactions on Parallel and Distributed Systems}, 
  title={A survey of recoverable distributed shared virtual memory systems}, 
  year={1997},
  volume={8},
  number={9},
  pages={959-969},
  abstract={Distributed Shared Virtual Memory (DSVM) systems provide a shared memory abstraction on distributed memory architectures. Such systems ease parallel application programming because the shared-memory programming model is often more natural than the message-passing paradigm. However, the probability of failure of a DSVM increases with the number of sites. Thus, fault tolerance mechanisms must be implemented in order to allow processes to continue their execution in the event of a failure. This paper gives an overview of recoverable DSVMs (RDSVMs) that provide a checkpointing mechanism to restart parallel computations in the event of a site failure.},
  keywords={},
  doi={10.1109/71.615441},
  ISSN={1558-2183},
  month={Sep.},}
@INPROCEEDINGS{616035,
  author={Deconinck, G. and Lauwereins, R.},
  booktitle={Proceedings Second IEEE Symposium on Computer and Communications}, 
  title={User-triggered checkpointing: system-independent and scalable application recovery}, 
  year={1997},
  volume={},
  number={},
  pages={418-423},
  abstract={User-triggered checkpointing and rollback is proposed as a system-independent and flexible way to integrate backward error recovery in long-running, computation-intensive message-passing applications on large parallel multicomputers. It employs library calls to coordinate the checkpointing, allowing a non-blocking and scalable approach that requires no protocol to save a consistent state because the coordination among the processes is implicit. The explicit indication of the checkpoint contents (i.e. the items of which the state must be saved) allows one to significantly reduce the amount of checkpoint data and the overhead. In contrast to other checkpointing approaches, the implementation does not rely on system-dependent features (like saving register-values or communication status) to save the state. Instead, re-executing the first part of the application brings the system-specific items into a consistent state with the rest of the checkpoint contents that is restored from the saved checkpoint data.},
  keywords={},
  doi={10.1109/ISCC.1997.616035},
  ISSN={},
  month={July},}
@INPROCEEDINGS{648209,
  author={Dutta, S.K. and Saha, D. and Das, P.K.},
  booktitle={TENCON '97 Brisbane - Australia. Proceedings of IEEE TENCON '97. IEEE Region 10 Annual Conference. Speech and Image Technologies for Computing and Telecommunications (Cat. No.97CH36162)}, 
  title={Analysis of real-time parallel programs using source-level timing schema}, 
  year={1997},
  volume={2},
  number={},
  pages={433-436 vol.2},
  abstract={The paper introduces deterministic timing schema or formulae for predicting the best and worst case execution times of real time parallel programs. Timing schema (J. Kim and A.C. Shaw; H.R. Callison and A.C. Shaw) are formulae based on source program elements to calculate the execution time of programs. The total execution time is computed from the schema provided for a variety of parallel program constructs in distributed message passing systems as well as using remote procedure calls. As an initial attempt to validate the proposition, we have conducted a series of experiments on a distributed memory multiprocessor system based on transputer nodes. We present deterministic timing schema for a variety of Occam constructs and test them for their validity with real systems in the parallel processing. An automated program for the determination of timing schema for parallel programs has been developed, which gives quite tolerable predictions.},
  keywords={},
  doi={10.1109/TENCON.1997.648209},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{648207,
  author={Dutta, S.K. and Saha, D. and Das, P.K.},
  booktitle={TENCON '97 Brisbane - Australia. Proceedings of IEEE TENCON '97. IEEE Region 10 Annual Conference. Speech and Image Technologies for Computing and Telecommunications (Cat. No.97CH36162)}, 
  title={Design of a parallel protocol verification system}, 
  year={1997},
  volume={2},
  number={},
  pages={425-428 vol.2},
  abstract={This paper presents a parallel protocol verification algorithm for checking the logical correctness of computer network protocols modeled as a collection of communicating finite state machines (CFSM) with first in first out (FIFO) queues. The method of parallelizing the automated reachability analysis in MIMD distributed memory message passing environment is a new approach to reduce the complexity of analyzing non-trivial protocols. A parallel algorithm has been developed to generate and search the different sub-trees of the reachability tree simultaneously in different processors. The software tool employs parallel reachability analysis of computer network protocols, modeled as a network of CFSMs and FIFO queues, for checking their logical correctness. It is written in Occam, and implements this procedure on a transputer based system and the results obtained from the verification of various protocols using a few available transputers are extrapolated to predict the performance gain achievable for a still larger configuration of similar nodes. This multi-processing approach can be combined with suitable search strategies to contain state explosion in reachability analysis, in order to further improve the overall system performance. Moreover the technique is general enough to be ported on various distributed processing system using general high level language such as PVM and C respectively.},
  keywords={},
  doi={10.1109/TENCON.1997.648207},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{663181,
  author={Cui Zhang and Becker, B.R. and Peticolas, D. and Heckman, M. and Levitt, K. and Olsson, R.A.},
  booktitle={Proceedings of the Thirtieth Hawaii International Conference on System Sciences}, 
  title={Verification of a distributed computing system by layered proofs}, 
  year={1997},
  volume={5},
  number={},
  pages={252-261 vol.5},
  abstract={This paper presents a technique for the verification of "full" distributed computing systems, building on the CLI stack which addresses verification of a layered sequential system. This paper also presents the application of our technique to the verification of a distributed system of three layers: a small high-level distributed programming language (microSR); a multiple processor architecture consisting of an instruction set and system calls; and a network interface. MicroSR programs are implemented by a compiler from microSR to the multiprocessor layer. System calls (for interprocess message passing) are implemented by network services. This work demonstrates that the correctness of a distributed program, most notably its interprocess communication, is verifiable through layers that guarantee the correctness of the compiled code that makes reference to operating system calls, of the operating system calls in terms of network calls, and of the network calls in terms of network transmission steps. The Cambridge HOL system is used for the specification and the proofs.},
  keywords={},
  doi={10.1109/HICSS.1997.663181},
  ISSN={1060-3425},
  month={Jan},}
@INPROCEEDINGS{634473,
  author={Singh Verma, C. and Rao, V.C.V.},
  booktitle={Proceedings Fourth International Conference on High-Performance Computing}, 
  title={Parallelization of finite volume computations for heat transfer application using unstructured mesh partitioning algorithms}, 
  year={1997},
  volume={},
  number={},
  pages={72-79},
  abstract={An effective parallelization of finite volume computations for heat transfer application using unstructured triangular meshes and mesh partitioning algorithms are presented. The mesh partitioning software (METIS) is employed to create nearly load balanced subdomains and to minimize the interprocessor communications. Efficient data structures are developed to handle the neighboring element information at the interfaces of all subdomains and a simple strategy to overlap the computations to communications has been implemented for improving the performance of the program. The explicit time integration method is used and the results for the rectangular domain and L-shaped domain have been presented. The code (PHEAT2D) is written in Fortran90 and MPI for message passing is used. The algorithm is tested on distributed memory MIMD machine, PARAM OPENFRAME.},
  keywords={},
  doi={10.1109/HIPC.1997.634473},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{634300,
  author={Mammeri, Z. and Haouam, K.-D.},
  booktitle={Proceedings 1997 IEEE International Workshop on Factory Communication Systems. WFCS'97}, 
  title={Connection allocation schemes for guaranteeing hard real-time communications with ATM network}, 
  year={1997},
  volume={},
  number={},
  pages={203-212},
  abstract={Two technical advantages of ATM, end-to-end QoS and high bandwidth, make ATM suitable for distributed real time systems (DRTSs). However, ATM capabilities cannot be used correctly and efficiently without an adequate mapping of timing constraints of messages onto ATM services. The paper presents an approach for a "systematic" mapping of real time message attributes onto parameters, and quality of service, of ATM connections. This approach is useful for one who needs to develop a distributed real time application above ATM with only little knowledge of ATM protocols. A message scheduling algorithm based on EDF is used to deal with the sharing of an ATM connection between several message sources.},
  keywords={},
  doi={10.1109/WFCS.1997.634300},
  ISSN={},
  month={Oct},}
@INPROCEEDINGS{634530,
  author={Sreenivas, M.V. and Bhalla, S.},
  booktitle={Proceedings Fourth International Conference on High-Performance Computing}, 
  title={Independent global snapshots in large distributed systems}, 
  year={1997},
  volume={},
  number={},
  pages={462-467},
  abstract={Distributed systems depend on consistent global snapshots for process recovery and garbage collection activity. We provide exact conditions for an arbitrary checkpoint based on independent dependency tracking within clusters of nodes. The method permits nodes (within clusters) to independently compute dependency information based on available (local) information. The existing models of global snapshot computations provide the necessary and sufficient conditions. But, these require expensive global computations. The proposed computations can be performed by a node to identify existing global checkpoints. The nodes can also compute conditions to make a checkpoint, or conditions, such that a collection of checkpoints, can belong to a global snapshot.},
  keywords={},
  doi={10.1109/HIPC.1997.634530},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{634480,
  author={Jai-Hoon Kim and Vaidya, N.H.},
  booktitle={Proceedings Fourth International Conference on High-Performance Computing}, 
  title={A cost model for distributed shared memory using competitive update}, 
  year={1997},
  volume={},
  number={},
  pages={112-117},
  abstract={This paper presents a new "cost" analysis model for distributed shared memory (DSM) using a competitive update protocol. The cost metric of interest is the overhead of message passing necessary to implement DSM. This approach is based on segment model proposed previously (Kim et al., 1996, 1997). The input parameter for the cost analysis model is the probability density function of the number of remote updates in a segment. This distribution can quite accurately characterize many applications. The proposed model is validated by comparing analytical results obtained using the model to experimental results. The competitive update protocol for shared memory is defined using a parameter called the "update limit" (or threshold). Using the proposed model, we compute the optimal update limit for the competitive update protocol.},
  keywords={},
  doi={10.1109/HIPC.1997.634480},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{634495,
  author={Biswas, R. and Oliker, L.},
  booktitle={Proceedings Fourth International Conference on High-Performance Computing}, 
  title={Load balancing sequences of unstructured adaptive grids}, 
  year={1997},
  volume={},
  number={},
  pages={212-217},
  abstract={Mesh adaption is a powerful tool for efficient unstructured grid computations but causes load imbalance on multiprocessor systems. To address this problem, we have developed PLUM, an automatic portable framework for performing adaptive large scale numerical computations in a message passing environment. The paper makes several important additions to our previous work. First, a new remapping cost model is presented and empirically validated on an SP2. Next, our load balancing strategy is applied to sequences of dynamically adapted unstructured grids. Results indicate that our framework is effective on many processors for both steady and unsteady problems with several levels of adaption. Additionally, we demonstrate that a coarse starting mesh produces high quality load balancing, at a fraction of the cost required for a fine initial mesh. Finally, we show that the data remapping overhead can be significantly reduced by applying our heuristic processor reassignment algorithm.},
  keywords={},
  doi={10.1109/HIPC.1997.634495},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{634510,
  author={Carrion, C. and Beivide, R. and Gregorio, J.A. and Vallejo, F.},
  booktitle={Proceedings Fourth International Conference on High-Performance Computing}, 
  title={A flow control mechanism to avoid message deadlock in k-ary n-cube networks}, 
  year={1997},
  volume={},
  number={},
  pages={322-329},
  abstract={We propose a flow control algorithm for k-ary n-cube networks which avoids the deadlock problems without using virtual channels. Some basic definitions and theorems are proposed in order to establish the necessary and sufficient conditions to verify that an algorithm is deadlock-free. Our proposal is based on a restriction of the virtual cut-through flow control rather than of the routing algorithm and it can be applied both over central buffers or edge buffers. A minimum free buffer space of two packets is required. The implementation complexity of the router according to Chien's (1993) model, is much easier and faster than using virtual channels. Network simulations considering the router complexity show the performance achieved by this new algorithm. The results display a latency improvement of 20% to 35% compared with the use of virtual channels depending on the load of the network.},
  keywords={},
  doi={10.1109/HIPC.1997.634510},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{635440,
  author={Weiping Zhu and Tyng-Yeu Liang and Ce Kuen Shieh},
  booktitle={1997 IEEE International Conference on Systems, Man, and Cybernetics. Computational Cybernetics and Simulation}, 
  title={Using extended neural network map tasks}, 
  year={1997},
  volume={3},
  number={},
  pages={2927-2932 vol.3},
  abstract={Software distributed shared memory (DSM) systems are being used as an alternative to parallel processing. To achieve high performance in terms of completion time for an application running on a DSM, an effective task mapping or scheduling method has to be employed. The method based on the characteristics of the application and the system configuration allocates tasks and data to machines to speed up execution. Due to the unique nature of the DSM in its communication, the task mapping methods developed for message-passing systems can not be directly applied on DSM systems. In this paper, a model describing the unique nature of DSM communication and the connection between tasks is put forward first. Based on the model, two task mapping methods are developed. One of the methods uses the Hopfield neural net, the other applies simulated annealing technique. They rely on evolutionary technique to search for optimum or near optimum solutions. The proposed methods have been implemented and tested under different configurations. Their performance has been evaluated by using representative applications, The results indicate the effectiveness of the methods and reveal the accuracy of the model.},
  keywords={},
  doi={10.1109/ICSMC.1997.635440},
  ISSN={1062-922X},
  month={Oct},}
@INPROCEEDINGS{637866,
  author={Mueller, F.},
  booktitle={Proceedings of 5th International Workshop on Parallel and Distributed Real-Time Systems and 3rd Workshop on Object-Oriented Real-Time Systems}, 
  title={Prioritized token-based mutual exclusion for distributed systems}, 
  year={1997},
  volume={},
  number={},
  pages={72-80},
  abstract={A number of solutions have been proposed for the problem of mutual exclusion in distributed systems. Some of these approaches have since been extended to a prioritized environment suitable for real-time applications but impose a higher message passing overhead than our approach. We present a new protocol for prioritized mutual exclusion in a distributed environment. Our approach uses a token-based model working on a logical tree structure, which is dynamically modified. In addition, we utilize a set of local queues whose union would resemble a single global queue. The prioritized algorithm has an average overhead of O(log(n)) messages per request for mutual exclusion with a worst-case overhead of O(n), where n represents the number of nodes in the system. Thus, our prioritized algorithm matches the message complexity of the best non-prioritized algorithms while previous prioritized algorithms have a higher message complexity, to our knowledge. Furthermore, the concept of local queues can be incorporated into arbitrary token-based protocols with or without priority support to reduce the amount of messages.},
  keywords={},
  doi={10.1109/WPDRTS.1997.637866},
  ISSN={},
  month={April},}
@INPROCEEDINGS{637876,
  author={Ujvary, B.G. and Kamenoff, N.I.},
  booktitle={Proceedings of 5th International Workshop on Parallel and Distributed Real-Time Systems and 3rd Workshop on Object-Oriented Real-Time Systems}, 
  title={Implementation of the Hartstone Distributed Benchmark for hard real-time distributed systems: results and conclusions}, 
  year={1997},
  volume={},
  number={},
  pages={98-103},
  abstract={This paper presents a first time approach for the implementation of the Hartstone Distributed Benchmark (HDB) for hard real-time distributed systems. From the series of experiments, as defined in the original HDB paper, six experiments have been implemented. The main idea behind the HDB is the definition of a number of (host processor) tasks on each node which exchange messages with corresponding tasks on the other nodes. The stopping criteria for each experiment is the missing of a message before the deadline of a receiving task. The variables in the HDB experiments are: the number of tasks sending and/or receiving messages; the number of messages sent and/or received per task period; the length of messages sent and/or received per task period; and the number of nodes participating in the experiments. The results of the implemented experiments show a high level of repeatability, and stability of the testbed setting used.},
  keywords={},
  doi={10.1109/WPDRTS.1997.637876},
  ISSN={},
  month={April},}
@INPROCEEDINGS{637097,
  author={Flaherty, J.E. and Loy, R.M. and Scully, P.C. and Shephard, M.S. and Szymanski, B.K. and Teresco, J.D. and Ziantz, L.H.},
  booktitle={Proceedings 17th International Conference of the Chilean Computer Science Society}, 
  title={Load balancing and communication optimization for parallel adaptive finite element methods}, 
  year={1997},
  volume={},
  number={},
  pages={246-255},
  abstract={The paper describes predictive load balancing schemes designed for use with parallel adaptive finite element methods. We provide an overview of data structures suitable for distributed storage of finite element mesh data as well as software designed for mesh adaptation and load balancing. During the course of a parallel computation, processor load imbalances are introduced at adaptive enrichment steps. The predictive load balancing methods described here use a priori estimates of work load for adaptive refinement and subsequent computation to improve enrichment efficiency and reduce total balancing time. An analysis code developed with these components for solving compressible flow problems is used to obtain predictive load balancing results on an IBM SP2 computer. Our test problem involves the transient solution of the three dimensional Euler equations of compressible flow inside a perforated shock tube. We also present a message passing library extension in development which allows for automated packing of messages to improve communication efficiency.},
  keywords={},
  doi={10.1109/SCCC.1997.637097},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{640140,
  author={Wei-Jih Li and Jyh-Jong Tsay},
  booktitle={Proceedings Pacific Rim International Symposium on Fault-Tolerant Systems}, 
  title={Checkpointing Message-Passing Interface (MPI) parallel programs}, 
  year={1997},
  volume={},
  number={},
  pages={147-152},
  abstract={Many scientific problems can be distributed on a large number of processes to take advantage of low cost workstations. In a parallel systems, a failure on any processor can halt the computation and requires restarting all applications. Checkpointing is a simple technique to recover the failed execution. Message Passing Interface (MPI) is a standard proposed for writing portable message-passing parallel programs. In this paper, we present a checkpointing implementation for MPI programs, which is transparent, and requires no changes to the application programs. Our implementation combines coordinated, uncoordinated and message logging techniques.},
  keywords={},
  doi={10.1109/PRFTS.1997.640140},
  ISSN={},
  month={Dec},}
@ARTICLE{641629,
  author={Garg, V.K.},
  journal={IEEE Concurrency}, 
  title={Methods for observing global properties in distributed systems}, 
  year={1997},
  volume={5},
  number={4},
  pages={69-77},
  abstract={The author surveys algorithms that focus on special classes of predicates to observe global properties in distributed systems. This abstraction is key to efficient debugging and fault tolerance. The algorithms are also flexible, allowing for optimizations to fit application needs. For example, algorithms to detect general predicates can be optimized by exploiting specific properties of the channel predicate. In checking if a channel is empty, it may be sufficient to deal with the number of messages only, rather than the message themselves.},
  keywords={},
  doi={10.1109/4434.641629},
  ISSN={1558-0849},
  month={Oct},}
@INPROCEEDINGS{644019,
  author={Kandemir, M. and Ramanujam, J. and Choudhary, A.},
  booktitle={Proceedings 1997 International Conference on Parallel Architectures and Compilation Techniques}, 
  title={Compiler algorithms for optimizing locality and parallelism on shared and distributed memory machines}, 
  year={1997},
  volume={},
  number={},
  pages={236-247},
  abstract={Distributed memory message passing machines can deliver scalable performance but are difficult to program. Shared memory machines, on the other hand, are easier to program but obtaining scalable performance with a large number of processors is difficult. Previously, some scalable architectures based on logically-shared physically-distributed memory have been designed and implemented. While some of the performance issues like parallelism and locality are common to the different parallel architectures, issues such as data decomposition are unique to specific types of architectures. One of the most important challenges compiler writers face is to design compilation techniques that can work on a variety of architectures. In this paper, we propose an algorithm that can be employed by optimizing compilers for different types of parallel architectures. Our optimization algorithm does the following: (1) transforms loop nests such that, where possible, the outermost loops can be run in parallel across processors; (2) decomposes each array across processors; (3) optimizes interprocessor communication by vectorizing it whenever possible; and (it) optimizes locality (cache performance) by assigning appropriate storage layout for each array. Depending on the underlying hardware system, some or all of these steps can be applied in a unified framework. We present simulation results for cache miss rates, and empirical results on SUN SPARCstation 5, IBM SP-2, SGI Challenge and Convex Exemplar to validate the effectiveness of our approach on different architectures.},
  keywords={},
  doi={10.1109/PACT.1997.644019},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{645076,
  author={Flauzac, O. and Villain, V.},
  booktitle={Proceedings of the 1997 International Symposium on Parallel Architectures, Algorithms and Networks (I-SPAN'97)}, 
  title={An implementable dynamic automatic self-stabilizing protocol}, 
  year={1997},
  volume={},
  number={},
  pages={91-97},
  abstract={The notion of self-stabilization was first introduced by Dijkstra: it is the property for a system to eventually recover by itself a legitimate state after any perturbation modifying the memory state. This paper proposes a dynamic automatic self-stabilizing protocol. This algorithm runs in the fully asynchronous message-passing model in which messages can also be corrupted. The principle of the algorithm is to compute regularly a global state and if necessary to generate a global reset. When the system is stabilized, the message complexity is O(max(/spl delta/*m, n/sup 2/)) where /spl delta/ is the degree of the communication graph, m the number of links and n the number of processors. This complexity allows a possible implementation.},
  keywords={},
  doi={10.1109/ISPAN.1997.645076},
  ISSN={1087-4089},
  month={Dec},}
@INPROCEEDINGS{652631,
  author={Kwang-Sik Chung and Ki-Bom Kim and Chong-Sun Hwang and Jin Gon Shon and Heon-Chang Yu},
  booktitle={Proceedings 1997 International Conference on Parallel and Distributed Systems}, 
  title={Hybrid checkpointing protocol based on selective-sender-based message logging}, 
  year={1997},
  volume={},
  number={},
  pages={788-793},
  abstract={This paper presents a hybrid checkpointing protocol-an asynchronous checkpointing protocol using a message sending/receiving state change for reducing the overhead of failure-free operation combined with a selective sender-based message logging protocol for reducing the cascade rollback of asynchronous checkpointing protocol. The selective sender-based message logging protocol records only potential orphan messages when taking a checkpoint. And this paper presents a message dependency tree recording the inter-process message sending/receiving information on a volatile storage for reducing the search time of inter-process information during the failure recovery.},
  keywords={},
  doi={10.1109/ICPADS.1997.652631},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{667203,
  author={Fatoohi, R.},
  booktitle={Proceedings of the Thirtieth Hawaii International Conference on System Sciences}, 
  title={Performance evaluation of communication software systems for distributed computing}, 
  year={1997},
  volume={1},
  number={},
  pages={100-109 vol.1},
  abstract={In recent years, there has been an increasing interest in object-oriented distributed computing since it is better equipped to deal with complex systems while providing extensibility, maintainability and reusability. At the same time, several new high-speed network technologies have emerged for local- and wide-area networks. However, the performance of networking software is not improving as fast as that of the networking hardware and the workstation microprocessors. This paper gives an overview and evaluates the performance of the Common Object Request Broker Architecture (CORBA) standard in a distributed computing environment at NASA Ames Research Center. The environment consists of two testbeds of SGI workstations connected by four networks: Ethernet, FDDI, HiPPI and ATM. The performance results for three communication software systems are presented, analyzed and compared. These systems are: BSD socket programming interface, IONA's Orbix, an implementation of the CORBA specification, and the PVM message-passing library. The results show that high-level communication interfaces, such as CORBA and PVM, can achieve reasonable performance under certain conditions.},
  keywords={},
  doi={10.1109/HICSS.1997.667203},
  ISSN={1060-3425},
  month={Jan},}
@INPROCEEDINGS{680939,
  author={Patrick, D. and Green, P. and York, T.},
  booktitle={Second International Conference On Genetic Algorithms In Engineering Systems: Innovations And Applications}, 
  title={A distributed genetic algorithm environment for UNIX workstation clusters}, 
  year={1997},
  volume={},
  number={},
  pages={69-74},
  abstract={This paper describes the development of the CNIX multiprocessor environment, that is specifically designed for the efficient execution of distributed genetic algorithms on clusters of UNIX work stations. CNIX is based around the TCP/IP client-server model and consists of two sets of 'C++' libraries functions. The CNIX libraries provide a standard 'C++' compiler with the necessary code to establish a multithreaded multiprocessor genetic algorithm environment. The first library migrates the major architectural features of the Transputer, along with selected instructions, to provide hardware independent parallel processing between multiple workstations and message passing communications across local area networks. The second library supplies a genetic algorithm tool kit to allow application programmers and engineers, with a basic knowledge of 'C++', to construct distributed genetic algorithm using a set of simple set of instructions. Results show that CNIX is capable of executing parallel programs over groups of UNIX workstations while achieving a multiprocessor speedup of up to 95%. Performance tests running distributed genetic algorithms across 16 workstations have demonstrated a speed-up of 15 compared to sequential 'C+ +' versions.},
  keywords={},
  doi={10.1049/cp:19971157},
  ISSN={0537-9989},
  month={Sep.},}
@INPROCEEDINGS{603430,
  author={Jensen, P.A. and Soparkar, N.R. and Mathur, A.G.},
  booktitle={Proceedings of 17th International Conference on Distributed Computing Systems}, 
  title={Characterizing multicast orderings using concurrency control theory}, 
  year={1997},
  volume={},
  number={},
  pages={586-593},
  abstract={Coordinating distributed executions is achieved by two widely used approaches: process groups and transactions. Typically, the two represent a trade-off in terms of the degrees of consistency and performance. By applying transaction concurrency control techniques to characterize and design process group multicast orderings, we aim to provide aspects of both ends of the trade-off. In particular, we propose a framework in which each message multicast is regarded as a transaction. Appropriate message ordering protocols are devised and shown to be correct using a variant of concurrency control theory. Also, we are able do incorporate certain aspects of application semantics for which existing process group approaches are inadequate. Finally, our framework provides a means to characterize the performance of orderings to allow a comparison of different ordering protocols.},
  keywords={},
  doi={10.1109/ICDCS.1997.603430},
  ISSN={1063-6927},
  month={May},}

@INPROCEEDINGS{603422,
  author={Baldoni, R. and Friedman, R. and van Renesse, R.},
  booktitle={Proceedings of 17th International Conference on Distributed Computing Systems}, 
  title={The hierarchical daisy architecture for causal delivery}, 
  year={1997},
  volume={},
  number={},
  pages={570-577},
  abstract={We propose the hierarchical daisy architecture, which provides causal delivery of messages sent to any subset of processes. The architecture provides fault tolerance and maintains the amount of control information within a reasonable size. It divides processes into logical groups. Messages inside a logical group are sent directly, while messages that need to cross logical group boundaries are forwarded by servers. We prove the correctness of the daisy architecture and discuss possible optimizations.},
  keywords={},
  doi={10.1109/ICDCS.1997.603422},
  ISSN={1063-6927},
  month={May},}
@INPROCEEDINGS{603426,
  author={Guerraoui, R. and Schiper, A.},
  booktitle={Proceedings of 17th International Conference on Distributed Computing Systems}, 
  title={Total order multicast to multiple groups}, 
  year={1997},
  volume={},
  number={},
  pages={578-585},
  abstract={We present a fault tolerant algorithm that ensures total order delivery of messages sent to multiple groups of processes. Our algorithm is a multiple group "genuine" multicast algorithm in the sense that: (1) any process can send a message to any set of process groups; and (2) only the sender and the receivers of a message take part in the algorithm needed to deliver the message. The correctness of our algorithm does not require reliable failure detectors, but requires causal order delivery of messages. This establishes a new and interesting link between causal order delivery and fault tolerance with unreliable failure detectors.},
  keywords={},
  doi={10.1109/ICDCS.1997.603426},
  ISSN={1063-6927},
  month={May},}
@INPROCEEDINGS{614098,
  author={Blough, D.M. and Torii, T.},
  booktitle={Proceedings of IEEE 27th International Symposium on Fault Tolerant Computing}, 
  title={Fault-injection-based testing of fault-tolerant algorithms in message-passing parallel computers}, 
  year={1997},
  volume={},
  number={},
  pages={258-267},
  abstract={Distributed-memory parallel computers offer inherent redundancy that can be exploited to provide software-implemented fault tolerance. Numerous algorithms have been developed for fault-tolerant unicast communication, fault-tolerant broadcast, fault diagnosis, check-point/rollback, various consensus problems, algorithm-based fault tolerance, etc. Correctness proofs for these algorithms tend to be quite complex and, as a result, are error-prone. Furthermore, the way in which an algorithm is implemented can have dramatic impact on its correctness. Fault-injection-based testing is, therefore, an essential component of the validation procedure for these algorithms, which can complement other methods such as formal verification. The authors present a methodology for fault injection in distributed-memory parallel computers that use a message-passing paradigm. Their approach is based on injection of faults into interprocessor communications, and allows emulation of fault models commonly used in design of fault-tolerant parallel algorithms. The methodology has been applied in a tool for fault injection in Intel iPSC/860 multicomputers, and has been demonstrated through the extensive testing of a fault-tolerant broadcast algorithm.},
  keywords={},
  doi={10.1109/FTCS.1997.614098},
  ISSN={0731-3071},
  month={June},}
@INPROCEEDINGS{614100,
  author={Lynch, N.A. and Shvartsman, A.A.},
  booktitle={Proceedings of IEEE 27th International Symposium on Fault Tolerant Computing}, 
  title={Robust emulation of shared memory using dynamic quorum-acknowledged broadcasts}, 
  year={1997},
  volume={},
  number={},
  pages={272-281},
  abstract={The paper presents a robust emulation of multi-writer/multireader registers in message-passing systems using dynamic quorum configurations. In addition to processor and link failures, this emulation tolerates changes in quorum configurations, i.e., on-line replacements of one quorum system consisting of read and write quorums with another such system. The new emulation is specified using a modular two-layer architecture. The lower layer uses unreliable broadcast to disseminate a client request to a set of processors, and then to collect responses from a subset of the processors. The higher layer emulates robust multi-writer/multi-reader registers where quorum configurations are used to ensure register atomicity. A unique feature of the read/write service is that it implements dynamically changing quorum configurations. The processor designated as the reconfigured executes requests that replace the current configuration with a new configuration. The combination of the higher and lower layers allows essentially unlimited concurrency and does not involve locks. Waiting can occur only due to processor or link failures that disconnect at least one processor in each read quorum or at least one processor in each write quorum of the specified configurations. Additional computation and communication overhead can be incurred by the read and write operations when they encounter frequent reconfigurations. The algorithms are specified here in terms of I/O automata and their correctness is proved using invariants and partial-order methods.},
  keywords={},
  doi={10.1109/FTCS.1997.614100},
  ISSN={0731-3071},
  month={June},}
@INPROCEEDINGS{612921,
  author={Aji, S.M. and McEliece, R.J.},
  booktitle={Proceedings of IEEE International Symposium on Information Theory}, 
  title={A general algorithm for distributing information in a graph}, 
  year={1997},
  volume={},
  number={},
  pages={6-},
  abstract={We present a general "message-passing" algorithm for distributing information in a graph. This algorithm may help us to understand the approximate correctness of both the Gallager-Tanner-Wiberg algorithm, and the turbo-decoding algorithm.},
  keywords={},
  doi={10.1109/ISIT.1997.612921},
  ISSN={},
  month={June},}
@ARTICLE{605920,
  author={Luksch, P. and Maier, U. and Rathmayer, S. and Weidmann, M. and Unger, F.},
  journal={IEEE Concurrency}, 
  title={SEMPA: software engineering for parallel scientific computing}, 
  year={1997},
  volume={5},
  number={3},
  pages={64-72},
  abstract={The Sempa project brings together researchers from computer science, mechanical engineering, and numerical analysis to define software-engineering methods for the parallelization of existing large-scale software packages in scientific computing. The parallel implementation of TfC, an industrial state-of-the-art computational-fluid-dynamics simulation program, serves as the central case study for defining and evaluating these methods. Sempa researchers have successfully implemented and tested a portable parallel version of TfC based on message-passing standards (PVM and MPI). In addition, Sempa researchers have demonstrated the potential of new languages and programming paradigms such as data parallelism and object orientation by reimplementing the algebraic multigrid solver-a key module in TfC-in Fortran 90, HPF, and C++. Networks of workstations have become very attractive as low-cost platforms. Efficiently using their resources for production runs of parallel software requires automated resource management that optimizes resource utilization for parallel batch jobs without impeding interactive use. Therefore, the Sempa project has also implemented a resource manager for batch execution of PVM programs.},
  keywords={},
  doi={10.1109/4434.605920},
  ISSN={1558-0849},
  month={July},}
@ARTICLE{565609,
  author={Marcenac, P.},
  journal={IEEE Potentials}, 
  title={The multiagent approach [geophysics]}, 
  year={1997},
  volume={16},
  number={1},
  pages={19-22},
  abstract={Complex systems can be defined as systems with behavior that is poorly understood. These systems appear in a large variety of fields, such as natural phenomena. Modeling natural phenomena is an interesting challenge because natural phenomena, such as earthquakes, hurricanes and volcanoes, can cause severe damage. What's more, in this area, most classical models have failed both to understand the underlying physical processes and to predict future behavior. Our approach is to consider macro-behavior (i.e., the result of the program execution) as the result of a set of interactions among smaller, independent entities. The whole system is then distributed among these entities, called agents. Our research project, named GEOMAS (GEOphysics and MultiAgent Systems), was started in 1994. As a test case, a complex system dealing with predicting volcano eruptions has been investigated. In particular, we studied the volcano of La Fournaise in La Reunion island.},
  keywords={},
  doi={10.1109/45.565609},
  ISSN={1558-1772},
  month={Feb},}
@INPROCEEDINGS{574037,
  author={Bruening, U. and Schaelicke, L.},
  booktitle={Proceedings. Advances in Parallel and Distributed Computing}, 
  title={ATOLL: a high-performance communication device for parallel systems}, 
  year={1997},
  volume={},
  number={},
  pages={228-234},
  abstract={Fast and efficient communication is one of the major design goals not only for parallel systems but also for clusters of workstations. The proposed model of the high performance communication device ATOLL features very low latency for the start of communication operations and reduces the software overhead for communication specific functions. To close the gap between off-the-shelf microprocessors and the communication system a highly sophisticated processor interface implements atomic start of communication, MMU support, and a flexible event scheduling scheme. The interconnectivity of ATOLL provided by four independent network ports combined with cut-through routing allows the configuration of a large variety of network topologies. A software transparent error correction mechanism significantly reduces the required protocol overhead. The presented simulation results promise high performance and low-latency communication.},
  keywords={},
  doi={10.1109/APDC.1997.574037},
  ISSN={},
  month={March},}
@INPROCEEDINGS{574049,
  author={Shuo Di and Wei Min Zheng},
  booktitle={Proceedings. Advances in Parallel and Distributed Computing}, 
  title={Reduced communication protocol for clusters}, 
  year={1997},
  volume={},
  number={},
  pages={314-319},
  abstract={With the development of CPUs and communication networks, workstation clusters using message-passing mechanism become a crucial role in the field of network computing. Today's clusters are mainly connected by networks running traditional communication protocols (such as TCP/IP). The high overheads of these protocols make many parallel applications running on clusters inefficient using the potential computation power provided by the workstations and the networks. A method to solve this problem is to construct reduced communication protocol. This paper gives a detailed analysis of overheads produced by traditional protocols and provides some global strategies to design a reduced communication protocol. Our implementation method of such a protocol is described here together with some core algorithms and the testing results.},
  keywords={},
  doi={10.1109/APDC.1997.574049},
  ISSN={},
  month={March},}
@ARTICLE{579208,
  author={Moller, F.},
  journal={IEEE Aerospace and Electronic Systems Magazine}, 
  title={Asynchronous router specification}, 
  year={1997},
  volume={12},
  number={3},
  pages={38-44},
  abstract={We describe the application of three formal design tools to a case study in the design of a distributed system. The case study in question involves the specification of an asynchronous message router; the three design tools are process algebra (specifically Milner's Calculus of Communicating Systems CCS), the modal μ-calculus and the Edinburgh Concurrency Workbench (CWB). We demonstrate how an informally-presented specification can be formalised within the language of the modal μ-calculus, allowing for a rigorous mathematical analysis of the correctness of our proposed implementation. For modest-sized versions of the router, this correctness proof has been carried out using the CWB.},
  keywords={},
  doi={10.1109/62.579208},
  ISSN={1557-959X},
  month={March},}
@INPROCEEDINGS{577998,
  author={Dieter, W.R. and Lumpp, J.E.},
  booktitle={1997 IEEE Aerospace Conference}, 
  title={Fault recovery for distributed shared memory systems}, 
  year={1997},
  volume={2},
  number={},
  pages={525-540 vol.2},
  abstract={Distributed Shared Memory (DSM) offers programmers a shared memory abstraction on top of an underlying network of distributed memory machines. Advances in network technology and price/performance of workstations suggest that DSM will be the dominant paradigm for future high-performance computing. However, as long running DSM applications scale to hundreds or even thousands of machines, the probability of a node or network link failing increases. Fault tolerance is typically achieved via "checkpointing" techniques that allow applications to "roll back" to a recent checkpoint rather than restarting. High-performance DSM systems using relaxed memory consistency are significantly more difficult to checkpoint than uniprocessor or message passing architectures. This paper describes previous approaches to checkpointing message passing parallel programs along with extensions to DSM systems.},
  keywords={},
  doi={10.1109/AERO.1997.577998},
  ISSN={},
  month={Feb},}
@INPROCEEDINGS{580884,
  author={Brehm, J. and Worley, P.H.},
  booktitle={Proceedings 11th International Parallel Processing Symposium}, 
  title={Performance prediction for complex parallel applications}, 
  year={1997},
  volume={},
  number={},
  pages={187-191},
  abstract={Today's massively parallel machines are typically message-passing systems consisting of hundreds or thousands of processors. Implementing parallel applications efficiently in this environment is a challenging task, and poor parallel design decisions can be expensive to correct. Tools and techniques that allow the fast and accurate evaluation of different parallelization strategies would significantly improve the productivity of application developers and increase throughput on parallel architectures. This paper investigates one of the major issues in building tools to compare parallelization strategies: determining what type of performance models of the application code and of the computer system are sufficient for a fast and accurate comparison of different strategies. The paper is built around a case study employing the Performance Prediction Tool (PerPreT) to predict performance of the Parallel Spectral Transform Shallow Water Model code (PSTSWM) on the Intel Paragon.},
  keywords={},
  doi={10.1109/IPPS.1997.580884},
  ISSN={1063-7133},
  month={April},}
@INPROCEEDINGS{581406,
  author={Cermele, M. and Colajanni, M. and Necci, G.},
  booktitle={Proceedings Sixth Heterogeneous Computing Workshop (HCW'97)}, 
  title={Dynamic load balancing of distributed SPMD computations with explicit message-passing}, 
  year={1997},
  volume={},
  number={},
  pages={2-16},
  abstract={Distributed systems have the potentiality of becoming an alternative platform for parallel computations. However, there are still many obstacles to overcome, one of the most serious is that distributed systems typically consist of shared heterogeneous components with highly variable computational power. We present a load balancing support that checks the load status and, if necessary, adapts the workload to dynamic platform conditions through data migrations from overloaded to underloaded nodes. Unlike task migration supports for task parallelism and other data migration frameworks for master/slave-based parallel applications, our support works for the entire class of SPMD regular applications with explicit communications such as linear algebra problems, partial differential equation solvers, image processing algorithms. Although we considered several variants (three activation mechanisms, three load monitoring techniques and four decision policies), we implemented only the protocols that guarantee program consistency. The efficiency of the strategies is tested in the instance of two SPMD algorithms that are based on the PVM library enriched by special-purpose primitives for data management. As additional contribution, our research keeps the entire support for dynamic load balancing transparent to the programmer. The only visible interface of our support is the activation phase.},
  keywords={},
  doi={10.1109/HCW.1997.581406},
  ISSN={},
  month={April},}
@INPROCEEDINGS{581423,
  author={Morariu, V. and Cunningham, M. and Letterman, M.},
  booktitle={Proceedings Sixth Heterogeneous Computing Workshop (HCW'97)}, 
  title={A performance and portability study of parallel applications using a distributed computing testbed}, 
  year={1997},
  volume={},
  number={},
  pages={222-231},
  abstract={A case study was conducted to examine the performance and portability of parallel applications, with an emphasis on data transfer among the processors in heterogeneous environments. Several parallel test programs using MPICH, a message passing interface (MPI) library, and the Linda parallel environment were developed to analyze communication performance and portability. These programs implement loosely and tightly synchronized communication models in which each processor exchanges data with two other processors. This data-exchange pattern mimics communication in certain parallel applications using striped partitioning of the computational domain. Tests were performed on an isolated, distributed computing testbed, a live development network and a symmetrical multiprocessing computer system. All network configurations used asynchronous transfer mode (ATM) network technologies. The testbed used in the study was a heterogeneous network consisting of various workstations and networking equipment. This paper presents an analysis of the results and recommendations for designing and implementing course-grained, parallel, scientific applications.},
  keywords={},
  doi={10.1109/HCW.1997.581423},
  ISSN={},
  month={April},}
@INPROCEEDINGS{581421,
  author={Maheshwari, P. and Ouyang, J.},
  booktitle={Proceedings Sixth Heterogeneous Computing Workshop (HCW'97)}, 
  title={Supporting fault-tolerance in heterogeneous distributed applications}, 
  year={1997},
  volume={},
  number={},
  pages={195-207},
  abstract={Heterogeneous computing opens up new challenges and opportunities in fields such as parallel and distributed processing, design of algorithms for applications, scheduling of parallel tasks, interconnection network technology and support for reliable distributed heterogeneous computing. A trend of supporting fault-tolerance in distributed computing systems is to incorporate fault-tolerance into applications at low cost, in terms of both run time performance and programming effort required to construct reliable application software. We present an approach for developing efficient reliable distributed applications for heterogeneous computing systems. We propose a library prototype, called H-Libra, to support fault-tolerance in heterogeneous systems with low run-time cost. Fault-tolerance is based on distributed consistent checkpointing and rollback-recovery integrated with a user-level network communication protocol. By employing novel mechanisms, minimum communication overhead is involved for taking a consistent distributed checkpoint and catching messages in transit during a checkpoint. By providing fault-tolerance transparency and a simple, easy to use high-level message-passing interface, H-Libra simplifies the development of reliable heterogeneous distributed applications.},
  keywords={},
  doi={10.1109/HCW.1997.581421},
  ISSN={},
  month={April},}
@INPROCEEDINGS{586486,
  author={Shaikh, S.A. and Szygenda, S.A.},
  booktitle={Proceedings of 1997 SCS Simulation Multiconference}, 
  title={Exploiting component/event-level parallelism in concurrent fault and design error simulation}, 
  year={1997},
  volume={},
  number={},
  pages={64-74},
  abstract={The paper describes the algorithm CON/sup 2/FERS, which exploits the event level and component level parallelisms in the concurrent technique for fault and design error simulation. This algorithm assumes asynchronous, message based operation with NORMA, and MIMD models of programming. A design verification tool based on this algorithm is developed with object oriented methodology using C++ and PVM. This implementation is executable on any Network of Workstations (NOW) and/or any general purpose parallel machine. The statistics on fault and error simulation performance and load balancing for some benchmark circuits are presented. Various experimental results of the effect of network and load on the performance of the CON/sup 2/FERS, and the applicability of the algorithm for the hardware acceleration of CFES are also presented.},
  keywords={},
  doi={10.1109/SIMSYM.1997.586486},
  ISSN={1080-241X},
  month={April},}
@INPROCEEDINGS{586449,
  author={Frazier, T.M. and Tamir, Y.},
  booktitle={Proceedings of 1997 SCS Simulation Multiconference}, 
  title={Execution-driven simulation of error recovery techniques for multicomputers}, 
  year={1997},
  volume={},
  number={},
  pages={4-13},
  abstract={DERT (Distributed Error Recovery Testbed) is a testbed for simulation and performance evaluation of several classes of application-transparent distributed error recovery schemes. DERT is built on top of an event-driven, message-passing, object-oriented, multithreaded simulation kernel. Actual compiled distributed applications are instrumented for data collection and executed on the simulated multicomputer. Checkpointing is implemented in full detail, including associated overhead per message, additional messages, and changes to the memory system. DERT allows easy modification of a wide variety of system parameters, thus offering a level of flexibility not easily achieved by experimentation on a particular real machine. This paper describes the design, functionality, and performance of DERT. The main problems encountered in DERT's development are discussed, as well as examples of its use in evaluating recovery schemes.},
  keywords={},
  doi={10.1109/SIMSYM.1997.586449},
  ISSN={1080-241X},
  month={April},}
@ARTICLE{588280,
  author={Cordsen, J. and Garnatz, T. and Sander, M. and Gerischer, A. and Gubitoso, M.D. and Haack, U. and Schroder-Preikchat, W.},
  journal={IEEE Concurrency}, 
  title={Vote for peace: implementation and performance of a parallel operating system}, 
  year={1997},
  volume={5},
  number={2},
  pages={16-27},
  abstract={Vote, a virtual shared-memory system and an extension to the Peace parallel operating system, provides architectural transparency and efficiency to effectively solve HPC problems.},
  keywords={},
  doi={10.1109/4434.588280},
  ISSN={1558-0849},
  month={April},}
@ARTICLE{588521,
  author={Holzmann, G.J.},
  journal={IEEE Transactions on Software Engineering}, 
  title={The model checker SPIN}, 
  year={1997},
  volume={23},
  number={5},
  pages={279-295},
  abstract={SPIN is an efficient verification system for models of distributed software systems. It has been used to detect design errors in applications ranging from high-level descriptions of distributed algorithms to detailed code for controlling telephone exchanges. The paper gives an overview of the design and structure of the verifier, reviews its theoretical foundation, and gives an overview of significant practical applications.},
  keywords={},
  doi={10.1109/32.588521},
  ISSN={1939-3520},
  month={May},}
@ARTICLE{588294,
  author={Richard, G.G. and Singhal, M.},
  journal={IEEE Concurrency}, 
  title={Using vector time to handle multiple failures in distributed systems}, 
  year={1997},
  volume={5},
  number={2},
  pages={50-59},
  abstract={To speed up the consistent-state restoration of distributed systems, complete process recovery uses vector time to address unorthodox message-handling issues and overlapping failures.},
  keywords={},
  doi={10.1109/4434.588294},
  ISSN={1558-0849},
  month={April},}
@ARTICLE{589204,
  author={Moga, A.N. and Gabbouj, M.},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Parallel image component labelling with watershed transformation}, 
  year={1997},
  volume={19},
  number={5},
  pages={441-450},
  abstract={The parallel watershed transformation used in gray scale image segmentation is reconsidered on the basis of the component labeling problem. The main idea is to break the sequentiality of the watershed transformation and to correctly delimit the extent of all connected components locally, on each processor, simultaneously. The internal fragmentation of the catchment basins, due to domain decomposition, into smaller subcomponents is finally solved by employing a global connected components operator. Therefore, in a pyramidal structure of master-slave processors, internal contours of adjacent subcomponents within the same component are hierarchically removed. Global final connected areas are efficiently obtained in log/sub 2/ N steps on a logical grid of N processors. Timings and segmentation results of the algorithm built on top of the message passing interface and tested on the Gray T3D are brought forward to justify the superiority of the novel design solution compared against previous implementations.},
  keywords={},
  doi={10.1109/34.589204},
  ISSN={1939-3539},
  month={May},}
@INPROCEEDINGS{592210,
  author={Choong-Sik Kim and Wan-Jin Chung and Chin-Young Lee},
  booktitle={Proceedings High Performance Computing on the Information Superhighway. HPC Asia '97}, 
  title={The parallelization of implicit code for springback analysis}, 
  year={1997},
  volume={},
  number={},
  pages={568-572},
  abstract={The parallelization of methods of implicit code for springback analysis have been carried out by using NX library. The program based on Fortran uses two large one-dimensional arrays for efficient memory usage, but this scheme makes the parallelization more difficult. Two main parts are parallelized: one is the formation of the global stiffness and force matrix from element matrices; and the other is the parallelization of a skyline solver based on Crout factorization. By distributing the skylined matrix in a slabbed and interleaving way, we succeeded in making an improvement to the load balance between processors and increasing parallelization efficiency. The benchmarking results show that the parallelized program running on 32 processors gives a speedup of about 20 times faster than the serial program running on an Intel Paragon.},
  keywords={},
  doi={10.1109/HPC.1997.592210},
  ISSN={},
  month={April},}
@INPROCEEDINGS{594583,
  author={Krishnaswamy, D. and Banerjee, P. and Rudnick, E.M. and Patel, J.H.},
  booktitle={Proceedings 11th Workshop on Parallel and Distributed Simulation}, 
  title={Asynchronous parallel algorithms for test set partitioned fault simulation}, 
  year={1997},
  volume={},
  number={},
  pages={30-37},
  abstract={We propose two new asynchronous parallel algorithms for test set partitioned fault simulation. The algorithms are based on a new two-stage approach to parallelizing fault simulation for sequential VLSI circuits in which the test set is partitioned among the available processors. These algorithms provide the same result as the previous synchronous two stage approach. However, due to the dynamic characteristics of these algorithms and due to the fact that there is very minimal redundant work, they run faster than the previous synchronous approach. A theoretical analysis comparing the various algorithms is also given to provide an insight into these algorithms. The implementations were done in MPI and are therefore portable to many parallel platforms. Results are shown for a shared memory multiprocessor.},
  keywords={},
  doi={10.1109/PADS.1997.594583},
  ISSN={},
  month={June},}
@INPROCEEDINGS{596827,
  author={Frey, M. and Oberhuber, M.},
  booktitle={Proceedings of PDSE '97: 2nd International Workshop on Software Engineering for Parallel and Distributed Systems}, 
  title={Testing parallel and distributed programs with temporal logic specifications}, 
  year={1997},
  volume={},
  number={},
  pages={62-72},
  abstract={This paper presents a new approach for testing parallel and distributed programs based on specifications. The requirements are formulated in temporal logic. The description of test cases is extended by control patterns enabling to cope with the demands of parallel applications. For the formulation of these patterns, an abstract execution model called POEM is introduced. After executing a parallel program with respect to a test case specification and its patterns, the resulting trace is checked against the temporal logic specification of the predefined requirements.},
  keywords={},
  doi={10.1109/PDSE.1997.596827},
  ISSN={},
  month={May},}
@INPROCEEDINGS{596834,
  author={Jin Song Dong and Lin Zucconi and Duke, R.},
  booktitle={Proceedings of PDSE '97: 2nd International Workshop on Software Engineering for Parallel and Distributed Systems}, 
  title={Specifying parallel and distributed systems in Object-Z: the lift case study}, 
  year={1997},
  volume={},
  number={},
  pages={140-149},
  abstract={There has been an increasing emphasis on formality in software system specification in the last few years. A number of standards bodies are recommending the use of formal notations for specifying software systems. Parallel and distributed systems have their own complex features such as: the concurrent interactions between various system components; the reactive nature of the systems; various message passing schemes between system components. Object-Z is an extension to the Z language specifically to facilitate specification in an object-oriented style. Because parallel and distributed systems are typically complex systems, the extra structuring afforded by the various Object-Z modelling constructs (i.e. the class, object containment constructs, and various composite operation expressions) enables the various hierarchical relationships and the communication between system components to be succinctly specified. Object-Z history invariants allow system temporal properties to be specified as well. The use of Object-Z in the specification of parallel and distributed systems is demonstrated by presenting a case study based on a multi-lift system. To enhance the understandability of the formal model, OMT notation is used to grasp the static structure of the system, and a finite state machine diagram is used to highlight the system behaviour.},
  keywords={},
  doi={10.1109/PDSE.1997.596834},
  ISSN={},
  month={May},}
@INPROCEEDINGS{596826,
  author={Kuo-Chung Tai},
  booktitle={Proceedings of PDSE '97: 2nd International Workshop on Software Engineering for Parallel and Distributed Systems}, 
  title={Reachability testing of asynchronous message-passing programs}, 
  year={1997},
  volume={},
  number={},
  pages={50-61},
  abstract={An execution of a message-passing program P with input X exercises a sequence of send and receive events, called a send-receive sequence (or SR-sequence). Assume that every execution of P with input X terminates. Reachability testing of P with input X is to execute all possible SR-sequences of P with input X. To perform reachability testing of P with input X, we first execute P with input X to collect one or more SR-sequences. For each collected SR-sequence, we identify its race conditions and derive its race-variants by modifying the outcome of race conditions. These race-variants are prefixes of other SR-sequences of P with input X. We use these race-variants to force P with input X to produce additional SR-sequences. By repeating this process, we eventually collect all possible SR-sequences of P with input X and thus can determine the correctness of P with input X. In this paper, we show derivation of race-variants of SR-sequences based on asynchronous communication and give an algorithm for reachability testing of asynchronous message-passing programs.},
  keywords={},
  doi={10.1109/PDSE.1997.596826},
  ISSN={},
  month={May},}
@ARTICLE{598280,
  author={Ho-Fung Leung and Hing-Fung Ting},
  journal={IEEE Transactions on Parallel and Distributed Systems}, 
  title={An optimal algorithm for global termination detection in shared-memory asynchronous multiprocessor systems}, 
  year={1997},
  volume={8},
  number={5},
  pages={538-543},
  abstract={In the literature, the problem of global termination detection in parallel systems is usually solved by message passing. In shared-memory systems, this problem can also be solved by using exclusively accessible variables with locking mechanisms. In this paper, we present an algorithm that solves the problem of global termination detection in shared-memory asynchronous multiprocessor systems without using locking. We assume a reasonable computation model in which concurrent reading does not require locking and concurrent writing different values without locking results in an arbitrary one of the values being actually written. For a system of n processors, the algorithm allocates a working space of 2n+1 bits. The worst case time complexity of the algorithm is n+2/spl radic/+1, which we prove is the lower bound under a reasonable model of computation.},
  keywords={},
  doi={10.1109/71.598280},
  ISSN={1558-2183},
  month={May},}
@INPROCEEDINGS{598047,
  author={Kuo-Chung Tai},
  booktitle={Proceedings of 17th International Conference on Distributed Computing Systems}, 
  title={Race analysis of traces of asynchronous message-passing programs}, 
  year={1997},
  volume={},
  number={},
  pages={261-268},
  abstract={An execution of a message-passing program is nondeterministic if message races exist. In this paper, a formal definition of a message race for asynchronous communication is presented. The trace of an execution of a message-passing program is a sequence of send and receive events. For a receive event r in a trace T, its race set is the set of messages in T that have a race with the message received at r and can be received at r during some possible executions of the same program with the same input. A race analysis algorithm analyzes a trace to determine the race set for each receive event in the trace. Three race analysis algorithms are given for three different types of sequences of send and receive events. It is shown that these race analysis algorithms can be used to solve a number of problems in testing and debugging message-passing programs.},
  keywords={},
  doi={10.1109/ICDCS.1997.598047},
  ISSN={1063-6927},
  month={May},}
@INPROCEEDINGS{598041,
  author={Ricciardi, A.},
  booktitle={Proceedings of 17th International Conference on Distributed Computing Systems}, 
  title={The Sage project: a new approach to software engineering for distributed applications}, 
  year={1997},
  volume={},
  number={},
  pages={244-252},
  abstract={We describe the Sage project, a new approach to software engineering for (fault-tolerant) distributed applications. Sage uses the modal logic of knowledge and applies theoretical results detailing how processes learn facts about each other's state to derive the minimal communication graph for a wide range of coordination problems. The specification interface is controlled, yet expressive enough to capture important distributed coordination problems and weaker variants appropriate for wide-area applications. The resulting graphical display shows programmers which messages must be received. Sage allows users to experiment on the derived protocol by crashing processes, reordering events, losing messages, and partitioning the network. If a solution still exists, Sage regenerates the communication graph. This animates the effects of unpredictable system events on distributed applications, and separates the issues in testing a protocol's behavior in the face of failures, from the effects background system conditions can have on the testing procedure itself.},
  keywords={},
  doi={10.1109/ICDCS.1997.598041},
  ISSN={1063-6927},
  month={May},}
@INPROCEEDINGS{726888,
  author={Hong, C. and Shen, C.M.},
  booktitle={1997 Fourth International Conference on Advances in Power System Control, Operation and Management, APSCOM-97. (Conf. Publ. No. 450)}, 
  title={Parallel transient stability analysis on distributed memory message passing multiprocessors}, 
  year={1997},
  volume={1},
  number={},
  pages={304-309 vol.1},
  abstract={This paper presents a new parallel-in-space algorithm for power system transient stability simulations. The nonlinear differential equations are discretized by applying the trapezoidal rule and solved together with the nonlinear algebraic equations for each time step. A network partitioning scheme, which is based on the subdivision of the factorization path tree of the network matrix, is proposed to exploit the parallelism-in-space of the transient stability problem. The parallel version of the very dishonest Newton (VDHN) method, in which the parallel algorithm for solving large sparse network matrix equations is incorporated, is developed and tested on a distributed memory message passing multicomputer. Test results on a sample power system are presented to show the performance of the proposed algorithm.},
  keywords={},
  doi={10.1049/cp:19971849},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{1592595,
  author={Hatay, F.F. and Jespersen, D.C. and Guruswamy, G.P. and Rizk, Y.M. and Chansup Byun and Ken Gee},
  booktitle={SC '97: Proceedings of the 1997 ACM/IEEE Conference on Supercomputing}, 
  title={A multi-level parallelization concept for high-fidelity multi-block solvers}, 
  year={1997},
  volume={},
  number={},
  pages={14-14},
  abstract={The integration of high-fidelity Computational Fluid Dynamics (CFD) analysis tools with the industrial design process benefits greatly from the robust implementations that are transportable across a wide range of computer architectures. In the present work, a hybrid domain-decomposition and parallelization concept was developed and implemented into the widely-used NASA multi-block Computational Fluid Dynamics (CFD) solvers employed in ENSAERO and OVERFLOW advanced flow analysis packages. These advanced engineering and scientific analysis packages include more than 300,000 lines of code written in FORTRAN 77 language in more than 1300 individual subprograms. The new parallel solver concept, PENS (Parallel Euler Navier-Stokes Solver), employs both fine and coarse granularity with data partitioning as well as data coalescing to obtain the desired load-balance characteristics on the available computer platforms for these legacy packages. This multi-level parallelism implementation itself introduces no changes to the numerical results, hence the original fidelity of the packages are identically preserved. The present implementation uses the Message Passing Interface (MPI) library for interprocessor message passing and memory accessing. By choosing an appropriate combination of the available partitioning and coalescing possibilities only during the execution stage, the PENS solver is used on different computer architectures from shared-memory to distributed-memory platforms with varying degrees of parallelism. Improvements in computational load-balance and speeds are extremely crucial on the realistic problems in the design of aerospace vehicles. The PENS implementation on the IBM SP2 distributed memory environment at the NASA Ames Research Center obtains 85 percent scalable parallel performance using fine-grain partitioning of single-block CFD domains using up to 128 wide computational nodes. Multi-block CFD simulations of complete aircraft geometries achieve 85 percent perfect load-balanced executions using data coalescing and the two levels of parallelism. SGI PowerChallenge, SGI Onyx2, and Cray T3E are the other platforms where the robustness, performance behavior, and the parallel scalability of the implementation are tested and fine-tuned for actual production run environments.},
  keywords={},
  doi={10.1145/509593.509607},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{1592597,
  author={Nucciarone, J.J. and Ozyoruk, Y. and Long, L.N.},
  booktitle={SC '97: Proceedings of the 1997 ACM/IEEE Conference on Supercomputing}, 
  title={New Life in Dusty Decks: Results of Porting a CM Fortran Based Aeroacoustic Model to High Performance Fortran}, 
  year={1997},
  volume={},
  number={},
  pages={16-16},
  abstract={The High Performance Fortran language is a 'standard by consensus', developed by individuals and vendors in the high performance computing industry, to provide a low barrier entry to parallel computing. It promises to be an easier to use development environment for distributed memory computing platforms compared to the programming complexity required by message passing libraries such as PVM and MPI. HPF promises much and is still in its infancy. Since HPF was developed in part based on experiences gained with early parallel Fortran compilers such as Thinking Machines CM Fortran, we decided to test the effectiveness of HPF with today's generation of HPF compilers by porting a complex existing model code originally developed using CM Fortran. The model code that we selected is a hybrid computational aeroacoustics code that solves the 3D, time-dependent Euler equations in the near flow field and uses a moving surface Kirchhoff's formula to predict the far field sound radiating from turbofan engine inlets. The original CM Fortran model code was developed on a Thinking Machines CM5. The extensive production research use of this model, using varying grid sizes, provides excellent benchmarks with which to compare the HPF port. Two HPF compilers were selected in the porting effort -- The Portland Group's (PGI) pghpf and the xlhpf compiler from IBM. IBM's xlhpf does not implement some elements of the HPF subset while PGI's offering provides several full-HPF extensions. porting efforts using each compiler exposed the strengths and weaknesses of each. Porting this complex code exposed many of the growing pains associated with the current generation of compilers. Critical sections of the code will be explained and these critical areas of the conversion effort will be discussed. Where necessary we will demonstrate how different porting strategies affected the performance of the code. Finally we will present how the ported code ran, using a varying number of processors, on an IBM SP2 and an SGI Origin 2000. While the current simple port does not match the speed of a CM-5, we hope further porting efforts and improved compiler technology will enable us to eventually match and then surpass CM-5 performance levels. With the shutdown of the NCSA CM-5 and the eventual removal and failure of the remaining Thinking Machines hardware currently installed, this effort will demonstrate that investments in CM Fortran code need not be abandoned and that new life can be breathed into those dusty decks.},
  keywords={},
  doi={10.1145/509593.509609},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{1592614,
  author={Yuqun Chen and Kai Li and Plank, J.S.},
  booktitle={SC '97: Proceedings of the 1997 ACM/IEEE Conference on Supercomputing}, 
  title={CLIP: A Checkpointing Tool for Message Passing Parallel Programs}, 
  year={1997},
  volume={},
  number={},
  pages={33-33},
  abstract={Checkpointing is a useful technique for rollback recovery. We present CLIP, a user-level library that provides semi-transparent checkpointing for parallel programs on the Intel Paragon multicomputer. Creating an actual tool for checkpointing a complex machine like the Paragon is not easy, because many issues arise that require careful design decisions to be made. We detail what these decisions are, and how they were made in CLIP. We present performance data when checkpointing several long-running parallel applications. These results show that a convenient, general-purpose checkpointing tool like CLIP can provide fault-tolerance on a massively parallel multicomputer with good performance.},
  keywords={},
  doi={},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{1592613,
  author={Naik, V.K. and Midkiff, S.P. and Moreira, J.E.},
  booktitle={SC '97: Proceedings of the 1997 ACM/IEEE Conference on Supercomputing}, 
  title={A Checkpointing Strategy for Scalable Recovery on Distributed Parallel Systems}, 
  year={1997},
  volume={},
  number={},
  pages={32-32},
  abstract={We describe a checkpoint/recovery scheme suitable for message-passing parallel applications. The novelty of our scheme is that checkpointed applications can be restored, from their checkpointed state, in reconfigured forms. Using this scheme, applications can quickly recover from partial system failures. A key component of our implementation is the distribution- independent representation of application array data structures in persistent storage. To further optimize the performance, we provide parallel array section streaming operations for distributed arrays. We compare the performance of the reconfigurable checkpoint/restart of parallel applications with that of conventional forms of checkpointing.},
  keywords={},
  doi={10.1145/509593.509625},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{659881,
  author={Hyosun Ko and Latifi, S. and Srimani, P.K.},
  booktitle={1998 IEEE International Performance, Computing and Communications Conference. Proceedings (Cat. No.98CH36191)}, 
  title={Near optimal broadcast in all-port wormhole routed hypercubes using error correcting codes}, 
  year={1998},
  volume={},
  number={},
  pages={8-14},
  abstract={A new broadcasting method is presented for hypercubes with wormhole routing mechanism. The approach is based on determination of the set of nodes (called stations) in the hypercube such that for any node in the network there is a station at distance of at most 1. Once stations are identified, parallel disjoint paths are formed from the source to all stations. The broadcasting is accomplished first by sending the message to all stations which will in turn inform the rest of the nodes of the message. To establish node-disjoint paths between the source node and all stations, we introduce a new routing strategy. We prove that multicasting can be done in one routing step as long as the number of destination nodes are fewer than or equal to n in an n-dimensional hypercube. The number of broadcasting steps using our routing is equal to or smaller than that obtained in an earlier work.},
  keywords={},
  doi={10.1109/PCCC.1998.659881},
  ISSN={1097-2641},
  month={Feb},}
@INPROCEEDINGS{659892,
  author={Hurfin, M. and Raynal, M. and Tronel, F.},
  booktitle={1998 IEEE International Performance, Computing and Communications Conference. Proceedings (Cat. No.98CH36191)}, 
  title={A practical building block for solving agreement problems in asynchronous distributed systems}, 
  year={1998},
  volume={},
  number={},
  pages={25-31},
  abstract={Providing processes with the same view of a global state or allowing them to take consistent decisions, despite asynchrony and failure occurrences, are fundamental problems encountered in distributed systems. These problems are called agreement problems. Non blocking atomic commitment and definition of a single delivery order for broadcast messages are examples of such problems. We define a paradigm (called Single Global View) that encompasses various practical agreement problems. The interest of this paradigm lies in its practicability: each process starts with an initial value, and all these values are pieced together in such a way that, despite process crashes and asynchrony, all correct processes are delivered the same set of values (namely, the Single Global View). The power of this paradigm is the same as that of the consensus problem defined by theoreticians. Instantiations of the paradigm, which solve practical agreement problems, are given. A protocol implementing the paradigm is also presented.},
  keywords={},
  doi={10.1109/PCCC.1998.659892},
  ISSN={1097-2641},
  month={Feb},}
@INPROCEEDINGS{647174,
  author={Rodriguez, A. and de la Fraga, L.G. and Zapata, E.L. and Carazo, J.M. and Trelles, O.},
  booktitle={Proceedings of the Sixth Euromicro Workshop on Parallel and Distributed Processing - PDP '98 -}, 
  title={Biological sequence analysis on distributed-shared memory multiprocessors}, 
  year={1998},
  volume={},
  number={},
  pages={20-26},
  abstract={In this paper we present a task-level implementation of several biological sequence analysis algorithms on distributed-shared memory multiprocessors. All the studied algorithms are computationally expensive and its computational patterns ranges from regular to very irregularly structured ones. An initial approach to evaluate the regularity level for this kind of algorithms based on the rate of free-dependent tasks, the data access pattern and the task homogeneity, is presented in this study. Extensive tests have been performed over different architectures using message-passing and thread-based programming models. A comparative analysis centered on performance and portability is also presented. The results give us a general knowledge about software portability and performance for algorithms on this area.},
  keywords={},
  doi={10.1109/EMPDP.1998.647174},
  ISSN={},
  month={Jan},}
@INPROCEEDINGS{647217,
  author={Clematis, A. and Deconinck, G. and Gianuzzi, V.},
  booktitle={Proceedings of the Sixth Euromicro Workshop on Parallel and Distributed Processing - PDP '98 -}, 
  title={A flexible state-saving library for message-passing systems}, 
  year={1998},
  volume={},
  number={},
  pages={335-341},
  abstract={Message passing applications on a distributed computer require tools to integrate state saving and rollback, to support dynamic program reconfiguration, fault tolerance and others. The paper presents the results of integrating two independently developed tools that combine flexibility and portability. The User-Triggered CheckPointing (UTCP) provides checkpointing and recovery while relying on the programmer to indicate the position of the recovery line and the contents of the checkpoint. The tool PVMsnap provides an extension to PVM to obtain a consistent cut of the message passing application. The combination of both tools results in a portable and flexible solution for fault tolerance which can be adapted to the applications' needs.},
  keywords={},
  doi={10.1109/EMPDP.1998.647217},
  ISSN={},
  month={Jan},}
@INPROCEEDINGS{647210,
  author={Supalov, A.V. and Thole, C.-A.},
  booktitle={Proceedings of the Sixth Euromicro Workshop on Parallel and Distributed Processing - PDP '98 -}, 
  title={PARASOL interface to new parallel solvers: a case study}, 
  year={1998},
  volume={},
  number={},
  pages={279-285},
  abstract={The paper presents an overview of the PARASOL interface and its potential impact on facilitating transfer of technology from the academic researchers to the industrial end users. The PARASOL project aims at developing scalable direct and iterative solvers and testing them on real problems with respect to applicability and robustness in the industrial applications such as linear structural analysis (MSC/NASTRAN and SESAM), simulation of nonlinear forming and deformation processes (ARC3D and INDEED), and modeling of incompressible viscous flow (POLYFLOW).},
  keywords={},
  doi={10.1109/EMPDP.1998.647210},
  ISSN={},
  month={Jan},}
@INPROCEEDINGS{657550,
  author={Desel, G. and Kindler, E.},
  booktitle={Proceedings 1998 International Conference on Application of Concurrency to System Design}, 
  title={Proving correctness of distributed algorithms using high-level Petri nets-a case study}, 
  year={1998},
  volume={},
  number={},
  pages={177-186},
  abstract={We argue that high-level Petri nets are well suited for the representation of distributed algorithms as well as for correctness proofs. To this end, we provide a simple definition of high-level Petri nets, a way to formulate message passing algorithms in this notion, a temporal logic style language for the formulation of properties, and a proof technique which combines techniques from Petri net theory and from temporal logic. As a nontrivial case study we present a variant of Raymond's (1989) message passing mutual exclusion algorithm that works on arbitrary connected networks.},
  keywords={},
  doi={10.1109/CSD.1998.657550},
  ISSN={},
  month={March},}
@ARTICLE{664653,
  author={MacLeod, I.M. and Stothert, A.},
  journal={IEEE Control Systems Magazine}, 
  title={Distributed intelligent control for a mine refrigeration system}, 
  year={1998},
  volume={18},
  number={2},
  pages={31-38},
  abstract={One way to construct intelligent controllers is to use an agent-centered approach in which the agents themselves determine the global structure of the controller and the inter-agent cooperation methods. To assess this approach, the design and testing of a distributed intelligent controller for a laboratory-scale mine refrigeration plant is discussed. Underlying theoretical concepts are briefly reviewed, and experimental results are presented. Important findings are that the approach supports the use of multiple knowledge representations, the use of partial results, and dynamic structuring of the distributed controller. The results presented indicate that development for practical, supervisory-level control applications is worthy of further investigation.},
  keywords={},
  doi={10.1109/37.664653},
  ISSN={1941-000X},
  month={April},}
@INPROCEEDINGS{666551,
  author={Sung-Yong Park and Joohan Lee and Hariri, S.},
  booktitle={Proceedings Seventh Heterogeneous Computing Workshop (HCW'98)}, 
  title={An efficient group communication architecture over ATM networks}, 
  year={1998},
  volume={},
  number={},
  pages={130-141},
  abstract={NYNET (ATM wide-area network testbed in New York state) Communication System (NCS) is a multithreaded message-passing tool developed at Syracuse University that provides low-latency and high-throughput communication services over Asynchronous Transfer Mode (ATM)-based high-performance distributed computing (HPDC) environments. NCS provides flexible and scalable group communication services based on dynamic grouping and tree-based multicasting. The NCS architecture, which separates the data and control functions, allows group operations to be implemented efficiently by utilizing the control connections when transferring status information (e.g. topology information, routing information). Furthermore, NCS provides several different algorithms for group communication and allows programmers to select an appropriate algorithm at runtime. The authors overview the general architecture of NCS and present the multicasting services provided by NCS. They analyze and compare the performance of NCS with that of other message-passing tools such as p4, PVM, and MPI in terms of primitive performance and performance.},
  keywords={},
  doi={10.1109/HCW.1998.666551},
  ISSN={1097-5209},
  month={March},}
@INPROCEEDINGS{666549,
  author={Hoyas-Rivera, G. and Martinez-Gonzalaz, E. and Rios-Rigueroa, H.V. and Sanchez-Arias, V.G. and Acosta-Mesa, H.G. and Lopez-Benitez, N.},
  booktitle={Proceedings Seventh Heterogeneous Computing Workshop (HCW'98)}, 
  title={Specification and control of cooperative work in a heterogeneous computing environment}, 
  year={1998},
  volume={},
  number={},
  pages={102-114},
  abstract={The implementation of an interface to support cooperative work in a heterogeneous completing environment is based on previously proposed definitions referred to as the cooperative work model (CWM) and cooperative work language (CWL). The interface for cooperative work (ICW) and the graphical interface for cooperative work (GICW) are the main two components of a tool useful in the set up and control of a cooperative working environment in a general purpose heterogeneous computing platform. This tool is described as well as some desired characteristics to improve its effectiveness. The specification and control of a virtual parallel machine are illustrated with an algorithm for 3D-reconstruction from two stereoscopic images. Test results on this application are also reported.},
  keywords={},
  doi={10.1109/HCW.1998.666549},
  ISSN={1097-5209},
  month={March},}
@INPROCEEDINGS{666792,
  author={Caughey, S.J. and Little, M.C. and Shrivastava, S.K.},
  booktitle={Proceedings First International Symposium on Object-Oriented Real-Time Distributed Computing (ISORC '98)}, 
  title={Checked transactions in an asynchronous message passing environment}, 
  year={1998},
  volume={},
  number={},
  pages={222-229},
  abstract={Traditionally transactions have been single-threaded. In such an environment the thread terminating the transaction is, by definition, the thread which performed the work. Therefore, transaction termination is implicitly synchronised with the completion of the transactional work. With the increased availability of both software and hardware multi-threading, transaction services are being required to allow multiple threads to be active within a transaction. In these systems it is important to guarantee that all threads have completed when a transaction is terminated otherwise some work may not be performed transactionally. In this paper we present a protocol for the enforcement of checked transactional behaviour within an asynchronous environment. We illustrate the use of the protocol within a proposed implementation for a CORBA-compliant Object Transaction Service intended for a soft real-time application which makes extensive use of concurrency and asynchronous message passing.},
  keywords={},
  doi={10.1109/ISORC.1998.666792},
  ISSN={},
  month={April},}
@INPROCEEDINGS{669925,
  author={Lumetta, S.S. and Culler, D.E.},
  booktitle={Proceedings of the First Merged International Parallel Processing Symposium and Symposium on Parallel and Distributed Processing}, 
  title={Managing concurrent access for shared memory active messages}, 
  year={1998},
  volume={},
  number={},
  pages={272-278},
  abstract={Passing messages through shared memory plays an important role in symmetric multiprocessors and on Clumps. The management of concurrent access to message queues is an important aspect of design for shared memory message passing systems. Using both microbenchmarks and applications, the paper compares the performance of concurrent access algorithms for passing active messages on a Sun Enterprise 5000 server. The paper presents a new lock free algorithm that provides many of the advantages of non blocking algorithms while avoiding the overhead of true non blocking behavior. The lock free algorithm couples synchronization tightly to the data structure and demonstrates application performance superior to all others studied. The success of this algorithm implies that other practical problems might also benefit from a reexamination of the non blocking literature.},
  keywords={},
  doi={10.1109/IPPS.1998.669925},
  ISSN={1063-7133},
  month={March},}
@INPROCEEDINGS{669961,
  author={Juurlink, B.H.H.},
  booktitle={Proceedings of the First Merged International Parallel Processing Symposium and Symposium on Parallel and Distributed Processing}, 
  title={Experimental validation of parallel computation models on the Intel Paragon}, 
  year={1998},
  volume={},
  number={},
  pages={492-497},
  abstract={Experimental data validating some of the proposed parallel computation models on the Intel Paragon is presented. This architecture is characterized by a large bandwidth and a relatively large startup cost of a message transmission, which makes it extremely important to employ bulk transfers. The models considered are the BSP model, in which it is assumed that all messages have a fixed short size, and the BPRAM, in which block transfers are rewarded.},
  keywords={},
  doi={10.1109/IPPS.1998.669961},
  ISSN={1063-7133},
  month={March},}
@INPROCEEDINGS{669896,
  author={Hovland, P. and Bischof, C.},
  booktitle={Proceedings of the First Merged International Parallel Processing Symposium and Symposium on Parallel and Distributed Processing}, 
  title={Automatic differentiation for message-passing parallel programs}, 
  year={1998},
  volume={},
  number={},
  pages={98-104},
  abstract={Many applications require the derivatives of functions defined by computer programs. Automatic differentiation (AD) is a means of developing code to compute the derivatives of complicated functions accurately and efficiently without the difficulties associated with developing correct code by hand. We discuss some of the issues involved in developing automatic differentiation tools for parallel programming environments.},
  keywords={},
  doi={10.1109/IPPS.1998.669896},
  ISSN={1063-7133},
  month={March},}
@INPROCEEDINGS{670018,
  author={Mueller, F.},
  booktitle={Proceedings of the First Merged International Parallel Processing Symposium and Symposium on Parallel and Distributed Processing}, 
  title={Prioritized token-based mutual exclusion for distributed systems}, 
  year={1998},
  volume={},
  number={},
  pages={791-795},
  abstract={A number of solutions have been proposed for the problem of mutual exclusion in distributed systems. Some of these approaches have since been extended to a prioritized environment suitable for real-time applications but impose a higher message passing overhead than our approach. We present a new protocol for prioritized mutual exclusion in a distributed environment. Our approach uses a token-based model working on a logical tree structure, which is dynamically modified. In addition, we utilize a set of local queues whose union would resemble a single global queue. Furthermore, our algorithm is designed for out-of-order message delivery, handles messages asynchronously and supports multiple requests from one node for multi-threaded nodes. The prioritized algorithm has an average overhead of O(log(n)) messages per request for mutual exclusion with a worst-case overhead of O(n), where n represents the number of nodes in the system. Thus, our prioritized algorithm matches the message complexity of the best non-prioritized algorithms while previous prioritized algorithms have a higher message complexity, to our knowledge. Our concept of local queues can be incorporated into arbitrary token-based protocols with or without priority support to reduce the amount of messages. Performance results indicate that the additional functionality of our algorithm comes at the cost of 30% longer response times within our test environment for distributed execution when compared with an unprioritized algorithm. This result suggests that the algorithm should be used when strict priority ordering is required.},
  keywords={},
  doi={10.1109/IPPS.1998.670018},
  ISSN={1063-7133},
  month={March},}
@INPROCEEDINGS{674177,
  author={Fenwick, J.B. and Pollock, L.L.},
  booktitle={Proceedings of the 1998 International Conference on Computer Languages (Cat. No.98CB36225)}, 
  title={Data flow analysis across tuplespace process boundaries}, 
  year={1998},
  volume={},
  number={},
  pages={272-281},
  abstract={A current limitation of compilers for shared memory parallel languages is their restricted use of traditional code-improving transformations, such as constant propagation and dead code elimination. A major problem lies in the lack of data flow analysis techniques for programs with user-specified parallelism. The authors demonstrate how data flow analysis remains quite viable in a compiler for shared memory parallel programs in a structured distributed shared memory environment, in which a shared space of tuples is accessed by properly synchronized methods. They demonstrate standard intraprocess data flow analysis performed in the midst of tuplespace communication statements, and present improvements to the precision of the analysis in the presence of these statements. They present a data flow system to compute reaching definitions across process boundaries, and a technique to improve the precision of this interprocess analysis. Lastly, some transformations enabled by this analysis are presented.},
  keywords={},
  doi={10.1109/ICCL.1998.674177},
  ISSN={1074-8970},
  month={May},}
@INPROCEEDINGS{679835,
  author={Mittal, N. and Garg, V.K.},
  booktitle={Proceedings. 18th International Conference on Distributed Computing Systems (Cat. No.98CB36183)}, 
  title={Consistency conditions for multi-object distributed operations}, 
  year={1998},
  volume={},
  number={},
  pages={582-589},
  abstract={The traditional distributed shared memory (DSM) model provides atomicity at levels of read and write on single objects. Therefore, multi-object operations such as double compare and swap, and atomic m-register assignment cannot be efficiently expressed in this model. We extend the traditional DSM model to allow operations to span multiple objects. We show that memory consistency conditions such as sequential consistency and linearizability can be extended to this general model. We also provide algorithms to implement these consistency conditions in a distributed system.},
  keywords={},
  doi={10.1109/ICDCS.1998.679835},
  ISSN={1063-6927},
  month={May},}
@INPROCEEDINGS{679521,
  author={Park, S.-Y. and Lee, J. and Hariri, S.},
  booktitle={Proceedings. 18th International Conference on Distributed Computing Systems (Cat. No.98CB36183)}, 
  title={A multithreaded message-passing system for high performance distributed computing applications}, 
  year={1998},
  volume={},
  number={},
  pages={258-265},
  abstract={NYNET (ATM wide area network testbed in New York state) Communication System (NCS) is a multithreaded message passing system developed at Syracase University that provides high performance and flexible communication services over asynchronous transfer mode (ATM) based high performance distributed computing (HPDC) environments. NCS capitalizes on thread based programming model to overlap computations and communications, and develop a dynamic message passing environment with separate data and control paths. This leads to a flexible and adaptive message passing environment that can support multiple flow control, error control, and multicasting algorithms. We provide an overview of the NCS architecture and present how NCS point to point communication services are implemented. We also analyze the overhead incurred by using multithreading and compare the performance of NCS point to point communication primitives with those of other message passing systems such as p4, PVM, and MPI. Benchmarking results indicate that NCS shows comparable performance to other systems for small message sizes but outperforms other systems for large message sizes.},
  keywords={},
  doi={10.1109/ICDCS.1998.679521},
  ISSN={1063-6927},
  month={May},}
@INPROCEEDINGS{679776,
  author={Guohong Cao and Singhal, M.},
  booktitle={Proceedings. 18th International Conference on Distributed Computing Systems (Cat. No.98CB36183)}, 
  title={Low-cost checkpointing with mutable checkpoints in mobile computing systems}, 
  year={1998},
  volume={},
  number={},
  pages={464-471},
  abstract={Mobile computing raises many new issues, such as lack of stable storage, low bandwidth of wireless channel, high mobility, and limited battery life. These new issues make traditional checkpointing algorithms unsuitable. We introduce the concept of mutable checkpoint, which is neither a tentative checkpoint nor a permanent checkpoint. Mutable checkpoints can be saved anywhere; e.g., the memory or local disk of MHs. In this way, taking a mutable checkpoint avoids the overhead of transferring a large amount of data to the stable storage in MSS over the wireless network. Based on mutable checkpoints, our non-blocking algorithm avoids the avalanche effect, minimizes the number of synchronization messages and forces only a minimum number of processes to take their checkpoints on the stable storage.},
  keywords={},
  doi={10.1109/ICDCS.1998.679776},
  ISSN={1063-6927},
  month={May},}
@INPROCEEDINGS{679522,
  author={Bechini, A. and Tai, K.-C.},
  booktitle={Proceedings. 18th International Conference on Distributed Computing Systems (Cat. No.98CB36183)}, 
  title={Timestamps for programs using messages and shared variables}, 
  year={1998},
  volume={},
  number={},
  pages={266-273},
  abstract={Algorithms for vector timestamps have been developed to determine the "happened before" relations between events of an execution of a message passing program. Many message passing programs contain variables shared by multiple processes (including threads). Such programs need to have vector timestamps for send, receive, read and write events. We define two "happened-before" relations, called strong happened-before (SHB) and weak happened-before (WHB), between events of an execution involving send, receive, read and write statements. We then present two timestamp assignment algorithms, one for SHB and the other for WHB, and show how to use such timestamps to determine the SHB or WHB relation between any two events of an execution involving send, receive, read and write statements. For a program containing n processes, the size of a vector timestamp for SHB or WHB is n, regardless of the number of shared variables in the program. Finally, we show how to apply WHB timestamps to perform race analysis for programs using messages and shared variables.},
  keywords={},
  doi={10.1109/ICDCS.1998.679522},
  ISSN={1063-6927},
  month={May},}
@INPROCEEDINGS{679774,
  author={Alvisi, L. and Rao, S. and Vin, H.M.},
  booktitle={Proceedings. 18th International Conference on Distributed Computing Systems (Cat. No.98CB36183)}, 
  title={Low-overhead protocols for fault-tolerant file sharing}, 
  year={1998},
  volume={},
  number={},
  pages={452-461},
  abstract={We quantify the adverse effect of file sharing on the performance of reliable distributed applications. We demonstrate that file sharing incurs significant overhead, which is likely to triple over the next five years. We present a novel approach that eliminates this overhead. Our approach: tracks causal dependencies resulting from file sharing using determinants; efficiently replicates the determinants in the volatile memory of agents to ensure their availability during recovery; and reproduces during recovery the interactions with the file server as well as the file data lost in a failure. Our approach allows agents to exchange files directly without first saving the files on disks at the server. As a consequence, the costs of supporting file sharing and message passing in a reliable distributed application become virtually identical. The result is a simple, uniform approach, which can provide low-overhead fault tolerance to applications in which communication is performed through message passing, file sharing, or a combination of the two.},
  keywords={},
  doi={10.1109/ICDCS.1998.679774},
  ISSN={1063-6927},
  month={May},}
@INPROCEEDINGS{679818,
  author={Chengzheng Sun and Zhiyi Huang and Wanju lei and Saitar, A.},
  booktitle={Proceedings. 18th International Conference on Distributed Computing Systems (Cat. No.98CB36183)}, 
  title={Toward transparent selective sequential consistency in distributed shared memory systems}, 
  year={1998},
  volume={},
  number={},
  pages={572-581},
  abstract={This paper proposes a transparent selective sequential consistency approach to distributed shared memory (DSM) systems. First, three basic techniques-time selection, processor selection, and data selection-are analyzed for improving the performance of strictly sequential consistency DSM systems, and a transparent approach to achieving these selections is proposed. Then, this paper focuses on the protocols and techniques devised to achieve transparent data selection, including a novel selective lazy/eager updates propagation protocol for propagating updates on shared data objects, and the critical region updated pages set scheme to automatically detect the associations between shared data objects and synchronization objects. The proposed approach is able to offer the same potential performance advantages as the entry consistency model or the scope consistency model, but it imposes no extra burden to programmers and never fails to execute programs correctly. The devised protocols and techniques have been implemented and experimented with in the context of the TreadMarks DSM system. Performance results have shown that for many applications, our transparent data selection approach outperforms the lazy release consistency model using a lazy or eager updates propagation protocol.},
  keywords={},
  doi={10.1109/ICDCS.1998.679818},
  ISSN={1063-6927},
  month={May},}
@INPROCEEDINGS{670012,
  author={Frumkin, M. and Hood, R. and Lopez, L.},
  booktitle={Proceedings of the First Merged International Parallel Processing Symposium and Symposium on Parallel and Distributed Processing}, 
  title={Trace-driven debugging of message passing programs}, 
  year={1998},
  volume={},
  number={},
  pages={753-762},
  abstract={We report on features added to a parallel debugger to simplify the debugging of message passing programs. These features include replay, setting consistent breakpoints based on interprocess event causality, a parallel undo operation, and communication supervision. These features all use trace information collected during the execution of the program being debugged. We used a number of different instrumentation techniques to collect traces. We also implemented trace displays using two different trace visualization systems. The implementation was tested on an SGI Power Challenge cluster and a network of SGI workstations.},
  keywords={},
  doi={10.1109/IPPS.1998.670012},
  ISSN={1063-7133},
  month={March},}
@INPROCEEDINGS{745026,
  author={Mink, A. and Bailly, C.},
  booktitle={1998 Winter Simulation Conference. Proceedings (Cat. No.98CH36274)}, 
  title={Parallel implementation of a molecular dynamics simulation program}, 
  year={1998},
  volume={1},
  number={},
  pages={491-498 vol.1},
  abstract={We have taken a NIST molecular dynamics simulation program (md3), which was configured as a single sequential process running on a CRAY C90 vector supercomputer, and parallelized it to run in a distributed memory message passing environment. Since portability was a major concern during parallelization, we used the Message Passing Interface (MPI) standard. The features of MPI provide a basic set of interprocess communication primitives on many architectures. The parallel md3 program has two basic algorithms resulting in an MPMD (Multiple Program Multiple Data) structure, versus the more common SPMD (Single Program Multiple Data) structure, and has the potential to exploit heterogeneous processing. For any given number of nodes we have devised an equation to determine the initial node allocation among these multiple programs which yields near optimal load balance. We also dynamically manage the load balance between processes to correct for run time variations and to achieve better performance. We compare the performance of this MPMD parallel code run on a range of distributed memory machines (an IBM SP2, a cluster of Pentium Pros, and a cluster of SGI Indigo2s with the R10000 processor) against the original code performance on the Cray. In addition to better performance, the code on distributed memory machines offers an ability to scale the problem size based upon the combined memory size of the host systems.},
  keywords={},
  doi={10.1109/WSC.1998.745026},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{745023,
  author={Prakash, S. and Bagrodia, R.L.},
  booktitle={1998 Winter Simulation Conference. Proceedings (Cat. No.98CH36274)}, 
  title={MPI-SIM: using parallel simulation to evaluate MPI programs}, 
  year={1998},
  volume={1},
  number={},
  pages={467-474 vol.1},
  abstract={This paper describes the design and implementation of MPI-SIM, a library for the execution driven parallel simulation of MPI programs. MPI-LITE, a portable library that supports multithreaded MPI, is also described. MPI-SIM, built on top of MPI-LITE, can be used to predict the performance of existing MPI programs as a function of architectural characteristics, including number of processors and message communication latencies. The simulation models can be executed sequentially or in parallel. Parallel executions of MPI-SIM models are synchronized using a set of asynchronous conservative protocols. MPI-SIM reduces synchronization overheads by exploiting the communication characteristics of the program it simulates. This paper presents validation and performance results from the use of MPI-SIM to simulate applications from the NAS Parallel Benchmark suite. Using the techniques described here, we are able to reduce the number of synchronizations in the parallel simulation as compared with the synchronous quantum protocol and are able to achieve speedups ranging from 3.2-11.9 in going from sequential to parallel simulation using 16 processors on the IBM SP2.},
  keywords={},
  doi={10.1109/WSC.1998.745023},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{741048,
  author={Yonjun Im and Yanghee Choi},
  booktitle={Proceedings 1998 International Conference on Parallel and Distributed Systems (Cat. No.98TB100250)}, 
  title={A distributed multicast routing algorithm for delay-sensitive applications}, 
  year={1998},
  volume={},
  number={},
  pages={232-239},
  abstract={We present a distributed multicast algorithm for constructing minimum cost multicast trees with delay constraints. The proposed algorithm, which provides multicasting and guaranteed end-to-end delay bound at the network layer, is also designed to find a reduced cost routing tree. The proposed algorithm requires limited network state information and the routing tree is computed through a single round of message exchanges between network nodes. We prove the algorithm's correctness by showing that it is always capable of constructing a delay constrained multicast tree, if one exists. The algorithm is verified by simulation, and it is shown that it exhibits superior performance compared to existing ones for the tree cost measure.},
  keywords={},
  doi={10.1109/ICPADS.1998.741048},
  ISSN={1521-9097},
  month={Dec},}
@INPROCEEDINGS{741035,
  author={Yu-Chee Tseng and Cheng-Chung Tan},
  booktitle={Proceedings 1998 International Conference on Parallel and Distributed Systems (Cat. No.98TB100250)}, 
  title={On termination detection protocols in a mobile distributed computing environment}, 
  year={1998},
  volume={},
  number={},
  pages={156-163},
  abstract={Incorporating mobile components into a distributed system has posed new challenges to the design of distributed computation. This paper studies a fundamental problem in distributed computing, the termination detection problem, in a mobile environment. Two types of termination detection protocols already exist: the diffusion-based schemes and the weight-throwing schemes, that are designed for traditional static distributed systems. We propose a hybrid scheme by combining these two protocols together. The scheme can better exploit the communication hierarchy (in terms of wired and wireless bandwidths) and can pave the gaps of computation and communication capability between static and mobile hosts, thus more scalable to larger distributed systems. Simulation results are presented, which show the advantage of the hybrid scheme over existing schemes.},
  keywords={},
  doi={10.1109/ICPADS.1998.741035},
  ISSN={1521-9097},
  month={Dec},}
@INPROCEEDINGS{711833,
  author={Zambonelli, F.},
  booktitle={Proceedings. 24th EUROMICRO Conference (Cat. No.98EX204)}, 
  title={Distributed checkpoint algorithms to avoid roll-back propagation}, 
  year={1998},
  volume={1},
  number={},
  pages={403-410 vol.1},
  abstract={Checkpointing is a very well known mechanism to achieve fault tolerance. In distributed applications, a local checkpoint is useful for fault tolerance purposes only if can belong to at least one consistent global checkpoint and then, execution can be restarted from it without needing to roll back the execution in the past. The paper introduces a theoretical framework that facilitates the definition and the analysis of distributed checkpoint algorithms to avoid roll backpropagation. On this base, several algorithms are presented and evaluated in a set of testbed applications.},
  keywords={},
  doi={10.1109/EURMIC.1998.711833},
  ISSN={1089-6503},
  month={Aug},}
@INPROCEEDINGS{708471,
  author={Dong Xuan and Weijia Jia and Wei Zhao},
  booktitle={Proceedings. 1998 International Conference on Parallel Processing (Cat. No.98EX205)}, 
  title={Routing algorithms for anycast messages}, 
  year={1998},
  volume={},
  number={},
  pages={122-130},
  abstract={We propose and analyze three routing algorithms for anycast packets: source-destination based routing with weighted random selection (SD/WRS); destination based routing with weighted random selection (D/WRS); and the shortest shortest path first (SSPF) algorithms. The SSPF algorithm is a simple extension to the traditional SPF algorithm for routing unicast packets. The SD/WRS and D/WRS algorithms explicitly take into account characteristics of anycast message traffic and its recipient group. As a result, our simulation study shows that both the SD/WRS and D/WRS algorithms perform much better than SSPF in terms of average end-to-end packet delay. In particular, SD/WRS performs very close to a dynamic optimal algorithm in most cases. Our algorithms are simple, efficient and compatible with the most of existing routing technologies. We also formally prove the loop free and correctness properties for our algorithms.},
  keywords={},
  doi={10.1109/ICPP.1998.708471},
  ISSN={0190-3918},
  month={Aug},}
@INPROCEEDINGS{708480,
  author={Rastello, F. and Rao, A. and Pande, S.},
  booktitle={Proceedings. 1998 International Conference on Parallel Processing (Cat. No.98EX205)}, 
  title={Optimal task scheduling to minimize inter-tile latencies}, 
  year={1998},
  volume={},
  number={},
  pages={172-179},
  abstract={This work addresses the issue of exploiting intra-tile parallelism by overlapping communication with computation removing the restriction of atomicity of tiles. The effectiveness of tiling is then critically dependent on the execution order of tasks within a tile. We present a theoretical framework based on equivalence classes that provides an optimal task ordering under assumptions of constant and different permutations of tasks in individual tiles. Our framework is able to handle constant but compile-time unknown dependences by generating optimal task permutations at run-time and results in significantly lower loop completion times. Our solution is an improvement over previous approaches (Chou and Kung, 1993) (Dion et al., 1995) and is optimal for all problem instances. We also propose efficient algorithms that provide the optimal solution. The framework has been implemented as an optimization pass in the SUIF compiler and has been tested on a distributed memory system using a message passing model. We show that the performance improvement over previous results is substantial.},
  keywords={},
  doi={10.1109/ICPP.1998.708480},
  ISSN={0190-3918},
  month={Aug},}
@INPROCEEDINGS{708534,
  author={Xian-He Sun and Pantano, M. and Fahringer, T.},
  booktitle={Proceedings. 1998 International Conference on Parallel Processing (Cat. No.98EX205)}, 
  title={Performance range comparison for restructuring compilation}, 
  year={1998},
  volume={},
  number={},
  pages={595-602},
  abstract={A major difficulty in restructuring compilation is how to compare parallel performance over a range of system and problem sizes. This study introduces the concept of range comparison for data-parallel programming. Unlike conventional execution time comparison in which performance is compared for a particular system and problem size, range comparison compares the performance of programs over a range of ensemble and problem sizes via scalability and performance crossing point analysis. An algorithm is developed to predict the crossing point automatically. The correctness of the algorithm is proved and a methodology is developed to integrate range comparison into restructuring compilations. A preliminary prototype of the methodology is implemented and tested under Vienna Fortran Compilation System. Experimental results demonstrate that range comparison is feasible and effective.},
  keywords={},
  doi={10.1109/ICPP.1998.708534},
  ISSN={0190-3918},
  month={Aug},}
@INPROCEEDINGS{708460,
  author={Radhakrishnan, R. and Abu-Ghazaleh, N. and Chetlur, M. and Wilsey, P.A.},
  booktitle={Proceedings. 1998 International Conference on Parallel Processing (Cat. No.98EX205)}, 
  title={On-line configuration of a time warp parallel discrete event simulator}, 
  year={1998},
  volume={},
  number={},
  pages={28-35},
  abstract={In time warp simulations, the overheads associated with rollbacks, state-saving and the communication induced by rollbacks are the chief contributors to the cost of the simulation; thus, these aspects of the simulation have been primary targets for optimizations. Unfortunately, the behavior of the time warp simulation is highly dynamic and greatly influenced by the application being simulated. Thus, the suggested optimizations are only effective for certain intervals of the simulation. This paper argues that the performance of time warp simulators benefits from a dynamic on-line decision process that selects and configures the sub-algorithms implementing the different aspects of the simulator to best match the current behavior of the simulation. In particular we study control strategies to dynamically: (i) adjust the checkpointing (or state-saving) interval (ii) select the cancellation strategy (lazy or aggressive), and (iii) determine the policy for aggregating the application messages (an optimization that significantly improves the performance in message passing environments). The strategies have been implemented in the WARPED time warp simulation kernel and the performance obtained via the dynamically controlled optimizations is shown to surpass that of their best performing static counterparts.},
  keywords={},
  doi={10.1109/ICPP.1998.708460},
  ISSN={0190-3918},
  month={Aug},}
@INPROCEEDINGS{708468,
  author={Verma, M. and Chiueh, T.-C.},
  booktitle={Proceedings. 1998 International Conference on Parallel Processing (Cat. No.98EX205)}, 
  title={Implementation and performance evaluation of Locust}, 
  year={1998},
  volume={},
  number={},
  pages={96-104},
  abstract={Locust is a distributed shared virtual memory system that exploits compile-time data dependency information to address the issues of false sharing, cache coherence overhead, and affinity process scheduling. The paper reports the results and their analysis of a comprehensive performance evaluation study of the first Locust prototype, which is implemented on a 12-node Pentium cluster running FreeBSD and has been fully operational for a year. The results show that for the set of regular programs tested, the performance of Locust is within 1-8% of that of the message passing system implemented on the same hardware/software platform. The main performance gain of Locust as compared to existing weak cache consistency models mainly comes from the elimination of unnecessary synchronizations using the generational cache coherence protocol, and the function-shipping approach of implementing synchronization operations.},
  keywords={},
  doi={10.1109/ICPP.1998.708468},
  ISSN={0190-3918},
  month={Aug},}
@INPROCEEDINGS{708518,
  author={Banikazemi, M. and Moorthy, V. and Panda, D.K.},
  booktitle={Proceedings. 1998 International Conference on Parallel Processing (Cat. No.98EX205)}, 
  title={Efficient collective communication on heterogeneous networks of workstations}, 
  year={1998},
  volume={},
  number={},
  pages={460-467},
  abstract={Networks of Workstations (NOW) have become an attractive alternative platform for high performance computing. Due to the commodity nature of workstations and interconnects and due to the multiplicity of vendors and platforms, the NOW environments are being gradually redefined as Heterogeneous Networks of Workstations (HNOW) environments. This paper presents a new framework for implementing collective communication operations (as defined by the Message Passing Interface (MPI) standard) efficiently for the emerging HNOW environments. We first classify different types of heterogeneity in HNOW and then focus on one important characteristic: communication capabilities of workstations. Taking this characteristic into account, we propose two new approaches Speed-Partitioned Ordered Chain (SPOC) and Fastest-Node First (FNF) to implement collective communication operations with reduced latency. We also investigate methods for deriving optimal trees for broadcast and multicast operations. Generating such trees is shown to be computationally intensive. It is shown that the FNF approach, in spite of its simplicity, can deliver performance within 1% of the performance of the optimal trees. Finally, these new approaches are compared with the approach used in the MPICH implementation on experimental as well as on simulated testbeds. On a 24-node existing HNOW environment with SGI workstations and ATM interconnection our approaches reduce the latency of broadcast and multicast operations by a factor of up to 3.5 compared to the approach used in the existing MPICH implementation. On a 64-node simulated testbed, our approaches can reduce the latency of broadcast and multicast operations by a factor of up to 4.5. Thus, these results demonstrate that there is significant potential for our approaches to be applied towards designing scalable collective communication libraries for current and future generation HNOW environments.},
  keywords={},
  doi={10.1109/ICPP.1998.708518},
  ISSN={0190-3918},
  month={Aug},}
@INPROCEEDINGS{708472,
  author={Kulkarni, S.S. and Arora, A.},
  booktitle={Proceedings. 1998 International Conference on Parallel Processing (Cat. No.98EX205)}, 
  title={Low-cost fault-tolerance in barrier synchronizations}, 
  year={1998},
  volume={},
  number={},
  pages={132-139},
  abstract={We show how fault-tolerance can be effectively added to several types of faults in program computations that use barrier synchronization. We divide the faults that occur in practice into two classes, detectable and undetectable, and design a fully distributed program that tolerates the faults in both classes. Our program guarantees that every barrier is executed correctly even if detectable faults occur, and that eventually every barrier is executed correctly even if undetectable faults occur. Via analytical as well as simulation results we show that the cost of adding fault-tolerance is low, in part by comparing the times required by our program with that required by the corresponding fault-intolerant counterpart.},
  keywords={},
  doi={10.1109/ICPP.1998.708472},
  ISSN={0190-3918},
  month={Aug},}
@INPROCEEDINGS{708138,
  author={Arapov, D. and Ivannikov, V. and Kalinov, A. and Lastovetsky, A. and Ledovskih, I.},
  booktitle={Proceedings. 24th EUROMICRO Conference (Cat. No.98EX204)}, 
  title={Managing processes with network objects and their translation}, 
  year={1998},
  volume={2},
  number={},
  pages={1037-1044 vol.2},
  abstract={The mpC language and its supportive portable programming environment are aimed at efficiently-portable modular parallel programming heterogeneous networks of computers (HNCs). Unlike traditional tools used for portable programming HNCs, mpC provides more advanced facilities for process management to support efficient portability. The paper presents the abstraction of network object introduced in the mpC language to manage processes constituting a message-passing program in order to ensure efficient execution of mpC applications on any particular HNC. The main attention is paid to the translation of this high-level mechanism into low-level notions of target message-passing programs.},
  keywords={},
  doi={10.1109/EURMIC.1998.708138},
  ISSN={1089-6503},
  month={Aug},}
@INPROCEEDINGS{699448,
  author={Bechini, A. and Cutajar, J. and Prete, C.A.},
  booktitle={MELECON '98. 9th Mediterranean Electrotechnical Conference. Proceedings (Cat. No.98CH36056)}, 
  title={A tool for testing of parallel and distributed programs in message-passing environments}, 
  year={1998},
  volume={2},
  number={},
  pages={1308-1312 vol.2},
  abstract={Due to the non-deterministic behavior of some parallel and distributed programs, addressing the problem of testing in such context is a non-trivial task. A proficient testing phase must be done using tools which record information about a single execution, and which are able to force a concurrent program to exercise a given execution. This paper describes a tool for testing of programs based on the Horus system. Our approach is novel in dealing with events connected to process group handling and group communication. Moreover, we show that using the capabilities of the Horus run-time system can be really helpful in solving testing problems. Our approach has the advantages of requiring no modifications neither in the program nor in the operating system, and to avoid a centralized solution through the use of partial orders of synchronization events.},
  keywords={},
  doi={10.1109/MELCON.1998.699448},
  ISSN={},
  month={May},}
@INPROCEEDINGS{699451,
  author={Bar-Noy, A. and Nir, U.},
  booktitle={MELECON '98. 9th Mediterranean Electrotechnical Conference. Proceedings (Cat. No.98CH36056)}, 
  title={The generalized postal model-broadcasting in a system with non-homogeneous delays}, 
  year={1998},
  volume={2},
  number={},
  pages={1323-1327 vol.2},
  abstract={In many communication systems we may assume that every node is directly connected to every other node. It does not matter whether the system is a massively parallel computer where each processor is a node and the connectivity is achieved using a software communication library or if the system is the Internet where each node is a computer and the connectivity is achieved using IP. The postal model started with this assumption and in addition assumed that the process of delivering a message between two nodes takes a constant amount of time called the communication delay (greater than one unit of time), and that when a node sends a message or receives a message it wastes a single time unit. In this paper, we enhanced the postal model by removing the assumption that the communication delay is constant. Without this constraint. The broadcasting problem is NP-complete and therefore we study two directions. (i) We present heuristic algorithms and analyze them. (ii) We evaluate simple topologies of networks (by assuming large delays when there is not a direct connection). We have also tested the heuristic algorithms with simulations and compared them to the optimal solutions.},
  keywords={},
  doi={10.1109/MELCON.1998.699451},
  ISSN={},
  month={May},}
@INPROCEEDINGS{693361,
  author={Di Martino, B. and Mazzeo, A. and Mazzocca, N. and Villano, U.},
  booktitle={Proceedings. 6th International Workshop on Program Comprehension. IWPC'98 (Cat. No.98TB100242)}, 
  title={Automatic detection of interaction patterns for parallel program analysis and development}, 
  year={1998},
  volume={},
  number={},
  pages={206-213},
  abstract={The parallel structure of most programs can be classified into a limited number of Parallel Programming Paradigms, that can be viewed as representative of the basic ways to organize a parallel computation. Interaction Paradigms or patterns describe how the communication and synchronization among the parallel components is structured. In this paper we present an approach and a prototyped implementation, for the analysis of parallel programs, based on the automatic and static detection of interaction patterns among the processes of message passing programs.},
  keywords={},
  doi={10.1109/WPC.1998.693361},
  ISSN={1092-8138},
  month={June},}
@INPROCEEDINGS{740469,
  author={Rao, S. and Alvisi, L. and Vin, H.M.},
  booktitle={Proceedings Seventeenth IEEE Symposium on Reliable Distributed Systems (Cat. No.98CB36281)}, 
  title={The cost of recovery in message logging protocols}, 
  year={1998},
  volume={},
  number={},
  pages={10-18},
  abstract={Past research in message logging has focused on studying the relative overhead imposed by pessimistic, optimistic, and causal protocols during failure-free executions. We give the first experimental evaluation of the performance of these protocols during recovery. We discover that, if a single failure is to be tolerated, pessimistic and causal protocols perform best, because they avoid rollbacks of correct processes. For multiple failures, however, the dominant factor in determining performance becomes where the recovery information is logged (i.e. at the sender, at the receiver, or replicated at a subset of the processes in the system) rather than when this information is logged (i.e. if logging is synchronous or asynchronous).},
  keywords={},
  doi={10.1109/RELDIS.1998.740469},
  ISSN={1060-9857},
  month={Oct},}
@INPROCEEDINGS{740524,
  author={Benkahla, O.-E.-K. and Robach, C.},
  booktitle={Proceedings Seventeenth IEEE Symposium on Reliable Distributed Systems (Cat. No.98CB36281)}, 
  title={Off-line diagnosis of parallel systems}, 
  year={1998},
  volume={},
  number={},
  pages={360-365},
  abstract={This paper presents an off-line diagnosis strategy for parallel message-passing systems. This strategy, called host-diagnosis, allows an external observer, i.e. the host system, to perform centralized diagnosis of the system state, given results of distributed tests performed among the system processors. Three algorithms that use the host-diagnosis strategy are proposed. The performance of the three algorithms are evaluated and compared to those of a classic distributed self-diagnosis algorithm. The obtained results show an interesting behaviour of the host-diagnosis algorithms in comparison with the self-diagnosis one.},
  keywords={},
  doi={10.1109/RELDIS.1998.740524},
  ISSN={1060-9857},
  month={Oct},}
@INPROCEEDINGS{739900,
  author={Katsinis, C.},
  booktitle={Proceedings 7th International Conference on Computer Communications and Networks (Cat. No.98EX226)}, 
  title={Performance analysis and simulation of the SOME-Bus architecture using message passing}, 
  year={1998},
  volume={},
  number={},
  pages={68-72},
  abstract={The simultaneous optical multiprocessor exchange bus (SOME-Bus) is a low-latency, high-bandwidth, fiber-optic interconnection network which directly links arbitrary pairs of processor nodes without contention. It contains a dedicated channel (of b bits) for the data output of each node, eliminating the need for global arbitration and providing bandwidth that scales directly with the number of nodes in the system. Each of N nodes has an array of receivers, with one receiver dedicated to each node output channel. The entire N-receiver array can be integrated an a single chip at a comparatively minor cost resulting in O(N) complexity. The receiver number remains constant as b is increased. This paper examines the performance of the SOME-Bus using a message-passing queueing network model. It develops theoretical results which provide distributions of messages in the system and predict processor utilization and message waiting time. It also presents simulation results which validate the theoretical results and compare processor utilization in the SOME-Bus, the crossbar and the torus using queueing network models, with and without synchronization. It demonstrates that, compared to the networks considered here, the SOME-Bus is the interconnection network whose performance is least affected by large message communication times. Even in the presence of intense synchronization, processor utilization remains practically unaffected while it drops quite dramatically in the other architectures.},
  keywords={},
  doi={10.1109/ICCCN.1998.739900},
  ISSN={1095-2055},
  month={Oct},}
@INPROCEEDINGS{740470,
  author={Byoungjoo Lee and Taesoon Park and Yeom, H.Y. and Yookun Cho},
  booktitle={Proceedings Seventeenth IEEE Symposium on Reliable Distributed Systems (Cat. No.98CB36281)}, 
  title={An efficient algorithm for causal message logging}, 
  year={1998},
  volume={},
  number={},
  pages={19-25},
  abstract={Causal message logging has many good properties such as nonblocking message logging and no rollback propagation. However, it requires a large amount of information to be piggybacked on each message, which may incur severe performance degradation. This paper presents an efficient causal logging algorithm based on the new message log structure, LogOn, which represents the causal interprocess dependency relation with much smaller overhead compared to the existing algorithms. The proposed algorithm is efficient in the sense that it requires no additional information other than LogOn to be carried in each message, while the other algorithms require extra information other than the message log, to eliminate the duplicates in log entries. Moreover, in those algorithms, as more extra information is added into the message, more duplicates can be detected. However, the proposed algorithm achieves the same degree of efficiency using only the message log carried in each message, without any extra information.},
  keywords={},
  doi={10.1109/RELDIS.1998.740470},
  ISSN={1060-9857},
  month={Oct},}
@INPROCEEDINGS{740478,
  author={Ramamurthy, B. and Upadhyaya, S. and Bhargava, J.},
  booktitle={Proceedings Seventeenth IEEE Symposium on Reliable Distributed Systems (Cat. No.98CB36281)}, 
  title={Design and analysis of a hardware-assisted checkpointing and recovery scheme for distributed applications}, 
  year={1998},
  volume={},
  number={},
  pages={84-90},
  abstract={A checkpointing and recovery scheme which exploits the low latency and high coverage characteristics of a hardware error detection scheme is presented. Message dependency which is the main source of multi-step rollback in distributed systems is minimized by using a new message validation technique derived from hardware-assisted error detection. The main contribution of this paper is the development of an analytical model to establish the completeness and correctness of the new scheme. A novel concept of global state matrix is defined to keep track of the global state in a distributed system and assist in recovery. An illustration is given to show the distinction between conventional and the new recovery schemes.},
  keywords={},
  doi={10.1109/RELDIS.1998.740478},
  ISSN={1060-9857},
  month={Oct},}
@ARTICLE{656771,
  author={Clark, D.},
  journal={IEEE Concurrency}, 
  title={OpenMP: a parallel standard for the masses}, 
  year={1998},
  volume={6},
  number={1},
  pages={10-12},
  abstract={The author considers how the recent release of OpenMP could finally shove parallel software applications out of the domain of high-performance scientific research and analysis, and onto the desktop. By supporting cross-platform, directive-based programming, the OpenMP application programming interface will simplify the development of parallel applications on shared-memory machines. Among other things, this means independent software vendors and other developers can now create parallel code once and run it on different systems, from two-way NT workstations to Unix-based supercomputers with 128 or more processors. The OpenMP specification is a set of compiler directives and callable runtime library routines that take advantage of shared memory multiprocessor (SMP) Unix and NT environments. This version of the OpenMP specification is Fortran-based, due to its widespread use for developing high-performance parallel scientific codes.},
  keywords={},
  doi={10.1109/4434.656771},
  ISSN={1558-0849},
  month={Jan},}
@INPROCEEDINGS{739771,
  author={Mink, A. and Salamon, W. and Hollingsworth, J.K. and Arunachalam, R.},
  booktitle={Proceedings 19th IEEE Real-Time Systems Symposium (Cat. No.98CB36279)}, 
  title={Performance measurement using low perturbation and high precision hardware assists}, 
  year={1998},
  volume={},
  number={},
  pages={379-388},
  abstract={We present the design and implementation of MultiKron PCI, a hardware performance monitor that can be plugged into any computer with a free PCI bus slot. The monitor provides a series of high-resolution timers, and the ability to monitor the utilization of the PCI bus. We also demonstrate how the monitor can be integrated with online performance monitoring tools such as the Paradyn parallel performance measurement tools to improve the overhead of key timer operations by a factor of 25. In addition, we present a series of case studies using the MultiKron hardware performance monitor to measure and tune high-performance parallel completing applications. By using the monitor, we were able to find and correct a performance bug in a popular implementation of the MPI message passing library that caused some communication primitives to run at one half their potential speed.},
  keywords={},
  doi={10.1109/REAL.1998.739771},
  ISSN={1052-8725},
  month={Dec},}
@INPROCEEDINGS{727292,
  author={Yunheung Paek and Navarro, A. and Zapata, E. and Padua, D.},
  booktitle={Proceedings. 1998 International Conference on Parallel Architectures and Compilation Techniques (Cat. No.98EX192)}, 
  title={Parallelization of benchmarks for scalable shared-memory multiprocessors}, 
  year={1998},
  volume={},
  number={},
  pages={401-408},
  abstract={This paper identifies practical compiling techniques for scalable shared memory machines. For this, we have focused on experimental studies using a real machine and representative codes. In the experiments, we transformed conventional codes to shared memory codes using several existing techniques and ran the output on the target machine to evaluate those techniques and to identify where improvement is needed. Based on the analysis of the results, we developed a few new techniques, and experimented again on the target machine to measure the effectiveness of each one. The results reported in this paper were quite positive, lending useful information to future research on compiler optimizations for existing SSM machines.},
  keywords={},
  doi={10.1109/PACT.1998.727292},
  ISSN={1089-795X},
  month={Oct},}
@INPROCEEDINGS{1437339,
  author={Taufer, M. and Stricker, T.},
  booktitle={SC '98: Proceedings of the 1998 ACM/IEEE Conference on Supercomputing}, 
  title={Accurate Performance Evaluation, Modelling and Prediction of a Message Passing Simulation Code based on Middleware}, 
  year={1998},
  volume={},
  number={},
  pages={52-52},
  abstract={In distributed and vectorized computing there is a large number of highly different supercomputing platforms an application could run on. Therefore most traditional parallel codes are ill equipped to collect data about their resource usage or their behavior at run time and the corresponding data are rarely published and few scientists attack the planning of an application and its platform systematically. As an improvement over the current state of the art, we propose an integrated approach to performance evaluation, modeling and prediction for different platforms. Our approach uses a combination of analytical modeling and systematically designed experimentation with full application runs, reduced application kernels and some benchmarks. We studied our methodology of performance assessment with Opal, an example code in molecular biology, developed at our institution to run on our four Cray J90 ``Classic'' Vector SMPs. Besides a detailed assessment of performance achieved on the J90s, the primary goal of our study was to find the most suitable and most cost effective hardware platform for the application, in particular to check the suitability of this application for slow CoPs, SMP CoPs and fast CoPs, three flavors of Clusters of PCs built with off-the-shelf Intel Pentium processors. A performance assessment based on our model is much easier than porting and parallelizing the application for a new target machine and so we could easily obtain and include performance estimates for a T3E-900, a high end MPP system. The predicted execution times and speedup figures indicate that a well designed cluster of PCs achieves similar if not better performance than the J90 vector processors currently used and that the computational efficiency compares favorably to the T3E-900 for that particular application code.},
  keywords={},
  doi={10.1109/SC.1998.10039},
  ISSN={},
  month={Nov},}
@ARTICLE{6075366,
  author={Delai, Chen and Bo, Hong and Zhiwu, Xie and Shilie, Weng},
  journal={Journal of Systems Engineering and Electronics}, 
  title={Efficient partially asynchronous parallel simulation on multicomputer systems: Research and practice}, 
  year={1998},
  volume={9},
  number={2},
  pages={40-47},
  abstract={This paper presents partially asynchronous parallel simulation of continuous-system (PAPSoCS) and some approaches to the issues of its implementation on a multicomputer system. To guarantee the simulation results correct and speedup the simulation, the scheme for efficient PAPSoCS is proposed and the virtual topology star is constructed to match the path of message passing for solving algorithm-architecture adequation problem. Under the circumstances that messages frequently passed inter-processor are much shorter, typically within several 4 bytes, asynchronous communication mode is employed to reduce the communication ratio. Experiment results show that asynchronous parallel simulation has much higher efficiency than its synchronous counterpart.},
  keywords={},
  doi={},
  ISSN={1004-4132},
  month={June},}
@INPROCEEDINGS{744381,
  author={Chen-Chi Kuo and Carter, J. and Kuramkote, R.},
  booktitle={Proceedings Fifth International Symposium on High-Performance Computer Architecture}, 
  title={MP-LOCKs: replacing H/W synchronization primitives with message passing}, 
  year={1999},
  volume={},
  number={},
  pages={284-288},
  abstract={Shared memory programs guarantee the correctness of concurrent accesses to shared data using interprocessor synchronization operations. The most common synchronization operators are locks, which are traditionally implemented via a mix of shared memory accesses and hardware synchronization primitives like test-and-set. In this paper, we argue that synchronization operations implemented using fast message passing and kernel-embedded lock managers are an attractive alternative to dedicated synchronization hardware. We propose three message passing lock (MP-LOCK) algorithms (centralized, distributed, and reactive) and provide implementation guidelines. MP-LOCKs reduce the design complexity and runtime occupancy of DSM controllers and can exploit software's inherent flexibility to adapt to differing applications lock access patterns. We compared the performance of MP-LOCKs with two common shared memory lock algorithms: test-and-test-and-set and MCS locks and found that MP-LOCKs scale better. For machines with 16 to 32 nodes, applications using MP-LOCKs ran up to 186% faster than the same applications with shared memory locks. For small systems (up to 8 nodes), three applications with MP-LOCKs slow down by no more than 18%, while the other two slowed by no more than 180% due to higher software overhead. We conclude that locks based on message passing should be considered as a replacement for hardware locks in future scalable multiprocessors that support efficient message passing mechanisms.},
  keywords={},
  doi={10.1109/HPCA.1999.744381},
  ISSN={},
  month={Jan},}
@INPROCEEDINGS{750452,
  author={Hoisie, A. and Lubeck, O. and Wasserman, H.},
  booktitle={Proceedings. Frontiers '99. Seventh Symposium on the Frontiers of Massively Parallel Computation}, 
  title={Scalability analysis of multidimensional wavefront algorithms on large-scale SMP clusters}, 
  year={1999},
  volume={},
  number={},
  pages={4-15},
  abstract={We develop a model for the parallel performance of algorithms that consist of concurrent, two-dimensional wavefronts implemented in a message passing environment. The model combines the separate contributions of computation and communication wavefronts. We validate the model on three supercomputer systems, with up to 500 processors, using data from an ASCI deterministic particle transport application, although the model is general to any wavefront algorithm implemented on a 2-D processor domain. We also use the model to make estimates of performance and scalability of wavefront algorithms on 100-TFLOPS computer systems expected to be in existence within the next decade. Our model shows that on a 1-billion-cell problem, single-node computation speed (nor inter-processor communication performance, as is widely believed) is the bottleneck. Finally, we present preliminary considerations that reveal the additional complexity associated with modeling wavefront algorithms on reduced-connectivity network topologies, such as clusters of SMPs.},
  keywords={},
  doi={10.1109/FMPC.1999.750452},
  ISSN={},
  month={Feb},}
@INPROCEEDINGS{746681,
  author={Yun Ding and Munch, M. and Laux, M.},
  booktitle={Proceedings of the Seventh Euromicro Workshop on Parallel and Distributed Processing. PDP'99}, 
  title={Dynamic coupling of grid-based multidisciplinary applications}, 
  year={1999},
  volume={},
  number={},
  pages={249-255},
  abstract={The GRISSLi coupling interface is a runtime library designed for the coupled computation of grid-based multidisciplinary applications. Established simulation programs, which are devoted to a single discipline, can be interconnected to a complex simulation system via the GRISSLi coupling interface without recoding the participating programs. We introduce a data model to establish the links between the (dynamic) grids and the attached coupling values in a single application program and to establish the mappings between grids and coupling values among different application programs. The user-specified consistency model is realized using asynchronous communication based on the MPI message passing standard. Efficient communication is achieved by pre-computing an optimized communication schedule and overlapping communication with computation. Flexible coupling algorithms with adaptive grids and branches are supported in GRISSLi. We have developed a prototype implementation, which provides language bindings in ANSI C and Fortran, and runs currently on IBM RS/6000 SP, Gray T3E, SGI Origin/Octane and HP-V Class. We verify the functionality and evaluate the performance of our library using an industry relevant pilot application, the steel strip production process.},
  keywords={},
  doi={10.1109/EMPDP.1999.746681},
  ISSN={},
  month={Feb},}
@INPROCEEDINGS{745170,
  author={Sander, I. and Jantsch, A.},
  booktitle={Proceedings Twelfth International Conference on VLSI Design. (Cat. No.PR00013)}, 
  title={Formal system design based on the synchrony hypothesis, functional models, and skeletons}, 
  year={1999},
  volume={},
  number={},
  pages={318-323},
  abstract={Formal approaches to HW and system design have not been generally adopted because designers often view the modelling concepts in these approaches as unsuitable for their problems. Moreover they are frequently on a too high abstraction level to allow for efficient synthesis with today's techniques. We address this problem with a modelling method, which is strictly formal and based on formal semantics, a pure functional language, and the synchrony hypothesis. But the use of skeletons in conjunction with a proper computational model allows to associate a direct hardware interpretation. In particular we use the synchrony hypothesis and a timed signal model to provide a high abstraction for communication at the system level. This facilitates efficient modelling and design space exploration at the functional level, because the designer is not concerned with complex communication mechanisms, and functionality can easily be moved from one block to another. To bridge the gap between an elegant and abstract functional model and the details of an implementation we use skeletons to encapsulate primitive structures, such as FSMs, buffers, computation units, etc. in a purely functional way.},
  keywords={},
  doi={10.1109/ICVD.1999.745170},
  ISSN={1063-9667},
  month={Jan},}
@INPROCEEDINGS{829513,
  author={Blahovec, J.D. and Sasser, G.E. and Luginsland, J.W. and Watrous, J.J.},
  booktitle={IEEE Conference Record - Abstracts. 1999 IEEE International Conference on Plasma Science. 26th IEEE International Conference (Cat. No.99CH36297)}, 
  title={Preliminary implementation of piecewise linear conformal boundaries in ICEPIC}, 
  year={1999},
  volume={},
  number={},
  pages={213-},
  abstract={Summary form only given, as follows. ICEPIC, developed by the air force research lab, is a 3-D particle-in-cell (PIC) code capable of being operated on parallel architectures using either the MPI or PVM message passing standards. ICEPIC utilizes a Cartesian coordinate-based grid system to simulate collisionless plasma physics phenomena, such as those that occur in high power microwave devices. Previous versions of ICEPIC represented curved boundaries by using 'stair-step' approximations. These Cartesian grid 'stair-steps' may cause inaccurate results in certain simulations, particularly in regions of extreme curvature. In order to increase the accuracy of the code, while retaining the computational ease of the Cartesian grid, various methods of embedded and conformal boundaries are considered. Preliminary results of tests of the accuracy and stability of these models are presented.},
  keywords={},
  doi={10.1109/PLASMA.1999.829513},
  ISSN={0730-9244},
  month={June},}
@INPROCEEDINGS{841004,
  author={Keyes, D.S. and Dillon, L.K. and Moon Jung Chung},
  booktitle={Proceedings of the 1999 International Conference on Software Engineering (IEEE Cat. No.99CB37002)}, 
  title={Analysis of a scheduler for a CAD framework}, 
  year={1999},
  volume={},
  number={},
  pages={152-161},
  abstract={The experience report describes a case study in which a key component of a software system was modeled and analyzed to better understand a proposed algorithm prior to implementation. A Promela model of a linear scheduler for a CAD framework was developed. The Spin simulator was used to debug the model and, later, to illustrate how the algorithm works in different scenarios. Additionally, the Spin verifier was used to check various safety and liveness properties. The study revealed a deficiency with the algorithm, as originally proposed. Subsequently, the modeling tools provided by Spin were used in devising solutions to the problems. Finally, the Promela model was modified and verified to be correct. The actual implementation of the scheduler involves a significant amount of message passing, multiple execution threads, and potentially huge data structures. By focusing on the interfaces between threads, restricting the system scope, and abstracting details of data structures and irrelevant computations, a very simple model was obtained, which nevertheless provides an accurate representation of the communication between threads. The paper describes the steps that were abstracted and highlights the restrictions imposed on the model.},
  keywords={},
  doi={10.1145/302405.302461},
  ISSN={0270-5257},
  month={May},}
@INPROCEEDINGS{746668,
  author={Tsiatsoulis, Z. and Cotronis, J.Y. and Floros, E.},
  booktitle={Proceedings of the Seventh Euromicro Workshop on Parallel and Distributed Processing. PDP'99}, 
  title={Testing and debugging message passing applications based on the synergy of program and specification executions}, 
  year={1999},
  volume={},
  number={},
  pages={196-203},
  abstract={We outline Ensemble, a design and implementation methodology for composing message passing (MP) applications from program components. We also outline specification composition, directly associated with application composition. We present the integration of specification and implementation of program development. We particularly elaborate on testing and debugging of MP applications based on the synergy of tools for specification simulations with tools for program execution visualisation.},
  keywords={},
  doi={10.1109/EMPDP.1999.746668},
  ISSN={},
  month={Feb},}
@INPROCEEDINGS{760506,
  author={Zambonelli, F. and Netzer, R.H.B.},
  booktitle={Proceedings 13th International Parallel Processing Symposium and 10th Symposium on Parallel and Distributed Processing. IPPS/SPDP 1999}, 
  title={An efficient logging algorithm for incremental replay of message-passing applications}, 
  year={1999},
  volume={},
  number={},
  pages={392-398},
  abstract={To support incremental replay of message-passing applications, processes must periodically checkpoint and the content of some messages must be logged, to break dependencies of the current state of the execution on past events. The paper presents a new adaptive logging algorithm that dynamically decides whether to log a message based on dependencies the incoming message introduces on past events of the execution. The paper discusses the implementation issues of the algorithm and evaluates its performances on several applications, showing how it improves previously known schemes.},
  keywords={},
  doi={10.1109/IPPS.1999.760506},
  ISSN={},
  month={April},}
@ARTICLE{770134,
  author={Xian-He Sun and Pantano, M. and Fahringer, T.},
  journal={IEEE Transactions on Parallel and Distributed Systems}, 
  title={Integrated range comparison for data-parallel compilation systems}, 
  year={1999},
  volume={10},
  number={5},
  pages={448-458},
  abstract={A major difficulty in restructuring compilation, and in parallel programming in general, is how to compare parallel performance over a range of system and problem sizes. Execution time varies with system and problem size and an initially fast implementation may become slow when system and problem size scale up. This paper introduces the concept of range comparison. Unlike conventional execution time comparison in which performance is compared for a particular system and problem size, range comparison compares the performance of programs over a range of ensemble and problem sizes via scalability and performance crossing point analysis. A novel algorithm is developed to predict the crossing point automatically. The correctness of the algorithm is proven and a methodology is developed to integrate range comparison into restructuring compilations for data-parallel programming. A preliminary prototype of the methodology is implemented and tested under Vienna Fortran Compilation System. Experimental results demonstrate that range comparison is feasible and effective. It is an important asset for program evaluation, restructuring compilation, and parallel programming.},
  keywords={},
  doi={10.1109/71.770134},
  ISSN={1558-2183},
  month={May},}
@INPROCEEDINGS{772902,
  author={Sobel, A.E.K.},
  booktitle={Proceedings of the 32nd Annual Hawaii International Conference on Systems Sciences. 1999. HICSS-32. Abstracts and CD-ROM of Full Papers}, 
  title={Security analysis of Tramel}, 
  year={1999},
  volume={Track3},
  number={},
  pages={8 pp.-},
  abstract={An operational formal specification of the Tramel system is presented. Tramel is used by NASA's Jet Propulsion Laboratory to support asynchronous inter-task communication of distributed software across varying architectures and operating systems. Security analysis of communications between non-Tramel programs and Tramel is explored using an operational trace-based specification model.},
  keywords={},
  doi={10.1109/HICSS.1999.772902},
  ISSN={},
  month={Jan},}
@INPROCEEDINGS{776505,
  author={Ramirez, J.C. and Melhem, R.G.},
  booktitle={Proceedings. 19th IEEE International Conference on Distributed Computing Systems (Cat. No.99CB37003)}, 
  title={Reducing message overhead in TMR systems}, 
  year={1999},
  volume={},
  number={},
  pages={45-54},
  abstract={Traditional TMR protocols assume either single, reliable voters for each triple-modular redundant unit (TMRU) or triplicated voters (one for each processor) for each TMRU. In the first case a voter is a single point of failure for the system. In the second case, many physical messages must be sent across the communication network for each logical data item. We examine some protocols which attempt to maintain the functionality of the triplicated voter TMR protocol while reducing the number of physical messages required by one third. Possible solutions are examined to the many issues that result from this reduction in communication. Three different reduced-communication triple-modular redundant (RTMR) protocols are considered, each of which makes different assumptions about the nature of the underlying computation.},
  keywords={},
  doi={10.1109/ICDCS.1999.776505},
  ISSN={1063-6927},
  month={June},}
@INPROCEEDINGS{779739,
  author={Zhou and Kuo-Chung Tai},
  booktitle={1999 Proceedings International Symposium on Software Engineering for Parallel and Distributed Systems}, 
  title={Deadlock analysis of synchronous message-passing programs}, 
  year={1999},
  volume={},
  number={},
  pages={62-69},
  abstract={Reachability analysis of a concurrent program involves the derivation of states of the program and the detection of deadlocks and other types of faults. To perform reachability analysis of a concurrent program P, the number of instances of each process type in P needs to be determined. How to select such numbers for P is a difficult issue. If these numbers are large, reachability analysis of P needs huge memory and very long CPU time. If these numbers are small, we have little confidence on whether P is deadlock-free for larger numbers of instances of process types in P. A deadlock cutoff number C for a process type T in P means that if under certain conditions P with C instances of T has no deadlocks, then P has no dead locks for any number of instances of T. We describe methods for finding deadlock cutoff numbers for three types of synchronous message-passing programs. Our methods are based on the theory of Milner's CCS. By applying these methods, the effort for detecting deadlocks in many synchronous message-passing programs can be significantly reduced. Empirical results of applying our methods to solutions to the dining philosophers and readers and writers problems are presented.},
  keywords={},
  doi={10.1109/PDSE.1999.779739},
  ISSN={},
  month={May},}
@INPROCEEDINGS{789219,
  author={Velamparambil, S.V. and Schutt-Aine, J.E. and Nickel, J.G. and Song, J.M. and Chew, W.C.},
  booktitle={IEEE Antennas and Propagation Society International Symposium. 1999 Digest. Held in conjunction with: USNC/URSI National Radio Science Meeting (Cat. No.99CH37010)}, 
  title={Solving large scale electromagnetic problems using a Linux cluster and parallel MLFMA}, 
  year={1999},
  volume={1},
  number={},
  pages={636-639 vol.1},
  abstract={The second half of the 1990s has witnessed the development of two important concepts in computational sciences. First, the fast multipole method (FMM) and its multilevel variants (MLFMA) have evolved into a powerful technique allowing researchers to solve large scale problems in electromagnetics. The other is in the area of commodity parallel computing. The development of fast but inexpensive microprocessors, the evolution of Linux as a reliable and efficient operating system, and message passing standards (MPI) have prompted various researchers to construct inexpensive high performance parallel computers from commodity components. By combining the two technologies, that of the MLFMA and the commodity parallel computers, one can solve large scale electromagnetic simulations fairly inexpensively. However, in order to exploit the computing power offered by a cluster of personal computers, efficient parallel implementations of MLFMA using the message passing paradigm have to be developed. We have previously developed a portable, parallel library, called ScaleME, for MLFMA for electrodynamic and acoustic integral equation solvers (Velamparambil et al., 1998). This library uses MPI for communication and has been tested successfully on a variety of parallel computers. As an attempt to solve large scale electromagnetic scattering problems on parallel computers made from commodity components using ScaleME, we previously constructed a Linux network, called the Orion cluster, from commodity components. In this paper, we demonstrate the combined power of ScaleME and Orion through a set of test problems.},
  keywords={},
  doi={10.1109/APS.1999.789219},
  ISSN={},
  month={July},}
@INPROCEEDINGS{778932,
  author={Daesuk Kwon and Sangyong Han and Heunghwan Kim},
  booktitle={Proceedings Fourth International Symposium on Parallel Architectures, Algorithms, and Networks (I-SPAN'99)}, 
  title={MPI backend for an automatic parallelizing compiler}, 
  year={1999},
  volume={},
  number={},
  pages={152-157},
  abstract={Many naive parallel processing schemes were not as successful as many researchers thought, because of the heavy cost of communication and synchronization resulting from parallelization. In this paper, we identify the reasons for this poor performance and the compiler requirements for performance improvement. We realized that the parallelizing decisions should be derived from the overhead information. We added this idea to the automatic parallelizing compiler SUIF. We substituted the original backend of SUIF with our backend using MPI, and gave it the capability to validate parallelization decisions based on overhead parameters. This backend converts shared memory-based parallel programs into distributed memory-based parallel programs with MPI function calls without excessive parallelization, which causes performance degradation.},
  keywords={},
  doi={10.1109/ISPAN.1999.778932},
  ISSN={1087-4089},
  month={June},}
@INPROCEEDINGS{795707,
  author={Qiang, J. and Ryne, R.D. and Habib, S.},
  booktitle={Proceedings of the 1999 Particle Accelerator Conference (Cat. No.99CH36366)}, 
  title={Parallel object-oriented design in Fortran for beam dynamics simulations}, 
  year={1999},
  volume={1},
  number={},
  pages={366-368 vol.1},
  abstract={In this paper we describe an object-oriented software design approach, using Fortran 90 (F90) and the Message Passing Interface (MPI), for modeling the transport of intense charged particle beams. The object-oriented approach improves the maintainability, reusability, and extensibility of the software, while the use of explicit message passing provides the freedom necessary to achieve high performance. Furthermore, an approach to object-oriented design based on Fortran will help those physicists familiar with procedure-oriented programming to make the transition to object-oriented design. In this paper we describe the implementation of this approach and our success in developing two-dimensional and three-dimensional parallel beam dynamics codes that achieve high performance with only a small overhead associated with the object-oriented design.},
  keywords={},
  doi={10.1109/PAC.1999.795707},
  ISSN={},
  month={March},}
@INPROCEEDINGS{797416,
  author={Sundar, N.S. and Jayanthi, S. and Sadayappan, P. and Visbal, M.},
  booktitle={Proceedings of the 1999 International Conference on Parallel Processing}, 
  title={An incremental methodology for parallelizing legacy stencil codes on message-passing computers}, 
  year={1999},
  volume={},
  number={},
  pages={302-310},
  abstract={There is considerable interest in converting existing production sequential/vector codes into scalable portable parallel message-passing programs. However the task is very tedious and error prone. In this paper we describe a systematic incremental methodology that greatly eases parallelization of stencil codes, by operating in a single address space while addressing data partitioning issues and then transitioning to multiple address spaces to handle communication and synchronization issues. The approach has been successfully used in manually parallelizing a production CFD code. Since the steps in the methodology are formalized as algorithms, the approach is amenable to automation.},
  keywords={},
  doi={10.1109/ICPP.1999.797416},
  ISSN={0190-3918},
  month={Sep.},}
@INPROCEEDINGS{797383,
  author={Kwan-Po Wong and Cho-Li Wang},
  booktitle={Proceedings of the 1999 International Conference on Parallel Processing}, 
  title={Push-Pull Messaging: a high-performance communication mechanism for commodity SMP clusters}, 
  year={1999},
  volume={},
  number={},
  pages={12-19},
  abstract={Push-Pull Messaging is a novel messaging mechanism for high-speed interprocess communication in a cluster of symmetric multi-processors (SMP) machines. This messaging mechanism exploits the parallelism in SMP nodes by allowing the execution of communication stages of a messaging event on different processors to achieve maximum performance. Push-Pull Messaging facilitates further improvement on communication performance by employing three optimizing techniques in our design: (1) Cross-Space Zero Buffer provides a unified buffer management mechanism to achieve a copy-less communication for the data transfer among processes within a SMP node. (2) Address Translation Overhead Masking removes the address translation overhead from the critical path in the internode communication. (3) Push-and-Acknowledge Overlapping overlaps the push and acknowledge phases to hide the acknowledge latency. Overall, Push-Pull Messaging effectively utilizes the system resources and improves the communication speed. It has been implemented to support high-speed communication for connecting quad Pentium Pro SMPs with 100 Mbit/s Fast Ethernet.},
  keywords={},
  doi={10.1109/ICPP.1999.797383},
  ISSN={0190-3918},
  month={Sep.},}
@ARTICLE{798312,
  author={Helary, J. and Mostefaoui, A. and Raynal, M.},
  journal={IEEE Transactions on Parallel and Distributed Systems}, 
  title={Communication-induced determination of consistent snapshots}, 
  year={1999},
  volume={10},
  number={9},
  pages={865-877},
  abstract={A classical way to determine consistent snapshots consists in using Chandy-Lamport's algorithm. This algorithm relies on specific control messages that allow processes to synchronize local checkpoint determination and message recording in order for the resulting snapshot to be consistent. This paper investigates a communication-induced approach to determine consistent snapshots. In such an approach, control information is carried out by application messages. Two abstract necessary and sufficient conditions are stated: one associated with global checkpoint consistency, the other associated with message recording. A general protocol is derived from these abstract conditions. Actually, this general protocol can be instantiated in distinct ways, giving rise to a family of communication-induced snapshot protocols. This general protocol shows there is an intrinsic trade-off between the number of forced checkpoints and the number of recorded messages. Finally, a particular instantiation of the general protocol is provided.},
  keywords={},
  doi={10.1109/71.798312},
  ISSN={1558-2183},
  month={Sep.},}

@INPROCEEDINGS{805096,
  author={Kongmunvattana, A. and Nian-Feng Tzeng},
  booktitle={Proceedings of the 18th IEEE Symposium on Reliable Distributed Systems}, 
  title={Logging and recovery in adaptive software distributed shared memory systems}, 
  year={1999},
  volume={},
  number={},
  pages={202-211},
  abstract={Software distributed shared memory (DSM) improves the programmability of message-passing machines and workstation clusters by providing a shared memory abstract (i.e., a coherent global address space) to programmers. As in any distributed system, however; the probability of software DSM failures increases as the system size grows. This paper presents a new efficient logging protocol for adaptive software DSM (ADSM), called adaptive logging (AL). It is suitable for both coordinated and independent checkpointing since it speeds up the recovery process and eliminates the unbounded rollback problem associated with independent checkpointing. By leveraging the existing coherence data maintained by ADSM, our AL protocol adapts to log only unrecoverable data (which cannot be recreated or retrieved after a failure) necessary for correct recovery, reducing both the number of messages logged and the amount of logged data. We have performed experiments on a cluster of eight Sun Ultra-5 workstations, comparing our AL protocol against the previous message logging (ML) protocol by implementing both protocols in TreadMarks-based ADSM. The experimental results show that our AL protocol consistently outperforms the ML protocol: Our protocol increases the execution time slightly by 2% to 10% during failure-free execution, while the ML protocol lengthens the execution time by many folds due to its larger log size and higher number of messages logged. Our AL-based recovery also outperforms ML-based recovery by 9% to 17% under parallel application examined.},
  keywords={},
  doi={10.1109/RELDIS.1999.805096},
  ISSN={1060-9857},
  month={Oct},}
@INPROCEEDINGS{805319,
  author={Ye Pu and Andresen, D.},
  booktitle={Proceedings. The Eighth International Symposium on High Performance Distributed Computing (Cat. No.99TH8469)}, 
  title={Distributed processing for cinematic holographic particle image velocimetry}, 
  year={1999},
  volume={},
  number={},
  pages={343-344},
  abstract={Recently the GEMINI Holographic Particle Image Velocimetry (HPIV) system developed in the Laser Flow Diagnostics (LFD) lab at Kansas State University has been successfully applied in volumetric 3D flow velocity measurement. Due to the 3D nature of this application, very large computation and communication requirements are imposed. An innovation algorithm, the Concise Cross Correlation (CCC), is employed in the system to extract velocity field from the hologram of the test flows. With CCC we achieved a compression ratio of 10/sup 4/ and a processing speed 1000 times faster than with traditional 3D FFT-based correlation. To further accelerate the processing speed for fully time- and space-resolved measurement, parallel processing is necessary. We present our design for a distributed system supporting this previously unparallelized application, and comment on our experiences implementing a master-slave distributed version of CCC utilizing MPI. Brief experimental results on Gigabit Ethernet and multiprocessor Pentium Xeon systems are given.},
  keywords={},
  doi={10.1109/HPDC.1999.805319},
  ISSN={1082-8907},
  month={Aug},}
@INPROCEEDINGS{805295,
  author={Agbaria, A.M. and Friedman, R.},
  booktitle={Proceedings. The Eighth International Symposium on High Performance Distributed Computing (Cat. No.99TH8469)}, 
  title={Starfish: fault-tolerant dynamic MPI programs on clusters of workstations}, 
  year={1999},
  volume={},
  number={},
  pages={167-176},
  abstract={This paper reports on the architecture and design of Starfish, an environment for executing dynamic (and static) MPI-2 programs on a cluster of workstations. Starfish is unique in being efficient, fault-tolerant, highly available, and dynamic as a system internally, and in supporting fault-tolerance and dynamicity for its application programs as well. Starfish achieves these goals by combining group communication technology with checkpoint/restart, and uses a novel architecture that is both flexible and portable and keeps group communication outside the critical data path, for maximum performance.},
  keywords={},
  doi={10.1109/HPDC.1999.805295},
  ISSN={1082-8907},
  month={Aug},}
@INPROCEEDINGS{806401,
  author={Lukowicz, P.},
  booktitle={Proceedings. 6th International Conference on Parallel Interconnects (PI'99) (Formerly Known as MPPOI)}, 
  title={The PHOTOBUS smart pixel interconnection system for symmetric multiprocessing using workstation clusters}, 
  year={1999},
  volume={},
  number={},
  pages={106-113},
  abstract={This paper describes how a smart pixel/fibre ribbon interconnection system, PHOTOBUS, can be used to extend the symmetric multiprocessor architecture usually found in multiprocessor workstations to workstation clusters. This could significantly simplify the programming of such clusters, increase their efficiency for a wide range of applications, and provide a uniform programming model for multiprocessor workstations and workstation clusters. The paper describes the protocols necessary to correctly and efficiently implement a symmetric multi-processor using the PHOTOBUS interconnection. We also present the results of a simulation of the performance of such systems using the SPLASH-2 shared memory benchmarks. The simulation demonstrates that good efficiency can be achieved using currently feasible technology.},
  keywords={},
  doi={10.1109/PI.1999.806401},
  ISSN={},
  month={Oct},}
@INPROCEEDINGS{807525,
  author={Zhiyuan Li},
  booktitle={1999 International Conference on Parallel Architectures and Compilation Techniques (Cat. No.PR00425)}, 
  title={Reducing cache conflicts by partitioning and privatizing shared arrays}, 
  year={1999},
  volume={},
  number={},
  pages={183-190},
  abstract={Parallelizing compilers for shared-memory multiprocessors typically generate fork-join programs in which multiple threads may access different sections of shared arrays. Each thread tends to access discontiguous addresses due to the gap between sections which belong to different arrays. Such interarray discontiguity often causes cache-set conflicts even when the private cache is large enough to hold the working set. A compiler technique, called array partition and privatization (or APP), is proposed to correct this problem. The APP technique partitions a shared array into sections, one for each computing thread, and then maps each section to the private stack of the corresponding thread. Interarray discontiguity is thus removed and the cache performance improved. This paper presents a compiler algorithm for APP and preliminary experimental results based on four benchmark programs running on an SGI Origin 2000 multiprocessor.},
  keywords={},
  doi={10.1109/PACT.1999.807525},
  ISSN={1089-795X},
  month={Oct},}
@INPROCEEDINGS{805105,
  author={Gendelman, E. and Bic, L.F. and Dillencourt, M.B.},
  booktitle={Proceedings of the 18th IEEE Symposium on Reliable Distributed Systems}, 
  title={An efficient checkpointing algorithm for distributed systems implementing reliable communication channels}, 
  year={1999},
  volume={},
  number={},
  pages={290-291},
  abstract={This paper presents a new checkpointing algorithm that guarantees the semantics of reliable communication channels despite the crash and recovery of processes. This algorithm requires O(n+m) communication messages, where n is the number of participating processes, and m is the number of "late" messages. The algorithm is nonblocking, requires minimal message logging, and has minimal stable storage requirements. This algorithm is also scalable, simple transparent to the user, and facilitates fast recovery. By introducing suitable delay in the checkpointing process, the parameter m can be made small. We also describe a variant of the algorithm that requires only O(n) messages, at a cost of O(n) additional storage for each process.},
  keywords={},
  doi={10.1109/RELDIS.1999.805105},
  ISSN={1060-9857},
  month={Oct},}
@INPROCEEDINGS{805079,
  author={Anastasi, G. and Bartoli, A. and Spadoni, F.},
  booktitle={Proceedings of the 18th IEEE Symposium on Reliable Distributed Systems}, 
  title={Group multicast in distributed mobile systems with unreliable wireless network}, 
  year={1999},
  volume={},
  number={},
  pages={14-23},
  abstract={We propose a multicast protocol for a distributed system that includes mobile hosts. The protocol guarantees reliable delivery, i.e. delivery of every multicast and absence of duplicates. The sender of each multicast may select among three increasingly strong delivery ordering guarantees: FIFO, causal, total. We make loose assumptions on the underlying computing system: (i) we consider an unreliable wireless network i.e. one that provides only incomplete spatial coverage and such that messages could be lost even within cells (e.g., due to physical obstructions); (ii) movements are unpredictable, i.e. a user that leaves a cell may enter any other cell, perhaps after a potentially long disconnection. Our solution does not store any sensible state information at mobile support stations, thus movements do not trigger the transmission query message in the wired network and no notion of hand-off is used. Furthermore, movements at inopportune times can cause only occasional performance penalty but do not affect correctness. Weak assumptions on the underlying computing system, absence of state information at mobile support stations and loose mobility assumptions, contribute to improve the reliability of applications deployed over the proposed protocol.},
  keywords={},
  doi={10.1109/RELDIS.1999.805079},
  ISSN={1060-9857},
  month={Oct},}
@INPROCEEDINGS{810896,
  author={Butler, D. and Roe, P.},
  booktitle={ICWC 99. IEEE Computer Society International Workshop on Cluster Computing}, 
  title={Sharing the Garden GATE: towards an efficient uniform programming model for CLUMPS}, 
  year={1999},
  volume={},
  number={},
  pages={271-277},
  abstract={Gardens integrates a programming language and system to support parallel computation over a network of workstations. Our goal is to develop extensions to Gardens allowing it to efficiently support clusters of SMP machines under a uniform programming model. Such support requires the implementation of high-performance shared memory message passing primitives as well as changes to the existing model invariants and the Gardens runtime system itself: The new communication primitives have demonstrated a minimum latency of 2.0 microseconds and can maintain a maximum bandwidth of approximately 194 MB/s on our test system. The NAS benchmarks, EP and CG have also demonstrated significant performance increases when parallelised by Gardens. The major contribution of this work is a system that efficiently supports multiprocessor computers in a network of workstations with a uniform programming model. Such a system promises to greatly simplify the task of developing high-performance parallel applications to run on CLUMPS.},
  keywords={},
  doi={10.1109/IWCC.1999.810896},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{810820,
  author={Taki, H. and Utard, G.},
  booktitle={ICWC 99. IEEE Computer Society International Workshop on Cluster Computing}, 
  title={MPI-IO on a parallel file system for cluster of workstations}, 
  year={1999},
  volume={},
  number={},
  pages={150-157},
  abstract={Since the MPI-IO definition, a standard interface for parallel IO, some implementations are available for clusters of workstations, but the performances are within the limits of the file system (typically NFS). New parallel file systems are now available on clusters of workstations and provide higher performances. A first idea is to interface such a parallel file system to a portable implementation of MPI-IO. We present first experimental results of a straightforward port of ROMIO, an MPI-IO implementation from Argonne National Laboratory, on PVFS, a parallel file system for cluster from Clemson University. We measure the performances for typical file accesses found in data-parallel applications, and we compare the results with the performances of ROMIO on NFS.},
  keywords={},
  doi={10.1109/IWCC.1999.810820},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{811023,
  author={Sureswaran, R. and Tharmaraj, K. and Guyennet, H. and Lapayre, J.C. and Chan, H.Y.},
  booktitle={1999 Internet Workshop. IWS99. (Cat. No.99EX385)}, 
  title={A fully distributed architecture to support multimedia conferencing}, 
  year={1999},
  volume={},
  number={},
  pages={261-267},
  abstract={As networks grow larger and faster, new forms of applications have to be created to support these massive infrastructures. High-bandwidth networks are being implemented to support large amounts of network traffic. The types of traffic that can be seen by these networks can be broadly classified under three categories: traffic that need not be real-time transference, traffic that needs to be real-time but non-interactive, and traffic that needs to be real-time and interactive. Real-time multimedia applications are becoming an important part of today's networks. Such applications are gaining popularity for both the Internet and corporate intranets. In order to allow the current and future network structures to support such high bandwidth- and resource-hungry applications, a form of distributed processing is necessary. This paper discusses the design and implementation of such a distributed system. This system should also be implemented in a black-box style format, where the inputs, outputs and requirements of the black box are clearly defined. Also, they can plug into a network and perform their functionality or be unplugged without crashing the system. Message passing is done by using the Internet Protocol. Thus, IP packets are used to transmit both control information and data to these entities and the output will be IP formatted packets as well. This paper takes you, step by step, through the theory, design stages, implementation, testing and commissioning of an example application which uses this distributed architecture. This application is a desktop multi-point multimedia conferencing system called MCS Version 4.O.},
  keywords={},
  doi={10.1109/IWS.1999.811023},
  ISSN={},
  month={Feb},}
@INPROCEEDINGS{794010,
  author={Barth, T. and Flender, G. and Freisleben, B. and Thilo, F.},
  booktitle={Proceedings of the International Symposium on Distributed Objects and Applications}, 
  title={Load distribution in a CORBA environment}, 
  year={1999},
  volume={},
  number={},
  pages={158-166},
  abstract={The design and implementation of a CORBA load distribution service for distributed scientific computing applications running in a network of workstations is described. The proposed approach is based on integrating load distribution into the CORBA naming service which in turn relies on information provided by the underlying WINNER resource management system developed for typical networked Unix workstation environments. The necessary extensions to the naming service, the WINNER features for collecting load information and the placement decisions are described. A prototypical implementation of the complete system is presented, and performance results obtained for the parallel optimization of a mathematical test function are discussed.},
  keywords={},
  doi={10.1109/DOA.1999.794010},
  ISSN={},
  month={Sep.},}
@INPROCEEDINGS{1592648,
  author={Mahinthakumar, G. and Hoffman, F.M. and Hargrove, W.W. and Karonis, N.T.},
  booktitle={SC '99: Proceedings of the 1999 ACM/IEEE Conference on Supercomputing}, 
  title={Multivariate Geographic Clustering in A Metacomputing Environment Using Globus}, 
  year={1999},
  volume={},
  number={},
  pages={5-5},
  abstract={The authors present a metacomputing application of multivariate, nonhierarchical statistical clustering to geographic environmental data from the 48 conterminous United States in order to produce maps of regions of ecological similarity, called ecoregions. These maps represent finer scale regionalizations than do those generated by the traditional technique: an expert with a marker pen. Several variables (e.g., temperature, organic matter, rainfall etc.) thought to affect the growth of vegetation are clustered at resolutions as fine as one square kilometer (1 km2). These data can represent over 7.8 million map cells in an n-dimensional (n = 9 to 25) data space. A parallel version of the iterative statistical clustering algorithm is developed by the authors using the MPI (Message Passing Interface) message passing routines. The parallel algorithm uses a classical, self-scheduling, single-program, multiple data (SPMD) organization; performs dynamic load balancing for reasonable performance in heterogeneous metacomputing environments; and provides fault tolerance by saving intermediate results for easy restarts in case of hardware failure. The parallel algorithm was tested on various geographically distributed heterogeneous metacomputing configurations involving an IBM SP3TM, an IBM SP2TM, and two SGI Origin 2000TM ’s. The tests were performed with minimal code modification, and were made possible by GlobusTM (a metacomputing software toolkit) and the Globus-enabled version of MPI (MPICH-G). Our performance tests indicate that while the algorithm works reasonably well under the metacomputing environment for a moderate number of processors, the communication overhead can become prohibitive for large processor configurations.},
  keywords={},
  doi={10.1145/331532.331537},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{1592698,
  author={Ji Qiang and Ryne, R. and Habib, S. and Decyk, V.},
  booktitle={SC '99: Proceedings of the 1999 ACM/IEEE Conference on Supercomputing}, 
  title={An Object-Oriented Parallel Particle-in-Cell Code for Beam Dynamics Simulation in Linear Accelerators}, 
  year={1999},
  volume={},
  number={},
  pages={55-55},
  abstract={In this paper, we present an object-oriented three-dimensional parallel particle-in-cell code for beam dynamics simulation in linear accelerators. A two-dimensional parallel domain decomposition approach is employed within a message passing programming paradigm along with a dynamic load balancing. Implementing object-oriented software design provides the code with better maintainability, reusability, and extensibility compared with conventional structure based code. This also helps to encapsulate the details of communication syntax. Performance tests on SGI/Cray T3E-900 and SGI Origin 2000 machines showgood scalability of the object-oriented code. Some important features of this code also include employing symplectic integration with linear maps of external focusing elements and using z as the independent variable, typical in accelerators. A successful application was done to simulate beam transport through three superconducting sections in the APT linac design.},
  keywords={},
  doi={10.1145/331532.331587},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{1592699,
  author={Zhiqiang Wang and Lupo, J. and McKenney, A. and Pachter, R.},
  booktitle={SC '99: Proceedings of the 1999 ACM/IEEE Conference on Supercomputing}, 
  title={Large Scale Molecular Dynamics Simulations with Fast Multipole Implementations}, 
  year={1999},
  volume={},
  number={},
  pages={56-56},
  abstract={We present the performance of the fast molecular dynamics (FMD) code designed for efficient, object-oriented, and scalable large scale molecular simulations. FMD uses an implementation of the three-dimensional fast multipole method, FMM3D, developed in our group. The Fast Multipole Method offers an efficient way (order O(N)) to handle long range electrostatic interactions, thus enabling a more realistic molecular dynamics simulation of large molecular systems. The performance testing was carried out on IBM SP2, SGI Origin 2000, and CRAY T3E systems with the MPI message passing system. Two models, a random charged particle model of up to 100,000 charges wth only non-bonded interactions, and a real molecular model of more than 35,000 atoms with full atomic interactions, are used for the order-N and parallel scalability testing. An application to a liquid crystalline material will be discussed.},
  keywords={},
  doi={10.1145/331532.331588},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{949310,
  author={Dewaraja, Y.K. and Ljungberg, M. and Majumdar, A. and Bose, A. and Koral, K.F.},
  booktitle={2000 IEEE Nuclear Science Symposium. Conference Record (Cat. No.00CH37149)}, 
  title={A parallel Monte Carlo code for planar and SPECT imaging: implementation, verification and applications in /sup 131/I SPECT}, 
  year={2000},
  volume={3},
  number={},
  pages={20/30-20/34 vol.3},
  abstract={This paper reports the implementation of the SIMIND Monte Carlo code on a IBM SP2 distributed memory parallel computer. Basic aspects of running Monte Carlo particle transport calculations on parallel architectures are described. The authors' parallelization is based on equally partitioning photons among the processors and uses the Message Passing Interface (MPI) library for interprocessor communication and the Scalable Parallel Random Number Generator (SPRNG) to generate uncorrelated random number streams. These parallelization techniques are also applicable to other distributed memory architectures. A linear increase in computing speed with the number of processors is demonstrated for up to 32 processors. This speed-up is especially significant in Single Photon Emission Computed Tomography (SPECT) simulations involving higher energy photon emitters, where explicit modeling of the phantom and collimator is required. For /sup 131/I, the accuracy of the parallel code is demonstrated by comparing simulated and experimental SPECT images from a heart/thorax phantom. Clinically realistic SPECT simulations using the voxel-man phantom are carried out to assess scatter and attenuation correction.},
  keywords={},
  doi={10.1109/NSSMIC.2000.949310},
  ISSN={1082-3654},
  month={Oct},}
@ARTICLE{842952,
  author={Gorlatch, S.},
  journal={IEEE Transactions on Software Engineering}, 
  title={Toward formally-based design of message passing programs}, 
  year={2000},
  volume={26},
  number={3},
  pages={276-288},
  abstract={Presents a systematic approach to the development of message passing programs. Our programming model is SPMD, with communications restricted to collective operations: scan, reduction, gather, etc. The design process in such an architecture-independent language is based on correctness-preserving transformation rules that are provable in a formal functional framework. We develop a set of design rules for composition and decomposition. For example, scan followed by reduction is replaced by a single reduction, and global reduction is decomposed into two faster operations. The impact of the design rules on the target performance is estimated analytically and tested in machine experiments. As a case study, we design two provably correct, efficient programs using the Message Passing Interface (MPI) for the famous maximum segment sum problem, starting from an intuitive, but inefficient, algorithm specification.},
  keywords={},
  doi={10.1109/32.842952},
  ISSN={1939-3520},
  month={March},}
@INPROCEEDINGS{839533,
  author={Tanaka, K. and Takizawa, M.},
  booktitle={Proceedings Third IEEE International Symposium on Object-Oriented Real-Time Distributed Computing (ISORC 2000) (Cat. No. PR00607)}, 
  title={Asynchronous checkpointing protocol for object-based systems}, 
  year={2000},
  volume={},
  number={},
  pages={218-225},
  abstract={We discuss how to take checkpoints in object based systems. Object based checkpoints are consistent in the object based system but may be inconsistent according to the traditional message based definition. We present an asynchronous protocol for taking object based checkpoints among objects. An object to take a checkpoint in the traditional protocol does not take a checkpoint if the current checkpoint is object based consistent with the other objects. The number of checkpoints can be reduced by the protocol.},
  keywords={},
  doi={10.1109/ISORC.2000.839533},
  ISSN={},
  month={March},}
@INPROCEEDINGS{850175,
  author={Hong, C. and Shen, C.M.},
  booktitle={2000 IEEE Power Engineering Society Winter Meeting. Conference Proceedings (Cat. No.00CH37077)}, 
  title={Implementation of parallel algorithms for transient stability analysis on a message passing multicomputer}, 
  year={2000},
  volume={2},
  number={},
  pages={1410-1415 vol.2},
  abstract={Real time transient stability analysis is a challenging computing problem. In order to speed up the solution of this problem, parallel processing technologies have been applied. In this paper, the implementation of parallel algorithms for power system transient stability analysis on a message passing multicomputer is described. Both parallelism-in-space and parallelism-in-time are exploited. Test simulations are performed for two large-scale power systems using an IBM SP2 parallel computer. Speedup results are presented to show the performance of the proposed algorithms.},
  keywords={},
  doi={10.1109/PESW.2000.850175},
  ISSN={},
  month={Jan},}
@INPROCEEDINGS{854009,
  author={Tovar, E. and Vasques, F.},
  booktitle={Proceedings 12th Euromicro Conference on Real-Time Systems. Euromicro RTS 2000}, 
  title={Non pre-emptive scheduling of messages on SMTV token-passing networks}, 
  year={2000},
  volume={},
  number={},
  pages={209-218},
  abstract={Fieldbus communication networks aim to interconnect sensors, actuators and controllers within distributed computer-controlled systems. Therefore, they constitute the foundation upon which real-time applications are to be implemented. A specific class of fieldbus communication networks is based on a simplified version of token-passing protocols, where each station may transfer, at most, a single message per token visit (SMTV). In this paper, we establish an analogy between non-preemptive task scheduling in single processors and the scheduling of messages on SMTV token-passing networks. Moreover, we clearly show that concepts such as blocking and interference in non-preemptive task scheduling have their counterparts in the scheduling of messages on SMTV token-passing networks. Based on this task/message scheduling analogy, we provide pre-run-time schedulability conditions for supporting real-time messages with SMTV token-passing networks. We provide both utilisation-based and response time tests to perform the pre-run-time schedulability analysis of real-time messages on SMTV token-passing networks, considering RM/DM (rate monotonic/deadline monotonic) and EDF (earliest deadline first) priority assignment schemes.},
  keywords={},
  doi={10.1109/EMRTS.2000.854009},
  ISSN={1068-3070},
  month={June},}
@INPROCEEDINGS{854636,
  author={Blaovec, J.D. and Luginsland, J.W. and Watrous, J.J.},
  booktitle={ICOPS 2000. IEEE Conference Record - Abstracts. 27th IEEE International Conference on Plasma Science (Cat. No.00CH37087)}, 
  title={Application of a parallel two-dimensional particle-in-cell code}, 
  year={2000},
  volume={},
  number={},
  pages={99-},
  abstract={Summary form only given. ICEPIC (Improved Concurrent Electromagnetic Particle-In-Cell), developed by the Air Force Research Lab, is a 3-D Particle-In-Cell (PIC) code that was designed to execute efficiently on parallel architectures using the MPI message passing standard. Its primary application is to simulate collisionless plasma physics in high-power microwave devices. Recently, ICEPIC was extended to include the functionality to simulate these devices in two dimensions. ICEPIC still remains a parallel code, but can now perform 3-D as well as 2-D simulations without being recompiled. This allows the researcher to perform quick initial simulations in two dimensions. The final design can then be validated in three dimensions to include the three-dimensional aspects of the device that could not be simulated with a two-dimensional PIC code. Comparisons of two-dimensional ICEPIC calculations to three-dimensional ICEPIC calculations were presented at ICOPS99. Comparisons of two-dimensional ICEPIC calculations to other two-dimensional PIC codes will be presented this year.},
  keywords={},
  doi={10.1109/PLASMA.2000.854636},
  ISSN={0730-9244},
  month={June},}
@INPROCEEDINGS{852458,
  author={Vestal, S.},
  booktitle={Proceedings Sixth IEEE Real-Time Technology and Applications Symposium. RTAS 2000}, 
  title={Formal verification of the MetaH executive using linear hybrid automata}, 
  year={2000},
  volume={},
  number={},
  pages={134-144},
  abstract={MetaH is a language and toolset for the development of real time high assurance software. There is an associated executive that is automatically configured by the tools to perform the task and message scheduling specified for an application. Linear hybrid automata are finite state automata augmented with real-valued variables. Transitions between discrete states may be conditional on the values of these variables and may reassign variables. These variables can be used to model real time and accumulated task compute time as well as program variables. We developed a concurrent linear hybrid automata model for that portion of the MetaH executive software that implements task scheduling and time partitioning. A reachability analysis was performed to verify selected properties for a selected set of application configurations. The approach combines aspects of testing and verification and automates much of the modeling and analysis. There are limits on the degree of assurance that can be provided, but the approach may be more thorough and less expensive than some traditional testing methods.},
  keywords={},
  doi={10.1109/RTTAS.2000.852458},
  ISSN={1080-1812},
  month={May},}
@INPROCEEDINGS{868985,
  author={Kewley, J.M. and Prodan, R.},
  booktitle={Proceedings. 34th International Conference on Technology of Object-Oriented Languages and Systems - TOOLS 34}, 
  title={A distributed object-oriented framework for tool development}, 
  year={2000},
  volume={},
  number={},
  pages={353-362},
  abstract={In recent years, there has been a substantial increase in the availability and quality of software engineering tools; such tools are invaluable in ensuring program correctness and identifying performance problems. The majority of these, however, do not interoperate and are available on a limited platform set. We analyse such deficiencies and propose an extensible architecture for a distributed software engineering tool framework using CORBA object-oriented technology. The resulting framework provides a unified interface for parallel, distributed and single-processor systems, facilitates tool development, promotes tool interoperability, and can be extended by the integration of new tools and services. This flexibility is demonstrated by the specification of an extension to support the MPI programming paradigm and a wide selection of tools that have been built using the system.},
  keywords={},
  doi={10.1109/TOOLS.2000.868985},
  ISSN={1530-2067},
  month={Aug},}
@INPROCEEDINGS{869110,
  author={Meth, K.Z. and Tuel, W.G.},
  booktitle={Proceedings 2000. International Workshop on Parallel Processing}, 
  title={Parallel checkpoint/restart without message logging}, 
  year={2000},
  volume={},
  number={},
  pages={253-258},
  abstract={We describe a parallel checkpoint/restart mechanism. The checkpoint is performed among the participating parallel tasks using a new algorithm that we call "Stop and Discard". Tasks may be checkpointed without waiting for previously sent messages to be received. Specific message logging is not required. Message data that may be in transit is saved in the checkpoint files.},
  keywords={},
  doi={10.1109/ICPPW.2000.869110},
  ISSN={1530-2016},
  month={Aug},}
@ARTICLE{844491,
  author={Nyland, L.S. and Prins, J.F. and Goldberg, A. and Mills, P.H.},
  journal={IEEE Transactions on Software Engineering}, 
  title={A design methodology for data-parallel applications}, 
  year={2000},
  volume={26},
  number={4},
  pages={293-314},
  abstract={A methodology for the design and development of data-parallel applications and components is presented. Data-parallelism is a well understood form of parallel computation, yet developing simple applications can involve substantial efforts to express the problem in low level notations. We describe a process of software development for data-parallel applications starting from high level specifications, generating repeated refinements of designs to match different architectural models and performance constraints, enabling a development activity with cost benefit analysis. Primary issues are algorithm choice, correctness, and efficiency, followed by data decomposition, load balancing, and message passing coordination. Development of a data-parallel multitarget tracking application is used as a case study, showing the progression from high to low level refinements. We conclude by describing tool support for the process.},
  keywords={},
  doi={10.1109/32.844491},
  ISSN={1939-3520},
  month={April},}
@INPROCEEDINGS{845991,
  author={Blough, D.M. and Peng Liu},
  booktitle={Proceedings 14th International Parallel and Distributed Processing Symposium. IPDPS 2000}, 
  title={FIMD-MPI: a tool for injecting faults into MPI application}, 
  year={2000},
  volume={},
  number={},
  pages={241-247},
  abstract={Parallel computing is seeing increasing use in critical applications. The need therefore arises to test the robustness of parallel applications in the presence of exceptional conditions, or faults. Communication-software-based fault injection is an extremely flexible approach to robustness testing in message-passing parallel computers. A fault injection methodology and tool that use this approach are presented. The tool, known as FIMD-MPI, allows injection of faults into MPI-based applications. The structure and operation of FIMD-MPI are described and the use of the tool is illustrated on an example fault-tolerant MPI application.},
  keywords={},
  doi={10.1109/IPDPS.2000.845991},
  ISSN={},
  month={May},}
@INPROCEEDINGS{846604,
  author={DongSheng Cai and Quanming Lu},
  booktitle={Proceedings Fourth International Conference/Exhibition on High Performance Computing in the Asia-Pacific Region}, 
  title={Parallel PIC code using Java on PC cluster}, 
  year={2000},
  volume={1},
  number={},
  pages={495-500 vol.1},
  abstract={The Java language has emerged as a dominant language that could eventually replace C++, due to it being object-oriented, architecture neutral, multi-threaded etc. and its support for applets. But Java is believed to be "too slow" for scientific computing. Many high-performance PCs such as those based on the Pentium II have been introduced, and these have great potential for high-performance computing. We are currently building a dual PentiumPro PC cluster. In this report, using a test skeleton-PIC-code developed by Prof. V.K. Decyk of UCLA for benchmarking purposes, we have measured the performance of the Java language in serial and parallel on our PC cluster compared with the Fortran language which is the main language for scientific computing. In our benchmarking, we use JavaMPI as an interface to MPI for message passing between PCs through a 100Base-TX/10Base-T Ethernet switch. The benchmark results indicate that Java is a good candidate for scientific computing.},
  keywords={},
  doi={10.1109/HPC.2000.846604},
  ISSN={},
  month={May},}
@INPROCEEDINGS{846585,
  author={Xue-Bin Chi},
  booktitle={Proceedings Fourth International Conference/Exhibition on High Performance Computing in the Asia-Pacific Region}, 
  title={Some factors of affecting performance of numerical parallel computation}, 
  year={2000},
  volume={1},
  number={},
  pages={395-398 vol.1},
  abstract={In this paper some factors affecting the performance of numerical parallel computing are analyzed. For a distributed parallel computer system, it includes the effective library utilization, parallel algorithm design, and selection of message passing functions. For a shared memory multiprocessor system, the affect of the parallel compiler is discussed. From an analysis and experiment of parallel computing of linear algebra problems, the above mentioned facts are found to be very important in improving the performance of numerical parallel computation. The scalability of a parallel program is also discussed. The numerical testing is performed on Dawning 1000, Dawning 2000, SR2201, T3E and Power Challenge.},
  keywords={},
  doi={10.1109/HPC.2000.846585},
  ISSN={},
  month={May},}
@ARTICLE{846297,
  author={Prakash, S. and Deelman, E. and Bagrodia, R.},
  journal={IEEE Transactions on Software Engineering}, 
  title={Asynchronous parallel simulation of parallel programs}, 
  year={2000},
  volume={26},
  number={5},
  pages={385-400},
  abstract={Parallel simulation of parallel programs for large datasets has been shown to offer significant reduction in the execution time of many discrete event models. The paper describes the design and implementation of MPI-SIM, a library for the execution driven parallel simulation of task and data parallel programs. MPI-SIM can be used to predict the performance of existing programs written using MPI for message passing, or written in UC, a data parallel language, compiled to use message passing. The simulation models can be executed sequentially or in parallel. Parallel execution of the models are synchronized using a set of asynchronous conservative protocols. The paper demonstrates how protocol performance is improved by the use of application-level, runtime analysis. The analysis targets the communication patterns of the application. We show the application-level analysis for message passing and data parallel languages. We present the validation and performance results for the simulator for a set of applications that include the NAS Parallel Benchmark suite. The application-level optimization described in the paper yielded significant performance improvements in the simulation of parallel programs, and in some cases completely eliminated the synchronizations in the parallel execution of the simulation model.},
  keywords={},
  doi={10.1109/32.846297},
  ISSN={1939-3520},
  month={May},}
@INPROCEEDINGS{873606,
  author={Hotchkiss, R. and O'Neill, B.C. and Clark, S.},
  booktitle={Proceedings International Conference on Parallel Computing in Electrical Engineering. PARELEC 2000}, 
  title={Fault tolerance for an embedded wormhole switched network}, 
  year={2000},
  volume={},
  number={},
  pages={79-83},
  abstract={The effectiveness of parallel and distributed systems depends heavily upon the reliability and efficiency of the method used for information transfer. To satisfy these requirements, the communication medium must supply fault tolerance throughout the communication layers, but should minimise operational overheads. The work described relates to a scalable communication system for a distributed-memory parallel processing architecture, which is constructed with message routing switches. The system employs a hardware mechanism that is local to each physical connection, which provides a distributed solution for fault detection and isolation. By isolating faults and the use of adaptive routing algorithms, networks may be designed that will maintain operability in the presence of faults. An explanation of the basic switch and fault isolation mechanism is provided. The paper concludes with implementation details of the operational hardware and details of the environment, in which it has been tested.},
  keywords={},
  doi={10.1109/PCEE.2000.873606},
  ISSN={},
  month={Aug},}
@INPROCEEDINGS{873593,
  author={Hillson, R. and Iglewski, M.},
  booktitle={Proceedings International Conference on Parallel Computing in Electrical Engineering. PARELEC 2000}, 
  title={C++2MPI: a software tool for automatically generating MPI datatypes from C++ classes}, 
  year={2000},
  volume={},
  number={},
  pages={13-17},
  abstract={The Message Passing Interface I.I (MPI I.I) standard defines a library of message-passing functions for parallel and distributed computing. We have developed a new software tool called C++2MPI which can automatically generate MPI derived datatypes for a specified C++ class. C++2MPI can generate data types for derived classes, for partially and fully-specialized templated classes, and for classes with private data members. Given one or more user-provided classes as input, C++2MPI generates, compiles and archives a function for creating the MPI derived datatype. When the generated function is executed, it builds the derived MPI datatype if the datatype does not already exist, and returns the value of an MPI handle for referencing the datatype. PGMT (Processing Graph Method Tool) is a set of application program interfaces for porting the Processing Graph Method (PGM), a parallel programming method, to diverse networks of processors. C++2MPI was developed as a component of PGMT, but can be used as a stand-alone tool.},
  keywords={},
  doi={10.1109/PCEE.2000.873593},
  ISSN={},
  month={Aug},}
@INPROCEEDINGS{873592,
  author={Grigoras, D. and Mihaila, S.},
  booktitle={Proceedings International Conference on Parallel Computing in Electrical Engineering. PARELEC 2000}, 
  title={A framework for component-based distributed applications design. The CODE: Component Oriented Distributed Environment}, 
  year={2000},
  volume={},
  number={},
  pages={8-12},
  abstract={This paper describes the design of CODE-Component Oriented Distributed Environment, which is a framework for building component-based distributed applications. This system uses the DCOM technology to provide a flexible infrastructure that supports communication among processes spread across a local area network (Intranet). A component-oriented architecture is also defined to make an easy and intuitive access to LAN-distributed processes, through a high level of abstraction. The encapsulation of these processes into software components allows developers to compose them in different ways in order to develop correct and cost-effective distributed applications. Another feature is the visual creation of distributed applications by drag & drop. We identify the requirements of a software layer that supports LAN client-server distributed completing, and we suggest a design that meets those requirements. Though our implementation uses C++, the fundamental ideas apply to any object-oriented language that supports (D)COM programming, messaging and threads.},
  keywords={},
  doi={10.1109/PCEE.2000.873592},
  ISSN={},
  month={Aug},}
@ARTICLE{862208,
  author={Dong Xuan and Weijia Jia and Wei Zhao and Hongwen Zhu},
  journal={IEEE Transactions on Parallel and Distributed Systems}, 
  title={A routing protocol for anycast messages}, 
  year={2000},
  volume={11},
  number={6},
  pages={571-588},
  abstract={An anycast packet is one that should be delivered to one member in a group of designated recipients. Using anycast services may considerably simplify some applications. Little work has been done on routing anycast packets. In this paper, we propose and analyze a routing protocol for anycast message. It is composed of two subprotocols: the routing table establishment subprotocol and the packet forwarding subprotocol. In the routing table establishment subprotocol, we propose four methods (SSP, MIN-D, SET, and GET) for enforcing an order among routers for the purpose of loop prevention. These methods differ from each other on information used to maintain orders, the impact on QoS, and the compatibility to the existing routing protocols. In the packet forwarding subprotocol, we propose a Weighted-Random Selection (WRS) approach for multiple path selection in order to balance network traffic. In particular, the fixed and adaptive methods are proposed to determine the weights. Both of them explicitly take into account the characteristics of distribution of anycast recipient group while the adaptive method uses the dynamic information of the anycast traffic as well. Correctness property of the protocol is formally proven. Extensive simulation is performed to evaluate our newly designed protocol. Performance data shows that the loop-prevention methods and the WRS approaches have great impact on the performance in terms of average end-to-end packet delay. In particular, the protocol using the SET or CBT loop-prevention methods and the adaptive WRS approach performs very close to a dynamic optimal routing protocol in most cases.},
  keywords={},
  doi={10.1109/71.862208},
  ISSN={1558-2183},
  month={June},}
@INPROCEEDINGS{896617,
  author={Giron-Sierra, J.M. and Halawa, S. and Rodriguez-Sanchez, J.R. and Alcaide, S.},
  booktitle={30th Annual Frontiers in Education Conference. Building on A Century of Progress in Engineering Education. Conference Proceedings (IEEE Cat. No.00CH37135)}, 
  title={A social robotics experimental project}, 
  year={2000},
  volume={2},
  number={},
  pages={S1C/18-S1C/22 vol.2},
  abstract={We have four small mobile hexapods. Each hexapod has almost no brain, but can communicate via radio with a PC, using a limited set of digital messages. The hexapods know how to move, and can detect obstacles and some kind of objects. We have four PCs, one for each hexapod (so each hexapod has a helping brain). The PCs are interconnected using the parallel port. We can assign a task for the team, for instance to explore a field. The PCs must work in a coordinated way, exchanging messages. The development of this experimental scenario has been the subject of several projects done by students involved in robotics and computer science. One of the aspects covered is the use of real time operating systems for the PCs to work together. Other aspects are related with mobile robotics and the behavior of insectoids. The general set-up has been completed recently, and a new project will start to accomplish a task and study the results. An object oriented simulation is also another new project, which will be validated against the experimental results. Every project must generate documentation for others to use it. In general, the idea is to establish an interesting challenge, with obvious results. The paper presents the main educational objectives, and describes the chief parts of the experimental set-up: robots and PCs, interconnection characteristics. Then, the paper focuses on the projects done and under way, with emphasis on the pedagogical impact.},
  keywords={},
  doi={10.1109/FIE.2000.896617},
  ISSN={0190-5848},
  month={Oct},}
@INPROCEEDINGS{895830,
  author={Fernandes, S.D.F. and Monteiro, A.M.V. and Mendes, C.L.},
  booktitle={Proceedings 13th Brazilian Symposium on Computer Graphics and Image Processing (Cat. No.PR00878)}, 
  title={Parallelism and images: a parallelization experiment for image segmentation with an application for automatic classification of scenes obtained from orbital platforms}, 
  year={2000},
  volume={},
  number={},
  pages={342-},
  abstract={Segmentation is an important step in image analysis for remote sensing; it is responsible for splitting the image into distinct parts. Current segmentation methods used in images of this type are usually based on an analysis of the pixel values in all image bands. This type of analysis can be computationally expensive. In order to reduce the processing time in the image segmentation process, this paper introduces a parallel approach to image segmentation. This method is based on a region-growing technique. The parallelism is done using the SPMD (single process, multiple data) paradigm and the message-passing model under MPI (Message Passing Interface). The results have been compared with the output of a sequential system executing in the same environment.},
  keywords={},
  doi={10.1109/SIBGRA.2000.895830},
  ISSN={1530-1834},
  month={Oct},}
@INPROCEEDINGS{857702,
  author={Hung-Chang Hsiao and Chung-Ta King},
  booktitle={Proceedings Seventh International Conference on Parallel and Distributed Systems (Cat. No.PR00568)}, 
  title={Does multicast communication make sense in write invalidation traffic?}, 
  year={2000},
  volume={},
  number={},
  pages={221-228},
  abstract={In distributed shared memory (DSM) multiprocessors, a write operation requires multiple messages to invalidate the nodes which share and cache the memory block to be written. The resulting write stall time is a performance hurdle to such systems. One approach to efficient invalidation is to use multicast messages to reach the sharing nodes. We use application driven simulation to evaluate two multicast based invalidation schemes: dual path (X. Lin and L.M. Ni, 1993) and pruning (M.P. Malumbres et al., 1996). Based on our experimental settings, we found that multicast improves invalidation traffic for four of the six evaluated real applications. The remaining two programs are computation intensive, and multicast based validation is less effective. But since they induce bursty communication, we found that multicasts help to relieve the network congestion during those periods of time. Dual path performs a little better than pruning, because it is less sensitive to routing delay in the routers. We also found that cache size is an important design parameter for multicast based invalidation. It is more effective for DSM multiprocessors with large caches.},
  keywords={},
  doi={10.1109/ICPADS.2000.857702},
  ISSN={1521-9097},
  month={July},}
@INPROCEEDINGS{857584,
  author={Mostefaoui, A. and Raynal, M. and Tronel, F.},
  booktitle={Proceeding International Conference on Dependable Systems and Networks. DSN 2000}, 
  title={The best of both worlds: A hybrid approach to solve consensus}, 
  year={2000},
  volume={},
  number={},
  pages={513-522},
  abstract={It is now well recognized that the consensus problem is a fundamental problem when one has to implement fault-tolerant distributed services in asynchronous distributed systems prone to process crash failures. This paper considers the binary consensus problem in such a system. Following an approach investigated by Aguilera and Toueg, it proposes a simple binary consensus protocol that combines failure detection and randomization. This protocol terminates deterministically when the failure detection mechanism works correctly; it terminates with probability 1, otherwise. A performance evaluation of the protocol is also provided. Last but not least, it is important to note that the proposed protocol is both efficient and simple. Additionally it can be simplified to give rise either to a deterministic failure detector-based consensus protocol or to a randomized consensus protocol.},
  keywords={},
  doi={10.1109/ICDSN.2000.857584},
  ISSN={},
  month={June},}
@INPROCEEDINGS{893625,
  author={Hiraishi, H.},
  booktitle={Proceedings of the Ninth Asian Test Symposium}, 
  title={Verification of deadlock free property of high level robot control}, 
  year={2000},
  volume={},
  number={},
  pages={198-203},
  abstract={This paper describes an efficient verification algorithm for deadlock free property of high level robot control called Task Control Architecture (TCA). TCA is a model of concurrent robot control processes. The verification tool we used is the Symbolic Model Verifier (SMV). Since the SMV is not so efficient for verification of liveness properties such as deadlock free property of many concurrent processes, we first described the deadlock free property by using safety properties that SMV can verify efficiently. In addition, we modify the symbolic model checking algorithm of the SMV so that it can handle many concurrent processes efficiently. Experimental measurements show that we can obtain more than 1000 times speed-up by these methods.},
  keywords={},
  doi={10.1109/ATS.2000.893625},
  ISSN={1081-7735},
  month={Dec},}
@INPROCEEDINGS{888347,
  author={Kandemir, M. and Ramanujam, J.},
  booktitle={Proceedings 2000 International Conference on Parallel Architectures and Compilation Techniques (Cat. No.PR00622)}, 
  title={Data relation vectors: a new abstraction for data optimizations}, 
  year={2000},
  volume={},
  number={},
  pages={227-236},
  abstract={This paper presents an abstraction called data relation vectors to improve the data access characteristics and memory layouts in a given regular computation. The key idea is to define a relation between the data elements accessed by close-by iterations and use this relation to guide to a number of optimizations for array-based computations. The specific optimizations studied in this paper include enhancing group-spatial and self-spatial reuses, improving intra-tile and inter-tile reuses, and reducing unnecessary communication on message-passing architectures. In addition, this abstraction works well with other known abstractions such as data reuse vectors. The data relation vector abstraction has been implemented in the SUIF compilation framework and has been tested using a set of twelve benchmarks from image processing and scientific computation domains. Preliminary results on a super-scalar processor show that it is successful in reducing compilation time and outperforms two previously proposed techniques, one that uses only loop transformations and one that uses both loop and data transformations. Our experiments also show that the proposed abstraction helps one to select good data tile shapes which can subsequently be used to determine iteration space tiles.},
  keywords={},
  doi={10.1109/PACT.2000.888347},
  ISSN={1089-795X},
  month={Oct},}
@INPROCEEDINGS{886452,
  author={James, J.R. and Ragsdale, D. and Schafer, J. and Presby, T.},
  booktitle={Smc 2000 conference proceedings. 2000 ieee international conference on systems, man and cybernetics. 'cybernetics evolving to systems, humans, organizations, and their complex interactions' (cat. no.0}, 
  title={Performance modeling of the advanced field artillery tactical data system}, 
  year={2000},
  volume={3},
  number={},
  pages={2257-2262 vol.3},
  abstract={Planning of complex activities is a deliberative process and automation support for re-planning activities should provide for cognitive modeling of the planning process. One approach for modeling military planning systems is to partition the process into separable components and analyze the components individually. The paper takes the position that the cognitive model should contain details of the domain being supported and, especially for support of online re-planning, knowledge of the system implementation architecture, including performance modeling of the implementation architecture. A possible issue is the failure of the separable components assumption when the system is composed of components. We discuss these thoughts in some detail and provide an overview of a test bed framework being implemented to perform experiments on the validity of this approach. In particular, we are interested in creating analysis tools that apply metrics to sensed data to assist in determining when a re-planning activity is required and in prioritizing re-planning activities. The framework is intended to support experiments with military decision making and, in particular, with re-planning activities that support execution of a military operation order (OPORD). We are investigating use of a simulation tool to accumulate information at the message-packet-level and perform analysis at the network-application-level. We discuss use of this framework for pattern recognition of activities distributed in time and space. We provide an introduction to our approach for partitioning the problem space and some ideas on design of experiments using this approach.},
  keywords={},
  doi={10.1109/ICSMC.2000.886452},
  ISSN={1062-922X},
  month={Oct},}
@INPROCEEDINGS{885392,
  author={Larrea, M. and Fernandez, A. and Arevalo, S.},
  booktitle={Proceedings 19th IEEE Symposium on Reliable Distributed Systems SRDS-2000}, 
  title={Optimal implementation of the weakest failure detector for solving consensus}, 
  year={2000},
  volume={},
  number={},
  pages={52-59},
  abstract={The concept of unreliable failure detector was introduced by T.D. Chandra and S. Toueg (1996) as a mechanism that provides information about process failures. Depending on the properties which the failure detectors guarantee, they proposed a taxonomy of failure detectors. It has been shown that one of the classes of this taxonomy, namely Eventually Strong (/spl nabla/S), is the weakest class allowing a solution of the Consensus problem. The authors present a new algorithm implementing /spl nabla/S. Our algorithm guarantees that eventually all the correct processes agree on a common correct process. This property trivially allows us to provide the accuracy and completeness properties required by /spl nabla/S. We show then that our algorithm is better than any other proposed implementation of /spl nabla/S in terms of the number of messages and the total amount of information periodically sent. In particular, previous algorithms require periodic exchange of at least a quadratic amount of information, while ours only requires O(n log n) (where n is the number of processes). However, we also propose a new measure to evaluate the efficiency of this kind of algorithm, the eventual monitoring degree, which does not rely on a periodic behavior and expresses the degree of processing required by the algorithms better. We show that the runs of our algorithm have optimal eventual monitoring degree.},
  keywords={},
  doi={10.1109/RELDI.2000.885392},
  ISSN={},
  month={Oct},}
@INPROCEEDINGS{885393,
  author={Pereira, J. and Rodrigues, L. and Oliveira, R.},
  booktitle={Proceedings 19th IEEE Symposium on Reliable Distributed Systems SRDS-2000}, 
  title={Semantically reliable multicast protocols}, 
  year={2000},
  volume={},
  number={},
  pages={60-69},
  abstract={Reliable multicast protocols can strongly simplify the design of distributed applications. However it is hard to sustain a high multicast throughput when groups are large and heterogeneous. In an attempt to overcome this limitation, previous work has focused on weakening reliability properties. The authors introduce a novel reliability model that exploits semantic knowledge to decide in which specific conditions messages can be purged without compromising application correctness. This model is based on the concept of message obsolescence: a message becomes obsolete when its content or purpose is overwritten by a subsequent message. We show that message obsolescence can be expressed in a generic way and can be used to configure the system to achieve higher multicast throughput.},
  keywords={},
  doi={10.1109/RELDI.2000.885393},
  ISSN={},
  month={Oct},}
@INPROCEEDINGS{884902,
  author={Deb, S. and Ghoshal, S. and Malepati, V.N. and Cavanaugh, K.},
  booktitle={19th DASC. 19th Digital Avionics Systems Conference. Proceedings (Cat. No.00CH37126)}, 
  title={Remote Diagnosis Server}, 
  year={2000},
  volume={2},
  number={},
  pages={6B2/1-6B2/8 vol.2},
  abstract={Modern systems such as fly-by-wire aircraft, nuclear power plants, manufacturing facilities, battlefields, etc. are all examples of highly connected network enabled systems. Many of these systems are also mission critical, and need to be monitored round the clock. Such systems typically consist of embedded sensors in networked subsystems that can transmit data to central (or remote) monitoring stations. Moreover, many legacy systems were originally not designed for real-time onboard diagnosis, but are safety critical, and would benefit from such a solution. Embedding additional software or hardware in such systems is often considered too intrusive, and introduces flight safety and validation concerns. Such systems can be equipped to transmit the sensor data to a remote-processing center for continuous health monitoring. At Qualtech Systems, we are developing a Remote Diagnosis Server (RDS) that can support multiple simultaneous diagnostic sessions from a variety of remote systems. The RDS server is built on a three-tier architecture with a "Broker" application in the middle layer, and multiple TEAMS-RT and TEAMATE based reasoners at the backend. The client layer consists of sensor agents that collect test results and transmit them over a message-passing network. The resultant solution is remarkably efficient. Even an old 50 MHz Sparc20 can support tens of concurrent sessions involving hundreds of tests. The solution scales easily to hundreds of sessions in any modern workstation or server. Inspired by the significant interest from the aerospace community, we are enhancing the scalability of our RDS solution to solve huge and complex systems such as system-wide health monitoring of the International Space station or a fleet of commercial jetliners. We also recently won an STTR from NASA to make RDS accessible to automobiles and appliances over standard wireless telephone networks.},
  keywords={},
  doi={10.1109/DASC.2000.884902},
  ISSN={},
  month={Oct},}
@INPROCEEDINGS{884669,
  author={Kitagata, G. and Sekiba, J. and Suganuma, T. and Kinoshita, T. and Shiratori, N.},
  booktitle={Proceedings Seventh International Conference on Parallel and Distributed Systems: Workshops}, 
  title={Communication mechanism of loose coupled agents in FAMES}, 
  year={2000},
  volume={},
  number={},
  pages={467-472},
  abstract={The traditional asynchronous messaging systems (e-mail systems etc.) lack many advanced features, e.g. intelligence, controllability, scalability etc. to accomplish effective and sophisticated message handling. To supplement these features, we propose a Flexible Asynchronous Messaging System (FAMES). FAMES consists of autonomous and collaborative software agents. The messaging functions are composed of an organization of agents, and enhanced messaging services which are provided through cooperative behavior of message flow control agents. The authors focus on the Communication Mechanism of Loose Coupled Agents in FAMES. The mechanism allows the flow control agents to do cooperative work without tight dependency, such as name specific communication represented by message passing. We show how the loose coupled flow control agents cooperate via a black board. A prototype of the system is implemented and the proposed functionalities are verified.},
  keywords={},
  doi={10.1109/PADSW.2000.884669},
  ISSN={},
  month={July},}
@ARTICLE{881719,
  author={Sridhar Ramesh and Perros, H.G.},
  journal={IEEE Transactions on Software Engineering}, 
  title={A multilayer client-server queueing network model with synchronous and asynchronous messages}, 
  year={2000},
  volume={26},
  number={11},
  pages={1086-1100},
  abstract={We analyze a multilayered queueing network that models a client-server system where clients and servers communicate via synchronous and asynchronous messages. The servers are organized in groups such that they form a multilayered hierarchical structure. The queueing network is approximately analyzed using a decomposition algorithm. Numerical tests show that the approximation algorithm has a good accuracy.},
  keywords={},
  doi={10.1109/32.881719},
  ISSN={1939-3520},
  month={Nov},}
@ARTICLE{879780,
  author={Fong Pong and Dubois, M.},
  journal={IEEE Transactions on Parallel and Distributed Systems}, 
  title={Formal automatic verification of cache coherence in multiprocessors with relaxed memory models}, 
  year={2000},
  volume={11},
  number={9},
  pages={989-1006},
  abstract={State-based, formal methods have been successfully applied to the automatic verification of cache coherence in sequentially consistent systems. However, coherence in shared memory multiprocessors under a relaxed memory model is much more complex to verify automatically. With relaxed memory models, incoming invalidations and outgoing updates can be delayed in each cache while processors are allowed to race ahead. This buffering of memory accesses considerably increases the amount of state in each cache and the complexity of protocol interactions. Moreover, because caches can hold inconsistent copies of the same data for long periods of time, coherence cannot be verified by simply checking that cached copies are identical at all times. This paper makes two major contributions. First, we demonstrate how to model and verify cache coherence under a relaxed memory model in the context of state-based verification methods. Frameworks for modeling the hardware and for generating correct memory access sequences driving the hardware model are developed. We also show correctness properties which must be verified on the hardware model. Second, we demonstrate a successful application of a state-based verification tool called SSM for the verification of the delayed protocol, an aggressive protocol for relaxed memory models. SSM is based on an abstraction technique preserving the properties to verify. We show that with classical, explicit approaches the verification of cache coherence is realistically unfeasible because of the state space explosion problem, whereas SSM is able to verify protocols both at both behavioral and message-passing levels.},
  keywords={},
  doi={10.1109/71.879780},
  ISSN={1558-2183},
  month={Sep.},}
@INPROCEEDINGS{911533,
  author={Abdallah, A.E. and Hawkins, J.},
  booktitle={ICECS 2000. 7th IEEE International Conference on Electronics, Circuits and Systems (Cat. No.00EX445)}, 
  title={Calculational design of special purpose parallel algorithms}, 
  year={2000},
  volume={1},
  number={},
  pages={261-267 vol.1},
  abstract={This paper adopts a transformational programming approach for deriving massively parallel algorithms from functional specifications. It gives a brief description of a framework for relating key higher order functions such as map, reduce, and scan with communicating processes with different configurations. The parallelisation of many interesting functional algorithms can then be systematically synthesized by combining "off the shelf" parallel implementations of instances of these higher order functions. Efficiency in the final message-passing algorithms is achieved by exploiting data parallelism, for generating the intermediate results in parallel; and functional parallelism, for processing intermediate results in stages such that the output of one stage is simultaneously input to the next one. This approach is illustrated through a case study for testing whether all the elements of a given list are distinct. Bird-Meertens formalism is used to concisely carry out algebraic transformations.},
  keywords={},
  doi={10.1109/ICECS.2000.911533},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{926675,
  author={Qiang Sun and Hao Zhang and Jianhui Zhang},
  booktitle={Proceedings of the 33rd Annual Hawaii International Conference on System Sciences}, 
  title={A time-stamp based solution for collective resource acquisition in a distributed system}, 
  year={2000},
  volume={},
  number={},
  pages={10 pp. vol.2-},
  abstract={In some distributed systems, resources are leased, usually for a fixed period of time. For instance, a client leases a network printer for ten minutes. We consider the first step of leasing-acquisition, and extend the concept of the acquisition of a single resource to that of a collection of resources. In such a context, clients must have simultaneous access to all of the requested resources for the lease to be useful. The paper describes designs and implementations for collective acquisition of resources in distributed systems. It begins with the application background of our research, followed by the formalization of the problem. We then introduce our algorithm and prove its correctness. Two implementations are specified and compared. Evaluation of the performance of the algorithms is based on the measurements of the network overhead caused by the exchange of control messages, and the measurements of the average response time for the requests. Implemented in Java, our system makes novel use of multicast to enhance performance and uses heart-beat heuristics to achieve fault resilience. Finally, we propose approaches to optimize the system performance exploiting soft global state information.},
  keywords={},
  doi={10.1109/HICSS.2000.926675},
  ISSN={},
  month={Jan},}
@INPROCEEDINGS{840969,
  author={Tai, A.T. and Tso, K.S. and Alkalai, L. and Chau, S.N. and Sanders, W.H.},
  booktitle={Proceedings 20th IEEE International Conference on Distributed Computing Systems}, 
  title={On low-cost error containment and recovery methods for guarded software upgrading}, 
  year={2000},
  volume={},
  number={},
  pages={548-555},
  abstract={To assure dependable onboard evolution, we have developed a methodology called guarded software upgrading (GSU). We focus on a low-cost approach to error containment and recovery for GSU. To ensure low development cost, we exploit inherent system resource redundancies as the fault tolerance means. In order to mitigate the effect of residual software faults at low performance cost, we take a crucial step in devising error containment and recovery methods by introducing the confidence-driven notion. This notion complements the message-driven (or communication-induced) approach employed by a number of existing checkpointing protocols for tolerating hardware faults. In particular, we discriminate between the individual software components with respect to our confidence in their reliability and keep track of changes of our confidence (due to knowledge about potential process state contamination) in particular processes. This, in turn, enables the individual processes in the spaceborne distributed system to make decisions locally at run-time, on whether to establish a checkpoint upon message passing and whether to roll back or roll forward during error recovery. The resulting message-driven confidence-driven approach enables cost-effective checkpointing and cascading-rollback free recovery.},
  keywords={},
  doi={10.1109/ICDCS.2000.840969},
  ISSN={1063-6927},
  month={April},}
@INPROCEEDINGS{840901,
  author={Misikangas, P. and Raatikainen, K.},
  booktitle={Proceedings 20th IEEE International Conference on Distributed Computing Systems}, 
  title={Agent migration between incompatible agent platforms}, 
  year={2000},
  volume={},
  number={},
  pages={4-10},
  abstract={Several general purpose agent platforms exist, for example, Voyager, Jade, and Grasshopper, each of which provides an environment for building and executing software agents. Unfortunately, the platforms are usually incompatible with each other. Thus, agents built for one platform cannot be used in another platform, nor can they interact with agents in other platforms. Some effort has been put into standardizing agent communication and migration in FIPA and in OMG, but these standards are not yet supported by most of the existing platforms. Therefore, we should find some other ways to allow interaction between agents in different platforms. We show that it is possible to make platform independent agents that are able to migrate between incompatible platforms. We also describe how messages can be delivered to agents in other platforms, and show how to build platform independent service agents that are used via method calls. The ideas have been tested in practice with Voyager, Jade, and Grasshopper platforms.},
  keywords={},
  doi={10.1109/ICDCS.2000.840901},
  ISSN={1063-6927},
  month={April},}
@INPROCEEDINGS{840956,
  author={Taesoon Park and Yeom, H.Y.},
  booktitle={Proceedings 20th IEEE International Conference on Distributed Computing Systems}, 
  title={An asynchronous recovery scheme based on optimistic message logging for mobile computing systems}, 
  year={2000},
  volume={},
  number={},
  pages={436-443},
  abstract={This paper presents an asynchronous recovery scheme to provide fault-tolerance for mobile computing systems. The proposed scheme is based on optimistic message logging, since the checkpointing-only schemes are not suitable for the mobile environment in which unreliable mobile hosts and fragile network connection may hinder any kind of coordination for checkpointing and recovery. Also, in order to reduce the overhead imposed on mobile hosts, mobile support stations take charge of logging and dependency tracking, and mobile hosts maintain only a small amount of information for mobility tracking. As a result, truly asynchronous recovery for mobile systems can be achieved with little overhead.},
  keywords={},
  doi={10.1109/ICDCS.2000.840956},
  ISSN={1063-6927},
  month={April},}
@INPROCEEDINGS{840842,
  author={Pop, P. and Eles, P. and Peng, Z.},
  booktitle={Proceedings Design, Automation and Test in Europe Conference and Exhibition 2000 (Cat. No. PR00537)}, 
  title={Bus access optimization for distributed embedded systems based on schedulability analysis}, 
  year={2000},
  volume={},
  number={},
  pages={567-574},
  abstract={We present an approach to bus access optimization and schedulability analysis for the synthesis of hard real-time distribution embedded systems. The communication model is based on a time-triggered protocol. We have developed an analysis for the communication delays proposing four different message scheduling policies over a time-triggered communication channel. Optimization strategies for the bus access scheme are developed, and the four approaches to message scheduling are compared using extensive experiments.},
  keywords={},
  doi={10.1109/DATE.2000.840842},
  ISSN={},
  month={March},}
@ARTICLE{814651,
  author={Shang, J.S. and Wagner, M. and Pan, Y. and Blake, D.C.},
  journal={Computing in Science & Engineering}, 
  title={Strategies for adopting FVTD on multicomputers [finite-volume time-domain analysis]}, 
  year={2000},
  volume={2},
  number={1},
  pages={10-21},
  abstract={Using the Message Passing Interface (MPI), Power Fortran and autotasking programming models, the authors have ported a sequential finite-volume numerical procedure, called Max3D, for solving the time-dependent (FVTD) Maxwell equations, to multicomputers. They have also demonstrated and verified a previously unobtainable high-frequency bistatic radar cross-section for a perfectly electrical conducting sphere.},
  keywords={},
  doi={10.1109/5992.814651},
  ISSN={1558-366X},
  month={Jan},}
@INPROCEEDINGS{1592732,
  author={Roy, A. and Foster, I. and Gropp, W. and Karonis, N. and Sander, V. and Toonen, B.},
  booktitle={SC '00: Proceedings of the 2000 ACM/IEEE Conference on Supercomputing}, 
  title={MPICH-GQ: Quality-of-Service for Message Passing Programs}, 
  year={2000},
  volume={},
  number={},
  pages={19-19},
  abstract={Parallel programmers typically assume that all resources required for a program’s execution are dedicated to that purpose. However, in local and wide area networks, contention for shared networks, CPUs, and I/O systems can result in significant variations in availability, with consequent adverse effects on overall performance. We describe a new message-passing architecture, MPICH-GQ, that uses quality of service (QoS) mechanisms to manage contention and hence improve performance of message passing interface (MPI) applications. MPICH-GQ combines new QoS specification, traffic shaping, QoS reservation, and QoS implementation techniques to deliver QoS capabilities to the high-bandwidth bursty flows, complex structures, and reliable protocols used in high-performance applications-characteristics very different from the low-bandwidth, constant bit-rate media flows and unreliable protocols for which QoS mechanisms were designed. Results obtained on a differentiated services testbed demonstrate our ability to maintain application performance in the face of heavy network contention.},
  keywords={},
  doi={10.1109/SC.2000.10017},
  ISSN={1063-9535},
  month={Nov},}
@INPROCEEDINGS{1592740,
  author={Ji Qiang and Ryne, R.D. and Habib, S.},
  booktitle={SC '00: Proceedings of the 2000 ACM/IEEE Conference on Supercomputing}, 
  title={Self-Consistent Langevin Simulation of Coulomb Collisions in Charged-Particle Beams}, 
  year={2000},
  volume={},
  number={},
  pages={27-27},
  abstract={In many plasma physics and changed-particle beam dynamics problems, Coulomb collisions are modeled by a Fokker-Planck equation. In order to incorporate these collisions, we present a three-dimensional parallel Langevin simulation method using a Particle-In-Cell (PIC) approach implemented on high-performance parallel computers. We perform, for the first time, a fully self-consistent simulation, in which the friction and diffusion coefficients are computed from first principles. We employ a two-dimensional domain decomposition approach within a message passing programming paradigm along with dynamic load balancing. Object oriented programming is used to encapsulate details of the communication syntax as well as to enhance reusability and extensibility. Performance tests on the SGI Origin 2000, IBM SP RS/6000 and the Cray T3E-900 have demonstrated good scalability. As a test example, we demonstrate the collisional relaxation to a final thermal equilibrium of a beam with an initially anisotropic velocity distribution.},
  keywords={},
  doi={10.1109/SC.2000.10047},
  ISSN={1063-9535},
  month={Nov},}
@INPROCEEDINGS{1592764,
  author={Vetter, J.S. and de Supinski, B.R.},
  booktitle={SC '00: Proceedings of the 2000 ACM/IEEE Conference on Supercomputing}, 
  title={Dynamic Software Testing of MPI Applications with Umpire}, 
  year={2000},
  volume={},
  number={},
  pages={51-51},
  abstract={As evidenced by the popularity of MPI (Message Passing Interface), message passing is an effective programming technique for managing coarse-grained concurrency on distributed computers. Unfortunately, debugging message-passing applications can be difficult. Software complexity, data races, and scheduling dependencies can make programming errors challenging to locate with manual, interactive debugging techniques. This article describes Umpire, a new tool for detecting programming errors at runtime in message passing applications. Umpire monitors the MPI operations of an application by interposing itself between the application and the MPI runtime system using the MPI profiling layer. Umpire then checks the application’s MPI behavior for specific errors. Our initial collection of programming errors includes deadlock detection, mismatched collective operations, and resource exhaustion. We present an evaluation on a variety of applications that demonstrates the effectiveness of this approach.},
  keywords={},
  doi={10.1109/SC.2000.10055},
  ISSN={1063-9535},
  month={Nov},}
@INPROCEEDINGS{983078,
  author={Ibrahim, M.A.M. and Xinda, L. and Rwakarambi, J.M.},
  booktitle={2001 International Conferences on Info-Tech and Info-Net. Proceedings (Cat. No.01EX479)}, 
  title={Parallel execution of an irregular algorithm depth first search (DFS) on heterogeneous clusters of workstation}, 
  year={2001},
  volume={3},
  number={},
  pages={328-332 vol.3},
  abstract={This paper presents a status report on our efforts and experiences with heterogeneous clusters of workstation based on dynamic load balancing for parallel tree computation depth-first-search (DFS) project at the High Performance Computing laboratory in Shanghai Jiaotong University. We describe an implementation of one parallel search algorithm DFS, running under the MPI message passing interface and Solaris operating system on heterogeneous workstation clusters. The main goal of this paper is to demonstrate the speed gained by the heterogeneous workstation clusters platform computing to solve large search problem, distribute the tree search space among the processors and show through a parallel simulation application, the maturity of the more recent technologies. We have run the parallelism and distribution of the search space of the DFS algorithm among the processors successfully found that the critical issue in parallel DFS algorithm is the distribution of the search space among the processors. First experimental results of parallel DFS are given for tests that will serve as a starting point for further development of our project. We are presenting our preliminary progress here, and we expect in the near future to demonstrate a real dynamic load balancing for DFS algorithm running on heterogeneous clusters of workstation computing platform resulting in a good load balance among all the processors.},
  keywords={},
  doi={10.1109/ICII.2001.983078},
  ISSN={},
  month={Oct},}
@ARTICLE{970581,
  author={Pedone, F.},
  journal={Computer}, 
  title={Boosting system performance with optimistic distributed protocols}, 
  year={2001},
  volume={34},
  number={12},
  pages={80-86},
  abstract={Optimistic distributed protocols can dramatically improve system performance if the underlying system assumptions are sound and carry a high degree of probability. Optimistic protocols aggressively execute actions based on best-case system assumptions. Using optimistic protocols unquestionably involves tradeoffs, but if a protocol is well designed and the optimistic assumptions hold frequently enough, the gain in performance outweighs the overhead of repairing actions that execute incorrectly. Optimistic distributed protocols can dramatically improve system performance if the underlying system assumptions are sound and carry a high degree of probability.},
  keywords={},
  doi={10.1109/2.970581},
  ISSN={1558-0814},
  month={Dec},}
@INPROCEEDINGS{965981,
  author={Yeo, E. and Pakzad, P. and Nikolic, B. and Anantharam, V.},
  booktitle={GLOBECOM'01. IEEE Global Telecommunications Conference (Cat. No.01CH37270)}, 
  title={High throughput low-density parity-check decoder architectures}, 
  year={2001},
  volume={5},
  number={},
  pages={3019-3024 vol.5},
  abstract={Two decoding schedules and the corresponding serialized architectures for low-density parity-check (LDPC) decoders are presented. They are applied to codes with parity-check matrices generated either randomly or using geometric properties of elements in Galois fields. Both decoding schedules have low computational requirements. The original concurrent decoding schedule has a large storage requirement that is dependent on the total number of edges in the underlying bipartite graph, while a new, staggered decoding schedule which uses an approximation of the belief propagation, has a reduced memory requirement that is dependent only on the number of bits in the block. The performance of these decoding schedules is evaluated through simulations on a magnetic recording channel.},
  keywords={},
  doi={10.1109/GLOCOM.2001.965981},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{966820,
  author={Thuente, D.J. and Whiteman, J.K.},
  booktitle={Proceedings Sixth IEEE International Symposium on High Assurance Systems Engineering. Special Topic: Impact of Networking}, 
  title={Systems engineering of communication protocols for command and control systems}, 
  year={2001},
  volume={},
  number={},
  pages={194-205},
  abstract={This paper presents an overview of the ten-year ongoing systems engineering effort for the communication system design of the preeminent command and control fire support system used by the United States Army and Marines today. The system is known as the Advanced Field Artillery Tactical Data System (AFATDS). The primary focus of this paper is the design of the communication system and the protocols that were developed to meet the requirements of time critical messages. The protocol designed for AFATDS has subsequently become a major component in MIL-STD-188-220B. Simulation results for critical design decisions are presented. General bandwidth utilization, throughput, and message latency were the primary concerns early in the systems engineering study. The performance for the most time critical messages, Check Fires, was subsequently studied and solved. Additional systems engineering work to enhance the protocols to further improve the performance for Check Fire messages are discussed.},
  keywords={},
  doi={10.1109/HASE.2001.966820},
  ISSN={1530-2059},
  month={Oct},}
@INPROCEEDINGS{989476,
  author={Jun Zhou and Kuo-Chung Tai},
  booktitle={Proceedings 12th International Symposium on Software Reliability Engineering}, 
  title={Efficient deadlock analysis of clients/server systems with two-way communication}, 
  year={2001},
  volume={},
  number={},
  pages={222-231},
  abstract={Deadlocks are a common type of fault in distributed programs. To detect deadlocks in a distributed program P, one approach is to construct the reachability graph (RG) of P, which contains all possible states of P. Since the size of RG(P) is an exponential function of the number of processes in P, the use of RGs for deadlock detection has limited success. The authors present an efficient technique for deadlock analysis of client/server programs with two-way communication, where the server and clients communicate through channels supporting synchronous message-passing. We consider client/server programs in which the server saves the IDs of some clients for future communication. For such a program, we describe how to construct its abstract client/server reachability graph (ACSRG), which contains a significantly smaller number of global states than the corresponding RG. One example is that for a solution to the gas station problem with one pump and six customers, its RG has 25394 states and its ACSRG 74 states. We show that the use of ACSRGs not only greatly reduces the effort for deadlock analysis but also provides a basis for proving freedom from deadlocks for any number of clients.},
  keywords={},
  doi={10.1109/ISSRE.2001.989476},
  ISSN={1071-9458},
  month={Nov},}
@INPROCEEDINGS{989481,
  author={Aizenbud-Reshef, N.},
  booktitle={Proceedings 12th International Symposium on Software Reliability Engineering}, 
  title={Coverage analysis for message flows}, 
  year={2001},
  volume={},
  number={},
  pages={276-286},
  abstract={Application messaging focuses on enabling integration, linking and extension of business applications. This focus has led to intelligent middleware development that encompasses a modular, plug and play components approach to providing an open message broker framework. A message broker is a value-added application-to-application middleware service that comprises one or more software facilities. It is capable of one-to-many, many-to-one and many-to-many message distribution. A message broker further enables one to decompose information transformation and routing requirements into message flows, which are a series of stepwise operations that can be connected using visual composition tools. A message flow is a new programming paradigm that supports message transformation, database integration, message warehousing, and message routing. In this paper we introduce the message flow concept and its execution model. Next, we concentrate on the definition of test adequacy criteria suitable for message flows and the description of a coverage analysis tool, based on the defined coverage criteria. The coverage analysis tool collects execution details from trace files, analyzes them and presents the coverage results to the user in an intuitive manner, both visually and textually.},
  keywords={},
  doi={10.1109/ISSRE.2001.989481},
  ISSN={1071-9458},
  month={Nov},}
@INPROCEEDINGS{989820,
  author={Fredlund, L.-A. and Gurov, D. and Noll, T.},
  booktitle={Proceedings 16th Annual International Conference on Automated Software Engineering (ASE 2001)}, 
  title={Semi-automated verification of Erlang code}, 
  year={2001},
  volume={},
  number={},
  pages={319-323},
  abstract={Erlang is a functional programming language with support for concurrency and message passing communication that is used at Ericsson for developing telecommunication applications. We consider the challenge of verifying temporal properties of systems programmed in Erlang with dynamically evolving process structures. To accomplish this, a rich verification framework for goal-directed, proof system-based verification is used. The paper investigates the problem of semi-automating the verification task by identifying the proof parameters crucial for successful proof search.},
  keywords={},
  doi={10.1109/ASE.2001.989820},
  ISSN={1938-4300},
  month={Nov},}
@INPROCEEDINGS{955120,
  author={Kurkoski, B.M. and Siegel, P.H. and Wolf, J.K.},
  booktitle={Proceedings 2001 IEEE Information Theory Workshop (Cat. No.01EX494)}, 
  title={Message-passing decoders and their application to storage systems}, 
  year={2001},
  volume={},
  number={},
  pages={12-13},
  abstract={Message-passing has been proposed for decoding parity check codes, especially low density parity check (LDPC) codes. We propose using message-passing detectors for partial response channels. Furthermore, we investigate how a single message-passing detector/decoder can be matched to a combination of a partial response channel and a LDPC code.},
  keywords={},
  doi={10.1109/ITW.2001.955120},
  ISSN={},
  month={Sep.},}
@INPROCEEDINGS{955124,
  author={Jilei Hou and Siegel, P.H. and Milstein, L.B. and Pfister, H.D.},
  booktitle={Proceedings 2001 IEEE Information Theory Workshop (Cat. No.01EX494)}, 
  title={Design of low-density parity-check codes for bandwidth efficient modulation}, 
  year={2001},
  volume={},
  number={},
  pages={24-26},
  abstract={We design low-density parity-check (LDPC) codes for bandwidth efficient modulation using a multilevel coding (MLC) technique. We develop a method to analyze the asymptotic performance of the LDPC codes using message-passing decoding at each level of the MLC scheme as the codeword length goes to infinity. Simulation of very large block size LDPC codes verifies the accuracy of the analytical results. We jointly optimize the code rates and code parameters of the LDPC codes at each level of the MLC scheme, and the asymptotic performance of the optimized irregular LDPC codes is very close to the channel capacity of the additive white Gaussian noise (AWGN) channel.},
  keywords={},
  doi={10.1109/ITW.2001.955124},
  ISSN={},
  month={Sep.},}
@INPROCEEDINGS{952077,
  author={Tourino, J. and Doallo, R.},
  booktitle={International Conference on Parallel Processing, 2001.}, 
  title={Characterization of message-passing overhead on the AP3000 multicomputer}, 
  year={2001},
  volume={},
  number={},
  pages={321-328},
  abstract={The performance of the communication primitives of parallel computers is critical for the overall system performance. The characterization of the communication overhead is very important to estimate the global performance of parallel applications and to detect possible bottlenecks. In this paper, we evaluate, model and compare the performance of the message-passing libraries provided by the Fujitsu AP3000 multicomputer: MPI/AP, PVM/AP and APlib. Our aim is to fairly characterize the communication primitives using general models and performance metrics.},
  keywords={},
  doi={10.1109/ICPP.2001.952077},
  ISSN={0190-3918},
  month={Sep.},}
@INPROCEEDINGS{962535,
  author={Roy, N.K.},
  booktitle={Proceedings IEEE International Symposium on Network Computing and Applications. NCA 2001}, 
  title={Real time resource management and adaptive parallel programming for a cluster of computers: a comparison of different approaches in a computationally intensive environment}, 
  year={2001},
  volume={},
  number={},
  pages={216-226},
  abstract={Two classic problems that are computationally intensive and show good speedup and scalability when solved in a parallel programming environment are used to test the different resource allocation and management algorithms used with the node intrusion and failure experiment. We divide the adaptive resource allocation experiments into two groups: (i) automatic survivability and scalability (ii) assessment of real-time quality of service (QoS). In the former, we use different algorithms to detect failed programs, host and network resources and idle times, computing an allocation, enactment of an allocation, and restart notification. We also use different techniques to detect dynamic paths that are receiving poor QoS possibly due to overload and to "scale up" such paths via reallocation. In the latter case, we use different fitness functions to classify the connections and the resources available on the nodes and study the effects of these on the overall resource allocation and the eventual speedup.},
  keywords={},
  doi={10.1109/NCA.2001.962535},
  ISSN={},
  month={Oct},}
@ARTICLE{962986,
  author={Sveda, M. and Vrba, R.},
  journal={Computer}, 
  title={Executable specifications for embedded distributed systems}, 
  year={2001},
  volume={34},
  number={1},
  pages={138-143},
  abstract={Combining hardware components with an executable specification language facilitates the specification prototyping of embedded distributed systems. The specification language should cover process management, timing, and communication commands that real-time executive and communication task services of every node prototype can interpret. We use a technique that employs attribute grammars and either a macro processor or Prolog to execute the language.},
  keywords={},
  doi={10.1109/2.962986},
  ISSN={1558-0814},
  month={Jan},}
@INPROCEEDINGS{935961,
  author={Junsheng Han and Takeshita, O.Y.},
  booktitle={Proceedings. 2001 IEEE International Symposium on Information Theory (IEEE Cat. No.01CH37252)}, 
  title={On the decoding structure for multiple turbo codes}, 
  year={2001},
  volume={},
  number={},
  pages={98-},
  abstract={We consider message-passing strategies for the iterative decoding of multiple turbo codes (MTCs). We contradict the conventional wisdom that the parallel decoding structure is the best for MTCs by proposing new non-parallel decoding structures which give better BER performances for the same computational complexity. Under a modified independent Gaussian assumption (IGA), we are able to theoretically validate our design, which is further supported by extensive simulation results.},
  keywords={},
  doi={10.1109/ISIT.2001.935961},
  ISSN={},
  month={June},}
@INPROCEEDINGS{922829,
  author={Ip, M.T.W. and Lin, W.W.K. and Wong, A.K.Y. and Dillon, T.S. and Dianhui Wang},
  booktitle={Fourth IEEE International Symposium on Object-Oriented Real-Time Distributed Computing. ISORC 2001}, 
  title={An adaptive buffer management algorithm for enhancing dependability and performance in mobile-object-based real-time computing}, 
  year={2001},
  volume={},
  number={},
  pages={138-144},
  abstract={In an ORC (object oriented real time computing) environment, it is important to reduce message retransmissions during message passing because these retransmissions cause significant time delay, and this makes it difficult to achieve the necessary timeliness. A cause of retransmission is message loss due to buffer overflow at the reception side. Here a P+I+D (P for proportional, I for integral and D for derivative) adaptive buffer control algorithm is proposed to prevent such possible overflow. The I control depends on the Convergence Algorithm (CA), which is a stable and efficient IEPM (Internet End-to-End Performance Measurement) tool that predicts the mean message roundtrip time (RTT) of a communication channel quickly and accurately. The P+I+D algorithm was tested under different conditions in a mobile ORC (MORC) environment where mobile agents collaborate freely over the Internet. The different test results confirm that the proposed P+I+D approach is indeed effective for preventing buffer overflow.},
  keywords={},
  doi={10.1109/ISORC.2001.922829},
  ISSN={},
  month={May},}
@INPROCEEDINGS{923171,
  author={Batchu, R. and Neelamegam, J.P. and Zhenqian Cui and Beddhu, M. and Skjellum, A. and Dandass, Y. and Apte, M.},
  booktitle={Proceedings First IEEE/ACM International Symposium on Cluster Computing and the Grid}, 
  title={MPI/FT/sup TM/: architecture and taxonomies for fault-tolerant, message-passing middleware for performance-portable parallel computing}, 
  year={2001},
  volume={},
  number={},
  pages={26-33},
  abstract={MPI has proven effective for parallel applications in situations with neither QoS nor fault handling. Emerging environments motivate fault-tolerant MPI middleware. Environments include space-based, wide-area/web/meta computing and scalable clusters. MPI/FT, the system described in the paper, trades off sufficient MPI fault coverage against acceptable parallel performance, based on mission requirements and constraints. MPI codes are evolved to use MPI/FT features. Non-portable code for event handlers and recovery management is isolated. User-coordinated recovery, checkpointing, transparency and event handling, as well as evolvability of legacy MPI codes form key design criteria. Parallel self-checking threads address four levels of MPI implementation robustness, three of which are portable to any multithreaded MPI. A taxonomy of application types provides six initial fault-relevant models; user-transparent parallel nMR computation is thereby considered. Key concepts from MPI/RT-real-time MPI-are also incorporated into MPI/FT, with further overt support for MPI/RT and MPI/FT in applications possible in future.},
  keywords={},
  doi={10.1109/CCGRID.2001.923171},
  ISSN={},
  month={May},}
@INPROCEEDINGS{924629,
  author={Perumalla, K. and Fujimoto, R.},
  booktitle={Proceedings 15th Workshop on Parallel and Distributed Simulation}, 
  title={Virtual time synchronization over unreliable network transport}, 
  year={2001},
  volume={},
  number={},
  pages={129-136},
  abstract={In parallel and distributed simulations, it is sometimes desirable that the application's time-stamped events and/or the simulator's time-management control messages be exchanged over a combination of reliable and unreliable network channels. A challenge in developing infrastructure for such simulations is to correctly compute simulation time advances despite the loss of some simulation events and/or control messages. The authors present algorithms for synchronization in distributed simulations, performed directly over best-effort network transport. The algorithms are presented in a sequence of progressive refinement, starting with all reliable transport and finishing with combinations of reliable and unreliable transport for both time-stamped events and time management messages. Performance results from a preliminary implementation of these algorithms are also presented. To our knowledge, this is the first work to solve asynchronous time synchronization performed directly over unreliable network transport.},
  keywords={},
  doi={10.1109/PADS.2001.924629},
  ISSN={},
  month={May},}
@ARTICLE{902749,
  author={Hamacher, V.C. and Hong Jiang},
  journal={IEEE Transactions on Computers}, 
  title={Hierarchical ring network configuration and performance modeling}, 
  year={2001},
  volume={50},
  number={1},
  pages={1-12},
  abstract={Approximate analytical queuing network models for expected message packet delay in 2-level and 3-level hierarchical ring interconnection networks (INs) are developed. A major class of traffic carried by these INs consists of cache line transfers between processor caches and remote memory modules in shared-memory multiprocessors. Such traffic consists of short, fixed-length messages; they can be conveniently transported by the slotted-ring transmission technique which is studied. The packet delay results derived from the models are shown to be quite accurate when checked against a simulation study. As well as facilitating analysis, the analytical models can be used to determine optimal sizes for the rings at different levels in the hierarchy, where optimality is in terms of minimizing average packet delay.},
  keywords={},
  doi={10.1109/12.902749},
  ISSN={1557-9956},
  month={Jan},}
@INPROCEEDINGS{905038,
  author={Bernaschi, M. and Richelli, G.},
  booktitle={Proceedings Ninth Euromicro Workshop on Parallel and Distributed Processing}, 
  title={MPI collective communication operations on large shared memory systems}, 
  year={2001},
  volume={},
  number={},
  pages={159-164},
  abstract={Collective communication performance is critical in a number of MPI applications yet relatively few results are available to assess the performance of MPI implementations specially for shared memory multiprocessors. In this paper we focus on the most widely used primitive, broadcast, and present experimental results for the Sun Enterprise 10000. We compare the performance of the Sun MPI primitives with our implementation based on a quasi-optimal algorithm. Our tests highlight advantages and drawbacks of vendors' implementations of collective communication primitives and suggest that the choice of the best algorithm may depend on exogenous factors like load balancing among tasks.},
  keywords={},
  doi={10.1109/EMPDP.2001.905038},
  ISSN={},
  month={Feb},}
@ARTICLE{910580,
  author={Sae-Young Chung and Richardson, T.J. and Urbanke, R.L.},
  journal={IEEE Transactions on Information Theory}, 
  title={Analysis of sum-product decoding of low-density parity-check codes using a Gaussian approximation}, 
  year={2001},
  volume={47},
  number={2},
  pages={657-670},
  abstract={Density evolution is an algorithm for computing the capacity of low-density parity-check (LDPC) codes under message-passing decoding. For memoryless binary-input continuous-output additive white Gaussian noise (AWGN) channels and sum-product decoders, we use a Gaussian approximation for message densities under density evolution to simplify the analysis of the decoding algorithm. We convert the infinite-dimensional problem of iteratively calculating message densities, which is needed to find the exact threshold, to a one-dimensional problem of updating the means of the Gaussian densities. This simplification not only allows us to calculate the threshold quickly and to understand the behavior of the decoder better, but also makes it easier to design good irregular LDPC codes for AWGN channels. For various regular LDPC codes we have examined, thresholds can be estimated within 0.1 dB of the exact value. For rates between 0.5 and 0.9, codes designed using the Gaussian approximation perform within 0.02 dB of the best performing codes found so far by using density evolution when the maximum variable degree is 10. We show that by using the Gaussian approximation, we can visualize the sum-product decoding algorithm. We also show that the optimization of degree distributions can be understood and done graphically using the visualization.},
  keywords={},
  doi={10.1109/18.910580},
  ISSN={1557-9654},
  month={Feb},}
@INPROCEEDINGS{918858,
  author={Al-Rawi, G. and Cioffi, J.},
  booktitle={Proceedings International Conference on Information Technology: Coding and Computing}, 
  title={A highly efficient domain-programmable parallel architecture for iterative LDPCC decoding}, 
  year={2001},
  volume={},
  number={},
  pages={569-577},
  abstract={We present a domain-programmable (code-independent) parallel architecture for efficiently implementing iterative probabilistic decoding of LDPC codes. The architecture is based on distributed computing and message passing. The exploited parallelism was found to be communication limited. To increase the utilization of the computational resources, we separate the routing process and state management functionalities performed by physical nodes from computation functionalities performed by function units that can be shared by multiple physical nodes. Simulation results show that the proposed architecture leads to improvements in FU utilization by 251%, 116%, and 209% compared to a hypothetical fully parallel custom implementation, a fully sequential implementation, and a proprietary FPGA custom implementation, respectively, that all use the same core FU design. Compared to an implementation on a shared-memory general-purpose parallel machine, the proposed architecture exhibits 75.6% improvement in scalability. We also introduce a novel low cost store-and-forward routing algorithm for deadlock avoidance in torus networks.},
  keywords={},
  doi={10.1109/ITCC.2001.918858},
  ISSN={},
  month={April},}
@INPROCEEDINGS{918855,
  author={Neogy, S. and Sinha, A. and Das, P.K.},
  booktitle={Proceedings International Conference on Information Technology: Coding and Computing}, 
  title={Checkpoint processing in distributed systems software using synchronized clocks}, 
  year={2001},
  volume={},
  number={},
  pages={555-559},
  abstract={The method of taking checkpoints in a truly distributed manner, that is in the absence of a global checkpoint coordinator has been very tricky. This has been dealt with in a system that uses a loosely synchronized clock. The constituent processes take their checkpoints according to their own clocks at predetermined checkpoint instants. Since these checkpoints are asynchronous, in order to determine a global consistent set of such checkpoints there must be some sort of synchronization among them. Synchronization information is appended to clock synchronization messages that are used by the constituent processes for checkpoint-synchronization. Communication in this system is synchronous, so processes may be blocked for communication at the checkpointing instants. The blocked processes take their checkpoints after they unblock. It is shown that the set of such i-th checkpoints is consistent and hence the rollback required by the system in case failure occurs is only up to the last saved state.},
  keywords={},
  doi={10.1109/ITCC.2001.918855},
  ISSN={},
  month={April},}
@INPROCEEDINGS{919007,
  author={Chanchio, K. and Xian-He Sun},
  booktitle={Proceedings 21st International Conference on Distributed Computing Systems}, 
  title={A protocol design of communication state transfer for distributed computing}, 
  year={2001},
  volume={},
  number={},
  pages={715-718},
  abstract={This paper presents the design of a communication state transfer protocol to support process migration in a dynamic, distributed computing environment. In our design, processes in distributed computation communicate one another via message passing and are migration-enabled. Due to mobility, mechanisms to maintain reliability and correctness of data communication are needed. Following an event-based approach, Such mechanisms are derived to handle various communication situations when a process migrates. These mechanisms collectively preserve the semantics of the communication and support efficient communication state transfer.},
  keywords={},
  doi={10.1109/ICDSC.2001.919007},
  ISSN={},
  month={April},}
@INPROCEEDINGS{918938,
  author={Arora, A. and Nesterenko, M.},
  booktitle={Proceedings 21st International Conference on Distributed Computing Systems}, 
  title={Unifying stabilization and termination in message-passing systems}, 
  year={2001},
  volume={},
  number={},
  pages={99-106},
  abstract={We dispel the myth that it is impossible for any stabilizing message passing program to be terminating. We identify fixpoint-symmetry as a necessary condition for a message passing stabilizing program to be terminating. Our results do confirm that a number of well-known input-output problems (e.g., leader election and consensus) do not admit a terminating and stabilizing solution. On the flip side, they show that reactive problems such as mutual exclusion and reliable-transmission do admit such solutions. We go on to present stabilizing and terminating programs for both problems. Also, we describe a way to add termination to a stabilizing program, and demonstrate it in the context of our design of a solution to the reliable-transmission problem.},
  keywords={},
  doi={10.1109/ICDSC.2001.918938},
  ISSN={},
  month={April},}
@INPROCEEDINGS{919181,
  author={Kaveh, N.},
  booktitle={Proceedings of the 23rd International Conference on Software Engineering. ICSE 2001}, 
  title={Model checking distributed objects design}, 
  year={2001},
  volume={},
  number={},
  pages={793-794},
  abstract={Potential advantages brought about by distributed system architectures has given rise to the number of applications being based around it. Advantages include an increase in fault tolerance due to replicated components and achieving cost effective scalability by distributing the execution of a task over several relatively cheap hosts rather than a central mainframe. The construction of distributed applications via the direct use of network operating system primitives is no longer feasible and middleware technologies are fast becoming the alternative approach. We note that amongst the different form of middleware, distributed object middleware offers the richest support to application designers and incorporates primitives for distributed transaction management and asynchronous message passing. From the set of distributed object middleware approaches, we concentrate on CORBA because it offers the richest set of synchronization and threading primitives.},
  keywords={},
  doi={10.1109/ICSE.2001.919181},
  ISSN={0270-5257},
  month={May},}
@ARTICLE{920589,
  author={Moritz, C.A. and Frank, M.I.},
  journal={IEEE Transactions on Parallel and Distributed Systems}, 
  title={LoGPG: Modeling network contention in message-passing programs}, 
  year={2001},
  volume={12},
  number={4},
  pages={404-415},
  abstract={In many real applications, for example, those with frequent and irregular communication patterns or those using large messages, network contention and contention for message processing resources can be a significant part of the total execution time. This paper presents a new cost model, called LoGPC, that extends the LogP and LogGP models to account for the impact of network contention and network interface DMA behavior on the performance of message passing programs. We validate LoGPC by analyzing three applications implemented with Active Messages on the MIT Alewife multiprocessor. Our analysis shows that network contention accounts for up to 50 percent of the total execution time. In addition, we show that the impact of communication locality on the communication costs is at most a factor of two on Alewife. Finally, we use the model to identify trade-offs between synchronous and asynchronous message passing styles.},
  keywords={},
  doi={10.1109/71.920589},
  ISSN={1558-2183},
  month={April},}
@INPROCEEDINGS{929780,
  author={Howland, C. and Blanksby, A.},
  booktitle={Proceedings of the IEEE 2001 Custom Integrated Circuits Conference (Cat. No.01CH37169)}, 
  title={A 220 mW 1 Gb/s 1024-bit rate-1/2 low density parity check code decoder}, 
  year={2001},
  volume={},
  number={},
  pages={293-296},
  abstract={A 1024 bit rate-1/2 Low Density Parity Check (LDPC) code decoder has been implemented that matches the coding gain of equivalent turbo codes. The parallel decoder architecture supports throughputs up to 1 Gb/s and convergence in the decoding algorithm translates into extremely low switching activity with power dissipation under 220 mW.},
  keywords={},
  doi={10.1109/CICC.2001.929780},
  ISSN={},
  month={May},}
@INPROCEEDINGS{925075,
  author={Pedersen, J.B. and Wagner, A.},
  booktitle={Proceedings 15th International Parallel and Distributed Processing Symposium. IPDPS 2001}, 
  title={Correcting errors in message passing systems}, 
  year={2001},
  volume={},
  number={},
  pages={1085-1085},
  abstract={},
  keywords={},
  doi={10.1109/IPDPS.2001.925075},
  ISSN={1530-2075},
  month={April},}
@INPROCEEDINGS{924943,
  author={Jiannong Cao and Chan, G.H. and Weijia jia and Dillon, T.S.},
  booktitle={Proceedings 15th International Parallel and Distributed Processing Symposium. IPDPS 2001}, 
  title={Checkpointing and rollback of wide-area distributed applications using mobile agents}, 
  year={2001},
  volume={},
  number={},
  pages={6 pp.-},
  abstract={We consider the problem of designing rollback error recovery algorithms for dynamic, wide area distributed systems like the Internet. The characteristics and the scale of such a system complicate the design and performance of the algorithms. Traditional message passing based algorithms incur large overhead, in both the network traffic and message passing delay, in such a wide-area environment. In this paper, we propose a novel approach to designing checkpointing and rollback algorithms using mobile agents as an aid. Using mobile agent leads to a reduction of the total amount of communication and allows us to design algorithms that take the advantage of the most up to date system information for decision making. It also allows us to develop algorithms implementing flexible and adaptive policies. A mobile agent enabled hybrid algorithm combining independent and coordinated checkpointing is proposed. A prototype of the algorithms is developed using IBM's Aglets. Results of performance evaluation are presented and discussed.},
  keywords={},
  doi={10.1109/IPDPS.2001.924943},
  ISSN={1530-2075},
  month={April},}
@INPROCEEDINGS{924991,
  author={Aumage, O. and Mercier, G. and Namyst, R.},
  booktitle={Proceedings 15th International Parallel and Distributed Processing Symposium. IPDPS 2001}, 
  title={MPICH/Madeleine: a true multi-protocol MPI for high performance networks}, 
  year={2001},
  volume={},
  number={},
  pages={8 pp.-},
  abstract={This paper introduces a version of MPICH handling efficiently different networks simultaneously. The core of the implementation relies on a device called ch-mad which is based on a generic multiprotocol communication library called Madeleine. The performance achieved with tested networks such as Fast-Ethernet, Scalable Coherent Interface or Myrinet is very good. Indeed, this multi-protocol version of MPICH generally outperforms other free or commercial implementations of MPI.},
  keywords={},
  doi={10.1109/IPDPS.2001.924991},
  ISSN={1530-2075},
  month={April},}
@INPROCEEDINGS{925208,
  author={Koniges, A.E. and Rabenseifner, R. and Solchenbach, K.},
  booktitle={Proceedings 15th International Parallel and Distributed Processing Symposium. IPDPS 2001}, 
  title={Benchmark design for characterization of balanced high-performance architectures}, 
  year={2001},
  volume={},
  number={},
  pages={2101-2112},
  abstract={},
  keywords={},
  doi={10.1109/IPDPS.2001.925208},
  ISSN={1530-2075},
  month={April},}
@INPROCEEDINGS{925101,
  author={Mueller, F.},
  booktitle={Proceedings 15th International Parallel and Distributed Processing Symposium. IPDPS 2001}, 
  title={Fault tolerance for token-based synchronization protocols}, 
  year={2001},
  volume={},
  number={},
  pages={1257-1264},
  abstract={},
  keywords={},
  doi={10.1109/IPDPS.2001.925101},
  ISSN={1530-2075},
  month={April},}
@INPROCEEDINGS{925176,
  author={JinHo Ahn and ChongSun Hwang},
  booktitle={Proceedings 15th International Parallel and Distributed Processing Symposium. IPDPS 2001}, 
  title={Efficient garbage collection schemes for causal message logging with independent checkpointing in message passing systems}, 
  year={2001},
  volume={},
  number={},
  pages={1857-1864},
  abstract={},
  keywords={},
  doi={10.1109/IPDPS.2001.925176},
  ISSN={1530-2075},
  month={April},}
@ARTICLE{940566,
  author={Alagar, S. and Venkatesan, S.},
  journal={IEEE Transactions on Software Engineering}, 
  title={Techniques to tackle state explosion in global predicate detection}, 
  year={2001},
  volume={27},
  number={8},
  pages={704-714},
  abstract={Global predicate detection, which is an important problem in testing and debugging distributed programs, is very hard due to the combinatorial explosion of the global state space. The paper presents several techniques to tackle the state explosion problem in detecting whether an arbitrary predicate /spl Phi/ is true at some consistent global state of a distributed system. We present space efficient online algorithms for detecting /spl Phi/. We then improve the performance of our algorithms, both in space and time, by increasing the granularity of the execution step from an event to a sequence of events in each process.},
  keywords={},
  doi={10.1109/32.940566},
  ISSN={1939-3520},
  month={Aug},}
@INPROCEEDINGS{957727,
  author={Chen, D. and Aoki, T. and Homma, N. and Higuchi, T.},
  booktitle={ICECS 2001. 8th IEEE International Conference on Electronics, Circuits and Systems (Cat. No.01EX483)}, 
  title={Distributed evolutionary design of constant-coefficient multipliers}, 
  year={2001},
  volume={1},
  number={},
  pages={249-252 vol.1},
  abstract={A parallel version of the evolutionary graph generation (EGG) system, called the distributed EGG (DEGG) system, was developed on a cluster of PCs using a message-passing interface (MPI). To demonstrate the capability of DEGG, it is applied to seeking the optimal design of various multipliers. Experimental results substantially show that DEGG consistently performs better than the EGG and known conventional designs.},
  keywords={},
  doi={10.1109/ICECS.2001.957727},
  ISSN={},
  month={Sep.},}
@INPROCEEDINGS{951929,
  author={Michailidis, P.D. and Margaritis, K.G.},
  booktitle={Proceedings International Conference on Parallel Processing Workshops}, 
  title={Parallel text searching application on a heterogeneous cluster of workstations}, 
  year={2001},
  volume={},
  number={},
  pages={169-175},
  abstract={In this paper we propose a high-performance text searching implementation on a heterogeneous cluster of workstations using MPI message passing library. We test this parallel implementation and present experimental results for different text sizes and number of workstations. We also present a performance prediction model that agrees well with our experimental measurements.},
  keywords={},
  doi={10.1109/ICPPW.2001.951929},
  ISSN={1530-2016},
  month={Sep.},}
@INPROCEEDINGS{960902,
  author={Blahovec, J.D. and Cartwright, K.L.},
  booktitle={IEEE Conference Record - Abstracts. PPPS-2001 Pulsed Power Plasma Science 2001. 28th IEEE International Conference on Plasma Science and 13th IEEE International Pulsed Power Conference (Cat. No.01CH37}, 
  title={Adding OpenMP to an existing MPI code: will it be beneficial?}, 
  year={2001},
  volume={},
  number={},
  pages={266-},
  abstract={Summary form only given, as follows. ICEPIC (Improved Concurrent Electromagnetic Particle In Cell), developed at the Air Force Research Laboratory, is a 3-D and 2-D parallel Particle-In-Cell (PIC) code that was specifically designed to execute efficiently on parallel high performance computing (HPC) resources using the MPI message passing standard. Its primary application is to simulate collisionless plasma physics in high-power microwave devices. ICEPIC has several novel features that allow efficient use of parallel architectures. It is written in ANSI C and uses the MPI message passing standard to provide portability to a variety of HPC systems. Recently, we have been computing on an IBM SMP with 8-way Power3 nodes using only MPI. OpenMP can increase the efficiency and/or scalability of a code executing on shared-memory architectures, such as the IBM SMP. The addition of OpenMP to ICEPIC required minor code modifications. The efficacy of the OpenMP is demonstrated with test problems.},
  keywords={},
  doi={10.1109/PPPS.2001.960902},
  ISSN={},
  month={June},}
@INPROCEEDINGS{934852,
  author={Paillard, G.A.L. and Franca, F.M.G. and Filho, J.A.M.},
  booktitle={Proceedings. Eighth International Conference on Parallel and Distributed Systems. ICPADS 2001}, 
  title={A distributed implementation of Structured Gamma}, 
  year={2001},
  volume={},
  number={},
  pages={445-450},
  abstract={Presents a distributed implementation of the Structured Gamma programming language, a language based on the Gamma multi-set rewriting paradigm. Structured Gamma offers, in addition to the advantages introduced by Gamma, implicit concurrent behavior and a type system where not only types themselves are defined but also the automatic verification of user-defined types at compilation time. The problems and mechanisms involved in an MPI-based implementation of Structured Gamma using a type-checking engine based on the most general unifier (MGU) are investigated.},
  keywords={},
  doi={10.1109/ICPADS.2001.934852},
  ISSN={1521-9097},
  month={June},}
@INPROCEEDINGS{934276,
  author={Walker, R.L.},
  booktitle={Proceedings of the 2001 Congress on Evolutionary Computation (IEEE Cat. No.01TH8546)}, 
  title={Parallel clustering system using the methodologies of evolutionary computations}, 
  year={2001},
  volume={2},
  number={},
  pages={831-838 vol. 2},
  abstract={Several versions of the parallel clustering system were studied to improve performance of its initial implementation. The current versions were restricted to 1024 Web pages which, in turn, were used to create adaptive probe sets that were distributed to each indexer node. The probe sets were used to compute fitness measures associated with each indexer node used to create sub-species for the purpose of applying the new and traditional GA/GP operators. Speedup resulted from fitness-enhancing mechanisms that provided information results from previous fitness measurements of previous generations, such as the non-genetic transmission of cultural information. The clustering results are being used in the Tocorime Apicu project to develop a bioinformatic approach to the design and validation of an integrated, experimental search engine. This model provides a foundation for an evolutionary expansion of this computational model as World Wide Web (WWW) documents continue to grow. The clustering results were generated using message passing interface (MPI) on a network of SUN workstations.},
  keywords={},
  doi={10.1109/CEC.2001.934276},
  ISSN={},
  month={May},}
@INPROCEEDINGS{934023,
  author={Sintotski, A. and Hammer, D.K. and van Roosmalen, O. and Hooman, J.},
  booktitle={Proceedings 13th Euromicro Conference on Real-Time Systems}, 
  title={Formal platform-independent design of real-time systems}, 
  year={2001},
  volume={},
  number={},
  pages={163-170},
  abstract={A formal approach for the development of real-time control systems is described. Our development process consists of two phases: the platform-independent phase, which includes specification programming and verification and the second phase, where execution platform considerations (i.e. resource constraints) are taken into account. This development process supports the use of end-to-end timing constraints through the whole design process without splitting them apart. A real-time application is modeled as a parallel composition of objects communicating by means of asynchronous message passing. This work concentrates on a compositional framework that combines the specification and verification of functional requirements and end-to-end timing constraints into one consistent formal model. In this paper we apply the approach to the mine pump control system. The formal analysis shows that a previously published implementation of the mine pump control system is incorrect.},
  keywords={},
  doi={10.1109/EMRTS.2001.934023},
  ISSN={},
  month={June},}
@INPROCEEDINGS{1592782,
  author={Smith, L.A. and Bull, J.M. and Obdrizalek, J.},
  booktitle={SC '01: Proceedings of the 2001 ACM/IEEE Conference on Supercomputing}, 
  title={A Parallel Java Grande Benchmark Suite}, 
  year={2001},
  volume={},
  number={},
  pages={6-6},
  abstract={Increasing interest is being shown in the use of Java for large scale or Grande applications. This new use of Java places speci.c demands on the Java execution environments that can be tested using the Java Grande benchmark suite [5], [6], [7]. The large processing requirements of Grande applications makes parallelisation of interest. A suite of parallel benchmarks has been developed from the serial Java Grande benchmark suite, using three parallel programming models: Java native threads, MPJ (a message passing interface) and JOMP (a set of OpenMP-like directives). The contents of the suite are described, and results presented for a number of platforms.},
  keywords={},
  doi={10.1145/582034.582042},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{1592808,
  author={Stewart, C.A. and Hart, D. and Berry, D.K. and Olsen, G.J. and Wernert, E.A. and Fischer, W.},
  booktitle={SC '01: Proceedings of the 2001 ACM/IEEE Conference on Supercomputing}, 
  title={Parallel Implementation and Performance of FastDNAml - A Program for Maximum Likelihood Phylogenetic Inference}, 
  year={2001},
  volume={},
  number={},
  pages={32-32},
  abstract={This paper describes the parallel implementation of fastDNAml, a program for the maximum likelihood inference of phylogenetic trees from DNA sequence data. Mathematical means of inferring phylogenetic trees have been made possible by the wealth of DNA data now available. Maximum likelihood analysis of phylogenetic trees is extremely computationally intensive. Availability of computer resources is a key factor limiting use of such analyses. fastDNAml is implemented in serial, PVM, and MPI versions, and may be modified to use other message passing libraries in the future. We have developed a viewer for comparing phylogenies. We tested the scaling behavior of fastDNAml on an IBM RS/6000 SP up to 64 processors. The parallel version of fastDNAml is one of very few computational phylogenetics codes that scale well. fastDNAml is available for download as source code or compiled for Linux or AIX.},
  keywords={},
  doi={10.1145/582034.582054},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{1592834,
  author={Prost, J. and Treumann, R. and Hedges, R. and Bin Jia and Koniges, A.},
  booktitle={SC '01: Proceedings of the 2001 ACM/IEEE Conference on Supercomputing}, 
  title={MPI-IO/GPFS, an Optimized Implementation of MPI-IO on Top of GPFS}, 
  year={2001},
  volume={},
  number={},
  pages={58-58},
  abstract={MPI-IO/GPFS is an optimized prototype implementation of the I/O chapter of the Message Passing Interface (MPI) 2 standard. It uses the IBM General Parallel File System (GPFS) Release 3 as the underlying file system. This paper describes optimization features of the prototype that take advantage of new GPFS programming interfaces. It also details how collective data access operations have been optimized by minimizing the number of messages exchanged in sparse accesses and by increasing the overlap of communication with file access. Experimental results show a performance gain. A study of the impact of varying the number of tasks running on the same node is also presented.},
  keywords={},
  doi={10.1145/582034.582051},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{994294,
  author={Seinstra, F.J. and Koelma, D.},
  booktitle={Proceedings 10th Euromicro Workshop on Parallel, Distributed and Network-based Processing}, 
  title={Incorporating memory layout in the modeling of message passing programs}, 
  year={2002},
  volume={},
  number={},
  pages={293-300},
  abstract={One of the most fundamental tasks of an automatic parallelization tool is to find an optimal domain decomposition for a given application. For regular domain problems (such as simple matrix manipulations) this task may seem trivial. However, communication costs in message passing programs often significantly depend on the memory layout of data blocks to be transmitted. As a consequence, straightforward domain decompositions may be non-optimal. In this paper we introduce a new point-to-point communication model (called P-3PC) that is specifically designed to overcome this problem. In comparison with related models (e.g., LogGP) P-3PC is similar in complexity, but more accurate in many situations. Although the model is aimed at MPI's standard point-to-point operations, it is applicable to similar message passing definitions as well. The effectiveness of the model is tested in a framework for automatic parallelization of imaging applications. Experiments are performed on two Beowulf-type systems, each having a different interconnection network, and a different MPI implementation. Results show that, where other models frequently fail, P-3PC correctly predicts the communication costs related to any type of domain decomposition.},
  keywords={},
  doi={10.1109/EMPDP.2002.994294},
  ISSN={},
  month={Jan},}
@INPROCEEDINGS{1001122,
  author={Thangaraj, A. and McLaughlin, S.W.},
  booktitle={2002 IEEE International Magnetics Conference (INTERMAG)}, 
  title={LDPC codes and thresholds for partial response channels}, 
  year={2002},
  volume={},
  number={},
  pages={EC2-},
  abstract={Summary form only given. The ultimate performance limit or threshold of low-density parity-check (LDPC) codes is close to capacity over various memoryless channels (S.-Y. Chung, IEEE Trans. Info. Theory, vol. 47, pp. 657-670, 2001). Since the capacity of binary-input partial response (PR) channels is unknown, we estimate the capacity by calculating the threshold of capacity-approaching LDPC codes over these channels. We assume a BCJR equalizer for the channel and a sum-product message-passing decoder for the LDPC code. We also assume that the log-likelihood ratios (LLRs) in the channel BCJR and the LDPC decoder are Gaussian. We use our results to guide the design of decoder schedules that minimize the number of computationally expensive BCJR steps. The threshold calculation method can be used to optimize the left and right degree sequences of the LDPC code factor graph, using fast linear programming methods, to provide better thresholds than regular codes.},
  keywords={},
  doi={10.1109/INTMAG.2002.1001122},
  ISSN={},
  month={April},}
@INPROCEEDINGS{1000035,
  author={Yau, S.S. and Xiaoyong Zhou},
  booktitle={Proceedings of the Seventh IEEE International Workshop on Object-Oriented Real-Time Dependable Systems. (WORDS 2002)}, 
  title={Schedulability in model-based software development for distributed real-time systems}, 
  year={2002},
  volume={},
  number={},
  pages={45-52},
  abstract={Schedulability of distributed real-time system has been studied extensively. However, due to the discrepancies the reference model used in scheduling analysis and the object-oriented model, the results cannot be easily used for distributed real-time object-oriented software development. Even if object-oriented models can be used to conduct schedulability analysis successfully, there still lacks an effective approach to validate the implementation with the design. Model-based approach alleviates the discrepancies between models of different stages and the implementation by automatically transforming models at different granularity until the code generation for the implementation from the generated design. In this paper, an approach to incorporating schedulability analysis reference diagrams into the existing framework for model-based software development will be presented. It will improve the predictability of a distributed real-time system as well as increase the capability of model refinements and code generation using the new reference diagrams and schedulability analysis results to generate code for implementing scheduling and synchronization aspects of the distributed real-time system.},
  keywords={},
  doi={10.1109/WORDS.2002.1000035},
  ISSN={1530-1443},
  month={Jan},}

@INPROCEEDINGS{1000046,
  author={Izaki, K. and Tanaka, K. and Takizawa, M.},
  booktitle={Proceedings of the Seventh IEEE International Workshop on Object-Oriented Real-Time Dependable Systems. (WORDS 2002)}, 
  title={Timed information flow among objects based on role concept}, 
  year={2002},
  volume={},
  number={},
  pages={139-146},
  abstract={In a secure object-based system, only authorized subjects are allowed to manipulate objects in authorized methods. In addition, every information flow to occur among objects is required to be legal, i.e. no confinement problem occur. First, abstract methods are classified with respect to whether or not data is input to and output from objects and state is changed. In this paper, we discuss how to prevent illegal information flow to occur among objects by performing methods in a role-based, access control model. In addition, we discuss an algorithm to check if illegal information flow occurs each, time a method is issued by a transaction.},
  keywords={},
  doi={10.1109/WORDS.2002.1000046},
  ISSN={1530-1443},
  month={Jan},}
@ARTICLE{1000451,
  author={Stankovic, N. and Kang Zhang},
  journal={IEEE Transactions on Software Engineering}, 
  title={A distributed parallel programming framework}, 
  year={2002},
  volume={28},
  number={5},
  pages={478-493},
  abstract={This paper presents Visper, a novel object-oriented framework that identifies and enhances common services and programming primitives, and implements a generic set of classes applicable to multiple programming models in a distributed environment. Groups of objects, which can be programmed in a uniform and transparent manner, and agent-based distributed system management, are also featured in Visper. A prototype system is designed and implemented in Java, with a number of visual utilities that facilitate program development and portability. As a use case, Visper integrates parallel programming in an MPI-like message-passing paradigm at a high level with services such as checkpointing and fault tolerance at a lower level. The paper reports a range of performance evaluation on the prototype and compares it to related works.},
  keywords={},
  doi={10.1109/TSE.2002.1000451},
  ISSN={1939-3520},
  month={May},}
@INPROCEEDINGS{995545,
  author={Ferner, C.S.},
  booktitle={Proceedings IEEE SoutheastCon 2002 (Cat. No.02CH37283)}, 
  title={The Paraguin compiler - message-passing code generation using SUIF [Stanford University Intermediate Format]}, 
  year={2002},
  volume={},
  number={},
  pages={1-6},
  abstract={Introduces the Paraguin project at the University of North Carolina at Wilmington. The goal of the project is to build an open-source message-passing parallelizing compiler for distributed-memory computer systems. We discuss the progress we have made in developing this compiler as well as mention the parts that have not yet been developed. It is our intent that, by providing an open-source compiler, we will stimulate research in automatic message-passing parallelism and encourage collaboration. We demonstrate a technique to improve the performance of a message-passing program by overlapping communication with computation. Although the original concept was introduced previously by S.P. Amarasinghe and M.S. Lam (1993), the algorithm was not developed nor shown to provide any benefit. Our preliminary results indicate that the technique significantly improves the performance. We were able to reduce the running time of our test program by 4-65%.},
  keywords={},
  doi={10.1109/SECON.2002.995545},
  ISSN={},
  month={April},}
@ARTICLE{1003830,
  author={Kurkoski, B.M. and Siegel, P.H. and Wolf, J.K.},
  journal={IEEE Transactions on Information Theory}, 
  title={Joint message-passing decoding of LDPC codes and partial-response channels}, 
  year={2002},
  volume={48},
  number={6},
  pages={1410-1422},
  abstract={Ideas of message passing are applied to the problem of removing the effects of intersymbol interference (ISI) from partial-response channels. Both bit-based and state-based parallel message-passing algorithms are proposed. For a fixed number of iterations less than the block length, the bit-error rate of the state-based algorithm approaches a nonzero constant as the signal-to-noise ratio (SNR) approaches infinity. This limitation can be removed by using a precoder. It is well known that low-density parity-check (LDPC) codes can be decoded using a message-passing algorithm. Here, a single message-passing detector/decoder matched to the combination of a partial-response channel and an LDPC code is investigated.},
  keywords={},
  doi={10.1109/TIT.2002.1003830},
  ISSN={1557-9654},
  month={June},}
@INPROCEEDINGS{1016973,
  author={Tiejun Yu and Carin, L.},
  booktitle={IEEE Antennas and Propagation Society International Symposium (IEEE Cat. No.02CH37313)}, 
  title={Parallel extended-Born analysis of electromagnetic scattering from 3-dimensional sub-rough surface targets}, 
  year={2002},
  volume={4},
  number={},
  pages={260-263 vol.4},
  abstract={The real 3-dimensional rough surface (RS) half space is treated as a perfect half-space with a special target which leads to a huge problem size if the integral equation (IE) based method of moments (MoM) is used, so a parallel algorithm is applied to speedup the EM scattering calculation from the RS. The message-passing interface (MPI) is the most widely used new standard for parallel calculation. It is not a new programming language, rather it is a library of subprograms that can be called from C++ and Fortran programs. In the paper, a powerful cluster with 33-CPU units connected by MPI network technique provides a good chance to investigate the real 3D RS half space EM scattering. Instead of rigorous MoM, a more efficient algorithm named extended-Born (E-Born) is used to model this 3D RS scattering problem. As E-Born is a very natural parallel algorithm, the complete parallel E-born code is almost P times fast as a series E-born code, where P is the CPU number in the cluster. When N is the problem size which is usually very large for real 3D-RS scattering, the LU-decomposition (LUD) solution of MoM is of the order of N/sup 3/ complexity, while a series E-Born solution is of the order of 27N, and the parallel E-Born solution is of the order of 27N/P. With such a computational complexity of 27N/P, a problem with size N >10/sup 5/ is no longer a prohibitive task. The accuracy and efficiency of the parallel E-Born method are validated by the MoM results.},
  keywords={},
  doi={10.1109/APS.2002.1016973},
  ISSN={},
  month={June},}
@INPROCEEDINGS{1019151,
  author={McGinn, S.F. and Shaw, R.E.},
  booktitle={Proceedings 16th Annual International Symposium on High Performance Computing Systems and Applications}, 
  title={Parallel Gaussian elimination using OpenMP and MPI}, 
  year={2002},
  volume={},
  number={},
  pages={169-173},
  abstract={In this paper, we present a parallel algorithm for Gaussian elimination: in both a shared memory environment using OpenMP, and in a distributed memory environment using MPI. Parallel LU and Gaussian algorithms for linear systems are studied extensively, and the the results of examining various load balancing schemes on both platforms are presented. The results show an improvement in many cases over the default implementation.},
  keywords={},
  doi={10.1109/HPCSA.2002.1019151},
  ISSN={},
  month={June},}
@ARTICLE{1019863,
  author={Seinstra, F.J. and Koelma, D.},
  journal={IEEE Transactions on Parallel and Distributed Systems}, 
  title={P-3PC: a point-to-point communication model for automatic and optimal decomposition of regular domain problems}, 
  year={2002},
  volume={13},
  number={7},
  pages={758-768},
  abstract={One of the most fundamental problems automatic parallelization tools are confronted with is to find an optimal domain decomposition for a given application. For regular domain problems (such as simple matrix manipulations), this task may seem trivial. However, communication costs in message-passing programs often depend significantly on the memory layout of data blocks to be transmitted. As a consequence, straightforward domain decompositions may be non-optimal. In this paper, we introduce a new point-to-point communication model, called P-3PC (Parameterized model based on the Three Paths of Communication), that is specifically designed to overcome this problem. In comparison with related models (e.g. LogGP), P-3PC is similar in complexity, but more accurate in many situations. Although the model is aimed at MPI's standard point-to-point operations, it is applicable to similar message-passing definitions as well. The effectiveness of the model is tested in a framework for automatic parallelization of low-level image processing applications. Experiments are performed on two Beowulf-type systems, each having a different interconnection network and a different MPI implementation. The results show that, where other models frequently fail, P-3PC correctly predicts the communication costs related to any type of domain decomposition.},
  keywords={},
  doi={10.1109/TPDS.2002.1019863},
  ISSN={1558-2183},
  month={July},}
@INPROCEEDINGS{1024793,
  author={Provan, G.},
  booktitle={Proceedings of the 2002 American Control Conference (IEEE Cat. No.CH37301)}, 
  title={Distributed diagnosability properties of discrete event systems}, 
  year={2002},
  volume={1},
  number={},
  pages={134-139 vol.1},
  abstract={We present a distributed diagnostics and control architecture for embedded distributed diagnostics. Using this architecture, we (1) propose a distributed diagnostics framework for discrete-event systems based on causal networks; (2) prove system diagnosability results based on component diagnosability; and (3) discuss the tradeoffs involving system diagnosability and communication requirements.},
  keywords={},
  doi={10.1109/ACC.2002.1024793},
  ISSN={0743-1619},
  month={May},}
@INPROCEEDINGS{1030842,
  author={Tran, P. and Greenfield, P. and Gorton, I.},
  booktitle={Proceedings 22nd International Conference on Distributed Computing Systems Workshops}, 
  title={Behavior and performance of message-oriented middleware systems}, 
  year={2002},
  volume={},
  number={},
  pages={645-650},
  abstract={The middleware technology used as the foundation of Internet-enabled enterprise systems is becoming increasingly complex. In addition, the various technologies offer a number of standard architectures that can be used by designers as templates to build applications. However, there is little concrete understanding in the software industry on the strengths and weaknesses of competing technologies, and the different trade-offs that various component architectures impose. The SACT Group at CSIRO has qualitatively and quantitatively evaluated a number of commercially available Message-Oriented Middleware (MOM) systems. This paper focuses on the results obtained from the performance evaluation of the IBM's MQSeries V5.2. It presents an overview of the technology, and discusses the metric used in this study for performance measurement The test results related to the sustainable performance of the system using various test configurations are described and their implications discussed.},
  keywords={},
  doi={10.1109/ICDCSW.2002.1030842},
  ISSN={},
  month={July},}
@ARTICLE{1067996,
  author={Gerkey, B.P. and Mataric, M.J.},
  journal={IEEE Transactions on Robotics and Automation}, 
  title={Sold!: auction methods for multirobot coordination}, 
  year={2002},
  volume={18},
  number={5},
  pages={758-768},
  abstract={The key to utilizing the potential of multirobot systems is cooperation. How can we achieve cooperation in systems composed of failure-prone autonomous robots operating in noisy, dynamic environments? We present a method of dynamic task allocation for groups of such robots. We implemented and tested an auction-based task allocation system which we call MURDOCH, built upon a principled, resource centric, publish/subscribe communication model. A variant of the Contract Net Protocol, MURDOCH produces a distributed approximation to a global optimum of resource usage. We validated MURDOCH in two very different domains: a tightly coupled multirobot physical manipulation task and a loosely coupled multirobot experiment in long-term autonomy. The primary contribution of the paper is to show empirically that distributed negotiation mechanisms such as MURDOCH are viable and effective for coordinating physical multirobot systems.},
  keywords={},
  doi={10.1109/TRA.2002.803462},
  ISSN={2374-958X},
  month={Oct},}
@ARTICLE{1039577,
  author={Blair, R. and Dawson, J. and Haberichter, W. and Schlereth, J. and Bock, R. and Bogaerts, A. and Boosten, M. and Dobinson, R. and Dobson, M. and Ellis, N. and Elsing, M. and Giacomini, F. and Knezo, E. and Martin, B. and Shears, T. and Tapprogge, S. and Werner, P. and Hansen, J.R. and Waananen, A. and Korcyl, K. and Lokier, J. and George, S. and Green, B. and Strong, J. and Clarke, P. and Cranfield, R. and Crone, G. and Sherwood, P. and Wheeler, S. and Hughes-Jones, R. and Kolya, S. and Mercer, D. and Hinkelbein, C. and Kornmesser, K. and Kugel, A. and Manner, R. and Muller, M. and Sessler, M. and Simmler, H. and Singpiel, H. and Abolins, M. and Ermoline, Y. and Gonzalez Pineiro, B. and Hauser, R. and Pope, B. and Sivoklokov, S. and Boterenbrood, H. and Jansweijer, P. and Kieft, G. and Scholte, R. and Slopsema, R. and Vermeulen, J. and Baines, J.T. and Belias, A. and Botterill, D. and Middleton, R. and Wickens, F. and Falciano, S. and Bystricky, J. and Calvet, D. and Gachelin, O. and Huet, M. and Le Du, P. and Mandjavidze, I. and Levinson, L. and Gonzalez, S. and Wiedenmann, W. and Zobernig, H.},
  journal={IEEE Transactions on Nuclear Science}, 
  title={The ATLAS Level-2 Trigger Pilot Project}, 
  year={2002},
  volume={49},
  number={3},
  pages={851-857},
  abstract={The Level-2 Trigger Pilot Project of ATLAS, one of the two general purpose LHC experiments, is part of the on-going program to develop the ATLAS high-level triggers (HLT). The Level-2 Trigger will receive events at up to 100 kHz, which has to be reduced to a rate suitable for full event-building of the order of 1 kHz. To reduce the data collection bandwidth and processing power required for the challenging Level-2 task it is planned to use Region of Interest guidance (from Level-1) and sequential processing. The Pilot Project included the construction and use of testbeds of up to 48 processing nodes, development of optimized components and computer simulations of a full system. It has shown how the required performance can be achieved, using largely commodity components and operating systems, and validated an architecture for the Level-2 system. This paper describes the principal achievements and conclusions of this project.},
  keywords={},
  doi={10.1109/TNS.2002.1039577},
  ISSN={1558-1578},
  month={June},}
@INPROCEEDINGS{1039781,
  author={Chanchio, K. and Xian-He Sun},
  booktitle={Proceedings. International Conference on Parallel Processing Workshop}, 
  title={SNOW: software systems for process migration in high-performance, heterogeneous distributed environments}, 
  year={2002},
  volume={},
  number={},
  pages={589-596},
  abstract={This paper reports our experiences on the scalable network of workstation (SNOW) project, which implements a novel methodology to support user-level process migration for traditional stack-based languages such as C and Fortran in heterogeneous distributed environments. Our methodology addresses the three outstanding problems of transferring execution state, memory state, and communication state. The concepts of migration point analysis and buffered data transfer mechanism are proposed for execution state migration. A memory space representation model is introduced to obtain the machine-independent format of the underlying data structures for memory state migration. Finally, process migration and communication protocols are developed to migrate the communication state and maintain the functionality and correctness of data communication. A coordinated software system consisting of compilation and runtime systems was developed based on these new mechanisms. The runtime systems include a runtime library and communication protocols. Sequential and parallel programs with different data structures and computing requirements are tested. Experimental results confirm our design analysis. They advocate the value of the migration methodology for distributed network computing.},
  keywords={},
  doi={10.1109/ICPPW.2002.1039781},
  ISSN={1530-2016},
  month={Aug},}
@INPROCEEDINGS{1039744,
  author={Pan, Y. and Ierotheou, C.S. and Hayat, M.M.},
  booktitle={Proceedings. International Conference on Parallel Processing Workshop}, 
  title={Parallel implementation of the recurrence method for computing the power-spectral density of thin avalanche photodiodes}, 
  year={2002},
  volume={},
  number={},
  pages={298-305},
  abstract={A simulation program has been developed to calculate the power-spectral density of thin avalanche photodiodes, which are used in optical networks. The program extends the time-domain analysis of the dead-space multiplication model to compute the autocorrelation function of the APD impulse response. However, the computation requires a large amount of memory space and is very time consuming. We describe our experiences in parallelizing the code using both MPI and OpenMP. Several array partitioning schemes and scheduling policies are implemented and tested Our results show that the OpenMP code is scalable up to 64 processors on an SGI Origin 2000 machine and has small average errors.},
  keywords={},
  doi={10.1109/ICPPW.2002.1039744},
  ISSN={1530-2016},
  month={Aug},}
@INPROCEEDINGS{1039740,
  author={Sangback Ma and Ho-Jong Jang},
  booktitle={Proceedings. International Conference on Parallel Processing Workshop}, 
  title={Comparisons of parallel preconditioners for the computation of interior eigenvalues by a CG-type method on a parallel computer}, 
  year={2002},
  volume={},
  number={},
  pages={270-273},
  abstract={Recently iterative algorithms based on the optimization of the Rayleigh quotient have been developed, and a CG scheme for the optimization of the Rayleigh quotient has been proven to be a very attractive and promising technique for large sparse eigenproblems for interior eigenvalues. Ax = /spl lambda/Bx (1) The given matrices A, and B are assumed to be large and sparse, and symmetric and B is further assumed to be positive definite. Also, the method is very amenable to parallel computations. A proper choice of the preconditioner significantly improves the convergence of the CG scheme. We compare the parallel preconditioners for the computation of the interior eigenvalues of a symmetric matrix by CG-type method. The considered preconditioners are ILU(0) in the natural order, ILU(0) in the multi-coloring order, and multi-color block SSOR (symmetric successive overrelaxation). Our results were implemented on the CRAY-T3E with 128 nodes, assuming B = I. The MPI (Message Passing Interface) library was adopted for the interprocessor communications. The test matrices are up to 512/spl times/512 in dimensions and were created from the discretizations of the elliptic PDE. All things considered the MC-BSSOR seems to be most robust preconditioner.},
  keywords={},
  doi={10.1109/ICPPW.2002.1039740},
  ISSN={1530-2016},
  month={Aug},}
@INPROCEEDINGS{1040883,
  author={Singh, G. and Ye Su},
  booktitle={Proceedings International Conference on Parallel Processing}, 
  title={Region synchronization in message passing systems}, 
  year={2002},
  volume={},
  number={},
  pages={276-283},
  abstract={The development of correct synchronization code for distributed programs is a challenging task. In this paper, we propose an aspect oriented technique for developing synchronization code for message passing systems. Our approach is to factor out synchronization as a separate aspect, synthesize synchronization code and then compose it with the functional code. Specifically, we allow the designer of an application to first design the functional code. The designer can then annotate the functional code with regions and specify a high-level "global invariant" specifying the synchronization policy. A synchronization policy essentially gives the occupancy rules for the various regions. The solution to this problem, which we term the region synchronization problem, involves deriving a set of rules for entering and exiting each region. We provide a systematic invariant into a message passing algorithm for a point-to-point message passing system. We show that many existing synchronization problems can be specified as instances of the region synchronization problem. Hence, our algorithms can be used to solve a large class of synchronization problems.},
  keywords={},
  doi={10.1109/ICPP.2002.1040883},
  ISSN={0190-3918},
  month={Aug},}
@INPROCEEDINGS{1044553,
  author={Neogy, S. and Sinha, A. and Das, P.K.},
  booktitle={Proceedings 26th Annual International Computer Software and Applications}, 
  title={Distributed checkpointing using synchronized clocks}, 
  year={2002},
  volume={},
  number={},
  pages={199-204},
  abstract={The processes of the distributed system considered in this paper use loosely synchronized clocks. The paper describes a method of taking checkpoints by such processes in a truly distributed manner, that is, in the absence of a global checkpoint coordinator. The constituent processes take checkpoints according to their own clocks at predetermined checkpoint instants. Since these checkpoints are asynchronous, so to determine a global consistent set of such checkpoints there must be some sort of synchronization among them. This is achieved by adding suitable information to the existing clock synchronization messages looking at which the processes synchronize their checkpoints to form a global consistent checkpoint. Communication in this system is synchronous, so, processes may be blocked for communication at the checkpointing instants. The blocked processes save the state in which they were just before being blocked. It is shown here that the set of such i-th checkpoints is consistent and hence the rollback required by the system in case failure occurs is only up to the last saved state.},
  keywords={},
  doi={10.1109/CMPSAC.2002.1044553},
  ISSN={0730-3157},
  month={Aug},}
@INPROCEEDINGS{1045878,
  author={Hsin-Ta Chiao and Chun-Han Lin and Kai-Chih Liang and Shyan-Ming Yuan},
  booktitle={Proceedings. 13th International Workshop on Database and Expert Systems Applications}, 
  title={The experience of using Java-based message-oriented middleware to build a distributed training simulator}, 
  year={2002},
  volume={},
  number={},
  pages={64-68},
  abstract={This paper presents a prototype of a distributed training simulator for a surface-to-air missile system. Since the system requirement enforces us to choose an open standard platform, and we think that Java has matured enough to offer acceptable performance and reliability, we decide to implement it by Java. Basically, this training simulator is a distributed interactive application, and lots of messages are exchanged within it. For the performance reason, we use an IP-multicast-based Java message service (JMS) implementation as the communication infrastructure for delivering time-critical events. In this paper, we present how to exploit the capability of the JMS publish/subscribe paradigm to implement this training simulator. Besides, we also perform a set of experiments to test and verify whether the training simulator can meet the system requirement. We think the experience of this paper is a good case study of using Java and message-oriented middleware to build message-intensive distributed systems.},
  keywords={},
  doi={10.1109/DEXA.2002.1045878},
  ISSN={1529-4188},
  month={Sep.},}
@INPROCEEDINGS{1046175,
  author={Krishnan, P. and Hartley, D.},
  booktitle={Proceedings. 28th Euromicro Conference}, 
  title={Using model checking to test a firewall: a case study}, 
  year={2002},
  volume={},
  number={},
  pages={284-291},
  abstract={This paper summarises our experience in using model checking technology to test concurrent programs. We use the tool Verisoft to understand various aspects of a firewall tool kit by instrumenting three components of the firewall tool kit with hooks to test their behaviour. Some of the key changes include changing socket communication to message passing queues and adding appropriate synchronisations so that the behaviour of the system can be tracked. We aim to minimize the number of changes to the original source code so that its original behaviour is not affected The main conclusion is that it is possible to inspect source code with a view towards verifying key behavioural properties without understanding the entire behaviour of the system.},
  keywords={},
  doi={10.1109/EURMIC.2002.1046175},
  ISSN={1089-6503},
  month={Sep.},}
@INPROCEEDINGS{1047600,
  author={Hong Chao},
  booktitle={Proceedings. International Conference on Power System Technology}, 
  title={Implementation of parallel-in-time Newton method for transient stability analysis on a message passing multicomputer}, 
  year={2002},
  volume={2},
  number={},
  pages={1239-1243 vol.2},
  abstract={This paper presents an efficient parallel implementation scheme of parallel-in-time Newton algorithm for transient stability analysis. Overlapping technique and nonblocking message passing mode are employed to reduce the wait time to a minimum. As a result, the proposed implementation scheme can produce high speedup gain and parallel efficiency results, especially when a large degree of parallelism-in-time is adopted. Test case simulations are performed for two large-scale power systems on an IBM-SP2 multicomputer. Higher speedups than previously reported for transient stability analysis are obtained.},
  keywords={},
  doi={10.1109/ICPST.2002.1047600},
  ISSN={},
  month={Oct},}
@INPROCEEDINGS{1049562,
  author={Dozier, G.},
  booktitle={Proceedings of the 5th Biannual World Automation Congress}, 
  title={Distributed constraint satisfaction via a society of hill-climbers}, 
  year={2002},
  volume={13},
  number={},
  pages={313-318},
  abstract={In this paper, we compare two modified versions of Yokoo's (2001) distributed breakout hill-climbing algorithm (DBA), mDBA-I and mDBA-II, along with six evolutionary computations referred to as societies of hill-climbers (SoHC) on 400 randomly generated distributed constraint satisfaction problems. Each SoHC is composed of S instances of mDBA-II running in parallel, where S represents the society size. The S hill-climbers communicate with one another through a distributed list of breakout elements which represent nogoods discovered at local minima. Our results show that larger society sizes are better in terms of convergence percentage and average cycle performance. However, this better performance comes at a cost of increased constraint checks and message sizes.},
  keywords={},
  doi={10.1109/WAC.2002.1049562},
  ISSN={},
  month={June},}
@INPROCEEDINGS{1115315,
  author={Craus, M. and Ardelean, D.},
  booktitle={Proceedings. International Conference on Parallel Computing in Electrical Engineering}, 
  title={Parallel implementation of a dynamic programming paradigm}, 
  year={2002},
  volume={},
  number={},
  pages={419-421},
  abstract={A new parallel algorithm that solves a dynamic programming paradigm is proposed. It has the time complexity of O(n) and uses (n-1)n/2 processors. An MPI implementation is used to test the algorithm.},
  keywords={},
  doi={10.1109/PCEE.2002.1115315},
  ISSN={},
  month={Sep.},}
@INPROCEEDINGS{1137755,
  author={Ming Li and Wenchao Tao and Goldberg, D. and Hsu, I. and Tamir, Y.},
  booktitle={Proceedings. IEEE International Conference on Cluster Computing}, 
  title={Design and validation of portable communication infrastructure for fault-tolerant cluster middleware}, 
  year={2002},
  volume={},
  number={},
  pages={266-274},
  abstract={We describe the communication infrastructure (CI) for our fault-tolerant cluster middleware, which is optimized for two classes of communication: for the applications and for the cluster management middleware. This CI was designed for portability and for efficient operation on top of modern user-level message passing mechanisms. We present a functional fault model for the CI and show how platform-specific faults map to this fault model. Based on this fault model, we have developed a fault injection scheme that is integrated with the CI and is thus portable across different communication technologies. We have used fault injection to validate and evaluate the implementation of the CI itself as well as the cluster management middleware in the presence of communication faults.},
  keywords={},
  doi={10.1109/CLUSTR.2002.1137755},
  ISSN={},
  month={Sep.},}
@INPROCEEDINGS{1137769,
  author={Sistare, S. and Test, J. and Plauger, D.},
  booktitle={Proceedings. IEEE International Conference on Cluster Computing}, 
  title={An architecture for integrated resource management of MPI jobs}, 
  year={2002},
  volume={},
  number={},
  pages={370-377},
  abstract={We present a new architecture for the integration of distributed resource management systems and parallel run-time environments such as MPI. The architecture solves the long-standing problem of achieving a tight integration between the two in a clean and robust manner that fully enables the functionality of both systems, including resource limit enforcement and accounting. We also present a more uniform command interface to the user, which simplifies the task of running parallel jobs and tools under a resource manager. The architecture is extensible and allows new systems to be incorporated. We describe the properties that a resource management system must have to work in this architecture, and find that these are ubiquitous in the resource management world. Using the Sun/spl trade/ Cluster Runtime Environment, we show the generality of the approach by implementing tight integrations with PBS, LSF and Sun Grid Engine software, and we demonstrate the advantages of a tight integration. No modifications or enhancements to these resource management systems were required, which is in marked contrast to ad-hoc approaches which typically require such changes.},
  keywords={},
  doi={10.1109/CLUSTR.2002.1137769},
  ISSN={},
  month={Sep.},}
@INPROCEEDINGS{1158667,
  author={Ramos, L.E.S. and Goes, L.F.W. and Martins, C.A.P.S.},
  booktitle={32nd Annual Frontiers in Education}, 
  title={Teaching and learning parallel processing through performance analysis using Prober}, 
  year={2002},
  volume={3},
  number={},
  pages={S2F-S2F},
  abstract={In this paper we analyze the teaching and learning of parallel processing through performance analysis using a software tool called Prober. This tool is a functional and performance analyzer of parallel programs that we proposed and developed during an undergraduate research project. Our teaching and learning approach consists of a practical class where students receive explanations about some concepts of parallel processing and the use of the tool. They do some oriented and simple performance tests on parallel programs and analyze their results using Prober as a single aid tool. Finally, students answer a self-assessment questionnaire about their formation, their knowledge of parallel processing concepts and also about the usability of Prober. Our main goal is to show that students can learn concepts of parallel processing in a clearer, faster and more efficient way using our approach.},
  keywords={},
  doi={10.1109/FIE.2002.1158667},
  ISSN={0190-5848},
  month={Nov},}
@INPROCEEDINGS{1167664,
  author={Tripakis, S.},
  booktitle={Sixth International Workshop on Discrete Event Systems, 2002. Proceedings.}, 
  title={Decentralized control of discrete event systems with bounded or unbounded delay communication}, 
  year={2002},
  volume={},
  number={},
  pages={18-25},
  abstract={We introduce problems of decentralized control with delayed communication, where delays are either unbounded or bounded by a given constant k. In the k-bounded-delay model, between the transmission of a message and its reception, the plant can execute at most k events. In the unbounded-delay model, the plant can execute any number of events between transmission and reception. We show that our framework yields an infinite hierarchy of control problems, /spl Cscr//spl Cscr/ =/spl Dscr//spl Cscr//spl Cscr//sub 0//spl sup//spl Dscr//spl Cscr//spl Cscr//sub 1//spl sup//spl Dscr//spl Cscr//spl Cscr//sub 2//spl sup//spl middot//spl middot//spl middot//spl sup//spl Dscr//spl Cscr//spl Uscr//spl Cscr//spl sup//spl Dscr//spl Cscr/ , where CC is the set of control problems solvable with a single controller (centralized case) and /spl Dscr//spl Cscr//spl Cscr//sub k/ (resp. /spl Dscr//spl Cscr//spl Uscr//spl Cscr/, /spl Dscr//spl Cscr/) is the set of problems solvable with two controllers in a k-bounded-delay network (resp. two controllers in an unbounded-delay network, two controllers without communication). The above containments are strict. We prove the undecidability of checking the existence of controllers in the unbounded-delay case, or in the case without any communication. Finally, we prove that a decentralized observation problem with bounded-delay communication is decidable.},
  keywords={},
  doi={10.1109/WODES.2002.1167664},
  ISSN={},
  month={Oct},}
@INPROCEEDINGS{1173279,
  author={Yu Lei and Kuo-Chung Tai},
  booktitle={13th International Symposium on Software Reliability Engineering, 2002. Proceedings.}, 
  title={Blocking-based simultaneous reachability analysis of asynchronous message-passing programs}, 
  year={2002},
  volume={},
  number={},
  pages={316-326},
  abstract={Existing reachability analysis techniques for asynchronous message-passing programs assume causal communication, which means that messages sent to a destination are received in the order they are sent. In this paper, we present a new reachability analysis approach, called blocking-based simultaneous reachability analysis (BSRA). BSRA can be applied to asynchronous message-passing programs based on any communication scheme. From a global state g, BSRA allows processes to proceed simultaneously until each of them terminates or is ready to execute a receive operation. Global states reached by such executions from g are called next blocking points of g. For each next blocking point of g, waiting messages and receive operations are matched to produce immediate BSRA-based successor states of g. Intermediate global states from g to each of g's immediate BSRA-based successors are not saved. We describe an algorithm for generating BSRA-based reachability, graphs and show that this algorithm guarantees the detection of deadlocks. Our empirical results indicate that BSRA significantly reduces the number of states in reachability graphs. Extensions of BSRA for partial order reduction and model checking are discussed.},
  keywords={},
  doi={10.1109/ISSRE.2002.1173279},
  ISSN={1071-9458},
  month={Nov},}
@INPROCEEDINGS{1173614,
  author={Hongjun Cao and Guihua Shan and Xuebin Chi},
  booktitle={Fifth International Conference on Algorithms and Architectures for Parallel Processing, 2002. Proceedings.}, 
  title={Parallel computing on Lyapunov exponents for continuous parameter-dependent ordinary differential equations}, 
  year={2002},
  volume={},
  number={},
  pages={430-433},
  abstract={The paper concerns the parallel computing and its application for solving the full Lyapunov exponents in the general nonlinear parameter-dependent continuous ordinary differential equations. Based on a standard serial algorithm developed by Wolf et al. (1985), we present a parallel algorithm using the block-cyclic decomposition method, and then apply it for solving the Lyapunov exponents of a continuous differential equation. By testing its performance of the parallel algorithm on the supercomputer DAWNING-200011, it is proved that the parallel algorithm is of high level parallelism, no need for message passing (little communication cost), and little I/O. In addition, the algorithm can be extended to any high dimensional ordinary differential equations.},
  keywords={},
  doi={10.1109/ICAPP.2002.1173614},
  ISSN={},
  month={Oct},}
@INPROCEEDINGS{1181496,
  author={Yu Lei and Kuo-Chung Tai},
  booktitle={Eighth IEEE International Conference on Engineering of Complex Computer Systems, 2002. Proceedings.}, 
  title={Efficient reachability testing of asynchronous message-passing programs}, 
  year={2002},
  volume={},
  number={},
  pages={35-44},
  abstract={An asynchronous message-passing program P is nondeterministic. Given the same input, multiple executions of P may exercise different send/receive event sequences (or SR-sequences) and may even produce different results. Such nondeterminacy makes it difficult to determine the correctness of P. Let X be an input of P. Assume that any execution of P with X terminates. Reachability testing of P with X is to execute, in a systematic manner, all possible SR-sequences of P with X such that the correctness of P with X can be determined. The basic idea of reachability testing is described as follows. We first execute P with X nondeterministically to collect one or more SR-sequences. For each collected SR-sequence, we analyze its race conditions and generate race variants, which are prefixes of other SR-sequences. We replay race variants to generate new SR-sequences. For each new SR-sequence, we repeat the same process until we eventually execute all possible SR-sequences of P with X. We describe an efficient implementation of reachability testing of asynchronous message-passing programs. Our technique deals with partially-ordered SR-sequences and reduces the complexity and redundancy caused by totally-ordered SR-sequences.},
  keywords={},
  doi={10.1109/ICECCS.2002.1181496},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{1181842,
  author={Leon, E.A. and Maccabe, A.B. and Brightwell, R.},
  booktitle={27th Annual IEEE Conference on Local Computer Networks, 2002. Proceedings. LCN 2002.}, 
  title={Instrumenting LogP parameters in GM: implementation and validation}, 
  year={2002},
  volume={},
  number={},
  pages={648-657},
  abstract={This paper describes an apparatus which can be used to vary communication performance parameters for MPI applications, and provides a tool to analyze the impact of communication performance on parallel applications. Our apparatus is based on Myrinet (along with GM). We use an extension of the LogP model to allow higher flexibility in determining the parameter(s) to which parallel applications may be more sensitive. We show that individual communication parameters can be controlled within a small percentage error, and that the other parameters remain unchanged.},
  keywords={},
  doi={10.1109/LCN.2002.1181842},
  ISSN={0742-1303},
  month={Nov},}
@INPROCEEDINGS{1183405,
  author={Wang, S.C. and Yan, K.Q. and Chiang, M.L.},
  booktitle={Ninth International Conference on Parallel and Distributed Systems, 2002. Proceedings.}, 
  title={Reach reliable decision by using secret agreement method}, 
  year={2002},
  volume={},
  number={},
  pages={233-238},
  abstract={Traditionally, it is very important to deliver data secretly and at low cost in a distributed environment. Using a reliable method to assist in communicating with each other needs to be discussed. Thus, we propose the two-phase agreement (TPA) protocol to solve those problems by verifying the received messages and achieve the agreement. The TPA protocol will assist the organization in achieving agreement and generate a common key to verify it. Similarly, there are many faults and attacks in the network, such as interruption, interception, modification and fabrication. The messages from a source might be changed. However we can use the TPA protocol to remove these faulty influences. The proposed TPA protocol doesn't only decrease the complexity of messages but also increases the capability of fault tolerance. Similarly, it is more reliable via the secret key in a real distributed system. This protocol can solve the agreement problem in net-meeting between arbitrary processors, like sub-company communication with the main-company or makes a decision in the company conference.},
  keywords={},
  doi={10.1109/ICPADS.2002.1183405},
  ISSN={1521-9097},
  month={Dec},}
@INPROCEEDINGS{1183434,
  author={Datta, A.K. and Gradinariu, M. and Kenitzki, A.B. and Tixeuil, S.},
  booktitle={Ninth International Conference on Parallel and Distributed Systems, 2002. Proceedings.}, 
  title={Self-stabilizing wormhole routing on ring networks}, 
  year={2002},
  volume={},
  number={},
  pages={425-430},
  abstract={Wormhole routing is the most common in parallel architecture in which messages are sent in small fragments called flits. It is a lightweight and efficient method of routing messages between parallel processors. Self-stabilization is a technique that guarantees tolerance to transient faults (e.g. memory corruption or communication hazard) for a given protocol. Self-stabilization guarantees that the network recovers to a correct behavior infinite time, without the need for human intervention. Self-stabilization also guarantees the safety property, meaning that once the network is in a legitimate state, it will remain there until another fault occurs. This paper presents the first self-stabilizing network algorithm in the wormhole routing model, using the unidirectional ring topology. Our solution benefits from wormhole routing by providing high throughput and low latency, and front self-stabilization by ensuring automatic resilience to all possible transient failures.},
  keywords={},
  doi={10.1109/ICPADS.2002.1183434},
  ISSN={1521-9097},
  month={Dec},}
@INPROCEEDINGS{1187067,
  author={Yeo, E. and Nikolic, B. and Anantharam, V.},
  booktitle={The 2002 45th Midwest Symposium on Circuits and Systems, 2002. MWSCAS-2002.}, 
  title={Architectures and implementations of low-density parity check decoding algorithms}, 
  year={2002},
  volume={3},
  number={},
  pages={III-III},
  abstract={Architectures for low-density parity-check (LDPC) decoders are discussed, with methods to reduce their complexity. Serial implementations similar to traditional microprocessor datapaths are compared against implementations with multiple processing elements that exploit the inherent parallelism in the decoding algorithm. Several classes of LDPC codes, such as those based on irregular random graphs and geometric properties of finite fields are evaluated in terms of their suitability for VLSI implementation and performance as measured by bit-error rate. Efficient realizations of low-density parity check decoders under area, power, and throughput constraints are of particular interest in the design of communications receivers.},
  keywords={},
  doi={10.1109/MWSCAS.2002.1187067},
  ISSN={},
  month={Aug},}
@INPROCEEDINGS{1035373,
  author={Gustafson, W.T. and Gillespie, A.},
  booktitle={Proceedings, IEEE Aerospace Conference}, 
  title={Onboard processing of orbital hyperspectral thermal infrared images}, 
  year={2002},
  volume={5},
  number={},
  pages={5-5},
  abstract={We have devised an on-board processing system for hyperspectral thermal infrared (TIR) images, to be acquired from a spacecraft in low-Earth orbit. The onboard thermal infrared spectrometer (OTIS) system is capable of in-scene atmospheric compensation, temperature-emissivity separation and image analysis with a choice of algorithms. OTIS is written in C using the message-passing interface (MPI) libraries that allow parallel processing for improved performance and fault tolerance. OTIS is implemented for testing on an 8-node Beowulf cluster of Intel-based PCs running Linux, as well as a series of multi-processor testbeds at JPL. OTIS functioning has been tested using airborne TIR imaging spectrometer images, as well as spaceborne multispectral TIR data from the currently operational Advanced Spaceborne Thermal Emission and Reflection Radiometer (ASTER) instrument on NASA's Earth Observing System Terra (formerly EOS-AM1) spacecraft.},
  keywords={},
  doi={10.1109/AERO.2002.1035373},
  ISSN={},
  month={March},}
@INPROCEEDINGS{1023606,
  author={Amraoui, A. and Dusad, S. and Urbanke, R.},
  booktitle={Proceedings IEEE International Symposium on Information Theory,}, 
  title={Achieving general points in the 2-user Gaussian MAC without time-sharing or rate-splitting by means of iterative coding}, 
  year={2002},
  volume={},
  number={},
  pages={334-},
  abstract={In this paper, we analyze iterative coding for the frame-asynchronous binary-input discrete-time Gaussian multiple access channel. Using the method of density evolution, we optimize degree distributions to exhibit code ensembles whose iterative decoding thresholds are only few tenths of dB away from the Shannon limit.},
  keywords={},
  doi={10.1109/ISIT.2002.1023606},
  ISSN={},
  month={June},}
@INPROCEEDINGS{1023385,
  author={Wainwright, M. and Jaakkola, T. and Willsky, A.},
  booktitle={Proceedings IEEE International Symposium on Information Theory,}, 
  title={Tree-based reparameterization analysis of belief propagation and related algorithms for approximate inference on graphs with cycles}, 
  year={2002},
  volume={},
  number={},
  pages={113-},
  abstract={Although it is straightforward to compute the marginals of a distribution p(x) defined by a tree-structured graphical model, this same task is often difficult for graphs with cycles. The belief propagation (BP) or sum-product algorithm is an approximate method for computing such marginals; it is used in various applications (e.g., iterative decoding of turbo and LDPC codes). Belief propagation is typically presented and analyzed as a sequence of message-passing operations. We develop a different conceptual perspective that involves reparameterizing the original distribution in terms of so-called pseudomarginals on cliques of the graph. This view gives rise to a simple characterization of the fixed points, as well as an exact expression and bounds on the error for an arbitrary graph with cycles.},
  keywords={},
  doi={10.1109/ISIT.2002.1023385},
  ISSN={},
  month={June},}
@INPROCEEDINGS{1023303,
  author={Lehmann, R. and Maggio, G.M.},
  booktitle={Proceedings IEEE International Symposium on Information Theory,}, 
  title={An approximate analytical model of the message passing decoder of LDPC codes}, 
  year={2002},
  volume={},
  number={},
  pages={31-},
  abstract={In this paper we introduce a novel one-dimensional model of the message passing decoding algorithm of low-density parity-check (LDPC) codes, based on Gaussian densities. The model consists of a closed-form 1-D map whose iterates directly represent the error probability. This map allows a qualitative analysis of the nonlinear dynamics of the decoding algorithm. Moreover, it is shown that our approach leads to the correct stability condition and that the corresponding threshold values are in good agreement with density evolution.},
  keywords={},
  doi={10.1109/ISIT.2002.1023303},
  ISSN={},
  month={June},}
@INPROCEEDINGS{1029622,
  author={Mansour, M.M. and Shanbhag, N.R.},
  booktitle={Proceedings of the International Symposium on Low Power Electronics and Design}, 
  title={Low-power VLSI decoder architectures for LDPC codes}, 
  year={2002},
  volume={},
  number={},
  pages={284-289},
  abstract={Iterative decoding of low-density parity check codes (LDPC) using the message-passing algorithm have proved to be extraordinarily effective compared to conventional maximum-likelihood decoding. However, the lack of any structural regularity in these essentially random codes is a major challenge for building a practical low-power LDPC decoder. In this paper, we jointly design the code and the decoder to induce the structural regularity needed for a reduced-complexity parallel decoder architecture. This interconnect-driven code design approach eliminates the need for a complex interconnection network while still retaining the algorithmic performance promised by random codes. Moreover, we propose a new approach for computing reliability metrics based on the BCJR algorithm that reduces the message switching activity in the decoder compared to existing approaches. Simulations show that the proposed approach results in power savings of up to 85.64% over conventional implementations.},
  keywords={},
  doi={10.1109/LPE.2002.146756},
  ISSN={},
  month={Aug},}
@INPROCEEDINGS{1540463,
  author={Ma, R.K.K. and Cho-Li. Wang and Lau, F.C.M.},
  booktitle={2nd IEEE/ACM International Symposium on Cluster Computing and the Grid (CCGRID'02)}, 
  title={M-JavaMPI: A Java-MPI Binding with Process Migration Support}, 
  year={2002},
  volume={},
  number={},
  pages={255-255},
  abstract={Several Java bindings to the Message Passing Interface (MPI) software have been developed for high-performance parallel Java-based computing with message-passing in the past. None of them however addressed the issue of supporting transparent Java process migration for achieving dynamic load distribution and balancing. This paper presents a middleware, called M-JavaMPI, that runs on top of the standard JVM to support transparent Java process migration and communication redirection. The middleware allows Java processes to freely and transparently migrate between machines to achieve load balancing, and migrated processes can continue communication with other processes using MPI. The method we use to achieve process migration is to capture execution context and restoring the execution context at the Java bytecode level using the Java Virtual Machine Debugger Interface (JVMDI). Post-migration interprocess communication is enabled via a Restorable Java-MPI API. Tests using a 16-node cluster have Shown that our mechanism yields considerable performance gain through migration.},
  keywords={},
  doi={10.1109/CCGRID.2002.1017134},
  ISSN={},
  month={May},}
@INPROCEEDINGS{1592865,
  author={Bosilca, G. and Bouteiller, A. and Cappello, F. and Djilali, S. and Fedak, G. and Germain, C. and Herault, T. and Lemarinier, P. and Lodygensky, O. and Magniette, F. and Neri, V. and Selikhov, A.},
  booktitle={SC '02: Proceedings of the 2002 ACM/IEEE Conference on Supercomputing}, 
  title={MPICH-V: Toward a Scalable Fault Tolerant MPI for Volatile Nodes}, 
  year={2002},
  volume={},
  number={},
  pages={29-29},
  abstract={Global Computing platforms, large scale clusters and future TeraGRID systems gather thousands of nodes for computing parallel scientific applications. At this scale, node failures or disconnections are frequent events. This Volatility reduces the MTBF of the whole system in the range of hours or minutes. We present MPICH-V, an automatic Volatility tolerant MPI environment based on uncoordinated checkpoint/roll-back and distributed message logging. MPICH-V architecture relies on Channel Memories, Checkpoint servers and theoretically proven protocols to execute existing or new, SPMD and Master-Worker MPI applications on volatile nodes. To evaluate its capabilities, we run MPICH-V within a framework for which the number of nodes, Channels Memories and Checkpoint Servers can be completely configured as well as the node Volatility. We present a detailed performance evaluation of every component of MPICH-V and its global performance for non-trivial parallel applications. Experimental results demonstrate good scalability and high tolerance to node volatility.},
  keywords={},
  doi={10.1109/SC.2002.10048},
  ISSN={1063-9535},
  month={Nov},}
@INPROCEEDINGS{1015521,
  author={Shaw, R.E. and Garey, L.E. and Lizotte, D.J.},
  booktitle={Proceedings 16th International Parallel and Distributed Processing Symposium}, 
  title={A parallel numerical algorithm for boundary-value FIDEs on a PC cluster}, 
  year={2002},
  volume={},
  number={},
  pages={6 pp-},
  abstract={An algorithm for parallel processing the discrete nonlinear system for solving Fredholm integro-differential equations with two-point boundary conditions on a PC cluster is considered. The cost of calculating the history terms is expensive and improvements are motivated by considering different architectures. The algorithm has been modified to minimize the communication overhead inherent in a distributed application and tested using two different messaging protocols: GAMMA, an efficient message system for clusters of PCs (Ciaccio, 1999) with low latency and high throughput and TCP/IP protocol with MPI. Numerical examples illustrate the results.},
  keywords={},
  doi={10.1109/IPDPS.2002.1015521},
  ISSN={},
  month={April},}
@ARTICLE{8213132,
  author={Komatitsch, Dimitri and Tromp, Jeroen},
  journal={Geophysical Journal International}, 
  title={Spectral-element simulations of global seismic wave propagation—I. Validation}, 
  year={2002},
  volume={149},
  number={2},
  pages={390-412},
  abstract={We use a spectral-element method to simulate seismic wave propagation throughout the entire globe. The method is based upon a weak formulation of the equations of motion and combines the flexibility of a finite-element method with the accuracy of a global pseudospectral method. The finite-element mesh honours all first- and second-order discontinuities in the earth model. To maintain a relatively constant resolution throughout the model in terms of the number of grid points per wavelength, the size of the elements is increased with depth in a conforming fashion, thus retaining a diagonal mass matrix. In the Earth's mantle and inner core we solve the wave equation in terms of displacement, whereas in the liquid outer core we use a formulation based upon a scalar potential. The three domains are matched at the inner core and core–mantle boundaries, honouring the continuity of traction and the normal component of velocity. The effects of attenuation and anisotropy are fully incorporated. The method is implemented on a parallel computer using a message passing technique. We benchmark spectral-element synthetic seismograms against normal-mode synthetics for a spherically symmetric reference model. The two methods are in excellent agreement for all body- and surface-wave arrivals with periods greater than about 20 s.},
  keywords={},
  doi={10.1046/j.1365-246X.2002.01653.x},
  ISSN={1365-246X},
  month={May},}
@ARTICLE{1167369,
  author={Keren, A. and Barak, A.},
  journal={IEEE Transactions on Parallel and Distributed Systems}, 
  title={Opportunity cost algorithms for reduction of I/O and interprocess communication overhead in a computing cluster}, 
  year={2003},
  volume={14},
  number={1},
  pages={39-50},
  abstract={Computing clusters (CC) consisting of several connected machines, could provide a high-performance, multiuser, timesharing environment for executing parallel and sequential jobs. In order to achieve good performance in such an environment, it is necessary to assign processes to machines in a manner that ensures efficient allocation of resources among the jobs. The paper presents opportunity cost algorithms for online assignment of jobs to machines in a CC. These algorithms are designed to improve the overall CPU utilization of the cluster and to reduce the I/O and the interprocess communication (IPC) overhead. Our approach is based on known theoretical results on competitive algorithms. The main contribution of the paper is how to adapt this theory into working algorithms that can assign jobs to machines in a manner that guarantees near-optimal utilization of the CPU resource for jobs that perform I/O and IPC operations. The developed algorithms are easy to implement. We tested the algorithms by means of simulations and executions in a real system and show that they outperform existing methods for process allocation that are based on ad hoc heuristics.},
  keywords={},
  doi={10.1109/TPDS.2003.1167369},
  ISSN={1558-2183},
  month={Jan},}
@INPROCEEDINGS{1183561,
  author={Thoai, N. and Kranzlmuller, D. and Volkert, J.},
  booktitle={Eleventh Euromicro Conference on Parallel, Distributed and Network-Based Processing, 2003. Proceedings.}, 
  title={EROS: an efficient method for minimizing the replay time based on the replay dependence relation}, 
  year={2003},
  volume={},
  number={},
  pages={23-30},
  abstract={Debugging parallel programs is still a challenge although many debugging techniques and corresponding tools have been developed. One reason why parallel programs are difficult to debug is the irreproducibility effect, which is caused by nondeterminism occurring at process interaction. Solutions to this problem are provided by so-called record and replay mechanisms or replay techniques. However, the rather long waiting time during replay often prohibits inclusion of these techniques to debugging tools, which must provide some degree of interactivity for user's investigations. This paper analyzes the possibility of combining debugging with checkpointing to shorten waiting time during re-executions. Related work in this area either cannot ensure a short waiting time or creates other effects on the autonomy of processes. The EROS approach introduces the replay dependence relation, which allows us to minimize the waiting time without the restrictions above. In fact, EROS provides a small upper bound of the replay time during debugging nondeterministic message passing programs.},
  keywords={},
  doi={10.1109/EMPDP.2003.1183561},
  ISSN={1066-6192},
  month={Feb},}
@INPROCEEDINGS{1183578,
  author={Verdoscia, L. and Scafuri, U.},
  booktitle={Eleventh Euromicro Conference on Parallel, Distributed and Network-Based Processing, 2003. Proceedings.}, 
  title={CODACS project: level-node communication policies}, 
  year={2003},
  volume={},
  number={},
  pages={134-139},
  abstract={Nodes in the CODACS prototype are connected in a WK-recursive topology. Since such a system can scale up to thousand nodes, simple policies are required to efficiently manage internode communication, specially when groups of cooperating nodes need to exchange groups of related information. The solution proposed for this collective communication resides in treating message transfer as communication among homologous level-nodes. This solution, which takes advantage of recursive network properties, allows each gather node of a sender level-node (1) to identify the correct message sequence; (2) to evaluate the quantum to assign to the scheduler; (3) to transfer the sequence as a unique message. The resulting message is then transferred to homologous ones of a receiver level-node by a level-channel in pipeline fashion to speed up the throughput. Delivering activity occurs adopting a straightforward communication algorithm.},
  keywords={},
  doi={10.1109/EMPDP.2003.1183578},
  ISSN={1066-6192},
  month={Feb},}
@INPROCEEDINGS{1183601,
  author={D'Ambra, P. and Danelutto, M. and di Serafino, D. and Lapegna, M.},
  booktitle={Eleventh Euromicro Conference on Parallel, Distributed and Network-Based Processing, 2003. Proceedings.}, 
  title={Integrating MPI-based numerical software into an advanced parallel computing environment}, 
  year={2003},
  volume={},
  number={},
  pages={283-291},
  abstract={In this paper we present first experiences concerning the integration of MPI-based numerical software into an advanced programming environment for building parallel and distributed high-performance applications, which is under development in the context of Italian national research projects. Such a programming environment, named ASSIST, is based on a combination of the concepts of structured parallel programming and component-based programming. Some activities within the projects are devoted to the definition, implementation and testing of a methodology for the integration of a parallel numerical library into ASSIST. The goal is providing a set of efficient, accurate and reliable tools that can be easily used as building blocks for high-performance scientific applications. We focus on the integration of existing and widely used MPI-based numerical library modules. To this aim, we propose a general approach to embed MPI computations into the ASSIST basic programming unit. This approach has been tested using the MPICH implementation of MPI for networks of workstations. Some modifications have been applied to the MPICH process startup procedure, in order to make it compliant with the ASSIST environment. Results of experiments concerning the integration of routines from a well-known FFT package are discussed.},
  keywords={},
  doi={10.1109/EMPDP.2003.1183601},
  ISSN={1066-6192},
  month={Feb},}
@INPROCEEDINGS{1183615,
  author={Seragiotto, C. and Fahringer, T. and Geissler, M. and Madsen, G. and Moritsch, H.},
  booktitle={Eleventh Euromicro Conference on Parallel, Distributed and Network-Based Processing, 2003. Proceedings.}, 
  title={On using Aksum for semi-automatically searching of performance problems in parallel and distributed programs}, 
  year={2003},
  volume={},
  number={},
  pages={385-392},
  abstract={There has been an increasing research interest in formalizing and automating the search for performance problems. In previous work we have introduced Aksum, which tries to automatically locate all performance problems in parallel and distributed applications based on multi-experiment performance analysis and user-provided machine and problem sizes. In this paper we report on experiences with Aksum for performance analysis of three realistic message passing, shared memory and mixed parallelism codes taken from laser physics, material science, and financial modeling. Aksum has been used to automatically decide which code regions must be instrumented, what performance information must be collected, and to launch experiments and test performance hypotheses as soon as more performance data becomes available. Multiple-experiment performance analysis enables the user to compare the performance behavior across a range of problem and machine sizes.},
  keywords={},
  doi={10.1109/EMPDP.2003.1183615},
  ISSN={1066-6192},
  month={Feb},}
@INPROCEEDINGS{1192915,
  author={Raynal, M.},
  booktitle={17th International Conference on Advanced Information Networking and Applications, 2003. AINA 2003.}, 
  title={Token-based sequential consistency in asynchronous distributed systems}, 
  year={2003},
  volume={},
  number={},
  pages={421-426},
  abstract={A concurrent object is an object that can be concurrently accessed by several processes. Sequential consistency is a consistency criterion for such objects. It informally states that a multiprocess program executes correctly if its results could have been produced by executing that program on a single processor system. (Sequential consistency is weaker than atomic consistency-the usual consistency criterion-as it does not refer to real-time.) The paper proposes a new, surprisingly simple protocol that ensures sequential consistency when the shared memory abstraction is supported by the local memories of nodes that can communicate only by exchanging messages through reliable channels. The protocol nicely combines, in a simple way, the use a of token with cached values. It has the noteworthy property to never invalidate cached values, thereby providing fast read operations (i.e., a process has never to wait to get a correct value of a shared object). Additionally, The paper presents a simple token navigation protocol.},
  keywords={},
  doi={10.1109/AINA.2003.1192915},
  ISSN={},
  month={March},}
@INPROCEEDINGS{1193938,
  author={Xinyu Chen and Lyu, M.R.},
  booktitle={The Sixth International Symposium on Autonomous Decentralized Systems, 2003. ISADS 2003.}, 
  title={Message logging and recovery in wireless CORBA using access bridge}, 
  year={2003},
  volume={},
  number={},
  pages={107-114},
  abstract={The emerging mobile wireless environment poses exciting challenges for distributed fault tolerant (FT) computing. This paper proposes a message logging and recovery protocol on the top of Telecom Wireless CORBA and FT-CORBA architectures. It uses the storage available at the access bridge as the stable storage to log messages and checkpoints on behalf of a mobile host. Our approach engages both quasi-sender-based and receiver-based logging methods and makes seamless handoff in the presence of failures. The details of how to tolerate mobile host disconnection, mobile host crash and access bridge crash are described. The normalized execution time of a mobile host engaging our proposed scheme and the handoff effect are evaluated.},
  keywords={},
  doi={10.1109/ISADS.2003.1193938},
  ISSN={},
  month={April},}
@ARTICLE{1199067,
  author={Adir, A. and Attiya, H. and Shurek, G.},
  journal={IEEE Transactions on Parallel and Distributed Systems}, 
  title={Information-flow models for shared memory with an application to the PowerPC architecture}, 
  year={2003},
  volume={14},
  number={5},
  pages={502-515},
  abstract={This paper introduces a generic framework for defining instructions, programs, and the semantics of their instantiation by operations in a multiprocessor environment. The framework captures information flow between operations in a multiprocessor program by means of a reads-from mapping from read operations to write operations. Two fundamental relations are defined on the operations: a program order between operations which instantiate the program of some processor and view orders which are specific to each shared memory model. An operation cannot read from the "hidden" pastor from the future; the future and the past causality can be examined either relative to the program order or relative to the view orders. A shared memory model specifies, for a given program, the permissible transformation of resource states. The memory model should reflect the programmer's view by citing the guaranteed behavior of the multiprocessor in the interface visible to the programmer. The model should retrain from dictating the design practices that should be followed by the implementation. Our framework allows an architect to reveal the programming view induced by a shared-memory architecture; it serves programmers exploring the limits of the programming interface and guides architecture-level verification. The framework is applicable for complex, commercial architectures as it can capture subtle programming-interface details, exposing the underlying aggressive microarchitecture mechanisms. As an illustration, we define the shared memory model supported by the PowerPC architecture, within our framework.},
  keywords={},
  doi={10.1109/TPDS.2003.1199067},
  ISSN={1558-2183},
  month={May},}
@INPROCEEDINGS{1199358,
  author={Ching, A. and Choudhary, A. and Coloma, K. and Wei-keng Liao and Ross, R. and Gropp, W.},
  booktitle={CCGrid 2003. 3rd IEEE/ACM International Symposium on Cluster Computing and the Grid, 2003. Proceedings.}, 
  title={Noncontiguous I/O accesses through MPI-IO}, 
  year={2003},
  volume={},
  number={},
  pages={104-111},
  abstract={I/O performance remains a weakness of parallel computing systems today. While this weakness is partly attributed to rapid advances in other system components, I/O interfaces available to programmers and the I/O methods supported by file systems have traditionally not matched efficiently with the types of I/O operations that scientific applications perform, particularly noncontiguous accesses. The MPI-IO interface allows for rich descriptions of the I/O patterns desired for scientific applications and implementations such as ROMIO have taken advantage of this ability while remaining limited by underlying file system methods. A method of noncontiguous data access, list I/O, was recently implemented in the Parallel Virtual File System (PVFS). We implement support for this interface in the ROMIO MPI-IO implementation. Through a suite of noncontiguous I/O tests we compared ROMIO list I/O to current methods of ROMIO noncontiguous access and found that the list I/O interface provides performance benefits in many noncontiguous cases.},
  keywords={},
  doi={10.1109/CCGRID.2003.1199358},
  ISSN={},
  month={May},}
@INPROCEEDINGS{1198784,
  author={Hacioglu, K. and Pellom, B.},
  booktitle={2003 IEEE International Conference on Acoustics, Speech, and Signal Processing, 2003. Proceedings. (ICASSP '03).}, 
  title={A distributed architecture for robust automatic speech recognition}, 
  year={2003},
  volume={1},
  number={},
  pages={I-I},
  abstract={In this paper, we attempt to decompose a state-of-the-art speech recognition system into its components and define an infrastructure that allows a flexible, efficient and effective interaction among the components. Motivated by the success of DARPA Communicator program, we select the open source Galaxy architecture as our development test bed. It consists of a hub that allows communication among servers connected to it by message passing and supports the plug-and-play paradigm. In addition to message passing it supports high bandwidth data (binary or audio) transfer between servers via a brokering scheme. For several reasons, we believe that it is the right time to start developing a distributed framework for speech recognition along with data and protocol standards supporting interoperability. We present our work towards that goal using the Colorado University (CU) Sonic recognizer. We divide Sonic into a number of components and structure it around the Hub. We describe the system in some detail and report on its present status with some possibilities for future development.},
  keywords={},
  doi={10.1109/ICASSP.2003.1198784},
  ISSN={1520-6149},
  month={April},}
@ARTICLE{1200854,
  author={Rubinstein, A. and Rachidi, F. and Rubinstein, M. and Reusser, B.},
  journal={IEEE Transactions on Electromagnetic Compatibility}, 
  title={A parallel implementation of NEC for the analysis of large structures}, 
  year={2003},
  volume={45},
  number={2},
  pages={177-188},
  abstract={We present a new, parallel version of the numerical electromagnetics code (NEC). The parallelization is based on a bidimensional block-cyclic distribution of matrices on a rectangular processor grid, assuring a theoretically optimal load balance among the processors. The code is portable to any platform supporting message passing parallel environments such as message passing interface and parallel virtual machine, where it could even be executed on heterogeneous clusters of computers running on different operating systems. The developed parallel NEC was successfully implemented on two parallel supercomputers featuring different architectures to test portability. Large structures containing up to 24000 segments, which exceeds currently available computer resources were successfully executed and timing and memory results are presented. The code is applied to analyze the penetration of electromagnetic fields inside a vehicle. The computed results are validated using other numerical methods and experimental data obtained using a simplified model of a vehicle (consisting essentially of the body shell) illuminated by an electromagnetic pulse (EMP) simulator.},
  keywords={},
  doi={10.1109/TEMC.2003.810806},
  ISSN={1558-187X},
  month={May},}
@INPROCEEDINGS{1202694,
  author={Abbasfar, A. and Kung Yao},
  booktitle={2003 IEEE International Conference on Acoustics, Speech, and Signal Processing, 2003. Proceedings. (ICASSP '03).}, 
  title={An efficient architecture for high speed turbo decoders}, 
  year={2003},
  volume={4},
  number={},
  pages={IV-521},
  abstract={Turbo codes not only achieve near Shannon-capacity performance, but also have decoders with modest complexity, which is crucial for implementation. So far efficient architectures for decoding of turbo codes have been proposed that are suitable for sequential processing. In this paper a novel parallel processing architecture for a very high-speed turbo decoder is presented. The performance of this decoder and the tradeoff between speed and efficiency are discussed. It is shown that some decoders can run faster by some orders of magnitude while maintaining almost the same processing load. A systolic implementation of this decoder is presented at the end.},
  keywords={},
  doi={10.1109/ICASSP.2003.1202694},
  ISSN={1520-6149},
  month={April},}
@INPROCEEDINGS{1203670,
  author={Huamin Chen and Mohapatra, P.},
  booktitle={23rd International Conference on Distributed Computing Systems Workshops, 2003. Proceedings.}, 
  title={Using service brokers for accessing backend servers for web applications}, 
  year={2003},
  volume={},
  number={},
  pages={928-933},
  abstract={Web service infrastructures usually are comprised of front-end Web servers that accept requests and process them, and backend servers that manage data and services. Current Web servers use various API sets to access backend services. This model does not support service differentiation, overload control, caching of contents generated by backend servers. We have proposed a framework for using service brokers to facilitate these features. Service brokers are software agents that are the access points to backend services in Web servers. Unlike the current API-based scheme where accesses to backend services are through stateless and isolated APIs, in service broker framework, they are undertaken bypassing messages to service brokers who gather all the requests and intelligently process them. We have prototyped this framework and validated its function in providing request clustering and service differentiation in accessing backend services. In addition, the performance in terms of the processing time is enhanced by this approach.},
  keywords={},
  doi={10.1109/ICDCSW.2003.1203670},
  ISSN={},
  month={May},}
@ARTICLE{1206506,
  author={Quaglia, F. and Santoro, A.},
  journal={IEEE Transactions on Parallel and Distributed Systems}, 
  title={Nonblocking checkpointing for optimistic parallel simulation: description and an implementation}, 
  year={2003},
  volume={14},
  number={6},
  pages={593-610},
  abstract={Describes a nonblocking checkpointing mode in support of optimistic parallel discrete event simulation. This mode allows real concurrency in the execution of state saving and other simulation specific operations (e.g, event list update, event execution) with the aim of removing the cost of recording state information from the completion time of the parallel simulation application. We present an implementation of a C library supporting nonblocking checkpointing on a myrinet based cluster, which demonstrates the practical viability of this checkpointing mode on standard off-the-shelf hardware. By the results of an empirical study on classical parameterized synthetic benchmarks, we show that, except for the case of minimal state granularity applications, nonblocking checkpointing allows improvement of the speed of the parallel execution, as compared to commonly adopted, optimized checkpointing methods based on the classical blocking mode. A performance study for the case of a personal communication system (PCS) simulation is additionally reported to point out the benefits from nonblocking checkpointing for a real world application.},
  keywords={},
  doi={10.1109/TPDS.2003.1206506},
  ISSN={1558-2183},
  month={June},}
@ARTICLE{1207365,
  author={Kavcic, A. and Xiao Ma and Mitzenmacher, M.},
  journal={IEEE Transactions on Information Theory}, 
  title={Binary intersymbol interference channels: Gallager codes, density evolution, and code performance bounds}, 
  year={2003},
  volume={49},
  number={7},
  pages={1636-1652},
  abstract={We study the limits of performance of Gallager codes (low-density parity-check (LDPC) codes) over binary linear intersymbol interference (ISI) channels with additive white Gaussian noise (AWGN). Using the graph representations of the channel, the code, and the sum-product message-passing detector/decoder, we prove two error concentration theorems. Our proofs expand on previous work by handling complications introduced by the channel memory. We circumvent these problems by considering not just linear Gallager codes but also their cosets and by distinguishing between different types of message flow neighborhoods depending on the actual transmitted symbols. We compute the noise tolerance threshold using a suitably developed density evolution algorithm and verify, by simulation, that the thresholds represent accurate predictions of the performance of the iterative sum-product algorithm for finite (but large) block lengths. We also demonstrate that for high rates, the thresholds are very close to the theoretical limit of performance for Gallager codes over ISI channels. If C denotes the capacity of a binary ISI channel and if C/sub i.i.d./ denotes the maximal achievable mutual information rate when the channel inputs are independent and identically distributed (i.i.d.) binary random variables (C/sub i.i.d.//spl les/C), we prove that the maximum information rate achievable by the sum-product decoder of a Gallager (coset) code is upper-bounded by C/sub i.i.d./. The last topic investigated is the performance limit of the decoder if the trellis portion of the sum-product algorithm is executed only once; this demonstrates the potential for trading off the computational requirements and the performance of the decoder.},
  keywords={},
  doi={10.1109/TIT.2003.813563},
  ISSN={1557-9654},
  month={July},}
@INPROCEEDINGS{1207417,
  author={Quaglia, F. and Santoro, A.},
  booktitle={Seventeenth Workshop on Parallel and Distributed Simulation, 2003. (PADS 2003). Proceedings.}, 
  title={CCL v3.0: multiprogrammed semi-asynchronous checkpoints}, 
  year={2003},
  volume={},
  number={},
  pages={21-28},
  abstract={CCL (Checkpointing and Communication Library) is a recently developed software in support of optimistic parallel simulation on myrinet based clusters. Beyond classical low latency message delivery functionalities, this library implements CPU offloaded, semiasynchronous checkpointing functionalities based on data transfer capabilities provided by a programmable DMA engine on board myrinet network cards. The latest version of CCL (v2.4), designed for M2M-PCI32C myrinet cards, only supports monoprogrammed semiasynchronous checkpoints. This forces resynchronization between CPU and DMA activities each time a new checkpoint request must be issued at the simulation application level while the last issued one is still being carried out by the DMA engine. We present CCL v3.0 that, exploiting hardware features of more advanced M3M-PCI64C myrinet cards, supports multiprogrammed semiasynchronous checkpoints. The multiprogrammed approach allows higher degree of concurrency between checkpointing and other simulation specific operations carried out by the CPU, with obvious benefits on performance. We also report the results of the evaluation of those benefits for the case of a personal communication system simulation application.},
  keywords={},
  doi={10.1109/PADS.2003.1207417},
  ISSN={1087-4097},
  month={June},}
@INPROCEEDINGS{1207416,
  author={Steinman, J.S. and Wong, J.W.},
  booktitle={Seventeenth Workshop on Parallel and Distributed Simulation, 2003. (PADS 2003). Proceedings.}, 
  title={The SPEEDES persistence framework and the standard simulation architecture}, 
  year={2003},
  volume={},
  number={},
  pages={11-20},
  abstract={We provide an overview of the SPEEDES persistence framework that is currently used to automate checkpoint/restart for the joint simulation system. The persistence framework interfaces are documented and standards are proposed for the standard simulation architecture. The persistence framework fundamentally keeps track of memory allocations and pointer references within a high-speed internal database linked with applications. With persistence, an object, and the collection of objects it recursively references through pointers, can be automatically packed into a buffer that is written to disk or sent as a message to another machine. Later, that buffer can be used to reconstruct the object and all of its recursively referenced objects. The reconstructed objects will likely be instantiated at different memory locations. The persistence framework automatically updates all affected pointer references to account for this fact. The persistence framework is fully integrated with the SPEEDES rollback infrastructure and built-in container class libraries that include an implementation of the standard template library. These utilities automate support for optimistic event processing required by many high-performance parallel and distributed time management algorithms. In the future, persistence will enable dynamic load balancing algorithms to migrate complex objects to different processors.},
  keywords={},
  doi={10.1109/PADS.2003.1207416},
  ISSN={1087-4097},
  month={June},}
@ARTICLE{1209016,
  author={Kemme, B. and Pedone, F. and Alonso, G. and Schiper, A. and Wiesmann, M.},
  journal={IEEE Transactions on Knowledge and Data Engineering}, 
  title={Using optimistic atomic broadcast in transaction processing systems}, 
  year={2003},
  volume={15},
  number={4},
  pages={1018-1032},
  abstract={Atomic broadcast primitives are often proposed as a mechanism to allow fault-tolerant cooperation between sites in a distributed system. Unfortunately, the delay incurred before a message can be delivered makes it difficult to implement high performance, scalable applications on top of atomic broadcast primitives. Recently, a new approach has been proposed for atomic broadcast which, based on optimistic assumptions about the communication system, reduces the average delay for message delivery to the application. We develop this idea further and show how applications can take even more advantage of the optimistic assumption by overlapping the coordination phase of the atomic broadcast algorithm with the processing of delivered messages. In particular, we present a replicated database architecture that employs the new atomic broadcast primitive in such a way that communication and transaction processing are fully overlapped, providing high performance without relaxing transaction correctness.},
  keywords={},
  doi={10.1109/TKDE.2003.1209016},
  ISSN={1558-2191},
  month={July},}
@INPROCEEDINGS{1207704,
  author={Beaudenon, V. and Encrenaz, E. and Desbarbieux, J.-L.},
  booktitle={Third International Conference on Application of Concurrency to System Design, 2003. Proceedings.}, 
  title={Design validation of ZCSP with SPIN}, 
  year={2003},
  volume={},
  number={},
  pages={102-110},
  abstract={We consider the problem of specifying a model of the zero copy secured protocol for the purpose of LTL verification with the SPIN model checker. ZCSP is based on direct memory access. Data is directly read/written in user space memory, decreasing latency and saving processor computing time. We first introduce the ZCSP protocol before analysing different ways of modelling it. Two main steps were performed: a finite and a nonfinite sequences model. The first model gave us an overview of the protocol robustness. The second allowed us to test realistic properties. We also describe LTL properties that were checked with the SPIN model checker. Unfortunately, the size of the system was frequently prohibitive. Thus, we explain all minimization steps we had to perform: variables' domains restriction, interleaving reduction, realistic environment representation by fairness constraints.},
  keywords={},
  doi={10.1109/CSD.2003.1207704},
  ISSN={},
  month={June},}
@INPROCEEDINGS{1210110,
  author={Sprenger, C. and Worytkiewicz, K.},
  booktitle={First ACM and IEEE International Conference on Formal Methods and Models for Co-Design, 2003. MEMOCODE '03. Proceedings.}, 
  title={A verification methodology for infinite-state message passing systems}, 
  year={2003},
  volume={},
  number={},
  pages={255-264},
  abstract={The verification methodology studied in this paper stems from investigations on respectively deduction-based model checking and semantics of concurrency. Specifically, we consider imperative programs with CSP-like communication and use a categorical semantics as foundation to extract from a program a control graph labeled by transition predicates. This logical content acts as system description for a deduction-based model checker of LTL properties. We illustrate the methodology with a concrete realization in form of the Mc5 verification tool written in Ocaml and using the theorem prover PVS as back-end.},
  keywords={},
  doi={10.1109/MEMCOD.2003.1210110},
  ISSN={},
  month={June},}
@INPROCEEDINGS{1213147,
  author={Hippold, J. and Runger, G.},
  booktitle={Proceedings International Parallel and Distributed Processing Symposium}, 
  title={Task pool teams for implementing irregular algorithms on clusters of SMPs}, 
  year={2003},
  volume={},
  number={},
  pages={8 pp.-},
  abstract={The characteristics of irregular algorithms make a parallel implementation difficult, especially for PC clusters or clusters of SMPs. These characteristics may include an unpredictable access behavior to dynamically changing data structures or strong irregular coupling of computations. Problems are an unknown load distribution and expensive irregular communication patterns for data accesses and redistributions. We propose task pool teams for implementing irregular algorithms on clusters of PCs or SMPs. A task pool team combines multithreaded programming using task pools on single nodes with explicit message passing between different nodes. As an application example, we use the hierarchical radiosity algorithm.},
  keywords={},
  doi={10.1109/IPDPS.2003.1213147},
  ISSN={1530-2075},
  month={April},}
@INPROCEEDINGS{1213161,
  author={Thiffault, C. and Voss, M. and Healey, S.T. and Seon Wook Kim},
  booktitle={Proceedings International Parallel and Distributed Processing Symposium}, 
  title={Dynamic instrumentation of large-scale MPI and OpenMP applications}, 
  year={2003},
  volume={},
  number={},
  pages={9 pp.-},
  abstract={In recent years, software infrastructures for the run-time instrumentation of programs have begun to emerge. The paper presents and evaluates prototypes of dynamic instrumentation and dynamic control of instrumentation for parallel mixed MPI/OpenMP applications. An overview of the technology behind these approaches is presented. Prototypes of dynamic instrumentation and dynamic control of instrumentation for use with the Vampir/Guide View (VGV) toolset (GmbH. Pallas, 2002) are discussed. Instrumentation evaluations using the ASCI kernel benchmarks are used for proof of concept on a cluster of SMPs. The results demonstrate that a mix of dynamic instrumentation and dynamic control of instrumentation can be an effective performance analysis alternative to the traditional static instrumentation of applications.},
  keywords={},
  doi={10.1109/IPDPS.2003.1213161},
  ISSN={1530-2075},
  month={April},}
@INPROCEEDINGS{1213188,
  author={Tipparaju, V. and Nieplocha, J. and Panda, D.},
  booktitle={Proceedings International Parallel and Distributed Processing Symposium}, 
  title={Fast collective operations using shared and remote memory access protocols on clusters}, 
  year={2003},
  volume={},
  number={},
  pages={10 pp.-},
  abstract={This paper describes a novel methodology for implementing a common set of collective communication operations on clusters based on symmetric multiprocessor (SMP) nodes. Called Shared-Remote-Memory collectives, or SRM, our approach replaces the point-to-point message passing, traditionally used in implementation of collective message-passing operations, with a combination of shared and remote memory access (RMA) protocols that are used to implement semantics of the collective operations directly. Appropriate embedding of the communication graphs in a cluster maximizes the use of shared memory and reduces network communication. Substantial performance improvements are achieved over the highly optimized commercial IBM implementation and the open-source MPICH implementation of MPI across a wide range of message sizes on the IBM SP. For example, depending on the message size and number of processors, SRM implementation of broadcast, reduce, and barrier outperforms IBM MPI/spl I.bar/Bcast by 27-84%, MPI/spl I.bar/Reduce by 24-79%, and MPI/spl I.bar/Barrier by 73% on 256 processors, respectively.},
  keywords={},
  doi={10.1109/IPDPS.2003.1213188},
  ISSN={1530-2075},
  month={April},}
@INPROCEEDINGS{1213190,
  author={Prodan, R. and Fahringer, T.},
  booktitle={Proceedings International Parallel and Distributed Processing Symposium}, 
  title={A Web service-based experiment management system for the Grid}, 
  year={2003},
  volume={},
  number={},
  pages={10 pp.-},
  abstract={We have developed the ZENTURIO experiment management system for performance studies, parameter studies, and software testing of parallel applications on cluster and Grid architectures. In this paper we describe the design and implementation of ZENTURIO as a Web service-based distributed architecture. We highlight limitations of Web services for deployment on the Grid and propose solutions. Experiment generator and experiment executor services are used to generate, respectively submit and manage experiments on remote Grid sites. A UDDI-based service repository publishes information about existing Web service implementations. Factory and registry services are employed to create and register Web services on the Grid. A GMA-compliant event infrastructure supports high-level notifications about important events. We compare our design with the open grid service architecture (OGSA) and highlight similarities and differences. We report results of using ZENTURIO to conduct performance analysis of a material science code executed on the Grid by using GRAM.},
  keywords={},
  doi={10.1109/IPDPS.2003.1213190},
  ISSN={1530-2075},
  month={April},}
@INPROCEEDINGS{1213255,
  author={Mohr, B. and Traff, J.L.},
  booktitle={Proceedings International Parallel and Distributed Processing Symposium}, 
  title={Initial design of a test suite for automatic performance analysis tools}, 
  year={2003},
  volume={},
  number={},
  pages={10 pp.-},
  abstract={Automatic performance tools must of course be tested as to whether they perform their task correctly. Because performance tools are meta-programs, tool testing is more complex than ordinary program testing and comprises at least three aspects. First, it must be ensured that the tools do neither alter the semantics nor distort the run-time behavior of the application under investigation. Next, it must be verified that the tools collect the correct performance data as required by their specification. Finally, it must be checked that the tools indeed perform their intended tasks and detect relevant performance problems. Focusing on the latter (correctness) aspect, testing can be done using synthetic test functions with controllable performance properties, and/or real world applications with known performance behavior. A systematic test suite can be built from synthetic test functions and other components, possibly with the help of tools to assist the user in putting the pieces together into executable test programs. Clearly, such a test suite can be highly useful to builders of performance analysis tools. It is surprising that up till now, no systematic effort has been undertaken to provide such a suite. In this paper we discuss the initial design of a test suite for checking the correctness (in the above sense) of automatic performance analysis tools. In particular, we describe a collection of synthetic test functions which allows to easily construct both simple and more complex test programs with desired performance properties.},
  keywords={},
  doi={10.1109/IPDPS.2003.1213255},
  ISSN={1530-2075},
  month={April},}
@INPROCEEDINGS{1213293,
  author={Rizk, N.J.},
  booktitle={Proceedings International Parallel and Distributed Processing Symposium}, 
  title={Parallelisation of IBD computation for determining genetic disease map}, 
  year={2003},
  volume={},
  number={},
  pages={6 pp.-},
  abstract={A number of software packages are available for the construction of comprehensive human genetic maps. In this paper we parallelize the widely used package Genehunter. We restrict our attention to only one function of the package, namely the computations of Identity By Descent (IBD) genes of a family. We use a master-slave model with the Message Passing Interface (MPI) parallel environment. Our tests are done on two different architectures: a network of workstations and a shared memory multiprocessor. A new and efficient strategy to classify the parallelization of genetic linkage analysis programs results from our experiments. The classification is based on values of parameters which affect the complexity of the computation.},
  keywords={},
  doi={10.1109/IPDPS.2003.1213293},
  ISSN={1530-2075},
  month={April},}
@INPROCEEDINGS{1213307,
  author={Rauber, T. and Runger, G. and Trautmann, S.},
  booktitle={Proceedings International Parallel and Distributed Processing Symposium}, 
  title={A distributed hierarchical programming model for heterogeneous cluster of SMPs}, 
  year={2003},
  volume={},
  number={},
  pages={8 pp.-},
  abstract={Cluster systems are getting increasingly popular since they provide large computational power at a reasonable price. The cluster nodes are often SMP with a small number of processors that can access a shared address space. The nodes are connected by a network like Myrinet or SCI, so the global address space is distributed. In this paper, we present a new programming model for such clusters of SMP. The model allows the programmer to adapt his program to the two-level structure of the address space by providing a micro-level and a macro-level. The micro-level allows a thread formulation of multiprocessor tasks that are executed within a node of the cluster system. The macro-level allows the hierarchical structuring of multiprocessor-tasks according to the structure of the algorithm using message passing for data-exchange. We demonstrate the usefulness of the approach by runtime tests on several cluster systems with different node architectures and different interconnection networks.},
  keywords={},
  doi={10.1109/IPDPS.2003.1213307},
  ISSN={1530-2075},
  month={April},}
@INPROCEEDINGS{1213364,
  author={Tinetti, F.G. and Luque, E.},
  booktitle={Proceedings International Parallel and Distributed Processing Symposium}, 
  title={Efficient broadcasts and simple algorithms for parallel linear algebra computing in clusters}, 
  year={2003},
  volume={},
  number={},
  pages={8 pp.-},
  abstract={This paper presents a natural and efficient implementation for the classical broadcast message passing routine which optimizes performance of Ethernet based clusters. A simple algorithm for parallel matrix multiplication is specifically designed to take advantage of both, parallel computing facilities (CPUs) provided by clusters, and optimized performance of broadcast messages on Ethernet based clusters. Also, this simple parallel algorithm proposed for matrix multiplication takes into account the possibly heterogenous computing hardware and maintains a balanced workload of computers according to their relative computing power. Performance tests are presented on a heterogenous cluster as well as on a homogeneous cluster, where it is compared with the parallel matrix multiplication provided by the ScaLAPACK library. Another simple parallel algorithm is proposed for LU matrix factorization (a general method to solve dense systems of equations) following the same guidelines used for the parallel matrix multiplication algorithm. Some performance tests are presented over a homogenous cluster.},
  keywords={},
  doi={10.1109/IPDPS.2003.1213364},
  ISSN={1530-2075},
  month={April},}
@INPROCEEDINGS{1213372,
  author={Cohen, A.},
  booktitle={Proceedings International Parallel and Distributed Processing Symposium}, 
  title={A performance analysis of 4X InfiniBand data transfer operations}, 
  year={2003},
  volume={},
  number={},
  pages={7 pp.-},
  abstract={The performance of 4X InfiniBand send/receive and RDMA operations is studied by running tests to measure latency, data rate, number of operations per second, and CPU load. The measurements performed are for application-to-application data transfers using user-level InfiniBand (IB) verbs. It is shown that IB is capable of low latencies (10 /spl mu/s for small messages) and very high data rates at low CPU loads (over 6 Gbs with 64 KB messages at under 20% CPU load). A very large number of operations per second (over 400,000) is obtained for small messages. Some comparisons are made with the performance of TCP/IP on Gigabit Ethernet. In addition, the paper studies the impact of varying the number of outstanding requests on the obtained throughput, and shows when the peak throughput can be obtained for messages of varying sizes. Finally, an approach for handling completions in user space without a busy wait and without the use of signals is introduced and CPU load results based on this approach are presented.},
  keywords={},
  doi={10.1109/IPDPS.2003.1213372},
  ISSN={1530-2075},
  month={April},}
@INPROCEEDINGS{1213421,
  author={Tsilikas, G. and Fleury, M.},
  booktitle={Proceedings International Parallel and Distributed Processing Symposium}, 
  title={Semi-structured portable library for multiprocessor servers}, 
  year={2003},
  volume={},
  number={},
  pages={6 pp.-},
  abstract={The MiPPS library supports a hybrid model of parallel programming. The library is targeted at commodity multiprocessors, with support for clusters. The implementation of the concurrency routines reveals discrepancies between popular operating systems. Tests on suitable applications also reveal similar discrepancies in performance across different multiprocessors. The MiPPS library has also been the basis of a parallelization of the Active Chart Parsing algorithm for speech understanding.},
  keywords={},
  doi={10.1109/IPDPS.2003.1213421},
  ISSN={1530-2075},
  month={April},}
@INPROCEEDINGS{1213430,
  author={Peuker, S. and Hayes, I.},
  booktitle={Proceedings International Parallel and Distributed Processing Symposium}, 
  title={Reasoning about deadlines in concurrent real-time programs}, 
  year={2003},
  volume={},
  number={},
  pages={8 pp.-},
  abstract={We propose a method for the timing analysis of concurrent real-time programs with hard deadlines. We divide the analysis into a machine-independent and a machine-dependent task. The latter takes into account the execution times of the program on a particular machine. Therefore, our goal is to make the machine-dependent phase of the analysis as simple as possible. We succeed in the sense that the machine-dependent phase remains the same as in the analysis of sequential programs. We shift the complexity introduced by concurrency completely to the machine-independent phase.},
  keywords={},
  doi={10.1109/IPDPS.2003.1213430},
  ISSN={1530-2075},
  month={April},}
@INPROCEEDINGS{1213471,
  author={Forgeau, B. and Killat, U.},
  booktitle={Proceedings International Parallel and Distributed Processing Symposium}, 
  title={An empirical study of different strategies for the parallel simulation of large-scale communication networks}, 
  year={2003},
  volume={},
  number={},
  pages={8 pp.-},
  abstract={An MPI-based parallel simulation system for wide area networks is described in this article, as well as some characteristics of the models it handles. A simple synchronization algorithm is then presented along with some additional synchronization strategies that could improve the performance. These strategies are tested on a reference model, what shows how the simulator scales and how it is sensitive to parameters such as connectivity and send granularity.},
  keywords={},
  doi={10.1109/IPDPS.2003.1213471},
  ISSN={1530-2075},
  month={April},}
@INPROCEEDINGS{1213492,
  author={Cantonnet, F. and Yao, Y. and Annareddy, S. and Mohamed, A.S. and El-Ghazawi, T.A.},
  booktitle={Proceedings International Parallel and Distributed Processing Symposium}, 
  title={Performance monitoring and evaluation of a UPC implementation on a NUMA architecture}, 
  year={2003},
  volume={},
  number={},
  pages={8 pp.-},
  abstract={UPC is an explicit parallel extension of ANSI C, which has been gaining rising attention from vendors and users. In this paper, we consider the low-level monitoring and experimental performance evaluation of a new implementation of the UPC compiler on the SGI Origin family of NUMA architectures. These systems offer many opportunities for the high-performance implantation of UPC They also offer, due to their many hardware monitoring counters, the opportunity for low-level performance measurements to guide compiler implementations. Early, UPC compilers have the challenge of meeting the syntax and semantics requirements of the language. As a result, such compilers tend to focus on correctness rather than on performance. In this paper, we report on the performance of selected applications and kernels under this new compiler. The measurements were designed to help shed some light on the next steps that should be taken by UPC compiler developers to harness the full performance and usability potential of UPC under these architectures.},
  keywords={},
  doi={10.1109/IPDPS.2003.1213492},
  ISSN={1530-2075},
  month={April},}
@INPROCEEDINGS{1218029,
  author={Derbel, B. and Mosbah, M.},
  booktitle={Proceedings on Seventh International Conference on Information Visualization, 2003. IV 2003.}, 
  title={Distributing the execution of a distributed algorithm over a network}, 
  year={2003},
  volume={},
  number={},
  pages={485-490},
  abstract={Visidia is a tool for the simulation and the visualization of distributed algorithms. The simulation has been done using one machine [M. Bauderon et al., (2002)]. We present an approach of such a simulation by using a network of machines. Indeed, we suppose that several machines connected by a network can take part in the simulation. We give both a specification of the set up model and a description of the implementation carried out.},
  keywords={},
  doi={10.1109/IV.2003.1218029},
  ISSN={},
  month={July},}
@ARTICLE{1222729,
  author={Engling Yeo and Anantharam, V.},
  journal={IEEE Communications Magazine}, 
  title={Iterative decoder architectures}, 
  year={2003},
  volume={41},
  number={8},
  pages={132-140},
  abstract={Implementation constraints on iterative decoders applying message-passing algorithms are investigated. Serial implementations similar to traditional microprocessor datapaths are compared against architectures with multiple processing elements that exploit the inherent parallelism in the decoding algorithm. Turbo codes and low-density parity check codes, in particular, are evaluated in terms of their suitability for VLSI implementation in addition to their bit error rate performance as a function of signal-to-noise ratio. It is necessary to consider efficient realizations of iterative decoders when area, power, and throughput of the decoding implementation are constrained by practical design issues of communications receivers.},
  keywords={},
  doi={10.1109/MCOM.2003.1222729},
  ISSN={1558-1896},
  month={Aug},}
@ARTICLE{1225055,
  author={Jichiang Tsai},
  journal={IEEE Transactions on Parallel and Distributed Systems}, 
  title={On properties of RDT communication-induced checkpointing protocols}, 
  year={2003},
  volume={14},
  number={8},
  pages={755-764},
  abstract={Rollback-dependency trackability (RDT) is a property stating that all rollback dependencies between local checkpoints are online trackable by using a transitive dependency vector. The most crucial RDT characterizations introduced in the literature can be represented as certain types of RDT-PXCM-paths. Here, let the U-path and V-path be any two types of RDT-PXCM-paths. We investigate several properties of communication-induced checkpointing protocols that ensure the RDT property. First, we prove that if an online RDT protocol encounters a U-path at a point of a checkpoint and communication pattern associated with a distributed computation, it also encounters a V-path there. Moreover, if this encountered U-path is invisibly doubled, the corresponding encountered V-path is invisibly doubled as well. Therefore, we can conclude that breaking all invisibly doubled U-paths is equivalent to breaking all invisibly doubled V-paths for an online RDT protocol. Next, we continue to demonstrate that a visibly doubled U-path must contain a doubled U-cycle in the causal past. These results can further deduce that some different checkpointing protocols actually have the same behavior for all possible patterns. Finally, we present a commendatory systematic technique for comparing the performance of online RDT protocols.},
  keywords={},
  doi={10.1109/TPDS.2003.1225055},
  ISSN={1558-2183},
  month={Aug},}
@INPROCEEDINGS{1228099,
  author={Lehmann, F.},
  booktitle={IEEE International Symposium on Information Theory, 2003. Proceedings.}, 
  title={Distance properties of irregular LDPC codes}, 
  year={2003},
  volume={},
  number={},
  pages={85-},
  abstract={In this paper, we investigate the distance properties of irregular LDPC codes using the ensemble construction proposed by Richardson et al (Ref. 2). By generalizing the method introduced by Gallager for regular LDPC codes [R.G. Gallager, 1963], we calculate the average weight distribution of irregular LDPC codes. Then, we interpret the stability condition of density evolution as a sufficient condition so that the error probability due to low weight codewords tends to zero under maximum-likelihood decoding.},
  keywords={},
  doi={10.1109/ISIT.2003.1228099},
  ISSN={},
  month={June},}
@INPROCEEDINGS{1232057,
  author={Lory, P.},
  booktitle={14th International Workshop on Database and Expert Systems Applications, 2003. Proceedings.}, 
  title={A coloured Petri net trust model}, 
  year={2003},
  volume={},
  number={},
  pages={415-419},
  abstract={Public-key infrastructures are a prerequisite for security in distributed systems and for reliable electronic commerce. It is their goal to provide the authenticity of public keys. Formal models for public-key infrastructures (trust models) contribute decisively to a deeper understanding of the desirable design principles of these infrastructures. The trust model of the presented paper is based on the modelling technique of coloured Petri nets. These are a special class of high-level Petri nets with an intuitively appealing graphical representation and a few powerful primitives. Elaborate and well tested software is available.},
  keywords={},
  doi={10.1109/DEXA.2003.1232057},
  ISSN={1529-4188},
  month={Sep.},}
@INPROCEEDINGS{1233836,
  author={Hanson, J.E. and Milosevic, Z.},
  booktitle={Seventh IEEE International Enterprise Distributed Object Computing Conference, 2003. Proceedings.}, 
  title={Conversation-oriented protocols for contract negotiations}, 
  year={2003},
  volume={},
  number={},
  pages={40-49},
  abstract={The expression of contracts in computer readable form, and the development of automated tests for completeness and well-formedness of contracts, has opened the door to significant advances in automating contract negotiation. To meet the needs of automation, such negotiations must follow explicitly specified message-exchange protocols. But to meet the needs of the negotiating parties, these protocols must be independent of the decision-making processes driving them as well as neutral to the outcome of the negotiations. In this paper we illustrate how both needs may be simultaneously met by a small set of conversation policies employed within a general purpose conversation support architecture.},
  keywords={},
  doi={10.1109/EDOC.2003.1233836},
  ISSN={},
  month={Sep.},}
@INPROCEEDINGS{1235639,
  author={Mansour, M.M. and Shanbhag, N.R.},
  booktitle={2003 IEEE Workshop on Signal Processing Systems (IEEE Cat. No.03TH8682)}, 
  title={A novel design methodology for high-performance programmable decoder cores for AA-LDPC codes}, 
  year={2003},
  volume={},
  number={},
  pages={29-34},
  abstract={A new parameterized-core-based design methodology targeted for programmable decoders for low-density parity-check (LDPC) codes is proposed. The methodology solves the two major drawbacks of excessive memory overhead and complex on-chip interconnects typical of existing decoder implementations and which limit the scalability, degrade the error-correction capability, and restrict the domain of application of LDPC codes. Diverse memory and interconnect optimizations are performed at the code-design, decoding algorithm, decoder architecture, and physical layout levels, with the following features: (1) architecture-aware (AA)-LDPC code design with embedded structural features that significantly reduce interconnect complexity; (2) faster and memory-efficient turbo-decoding algorithm for LDPC codes; (3) programmable architecture having distributed memory, parallel message processing units, and dynamic/scalable transport networks for routing messages; (4) a parameterized macro-cell layout library implementing the main components of the architecture with scaling parameters that enable low-level transistor sizing and power-rail scaling for power-delay-area optimization. A 14 mm/sup 2/ programmable decoder core for a rate- 1/2 , length 2048 AA-LDPC code generated using the proposed methodology is presented; it delivers a throughput of 1.6 Gbps at 125 MHz and consumes 760 mW of power.},
  keywords={},
  doi={10.1109/SIPS.2003.1235639},
  ISSN={1520-6130},
  month={Aug},}
@INPROCEEDINGS{1236208,
  author={Sangiorgi, D.},
  booktitle={First International Conference onSoftware Engineering and Formal Methods, 2003.Proceedings.}, 
  title={Taming mobile processes using types}, 
  year={2003},
  volume={},
  number={},
  pages={64-70},
  abstract={We discuss some examples of the use of types for taming the behavior of concurrent systems, in particular systems of mobile processes. By "taming" we mean that we use types to enforce expected - and desirable - properties of systems. These properties would not hold without types. The examples we discuss are a printer with mobile ownership, a Boolean package implementation, and the termination property. In all these examples, the solutions based on types are only sketched. Details on the types themselves (the formal systems and their basic properties), and on the proof techniques based on types with which the equalities in the examples are proved can be found following the reference pointers, especially the work of Sangiorgi and Walker (2001) and Sangiorgi (2001). The examples are presented in the /spl pi/-calculus described by Milner (1992), a paradigmatical process calculus for message-passing concurrency.},
  keywords={},
  doi={10.1109/SEFM.2003.1236208},
  ISSN={},
  month={Sep.},}
@INPROCEEDINGS{1236348,
  author={Werstein, P. and Pethick, M. and Huang, Z.},
  booktitle={Proceedings of the Fourth International Conference on Parallel and Distributed Computing, Applications and Technologies}, 
  title={A performance comparison of DSM, PVM, and MPI}, 
  year={2003},
  volume={},
  number={},
  pages={476-482},
  abstract={We compare the performance of the Treadmarks DSM system with two popular message passing systems (PVM and MPI). The comparison is done on 1, 2, 4, 8, 16, 24, and 32 nodes. Applications are chosen to represent three classes of problems: loosely synchronous, embarrassingly parallel, and synchronous. The results show DSM has similar performance to message passing for the embarrassingly parallel class. However the performance of DSM is lower than PVM and MPI for the synchronous and loosely synchronous classes of problems. An analysis of the reasons is presented.},
  keywords={},
  doi={10.1109/PDCAT.2003.1236348},
  ISSN={},
  month={Aug},}
@INPROCEEDINGS{1236426,
  author={Qiang Peng and Yulin Zhao},
  booktitle={Proceedings of the Fourth International Conference on Parallel and Distributed Computing, Applications and Technologies}, 
  title={Study on parallel approach in H.26L video encoder}, 
  year={2003},
  volume={},
  number={},
  pages={834-837},
  abstract={H.26L is an emerging video encoding standard proposed by ITU, which goal is for video communication and multicast in low bit rate conditions. We give detailed analysis and performance tests for the parallelism of the H.26L video encoder test model long-term (TML8.0). Based on these tests, several parallel schedule strategies are discussed in different aspects, and the optimal one is selected and implemented by using MPI. At last, experiment results on Dawning-2000 MPP machines with different processors are given. The analysis and simulation results show that the H.26L has a good parallel performance and scalability on slice layer, and parallel computing can greatly speed up the processing of H.26L encoder. The experiment methods and results can be applied to many parallel systems for H.26L video processing.},
  keywords={},
  doi={10.1109/PDCAT.2003.1236426},
  ISSN={},
  month={Aug},}
@INPROCEEDINGS{1238069,
  author={Fenkam, P. and Gall, H. and Jazayeri, M.},
  booktitle={22nd International Symposium on Reliable Distributed Systems, 2003. Proceedings.}, 
  title={A systematic approach to the development of event based applications}, 
  year={2003},
  volume={},
  number={},
  pages={199-208},
  abstract={We propose a novel framework logic of event consumption and publication (LECAP) for the development of event-based applications. Our approach offers the following advantages over existing approaches: 1) it supports a while-parallel language, 2) the reasoning allows a dynamic (instead of static) binding of programs to events, 3) it is oriented towards stepwise development of systems, and 4) the underlying logic supports the composition of specifications. The event based architectural style has been recognized as fostering the development of large-scale and complex systems by loosely coupling their components. It is therefore increasingly deployed in various environments such as middleware for mobile computing, message oriented middleware, integration frameworks, communication standards, and commercial toolkits. Current approaches to the development of event-based applications are ad hoc and do not support reasoning about their correctness. The LECAP approach is intended to solve this problem through a compositional and stepwise approach to specification and verification of event-based applications.},
  keywords={},
  doi={10.1109/RELDIS.2003.1238069},
  ISSN={1060-9857},
  month={Oct},}
@ARTICLE{1239030,
  author={Chandramani, P. and Ping Gui and Ekman, J. and Xiaoqing Wang and Kiamilev, F. and Christensen, M. and Milojkovic, P. and Haney, M.W. and Anderson, J. and Driscoll, K. and Vanvoorst, B.},
  journal={IEEE Journal of Selected Topics in Quantum Electronics}, 
  title={Design of a multigigabit optical network interface card}, 
  year={2003},
  volume={9},
  number={2},
  pages={636-646},
  abstract={High-speed optical data links enable local area networks (LANs) that operate at data rates above 10 Gb/s. Various network, protocol and switch architectures have been proposed that use these links. The optical network interface card (ONIC) is an important component for demonstrating efficient application of these architectures. In this paper, we describe the design of a programmable ONIC that interfaces a 12-channel gigabit parallel optical link module with a 64-bit/66-MHz PCI computer bus. Hardware programmability (using FPGAs) enables the ONIC to efficiently implement different communication protocols. For hardware testing, the ONIC hardware was programmed for bit error rate (BER) analysis. In continuous operation at 8 Gb/s for 30 days through a 1-m fiber, no errors occured. For application testing, a custom ONIC software driver was developed. We used this driver to demonstrate message passing between applications running on two ONIC-equipped servers. The ONIC design provides a low-cost solution that can be readily adapted for application and device specific requirements. The use of ONIC in a free-space optical switch system is described here.},
  keywords={},
  doi={10.1109/JSTQE.2003.813320},
  ISSN={1558-4542},
  month={March},}
@INPROCEEDINGS{1240288,
  author={},
  booktitle={18th IEEE International Conference on Automated Software Engineering, 2003. Proceedings.}, 
  title={Proceedings 18th IEEE International Conference on Automated Software Engineering}, 
  year={2003},
  volume={},
  number={},
  pages={},
  abstract={The following topics are discussed: requirements, interfaces, and groupware; software architectures and distributed systems; model checking; software components; software evolution and maintenance; and automated software engineering.},
  keywords={},
  doi={10.1109/ASE.2003.1240288},
  ISSN={1938-4300},
  month={Oct},}
@INPROCEEDINGS{1240299,
  author={Barnat, J. and Brim, L. and Chaloupka, J.},
  booktitle={18th IEEE International Conference on Automated Software Engineering, 2003. Proceedings.}, 
  title={Parallel breadth-first search LTL model-checking}, 
  year={2003},
  volume={},
  number={},
  pages={106-115},
  abstract={We propose a practical parallel on-the-fly algorithm for enumerative LTL (linear temporal logic) model checking. The algorithm is designed for a cluster of workstations communicating via MPI (message passing interface). The detection of cycles (faulty runs) effectively employs the so called back-level edges. In particular, a parallel level-synchronized breadth-first search of the graph is performed to discover back-level edges. For each level, the back-level edges are checked in parallel by a nested depth-first search to confirm or refute the presence of a cycle. Several optimizations of the basic algorithm are presented and advantages and drawbacks of their application to distributed LTL model-checking are discussed. Experimental implementation of the algorithm shows promising results.},
  keywords={},
  doi={10.1109/ASE.2003.1240299},
  ISSN={1938-4300},
  month={Oct},}
@INPROCEEDINGS{1240303,
  author={Foster, H. and Uchitel, S. and Magee, J. and Kramer, J.},
  booktitle={18th IEEE International Conference on Automated Software Engineering, 2003. Proceedings.}, 
  title={Model-based verification of Web service compositions}, 
  year={2003},
  volume={},
  number={},
  pages={152-161},
  abstract={In this paper, we discuss a model-based approach to verifying Web service compositions for Web service implementations. The approach supports verification against specification models and assigns semantics to the behavior of implementation model so as to confirm expected results for both the designer and implementer. Specifications of the design are modeled in UML (Unified Modeling Language), in the form of message sequence charts (MSC), and mechanically compiled into the finite state process notation (FSP) to concisely describe and reason about the concurrent programs. Implementations are mechanically translated to FSP to allow a trace equivalence verification process to be performed. By providing early design verification, the implementation, testing, and deployment of Web service compositions can be eased through the understanding of the differences, limitations and undesirable traces allowed by the composition. The approach is supported by a suite of cooperating tools for specification, formal modeling and trace animation of the composition workflow.},
  keywords={},
  doi={10.1109/ASE.2003.1240303},
  ISSN={1938-4300},
  month={Oct},}
@INPROCEEDINGS{1240368,
  author={Michailidis, P.D. and Margaritis, K.G.},
  booktitle={2003 International Conference on Parallel Processing Workshops, 2003. Proceedings.}, 
  title={Performance analysis of approximate string searching implementations for heterogeneous computing platform}, 
  year={2003},
  volume={},
  number={},
  pages={173-180},
  abstract={This paper presents an analytical performance prediction model that can be used to predict the execution time, speedup and similar performance metrics of four approximate string searching implementations running on an MPI cluster of heterogeneous workstations. The four implementations are based on master-worker model using static and dynamic allocation of the text collection. The developed performance model has been validated on an 8-cluster of heterogeneous workstations and it has been shown that the model is able to predict the execution time and other performance metrics of four parallel implementations accurately.},
  keywords={},
  doi={10.1109/ICPPW.2003.1240368},
  ISSN={1530-2016},
  month={Oct},}
@INPROCEEDINGS{1240395,
  author={Di Pietro, R. and Mancini, L.V. and Yee Wei Law and Etalle, S. and Havinga, P.},
  booktitle={2003 International Conference on Parallel Processing Workshops, 2003. Proceedings.}, 
  title={LKHW: a directed diffusion-based secure multicast scheme for wireless sensor networks}, 
  year={2003},
  volume={},
  number={},
  pages={397-406},
  abstract={In this paper, we present a mechanism for securing group communications in Wireless Sensor Networks (WSN). First, we derive an extension of logical key hierarchy (LKH). Then we merge the extension with directed diffusion. The resulting protocol, LKHW, combines the advantages of both LKH and directed diffusion: robustness in routing, and security from the tried and tested concepts of secure multicast. In particular, LKHW enforces both backward and forward secrecy, while incurring an energy cost that scales roughly logarithmically with the group size. This is the first security protocol that leverages directed diffusion, and we show how directed diffusion can be extended to incorporate security in an efficient manner.},
  keywords={},
  doi={10.1109/ICPPW.2003.1240395},
  ISSN={1530-2016},
  month={Oct},}
@INPROCEEDINGS{1240586,
  author={Liao, W.-K. and Alok Choudhary and Coloma, K. and Thiruvathukal, G.K. and Ward, L. and Russell, E. and Pundit, N.},
  booktitle={2003 International Conference on Parallel Processing, 2003. Proceedings.}, 
  title={Scalable implementations of MPI atomicity for concurrent overlapping I/O}, 
  year={2003},
  volume={},
  number={},
  pages={239-246},
  abstract={For concurrent I/O operations, atomicity defines the results in the overlapping file regions simultaneously read/written by requesting processes. Atomicity has been well studied at the file system level, such as POSIX standard. We investigate the problems arising from the implementation of MPI atomicity for concurrent overlapping write access and provide two programming solutions. Since the MPI definition of atomicity differs from the POSIX one, an implementation that simply relies on the POSIX file systems does not guarantee correct MPI semantics. To have a correct implementation of atomic I/O in MPI, we examine the efficiency of three approaches: I) file locking, 2) graph-coloring, and 3) process-rank ordering. Performance complexity for these methods are analyzed and their experimental results are presented for file systems including NFS, SGI's XFS, and IBM's GPFS.},
  keywords={},
  doi={10.1109/ICPP.2003.1240586},
  ISSN={0190-3918},
  month={Oct},}
@INPROCEEDINGS{1240594,
  author={Jiannong Cao and Liang Zhang and Xinyu Feng and Das, S.K.},
  booktitle={2003 International Conference on Parallel Processing, 2003. Proceedings.}, 
  title={Path compression in forwarding-based reliable mobile agent communications}, 
  year={2003},
  volume={},
  number={},
  pages={313-320},
  abstract={We concern with the design of efficient algorithms for mobile agent communications. We first describe a novel mailbox-based scheme for flexible and adaptive message delivery in mobile agent systems and a specific adaptive protocol derived from the scheme. Then we present the design and verification of a path compression and garbage collection algorithm for improving the performance of the proposed protocol. Simulation results showed that by properly setting some parameters, the algorithm can effectively reduce both the number of location registrations and the communication overhead of each registration. Consequently, the total location registration overhead during the life cycle of a mobile agent is greatly reduced. The algorithm can also be used for clearing useless addresses of mobile agents cached by hosts in the network.},
  keywords={},
  doi={10.1109/ICPP.2003.1240594},
  ISSN={0190-3918},
  month={Oct},}
@INPROCEEDINGS{1241155,
  author={Maes, S. and Reumers, J. and Manderick, B.},
  booktitle={IEEE/WIC International Conference on Intelligent Agent Technology, 2003. IAT 2003.}, 
  title={Identifiability of causal effects in a multi-agent causal model}, 
  year={2003},
  volume={},
  number={},
  pages={605-608},
  abstract={This paper is a first step to extending Judea Pearl's work on identification of causal effects to a multi-agent context. We introduce multi-agent causal models consisting of a collection of agents each having access to a non-disjoint subset of the variables constituting the domain. Every agent has a causal model, determined by nonexperimental data and an acyclic causal diagram over its variables. The algorithm under investigation in this paper, tests whether the assumptions made in a causal model are sufficient to calculate the effect of an intervention (i.e. whether the effect of an intervention is identifiable). It is a distributed algorithm with a minimum amount of inter-agent communication concerning solely shared variables and where the details of each local causal model are kept confidential.},
  keywords={},
  doi={10.1109/IAT.2003.1241155},
  ISSN={},
  month={Oct},}
@INPROCEEDINGS{1243083,
  author={Tang Jianquan and Tong Weiqing and Ding Jingbo and Cai Lizhi},
  booktitle={2003 International Conference on Computer Networks and Mobile Computing, 2003. ICCNMC 2003.}, 
  title={MOM-G: message-oriented middleware on grid environment based on OGSA}, 
  year={2003},
  volume={},
  number={},
  pages={424-427},
  abstract={OGSA (open gird service architecture) implements grid service that is an abstract of every resource via the Web services. But the XML-RPC (remote procedure call based on the eXtensibile Mark Language) convention that grid service commonly uses limits the convenient and massive data transmission. A new mechanism, which is MOM (message-oriented middleware) based on OGSA, is presented here to efficiently solve this problem. It can be utilized by the grid service instances to exchange data with high performance by simplifying data communication mechanism in OGSA. Our MOM mechanism is based not on RPC style message, but original SOAP (simple object access protocol) message.},
  keywords={},
  doi={10.1109/ICCNMC.2003.1243083},
  ISSN={},
  month={Oct},}
@INPROCEEDINGS{1242867,
  author={Araujo, J.S. and Santos, R.O. and Sobrinho, C.L.S.S. and Rocha, J.M. and Guedes, L.A. and Kawasaki, R.Y.},
  booktitle={Proceedings of the 2003 SBMO/IEEE MTT-S International Microwave and Optoelectronics Conference - IMOC 2003. (Cat. No.03TH8678)}, 
  title={Analysis of antennas by FDTD method using parallel processing with MPI}, 
  year={2003},
  volume={2},
  number={},
  pages={1049-1054 vol.2},
  abstract={As far as we are concerned, the implementation of the Finite Differences in the Time Domain (FDTD) method requires, for the solutions of several practical problems in electromagnetism, a long process time and a large amount of memory, what makes it impracticable in various cases, principally when the serial process is used. The current work deals with the concept of a Beowulf cluster and it aims to implement the FDTD method using parallel process for the study of antennas. The obtained system efficiency is then tested in the analysis of two antennas, i. e., a horn antenna and a monopole antenna, what is done by comparing the time spent in the parallel and serial processing.},
  keywords={},
  doi={10.1109/IMOC.2003.1242867},
  ISSN={},
  month={Sep.},}
@INPROCEEDINGS{1250329,
  author={Souto, R.P. and de Campos Velho, H.F. and Stephany, S. and Preto, A.J. and Segatto, C.F. and Vilhena, M.T.},
  booktitle={Proceedings. 15th Symposium on Computer Architecture and High Performance Computing}, 
  title={A parallel implementation of the LTSn method for a radiative transfer problem}, 
  year={2003},
  volume={},
  number={},
  pages={116-122},
  abstract={A radiative transfer solver that implements the LTSn method was optimized and parallelized using the MPI message passing communication library. Timing and profiling information was obtained for the sequential code in order to identify performance bottlenecks. Performance tests were executed in a distributed memory parallel machine, a multicomputer based on IA-32 architecture. The radiative transfer equation was solved for a cloud test case to evaluate the parallel performance of the LTSn method. The LTSn code includes spatial discretization of the domain and Fourier decomposition of the radiances leading to independent azimuthal modes. This yields an independent radiative transfer equation for each mode that can be executed by a different processor in a parallel implementation. Speed-up results show that the parallel implementation is suitable for the used architecture.},
  keywords={},
  doi={10.1109/CAHPC.2003.1250329},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{1250321,
  author={de Carvalho, F.H. and Lins, R.D. and Quental, N.C.},
  booktitle={Proceedings. 15th Symposium on Computer Architecture and High Performance Computing}, 
  title={On the implementation of SPMD applications using Haskell/sub #/}, 
  year={2003},
  volume={},
  number={},
  pages={55-63},
  abstract={Commodities-built clusters, a low cost alternative for distributed parallel processing, brought high-performance computing to a wide range of users. However, the existing widespread tools for distributed parallel programming, such as messaging passing libraries, does not attend new software engineering requirements that have emerged due to increase in complexity of applications. Haskell/sub #/ is a parallel programming language intending to reconcile higher abstraction and modularity with scalable performance. It is demonstrated the use of Haskell/sub #/ in the programming of three SPMD benchmark programs, which have lower-level MPI implementations available.},
  keywords={},
  doi={10.1109/CAHPC.2003.1250321},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{1250330,
  author={Cucchieri, A. and Mendes, T. and Travieso, G. and Taurines, A.R.},
  booktitle={Proceedings. 15th Symposium on Computer Architecture and High Performance Computing}, 
  title={Parallel implementation of a lattice-gauge-theory code: studying quark confinement on PC clusters}, 
  year={2003},
  volume={},
  number={},
  pages={123-131},
  abstract={We consider the implementation of a parallel Monte Carlo code for high-performance simulations on PC clusters with MPI. We carry out tests of speedup and efficiency. The code is used for numerical simulations of pure SU(2) lattice gauge theory at very large lattice volumes, in order to study the infrared behavior of gluon and ghost propagators. This problem is directly related to the confinement of quarks and gluons in the physics of strong interactions.},
  keywords={},
  doi={10.1109/CAHPC.2003.1250330},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{1253606,
  author={Pop, P. and Eles, P. and Zebo Peng},
  booktitle={2003 Design, Automation and Test in Europe Conference and Exhibition}, 
  title={Schedulability analysis and optimization for the synthesis of multi-cluster distributed embedded systems}, 
  year={2003},
  volume={},
  number={},
  pages={184-189},
  abstract={We present an approach to schedulability analysis for the synthesis of multi-cluster distributed embedded systems consisting of time-triggered and event-triggered clusters, interconnected via gateways. We have also proposed a buffer size and worst case queuing delay analysis for the gateways, responsible for routing inter-cluster traffic. Optimization heuristics for the priority assignment and synthesis of bus access parameters, aimed at producing a schedulable system with minimal buffer needs, have been proposed. Extensive experiments and a real-life example show the efficiency of our approaches.},
  keywords={},
  doi={10.1109/DATE.2003.1253606},
  ISSN={1530-1591},
  month={March},}

@INPROCEEDINGS{1257637,
  author={Jinfeng Liu and Chou, P.H.},
  booktitle={ICCAD-2003. International Conference on Computer Aided Design (IEEE Cat. No.03CH37486)}, 
  title={Energy optimization of distributed embedded processors by combined data compression and functional partitioning}, 
  year={2003},
  volume={},
  number={},
  pages={201-208},
  abstract={Transmitting compressed data can reduce inter-processor communication traffic and create new opportunities for DVS (dynamic voltage scaling) in distributed embedded systems. However, data compression alone may not be effective unless coordinated with functional partitioning. This paper presents a dynamic programming technique that combines compression and functional partitioning to minimize energy on multiple voltage-scalable processors running pipelined data-regular applications under performance constraints. Our algorithm computes the optimal functional partitioning, CPU speed for each node, and their respective compression ratios. We validate the algorithm's effectiveness on a real distributed embedded system running an image processing algorithm.},
  keywords={},
  doi={10.1109/ICCAD.2003.1257637},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{1253321,
  author={Bouteiller and Lemarinier and Krawezik and Capello},
  booktitle={2003 Proceedings IEEE International Conference on Cluster Computing}, 
  title={Coordinated checkpoint versus message log for fault tolerant MPI}, 
  year={2003},
  volume={},
  number={},
  pages={242-250},
  abstract={MPI is one of the most adopted programming models for large clusters and grid deployments. However, these systems often suffer from network or node failures. This raises the issue of selecting a fault tolerance approach for MPI. Automatic and transparent ones are based on either coordinated checkpointing or message logging associated with uncoordinated checkpoint. There are many protocols, implementations and optimizations for these approaches but few results about their comparison. Coordinated checkpoint has the advantage of a very low overhead on fault free executions. In contrary a message logging protocol systematically adds a significant message transfer penalty. The drawbacks of coordinated checkpoint come from its synchronization cost at checkpoint and restart times. In this paper we implement, evaluate and compare the two kinds of protocols with a special emphasis on their respective performance according to fault frequency. The main conclusion (under our experimental conditions) is that message logging becomes relevant for a large scale cluster from one fault every hour for applications with large dataset.},
  keywords={},
  doi={10.1109/CLUSTR.2003.1253321},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{1253331,
  author={Ching and Choudhary and Wei-keng Liao and Ross and Gropp},
  booktitle={2003 Proceedings IEEE International Conference on Cluster Computing}, 
  title={Efficient structured data access in parallel file systems}, 
  year={2003},
  volume={},
  number={},
  pages={326-335},
  abstract={Parallel scientific applications store and retrieve very large, structured datasets. Directly supporting these structured accesses is an important step in providing high-performance I/O solutions for these applications. High-level interfaces such as HDF5 and Parallel netCDF provide convenient APIs for accessing structured datasets, and the MPI-IO interface also supports efficient access to structured data. However, parallel file systems do not traditionally support such access. In this work we present an implementation of structured data access support in the context of the parallel virtual file system (PVFS). We call this support "datatype I/O" because of its similarity to MPI datatypes. This support is built by using a reusable datatype-processing component from the MPICH2 MPI implementation. We describe how this component is leveraged to efficiently process structured data representations resulting from MPI-IO operations. We quantitatively assess the solution using three test applications. We also point to further optimizations in the processing path that could be leveraged for even more efficient operation.},
  keywords={},
  doi={10.1109/CLUSTR.2003.1253331},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{1254408,
  author={Goldson, D.},
  booktitle={Tenth Asia-Pacific Software Engineering Conference, 2003.}, 
  title={Extending the theory of Owicki and Gries with asynchronous message passing}, 
  year={2003},
  volume={},
  number={},
  pages={532-541},
  abstract={We describe an extension of the theory of Owicki and Gries (1976) to a programming language that supports asynchronous message passing based on unconditional send actions and conditional receive actions. The focus is on exploring the fitness of the extension for distributed program derivation. A number of experiments are reported, based on a running example problem, and with the aim of exploring design heuristics and of streamlining derivations and progress arguments.},
  keywords={},
  doi={10.1109/APSEC.2003.1254408},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{1258596,
  author={Olcer, S.},
  booktitle={GLOBECOM '03. IEEE Global Telecommunications Conference (IEEE Cat. No.03CH37489)}, 
  title={Decoder architecture for array-code-based LDPC codes}, 
  year={2003},
  volume={4},
  number={},
  pages={2046-2050 vol.4},
  abstract={We describe a decoder architecture intended for decoding array-code-based low-density parity-check (LDPC) codes using the sum-product algorithm (SPA). The advantages of the proposed architecture, as compared to the fully parallel implementation of the SPA, are: reduced memory size, avoidance of complex signal interconnect patterns, and ease of programmability to accommodate various code parameters. These advantages are derived from exploiting the well-defined structure of the parity-check matrix of array-code based LDPC codes. Sum-product decoding with modified message-passing schedules are proposed to simplify the decoder implementation further.},
  keywords={},
  doi={10.1109/GLOCOM.2003.1258596},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{1259809,
  author={Gang Yang and Xingshe Zhou and Xiaojun Wu},
  booktitle={Proceedings of the 2003 International Conference on Machine Learning and Cybernetics (IEEE Cat. No.03EX693)}, 
  title={MAM/sup 2/ : a novel mixed adaptive messaging middleware}, 
  year={2003},
  volume={3},
  number={},
  pages={1910-1914 Vol.3},
  abstract={Messaging has been widely used in large scale distributed application of bank, finance, local data center, and even military applications. Current messaging service is either subscribe-publish (SP) or point-to-point (PTP) mode. But neither modes can satisfy the requirements of these applications. This paper introduces a mixed adaptive message middleware (MAM/sup 2/), which includes advantages of both modes. MAM/sup 2/ provides flexible, adaptive, high efficiency, and routing based on content messaging service for users. MAM/sup 2/'s prototype has been implemented and it is in testing stage.},
  keywords={},
  doi={10.1109/ICMLC.2003.1259809},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{1259837,
  author={Ting-Yao Jiang and Qing-Hua Li},
  booktitle={Proceedings of the 2003 International Conference on Machine Learning and Cybernetics (IEEE Cat. No.03EX693)}, 
  title={An efficient recovery scheme for mobile computing system}, 
  year={2003},
  volume={4},
  number={},
  pages={2031-2036 Vol.4},
  abstract={It is very necessary for the mobile computing system to be equipped with the checkpointing recovery facility because of the fact that the MHs are vulnerable to the failures. Previous recovery schemes based on message logging are under the condition that exchanged messages among mobile hosts are forwarded by MSSs(m-MSS-m communication). A new recovery protocol is presented for mobile host direct to mobile host(m-m) communication wireless network in this paper. The m-m communication contributes to a less contention on the wireless network and a lower latency for message transmission than m-MSS-m. Theoretical analyses and simulation results show that the proposed approach provides higher performance in terms of fail-free overhead and recovery overhead than traditional schemes.},
  keywords={},
  doi={10.1109/ICMLC.2003.1259837},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{1282260,
  author={Jianqing Wang and Mukaide, N. and Fujiwara, O.},
  booktitle={Asia-Pacific Conference on Environmental Electromagnetics, 2003. CEEM 2003. Proceedings.}, 
  title={FDTD calculation of organ resonance characteristics in an anatomically based human model for plane-wave exposure}, 
  year={2003},
  volume={},
  number={},
  pages={126-129},
  abstract={It is well known that electromagnetic (EM) energy is absorbed inhomogeneously in the human body even for plane-wave exposure. This implies that local resonance for various individual organs may occur. In order to investigate this implication, we analyzed numerically the organ resonance characteristics in the frequency range from 30 MHz up to 3 GHz with an anatomically based high-precision human body model and a parallel finite-difference time-domain (FDTD) technique. As a result, we found that the whole-body resonance occurring around 65 MHz causes the local resonance for all the organs at the same frequency. Local resonance peculiar to each of organs was also found to occur around 900 GHz for the brain, eyes and heart, 600 MHz for the testicles, and so on.},
  keywords={},
  doi={10.1109/CEEM.2003.238647},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{1285035,
  author={Abbasfar, A. and Kung Yao},
  booktitle={2003 IEEE 58th Vehicular Technology Conference. VTC 2003-Fall (IEEE Cat. No.03CH37484)}, 
  title={An efficient and practical architecture for high speed turbo decoders}, 
  year={2003},
  volume={1},
  number={},
  pages={337-341 Vol.1},
  abstract={Turbo codes not only achieve near Shannon capacity performance, but also have decoders with modest complexity, which is crucial for implementation. So far, efficient architectures for decoding of turbo codes have been proposed that are suitable for sequential processing. A novel architecture for a very high-speed turbo decoder is presented. The method makes parallel processing feasible. The performance of this decoder is illustrated and the tradeoff between speed and efficiency is discussed. It is shown that some decoders can run faster by some order of magnitude while maintaining almost the same processing load. A new structure for the interleaver is proposed, which makes the implementation of such a decoder feasible. It has been shown that the new interleaver structure can perform as well as other good interleavers.},
  keywords={},
  doi={10.1109/VETECF.2003.1285035},
  ISSN={1090-3038},
  month={Oct},}
@INPROCEEDINGS{1285102,
  author={Hao Zhong and Tong Zhang},
  booktitle={2003 IEEE 58th Vehicular Technology Conference. VTC 2003-Fall (IEEE Cat. No.03CH37484)}, 
  title={Design of VLSI implementation-oriented LDPC codes}, 
  year={2003},
  volume={1},
  number={},
  pages={670-673 Vol.1},
  abstract={Recently, low-density parity-check (LDPC) codes have attracted much attention because of their excellent error-correcting performance and highly parallelizable decoding scheme. However, the effective VLSI implementation of an LDPC decoder remains a big challenge and is a crucial issue in determining how well we can exploit the benefits of the LDPC codes in real applications. In this paper, following the joint code and decoder design philosophy, we propose a semi-random design scheme to construct the LDPC codes that not only exhibit very good error-correcting performance but also effectively fit to partially parallel VLSI decoder implementations. The corresponding partially parallel decoder has a very regular structure and simple control mechanism. Our computer simulations show that such LDPC codes achieve very good performance comparable to their counterparts constructed in a fully random scheme, which however have little chance of fitting to partially parallel decoder implementations.},
  keywords={},
  doi={10.1109/VETECF.2003.1285102},
  ISSN={1090-3038},
  month={Oct},}
@INPROCEEDINGS{1292464,
  author={Du Zhihua and Lin Feng},
  booktitle={Fourth International Conference on Information, Communications and Signal Processing, 2003 and the Fourth Pacific Rim Conference on Multimedia. Proceedings of the 2003 Joint}, 
  title={Parallel computation for multiple sequence alignments}, 
  year={2003},
  volume={1},
  number={},
  pages={300-303 Vol.1},
  abstract={Sequence alignment is used to detect homologies between newly sequenced and existing protein/DNA families, and furthermore predict secondary and tertiary structures. Development of methods for multiple sequence alignment (MSA) is a hot topic in computational biology. This paper presents our development of a parallel MSA algorithm and its experimental results, using the message passing interface on a multi-node compute cluster. Typical sequence data of the G-protein coupled receptor family from NCBI are used for scaling tests. The experimental results are encouraging.},
  keywords={},
  doi={10.1109/ICICS.2003.1292464},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{1352380,
  author={Watabe, H. and Sang-Keun Woo and Kim, K.-M. and Kudomi, N. and Iida, H.},
  booktitle={2003 IEEE Nuclear Science Symposium. Conference Record (IEEE Cat. No.03CH37515)}, 
  title={Performance improvement of event-based motion correction for PET using a PC cluster}, 
  year={2003},
  volume={4},
  number={},
  pages={2407-2409 Vol.4},
  abstract={Head motion during PET scanning produces significant artifact or spatial resolution loss on the reconstructed image. Event-based motion correction (EBMC) technique has been developed to correct head movement during the scan incorporated with list mode acquisition of PET and an optical tracking system. In EBMC technique, each line-of-response (LOR) in the list-mode data was reoriented due to the motion data by the optical tracking system. Although EBMC technique has potential to correct head movement during PET acquisition, large size of list mode data set hampers the capability of on-line processing for the correction. In order to improve in the speed of computing time for EBMC, we implemented EBMC on a Beowulf PC cluster consisting of 7 PCs (24 GHz Xeon for a master node and 1.4 GHz PentiumIII for slave nodes) connecting each other through Gbit Ethernet. MPI (Message Passing Interface) protocol was utilized for parallelizing the task of EBMC. The performance of the PC cluster was evaluated using list-mode data and head motion data acquired by ECAT EXACT HR+ (CTI/Siemens) PET scanner and POLARIS (Northern Digital) optical tracking system. The six list-mode data sets (file sizes are from 161 to 253 Mbytes) were corrected for motion by EBMC technique on a single PC and the PC cluster. The PC cluster was 5.2 times faster than the single PC to perform the motion correction. The PC cluster remarkably improves the performance of EBMC with low cost.},
  keywords={},
  doi={10.1109/NSSMIC.2003.1352380},
  ISSN={1082-3654},
  month={Oct},}
@INBOOK{6277568,
  author={Reed, Daniel A.},
  booktitle={Scalable Input/Output: Achieving System Balance}, 
  title={CLIP: A Checkpointing Tool for Message Passing Parallel Programs}, 
  year={2003},
  volume={},
  number={},
  pages={181-199},
  abstract={This chapter contains sections titled: Intel Paragon, CLIP Programming Interface, The Design of CLIP, Performance, Related Work, Conclusions, Acknowledgments},
  keywords={},
  doi={},
  ISSN={},
  publisher={MIT Press},
  isbn={},
  url={https://ieeexplore.ieee.org/document/6277568},}
@ARTICLE{1268994,
  author={Liu, J. and Balasubramanian Chandrasekaran and Yu, W. and Wu, J. and Buntinas, D. and Sushmitha Kini and Panda, D.K. and Wyckoff, P.},
  journal={IEEE Micro}, 
  title={Microbenchmark performance comparison of high-speed cluster interconnects}, 
  year={2004},
  volume={24},
  number={1},
  pages={42-51},
  abstract={Today's distributed and high-performance applications require high computational power and high communication performance. Recently, the computational power of commodity PCs has doubled about every 18 months. At the same time, network interconnects that provide very low latency and very high bandwidth are also emerging. This is a promising trend in building high-performance computing environments by clustering - combining the computational power of commodity PCs with the communication performance of high-speed network interconnects. There are several network interconnects that provide low latency and high bandwidth. Traditionally, researchers have used simple microbenchmarks, such as latency and bandwidth tests, to characterize a network interconnects communication performance. Later, they proposed more sophisticated models such as LogP. However, these tests and models focus on general parallel computing systems and do not address many features present in these emerging commercial interconnects. Another way to evaluate different network interconnects is to use real-world applications. However, real applications usually run on top of a middleware layer such as the message passing interface (MPI). Our results show that to gain more insight into the performance characteristics of these interconnects, it is important to go beyond simple tests such as those for latency and bandwidth. In future, we plan to expand our microbenchmark suite to include more tests and more interconnects.},
  keywords={},
  doi={10.1109/MM.2004.1268994},
  ISSN={1937-4143},
  month={Jan},}
@INPROCEEDINGS{1271422,
  author={Avresky, D.R. and Varoglu, Y. and Marinov, M.},
  booktitle={12th Euromicro Conference on Parallel, Distributed and Network-Based Processing, 2004. Proceedings.}, 
  title={Dynamically scaling system area networks}, 
  year={2004},
  volume={},
  number={},
  pages={22-27},
  abstract={New network components joining running system area networks can require communication path reconfigurations. We present a novel efficient algorithm to dynamically reconfigure the network with an arbitrary topology, for the case of newly joining node. We define a restoration graph which overcomes the restriction of the up/down algorithm. We obtain an upper bound in terms of the number of messages generated in order to reconfigure the network. The termination and the liveness properties of the proposed algorithm are proven. The validation and performance improvement of the system area network (SAN) with the proposed algorithm in comparison to the up/down algorithm is presented.},
  keywords={},
  doi={10.1109/EMPDP.2004.1271422},
  ISSN={1066-6192},
  month={Feb},}
@INPROCEEDINGS{1271437,
  author={Borkowski, J.},
  booktitle={12th Euromicro Conference on Parallel, Distributed and Network-Based Processing, 2004. Proceedings.}, 
  title={Strongly consistent global state detection for on-line control of distributed applications}, 
  year={2004},
  volume={},
  number={},
  pages={126-133},
  abstract={Global states can be used for distributed/parallel application monitoring and control. Strongly consistent global states (SCGS) are especially well suited for on-line controlling. Existing SCGS detecting algorithms work with process local states. They must wait for state terminations before complete states can be taken into account. Because of that the global states seen by a monitor always belong to the past. We present an algorithm, which works with unterminated local states. This approach lets the monitor detect SCGS sooner: currently lasting global states can be perceived promptly after they started. Application control based on SCGS detection should react quicker to arising situations when using the new algorithm. The quick reactions contribute to a better parallel/distributed application performance. Simulation tests confirm these suppositions. Our solution utilizes bounded maximal message transfer time. It is compared with another method, which employs frequent confirmation messages. While both methods can lead to similar application performance, our approach induces a few times lower both monitor load and network traffic.},
  keywords={},
  doi={10.1109/EMPDP.2004.1271437},
  ISSN={1066-6192},
  month={Feb},}
@INPROCEEDINGS{1271465,
  author={Bahi, J. and Domas, S. and Mazouzi, K.},
  booktitle={12th Euromicro Conference on Parallel, Distributed and Network-Based Processing, 2004. Proceedings.}, 
  title={Jace: a Java environment for distributed asynchronous iterative computations}, 
  year={2004},
  volume={},
  number={},
  pages={350-357},
  abstract={Distributed computing over large networks often suffers poor performances due to architecture heterogeneity and synchronization delays. This is the case of classical computing libraries which are dedicated to parallel machines or clusters. To achieve a better efficiency on multisites heterogeneous networks, one can use asynchronous algorithms which are less sensible to communication delays and loss of messages. Implementing such algorithms with classical MPI versions is not the best choice. We propose Jace, a Java environment dedicated to distributed asynchronous computations, and more especially to asynchronous iterations-asynchronous communications algorithms. It contains all facilities to build a parallel virtual machine and to implement computing tasks in a message passing style. Communications have a special semantic adapted to asynchronism. First tests on a simple Jacobi algorithm clearly show the benefits of our environment to compute on a multisite heterogeneous network, that is, the grid.},
  keywords={},
  doi={10.1109/EMPDP.2004.1271465},
  ISSN={1066-6192},
  month={Feb},}
@INPROCEEDINGS{1276554,
  author={Jicchiang Tsai},
  booktitle={10th IEEE Pacific Rim International Symposium on Dependable Computing, 2004. Proceedings.}, 
  title={Systematic comparisons of RDT communication-induced checkpointing protocols}, 
  year={2004},
  volume={},
  number={},
  pages={66-75},
  abstract={Rollback-dependency trackability (RDT) is a property stating that all rollback dependencies between local checkpoints are online trackable by using a transitive dependency vector. Since the RDT property was introduced, many communication-induced checkpointing protocols satisfying such a property have been proposed in the literature. Most protocols can be classified as three families, PCM family, EPSCM family and PMM family, according to their underlying RDT characterizations. Up to now, several theoretical analyses on comparing the performance of RDT protocols were addressed, but simulation studies on this topic are rare and not comprehensive. We present a simulation study for comparing RDT protocols systematically. The simulation is carried out in different computational environments. We will not only verify the results from existing theoretical analyses, but also explore the impact of optimizations on protocols. Our results can provide guidelines for understanding the efficiency of RDT protocols.},
  keywords={},
  doi={10.1109/PRDC.2004.1276554},
  ISSN={},
  month={March},}
@INPROCEEDINGS{1276596,
  author={Jin-Min Yang and Da-Fang Zhang and Zheng Qin and Xue-Dong Yang},
  booktitle={10th IEEE Pacific Rim International Symposium on Dependable Computing, 2004. Proceedings.}, 
  title={WINDAR: a multithreaded rollback-recovery toolkit on windows}, 
  year={2004},
  volume={},
  number={},
  pages={395-400},
  abstract={We describe the design and implementation of WINDAR, an object-oriented toolkit for transparent rollback-recovery of distributed applications running on Windows platform. In WINDAR, the workloads of a process are multithreaded, exploiting effectively processor execution resources to improve execution efficiency. In addition, WINDAR's unified framework for various rollback recovery protocols enables dynamic protocol configuration to adapt itself to the need of recovery-oriented computing (ROC) and distributed computations in Internet environment. WINDAR was evaluated using three benchmarks. It is observed that multithreading is an effective approach to improve the performance of message logging protocols, especially for pessimistic message logging. In our experiment, the overhead ratio of pessimistic message logging was reduced to the same magnitude as that of the optimistic message logging for three benchmarks.},
  keywords={},
  doi={10.1109/PRDC.2004.1276596},
  ISSN={},
  month={March},}
@INPROCEEDINGS{1300419,
  author={Ramos, C.F.F.},
  booktitle={Second IEEE Workshop on Software Technologies for Future Embedded and Ubiquitous Systems, 2004. Proceedings.}, 
  title={Methodology for analysis and design of systems}, 
  year={2004},
  volume={},
  number={},
  pages={80-84},
  abstract={In this article is presented a formal methodology to develop software solutions based on agents. The proposed methodology is based on Beliefs-Intentions agent architecture and uses the temporal logic alphabet and axioms to model the system. The methodology details explicitly the multiagent construction phases from the specification to the verification. Contributions of this article are: first, propose an analysis and design methodology, which use interaction as support for developing distributed complex application. Second, propose a formal object language in order to specify in a natural and comprehensive way the multiagent characteristics and properties, and also validate this specification.},
  keywords={},
  doi={10.1109/WSTFES.2004.1300419},
  ISSN={},
  month={May},}
@INPROCEEDINGS{1300471,
  author={Jiannong Cao and Yifeng Chen and Kang Zhang and Yanxiang He},
  booktitle={7th International Symposium on Parallel Architectures, Algorithms and Networks, 2004. Proceedings.}, 
  title={Checkpointing in hybrid distributed systems}, 
  year={2004},
  volume={},
  number={},
  pages={136-141},
  abstract={To provide fault tolerance to computer systems suffering from transient faults, checkpointing and rollback recovery is widely-used. Among other techniques, two primary checkpointing schemes have been proposed: independent and coordinated schemes. However, most existing work addresses only the need to employ a single checkpointing and rollback recovery scheme to a target system. In this paper, issues are discussed and a new algorithm is developed to address the need of integrating independent and coordinated checkpointing schemes for applications running in a hybrid distributed environment containing multiple heterogeneous subsystems. The required changes to the original checkpointing schemes for each subsystem and the overall prevented unnecessary rollbacks for the integrated system are presented. Also described is an algorithm for collecting garbage checkpoints in the combined hybrid system.},
  keywords={},
  doi={10.1109/ISPAN.2004.1300471},
  ISSN={1087-4089},
  month={May},}
@ARTICLE{1302302,
  author={Sason, I. and Urbanke, R.},
  journal={IEEE Transactions on Information Theory}, 
  title={Complexity versus performance of capacity-achieving irregular repeat-accumulate codes on the binary erasure channel}, 
  year={2004},
  volume={50},
  number={6},
  pages={1247-1256},
  abstract={We derive upper and lower bounds on the encoding and decoding complexity of two capacity-achieving ensembles of irregular repeat-accumulate (IRA1 and IRA2) codes on the binary erasure channel (BEC). These bounds are expressed in terms of the gap between the channel capacity and the rate of a typical code from this ensemble for which reliable communications is achievable under message-passing iterative (MPI) decoding. The complexity of the ensemble of IRA1 codes grows like the negative logarithm of the gap to capacity. On the other hand, the complexity of the ensemble of IRA2 codes with any choice of the degree distribution grows at least like the inverse square root of the gap to capacity, and at most like the inverse of the gap to capacity.},
  keywords={},
  doi={10.1109/TIT.2004.828101},
  ISSN={1557-9654},
  month={June},}
@INPROCEEDINGS{1301287,
  author={Kalantery, N.},
  booktitle={18th Workshop on Parallel and Distributed Simulation, 2004. PADS 2004.}, 
  title={Time warp - connection oriented}, 
  year={2004},
  volume={},
  number={},
  pages={71-77},
  abstract={Conservative parallel discrete event simulation takes a connection-oriented approach to inter-process communication. Conservative processes modeling physical entities are connected via channels that represent physical links in the target system. By contrast, optimistic strategy and its implementation in time warp machine, take a connectionless approach where a process can communicate freely with any other process without prior connection. This paper presents the case for a connection-oriented optimistic approach and provides a data structure for the event set of time warp processes that significantly reduce the cost of event scheduling and cancellation under connection-oriented operation. Detailed description of the proposed implementation is given and performance of the structure in forward event scheduling and backward event cancellation is tested and the results are discussed.},
  keywords={},
  doi={10.1109/PADS.2004.1301287},
  ISSN={1087-4097},
  month={May},}
@INPROCEEDINGS{1301296,
  author={Park, A. and Fujimoto, R.M. and Perumalla, K.S.},
  booktitle={18th Workshop on Parallel and Distributed Simulation, 2004. PADS 2004.}, 
  title={Conservative synchronization of large-scale network simulations}, 
  year={2004},
  volume={},
  number={},
  pages={153-161},
  abstract={Parallel discrete event simulation techniques have enabled the realization of large-scale models of communication networks containing millions of end hosts and routers. However, the performance of these parallel simulators could be severely degraded if proper synchronization algorithms are not utilized. In this paper, we compare the performance and scalability of synchronous and asynchronous algorithms for conservative parallel network simulation. We develop an analytical model to evaluate the efficiency and scalability of certain variations of the well-known null message algorithm, and present experimental data to verify the accuracy of this model. This analysis and initial performance measurements on parallel machines containing hundreds of processors suggest that for scenarios simulating scaled network models with constant number of input and output channels per logical process, an optimized null message algorithm offers better scalability than efficient global reduction based synchronous protocols.},
  keywords={},
  doi={10.1109/PADS.2004.1301296},
  ISSN={1087-4097},
  month={May},}
@INPROCEEDINGS{1302905,
  author={Ayguade, E. and Gonzalez, M. and Martorell, X. and Jost, G.},
  booktitle={18th International Parallel and Distributed Processing Symposium, 2004. Proceedings.}, 
  title={Employing nested OpenMP for the parallelization of multi-zone computational fluid dynamics applications}, 
  year={2004},
  volume={},
  number={},
  pages={6-},
  abstract={Summary form only given. We describe the parallelization of the multizone code versions of the NAS parallel benchmarks employing multilevel OpenMP parallelism. For our study we use the NanosCompiler, which supports nesting of OpenMP directives and provides clauses to control the grouping of threads, load balancing, and synchronization. We report the benchmark results, compare the timings with those of different hybrid parallelization paradigms and discuss OpenMP implementation issues which effect the performance of multilevel parallel applications.},
  keywords={},
  doi={10.1109/IPDPS.2004.1302905},
  ISSN={},
  month={April},}
@INPROCEEDINGS{1302906,
  author={Jin, H. and Van der Wijngaart, R.F.},
  booktitle={18th International Parallel and Distributed Processing Symposium, 2004. Proceedings.}, 
  title={Performance characteristics of the multi-zone NAS parallel benchmarks}, 
  year={2004},
  volume={},
  number={},
  pages={6-},
  abstract={Summary form only given. We describe a new suite of computational benchmarks that models applications featuring multiple levels of parallelism. Such parallelism is often available in realistic flow computations on systems of meshes, but had not previously been captured in benchmarks. The new suite, named NPB (NAS parallel benchmarks) multizone, is extended from the NPB suite, and involves solving the application benchmarks LU, BT and SP on collections of loosely coupled discretization meshes. The solutions on the meshes are updated independently, but after each time step they exchange boundary value information. This strategy provides relatively easily exploitable coarse-grain parallelism between meshes. Three reference implementations are available: one serial, one hybrid using the message passing interface (MPI) and OpenMP, and another hybrid using a shared memory multilevel programming model (SMP+OpenMP). We examine the effectiveness of hybrid parallelization paradigms in these implementations on three different parallel computers. We also use an empirical formula to investigate the performance characteristics of the hybrid parallel codes.},
  keywords={},
  doi={10.1109/IPDPS.2004.1302906},
  ISSN={},
  month={April},}
@INPROCEEDINGS{1302919,
  author={Drosinos, N. and Koziris, N.},
  booktitle={18th International Parallel and Distributed Processing Symposium, 2004. Proceedings.}, 
  title={Performance comparison of pure MPI vs hybrid MPI-OpenMP parallelization models on SMP clusters}, 
  year={2004},
  volume={},
  number={},
  pages={15-},
  abstract={Summary form only given. We compare the performance of three programming paradigms for the parallelization of nested loop algorithms onto SMP clusters. More specifically, we propose three alternative models for tiled nested loop algorithms, namely a pure message passing paradigm, as well as two hybrid ones, that implement communication both through message passing and shared memory access. The hybrid models adopt an advanced hyperplane scheduling scheme, that allows both for minimal thread synchronization, as well as for pipelined execution with overlapping of computation and communication phases. We focus on the experimental evaluation of all three models, and test their performance against several iteration spaces and parallelization grains with the aid of a typical microkernel benchmark. We conclude that the hybrid models can in some cases be more beneficial compared to the monolithic pure message passing model, as they exploit better the configuration characteristics of an hierarchical parallel platform, such as an SMP cluster.},
  keywords={},
  doi={10.1109/IPDPS.2004.1302919},
  ISSN={},
  month={April},}
@INPROCEEDINGS{1302920,
  author={Aulwes, R.T. and Daniel, D.J. and Desai, N.N. and Graham, R.L. and Risinger, L.D. and Taylor, M.A. and Woodall, T.S. and Sukalski, M.W.},
  booktitle={18th International Parallel and Distributed Processing Symposium, 2004. Proceedings.}, 
  title={Architecture of LA-MPI, a network-fault-tolerant MPI}, 
  year={2004},
  volume={},
  number={},
  pages={15-},
  abstract={Summary form only given. We discuss the unique architectural elements of the Los Alamos message passing interface (LA-MPI), a high-performance, network-fault-tolerant, thread-safe MPI library. LA-MPI is designed for use on terascale clusters which are inherently unreliable due to their sheer number of system components and trade-offs between cost and performance. We examine in detail the design concepts used to implement LA-MPI. These include reliability features, such as application-level checksumming, message retransmission, and automatic message rerouting. Other key performance enhancing features, such as concurrent message routing over multiple, diverse network adapters and protocols, and communication-specific optimizations (e.g., shared memory) are examined.},
  keywords={},
  doi={10.1109/IPDPS.2004.1302920},
  ISSN={},
  month={April},}
@INPROCEEDINGS{1302912,
  author={Liu, J. and Mamidala, A.R. and Panda, D.K.},
  booktitle={18th International Parallel and Distributed Processing Symposium, 2004. Proceedings.}, 
  title={Fast and scalable MPI-level broadcast using InfiniBand's hardware multicast support}, 
  year={2004},
  volume={},
  number={},
  pages={10-},
  abstract={Summary form only given. Modern high performance applications require efficient and scalable collective communication operations. Currently, most collective operations are implemented based on point-to-point operations. We propose to use hardware multicast in InfiniBand to design fast and scalable broadcast operations in MPl. InfiniBand supports multicast with unreliable datagram (UD) transport service. This makes it hard to be directly used by an upper layer such as MPl. To bridge the semantic gap between MPI/spl I.bar/Bcast and InfiniBand hardware multicast, we have designed and implemented a substrate on top of InfiniBand which provides functionalities such as reliability, inorder delivery and large message handling. By using a sliding-window based design, we improve MPI/spl I.bar/Bcast latency by removing most of the overhead in the substrate out of the communication critical path. By using optimizations such as a new coroot based scheme and delayed ACK, we can further balance and reduce the overhead. We have also addressed many detailed design issues such as buffer management, efficient handling of out-of-order and duplicate messages, timeout and retransmission, flow control and RDMA based ACK communication. Our performance evaluation shows that in an 8 node cluster testbed, hardware multicast based designs can improve MPl broadcast latency up to 58% and broadcast throughput up to 112%. The proposed solutions are also much more tolerant to process skew compared with the current point-to-point based implementation. We have also developed analytical model for our multicast based schemes and validated them with experimental numbers. Our analytical model shows that with the new designs, one can achieve MPl broadcast latency of small messages with 20.0/spl mu/s and of one MTU size message (around 1836 bytes of data payload) with 40.0/spl mu/s in a 1024 node cluster.},
  keywords={},
  doi={10.1109/IPDPS.2004.1302912},
  ISSN={},
  month={April},}
@INPROCEEDINGS{1302943,
  author={Tipparaju, V. and Santhanaraman, G. and Nieplocha, J. and Panda, O.K.},
  booktitle={18th International Parallel and Distributed Processing Symposium, 2004. Proceedings.}, 
  title={Host-assisted zero-copy remote memory access communication on InfiniBand}, 
  year={2004},
  volume={},
  number={},
  pages={31-},
  abstract={Summary form only given. The remote memory access (RMA) is an increasingly important communication model due to its excellent potential for overlapping communication and computations and achieving high performance on modern networks with RDMA hardware such as Infiniband. RMA plays a vital role in supporting the emerging global address space programming models. We describe how RMA can be implemented efficiently over InfiniBand. The capabilities not offered directly by the Infiniband verb layer can be implemented efficiently using the novel host-assisted approach while achieving zero-copy communication and supporting an excellent overlap of computation with communication. For contiguous data we are able to achieve a small message latency of 6/spl mu/s and a peak bandwidth of 830 MB/s for 'put' and a small message latency of 12/spl mu/s and a peak bandwidth of 765 Megabytes for 'get'. These numbers are almost as good as the performance of the native VAPI layer. For the noncontiguous data, the host assisted approach can deliver bandwidth close to that for the contiguous data. We also demonstrate the superior tolerance of host-assisted data-transfer operations to CPU intensive tasks due to minimum host involvement in our approach as compared to the traditional host-based approach. Our implementation also supports a very high degree of overlap of computation and communication. 99% overlap for contiguous and up to 95% for noncontiguous in case of large message sizes were achieved. The NAS MG and matrix multiplication benchmarks were used to validate effectiveness of our approach, and demonstrated excellent overall performance.},
  keywords={},
  doi={10.1109/IPDPS.2004.1302943},
  ISSN={},
  month={April},}
@INPROCEEDINGS{1302962,
  author={Donninger, C. and Kure, A. and Lorenz, U.},
  booktitle={18th International Parallel and Distributed Processing Symposium, 2004. Proceedings.}, 
  title={Parallel Brutus: the first distributed, FPGA accelerated chess program}, 
  year={2004},
  volume={},
  number={},
  pages={44-},
  abstract={Summary form only given. As FPGA technology has reached maturity such that complex designs are possible, the border between hardware and software has vanished. It is now possible to develop fine grained parallel applications without long-lasting chip design cycles. Simultaneously, by the help of message passing libraries like MPI it is easy to write coarse grained parallel applications. The chess program Brutus is a high level application, which profits from both worlds. When playing board games like chess, checkers, othello etc., computers use game tree search algorithms to evaluate a position. The most spectacular success of a game playing program so far, has been the victory of the chess machine 'Deep Blue' vs. G. Kasparov, the best human chess player in the world at that time. The world has now reached a point such that a chess program can not only win one match against a human top player, but they are just getting stronger than the best human players. We describe the design philosophy, general architecture and performance of the chess program Brutus, which has just won an International Grandmaster Tournament with seven wins and four draws. Brutus is split up into a hardware and software engine. The hardware (FPGA simulated hardware) calculates the time critical part of the search tree near the leaves. The part near the root is done by software, because it is much easier to to develop sophisticated algorithms. The FPGA cards allow the implementation of sophisticated chess knowledge without decreasing the computational speed. Thus, Brutus follows its famous predecessors Belle and Deep Blue.},
  keywords={},
  doi={10.1109/IPDPS.2004.1302962},
  ISSN={},
  month={April},}
@INPROCEEDINGS{1303014,
  author={Pakin, S.},
  booktitle={18th International Parallel and Distributed Processing Symposium, 2004. Proceedings.}, 
  title={CONCEPTUAL: a network correctness and performance testing language}, 
  year={2004},
  volume={},
  number={},
  pages={79-},
  abstract={Summary form only given. We introduce a new, domain-specific specification language called CONCEPTUAL. CONCEPTUAL enables the expression of sophisticated communication benchmarks and network validation tests in comparatively few lines of code. Besides helping programmers save time writing and debugging code, CONCEPTUAL addresses the important-but largely unrecognized-problem of benchmark opacity. Benchmark opacity refers to the current impracticality of presenting performance measurements in a manner that promotes reproducibility and independent evaluation of the results. For example, stating that a performance graph was produced by a "bandwidth" test says nothing about whether that test measures the data rate during a round-trip transmission or the average data rate over a number of back-to-back unidirectional messages; whether the benchmark preregisters buffers, sends warm-up messages, and/or preposts asynchronous receives before starting the clock; how many runs were performed and whether these were aggregated by taking the mean, median, or maximum; or, even whether a data unit such as "MB/s" indicates 10/sup 6/ or 2/sup 20/ bytes per second. Because CONCEPTUAL programs are terse, a benchmark's complete source code can be listed alongside performance results, making explicit all of the design decisions that went into the benchmark program. Because CONCEPTUAL's grammar is English-like, CONCEPTUAL programs can easily be understood by nonexperts. And because CONCEPTUAL is a high-level language, it can target a variety of messaging layers and networks, enabling fair and accurate performance comparisons.},
  keywords={},
  doi={10.1109/IPDPS.2004.1303014},
  ISSN={},
  month={April},}
@INPROCEEDINGS{1303148,
  author={Su, J. and Yelick, K.},
  booktitle={18th International Parallel and Distributed Processing Symposium, 2004. Proceedings.}, 
  title={Array prefetching for irregular array accesses in Titanium}, 
  year={2004},
  volume={},
  number={},
  pages={158-},
  abstract={Summary form only given. Compiling irregular applications, such as sparse matrix vector multiply and particle/mesh methods in a SPMD parallel language is a challenging problem. These applications contain irregular array accesses, for which the array access pattern is not known until runtime. Numerous research projects have approached this problem under the inspector executor paradigm in the last 15 years. The value added by the work described in this paper is in using performance modeling to choose the best data communication method in the inspector executor model. We explore our ideas in a compiler for Titanium, a dialect of Java designed for high performance computing. For a sparse matrix vector multiply benchmark, experimental results show that the optimized Titanium code has comparable performance to C code with MPI using the Aztec library.},
  keywords={},
  doi={10.1109/IPDPS.2004.1303148},
  ISSN={},
  month={April},}
@INPROCEEDINGS{1303193,
  author={Liu, J. and Panda, D.K.},
  booktitle={18th International Parallel and Distributed Processing Symposium, 2004. Proceedings.}, 
  title={Implementing efficient and scalable flow control schemes in MPI over InfiniBand}, 
  year={2004},
  volume={},
  number={},
  pages={183-},
  abstract={Summary form only given. We present a detailed study of how to design efficient and scalable flow control mechanisms in MPI over the InfiniBand architecture. Two of the central issues inflow control are performance and scalability in terms of buffer usage. We propose three different flow control schemes (hardware-based, user-level static and user-level dynamic) and describe their respective design issues. We have implemented all three schemes in our MPI implementation over InfiniBand and conducted performance evaluation using both microbenchmarks and the NAS parallel benchmarks. Our performance analysis shows that in our testbed, most NAS applications only require a very small number of preposted buffers for every connection to achieve good performance. We also show that the user-level dynamic scheme can achieve both performance and buffer efficiency by adapting itself according to the application communication pattern. These results have significant impact in designing large-scale clusters (in the order of 1,000 to 10,000 nodes) with InfiniBand.},
  keywords={},
  doi={10.1109/IPDPS.2004.1303193},
  ISSN={},
  month={April},}
@INPROCEEDINGS{1303192,
  author={Brightwell, R. and Underwood, K.D.},
  booktitle={18th International Parallel and Distributed Processing Symposium, 2004. Proceedings.}, 
  title={An analysis of NIC resource usage for offloading MPI}, 
  year={2004},
  volume={},
  number={},
  pages={183-},
  abstract={Summary form only given. Modern cluster interconnection networks rely on processing on the network interface to deliver higher bandwidth and lower latency than what could be achieved otherwise. These processors are relatively slow, but they provide adequate capabilities to accelerate some portion of the protocol stack in a cluster computing environment. This offload capability is conceptually appealing, but the standard evaluation of NIC-based protocol implementations relies on simplistic microbenchmarks that create idealized usage scenarios. We evaluate characteristics of MPI usage scenarios using application benchmarks to help define the parameter space that protocol offload implementations should target. Specifically, we analyze characteristics that we expect to have an impact on NIC resource allocation and management strategies, including the length of the MPI posted receive and unexpected message queues, the number of entries in these queues that are examined for a typical operation, and the number of unexpected and expected messages.},
  keywords={},
  doi={10.1109/IPDPS.2004.1303192},
  ISSN={},
  month={April},}
@INPROCEEDINGS{1303238,
  author={Natchev, N. and Avresky, D.},
  booktitle={18th International Parallel and Distributed Processing Symposium, 2004. Proceedings.}, 
  title={Validation of NetRec - a dynamic reconfiguration algorithm for irregular topologies in presence of multiple failures}, 
  year={2004},
  volume={},
  number={},
  pages={209-},
  abstract={Summary form only given. Component failures in high-speed local and system area networks can result in significant topological changes. In such cases, a network reconfiguration algorithm is executed to restore the connectivity. Most of the current networks use either static reconfiguration algorithms or stop the user traffic to prevent cyclic dependencies in the routing tables. The goal is to validate an extension of the dynamic reconfiguration algorithm NetRec, which was previously published by the authors. The extensions is designed to increase the network availability in the presence of multiple link and node failures. It updates the routing tables asynchronously and doesn't require any global knowledge about the network topology. Certain phases of NetRec are executed in parallel, thus reducing the reconfiguration time. We present results from validation of the algorithm in a distributed network testbed, based on the MPI 1.2 features for building virtual topologies.},
  keywords={},
  doi={10.1109/IPDPS.2004.1303238},
  ISSN={},
  month={April},}
@INPROCEEDINGS{1303244,
  author={Chakravorty, S. and Kale, L.V.},
  booktitle={18th International Parallel and Distributed Processing Symposium, 2004. Proceedings.}, 
  title={A fault tolerant protocol for massively parallel systems}, 
  year={2004},
  volume={},
  number={},
  pages={212-},
  abstract={Summary form only given. As parallel machines grow larger, the mean time between failure shrinks. With the planned machines of near future, therefore, fault tolerance will become an important issue. The traditional method of dealing with faults is to checkpoint the entire application periodically and to start from the last checkpoint. However, such a strategy wastes resources by requiring all the processors to revert to an earlier state, whereas only one processor has lost its current state. We present a scheme for fault tolerance that aims at low overhead on the forward path (i.e. when there are no failures) and a fast recovery from faults, without wasting computation done by processors that have not faulted. The scheme does not require any individual component to be fault-free. We present the basic scheme and performance data on small clusters. Since it is based on Charm++ and Adaptive MPI, where each processor houses several virtual processors, the scheme has potential to reduce fault recovery time significantly, by migrating the recovering virtual processors.},
  keywords={},
  doi={10.1109/IPDPS.2004.1303244},
  ISSN={},
  month={April},}
@INPROCEEDINGS{1303269,
  author={Guo, M.},
  booktitle={18th International Parallel and Distributed Processing Symposium, 2004. Proceedings.}, 
  title={Automatic parallelization and optimization for irregular scientific applications}, 
  year={2004},
  volume={},
  number={},
  pages={228-},
  abstract={Summary form only given. Some automatic parallelization and optimization techniques for irregular scientific computing are proposed. These techniques include communication cost reduction for irregular loop partitioning, interprocedural optimization techniques for communication preprocessing when the irregular code has the procedure call, global vs. local indirection arrays remapping methods, and OpenMP directive extension for irregular computing.},
  keywords={},
  doi={10.1109/IPDPS.2004.1303269},
  ISSN={},
  month={April},}
@INPROCEEDINGS{1303274,
  author={Ono, M. and Higaki, H.},
  booktitle={18th International Parallel and Distributed Processing Symposium, 2004. Proceedings.}, 
  title={Hybrid checkpoint protocol for cell-dependent infrastructured networks}, 
  year={2004},
  volume={},
  number={},
  pages={230-},
  abstract={Summary form only given. For supporting mission-critical applications in a mobile network system, hybrid checkpointing has been proposed. In a recent mobile network, wireless LAN protocols such as IEEE 802.11 and HIPERLAN are getting popular and communication with mobile computers is realized by using Mobile IP in the Internet. We propose a novel hybrid checkpoint protocol. Here, message logging for mobile computers is achieved based on broadcast property of wireless LAN protocols. In addition, by extending Mobile IP, network overload in recovery is avoided. For both checkpointing and recovery in the proposed protocol, all required information is piggied back to messages. That is, no additional message is required.},
  keywords={},
  doi={10.1109/IPDPS.2004.1303274},
  ISSN={},
  month={April},}
@INPROCEEDINGS{1303309,
  author={Grove, D.A. and Coddington, P.D.},
  booktitle={18th International Parallel and Distributed Processing Symposium, 2004. Proceedings.}, 
  title={Communication benchmarking and performance modelling of MPI programs on cluster computers}, 
  year={2004},
  volume={},
  number={},
  pages={249-},
  abstract={Summary form only given. We give an overview of two related tools that we have developed to provide more accurate measurement and modelling of the performance of message passing programs and communications on distributed memory parallel computers. MPIBench uses a very precise, globally synchronised clock to measure the performance of MPI communication routines, and can generate probability distributions of communication times, not just the average values produced by other MPI benchmarks. This allows useful insights into MPI communications performance of parallel computers, particularly the effects of network contention. PEVPM provides a simple, fast and accurate technique for performance modelling and prediction of message-passing parallel programs. It uses a virtual parallel machine to simulate the execution of the parallel program. The effects of network contention can be accurately modelled by sampling from the probability distributions generated by MPIBench. These tools are particularly useful on Beowulf clusters with commodity Ethernet networks, where relatively high latencies, network congestion and TCP problems can significantly affect communication performance, and can be difficult to model accurately using other tools. Experiments with example parallel programs demonstrate that PEVPM gives accurate performance predictions on Beowulf clusters. We also show that modelling communication performance using average times rather than sampling from probability distributions can give misleading results, particularly for a large number of processors.},
  keywords={},
  doi={10.1109/IPDPS.2004.1303309},
  ISSN={},
  month={April},}
@INPROCEEDINGS{1303311,
  author={Celebioglu, O. and Saify, A. and Leng, T. and Hsieh, J. and Mashayekhi, V. and Rooholamini, R.},
  booktitle={18th International Parallel and Distributed Processing Symposium, 2004. Proceedings.}, 
  title={The performance impact of computational efficiency on HPC clusters with hyper-threading technology}, 
  year={2004},
  volume={},
  number={},
  pages={250-},
  abstract={Summary form only given. The effect of Intel/spl reg/ hyper-threading (HT) technology on a system's performance varies according to the characteristics of the application running on the system and the configuration of the system. High performance computing (HPC) clusters introduce additional variables, such as the math libraries used in solving linear algebra equations that can affect the performance of scientific and engineering applications in particular. We study the effect of HT on MPI-based applications by varying the math library. We configure an Intel-based HPC cluster and used the High Performance Linpack (HPL) benchmark to study the performance characteristics without changing hardware or communication parameters, but by linking the application with different math libraries. What we have found is that, even though the application or hardware parameters remain the same, HT may help or hinder the overall performance of the cluster depending on the computational efficiency of the mathematical functions.},
  keywords={},
  doi={10.1109/IPDPS.2004.1303311},
  ISSN={},
  month={April},}
@ARTICLE{1304967,
  author={Yanni Chen and Parhi, K.K.},
  journal={IEEE Transactions on Circuits and Systems I: Regular Papers}, 
  title={Overlapped message passing for quasi-cyclic low-density parity check codes}, 
  year={2004},
  volume={51},
  number={6},
  pages={1106-1113},
  abstract={In this paper, a systematic approach is proposed to develop a high throughput decoder for quasi-cyclic low-density parity check (LDPC) codes, whose parity check matrix is constructed by circularly shifted identity matrices. Based on the properties of quasi-cyclic LDPC codes, the two stages of belief propagation decoding algorithm, namely, check node update and variable node update, could be overlapped and thus the overall decoding latency is reduced. To avoid the memory access conflict, the maximum concurrency of the two stages is explored by a novel scheduling algorithm. Consequently, the decoding throughput could be increased by about twice assuming dual-port memory is available.},
  keywords={},
  doi={10.1109/TCSI.2004.826194},
  ISSN={1558-0806},
  month={June},}
@INPROCEEDINGS{1309092,
  author={Huaxia Xia and Dail, H. and Casanova, H. and Chien, A.A.},
  booktitle={Proceedings of the Second International Workshop on Challenges of Large Applications in Distributed Environments, 2004. CLADE 2004.}, 
  title={The MicroGrid: using online simulation to predict application performance in diverse grid network environments}, 
  year={2004},
  volume={},
  number={},
  pages={52-61},
  abstract={Improvements in networking and middleware technology are enabling large-scale grids that aggregate resources over wide-area networks to support applications at unprecedented levels of scale and performance. Unfortunately, existing middleware and tools provide little information to users as to the suitability of a given grid topology for a specific grid application. Instead, users generally use ad-hoc performance models to evaluate mappings of their applications to resource and network topologies. Grid application behavior alone is complex, and adding resource and network behavior makes the situation even worse. As a result, users typically employ nearly blind experimentation to find good deployments of their applications in each new grid environment. Only through actual deployment and execution can a user discovers if the mapping was a good one. Further, even after finding a good configuration, there is no basis to determine if a much better configuration has been missed. This approach slows effective grid application development and deployment. We present a richer methodology for evaluating grid software and diverse grid environments based on the MicroGrid grid online simulator. With the MicroGrid, users, grid researchers, or grid operators can define and simulate arbitrary collections of resources and networks. This allows study of an existing grid testbed under controlled conditions or even to study the efficacy of higher performance environments than are available today. Further, the MicroGrid supports direct execution of grid applications unchanged. These application can be written with MPI, C, C++, Perl, and/or Python and use the Globus middleware. This enables detailed and accurate study of application behavior. This work presents: (1) the first validation of the MicroGrid for studying whole-program performance of MPI grid applications and (2) a demonstration of the MicroGrid as a tool for predicting the performance of applications on a range of grid resources and novel network topologies.},
  keywords={},
  doi={10.1109/CLADE.2004.1309092},
  ISSN={},
  month={June},}
@INPROCEEDINGS{1309125,
  author={Sirjani, M. and Shali, A. and Jaghoori, M.M. and Iravanchi, H. and Movaghar, A.},
  booktitle={Proceedings. Fourth International Conference on Application of Concurrency to System Design, 2004. ACSD 2004.}, 
  title={A front-end tool for automated abstraction and modular verification of actor-based models}, 
  year={2004},
  volume={},
  number={},
  pages={145-148},
  abstract={Actor-based modeling is known to be an appropriate approach for representing concurrent and distributed systems. Rebeca is an actor-based language with a formal foundation, based on an operational interpretation of the actor model. We develop a front-end tool for translating a subset of Rebeca to SMV in order to model check Rebeca models. Automated modular verification and abstraction techniques are supported by the tool.},
  keywords={},
  doi={10.1109/CSD.2004.1309125},
  ISSN={},
  month={June},}
@INPROCEEDINGS{1317463,
  author={Ryan, N.D. and Wolf, A.L.},
  booktitle={Proceedings. 26th International Conference on Software Engineering}, 
  title={Using event-based translation to support dynamic protocol evolution}, 
  year={2004},
  volume={},
  number={},
  pages={408-417},
  abstract={All systems built from distributed components involve the use of one or more protocols for inter-component communication. Whether these protocols are based on a broadly used standard or are specially designed for a particular application, they are likely to evolve. The goal of the work described here is to contribute techniques that can support protocol evolution. We are concerned not with how or why a protocol might evolve, or even whether that evolution is in some sense correct. Rather, our concern is with making it possible for applications to accommodate protocol changes dynamically. Our approach is based on a method for isolating the syntactic details of a protocol from the semantic concepts manipulated within components. Protocol syntax is formally specified in terms of tokens, message structures, and message sequences. Event-based translation techniques are used in a novel way to present to the application the semantic concepts embodied by these syntactic elements. We illustrate our approach by showing how it would support an HTTP 1.1 client interacting with an HTTP 1.0 server.},
  keywords={},
  doi={10.1109/ICSE.2004.1317463},
  ISSN={0270-5257},
  month={May},}
@INPROCEEDINGS{1312528,
  author={Nouh, A. and Banihashemi, A.H.},
  booktitle={2004 IEEE International Conference on Communications (IEEE Cat. No.04CH37577)}, 
  title={Reliability-based schedule for decoding low-density parity-check codes}, 
  year={2004},
  volume={1},
  number={},
  pages={444-447},
  abstract={A reliability-based message-passing schedule for iterative decoding of low-density parity-check codes is proposed. Simulation results for bit-flipping algorithms (with binary messages) show that reliability-based schedule can provide considerable improvement in performance and decoding speed over the so-called flooding (parallel) schedule as well as the existing graph-based schedules. The cost associated with this improvement is negligible and is equivalent to having a 2-bit representation for initial messages, instead of the standard 1-bit for hard-decision algorithms, only at the first iteration (all the exchanged messages are still binary).},
  keywords={},
  doi={10.1109/ICC.2004.1312528},
  ISSN={},
  month={June},}
@INPROCEEDINGS{1312745,
  author={Chao-Cheng Wen and Yuan-Sun Chu and Kim-Joan Chen},
  booktitle={2004 IEEE International Conference on Communications (IEEE Cat. No.04CH37577)}, 
  title={Causal-ordered communication of grid computing on Internet}, 
  year={2004},
  volume={3},
  number={},
  pages={1416-1420 Vol.3},
  abstract={Grid computing is a state-of-the-art parallel computing technology which enables the worldwide computers to dynamically share their computing powers and resource to each other. The Grid takes advantage of Internet as an universal communication platform to carry messages. Basically, Internet doesn't guarantee loss-free and ordered transmission, hence, the Grid should keep the cause and effect of events by itself for the correct order of command invocation in the remote hosts. The ordering issue arises when the messages travel across the networks with unpredictable delay. Recent researches study the security and resource control issues but doesn't study the requirements of communication platform in the Grid. In this paper, we propose a Causal Ordered Grid (COG) architecture and implement it to study the performance issues when the Grid is built over worldwide networks. The COG provides a novel service model to the applications with time-sensitive and causal ordering transportation. From our experiments, the design of the Grid middleware should use a causal-ordered, time-sensitive transportation rather than TCP. Our research will be beneficial to the improvement of the Grid Computing and can provide wealthy empirical results for the designer.},
  keywords={},
  doi={10.1109/ICC.2004.1312745},
  ISSN={},
  month={June},}
@INPROCEEDINGS{1316627,
  author={Emma, D. and Pescape, A. and Ventre, G.},
  booktitle={Proceedings. 10th IEEE International Workshop on Future Trends of Distributed Computing Systems, 2004. FTDCS 2004.}, 
  title={Analysis and experimentation of an open distributed platform for synthetic traffic generation}, 
  year={2004},
  volume={},
  number={},
  pages={277-283},
  abstract={This work presents an open distributed platform for traffic generation that we called distributed Internet traffic generator (D-ITG), capable of producing traffic (network transport and application layer) and of accurately replicating appropriate stochastic processes for both IDT (inter departure time) and PS (packet size) random variables. We implemented two different versions of our distributed generator. In the first one, a log server is in charge of recording the information transmitted by senders and receivers and these communications are based either on TCP or UDP. In the other one, senders and receivers make use of the MPI library. A complete performance analysis among centralized version and the two versions of D-ITG is presented. To our knowledge, no similar works are available.},
  keywords={},
  doi={10.1109/FTDCS.2004.1316627},
  ISSN={},
  month={May},}
@ARTICLE{1318607,
  author={Glasser, U. and Gurevich, Y. and Veanes, M.},
  journal={IEEE Transactions on Software Engineering}, 
  title={Abstract communication model for distributed systems}, 
  year={2004},
  volume={30},
  number={7},
  pages={458-472},
  abstract={In some distributed and mobile communication models, a message disappears in one place and miraculously appears in another. In reality, of course, there are no miracles. A message goes from one network to another; it can be lost or corrupted in the process. Here, we present a realistic but high-level communication model where abstract communicators represent various nets and subnets. The model was originally developed in the process of specifying a particular network architecture, namely, the Universal Plug and Play architecture. But, it is general. Our contention is that every message-based distributed system, properly abstracted, gives rise to a specialization of our abstract communication model. The purpose of the abstract communication model is not to design a new kind of network; rather, it is to discover the common part of all message-based communication networks. The generality of the model has been confirmed by its successful reuse for very different distributed architectures. The model is based on distributed abstract state machines. It is implemented in the specification language AsmL and is used for testing distributed systems.},
  keywords={},
  doi={10.1109/TSE.2004.25},
  ISSN={1939-3520},
  month={July},}
@INPROCEEDINGS{1324034,
  author={Fang Wu and Yaojiang Zhang and Zaw Zaw Oo and Erping Li},
  booktitle={Proceedings. Seventh International Conference on High Performance Computing and Grid in Asia Pacific Region, 2004.}, 
  title={Parallel fast algorithm for large-scale electromagnetic scattering}, 
  year={2004},
  volume={},
  number={},
  pages={188-194},
  abstract={Electromagnetic scattering analysis for radar cross section (RCS) prediction and electromagnetic compatibility analysis have extensive military and civil applications. Meanwhile, it presents very large computational demands. Parallel multi-level fast multipole method (MLFMM), a powerful and efficient computational algorithm on solving large-scale RCS problems, is developed and implemented on massively parallel, distributed memory computer systems. Multilevel grouping structure is partitioned carefully to separate computational tasks and reduce data communication. Message passing interface (MPI) is employed to perform the data transfer among processors and support the matrix-vector product in parallel iterative procedure. The accuracy of code is verified by comparison with results of benchmark target. The computational complexity and efficiency of parallel MLFMM is discussed. The parallel code is validated on Unix and Linux platforms with different number of processors, and proven to be scalable, portable, and efficient.},
  keywords={},
  doi={10.1109/HPCASIA.2004.1324034},
  ISSN={},
  month={July},}
@INPROCEEDINGS{1324026,
  author={Selvakumar, A.D. and Sobha, P.M. and Ravindra, G.C. and Pitchiah, R.},
  booktitle={Proceedings. Seventh International Conference on High Performance Computing and Grid in Asia Pacific Region, 2004.}, 
  title={Design, implementation and performance of fault-tolerant message passing interface (MPI)}, 
  year={2004},
  volume={},
  number={},
  pages={120-129},
  abstract={Fault tolerant MPI (FTMPI) enables fault tolerance to the MPICH, an open source GPL licensed implementation of MPI standard by Argonne National Laboratory's Mathematics and Computer Science Division. FTMPI is a transparent fault-tolerant environment, based on synchronous checkpointing and restarting mechanism. FTMPI relies on non-multithreaded single process checkpointing library to synchronously checkpoint an application process. Global replicated system controller and cluster node specific node controller monitors and controls check pointing and recovery activities of all MPI applications within the cluster. This work details the architecture to provide fault tolerance mechanism for MPI based applications running on clusters and the performance of NAS parallel benchmarks and parallelized medium range weather forecasting models, P-T80 and P-TI26. The architecture addresses the following issues also: Replicating system controller to avoid single point of failure. Ensuring consistency of checkpoint files based on distributed two phase commit protocol, and robust fault detection hierarchy.},
  keywords={},
  doi={10.1109/HPCASIA.2004.1324026},
  ISSN={},
  month={July},}
@INPROCEEDINGS{1324043,
  author={Ngiamsoongnirn, K. and Juntasaro, E. and Juntasaro, V. and Uthayopas, P.},
  booktitle={Proceedings. Seventh International Conference on High Performance Computing and Grid in Asia Pacific Region, 2004.}, 
  title={A parallel semi-coarsening multigrid algorithm for solving the Reynolds-averaged Navier-Stokes equations}, 
  year={2004},
  volume={},
  number={},
  pages={258-266},
  abstract={The multigrid method adopted in conjunction with the parallel computing is presented. The standard multigrid doubling the mesh size in all directions, called full-coarsening technique, suffers from the partitioning of data for parallel computing. To remedy this problem, the semicoarsening technique should be used instead. This work is aimed to present an algorithm of the semicoarsening multigrid technique combined with the parallel computing technique. The parallel computing technique used is the one based on the distributed memory machine. The MPI library is adopted in order to exchange the data among processors. The solver code is developed for three-dimensional turbulent flows and validated with the available experimental data.},
  keywords={},
  doi={10.1109/HPCASIA.2004.1324043},
  ISSN={},
  month={July},}
@INPROCEEDINGS{1260944,
  author={Tun Li and Yang Guo and Si-Kun Li},
  booktitle={17th International Conference on VLSI Design. Proceedings.}, 
  title={Design and implementation of a parallel Verilog simulator: PVSim}, 
  year={2004},
  volume={},
  number={},
  pages={329-334},
  abstract={Parallel HDL simulation is an efficient method to accelerate the verification process of large complex VLSI system design. This paper presents a parallel Verilog simulator-PVSim, which bases on optimistic asynchronous parallel simulation algorithm and MPI library. A new module-based simulation component mapping method is proposed. And an efficient module-based partition algorithm combined with pre-simulation partition algorithm is adopted. This paper introduces the architecture of PVSim, the Verilog component mapping techniques, the distributed simulation cycle arrangement and the circuit partition algorithm in detail. Experimental results show that PVSim can get promising speedup, as well as distributed workload and communication cost across processors.},
  keywords={},
  doi={10.1109/ICVD.2004.1260944},
  ISSN={},
  month={Jan},}
@ARTICLE{1327834,
  author={Sankar, H. and Narayanan, K.R.},
  journal={IEEE Transactions on Communications}, 
  title={Memory-efficient sum-product decoding of LDPC codes}, 
  year={2004},
  volume={52},
  number={8},
  pages={1225-1230},
  abstract={Low-density parity-check (LDPC) codes perform very close to capacity for long lengths on several channels. However, the amount of memory (fixed-point numbers that need to be stored) required for implementing the message-passing algorithm increases linearly as the number of edges in the graph increases. In this letter, we propose a decoding algorithm for decoding LDPC codes that reduces the memory requirement at the decoder. The proposed decoding algorithm can be analyzed using density evolution; further, we show how to design good LDPC codes using this. Results show that this algorithm provides almost the same performance as the conventional sum-product decoding of LDPC codes.},
  keywords={},
  doi={10.1109/TCOMM.2004.833016},
  ISSN={1558-0857},
  month={Aug},}
@ARTICLE{1327839,
  author={Tan, W. and Cruz, J.R.},
  journal={IEEE Transactions on Communications}, 
  title={Performance evaluation of low-density parity-check codes on partial-response channels using density evolution}, 
  year={2004},
  volume={52},
  number={8},
  pages={1253-1256},
  abstract={A method to evaluate the performance of a low-density parity-check (LDPC) code on partial-response (PR) channels in terms of the noise threshold and decoding error is presented. Given a particular codeword or assuming an independent and uniformly distributed (i.u.d.) codeword for transmission, the density-evolution algorithm is used to compute the probability density function of messages passing in the decoding process, from which the decoding error is extracted. This estimated i.u.d. decoding error is used to approximate the decoding error of an ensemble of LDPC codes on arbitrary PR channels. Comparison with simulation results shows that it is a very good approximation for the simulated codes, provided their length is large enough.},
  keywords={},
  doi={10.1109/TCOMM.2004.833029},
  ISSN={1558-0857},
  month={Aug},}
@INPROCEEDINGS{1327915,
  author={Underwood, K.D. and Brightwell, R.},
  booktitle={International Conference on Parallel Processing, 2004. ICPP 2004.}, 
  title={The impact of MPI queue usage on message latency}, 
  year={2004},
  volume={},
  number={},
  pages={152-160 vol.1},
  abstract={It is well known that traditional microbenchmarks do not fully capture the salient architectural features that impact application performance. Even worse, microbenchmarks that target MPI and the communications subsystem do not accurately represent the way that applications use MPI. For example, traditional MPI latency benchmarks time a ping-pong communication with one send and one receive on each of two nodes. The time to post the receive is never counted as part of the latency. This scenario is not even marginally representative of most applications. Two new microbenchmarks are presented here that analyze network latency in a way that more realistically represents the way that MPI is typically used. These benchmarks are used to evaluate modern high-performance networks, including Quadrics, InfiniBand, and Myrinet.},
  keywords={},
  doi={10.1109/ICPP.2004.1327915},
  ISSN={0190-3918},
  month={Aug},}
@INPROCEEDINGS{1327931,
  author={Beaumont, O. and Legrand, A. and Marchal, L. and Robert, Y.},
  booktitle={International Conference on Parallel Processing, 2004. ICPP 2004.}, 
  title={Complexity results and heuristics for pipelined multicast operations on heterogeneous platforms}, 
  year={2004},
  volume={},
  number={},
  pages={267-274 vol.1},
  abstract={We consider the communications involved by the execution of a complex application deployed on a heterogeneous platform. Such applications extensively use macro-communication schemes, such as multicast operations, where messages are broadcast to a set of predefined targets. We assume that there are a large number of messages to be multicast in pipeline fashion, and we seek to maximize the throughput of the steady-state operation. We target heterogeneous platforms, modeled by a graph where links have different communication speeds. We show that the problem of computing the best throughput for a multicast operation is NP-hard, whereas the best throughput to broadcast a message to every node in a graph can be computed in polynomial time. Thus, we introduce several heuristics to deal with this problem and prove that some of them are approximation algorithms. We perform, simulations to test these heuristics and show that their results are close to a theoretical upper bound on the throughput that we obtain with a linear programming approach.},
  keywords={},
  doi={10.1109/ICPP.2004.1327931},
  ISSN={0190-3918},
  month={Aug},}
@ARTICLE{1327577,
  author={Chanchio, K. and Sun, X.-H.},
  journal={IEEE Transactions on Computers}, 
  title={Communication state transfer for the mobility of concurrent heterogeneous computing}, 
  year={2004},
  volume={53},
  number={10},
  pages={1260-1273},
  abstract={In a dynamic environment where a process can migrate from one host to another host, communication state transfer is a key issue of process coordination. We present a set of data communication and process migration protocols to support communication state transfer in a dynamic, distributed parallel environment. The protocols preserve the semantics of point-to-point communication; they guarantee message delivery, maintain message ordering, and do not introduce deadlock when blocking send or receive operations are performed during process migration. Analytical proofs and prototype implementation are conducted to confirm the correctness of the protocols. Analytical and experimental results show the proposed design is valid and has a true potential in network computing.},
  keywords={},
  doi={10.1109/TC.2004.73},
  ISSN={1557-9956},
  month={Oct},}
@ARTICLE{1327592,
  author={Seinstra, F.J. and Koelma, D. and Bagdanov, A.D.},
  journal={IEEE Transactions on Parallel and Distributed Systems}, 
  title={Finite state machine-based optimization of data parallel regular domain problems applied in low-level image processing}, 
  year={2004},
  volume={15},
  number={10},
  pages={865-877},
  abstract={A popular approach to providing nonexperts in parallel computing with an easy-to-use programming model is to design a software library consisting of a set of preparallelized routines, and hide the intricacies of parallelization behind the library's API. However, for regular domain problems (such as simple matrix manipulations or low-level image processing applications-in which all elements in a regular subset of a dense data field are accessed in turn) speedup obtained with many such library-based parallelization tools is often suboptimal. This is because interoperation optimization (or: time-optimization of communication steps across library calls) is generally not incorporated in the library implementations. We present a simple, efficient, finite state machine-based approach for communication minimization of library-based data parallel regular domain problems. In the approach, referred to as lazy parallelization, a sequential program is parallelized automatically at runtime by inserting communication primitives and memory management operations whenever necessary. Apart from being simple and cheap, lazy parallelization guarantees to generate legal, correct, and efficient parallel programs at all times. The effectiveness of the approach is demonstrated by analyzing the performance characteristics of two typical regular domain problems obtained from the field of low-level image processing. Experimental results show significant performance improvements over nonoptimized parallel applications. Moreover, obtained communication behavior is found to be optimal with respect to the abstraction level of message passing programs.},
  keywords={},
  doi={10.1109/TPDS.2004.55},
  ISSN={1558-2183},
  month={Oct},}
@INPROCEEDINGS{1329292,
  author={Se-Hyeon Kang and In-Cheol Park},
  booktitle={2004 IEEE International Symposium on Circuits and Systems (ISCAS)}, 
  title={Memory-based low density parity check code decoder architecture using loosely coupled two data-flows}, 
  year={2004},
  volume={2},
  number={},
  pages={II-397},
  abstract={To achieve high throughput, parallel decoding of low density parity check (LDPC) codes is required, but needs a large set of registers and complex interconnection due to randomly located 1's in a sparse parity check matrix of large block size. This paper proposes a memory-based decoding architecture for low density parity check codes using loosely coupled two data flows. Instead of register, intermediate values are optimally grouped and scheduled to store into the segmented memory, which reduces large area and enables a scalable architecture. The performance of the proposed decoder architecture is demonstrated by implementing a 1024 bit, rate-1/2 LDPC codes decoder.},
  keywords={},
  doi={10.1109/ISCAS.2004.1329292},
  ISSN={},
  month={May},}
@INPROCEEDINGS{1330280,
  author={Liu, N. and Lu, M. and Shanker, B. and Michielssen, E.},
  booktitle={IEEE Antennas and Propagation Society Symposium, 2004.}, 
  title={The parallel plane wave time domain algorithm-accelerated marching on in time solvers for large-scale electromagnetic scattering problems}, 
  year={2004},
  volume={4},
  number={},
  pages={4212-4215 Vol.4},
  abstract={The plane wave time domain (PWTD) algorithm permits the fast evaluation of transient wave fields generated by like sources and thereby constitutes the extension to the time domain of the frequency domain fast multipole method. When coupled to classical marching on in time (MOT) solvers, it drastically accelerates the solution of time domain integral equations (TDIE) pertinent to the analysis of electromagnetic scattering problems while minimizing their memory requirements. This paper describes a parallel implementation of a multilevel PWTD kernel and associated MOT scheme that solves a combined field integral equation (CFIE) pertinent to the analysis of transient scattering from three-dimensional perfect electrically conducting (PEC) objects. The described solver executes on a distributed-memory parallel cluster and uses the message passing interface (MPI) paradigm to communicate data between processors. A "space/direction partitioning" scheme is adopted to divide the computational tasks involved and achieve reasonable load balancing among the available processors. The performance of the parallel solvers is verified by a numerical example.},
  keywords={},
  doi={10.1109/APS.2004.1330280},
  ISSN={},
  month={June},}
@INPROCEEDINGS{1333606,
  author={Yamada, T. and Aihara, K. and Takasu, A. and Adachi, J.},
  booktitle={Proceedings. 15th International Workshop on Database and Expert Systems Applications, 2004.}, 
  title={An index system for dynamic peer-to-peer network based on document usefulness}, 
  year={2004},
  volume={},
  number={},
  pages={986-990},
  abstract={Peer-to-peer (P2P) systems are applied to cooperative working environments, but require more effective document sharing mechanisms, particularly, more efficient query processing. To achieve efficient query processing in the environment, we study a distributed indexing mechanism, normal direct indices (DIs), which are the key to reducing the number of queries and improving scalability over P2P networks. However, query processing with DIs cannot efficiently deal with an increase in the number of document categories because a DI holds the peer's information, not the document information. Therefore, we propose an improved DI, query-based DIs (QDIs). We assume that the peer is relevant to the query terms that the peer sends. This assumption allows each peer with correct QDIs to forward the query messages to their destination. To validate the QDIs, we show experimental results on query processing with and without DIs and show the improvement in network performance.},
  keywords={},
  doi={10.1109/DEXA.2004.1333606},
  ISSN={1529-4188},
  month={Sep.},}
@INPROCEEDINGS{1336601,
  author={Badrinath, R. and Morin, C.},
  booktitle={IEEE International Symposium on Cluster Computing and the Grid, 2004. CCGrid 2004.}, 
  title={Locks and barriers in checkpointing and recovery}, 
  year={2004},
  volume={},
  number={},
  pages={459-466},
  abstract={Dependency tracking between communicating tasks is an important concept in backward error recovery for parallel applications. One can extend the traditional dependence tracking model for message passing systems to track dependencies between shared memory and task private states for shared memory applications. The objective of this paper is to analyze the issues generated by locks and barriers in parallel applications so that we can checkpoint tasks at any time (even when holding or waiting for locks and barriers). In particular we attempt to extend earlier dependency tracking mechanisms to locks and barriers. We address both coordinated and uncoordinated checkpointing schemes.},
  keywords={},
  doi={10.1109/CCGrid.2004.1336601},
  ISSN={},
  month={April},}
@INPROCEEDINGS{1336586,
  author={Parker, D.C. and Collins, S.A. and Cleary, D.C.},
  booktitle={IEEE International Symposium on Cluster Computing and the Grid, 2004. CCGrid 2004.}, 
  title={Building near real-time P-2-P applications with JXTA}, 
  year={2004},
  volume={},
  number={},
  pages={338-345},
  abstract={The development of peer-to-peer applications has reached a point where they will have to surpass the limitations of tradition file sharing applications like those pioneered by Napster and Gnutella. In this paper we examine the JXTA platform v2.1 and the challenges it faces in meeting the near real-time characteristics required by next generation peer-to-peer applications.},
  keywords={},
  doi={10.1109/CCGrid.2004.1336586},
  ISSN={},
  month={April},}
@INPROCEEDINGS{1290459,
  author={Goldson, D.},
  booktitle={2004 Australian Software Engineering Conference. Proceedings.}, 
  title={An experiment in the design of distributed programs}, 
  year={2004},
  volume={},
  number={},
  pages={70-76},
  abstract={We describe an experiment in the design of distributed programs. It is based on the theory of Owicki and Gries extended with rules for reasoning about message passing. The experiment is designed to test the effectiveness of the extended theory for designing distributed programs.},
  keywords={},
  doi={10.1109/ASWEC.2004.1290459},
  ISSN={},
  month={April},}
@INPROCEEDINGS{1291353,
  author={Balaji, P. and Narravula, S. and Vaidyanathan, K. and Krishnamoorthy, S. and Wu, J. and Panda, D.K.},
  booktitle={IEEE International Symposium on - ISPASS Performance Analysis of Systems and Software, 2004}, 
  title={Sockets Direct Protocol over InfiniBand in clusters: is it beneficial?}, 
  year={2004},
  volume={},
  number={},
  pages={28-35},
  abstract={The Sockets Direct Protocol (SDP) had been proposed recently in order to enable sockets based applications to take advantage of the enhanced features provided by InfiniBand architecture. In this paper, we study the benefits and limitations of an implementation of SDP. We first analyze the performance of SDP based on a detailed suite of micro-benchmarks. Next, we evaluate it on two different real application domains: (1) A multitier data-center environment and (2) A Parallel Virtual File System (PVFS). Our micro-benchmark results show that SDP is able to provide up to 2.7 times better bandwidth as compared to the native sockets implementation over InfiniBand (IPoIB) and significantly better latency for large message sizes. Our experimental results also show that SDP is able to achieve a considerably higher performance (improvement of up to 2.4 times) as compared to IPoIB in the PVFS environment. In the data-center environment, SDP outperforms IPoIB for large file transfers inspite of currently being limited by a high connection setup time. However, this limitation is entirely implementation specific and as the InfiniBand software and hardware products are rapidly maturing, we expect this limitation to be overcome soon. Based on this, we have shown that the projected performance for SDP, without the connection setup time, can outperform IPoIB for small message transfers as well.},
  keywords={},
  doi={10.1109/ISPASS.2004.1291353},
  ISSN={},
  month={March},}
@INPROCEEDINGS{1314669,
  author={Adhikari, S. and Fang, J. and Lindgren, G. and Wadie, S. and DeVore, M.D.},
  booktitle={Proceedings of the 2004 IEEE Systems and Information Engineering Design Symposium, 2004.}, 
  title={Simulation of a distributed target recognition system with variable operating conditions}, 
  year={2004},
  volume={},
  number={},
  pages={105-112},
  abstract={This paper details a simulation tool for assessing the effect of variable operating conditions on an automatic target recognition system. The simulation tool helped to assess the impact of variable operating conditions and hardware capability on the performance of distributed target recognition systems. Its user interface allowed for real-time monitoring of the best object classification, its associated likelihood value, and the time required to make the classification. Testing revealed that the available network bandwidth and the number of processing nodes used to compute most greatly influenced system performance, followed closely by the level of resolution of the target model images},
  keywords={},
  doi={10.1109/SIEDS.2004.239822},
  ISSN={},
  month={April},}
@ARTICLE{1341626,
  author={Yilmaz, A.E. and Jian-Ming Jin and Michielssen, E.},
  journal={IEEE Transactions on Antennas and Propagation}, 
  title={Time domain adaptive integral method for surface integral equations}, 
  year={2004},
  volume={52},
  number={10},
  pages={2692-2708},
  abstract={An efficient marching-on-in-time (MOT) scheme is presented for solving electric, magnetic, and combined field integral equations pertinent to the analysis of transient electromagnetic scattering from perfectly conducting surfaces residing in an unbounded homogenous medium. The proposed scheme is the extension of the frequency-domain adaptive integral/pre-corrected fast-Fourier transform (FFT) method to the time domain. Fields on the scatterer that are produced by space-time sources residing on its surface are computed: 1) by locally projecting, for each time step, all sources onto a uniform auxiliary grid that encases the scatterer; 2) by computing everywhere on this grid the transient fields produced by the resulting auxiliary sources via global, multilevel/blocked, space-time FFTs; 3) by locally interpolating these fields back onto the scatterer surface. As this procedure is inaccurate when source and observer points reside close to each other; and 4) near fields are computed classically, albeit (pre-)corrected, for errors introduced through the use of global FFTs. The proposed scheme has a computational complexity and memory requirement of O(N/sub t/N/sub s/log/sup 2/N/sub s/) and O(N/sub s//sup 3/2/) when applied to quasiplanar structures, and of O(N/sub t/N/sub s//sup 3/2/log/sup 2/N/sub s/) and O(N/sub s//sup 2/) when used to analyze scattering from general surfaces. Here, N/sub s/ and N/sub t/ denote the number of spatial and temporal degrees of freedom of the surface current density. These computational cost and memory requirements are contrasted to those of classical MOT solvers, which scale as O(N/sub t/N/sub s//sup 2/) and O(N/sub s//sup 2/), respectively. A parallel implementation of the scheme on a distributed-memory computer cluster that uses the message-passing interface is described. Simulation results demonstrate the accuracy, efficiency, and the parallel performance of the implementation.},
  keywords={},
  doi={10.1109/TAP.2004.834399},
  ISSN={1558-2221},
  month={Oct},}
@INPROCEEDINGS{1332472,
  author={Huimin Geng and Bastola, D. and Ali, H.},
  booktitle={Proceedings. 2004 IEEE Computational Systems Bioinformatics Conference, 2004. CSB 2004.}, 
  title={A new approach to clustering biological data using message passing}, 
  year={2004},
  volume={},
  number={},
  pages={493-494},
  abstract={Clustering algorithms are widely used in bioinformatics to classify data, as in the analysis of gene expression and in the building of phylogenetic trees. Biological data often describe parallel and spontaneous processes. To capture these features, we propose a new clustering algorithm that employs the concept of message passing. Message passing clustering (MPC) allows data objects to communicate with each other and produces clusters in parallel, thereby making the clustering process intrinsic. We have proved that MPC shares similarity with hierarchical clustering (HC) but offers significantly improved performance because it takes into account both local and global structure. We analyzed 35 sets of simulated dynamic gene expression data, achieving a 95% hit rate in which 639 genes out of total 674 genes were correctly clustered. We have also applied MPC to a real data set to build a phylogenetic tree from aligned mycobacterium sequences. The results show higher classification accuracies as compared to traditional clustering methods such as HC.},
  keywords={},
  doi={10.1109/CSB.2004.1332472},
  ISSN={},
  month={Aug},}
@INPROCEEDINGS{1332526,
  author={Lie-Quan Lee and Varner, J. and Kwok Ko},
  booktitle={Proceedings. 2004 IEEE Computational Systems Bioinformatics Conference, 2004. CSB 2004.}, 
  title={Parallel extreme pathway computation for metabolic networks}, 
  year={2004},
  volume={},
  number={},
  pages={636-639},
  abstract={We parallelized the serial extreme pathways algorithm presented by Schilling et al., in J. Theor. Biol. 203 (2000) using the message passing interface (MPI). The parallel algorithm exhibits super-linear scalability because the number of independence tests performed decreases as the number of MPI nodes increases. A subsystem of the metabolic network of Escherichia coli with 140 reactions and 96 metabolites (without preprocessing) is used as a benchmark. The extreme pathways of this system are computed in under 280 seconds using 70 2.4 GHz Intel Pentium-IV CPUs with Myrinet interconnection among the dual-CPU nodes of the Linux cluster.},
  keywords={},
  doi={10.1109/CSB.2004.1332526},
  ISSN={},
  month={Aug},}
@INPROCEEDINGS{1345932,
  author={Wang Lin and Xiao Juan and Guanrong Chen},
  booktitle={2004 International Conference on Communications, Circuits and Systems (IEEE Cat. No.04EX914)}, 
  title={Density evolution method and threshold decision for irregular LDPC codes}, 
  year={2004},
  volume={1},
  number={},
  pages={25-28 Vol.1},
  abstract={Density evolution is a new method for analyzing the asymptotic performance of network capability approaching error-correcting codes. For irregular LDPC codes with message-passing decoding, the density evolution method can track the messages to find out the threshold, enabling optimization of the degree distribution. In this paper, the principle of density evolution combined with the decoding process is firstly explored. Then, two algorithms for programming the evolution proceeding are discussed: the discretized density evolution and the Gaussian approximation, as well as their application conditions. Finally, simulation results are presented.},
  keywords={},
  doi={10.1109/ICCCAS.2004.1345932},
  ISSN={},
  month={June},}
@ARTICLE{1353239,
  author={Xiang-Yang Li and Yu Wang and Wen-Zhan Song},
  journal={IEEE Transactions on Parallel and Distributed Systems}, 
  title={Applications of k-local MST for topology control and broadcasting in wireless ad hoc networks}, 
  year={2004},
  volume={15},
  number={12},
  pages={1057-1069},
  abstract={We propose a family of structures, namely, k-localized minimum spanning tree (LMST/sub k/) for topology control and broadcasting in wireless ad hoc networks. We give an efficient localized method to construct LMST/sub k/ using only O(n) messages under the local-broadcast communication model, i.e., the signal sent by each node would be received by all nodes within the node's transmission range. We also analytically prove that the node degree of the structure LMST/sub k/ is at most 6, LMST/sub k/ is connected and planar and, more importantly, the total edge length of the LMST/sub k/ is within a constant factor of that of the minimum spanning tree when k/spl ges/2 (called low weighted hereafter). We then propose another low weighted structure, called Incident MST and RNG Graph (IMRG), that can be locally constructed using at most 13n messages under the local broadcast communication model. Test results are corroborated in the simulation study. We study the performance of our structures in terms of the total power consumption for broadcasting, the maximum node power needed to maintain the network connectivity. We theoretically prove that our structures are asymptotically the best possible for broadcasting among all locally constructed structures. Our simulations show that our new structures outperform previous locally constructed structures in terms of broadcasting and power assignment for connectivity.},
  keywords={},
  doi={10.1109/TPDS.2004.77},
  ISSN={1558-2183},
  month={Dec},}
@INPROCEEDINGS{1349074,
  author={Hu Liang and Wu Xiuchuan and Kang Jian and Hu Ming},
  booktitle={8th International Conference on Computer Supported Cooperative Work in Design}, 
  title={An efficient communication protocol for PC clusters}, 
  year={2004},
  volume={1},
  number={},
  pages={505-511 Vol.1},
  abstract={When clusters are used in parallel computing, the communication speed between processes is the bottleneck due to low network communication bandwidth. In this paper, we overview some methods used to improve communication performance, and introduce a new transport protocol that we have designed and implemented based on Ethernet. In addition, the TCP/IP protocol is replaced by the new protocol in cluster computing. This work will used in CSCW applications. The results show that parallel computing using the new protocol on an Ethernet compared to using the TCP/IP protocol on an Ethernet can provide larger communication bandwidth and improve the performance of a cluster system.},
  keywords={},
  doi={10.1109/CACWD.2004.1349074},
  ISSN={},
  month={May},}
@INPROCEEDINGS{1349072,
  author={Hu Liang and Meng Faner and Hu Ming},
  booktitle={8th International Conference on Computer Supported Cooperative Work in Design}, 
  title={A dynamic load balancing system based on data migration}, 
  year={2004},
  volume={1},
  number={},
  pages={493-499 Vol.1},
  abstract={The problem of load balancing is a key factor that influences the performance of the cluster computing system. In this paper, we describe a dynamic scheduling system and a load balancing system based on PVM, this system supports dynamic scheduling parallel processes and balances load in a cluster computing environment, this work is used in CSCW application. The results of the performance test show this dynamic load balancing system can reduce the execution time of some parallel applications.},
  keywords={},
  doi={10.1109/CACWD.2004.1349072},
  ISSN={},
  month={May},}
@INPROCEEDINGS{1347769,
  author={Tauber, J.A. and Lynch, N.A. and Tsai, M.J.},
  booktitle={Third IEEE International Symposium on Network Computing and Applications, 2004. (NCA 2004). Proceedings.}, 
  title={Compiling IOA without global synchronization}, 
  year={2004},
  volume={},
  number={},
  pages={121-130},
  abstract={This work presents a strategy for compiling distributed systems specified in IOA, a formal language for describing such systems as I/O automata, into Java programs running on a group of networked workstations. The translation works node-by-node, translating IOA programs into Java classes that communicate using the message passing interface. The resulting system runs without any global synchronization. We prove that, subject to certain restrictions on the program to be compiled, assumptions on the correctness of hand-coded datatype implementations, and basic assumptions about the behavior of the network, the compilation method preserves safety properties of the IOA program in the generated Java code. We model the generated Java code itself as a threaded, low-level I/O automaton and use a refinement mapping to show that the external behavior of the system is preserved by the translation. The IOA compiler is part of the IOA toolkit which supports algorithm design, development, testing, and formal verification using automated tools.},
  keywords={},
  doi={10.1109/NCA.2004.1347769},
  ISSN={},
  month={Sep.},}
@INPROCEEDINGS{1347771,
  author={Cholvi, V. and Fernandez, A. and Jimenez, E. and Raynal, M.},
  booktitle={Third IEEE International Symposium on Network Computing and Applications, 2004. (NCA 2004). Proceedings.}, 
  title={A methodological construction of an efficient sequential consistency protocol}, 
  year={2004},
  volume={},
  number={},
  pages={141-148},
  abstract={A concurrent object is an object that can be concurrently accessed by several processes. Sequential consistency is a consistency criterion for such objects. Informally, it states that a multiprocess program executes correctly if its results could have been produced by executing that program on a single processor system. (Sequential consistency is weaker than atomic consistency -the usual consistency criterion- as it does not refer to real-time.) The paper proposes a simple protocol that ensures sequential consistency when the shared memory abstraction is supported by the local memories of nodes that can communicate only by exchanging messages through reliable channels. Differently from other sequential consistency protocols, the proposed protocol does not rely on a strong synchronization mechanism such as an atomic broadcast primitive or a central node managing a copy of every shared object. From a methodological point of view, the protocol is built incrementally starting from the very definition of sequential consistency. It lies the noteworthy property of providing fast writes operations (i.e., a process has never to wait when it writes a new value in a shared object). According to the current local state, some read operations can also be fast. An experimental evaluation of the protocol is also presented. The proposed protocol could be used to manage Web page caching.},
  keywords={},
  doi={10.1109/NCA.2004.1347771},
  ISSN={},
  month={Sep.},}
@INPROCEEDINGS{1348041,
  author={Chung, M.-Y. and Ciardo, G.},
  booktitle={First International Conference on the Quantitative Evaluation of Systems, 2004. QEST 2004. Proceedings.}, 
  title={Saturation NOW}, 
  year={2004},
  volume={},
  number={},
  pages={272-281},
  abstract={We present a distributed version of the saturation algorithm for symbolic state-space generation of discrete-state models. The execution is strictly sequential but utilizes the overall available memory. A level-based allocation of the decision diagram nodes onto the workstations is created. No additional node or work is created. A dynamic memory load balancing heuristic helps coping with the uneven growth of the decision diagram levels allocated to each workstation. Experiments on a conventional network of workstations show that the runtime of our distributed implementation is close to the sequential one even when balancing is triggered, while it is of course much better when the sequential implementation is forced to rely on virtual memory.},
  keywords={},
  doi={10.1109/QEST.2004.1348041},
  ISSN={},
  month={Sep.},}
@INPROCEEDINGS{1353000,
  author={Khanna, G. and Varadharajan, P. and Bagchi, S.},
  booktitle={Proceedings of the 23rd IEEE International Symposium on Reliable Distributed Systems, 2004.}, 
  title={Self checking network protocols: a monitor based approach}, 
  year={2004},
  volume={},
  number={},
  pages={18-30},
  abstract={The wide deployment of high-speed computer networks has made distributed systems ubiquitous in today's connected world. The machines on which the distributed applications are hosted are heterogeneous in nature, the applications often run legacy code without the availability of their source code, the systems are of very large scales, and often have soft real-time guarantees. In this paper, we target the problem of online detection of disruptions through a generic external entity called Monitor that is able to observe the exchanged messages between the protocol participants and deduce any ongoing disruption by matching against a rule base composed of combinatorial and temporal rules. The Monitor architecture is application neutral, with the rule base making it specific to a protocol. To make the detection infrastructure scalable and dependable, we extend it to a hierarchical Monitor structure. The infrastructure is applied to a streaming video application running on a reliable multicast protocol called TRAM installed on the campus wide network. The evaluation brings out the scalability of the monitor infrastructure and detection coverage under different kinds of faults for the single level and the hierarchical arrangements.},
  keywords={},
  doi={10.1109/RELDIS.2004.1353000},
  ISSN={1060-9857},
  month={Oct},}
@INPROCEEDINGS{1353023,
  author={Pereira, J. and Oliveira, R.},
  booktitle={Proceedings of the 23rd IEEE International Symposium on Reliable Distributed Systems, 2004.}, 
  title={The mutable consensus protocol}, 
  year={2004},
  volume={},
  number={},
  pages={218-227},
  abstract={In this paper we propose the mutable consensus protocol, a pragmatic and theoretically appealing approach to enhance the performance of distributed consensus. First, an apparently inefficient protocol is developed using the simple stubborn channel abstraction for unreliable message passing. Then, performance is improved by introducing judiciously chosen finite delays in the implementation of channels. Although this does not compromise correctness, which rests on an asynchronous system model, it makes it likely that the transmission of some messages is avoided and thus the message exchange pattern at the network level changes noticeably. By choosing different delays in the underlying stubborn channels, the mutable consensus protocol can actually be made to resemble several different protocols. Besides presenting the mutable consensus protocol and four different mutations, we evaluate in detail the particularly interesting permutation gossip mutation, which allows the protocol to scale gracefully to a large number of processes by balancing the number of messages to be handled by each process with the number of communication steps required to decide. The evaluation is performed using a realistic simulation model which accurately reproduces resource consumption in real systems.},
  keywords={},
  doi={10.1109/RELDIS.2004.1353023},
  ISSN={1060-9857},
  month={Oct},}
@INPROCEEDINGS{1353027,
  author={Chand, R. and Felber, P.},
  booktitle={Proceedings of the 23rd IEEE International Symposium on Reliable Distributed Systems, 2004.}, 
  title={XNET: a reliable content-based publish/subscribe system}, 
  year={2004},
  volume={},
  number={},
  pages={264-273},
  abstract={Content-based publish/subscribe systems are usually implemented as a network of brokers that collaboratively route messages from information providers to consumers. A major challenge of such middleware infrastructures is their reliability and their ability to cope with failures in the system. In this paper, we present the architecture of the XNET XML content network and we detail the mechanisms that we implemented to gracefully handle failures and maintain the system state consistent with the consumer population at all times. In particular, we propose several approaches to fault tolerance so that our system can recover from various types of router and link failures. We analyze the efficiency of our techniques in a large scale experimental deployment on the PlanetLab testbed. We show that XNET does not only offer good performance and scalability with large consumer populations under normal operation, but can also quickly recover from system failures.},
  keywords={},
  doi={10.1109/RELDIS.2004.1353027},
  ISSN={1060-9857},
  month={Oct},}
@INPROCEEDINGS{1364747,
  author={Roberti, D.R. and Souto, R.P. and de Campos Velho, H.F. and Degrazia, G.A. and Anfossi, D.},
  booktitle={16th Symposium on Computer Architecture and High Performance Computing}, 
  title={Parallel implementation of a Lagrangian stochastic model for pollution dispersion}, 
  year={2004},
  volume={},
  number={},
  pages={142-149},
  abstract={Pollutant dispersion models in the atmosphere can describe by Eulerian or Lagrangian approaches. Lagrangian models belong to the class of Monte Carlo methods. This type of method is very flexible, solving more complex problems, however this computational cost is greater than Eulerian models, as it is well established in the atmospheric pollutant and nuclear engineering communities. A parallel version of the Lagrangian particle model - LAMBDA - is developed using the MPI message passing communication library. Performance tests were executed in a distributed memory parallel machine, a multicomputer based on IA-32 architecture. Portions of the pollutant in the air are considered particles emitted from a pollutant source, evolving under stochastic forcing. This yields independent evolution equations for each particle of the model that can be executed by a different processor in a parallel implementation. Speed-up results show that the parallel implementation is suitable for the used architecture.},
  keywords={},
  doi={10.1109/SBAC-PAD.2004.30},
  ISSN={1550-6533},
  month={Oct},}
@INPROCEEDINGS{1364741,
  author={Sanches, A.L.G. and Secco, F.R. and Frohlich, A.A.},
  booktitle={16th Symposium on Computer Architecture and High Performance Computing}, 
  title={High performance communication system based on generic programming}, 
  year={2004},
  volume={},
  number={},
  pages={92-99},
  abstract={This paper presents a high performance communication system based on generic programming. The system adapts itself according to the protocol being used on communication, simplifying the development of libraries. In order to validate the concepts, a MPI implementation has been developed and it is compared to a traditional implementation - MPICH-GM. It is demonstrated that the same functionality and interface can be offered with similar performance, but with much less programming effort. That is evidence that the large size of traditional MPI implementations is due to the limitations of conventional communication systems.},
  keywords={},
  doi={10.1109/SBAC-PAD.2004.19},
  ISSN={1550-6533},
  month={Oct},}
@INPROCEEDINGS{1364760,
  author={Midorikawa, E.T. and de Oliveira, H.M. and Laine, J.M.},
  booktitle={16th Symposium on Computer Architecture and High Performance Computing}, 
  title={PEMPIs: a new methodology for modeling and prediction of MPI programs performance}, 
  year={2004},
  volume={},
  number={},
  pages={246-253},
  abstract={The evaluation and prediction of parallel program performance is becoming more and more important, so that it requires appropriate techniques to identify the factors which influence the application execution time and also the way they interact. In this paper, we present some contributions of our research in this area by describing PEMPIs: a new methodology applied to the analysis and prediction of MPI programs. A new task graph helps us both to understand details of the application and to increase the accuracy of the prediction models. The proposed techniques are detailed and tested through the modeling of a complete application. PEMPIs efficiency has been proved by the results of this application modeling - most tests executed in a cluster of workstations exhibited errors up to 10%.},
  keywords={},
  doi={10.1109/SBAC-PAD.2004.31},
  ISSN={1550-6533},
  month={Oct},}
@ARTICLE{1369610,
  author={Nouh, A. and Banihashemi, A.H.},
  journal={IEEE Transactions on Communications}, 
  title={Reliability-based schedule for bit-flipping decoding of low-density Parity-check codes}, 
  year={2004},
  volume={52},
  number={12},
  pages={2038-2040},
  abstract={A reliability-based message-passing schedule for iterative decoding of low-density parity-check codes is proposed. Simulation results for bit-flipping algorithms (with binary messages) show that a reliability-based schedule can provide considerable improvement in performance and decoding speed over the so-called flooding (parallel) schedule, as well as the existing graph-based schedules. The cost associated with this improvement is negligible and is equivalent to having a two-bit representation for initial messages, instead of the standard one bit for hard-decision algorithms, only at the first iteration (all the exchanged messages are still binary).},
  keywords={},
  doi={10.1109/TCOMM.2004.838704},
  ISSN={1558-0857},
  month={Dec},}
@ARTICLE{1369623,
  author={Ardakani, M. and Kschischang, F.R.},
  journal={IEEE Transactions on Communications}, 
  title={A more accurate one-dimensional analysis and design of irregular LDPC codes}, 
  year={2004},
  volume={52},
  number={12},
  pages={2106-2114},
  abstract={We introduce a new one-dimensional (1-D) analysis of low-density parity-check (LDPC) codes on additive white Gaussian noise channels which is significantly more accurate than similar 1-D methods. Our method assumes a Gaussian distribution in message-passing decoding only for messages from variable nodes to check nodes. Compared to existing work, which makes a Gaussian assumption both for messages from check nodes and from variable nodes, our method offers a significantly more accurate estimate of convergence behavior and threshold of convergence. Similar to previous work, the problem of designing irregular LDPC codes reduces to a linear programming problem. However, our method allows irregular code design in a wider range of rates without any limit on the maximum variable-node degree. We use our method to design irregular LDPC codes with rates greater than 1/4 that perform within a few hundredths of a decibel from the Shannon limit. The designed codes perform almost as well as codes designed by density evolution.},
  keywords={},
  doi={10.1109/TCOMM.2004.838718},
  ISSN={1558-0857},
  month={Dec},}
@ARTICLE{1369622,
  author={Hua Xiao and Banihashemi, A.H.},
  journal={IEEE Transactions on Communications}, 
  title={Graph-based message-passing schedules for decoding LDPC codes}, 
  year={2004},
  volume={52},
  number={12},
  pages={2098-2105},
  abstract={We study a wide range of graph-based message-passing schedules for iterative decoding of low-density parity-check (LDPC) codes. Using the Tanner graph (TG) of the code and for different nodes and edges of the graph, we relate the first iteration in which the corresponding messages deviate from their optimal value (corresponding to a cycle-free graph) to the girths and the lengths of the shortest closed walks in the graph. Using this result, we propose schedules, which are designed based on the distribution of girths and closed walks in the TG of the code, and categorize them as node based versus edge based, unidirectional versus bidirectional, and deterministic versus probabilistic. These schedules, in some cases, outperform the previously known schedules, and in other cases, provide less complex alternatives with more or less the same performance. The performance/complexity tradeoff and the best choice of schedule appear to depend not only on the girth and closed-walk distributions of the TG, but also on the iterative decoding algorithm and channel characteristics. We examine the application of schedules to belief propagation (sum-product) over additive white Gaussian noise (AWGN) and Rayleigh fading channels, min-sum (max-sum) over an AWGN channel, and Gallager's algorithm A over a binary symmetric channel.},
  keywords={},
  doi={10.1109/TCOMM.2004.838730},
  ISSN={1558-0857},
  month={Dec},}
@INPROCEEDINGS{1372046,
  author={Craus, M. and Rudeanu, L.},
  booktitle={Third International Symposium on Parallel and Distributed Computing/Third International Workshop on Algorithms, Models and Tools for Parallel Computing on Heterogeneous Networks}, 
  title={Parallel framework for ant-like algorithms}, 
  year={2004},
  volume={},
  number={},
  pages={36-41},
  abstract={This paper describes the work of an objective framework designed to be used in the parallelization of a set of related algorithms. As a concrete application a parallel ant colony optimization algorithm (ACO) for the travelling salesman problem (TSP) is presented. The idea behind the system we are describing is to have a reusable framework for running several sequential algorithms in a parallel environment. The algorithms that the framework can be used with have several things in common: they have to run in cycles and the work should be possible to be split between several "processing units". The parallel framework uses the message-passing communication paradigm and is organized as a master-slave system. The ACO for TSP implemented by means of the parallel framework proves to have good performances: approximately linear speedup and low communication cost.},
  keywords={},
  doi={10.1109/ISPDC.2004.37},
  ISSN={},
  month={July},}
@INPROCEEDINGS{1372091,
  author={Wong, P. and Haoqiang Jin and Becker, J.},
  booktitle={Third International Symposium on Parallel and Distributed Computing/Third International Workshop on Algorithms, Models and Tools for Parallel Computing on Heterogeneous Networks}, 
  title={Load balancing multi-zone applications on a heterogeneous cluster with multi-level parallelism}, 
  year={2004},
  volume={},
  number={},
  pages={388-393},
  abstract={We investigate the feasibility of running parallel applications on heterogeneous clusters. The motivation for doing so is twofold. First, it is practical to be able to pull together existing machines to run a job that is too big for any one of them, especially if such jobs are run rarely. Second, in the event of an emergency, where a very large problem must be solved in a few days, it may not be feasible to purchase and install a new machine in time, and any existing machines will have to be brought to bear on the problem. We ran the Multi-zone versions of the NAS Parallel Benchmarks (NPB) on a cluster composed of two SGI Origin 2000 servers, and an Intel SMP Xeon server connected by Gigabit Ethernet. We report on the results and their implications for running parallel applications on heterogeneous clusters.},
  keywords={},
  doi={10.1109/ISPDC.2004.33},
  ISSN={},
  month={July},}
@INPROCEEDINGS{1372483,
  author={Cavrak, I. and Stranjak, A. and Zagar, M.},
  booktitle={26th International Conference on Information Technology Interfaces, 2004.}, 
  title={Autonomous mobile mailbox model for communication cost reduction}, 
  year={2004},
  volume={},
  number={},
  pages={593-598 Vol.1},
  abstract={This work presents a cost-reductive communication schema for distributed multiagent environments containing mobile agents. Communication cost reduction is achieved by employing autonomous mobile mailbox as a message-relay system component. Beneficial modes of mobile mailbox behavior are identified under various operational conditions. A mobile mailbox model is proposed and simulation conducted in order to verify its usability.},
  keywords={},
  doi={},
  ISSN={},
  month={June},}
@INPROCEEDINGS{1365311,
  author={Ma, X. and Yang, E.},
  booktitle={International Symposium onInformation Theory, 2004. ISIT 2004. Proceedings.}, 
  title={Low-density parity-check codes with fast decoding convergence speed}, 
  year={2004},
  volume={},
  number={},
  pages={277-},
  abstract={In this paper, the design of low-density parity-check (LDPC) codes for binary erasure channels (BEC) with less number of decoding iterations in the parallel message-passing decoding is presented. We consider only the cases where the capacity is approached with sufficiently low parity-check matrix density.},
  keywords={},
  doi={10.1109/ISIT.2004.1365311},
  ISSN={},
  month={June},}
@INPROCEEDINGS{1365313,
  author={Kumar, V. and Milenkovic, O. and Vasic, B.},
  booktitle={International Symposium onInformation Theory, 2004. ISIT 2004. Proceedings.}, 
  title={Structured LDPC codes over GF(2/sup m/) and companion matrix based decoding}, 
  year={2004},
  volume={},
  number={},
  pages={273-},
  abstract={It is well known that random-like low-density parity-check (LDPC) codes over the extension fields GF(2/sup m/) of GF(2), for m>1, tend to outperform their binary counterparts of comparable length and rate. At the same time, structured LDPC codes offer the advantage of reduced implementation and storage complexity, so that it is of interest to investigate mathematical design methods for codes on graphs over fields of large order. We propose a new class of combinatorially developed codes obtained by properly combining Reed-Solomon (RS) type parity-check matrices and sparse parity-check matrices based on permutation matrices. The proposed codes have large girth and minimum distance. In order to further reduce the decoding complexity of the proposed scheme, we introduce a new decoding algorithm based on matrix representations of the underlying field, which trades performance for complexity. The particular field representation described in this abstract is based on a power basis generated by a companion matrix of a primitive polynomial of the field GF(2/sup m/). It is observed that the choice of the primitive polynomial influences the cycle distribution of the code graph.},
  keywords={},
  doi={10.1109/ISIT.2004.1365313},
  ISSN={},
  month={June},}
@INPROCEEDINGS{1376590,
  author={Jin-Min Yang and Da-Fang Zhang},
  booktitle={13th Asian Test Symposium}, 
  title={Bounding rollback-recovery of large distributed computation in WAN environment}, 
  year={2004},
  volume={},
  number={},
  pages={394-399},
  abstract={In the existing optimistic message logging protocols, the dependency must be tracked in whole system, and all processes are involved in rollback recovery in the event of failure. For large distributed computation in WAN environment with the low available bandwidth and high transmission latency, its fault-free overhead and recovery overhead are outstanding, recovery efficiency decreasing with the scale of system. This paper introduces a three-layer model of large distributed system in WAN environment, and presents a protocol of message dependency tracking based on proxy. Utilizing private proxy to log messages and dependencies, the protocol limits rollback-recovery to a scope called block rather than the entire system, achieving relative low fault-free overhead and fast output commit, as well as improved recovery efficiency and low recovery overhead.},
  keywords={},
  doi={10.1109/ATS.2004.27},
  ISSN={1081-7735},
  month={Nov},}
@INPROCEEDINGS{1378472,
  author={Mansour, M.M.},
  booktitle={IEEE Global Telecommunications Conference, 2004. GLOBECOM '04.}, 
  title={High-performance decoders for regular and irregular repeat-accumulate codes}, 
  year={2004},
  volume={4},
  number={},
  pages={2583-2588 Vol.4},
  abstract={This paper investigates high-performance decoder design for regular and irregular repeat-accumulate (RA) codes of large block length. In order to achieve throughputs and bit-error rate performance that are inline with future trends in high-speed communications. high-throughput and low-power decoders of low complexity are needed. To meet such conflicting requirements for long codes, the concept of architecture-aware RA (AARA) code design is proposed. AARA code design decouples the complexity of the decoder from the owe structure by inducing structural regularity features that are amenable to efficient and scalable decoder implementations. Design methods of AARA codes with structured permuters for which an iterative decoding algorithm performs well under message-passing are analogous to those for AA LDPC codes. Algorithmic and architectural optimizations that address the latency, memory overhead, and complexity problems typical of iterative decoders for long RA codes are investigated, and a staggered decoding schedule is introduced. AARA decoders using the proposed schedule have substantial advantage over serial and parallel RA decoders.},
  keywords={},
  doi={10.1109/GLOCOM.2004.1378472},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{1381949,
  author={Plarre, K. and Kumar, P.R. and Seidman, T.},
  booktitle={2004 First Annual IEEE Communications Society Conference on Sensor and Ad Hoc Communications and Networks, 2004. IEEE SECON 2004.}, 
  title={Increasingly correct message passing algorithms for heat source detection in sensor networks}, 
  year={2004},
  volume={},
  number={},
  pages={470-479},
  abstract={Solving complex source inference and estimation problems in the distributed environment of sensor networks is a difficult task. Data is distributed, as is computational power, and energy is limited. We consider the problem of detecting and locating a heat source appearing in a region monitored by a sensor network. This task requires complex computations that must be shared by all sensors. One significant difficulty we overcome is the problem of local minima. By using a two step procedure, where in the first step the nodes estimate their distances to the source, and in the second step we localize it and avoid the problem of having erroneous location estimates of the local minima. Furthermore, to organize the computations involved, we draw on ideas from graphical models. We develop an algorithm that has a property which we call "increasing correctness" that at any time the algorithm can be stopped and it nevertheless provides the correct answer for the problem defined by the information that has been fed into the algorithm up to that time.},
  keywords={},
  doi={10.1109/SAHCN.2004.1381949},
  ISSN={},
  month={Oct},}
@INPROCEEDINGS{1382824,
  author={Bouteiller, A. and Bouziane, H.-L. and Herault, T. and Lemarinier, P. and Cappello, F.},
  booktitle={Fifth IEEE/ACM International Workshop on Grid Computing}, 
  title={Hybrid preemptive scheduling of MPI applications on the grids}, 
  year={2004},
  volume={},
  number={},
  pages={130-137},
  abstract={Time sharing between cluster resources in grid is a major issue in cluster and grid integration. Classical grid architecture involves a higher level scheduler which submits nonoverlapping jobs to the independent batch schedulers of each cluster of the grid. The sequentiality induced by this approach does not fit with the expected number of users and job heterogeneity of the grids. Time sharing techniques address this issue by allowing simultaneous executions of many applications on the same resources. Co-scheduling and gang scheduling are the two best known techniques for time sharing cluster resources. Co-scheduling relies on the operating system of each node to schedule the processes of every application. Gang scheduling ensures that the same application is scheduled on all nodes simultaneously. Previous work has proven that co-scheduling techniques outperforms gang scheduling when physical memory is not exhausted. In this paper, we introduce a new hybrid sharing technique providing checkpoint based explicit memory management. It consists in co-scheduling parallel applications within a set, until the memory capacity of the node is reached, and using gang scheduling related techniques to switch from one set to another one. We compare experimentally the merits of the three solutions: co, gang and hybrid scheduling, in the context of out-of-core computing, which is likely to occur in the grid context, where many users share the same resources. The experiments show that the hybrid solution is as efficient as the co-scheduling technique when the physical memory is not exhausted, and is more efficient than gang scheduling and co-scheduling when physical memory is exhausted.},
  keywords={},
  doi={10.1109/GRID.2004.39},
  ISSN={1550-5510},
  month={Nov},}
@INPROCEEDINGS{1387699,
  author={Guedea, F. and Insop Song and Karray, F.},
  booktitle={Proceedings of the 2004 IEEE International Symposium on Intelligent Control, 2004.}, 
  title={Distributed control framework design and implementation for multi-robotic systems: a case study on block manipulation}, 
  year={2004},
  volume={},
  number={},
  pages={299-304},
  abstract={This work describes the design and development of a multi-robotic system. Each subsystem is built, tested separately and then integrated, using middleware standard, CORBA. Using middleware reduces the burden of network programming, error, and complication of integration, and increases reusability and portability. CORBA is the major and leading standard for distributed platforms. Our approach is to deploy CORBA to integrate distributed robotic and automatic control systems. Using standard specification language, we can describe clearly the system's overview as well as in detail subsystems, even in a large complex system. It helps to define message passing and interaction among subsystems in distributed environments. We summarize SDL (specification description language), and explain our robot system using the SDL. To show the feasibility of our system, small blocks are grasped and moved by the manipulator robot.},
  keywords={},
  doi={10.1109/ISIC.2004.1387699},
  ISSN={2158-9860},
  month={Sep.},}
@INPROCEEDINGS{1392602,
  author={Baer, T. and Wyckoff, P.},
  booktitle={2004 IEEE International Conference on Cluster Computing (IEEE Cat. No.04EX935)}, 
  title={A parallel I/O mechanism for distributed systems}, 
  year={2004},
  volume={},
  number={},
  pages={63-69},
  abstract={Access to shared data is critical to the long term success of grids of distributed systems. As more parallel applications are being used on these grids, the need for some kind of parallel I/O facility across distributed systems increases. However, grid middleware has thus far had only limited support for distributed parallel I/O. In this paper, we present an implementation of the MPI-2 I/O interface using the Globus GridFTP client API. MPI is widely used for parallel computing, and its I/O interface maps onto a large variety of storage systems. The limitations of using GridFTP as an MPI-I/O transport mechanism are described, as well as support for parallel access to scientific data formats such as HDF and NetCDF. We compare the performance of GridFTP to that of NFS on the same network using several parallel I/O benchmarks. Our tests indicate that GridFTP can be a workable transport for parallel I/O, particularly for distributed read-only access to shared data sets.},
  keywords={},
  doi={10.1109/CLUSTR.2004.1392602},
  ISSN={1552-5244},
  month={Sep.},}
@INPROCEEDINGS{1392596,
  author={Vinod, U.V. and Baruah, P.K.},
  booktitle={2004 IEEE International Conference on Cluster Computing (IEEE Cat. No.04EX935)}, 
  title={MPIIMGEN - a code transformer that parallelizes image processing codes to run on a cluster of workstations}, 
  year={2004},
  volume={},
  number={},
  pages={5-12},
  abstract={An enormous body of image and video processing software has been written for conventional (sequential) desktop computers. These implement a wide range of operations, such as convolution, histogram equalization and template matching. These applications usually have a tremendous potential for parallelism. However a significant barrier in exploiting such parallelism is the difficulty of writing parallel software. In this work, the design and implementation of MPIIMGEN -- a code transformer that automatically transforms these sequential image processing codes into parallel codes that are capable of running on a cluster of workstations is presented. This tool uses a pattern driven approach to parallelize the sequential codes.},
  keywords={},
  doi={10.1109/CLUSTR.2004.1392596},
  ISSN={1552-5244},
  month={Sep.},}
@INPROCEEDINGS{1392620,
  author={Cheung, B.W.L. and Cho-Li Wang and Lau, F.C.M.},
  booktitle={2004 IEEE International Conference on Cluster Computing (IEEE Cat. No.04EX935)}, 
  title={LOTS: a software DSM supporting large object space}, 
  year={2004},
  volume={},
  number={},
  pages={225-234},
  abstract={Software DSM provides good programmability for cluster computing, but its performance and limited shared memory space for large applications hinder its popularity. This paper introduces LOTS, a C++ runtime library supporting a large shared object space. With its dynamic memory mapping mechanism, LOTS can map more objects, lazily from the local disk to the virtual memory during access, leaving only a trace of control information for each object in the local process space. To our knowledge, LOTS is the first pure runtime software DSM supporting a shared object space larger than the local process space. Our testing shows that LOTS can utilize all the free hard disk space available to support hundreds of gigabytes of shared objects with a small overhead. The scope consistency memory model and a mixed coherence protocol allow LOTS to achieve better scalability with respect to problem size and cluster size.},
  keywords={},
  doi={10.1109/CLUSTR.2004.1392620},
  ISSN={1552-5244},
  month={Sep.},}
@INPROCEEDINGS{1392625,
  author={Morin, C. and Lottiaux, R. and Vallee, G. and Gallard, P. and Margery, D. and Berthou, J.-Y. and Scherson, I.D.},
  booktitle={2004 IEEE International Conference on Cluster Computing (IEEE Cat. No.04EX935)}, 
  title={Kerrighed and data parallelism: cluster computing on single system image operating systems}, 
  year={2004},
  volume={},
  number={},
  pages={277-286},
  abstract={A working single system image distributed operating system is presented. Dubbed Kerrighed, it provides a unified approach and support to both the MPI and the shared memory programming models. The system is operational in a 16-processor cluster at the Institut de Recherche en Informatique et Systemes Aleatoires in Rennes, France. In this paper, the system is described with emphasis on its main contributing and distinguishing factors, namely its DSM based on memory containers, its flexible handling of scheduling and checkpointing strategies, and its efficient and unified communications layer. Because of the importance and popularity of data parallel applications in these systems, we present a brief discussion of the mapping of two well known and established data parallel algorithms. It is shown that ShearSort is remarkably well suited for the architecture/system pair as is the ever so popular and important two-dimensional fast Fourier transform. (2D FFT).},
  keywords={},
  doi={10.1109/CLUSTR.2004.1392625},
  ISSN={1552-5244},
  month={Sep.},}

@INPROCEEDINGS{1392639,
  author={Goes, L.F.W. and Ramos, L.E.S. and Martins, C.A.P.S.},
  booktitle={2004 IEEE International Conference on Cluster Computing (IEEE Cat. No.04EX935)}, 
  title={ClusterSim: a Java-based parallel discrete-event simulation tool for cluster computing}, 
  year={2004},
  volume={},
  number={},
  pages={401-410},
  abstract={We present the proposal and implementation of a Java-based parallel discrete-event simulation tool for cluster computing called ClusterSim (cluster simulation tool). The ClusterSim supports visual modeling and simulation of clusters and their workloads for performance analysis. A cluster is composed of single or multiprocessed nodes, parallel job schedulers, network topologies and technologies. A workload is represented by users that submit jobs composed of tasks described by probability' distributions and their internal structure (CPU, I/O and MPI instructions). Our main objectives in This work: to present the proposal and implementations of the software architecture and simulation model of ClusterSim; to verify and validate ClusterSim; to analyze ClusterSim by means of a case study. Our main contributions are: the proposal and implementation of ClusterSim with an hybrid workload model, a graphical environment, the modeling of heterogeneous clusters and a statistical and performance module.},
  keywords={},
  doi={10.1109/CLUSTR.2004.1392639},
  ISSN={1552-5244},
  month={Sep.},}
@INPROCEEDINGS{1395181,
  author={Fernandes, S.F.L. and Silva, W.J. and Silva, M.J.C. and Rosa, N.S. and Maciel, P.R.M. and Sadok, D.F.H.},
  booktitle={IEEE International Conference on Performance, Computing, and Communications, 2004}, 
  title={On the generalised stochastic Petri net modeling of message-oriented middleware systems}, 
  year={2004},
  volume={},
  number={},
  pages={783-788},
  abstract={This paper presents how to model and carry out the performance analysis of message-oriented middleware (MOM) using generalised stochastic Petri Net (GSPN) models. The results obtained from the Petri net analysis are compared against ones measured in a commercial MOM. Additionally, some results are presented in order to demonstrate the flexibility and the benefits of the proposed model. This research also focuses on how to improve the MOM performance by suggesting appropriated techniques and adjustments to the MOM basic architecture. Finally, we point out some decisions usually taken by systems administrators that may have a major impact on the performance of MOM systems.},
  keywords={},
  doi={10.1109/PCCC.2004.1395181},
  ISSN={},
  month={April},}
@INPROCEEDINGS{1281621,
  author={Raynal, M. and Krishnamurthy Vidyasankar},
  booktitle={24th International Conference on Distributed Computing Systems, 2004. Proceedings.}, 
  title={A distributed implementation of sequential consistency with multi-object operations}, 
  year={2004},
  volume={},
  number={},
  pages={544-551},
  abstract={Sequential consistency is a consistency criterion for concurrent objects stating that the execution of a multiprocess program is correct if it could have been produced by executing the program on a mono-processor system, preserving the order of the operations of each individual process. Several protocols implementing sequential consistency on top of asynchronous distributed systems have been proposed. They assume that the processes access the shared objects through basic read and write operations. We consider the case where the processes can invoke multiobject operations which can read or write several objects in a single operation atomically. It proposes a particularly simple protocol that guarantees sequentially consistent executions in such a context. The previous sequential consistency protocols, in addition to considering only unary operations, assume either full replication or a central manager storing copies of all the objects. In contrast, the proposed protocol has the noteworthy feature that each object has a separate manager. Interestingly, this provides the protocol with a versatility dimension that allows deriving simple protocols providing sequential consistency or atomic consistency when each operation is on a single object.},
  keywords={},
  doi={10.1109/ICDCS.2004.1281621},
  ISSN={1063-6927},
  month={March},}
@INPROCEEDINGS{1400744,
  author={Shuang Quan Li and Huo Yan Chen and Yu Xia Sun},
  booktitle={2004 IEEE International Conference on Systems, Man and Cybernetics (IEEE Cat. No.04CH37583)}, 
  title={A framework of reachability testing for Java multithread programs}, 
  year={2004},
  volume={3},
  number={},
  pages={2730-2734 vol.3},
  abstract={The nondeterministic behavior of concurrent software makes the results of its running and testing uncertain. So it is difficult to debug and test concurrent software. Reachability testing is an effective method for concurrent software testing. This paper presents a framework for selecting synchronization sequences from Java multithread program based on the analysis of reading and writing shared variables. Our framework consists of a strategy for generating synchronization sequence set of reachability testing, and an approach for deterministic testing of the synchronization sequences. A prototype for reachability testing of Java multithread program has been developed. In the prototype, a dynamic proxy class is used to implement a deterministic testing framework of Java multithread program.},
  keywords={},
  doi={10.1109/ICSMC.2004.1400744},
  ISSN={1062-922X},
  month={Oct},}
@INPROCEEDINGS{1403842,
  author={Zhong, W. and Altun, G. and Tian, X. and Harrison, R. and Tai, P.C. and Pan, Y.},
  booktitle={The 26th Annual International Conference of the IEEE Engineering in Medicine and Biology Society}, 
  title={Parallel protein secondary structure prediction based on neural networks}, 
  year={2004},
  volume={2},
  number={},
  pages={2968-2971},
  abstract={Protein secondary structure prediction has a fundamental influence on today's bioinformatics research. In this work, binary and tertiary classifiers of protein secondary structure prediction are implemented on Denoeux belief neural network (DBNN) architecture. Hydrophobicity matrix, orthogonal matrix, BLOSUM62 and PSSM (position specific scoring matrix) are experimented separately as the encoding schemes for DBNN. The experimental results contribute to the design of new encoding schemes. New binary classifier for Helix versus not Helix (/spl sim/H) for DBNN produces prediction accuracy of 87% when PSSM is used for the input profile. The performance of DBNN binary classifier is comparable to other best prediction methods. The good test results for binary classifiers open a new approach for protein structure prediction with neural networks. Due to the time consuming task of training the neural networks, Pthread and OpenMP are employed to parallelize DBNN in the hyperthreading enabled Intel architecture. Speedup for 16 Pthreads is 4.9 and speedup for 16 OpenMP threads is 4 in the 4 processors shared memory architecture. Both speedup performance of OpenMP and Pthread is superior to that of other research. With the new parallel training algorithm, thousands of amino acids can be processed in reasonable amount of time. Our research also shows that hyperthreading technology for Intel architecture is efficient for parallel biological algorithms.},
  keywords={},
  doi={10.1109/IEMBS.2004.1403842},
  ISSN={},
  month={Sep.},}
@INPROCEEDINGS{1397596,
  author={McNaughton, G.A. and Gordon, M.E.},
  booktitle={IEEE PES Power Systems Conference and Exposition, 2004.}, 
  title={MultiSpeak/spl reg/2-a framework for real-time utility software integration}, 
  year={2004},
  volume={},
  number={},
  pages={1645-1650 vol.3},
  abstract={Effective integration of software has been an elusive goal for electric utilities for many years. Integration, particularly among operations applications-such as supervisory control and data acquisition (SCADA), automated meter reading (AMR), outage management (OMS), and load management (LM) systems-has been particularly difficult. Such integration, where possible at all, has often required costly custom programming. The expense and complexity of custom integration has often prohibited electric distribution utilities from achieving successful interaction among operations applications. The MultiSpeak/spl reg/ Initiative is a collaborative effort by software vendors, sponsored by the cooperative research network of the National Rural Electric Cooperative Association. The Initiative has developed a specification that defines how a wide variety of application software provided by different vendors can be integrated in a platform, database, and operating system-independent manner. This is done using a real-time messaging framework and standard information systems protocols. This paper discusses the implementation of the application interfaces and the real-time messaging framework. It also discusses how the vendor-developed interfaces are tested for compliance with the specification.},
  keywords={},
  doi={10.1109/PSCE.2004.1397596},
  ISSN={},
  month={Oct},}
@INPROCEEDINGS{1420874,
  author={Valisetty, R. and Cheung, P. and Namburu, R.},
  booktitle={2004 Users Group Conference (DOD_UGC'04)}, 
  title={Scalable coupling of multi-scale AEH and PARADYN impact analyses}, 
  year={2004},
  volume={},
  number={},
  pages={222-226},
  abstract={This work describes scalable coupling of two stand alone computer codes for multiscale impact analysis of composites. An asymptotic expansion homogenization (AEH) based microstructural code available for modeling microstructural aspects of modern armor materials is coupled with PARADYN, a parallel explicit Lagrangian finite element code. The first code enables modeling of material microstructures in simple loading situations in stand-alone form. The coupling of this code to PARADYN, which is a parallel version of the Lawrence Livermore National Laboratory (LLNL)'s serial DYNA3D, enables a micro-macro type multiscale analysis of large elastic-plastic deformation response of structures under generalized three dimensional impact conditions. Three sets of results are presented to demonstrate: 1) the verification of the AEH-PARADYN model coupling to PARADYN, 2) validation of the AEH, and 3) the scalability of the coupled model.},
  keywords={},
  doi={10.1109/DOD_UGC.2004.41},
  ISSN={},
  month={June},}
@INPROCEEDINGS{1420890,
  author={Ruyten, W. and Sisson, W.E.},
  booktitle={2004 Users Group Conference (DOD_UGC'04)}, 
  title={Message passing for parallel processing of pressure-sensitive paint images}, 
  year={2004},
  volume={},
  number={},
  pages={308-312},
  abstract={A message-passing scheme is described that allows parallel processing of pressure-sensitive paint images on a machine with multiple processors or a cluster with multiple nodes. The scheme implements the use of forks and pipes in the former case and socket-based TCP/IP communications in the latter. The approach demonstrates how multiple copies of a nonparallel legacy code (in this case, NASA's Green Boot software) can be made to run in parallel in either a parent-child or a client-server configuration. Results are presented for benchmark data from wind tunnel tests of an F-16C fighter jet model and NASA's X-38 Crew Return Vehicle.},
  keywords={},
  doi={10.1109/DOD_UGC.2004.27},
  ISSN={},
  month={June},}
@ARTICLE{1347066,
  author={Lyu, M.R. and Xinyu Chen and Tsz Yeung Wong},
  journal={IEEE Intelligent Systems}, 
  title={Design and evaluation of a fault-tolerant mobile-agent system}, 
  year={2004},
  volume={19},
  number={5},
  pages={32-38},
  abstract={The mobile agents create a new paradigm for data exchange and resource sharing in rapidly growing and continually changing computer networks. In a distributed system, failures can occur in any software or hardware component. A mobile agent can get lost when its hosting server crashes during execution, or it can get dropped in a congested network. Therefore, survivability and fault tolerance are vital issues for deploying mobile-agent systems. This fault tolerance approach deploys three kinds of cooperating agents to detect server and agent failures and recover services in mobile-agent systems. An actual agent is a common mobile agent that performs specific computations for its owner. Witness agents monitor the actual agent and detect whether it's lost. A probe recovers the failed actual agent and the witness agents. A peer-to-peer message-passing mechanism stands between each actual agent and its witness agents to perform failure detection and recovery through time-bounded information exchange; a log records the actual agent's actions. When failures occur, the system performs rollback recovery to abort uncommitted actions. Moreover, our method uses checkpointed data to recover the lost actual agent.},
  keywords={},
  doi={10.1109/MIS.2004.40},
  ISSN={1941-1294},
  month={Sep.},}
@INPROCEEDINGS{1384706,
  author={Alanyali, M. and Venkatesh, S. and Savas, O. and Aeron, S.},
  booktitle={Proceedings of the 2004 American Control Conference}, 
  title={Distributed Bayesian hypothesis testing in sensor networks}, 
  year={2004},
  volume={6},
  number={},
  pages={5369-5374 vol.6},
  abstract={We consider the scenario of N distributed noisy sensors observing a single event. The sensors are distributed and can only exchange messages through a network. The sensor network is modelled by means of a graph, which captures the connectivity of different sensor nodes in the network. The task is to arrive at a consensus about the event after exchanging such messages. The focus of this paper is twofold: a) characterize conditions for reaching a consensus; b) derive conditions for when the consensus converges to the centralized MAP estimate. The novelty of the paper lies in applying belief propagation as a message passing strategy to solve a distributed hypothesis testing problem for a pre-specified network connectivity. We show that the message evolution can be re-formulated as the evolution of a linear dynamical system, which is primarily characterized by network connectivity. This leads to a fundamental understanding of as to which network topologies naturally lend themselves to consensus building and conflict avoidance.},
  keywords={},
  doi={10.23919/ACC.2004.1384706},
  ISSN={0743-1619},
  month={June},}
@INPROCEEDINGS{1429378,
  author={Graham, S. and Kumar, P.R.},
  booktitle={2004 43rd IEEE Conference on Decision and Control (CDC) (IEEE Cat. No.04CH37601)}, 
  title={Time in general-purpose control systems: the Control Time Protocol and an experimental evaluation}, 
  year={2004},
  volume={4},
  number={},
  pages={4004-4009 Vol.4},
  abstract={No two clocks generally agree. Distributed control applications, however, require accurate timing information. This necessitates some form of message passing for interpretation of distributed clocks. We exhibit a fundamental indeterminacy in estimating time when delays are unequal in the two directions, necessitating an assumption of symmetry. We present the Control Time Protocol as an architecturally clean algorithm for providing timing information in the domain of distributed control. The protocol introduces no additional dependencies beyond those already present in the very control loops, thus enhancing the reliability of the systems. It has been implemented on the testbed in the Convergence Laboratory at the University of Illinois. Experimental results demonstrating how time stamping can be used to enhance stability and performance, as well as measurements of network latencies, are provided.},
  keywords={},
  doi={10.1109/CDC.2004.1429378},
  ISSN={0191-2216},
  month={Dec},}
@INPROCEEDINGS{1414955,
  author={Kartawidjaja, M.A. and Suhartanto, H. and Basaruddin, T.},
  booktitle={2004 IEEE Region 10 Conference TENCON 2004.}, 
  title={Performance of a parallel technique for solving nonlinear systems arising from ODEs}, 
  year={2004},
  volume={D},
  number={},
  pages={403-406 Vol. 4},
  abstract={An inexact Newton method is commonly used to solve large nonlinear systems, arising for instance from simulating models in mathematics, chemistry and physics. In this paper, we propose an implementation of parallelization across the method in solving a nonlinear system, arising from Runge-Kutta method, which is a part of our work on ODE. We also implement parallelization across the system in solving the arising linear system, with the aim of investigating whether this will contribute to speedup to the whole process. We used two kinds of test problems related to ordinary differential equations (ODEs), i.e. Brusselator and Dense problems. The experiment was performed on a cluster of PCs with PVM message passing environment. Our observation shows that for Brusselator problem, using multiprocessors will result in a better performance in terms of speedup for sufficiently large data. For Dense problem, though we expect to have speedup more than two, the maximum attainable speedup is only two.},
  keywords={},
  doi={10.1109/TENCON.2004.1414955},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{1414655,
  author={Neogy, S. and Sinha, A. and Das, P.K.},
  booktitle={2004 IEEE Region 10 Conference TENCON 2004.}, 
  title={CCUML: a checkpointing protocol for distributed system processes}, 
  year={2004},
  volume={B},
  number={},
  pages={553-556 Vol. 2},
  abstract={This paper presents a checkpointing protocol CCUML-coordinated checkpointing with unacknowledged message logging. A checkpoint initiator initiates taking of checkpoints at the end of each checkpoint interval. Processes take local checkpoints only after being notified by the initiator. However, there is no central initiator, but each process takes turn to act as the initiator at each checkpoint initiation. The guaranty that no message would be lost in case of failure, has been brought about by maintaining a log of unacknowledged messages along with the latest checkpoint in a process. Since only unacknowledged messages are logged, the overhead is negligible. Thus, the distributed checkpointing protocol described here always ensures a consistent set of checkpoints from which processes can resume during recovery after a fault.},
  keywords={},
  doi={10.1109/TENCON.2004.1414655},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{1432393,
  author={Balduino, L. and Alves, A.C.B.},
  booktitle={2004 IEEE/PES Transmision and Distribution Conference and Exposition: Latin America (IEEE Cat. No. 04EX956)}, 
  title={Parallel processing in a cluster of microcomputers with application in contingency analysis}, 
  year={2004},
  volume={},
  number={},
  pages={285-290},
  abstract={This work is about the use of a microcomputer network as a parallel processing environment. In order to allow the communication, the synchronization and the distribution of the tasks among processes, the PVM (parallel virtual machine) and MPI (message passing interface) systems, were used. These computational systems allowed for parallel processing in the area of electric power systems, namely the contingency analysis. This application, usually found in energy management systems, requires the use of a large quantity of resources in a short time. The aim is to analyze thousands of disturbance scenarios, in a preventive mode in real time. Two parallel programming paradigms classified as Master/Slave, in the synchronous and asynchronous modes, were implemented. Case studies with sequential and parallel implementations were carried out to validate the algorithms used to analyze elaborated contingencies, including the use of data from the interconnected Brazilian electric power system, allowing the analysis of single and multiple disturbances.},
  keywords={},
  doi={10.1109/TDC.2004.1432393},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{1433875,
  author={Dominguez-Dominguez, S. and Buenabad-Chavez, J.},
  booktitle={(ICEEE). 1st International Conference on Electrical and Electronics Engineering, 2004.}, 
  title={Distributed parallel file system for I/O intensive parallel computing on clusters}, 
  year={2004},
  volume={},
  number={},
  pages={194-199},
  abstract={Local area networks are now widely used to run parallel applications. They are particularly suitable to run I/O intensive applications, because each node usually includes disk space. However, programming these applications is rather difficult. The programmer must partition data into disk nudes and, at run time, transfer data from disk space into the memory of each node that uses the data and vice versa. Also, such partitioning gives data a fixed location in disk space, and is usually not adequate for performance because processors do not access mostly data in their local memory or disk, but on disk space in remote nodes. This paper presents a distributed parallel file system that both eases the programming and improves the performance of parallel I/O intensive applications. Our file system eases programming through mapping into memory files of size up to hundreds of Giga bytes. It improves performance through automatically diffusing, or migrating and replicating, data in files to the local memory or local disk of the processors that use the data. Data diffusion occurs under a multiple-readers-single-writer protocol. On applications tested the performance gain can be up to 20 % compared to versions using the MPI file system. },
  keywords={},
  doi={10.1109/ICEEE.2004.1433875},
  ISSN={},
  month={Sep.},}
@INPROCEEDINGS{1433805,
  author={Fanucci, L. and Rossi, F.},
  booktitle={Proceedings of the Fourth IEEE International Symposium on Signal Processing and Information Technology, 2004.}, 
  title={A throughput/complexity analysis for the VLSI implementation of LDPC decoder}, 
  year={2004},
  volume={},
  number={},
  pages={409-412},
  abstract={This paper presents an analysis of the VLSI complexity of different LDPC decoder implementations. Both fully parallel and serial solutions are considered and compared in terms of architectural issues, hardware complexity, power consumption and supported throughput. To provide numeric results a 1/2 rate, (3,6) regular LDPC code with a 2048 codeword has been considered and area complexity estimations have been carried out with reference to a 0.18 /spl mu/m standard-cell CMOS technology.},
  keywords={},
  doi={10.1109/ISSPIT.2004.1433805},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{1439282,
  author={Berlin, P. and Tuninetti, D.},
  booktitle={IEEE 5th Workshop on Signal Processing Advances in Wireless Communications, 2004.}, 
  title={LDPC codes for Gaussian broadcast channels}, 
  year={2004},
  volume={},
  number={},
  pages={444-448},
  abstract={We study coding over a class of two-user broadcast channels with additive white Gaussian noise and fading known at the receivers only. Joint decoding of low-density parity-check codes is analyzed. The message update rule at the mapping node linking the users' codes is derived and is shown to exhibit an interesting soft interference cancellation property. Good degree distributions are found using the differential evolution optimization technique and extrinsic information transfer analysis. The corresponding codes have rates close to the boundary of the achievable region for binary constrained input channels, both with and without fading. Simulation results for moderate blocklength show that the optimized codes operate within 1 dB of their thresholds.},
  keywords={},
  doi={10.1109/SPAWC.2004.1439282},
  ISSN={},
  month={July},}
@INPROCEEDINGS{1439171,
  author={Malema, G. and Liebelt, M.},
  booktitle={Proceedings of 2004 International Symposium on Intelligent Signal Processing and Communication Systems, 2004. ISPACS 2004.}, 
  title={Programmable low-density parity-check decoder}, 
  year={2004},
  volume={},
  number={},
  pages={801-804},
  abstract={This paper presents a programmable semi-parallel architecture for low-density parity-check (LDPC) codes. Communication conflicts are avoided by edge-coloring the code graph and grouping of edges/physical connections by color. The architecture model is easily scalable and programmable for larger block sizes. Though the communication hardware cost is high, the model can be easily reconfigured to reduce hardware cost at the expense of flexibility in code design and decoding performance. The hardware cost, latency, code flexibility and code performance tradeoffs can be varied over a wide range to suit a wide range of applications. Simple execution control and mapping are other advantages of this model. A behavioral VHDL implementation was developed to verify the functionality of the architecture.},
  keywords={},
  doi={10.1109/ISPACS.2004.1439171},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{1459298,
  author={Fang Wu and ErPing Li and Zaw Zaw Oo and Yaojiang Zhang},
  booktitle={Proceedings. ICCEA 2004. 2004 3rd International Conference on Computational Electromagnetics and Its Applications, 2004.}, 
  title={Parallel multilevel fast multipole method for solving large scale electromagnetic problems [radar cross section problems]}, 
  year={2004},
  volume={},
  number={},
  pages={96-99},
  abstract={The parallel multilevel fast multipole method (MLFMM) is an efficient computational algorithm for solving large-scale radar cross section (RCS) problems. The code is developed and implemented on massively parallel, distributed memory computer systems. The multilevel grouping structure is partitioned carefully to separate computational tasks and reduce data communication. A message passing interface (MPI) is employed to perform the data transfer and support the matrix-vector product in the parallel iterative procedure. The accuracy of the code is verified by comparison with results of a benchmark target. The computational complexity and efficiency of the parallel MLFMM is discussed.},
  keywords={},
  doi={10.1109/ICCEA.2004.1459298},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{1459856,
  author={Chaki, S. and Clarke, E. and Ouaknine, J. and Sharygina, N.},
  booktitle={Proceedings. Second ACM and IEEE International Conference on Formal Methods and Models for Co-Design, 2004. MEMOCODE '04.}, 
  title={Automated, compositional and iterative deadlock detection}, 
  year={2004},
  volume={},
  number={},
  pages={201-210},
  abstract={We present an algorithm to detect deadlocks in concurrent message-passing programs. Even though deadlock is inherently noncompositional and its absence is not preserved by standard abstractions, our framework employs both abstraction and compositional reasoning to alleviate the state space explosion problem. We iteratively construct increasingly more precise abstractions on the basis of spurious counterexamples to either detect a deadlock or prove that no deadlock exists. Our approach is inspired by the counterexample-guided abstraction refinement paradigm. However, our notion of abstraction as well as our schemes for verification and abstraction refinement differs in key respects from existing abstraction refinement frameworks. Our algorithm is also compositional in that abstraction, counterexample validation, and refinement are all carried out component-wise and do not require the construction of the complete state space of the concrete system under consideration. Finally, our approach is completely automated and provides diagnostic feedback in case a deadlock is detected. We have implemented our technique in the MAGIC verification tool and present encouraging results (up to 20 times speed-up in time and 4 times less memory consumption) with concurrent message-passing C programs. We also report a bug in the real-time operating system MicroC/OS version 2.70.},
  keywords={},
  doi={10.1109/MEMCOD.2004.1459856},
  ISSN={},
  month={June},}
@INPROCEEDINGS{1459815,
  author={Baier, C. and Ciesinski, F. and Grosser, M.},
  booktitle={Proceedings. Second ACM and IEEE International Conference on Formal Methods and Models for Co-Design, 2004. MEMOCODE '04.}, 
  title={PROBMELA: a modeling language for communicating probabilistic processes}, 
  year={2004},
  volume={},
  number={},
  pages={57-66},
  abstract={Building automated tools to address the analysis of reactive probabilistic systems requires a simple, but expressive input language with a formal semantics based on a probabilistic operational model that can serve as starting point for verification algorithms. We introduce for probabilistic parallel programs with shared variables, message passing via synchronous and (perfect or lossy) fifo channels and atomic regions and provide a structured operational semantics. Applied to finite-state systems, the semantics can serve as basis for the algorithmic generation of a Markov decision process that models the stepwise behavior of the given system.},
  keywords={},
  doi={10.1109/MEMCOD.2004.1459815},
  ISSN={},
  month={June},}
@INPROCEEDINGS{1493276,
  author={Abbasfar, A. and Divsalar, D. and Kung Yao},
  booktitle={IEEE MILCOM 2004. Military Communications Conference, 2004.}, 
  title={A class of turbo-like codes with efficient and practical high-speed decoders}, 
  year={2004},
  volume={1},
  number={},
  pages={245-250 Vol. 1},
  abstract={Turbo-like codes not only achieve near Shannon-capacity performance, but also have decoders with modest complexity, which is crucial for implementation. Recently some efficient architectures for high-speed decoding of turbo and LDPC codes have been presented in the literature. The memory access is the main problem in practical implementation of such decoders. This problem has also been solved by using interleaves with special structure. In this paper, a generalized class of turbo-like codes that have high-speed decoding capability, which is based on the graphical interpretation of their code, is introduced. It has been shown that previous codes are part of this class. This class of codes not only provides code structure for parallel processing, but also provides the interleaver structure for practical implementation. A general architecture for high-speed decoding of these codes is presented. Regularity and modularity of the decoder makes it the architecture of choice for VLSI implementation of very high-speed decoders.},
  keywords={},
  doi={10.1109/MILCOM.2004.1493276},
  ISSN={},
  month={Oct},}
@ARTICLE{1362635,
  author={Nguyen, G.D.},
  journal={IEEE Transactions on Computers}, 
  title={Error-detection codes: algorithms and fast implementation}, 
  year={2005},
  volume={54},
  number={1},
  pages={1-11},
  abstract={Binary CRCs are very effective for error detection, but their software implementation is not very efficient. Thus, many binary nonCRC codes (which are not as strong as CRCs, but can be more efficiently implemented in software) are proposed as alternatives to CRCs. The nonCRC codes include WSC, CXOR, one's-complement checksum, Fletcher checksum, and block-parity code. We present a general algorithm for constructing a family of binary error-detection codes. This family is large because it contains all these nonCRC codes, CRCs, perfect codes, as well as other linear and nonlinear codes. In addition to unifying these apparently disparate codes, our algorithm also generates some nonCRC codes that have minimum distance 4 (like CRCs) and efficient software implementation.},
  keywords={},
  doi={10.1109/TC.2005.7},
  ISSN={1557-9956},
  month={Jan},}
@INPROCEEDINGS{1395729,
  author={Cheong, E. and Liu, J.},
  booktitle={Design, Automation and Test in Europe}, 
  title={galsC: a language for event-driven embedded systems}, 
  year={2005},
  volume={},
  number={},
  pages={1050-1055 Vol. 2},
  abstract={We introduce galsC, a language designed for programming event-driven embedded systems such as sensor networks. galsC implements the TinyGALS (globally asynchronous and locally synchronous) programming model. At the local level, software components are linked via synchronous method calls to form actors. At the global level, actors communicate with each other asynchronously via message passing, which separates the flow of control between actors. A complementary model, called TinyGUYS, is a guarded yet synchronous model designed to allow thread-safe sharing of global state between actors via parameters without explicitly passing messages. The galsC compiler extends the nesC compiler, which allows for better type checking and code generation. Having a well-structured concurrency model at the application level greatly reduces the risk of concurrency errors, such as deadlock and race conditions. The galsC language is implemented on the Berkeley motes and is compatible with the TinyOS/nesC component library. We use a multi-hop wireless sensor network as an example to illustrate the effectiveness of the language.},
  keywords={},
  doi={10.1109/DATE.2005.165},
  ISSN={1558-1101},
  month={March},}
@INPROCEEDINGS{1395665,
  author={Francesco, P. and Antonio, P. and Marchal, P.},
  booktitle={Design, Automation and Test in Europe}, 
  title={Flexible hardware/software support for message passing on a distributed shared memory architecture}, 
  year={2005},
  volume={},
  number={},
  pages={736-741 Vol. 2},
  abstract={With the advent of multiprocessor systems on a chip, the interest for message passing libraries has revived. Message passing helps in mastering the design complexity of parallel systems. However to satisfy the stringent energy-budget of embedded applications, the message passing overhead should be limited. Recently, several hardware extensions have been proposed for reducing the transfer cost on a distributed memory architecture. Unfortunately, they ignore the synchronization cost between sender/receiver and/or require many dedicated hardware blocks. To overcome the above limitations, we present in this paper lightweight support for message passing. Moreover, we have made our library as flexible as possible such that we can optimally match the application with the target architecture. We demonstrate the benefits of our approach by means of representative benchmarks from the multimedia domain.},
  keywords={},
  doi={10.1109/DATE.2005.156},
  ISSN={1558-1101},
  month={March},}
@ARTICLE{1417070,
  author={Hao Zhong and Tong Zhang},
  journal={IEEE Transactions on Circuits and Systems I: Regular Papers}, 
  title={Block-LDPC: a practical LDPC coding system design approach}, 
  year={2005},
  volume={52},
  number={4},
  pages={766-775},
  abstract={This paper presents a joint low-density parity-check (LDPC) code-encoder-decoder design approach, called Block-LDPC, for practical LDPC coding system implementations. The key idea is to construct LDPC codes subject to certain hardware-oriented constraints that ensure the effective encoder and decoder hardware implementations. We develop a set of hardware-oriented constraints, subject to which a semi-random approach is used to construct Block-LDPC codes with good error-correcting performance. Correspondingly, we develop an efficient encoding strategy and a pipelined partially parallel Block-LDPC encoder architecture, and a partially parallel Block-LDPC decoder architecture. We present the estimation of Block-LDPC coding system implementation key metrics including the throughput and hardware complexity for both encoder and decoder. The good error-correcting performance of Block-LDPC codes has been demonstrated through computer simulations. With the effective encoder/decoder design and good error-correcting performance, Block-LDPC provides a promising vehicle for real-life LDPC coding system implementations.},
  keywords={},
  doi={10.1109/TCSI.2005.844113},
  ISSN={1558-0806},
  month={April},}
@INPROCEEDINGS{1402343,
  author={Takeuchi, Y. and Okamoto, T. and Yokoyama, K. and Matsuda, S.},
  booktitle={2005 IEEE International Conference on e-Technology, e-Commerce and e-Service}, 
  title={A differential-analysis approach for improving SOAP processing performance}, 
  year={2005},
  volume={},
  number={},
  pages={472-479},
  abstract={The performance of SOAP is lower than that of existing distributed object technologies such as RMI and CORBA, because SOAP needs extra process parsing and building message to process an XML document. Therefore, performance improvement for SOAP processing is challenge to apply SOAP to a high-performance system. In the case that we focus on SOAP message features, we notice a SOAP message format is pre-defined for each service program and the format does not change while the system is running. A little part of a SOAP message is variable and the rest that includes tag description is invariable. In this paper, we focus on the above features and we create a template from a SOAP message format. Our approach parses a SOAP message by analyzing differential between a SOAP message and the template. Our approach improves the performance to improve lexical analysis and validation while processing an XML document.},
  keywords={},
  doi={10.1109/EEE.2005.5},
  ISSN={},
  month={March},}
@INPROCEEDINGS{1405204,
  author={Piming Ma and Dongfeng Yuan},
  booktitle={Second IEEE Consumer Communications and Networking Conference, 2005. CCNC. 2005}, 
  title={Irregular LDPC coded BICM in image transmission over Rayleigh fading channel}, 
  year={2005},
  volume={},
  number={},
  pages={397-401},
  abstract={If the degree distribution is chosen carefully, the irregular LDPC codes can outperform the regular ones. In this paper, we proposed an LDPC coded BICM scheme in image transmission system to improve both efficiency and reliability. Simulation results show that LDPC codes are good coding schemes over fading channel in image communication. Simultaneously, irregular codes can obtain a code gain of about 0.7 dB than regular ones when BER is 10/sup -4/. So the irregular LDPC codes are more suitable for image transmission than the regular codes.},
  keywords={},
  doi={10.1109/CCNC.2005.1405204},
  ISSN={2331-9860},
  month={Jan},}
@INPROCEEDINGS{1420226,
  author={Pjesivac-Grbovic, J. and Angskun, T. and Bosilca, G. and Fagg, G.E. and Gabriel, E. and Dongarra, J.J.},
  booktitle={19th IEEE International Parallel and Distributed Processing Symposium}, 
  title={Performance analysis of MPI collective operations}, 
  year={2005},
  volume={},
  number={},
  pages={8 pp.-},
  abstract={Previous studies of application usage show that the performance of collective communications are critical for high-performance computing and are often overlooked when compared to the point-to-point performance. In this paper, we analyze and attempt to improve intra-cluster collective communication in the context of the widely deployed MPI programming paradigm by extending accepted models of point-to-point communication, such as Hockney, LogP/LogGP, and PLogP. The predictions from the models were compared to the experimentally gathered data and our findings were used to optimize the implementation of collective operations in the FT-MPI library.},
  keywords={},
  doi={10.1109/IPDPS.2005.335},
  ISSN={1530-2075},
  month={April},}
@INPROCEEDINGS{1419817,
  author={Freeh, V.W. and Feng Pan and Kappiah, N. and Lowenthal, D.K. and Springer, R.},
  booktitle={19th IEEE International Parallel and Distributed Processing Symposium}, 
  title={Exploring the energy-time tradeoff in MPI programs on a power-scalable cluster}, 
  year={2005},
  volume={},
  number={},
  pages={10 pp.-},
  abstract={Recently, energy has become an important issue in high-performance computing. For example, supercomputers that have energy in mind, such as BlueGene/L, have been built; the idea is to improve the energy efficiency of nodes. Our approach, which uses off-the-shelf, high-performance cluster nodes that are frequency scalable, allows energy saving by scaling down the CPU. This paper investigates the energy consumption and execution time of applications from a standard benchmark suite (NAS) on a power-scalable cluster. We study via direct measurement and simulation both intra-node and inter-node effects of memory and communication bottlenecks, respectively. Additionally, we compare energy consumption and execution time across different numbers of nodes. Our results show that a power-scalable cluster has the potential to save energy by scaling the processor down to lower energy levels. Furthermore, we found that for some programs, it is possible to both consume less energy and execute in less time when using a larger number of nodes, each at reduced energy. Additionally, we developed and validated a model that enables us to predict the energy-time tradeoff of larger clusters.},
  keywords={},
  doi={10.1109/IPDPS.2005.214},
  ISSN={1530-2075},
  month={April},}
@INPROCEEDINGS{1419925,
  author={Bouteiller, A. and Collin, B. and Herault, T. and Lemarinier, P. and Cappello, F.},
  booktitle={19th IEEE International Parallel and Distributed Processing Symposium}, 
  title={Impact of event logger on causal message logging protocols for fault tolerant MPI}, 
  year={2005},
  volume={},
  number={},
  pages={10 pp.-},
  abstract={Fault tolerance in MPI becomes a main issue in the HPC community. Several approaches are envisioned from user or programmer controlled fault tolerance to fully automatic fault detection and handling. For this last approach, several protocols have been proposed in the literature. In a recent paper, we have demonstrated that uncoordinated checkpointing tolerates higher fault frequency than coordinated checkpointing. Moreover causal message logging protocols have been proved the most efficient message logging technique. These protocols consist in piggybacking non deterministic events to computation message. Several protocols have been proposed in the literature. Their merits are usually evaluated from four metrics: a) piggybacking computation cost, b) piggyback size, c) applications performance and d) fault recovery performance. In this paper, we investigate the benefit of using a stable storage for logging message events in causal message logging protocols. To evaluate the advantage of this technique we implemented three protocols: 1) a classical causal message protocol proposed in Manetho, 2) a state of the art protocol known as LogOn, 3) a light computation cost protocol called Vcausal. We demonstrate a major impact of this stable storage for the three protocols, on the four criteria for micro benchmarks as well as for the NAS benchmark.},
  keywords={},
  doi={10.1109/IPDPS.2005.249},
  ISSN={1530-2075},
  month={April},}
@INPROCEEDINGS{1419959,
  author={Peng, Z. and Lastovetsky, A.},
  booktitle={19th IEEE International Parallel and Distributed Processing Symposium}, 
  title={Event logging: portable and efficient checkpointing in heterogeneous environments with non-FIFO communication platforms}, 
  year={2005},
  volume={},
  number={},
  pages={15 pp.-},
  abstract={The Chandy-Lamport checkpointing algorithm is widely used in fault tolerant implementations of MPI. However, it assumes the FIFO property of message passing, which is not guaranteed by the MPI standard at the application level. Therefore, this algorithm cannot serve as a basis for an implementation-independent fault tolerant MPI. In this paper, we present a variant of the Chandy-Lamport algorithm that does not rely on the FIFO property. This algorithm can be implemented on top of MPI and, hence, used for development of a supplement software component enabling the fault tolerance of any MPI implementation compliant with the MPI standard. We prove the correctness of the algorithm and analyze its performance. Experimental results demonstrating the efficiency of the algorithm are also presented.},
  keywords={},
  doi={10.1109/IPDPS.2005.207},
  ISSN={1530-2075},
  month={April},}
@INPROCEEDINGS{1419953,
  author={Banicescu, I. and Carino, R.L. and Pabico, J.P. and Balasubramaniam, M.},
  booktitle={19th IEEE International Parallel and Distributed Processing Symposium}, 
  title={Overhead analysis of a dynamic load balancing library for cluster computing}, 
  year={2005},
  volume={},
  number={},
  pages={10 pp.-},
  abstract={This paper investigates the overhead of a dynamic load balancing library for large irregular data-parallel scientific applications on general-purpose clusters. The library is based on an integrated approach combining the advantages of novel dynamic loop scheduling strategies as data migration policies with the advances in resource management and task migration capabilities offered by a recently developed parallel runtime system. The paper focuses on the contribution of the runtime system software layer to the total overhead of the library. Experiments to compare the performance of two applications using the library, the N-body simulations and the profiling of a quadrature routine, with the performance of the same applications using an MPI-only implementation of the dynamic scheduling techniques indicate only a slight decrease in performance due to the overhead of the runtime system software layer. The results validate the suitability of the runtime system as an implementation platform for dynamic load balancing schemes, and underscore the significance of using the integrated approach, as well as the benefits of using the library especially in cluster applications characterized by irregular and unpredictable behavior.},
  keywords={},
  doi={10.1109/IPDPS.2005.320},
  ISSN={1530-2075},
  month={April},}
@INPROCEEDINGS{1420054,
  author={Zhang, Y. and Tipparaju, V. and Nieplocha, J. and Hariri, S.},
  booktitle={19th IEEE International Parallel and Distributed Processing Symposium}, 
  title={Parallelization of the NAS Conjugate Gradient benchmark using the global arrays shared memory programming model}, 
  year={2005},
  volume={},
  number={},
  pages={8 pp.-},
  abstract={The NAS Conjugate Gradient (CG) benchmark is an important scientific kernel used to evaluate machine performance and compare characteristics of different programming models. Global Arrays (GA) toolkit supports a shared memory programming paradigm and offers the programmer control over the distribution and locality that are important for optimizing performance on scalable architectures. In this paper, we describe and compare two different parallelization strategies of the CG benchmark using GA and report performance results on a shared-memory system as well as on a cluster. Performance benefits of using shared memory for irregular/sparse computations have been demonstrated before in the context of the CG benchmark using OpenMP. Similarly, the GA implementation outperforms the standard MPI implementation on shared memory system, in our case the SGI Altix. However, with GA these benefits are extended to distributed memory systems and demonstrated on a Linux cluster with Myrinet.},
  keywords={},
  doi={10.1109/IPDPS.2005.331},
  ISSN={1530-2075},
  month={April},}
@INPROCEEDINGS{1420065,
  author={Caromel, D. and di Costanzo, A. and Gannon, D. and Slominski, A.},
  booktitle={19th IEEE International Parallel and Distributed Processing Symposium}, 
  title={Asynchronous peer-to-peer Web services and firewalls}, 
  year={2005},
  volume={},
  number={},
  pages={6 pp.-},
  abstract={In this paper we test the suitability of Java to implement a scalable Web Service that solves a set of problems related to peer-to-peer interactions between Web Services that are behind firewalls or not generally accessible. In particular we describe how to enable reliable and long running conversations through firewalls between Web Service peers that have no accessible network endpoints. Our solution is to implement in Java a Web services dispatcher (WSD) that is an intermediary service that forwards messages and can facilitate message exchanges by supporting SOAP RPC over HTTP and WS-addressing for asynchronous messaging. We describe how Web service clients that have no network endpoints, such as applets, can become Web Service peers by using an additional message store-and-forward service ("mailbox"). Then we conduct a set of experiments to evaluate performance of Java implementation in realistic Web Service scenarios, involving intercontinental tests between France and the US.},
  keywords={},
  doi={10.1109/IPDPS.2005.114},
  ISSN={1530-2075},
  month={April},}
@INPROCEEDINGS{1420063,
  author={Taboada, G.L. and Tourino, J. and Doallo, R.},
  booktitle={19th IEEE International Parallel and Distributed Processing Symposium}, 
  title={Designing efficient Java communications on clusters}, 
  year={2005},
  volume={},
  number={},
  pages={7 pp.-},
  abstract={This paper aims at designing communication strategies for parallel and distributed Java applications to obtain higher degrees of performance on clusters. Several specific approaches exist to increase the efficiency of Java communications, specially of high level APIs like RMI, although their applicability is relatively limited on clusters, since the development of high performance solutions on clusters usually involves the use of the basic Java Socket interface. This paper examines the current outlook of Java Socket optimisations involving both native and Java side issues in order to make a design proposal named Java Fast Sockets. We have accomplished a thorough analysis of the effects of the suggested configurations and implementations on our scalable coherent interface (SCI) testbed cluster. This evaluation has demonstrated that Java communication performance on clusters can compete with native performance.},
  keywords={},
  doi={10.1109/IPDPS.2005.164},
  ISSN={1530-2075},
  month={April},}
@INPROCEEDINGS{1420099,
  author={Babvey, S. and Bourgeois, A.G. and Fernandez-Zepeda, J.A. and McLaughlin, S.W.},
  booktitle={19th IEEE International Parallel and Distributed Processing Symposium}, 
  title={An efficient R-Mesh implementation of LDPC codes message-passing decoder}, 
  year={2005},
  volume={},
  number={},
  pages={8 pp.-},
  abstract={In this paper we propose a constant-time parallel algorithm for implementing the message-passing decoder of LDPC codes on a two dimensional R-Mesh, trying to keep the number of processors small. The R-Mesh provides dynamic reconfiguration, hardware reuse, and flexibility to problem changes. To decode a different code, we may simply set up the required connections between the bit-nodes and check-nodes by modifying the initialization phase of the R-Mesh algorithm. No extra wiring or hardware changes are required, as compared to other existing approaches. Moreover, the same hardware can implement the decoder in both probability and logarithm domains. We illustrate that the R-Mesh is an efficient model for parallel implementation of the decoder in terms of time complexity, flexibility to problem changes and simplicity of routing messages.},
  keywords={},
  doi={10.1109/IPDPS.2005.91},
  ISSN={1530-2075},
  month={April},}
@INPROCEEDINGS{1420112,
  author={Saletore, V.A. and Stillwell, P.M. and Wiegert, J.A. and Cayton, P. and Gray, J. and Regnier, G.J.},
  booktitle={19th IEEE International Parallel and Distributed Processing Symposium}, 
  title={Efficient direct user level sockets for an Intel/spl reg/ Xeon/spl trade/ processor based TCP on-load engine}, 
  year={2005},
  volume={},
  number={},
  pages={8 pp.-},
  abstract={Intel Labs has continued development of the embedded transport acceleration (ETA) software prototype that uses one of the Intel/spl reg/ Xeon/spl trade/ processors in a multi-processor server as a packet processing engine (PPE) that is closely tied to the server's core CPU and memory complex. We have further developed the prototype to provide support for user-level, asynchronous interface for sockets. The direct user socket interface (DUSI) allows user-level applications to interface directly to the PPE using familiar socket commands and semantics. The prototype runs in an asymmetric multiprocessing mode, in that the PPE does not run as a general computing resource for the host operating system. We describe the prototype software architecture, the DUSI application interface, and detail our measurement and analysis of some micro-benchmarks. In particular, we measure throughput for transactions and end-to-end latency as the key metrics for the analysis.},
  keywords={},
  doi={10.1109/IPDPS.2005.191},
  ISSN={1530-2075},
  month={April},}
@INPROCEEDINGS{1420205,
  author={Shao-Ming Yu and Yiming Li},
  booktitle={19th IEEE International Parallel and Distributed Processing Symposium}, 
  title={A pattern-based domain partition approach to parallel optical proximity correction in VLSI designs}, 
  year={2005},
  volume={},
  number={},
  pages={7 pp.-},
  abstract={A novel parallel optical proximity correction (OPC) technique is proposed for process distortion compensation of layout mask in design and fabrication of very large scale integration (VLSI) circuits. Based on a genetic algorithm (GA), rule- and model-based correction methods, and domain decomposition algorithms, a parallel OPC system is successfully developed for the layout mask correction of VLSI circuits on a Linux-based PC cluster with the message passing interface (MPI) libraries. Tested on several layout patterns, the implemented pattern-based partition scheme shows good accuracy for the OPC-corrected layout mask of VLSI designs. Computational and parallel benchmarks, such as speedup and efficiency, are achieved and exhibit excellent performance of the developed system. Our approach provides an alternative in developing advanced computer aided design (CAD) tools and benefits design and fabrication of system-on-chip (SoC).},
  keywords={},
  doi={10.1109/IPDPS.2005.56},
  ISSN={1530-2075},
  month={April},}
@INPROCEEDINGS{1423508,
  author={Chao-Tung Yang and Yi-Chun Hsiung and Heng-Chuan Kan},
  booktitle={19th International Conference on Advanced Information Networking and Applications (AINA'05) Volume 1 (AINA papers)}, 
  title={Implementation and evaluation of a Java based computational grid for bioinformatics applications}, 
  year={2005},
  volume={1},
  number={},
  pages={298-303 vol.1},
  abstract={In the present study, THUBioGrid, an experimental distributed computing application for bioinformatics (BioGrid) is proposed. THUBioGrid incorporates directory services (data and software), grid computing methods (security, authentication, data transport and remote jobs), and gene sequence/genomic data processing methods. It uses Java CoG Kit plus bioinformatics Java packages to perform various computational tasks. The performance of THUBioGrid has been tested by executing the FASTA and mpiBLAST programs for protein sequence alignment applications. Results demonstrate the speed-up effects with increasing number of processors used in the computations.},
  keywords={},
  doi={10.1109/AINA.2005.209},
  ISSN={2332-5658},
  month={March},}
@INPROCEEDINGS{1423734,
  author={Jahanshahi, M. and Mostafavi, K. and Kordafshari, M.S. and Gholipour, M. and Haghighat, A.T.},
  booktitle={19th International Conference on Advanced Information Networking and Applications (AINA'05) Volume 1 (AINA papers)}, 
  title={Two new approaches for orphan detection}, 
  year={2005},
  volume={2},
  number={},
  pages={461-464 vol.2},
  abstract={In distributed systems which use RPC, if a failed process sent a request before failing, the receiver of this request becomes an orphan process and must roll back to undo the effects of receiving the message. There are two types of orphan: one of them mostly called "crash- orphan" in which client crashes. Another which causes orphan process is called abort-orphan in which parent's process is aborted (Baumann and Rothermel). Orphans are undesirable because they waste system resources and can make inconsistent data (Herlihy and Mckendry, 1990). In this paper initially we present two novel methods for orphan detection. Finally we compare our new methods with the older ones.},
  keywords={},
  doi={10.1109/AINA.2005.334},
  ISSN={2332-5658},
  month={March},}
@ARTICLE{1425635,
  author={Chugg, K.M. and Mingrui Zhu},
  journal={IEEE Journal on Selected Areas in Communications}, 
  title={A new approach to rapid PN code acquisition using iterative message passing techniques}, 
  year={2005},
  volume={23},
  number={5},
  pages={884-897},
  abstract={Iterative message passing algorithms on graphs, which are generalized from the well-known turbo decoding algorithm, have been studied intensively in recent years because they can provide near-optimal performance and significant complexity reduction. In this paper, we demonstrate that this technique can be applied to pseudorandom code acquisition problems as well. To do this, we represent good pseudonoise (PN) patterns using sparse graphical models, then apply the standard iterative message passing algorithms over these graphs to approximate maximum-likelihood synchronization. Simulation results show that the proposed algorithm achieves better performance than both serial and hybrid search strategies in that it works at low signal-to-noise ratios and is much faster. Compared with full parallel search, this approach typically provides significant complexity reduction.},
  keywords={},
  doi={10.1109/JSAC.2005.845424},
  ISSN={1558-0008},
  month={May},}
@INPROCEEDINGS{1427059,
  author={Kleinmann, Karl and Wright, Todd},
  booktitle={International Conference on Integration of Knowledge Intensive Multi-Agent Systems, 2005.}, 
  title={Scalability aspects of agent-based naming services}, 
  year={2005},
  volume={},
  number={},
  pages={91-96},
  abstract={In this paper, we discuss the scalability of the White Pages (WP) service implementation of the Cougaar distributed agent architecture. We give an overview of its design and derive performance equations that provide a model-based estimate for both WP message counts and related message size in bytes. We present experimental results performed on two different agent societies of different scale to validate the performance equations. The experiments confirm the accuracy of the model and demonstrate the scalability of the design of the Cougaar WP naming service},
  keywords={},
  doi={10.1109/KIMAS.2005.1427059},
  ISSN={},
  month={April},}
@INPROCEEDINGS{1421074,
  author={Dovland, J. and Johnsen, E.B. and Owe, O.},
  booktitle={IEEE International Conference on Software - Science, Technology & Engineering (SwSTE'05)}, 
  title={Verification of concurrent objects with asynchronous method calls}, 
  year={2005},
  volume={},
  number={},
  pages={141-150},
  abstract={Current object-oriented approaches to distributed programs may be criticized in several respects. First, method calls are generally synchronous, which leads to much waiting in distributed and unstable networks. Second, the common model of thread concurrency makes reasoning about program behavior very challenging. A model based on concurrent objects communicating by means of asynchronous method calls has been proposed to combine object orientation and distribution in a more satisfactory way. This paper introduces a reasoning system for this model, focusing on simplicity and modularity. We believe that a simple and compositional proof system is paramount to allow verification of real programs. The proposed proof rules are derived from the Hoare rules of a standard sequential language by means of a semantic encoding preserving soundness and relative completeness.},
  keywords={},
  doi={10.1109/SWSTE.2005.24},
  ISSN={},
  month={Feb},}
@INPROCEEDINGS{1430062,
  author={Yang, J. and Goodwin, S.D.},
  booktitle={19th International Symposium on High Performance Computing Systems and Applications (HPCS'05)}, 
  title={High performance constraint satisfaction problem solving: state-recomputation versus state-copying}, 
  year={2005},
  volume={},
  number={},
  pages={117-123},
  abstract={Constraint satisfaction problems (CSPs) in artificial intelligence have been an important focus of research and have been a useful model for various applications. Most CSP solving techniques rely on a single processor. With the increasing popularization of multiple processors, parallel search methods are becoming alternatives to speed up search processing. In this paper, we present a forward checking algorithm that solves non-binary CSPs by distributing different branches of the search tree to different processors, i.e., an OR-parallel approach. However, the problem is how to efficiently communicate the state of the search among processors. Two parallel communication models, namely, state-recomputation and state-copying via message passing, are implemented and evaluated. The experimental results demonstrate that when constraints are tight, the state-recomputation model has better performance than the state-copying model, but when constraints are loose, the state-copying model is a better choice.},
  keywords={},
  doi={10.1109/HPCS.2005.30},
  ISSN={2378-2099},
  month={May},}
@INPROCEEDINGS{1425167,
  author={Shanmuganathan, G.S.R. and Zhang, K. and Wong, E. and Qi, Y.},
  booktitle={International Conference on Information Technology: Coding and Computing (ITCC'05) - Volume II}, 
  title={Analyzing message-passing programs through visual slicing}, 
  year={2005},
  volume={2},
  number={},
  pages={341-346 Vol. 2},
  abstract={Program slicing decomposes a large program into smaller sections that contain statements relevant to a computation under study. This paper presents a novel method for visual slicing of message passing programs. Each slice is computed based on predicates and focuses on inter-process messages that influence the predicate. A predicate slice is visualized based on the space-time diagram and captures some global requirements or suspected error properties of the distributed program. We have implemented the methods in Visper, an MPI-like message-passing environment that supports high level services such as check-pointing and fault tolerance.},
  keywords={},
  doi={10.1109/ITCC.2005.86},
  ISSN={},
  month={April},}
@INPROCEEDINGS{1434902,
  author={Babvey, S. and Bourgeois, A.G. and Fernandez-Zepeda, J.A. and McLaughlin, S.W.},
  booktitle={Sixth International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing and First ACIS International Workshop on Self-Assembling Wireless Network}, 
  title={A parallel implementation of the message-passing decoder of LDPC codes using a reconfigurable optical model}, 
  year={2005},
  volume={},
  number={},
  pages={288-293},
  abstract={In this paper we propose a constant-time algorithm for parallel implementation of the message-passing decoder of low density parity check (LDPC) codes on the linear array with a reconfigurable pipelined bus system (LARPBS), achieving the minimum number of processors required for a fully parallel implementation. Dynamic reconfiguration provides flexibility to code changes and efficient message routing. To decode a different code, we may simply set up the required connections between the bit-nodes and check-nodes by modifying the initialization phase of the LARPBS algorithm. No extra wiring or hardware changes are required, as compared to other existing approaches. Moreover, the same hardware can implement the decoder in both probability and logarithm domains. The LARPBS also allows reducing the number of the bus cycles required for processor communications to a small constant, regardless of the code length. We illustrate that the LARPBS is an efficient and fast model for implementing the decoder.},
  keywords={},
  doi={10.1109/SNPD-SAWN.2005.6},
  ISSN={},
  month={May},}
@INPROCEEDINGS{1452013,
  author={Kaji, I. and Kano, K.},
  booktitle={Proceedings Autonomous Decentralized Systems, 2005. ISADS 2005.}, 
  title={Considerations on transaction response time and configuration checking in autonomous decentralized DB (ADDS)}, 
  year={2005},
  volume={},
  number={},
  pages={33-40},
  abstract={In a distributed computing environment, the autonomous decentralized database system (ADDS) has been proposed to avoid the single point of failure. In ADDS, the update operations at each node are autonomously performed without communicating with other nodes if the amount of update requests are within the allowance volume (AV), thus the short response time of the transactions can be realized. Each node starts the AV adjustments when given AV amounts reach the threshold value, and gets the AV from relatively surplus nodes. To communicate with other nodes, there are two types of communications, one is a point to point (P2P) communication and the other is a mobile agent (MA) circulation. This paper discusses the relationship among the message amount, the configuration check frequency and the transaction response time in the P2P communication. We have defined the configuration checking frequency (f) that expresses how frequently a node confirms the configuration per AV request. It is expected that the value f which gives the minimum transaction response may exist. The simulator has been developed to evaluate the relationship and simulations have been performed in various parameters.},
  keywords={},
  doi={10.1109/ISADS.2005.1452013},
  ISSN={1541-0056},
  month={April},}
@INPROCEEDINGS{1443315,
  author={Lee, S. and Leaney, J. and O'Neill, T. and Hunter, M.},
  booktitle={Workshop on Principles of Advanced and Distributed Simulation (PADS'05)}, 
  title={Performance benchmark of a parallel and distributed network simulator}, 
  year={2005},
  volume={},
  number={},
  pages={101-108},
  abstract={Simulation of large-scale networks requires enormous amounts of memory and processing time. One way of speeding up these simulations is to distribute the model over a number of connected workstations. However, this introduces inefficiencies caused by the need for synchronization and message passing between machines. In distributed network simulation, one of the factors affecting message passing overhead is the amount of cross-traffic between machines. We perform an independent benchmark of the parallel/distributed network simulator (PDNS) based on experimental results processed at the Australian centre for advanced computing and communications (ACS) supercomputing cluster. We measure the effect of cross-traffic on wall-clock time needed to complete a simulation for a set of basic network topologies by comparing the result with the wall-clock time needed on a single processor. Our results show that although efficiency is reduced with large amounts of cross-traffic, speedup can still be achieved with PDNS. With these results, we developed a performance model that can be used as a guideline for designing future simulations.},
  keywords={},
  doi={10.1109/PADS.2005.19},
  ISSN={1087-4097},
  month={June},}
@ARTICLE{1459047,
  author={Pfister, H.D. and Sason, I. and Urbanke, R.},
  journal={IEEE Transactions on Information Theory}, 
  title={Capacity-achieving ensembles for the binary erasure channel with bounded complexity}, 
  year={2005},
  volume={51},
  number={7},
  pages={2352-2379},
  abstract={We present two sequences of ensembles of nonsystematic irregular repeat-accumulate (IRA) codes which asymptotically (as their block length tends to infinity) achieve capacity on the binary erasure channel (BEC) with bounded complexity per information bit. This is in contrast to all previous constructions of capacity-achieving sequences of ensembles whose complexity grows at least like the log of the inverse of the gap (in rate) to capacity. The new bounded complexity result is achieved by puncturing bits, and allowing in this way a sufficient number of state nodes in the Tanner graph representing the codes. We derive an information-theoretic lower bound on the decoding complexity of randomly punctured codes on graphs. The bound holds for every memoryless binary-input output-symmetric (MBIOS) channel and is refined for the binary erasure channel.},
  keywords={},
  doi={10.1109/TIT.2005.850079},
  ISSN={1557-9654},
  month={July},}
@INPROCEEDINGS{1465951,
  author={In-Cheol Park and Se-Hyeon Kang},
  booktitle={2005 IEEE International Symposium on Circuits and Systems (ISCAS)}, 
  title={Scheduling algorithm for partially parallel architecture of LDPC decoder by matrix permutation}, 
  year={2005},
  volume={},
  number={},
  pages={5778-5781 Vol. 6},
  abstract={The fully parallel LDPC decoding architecture can achieve high decoding throughput, but it suffers from large hardware complexity caused by a large set of processing units (PUs) and complex interconnections. A practical solution of area-efficient decoders is to use the partially parallel architecture in which a PU is shared for several rows or columns. It is important in the partially parallel architecture to determine the rows or columns to be processed in a PU and their processing order. The dependencies between rows and columns should be considered to minimize the overall processing time by overlapping the decoding operations. This paper proposes an efficient scheduling algorithm that can be applied to general LDPC codes, which is based on the concept of matrix permutation. Experimental results show that the proposed scheduling achieves a higher decoding rate, leading to a reduction of 25% processing time on average. A 1024-bit rate-1/2 LDPC decoder, employing the proposed scheduling algorithm, provides almost 1 Gbps decoding throughput and occupies one-fifth the area compared to the fully parallel decoder.},
  keywords={},
  doi={10.1109/ISCAS.2005.1465951},
  ISSN={2158-1525},
  month={May},}
@INPROCEEDINGS{1465953,
  author={Zhongfeng Wang and Qing-wei Jia},
  booktitle={2005 IEEE International Symposium on Circuits and Systems (ISCAS)}, 
  title={Low complexity, high speed decoder architecture for quasi-cyclic LDPC codes}, 
  year={2005},
  volume={},
  number={},
  pages={5786-5789 Vol. 6},
  abstract={This paper presents a low complexity, very high speed decoder architecture for quasi-cyclic low density parity check (QC-LDPC) codes, specifically Euclidian geometry (EG) based QC-LDPC codes. Algorithmic transformation and architectural level optimizations are employed to increase the clock speed. Enhanced partially parallel decoding architectures are proposed to linearly increase the overall throughput with the introduction of a small percentage of extra hardware. Based on the proposed architecture, a FPGA implementation of a (8176, 7154) EG-LDPC decoder can achieve a worst-case throughput of 169 Mbit/s.},
  keywords={},
  doi={10.1109/ISCAS.2005.1465953},
  ISSN={2158-1525},
  month={May},}
@INPROCEEDINGS{1467891,
  author={Peiyi Tang},
  booktitle={10th IEEE International Conference on Engineering of Complex Computer Systems (ICECCS'05)}, 
  title={Formal methods to generate parallel iterative codes for PDE-based applications}, 
  year={2005},
  volume={},
  number={},
  pages={106-115},
  abstract={Developing parallel software is far more complex than traditional sequential software. An effective approach to deal with the complexity of parallel software is domain-specific programming in an abstraction higher than general-purpose programming languages. In this paper, we focus on the domain of the applications based on partial differential equations (PDE) and provide a formal framework and methods for PDE compilers to generate parallel iterative codes for the domain. We also provide a PDE compiler optimization to minimize the number of messages between parallel processors. Our framework and methods can be used to build PDE compilers to generate efficient parallel software for PDE-based applications automatically.},
  keywords={},
  doi={10.1109/ICECCS.2005.46},
  ISSN={},
  month={June},}
@INPROCEEDINGS{1488630,
  author={Lawry, W.F. and Underwood, K.D.},
  booktitle={2005 International Conference on Parallel Processing (ICPP'05)}, 
  title={Considering the relative importance of network performance and network features}, 
  year={2005},
  volume={},
  number={},
  pages={329-337},
  abstract={Latency and bandwidth are usually considered to be the dominant factor in parallel application performance; however, recent studies have indicated that support for independent progress in MPI can also have a significant impact on application performance. This paper leverages the Cplant system at Sandia National Labs to compare a faster, vendor provided MPI library without independent progress to an internally developed MPI library that sacrifices some performance to provide independent progress. The results are surprising. Although some applications see significant negative impacts from the reduced network performance, others are more sensitive to the presence of independent progress.},
  keywords={},
  doi={10.1109/ICPP.2005.26},
  ISSN={2332-5690},
  month={June},}
@INPROCEEDINGS{1488686,
  author={Long Liu and Wei Hu and Chunrong Lai and Hong-shan Jiang and Wenguang Chen and Weimin Zheng and Yimin Zhang},
  booktitle={2005 International Conference on Parallel Processing Workshops (ICPPW'05)}, 
  title={Parallel module network learning on distributed memory multiprocessors}, 
  year={2005},
  volume={},
  number={},
  pages={129-134},
  abstract={As an extension of the Bayesian network, the module network is used in situations where there are many variables but only a small set of data available. However, using this network is still time-consuming. In this paper, the authors proposed a parallel implementation of the module network, a less time-consuming, learning algorithm based on the message-passing model. In order to solve the load-imbalance problem introduced by either result caching or intrinsic computation, a grouping strategy was proposed, which groups computations by modules and then distributes them cyclically. The algorithm was tested on eight 4-way Intel Xeon multiprocessors. Speedups of 29.26 on 32 processors have been observed. The result shows that our algorithm is effective.},
  keywords={},
  doi={10.1109/ICPPW.2005.66},
  ISSN={2332-5690},
  month={June},}
@INPROCEEDINGS{1488681,
  author={Katz, D.S. and Jacob, J.C. and Deelman, E. and Kesselman, C. and Gurmeet Singh and Mei-Hui Su and Berriman, G.B. and Good, J. and Laity, A.C. and Prince, T.A.},
  booktitle={2005 International Conference on Parallel Processing Workshops (ICPPW'05)}, 
  title={A comparison of two methods for building astronomical image mosaics on a grid}, 
  year={2005},
  volume={},
  number={},
  pages={85-94},
  abstract={This paper compares two methods for running an application composed of a set of modules on a grid. The set of modules (collectively called Montage) generates large astronomical image mosaics by composing multiple small images. The workflow that describes a particular run of Montage can be expressed as a directed acyclic graph (DAG), or as a short sequence of parallel (MPI) and sequential programs. In the first case, Pegasus can be used to run the workflow. In the second case, a short shell script that calls each program can be run. In this paper, we discuss the Montage modules, the workflow run for a sample job, and the two methods of actually running the workflow. We examine the run time for each method and compare the portions that differ between the two methods.},
  keywords={},
  doi={10.1109/ICPPW.2005.6},
  ISSN={2332-5690},
  month={June},}
@INPROCEEDINGS{1488702,
  author={Polaschegg, M. and Steger, C. and Dalton, D. and Vadher, A.},
  booktitle={2005 International Conference on Parallel Processing Workshops (ICPPW'05)}, 
  title={Parallel simulation with a generic simulation framework featuring loose coupling}, 
  year={2005},
  volume={},
  number={},
  pages={251-257},
  abstract={For developing parallel systems composed of hard- and software, powerful simulation tools are needed in order to decrease time-to-market. With the generic simulation framework, clock-cycle accurate simulation for parallel devices communicating with each other is possible. This tool is designed to support different model techniques at various levels of abstraction and is used for verification and design-space exploration in the design process of the APPLES processor developed by the Irish company Neosera Systems.},
  keywords={},
  doi={10.1109/ICPPW.2005.67},
  ISSN={2332-5690},
  month={June},}
@INPROCEEDINGS{1488711,
  author={Youhui Zhang and Ruini Xue and Dongsheng Wong and Weimin Zheng},
  booktitle={2005 International Conference on Parallel Processing Workshops (ICPPW'05)}, 
  title={A checkpointing/recovery system for MPI applications on cluster of IA-64 computers}, 
  year={2005},
  volume={},
  number={},
  pages={320-327},
  abstract={As the clusters continue to grow in size and popularity, issues of fault tolerance and reliability turn into limiting factors on application scalability and system availability. To address these issues, we design and implement a high availability parallel run-time system - ChaRM64 for MPI, a checkpoint-based rollback recovery and migration system for MPI programs on a cluster of IA-64 computers. Our approach integrates MPICH with a user-level, single process checkpoint/recovery library for IA-64 Linux, and modifies P4 libraries to implement a coordinated checkpointing and rollback recovery (CRR) and migration mechanism for parallel applications. In addition, the CRR of file operations is supported. Testing shows negligible performance overhead introduced by the CRR mechanism in our implementation.},
  keywords={},
  doi={10.1109/ICPPW.2005.5},
  ISSN={2332-5690},
  month={June},}
@INPROCEEDINGS{1488739,
  author={Boukerche, A. and Melo, A.C.M.A. and Koch, J.G. and Galdino, C.R.},
  booktitle={2005 International Conference on Parallel Processing Workshops (ICPPW'05)}, 
  title={Multiple coherence and coordinated checkpointing protocols for DSM systems}, 
  year={2005},
  volume={},
  number={},
  pages={531-538},
  abstract={In this article, we address two important issues in DSM research: improving performance and providing reliability. To improve performance, we designed a low-overhead multiple coherence protocol mechanism and to augment the reliability of the system, we propose a coordinated checkpointing/recovery mechanism. Both mechanisms were implemented and incorporated in JIAJIA, a DSM system that implements scope consistency with a write-invalidate protocol. Our results on an eight machine cluster with some popular benchmarks show, for the multiple coherence protocol strategy, a significant reduction on the number of messages exchanged, leading to better performance results. Also, our results for the checkpointing strategy show that the overhead introduced in failure-free executions is small when considering the benefits obtained.},
  keywords={},
  doi={10.1109/ICPPW.2005.57},
  ISSN={2332-5690},
  month={June},}
@INPROCEEDINGS{1488735,
  author={Krietemeyer, M. and Kopp, H. and Versick, D. and Tavangarian, D.},
  booktitle={2005 International Conference on Parallel Processing Workshops (ICPPW'05)}, 
  title={Environment for I/O performance measurement of distributed and local secondary storage}, 
  year={2005},
  volume={},
  number={},
  pages={501-508},
  abstract={Whilst the performance gap between main memory and secondary storage of computer systems increased rapidly during the last years, especially the analysis of secondary storage performance becomes very important. For that purpose this paper introduces a plugin-based framework providing an integrated execution environment for new benchmarks and offering analysis tools for the complex result output of particularly I/O measurements. As an example of this environment we describe the PRIOmark, an I/O benchmark that characterizes file system performance of single and distributed systems by means of two different file system interfaces. Additionally, the I/O performance of three file systems, two file system interfaces as well as different I/O workloads are compared to show the flexibility of the presented PRIOmark.},
  keywords={},
  doi={10.1109/ICPPW.2005.30},
  ISSN={2332-5690},
  month={June},}
@INPROCEEDINGS{1488734,
  author={Javadi, B. and Akbari, M.K. and Abawajy, J.H.},
  booktitle={2005 International Conference on Parallel Processing Workshops (ICPPW'05)}, 
  title={Performance analysis of heterogeneous multi-cluster systems}, 
  year={2005},
  volume={},
  number={},
  pages={493-500},
  abstract={When building a cost-effective high-performance parallel processing system, a performance model is a useful tool for exploring the design space and examining various parameters. However, performance analysis in such systems has proven to be a challenging task that requires the innovative performance analysis tools and methods to keep up with the rapid evolution and ever increasing complexity of such systems. To this end, we propose an analytical model for heterogeneous multi-cluster systems. The model takes into account stochastic quantities as well as network heterogeneity in bandwidth and latency in each cluster. Also, blocking and non-blocking network architecture model is proposed and are used in performance analysis of the system. The message latency is used as the primary performance metric. The model is validated by constructing a set of simulators to simulate different types of clusters, and by comparing the modeled results with the simulated ones.},
  keywords={},
  doi={10.1109/ICPPW.2005.70},
  ISSN={2332-5690},
  month={June},}
@ARTICLE{1492478,
  author={Walter, J.E. and Tsai, E.M. and Amato, N.M.},
  journal={IEEE Transactions on Robotics}, 
  title={Algorithms for fast concurrent reconfiguration of hexagonal metamorphic robots}, 
  year={2005},
  volume={21},
  number={4},
  pages={621-631},
  abstract={The problem addressed is the distributed reconfiguration of a system of hexagonal metamorphic robots (modules) from an initial straight chain to a goal configuration that satisfies a simple admissibility condition. Our reconfiguration strategy depends on finding a contiguous path of cells that spans the goal configuration and over which modules can move concurrently without collision or deadlock, called an admissible substrate path. A subset of modules first occupy the admissible substrate path, which is then traversed by other modules to fill in the remainder of the goal. We present a two-phase reconfiguration strategy, beginning with a centralized preprocessing phase that finds and heuristically ranks all admissible substrate paths in the goal configuration, according to which path is likely to result in fast parallel reconfiguration. We prove the correctness of our path-finding algorithm and demonstrate its effectiveness through simulation. The second phase of reconfiguration is accomplished by a deterministic, distributed algorithm that uses little or no intermodule message passing.},
  keywords={},
  doi={10.1109/TRO.2004.842325},
  ISSN={1941-0468},
  month={Aug},}
@INPROCEEDINGS{1494672,
  author={Prabhakar, A. and Narayanan, K.},
  booktitle={IEEE International Conference on Communications, 2005. ICC 2005. 2005}, 
  title={A scalable decoder architecture for linear congruential LDPC codes}, 
  year={2005},
  volume={3},
  number={},
  pages={1911-1915 Vol. 3},
  abstract={Maximal length linear congruential sequence (MLLCS) based LDPC codes have the advantage that the LDPC code graph can be generated at the receiver without having to explicity store the graph. Hence, these codes are advantageous when the same hardware needs to be used for different sets of rates and lengths. In this paper, we reveal an inherent structure in these codes that facilitates parallel implementation of the decoding algorithm. Based on this, we present an architecture for the MLLCS-LDPC decoder that facilitates parallel scalable implementation and joint code-decoder design.},
  keywords={},
  doi={10.1109/ICC.2005.1494672},
  ISSN={1938-1883},
  month={May},}
@INPROCEEDINGS{1498546,
  author={Khude, N. and Kumar, A. and Karnik, A.},
  booktitle={Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.}, 
  title={Time and energy complexity of distributed computation in wireless sensor networks}, 
  year={2005},
  volume={4},
  number={},
  pages={2625-2637 vol. 4},
  abstract={We consider a scenario where a wireless sensor network is formed by randomly deploying n sensors to measure some spatial function over a field, with the objective of computing the maximum value of the measurements and communicating it to an operator station. We view the problem as one of message passing distributed computation over a geometric random graph. The network is assumed to be synchronous; at each sampling instant each sensor measures a value, and then the sensors collaboratively compute and deliver the maximum of these values to the operator station. Computation algorithms differ in the messages they need to exchange, and our formulation focuses on the problem of scheduling of the message exchanges. We do not exploit techniques such as source compression, or block coding of the computations. For this problem, we study the computation time and energy expenditure for one time maximum computation, and also the pipeline throughput. We show that, for an optimal algorithm, the computation time, energy expenditure and the achievable rate of computation scale as /spl Theta/(/spl radic/ n/log n), /spl Theta/(n) and /spl Theta/(1/log n) asymptotically (in probability) as the number of sensors n/spl rarr//spl infin/. We also analyze the performance of three specific computational algorithms, namely, the tree algorithm, multihop transmission, and the ripple algorithm, and obtain scaling laws for the computation time and energy expenditure as n/spl rarr//spl infin/. Simulation results are provided to show that our analysis indeed captures the correct scaling; the simulations also yield estimates of the constant multipliers in the scaling laws. Our analyses throughout assume a centralized scheduler and hence our results can be viewed as providing bounds for the performance with a distributed scheduler.},
  keywords={},
  doi={10.1109/INFCOM.2005.1498546},
  ISSN={0743-166X},
  month={March},}
@ARTICLE{1501839,
  author={Wiese, K.C. and Hendriks, A. and Deschenes, A. and Youssef, B.B.},
  journal={IEEE Transactions on NanoBioscience}, 
  title={P-RnaPredict-a parallel evolutionary algorithm for RNA folding: effects of pseudorandom number quality}, 
  year={2005},
  volume={4},
  number={3},
  pages={219-227},
  abstract={This paper presents a fully parallel version of RnaPredict, a genetic algorithm (GA) for RNA secondary structure prediction. The research presented here builds on previous work and examines the impact of three different pseudorandom number generators (PRNGs) on the GA's performance. The three generators tested are the C standard library PRNG RAND, a parallelized multiplicative congruential generator (MCG), and a parallelized Mersenne Twister (MT). A fully parallel version of RnaPredict using the Message Passing Interface (MPI) was implemented on a 128-node Beowulf cluster. The PRNG comparison tests were performed with known structures whose sequences are 118, 122, 468, 543, and 556 nucleotides in length. The effects of the PRNGs are investigated and the predicted structures are compared to known structures. Results indicate that P-RnaPredict demonstrated good prediction accuracy, particularly so for shorter sequences.},
  keywords={},
  doi={10.1109/TNB.2005.853656},
  ISSN={1558-2639},
  month={Sep.},}
@INPROCEEDINGS{1465805,
  author={Darabiha, A. and Carusone, A.C. and Kschischang, F.R.},
  booktitle={2005 IEEE International Symposium on Circuits and Systems}, 
  title={Multi-Gbit/sec low density parity check decoders with reduced interconnect complexity}, 
  year={2005},
  volume={},
  number={},
  pages={5194-5197 Vol. 5},
  abstract={A 3.2-Gbit/sec 2048-bit parallel LDPC decoder is implemented in a 0.18 /spl mu/m CMOS process. We employ two new techniques to address the interconnect problem: A broadcasting technique reduces the total amount of check-to-variable interconnect wires by more than 40%. A hierarchical placement algorithm places the variable and check nodes in the top-level hierarchy of the design and reduces the maximum wire length by up to 50%.},
  keywords={},
  doi={10.1109/ISCAS.2005.1465805},
  ISSN={2158-1525},
  month={May},}
@ARTICLE{1437365,
  author={Sheng Tong and Baoming Bai and Xinmei Wang},
  journal={IEEE Communications Letters}, 
  title={Convergence rates comparison of sum-product decoding of RA codes under different message-passing schedules}, 
  year={2005},
  volume={9},
  number={6},
  pages={543-545},
  abstract={In iterative decoding of turbo-like codes, serial schedule generally provides a much faster convergence rate compared with parallel schedule. With the aid of extrinsic information transfer (EXIT) charts, sum-product decoding of repeat accumulate (RA) codes under both message passing schedules is investigated as an example for verifying the above statement.},
  keywords={},
  doi={10.1109/LCOMM.2005.1437365},
  ISSN={1558-2558},
  month={June},}
@INPROCEEDINGS{1503122,
  author={Chang-Yi Lin and Jiazheng Zhou and Yeh-Ching Chung},
  booktitle={ITRE 2005. 3rd International Conference on Information Technology: Research and Education, 2005.}, 
  title={An adaptive migratory home protocol for software DSM systems}, 
  year={2005},
  volume={},
  number={},
  pages={272-276},
  abstract={In software distributed shared memory systems, home-based protocols are very good designs because of easy implementation, little memory overheads and good performance. The home-based protocols can be divided into two categories, the fix home protocol and the migratory home protocol. The fix home protocol produces less number of page faults than the migratory home protocol. The migratory home protocols can save the number of diff creating and diff propagation. For an application program, its execution behavior is suitable for the fixed home protocol in some time periods and is suitable for the migratory home protocol in some other time periods. A protocol that can be adapted between the fixed home protocol and the migratory home protocol is important for the performance of an application program. In this paper, we proposed an adaptive migratory home protocol, which combines the advantages of the fixed home and the migratory home protocols. In the adaptive migratory home protocol, the home node of a page can change the state of the page according the application behavior. To evaluate the adaptive migratory home protocol, we have implemented the proposed protocol along with the home-based protocol and the migratory home protocol. We tested eight application programs for the three protocols on the same platform. The experimental result shows that the home-based protocol works well for applications with sharing access pattern. The migratory home protocol has good performance for migratory access pattern. The performance of the adaptive migratory home protocol is in between these two protocols and performs well for most of the applications.},
  keywords={},
  doi={10.1109/ITRE.2005.1503122},
  ISSN={},
  month={June},}
@INPROCEEDINGS{1508146,
  author={Sirjani, M. and de Boer, F. and Movaghar, A. and Shali, A.},
  booktitle={Fifth International Conference on Application of Concurrency to System Design (ACSD'05)}, 
  title={Extended Rebeca: a component-based actor language with synchronous message passing}, 
  year={2005},
  volume={},
  number={},
  pages={212-221},
  abstract={In this paper, we propose extended Rebeca as a tool-supported actor-based language for modeling and verifying concurrent and distributed systems. We enrich Rebeca with a formal concept of components which integrates the message-driven computational model of actor-based languages with synchronous message passing. Components are used to encapsulate a set of internal active objects which react asynchronously to messages by means of methods and which additionally interact via a synchronous message passing mechanism. Components themselves interact only via asynchronous and anonymous messages. We present our compositional verification approach and abstraction techniques, and the theory corresponding to it, based on the formal semantics of Rebeca. These techniques are exploited to overcome the state explosion problem in model checking.},
  keywords={},
  doi={10.1109/ACSD.2005.12},
  ISSN={1550-4808},
  month={June},}
@ARTICLE{1512437,
  author={Ardakani, M. and Kschischang, F.R.},
  journal={IEEE Transactions on Information Theory}, 
  title={Properties of optimum binary message-passing decoders}, 
  year={2005},
  volume={51},
  number={10},
  pages={3658-3665},
  abstract={We consider a class of message-passing decoders for low-density parity-check (LDPC) codes whose messages are binary valued. We prove that if the channel is symmetric and all codewords are equally likely to be transmitted, an optimum decoding rule (in the sense of minimizing message error rate) should satisfy certain symmetry and isotropy conditions. Using this result, we prove that Gallager's Algorithm B achieves the optimum decoding threshold among all binary message-passing decoding algorithms for regular codes. For irregular codes, we argue that when the nodes of the message-passing decoder do not exploit knowledge of their decoding neighborhood, optimality of Gallager's Algorithm B is preserved. We also consider the problem of designing irregular LDPC codes and find a bound on the achievable rates with Gallager's Algorithm B. Using this bound, we study the case of low error-rate channels and analytically find good degree distributions for them.},
  keywords={},
  doi={10.1109/TIT.2005.855611},
  ISSN={1557-9654},
  month={Oct},}
@INPROCEEDINGS{1510071,
  author={Guohui Li and LihChyun Shu},
  booktitle={29th Annual International Computer Software and Applications Conference (COMPSAC'05)}, 
  title={A low-latency checkpointing scheme for mobile computing systems}, 
  year={2005},
  volume={1},
  number={},
  pages={491-496 Vol. 2},
  abstract={Fault-tolerant mobile computing systems have different requirements and restrictions, not taken into account by conventional distributed systems. This paper presents a coordinated checkpointing scheme which reduces the delay involved in a global checkpointing process for mobile systems. A piggyback technique is used to track and record the checkpoint dependency information among processes during normal message transmission. During checkpointing, a concurrent checkpointing technique is designed to use the pre-recorded process dependency information to minimize process blocking time by sending checkpoint requests to dependent processes at once, hence saving the time to trace the dependency tree. Our checkpoint algorithm forces a minimum number of processes to take checkpoints. Via probability-based analysis, we show that our scheme can significantly reduce the latency associated with checkpoint request propagation, compared to traditional coordinated checkpointing approach.},
  keywords={},
  doi={10.1109/COMPSAC.2005.26},
  ISSN={0730-3157},
  month={July},}
@INPROCEEDINGS{1520898,
  author={Kim, H.S. and Yeom, H.Y.},
  booktitle={CLADE 2005. Proceedings Challenges of Large Applications in Distributed Environments, 2005.}, 
  title={A user-transparent recoverable file system for distributed computing environment}, 
  year={2005},
  volume={},
  number={},
  pages={45-53},
  abstract={In a distributed computing environment, particularly grid, fault-tolerance is one of the core functionalities the system should provide. MPICH-GF is such a resilient system designed to resist external or internal failures, especially for message passing applications in the grid environment. But it does not stand the loss of a valuable resource: files. In a normal case, users open files and write data into them in an asynchronous manner, and checkpointing is initiated with no regard to the state of the context of the process. Therefore, the checkpointing system should automatically recognize the running process and protect the open files transparently. We have implemented a recoverable file system, named ReFS, which is incorporated into our fault-tolerant system MPICH-GF. ReFS is a versioning-like file system. ReFS provides middleware libraries with the system call interface to protect specific files at a given time. This prevents applications from processing their jobs with corrupted data and resulting in incorrect results in case of failures. We have focused not only on the reliability of the system but also on the reduction of inevitable overheads. This paper describes the design and implementation of ReFS and justifies the validity of the behavior of ReFS. We have developed ReFS on Linux, based on Ext2.},
  keywords={},
  doi={10.1109/CLADE.2005.1520898},
  ISSN={},
  month={July},}
@INPROCEEDINGS{1522967,
  author={Spagnol, C. and Marnane, W. and Popovici, E.},
  booktitle={Proceedings of the 2005 European Conference on Circuit Theory and Design, 2005.}, 
  title={Reduced complexity, FPGA implementation of quasi-cyclic LDPC decoder}, 
  year={2005},
  volume={1},
  number={},
  pages={I/289-I/292 vol. 1},
  abstract={This paper describes an FPGA implementation of a decoder for a particular family of low density parity check (LDPC) codes, the quasi-cyclic LDPC codes. The structure of a quasi-cyclic code is well known and allows us to reduce the complexity of the interconnections between bit nodes and check nodes. The decoder has a semi-parallel architecture and it takes full advantage of the structure of the code and the hardware resources present in an FPGA. We achieve simple memory controller resulting in an efficient use of the memory. The decoder is implemented based on the parameters that characterize a quasi-cyclic LDPC code. This makes it easily adaptable for a class of quasi-cyclic codes. We evaluate the performance of our codes and present some FPGA design trade-off.},
  keywords={},
  doi={10.1109/ECCTD.2005.1522967},
  ISSN={},
  month={Sep.},}
@INPROCEEDINGS{1523112,
  author={Byrne, A. and Popovici, E.M. and O'Sullivan, M.},
  booktitle={Proceedings of the 2005 European Conference on Circuit Theory and Design, 2005.}, 
  title={Versatile architectures for decoding a class of LDPC codes}, 
  year={2005},
  volume={3},
  number={},
  pages={III/269-III/272 vol. 3},
  abstract={This paper presents a construction for low and high rate Low-Density Parity Check (LDPC) codes, their performance and efficient hardware implementation. The problem with decoding for LDPC codes is the linear increase in resource requirements as the size of the parity check matrix increases. This results in a number of issues with regard to practical implementation. These issues include interconnect routing, memory size and parallelism. A construction for low complexity, variable rate LDPC code will be introduced and an architecture that takes advantage of certain properties of this construction is proposed. A versatile LDPC decoding architecture is then evaluated on FPGA.},
  keywords={},
  doi={10.1109/ECCTD.2005.1523112},
  ISSN={},
  month={Sep.},}
@INPROCEEDINGS{1523592,
  author={Wainwright, M.J. and Maneva, E.},
  booktitle={Proceedings. International Symposium on Information Theory, 2005. ISIT 2005.}, 
  title={Lossy source encoding via message-passing and decimation over generalized codewords of LDGM codes}, 
  year={2005},
  volume={},
  number={},
  pages={1493-1497},
  abstract={We describe message-passing and decimation approaches for lossy source coding using low-density generator matrix (LDGM) codes. In particular, this paper addresses the problem of encoding a Bernoulli(1/2) source: for randomly generated LDGM codes with suitably irregular degree distributions, our methods yield performance very close to the rate distortion limit over a range of rates. Our approach is inspired by the survey propagation (SP) algorithm, originally developed by Mezard et al. (2002) for solving random satisfiability problems. Previous work by Maneva et al. (2005) shows how SP can be understood as belief propagation (BP) for an alternative representation of satisfiability problems. In analogy to this connection, our approach is to define a family of Markov random fields over generalized codewords, from which local message-passing rules can be derived in the standard way. The overall source encoding method is based on message-passing, setting a subset of bits to their preferred values (decimation), and reducing the code},
  keywords={},
  doi={10.1109/ISIT.2005.1523592},
  ISSN={2157-8117},
  month={Sep.},}
@INPROCEEDINGS{1523648,
  author={Bayati, M. and Shah, D. and Sharma, M.},
  booktitle={Proceedings. International Symposium on Information Theory, 2005. ISIT 2005.}, 
  title={Maximum weight matching via max-product belief propagation}, 
  year={2005},
  volume={},
  number={},
  pages={1763-1767},
  abstract={The max-product "belief propagation" algorithm is an iterative, local, message passing algorithm for finding the maximum a posteriori (MAP) assignment of a discrete probability distribution specified by a graphical model. Despite the spectacular success of the algorithm in many application areas such as iterative decoding and computer vision which involve graphs with many cycles, theoretical convergence results are only known for graphs which are tree-like or have a single cycle. In this paper, we consider a weighted complete bipartite graph and define a probability distribution on it whose MAP assignment corresponds to the maximum weight matching (MWM) in that graph. We analyze the fixed points of the max-product algorithm when run on this graph and prove the surprising result that even though the underlying graph has many short cycles, the maxproduct assignment converges to the correct MAP assignment. We also provide a bound on the number of iterations required by the algorithm},
  keywords={},
  doi={10.1109/ISIT.2005.1523648},
  ISSN={2157-8117},
  month={Sep.},}
@INPROCEEDINGS{1524200,
  author={Shimizu, K. and Ishikawa, T. and Togawa, N. and Ikenaga, T. and Goto, S.},
  booktitle={2005 International Conference on Computer Design}, 
  title={Partially-parallel LDPC decoder based on high-efficiency message-passing algorithm}, 
  year={2005},
  volume={},
  number={},
  pages={503-510},
  abstract={This paper proposes a partially-parallel LDPC decoder based on a high-efficiency message-passing algorithm. Our proposed partially-parallel LDPC decoder performs the column operations for bit nodes in conjunction with the row operations for check nodes. Bit functional unit with pipeline architecture in our LDPC decoder allows us to perform column operations for every bit node connected to each of check nodes which are updated by the row operations in parallel. Our proposed LDPC decoder improves the tuning when the column operations are performed, accordingly it improves the message-passing efficiency within the limited number of iterations for decoding. We implemented the proposed partially-parallel LDPC decoder on an FPGA, and simulated its decoding performance. Practical simulation shows that our proposed LDPC decoder reduces the number of iterations for decoding, and it improves the bit error performance with a small hardware overhead.},
  keywords={},
  doi={10.1109/ICCD.2005.83},
  ISSN={1063-6404},
  month={Oct},}
@ARTICLE{1532540,
  author={Wenhua Yu and Yongjun Liu and Tao Su and Neng-Tien Hunag and Mittra, R.},
  journal={IEEE Antennas and Propagation Magazine}, 
  title={A robust parallel conformal finite-difference time-domain processing package using the MPI library}, 
  year={2005},
  volume={47},
  number={3},
  pages={39-59},
  abstract={We present a parallel conformal finite-difference time-domain (PCFDTD) technique using the MPI library, which carries out the field exchange between the neighboring processes in a highly efficient way. A robust conformal mesh-generation technique based on the proposed parallel-processing scheme is also described. In addition, this paper introduces some novel approaches to implementing the excitation sources, including rectangular and circular waveguides, lumped elements, matched terminators, and sub-gridding, as well as meshing and simulation-result collection in the parallel scheme. The efficiency of the parallel-processing FDTD code is analyzed through several typical examples. Several electrically large finite antenna arrays are presented to validate the proposed techniques.},
  keywords={},
  doi={10.1109/MAP.2005.1532540},
  ISSN={1558-4143},
  month={June},}
@INPROCEEDINGS{1530964,
  author={Harmanani, H. and Karablieh, B.},
  booktitle={Fifth International Workshop on System-on-Chip for Real-Time Applications (IWSOC'05)}, 
  title={A hybrid distributed test generation method using deterministic and genetic algorithms}, 
  year={2005},
  volume={},
  number={},
  pages={317-322},
  abstract={Test generation is a highly complex and time-consuming task. In this work, we present a distributed method for combinational test generation. The method is based on a hybrid approach that combines both deterministic and genetic approaches. The deterministic phase is based on the D-algorithm and generates an initial set of test vectors that are evolved in the genetic phase in order to achieve high fault coverage in a short time. The algorithm is parallelized based on a cluster of workstations using the message passing interface (MPI) library. Several benchmark circuits were attempted, and favorable results comparisons are reported.},
  keywords={},
  doi={10.1109/IWSOC.2005.13},
  ISSN={},
  month={July},}
@INPROCEEDINGS{1531116,
  author={Byung-Hyun Yu and Werstein, P. and Purvis, M. and Cranefield, S.},
  booktitle={11th International Conference on Parallel and Distributed Systems (ICPADS'05)}, 
  title={Performance improvement techniques for software distributed shared memory}, 
  year={2005},
  volume={1},
  number={},
  pages={119-125 Vol. 1},
  abstract={This paper presents our novel lazy home-based protocol briefly and two implementation techniques. These techniques are developed by exploiting a relaxed memory consistency model such as scope consistency. First, we present a novel diff integration technique which can solve most diff accumulation problems that are prevalent in migratory DSM applications. Second, we propose a dynamic home migration protocol that solves the static home assignment problem in the original home-based protocol. To evaluate our protocol and techniques, we have done performance tests using well known DSM benchmark applications. The performance results proved our diff integration and dynamic home allocation solve the diff accumulation and wrong static home assignment problems respectively.},
  keywords={},
  doi={10.1109/ICPADS.2005.232},
  ISSN={1521-9097},
  month={July},}
@INPROCEEDINGS{1531143,
  author={Jiannong Cao and Yinghao Li and Minyi Guo},
  booktitle={11th International Conference on Parallel and Distributed Systems (ICPADS'05)}, 
  title={Process migration for MPI applications based on coordinated checkpoint}, 
  year={2005},
  volume={1},
  number={},
  pages={306-312 Vol. 1},
  abstract={A lot of research has been done on fault-tolerance for MPI applications, some on checkpoint/restart, and some on network fault-tolerance. Process migration, however, has not gained widespread use due to the additional complexity of the requirement that the knowledge about the new location of a migrated process has to be made known to every other process in the application. Here we present a simple yet effective method of process migration based on coordinated checkpointing of MPI applications. Migration is achieved by checkpointing the application, modifying the process location information in the checkpoint files, and restarting the application. Checkpoint/restart and migration are transparent to MPI applications. Performance evaluation results showed that the additional checkpoint/restart capability has little impact on application performance, and the migration method scales well on a large number of nodes.},
  keywords={},
  doi={10.1109/ICPADS.2005.241},
  ISSN={1521-9097},
  month={July},}
@INPROCEEDINGS{1531185,
  author={Weijia Jia and Bo Han and Ji Shen and Haohuan Fu and Man-Ching Yuen},
  booktitle={11th International Conference on Parallel and Distributed Systems (ICPADS'05)}, 
  title={Efficient implementation of 3G-324M protocol stack for multimedia communication}, 
  year={2005},
  volume={1},
  number={},
  pages={599-605 Vol. 1},
  abstract={In order to support real-time video, audio and data communication among heterogeneous third generation (3G) handsets, 3G phones/terminals are required to support 3G-324M, the multimedia transmission protocol stack for 3G communication. This paper discusses some efficient approaches and experiences in the implementation of 3G-324M protocol stack. Specifically, we discuss: (1) event-driven approach for the overall information exchange; (2) single-step direct message transformation for the optimization of tree-structured message processing and (3) serialization of nested multiplex table entries in multiplexing/demultiplexing processing. Our implementation has been tested in a realistic heterogeneous 3G communication environment for transmission of real-time video, audio and data and its performance is satisfactory.},
  keywords={},
  doi={10.1109/ICPADS.2005.144},
  ISSN={1521-9097},
  month={July},}
@INPROCEEDINGS{1541189,
  author={Mostefaoui, A. and Raynal, M. and Travers, C. and Patterson, S. and Divyakant Agrawal and Abbadi, A.E.},
  booktitle={24th IEEE Symposium on Reliable Distributed Systems (SRDS'05)}, 
  title={From static distributed systems to dynamic systems}, 
  year={2005},
  volume={},
  number={},
  pages={109-118},
  abstract={A noteworthy advance in distributed computing is due to the recent development of peer-to-peer systems. These systems are essentially dynamic in the sense that no process can get a global knowledge on the system structure. They mainly allow processes to look up for data that can be dynamically added/suppressed in a permanently evolving set of nodes. Although protocols have been developed for such dynamic systems, to our knowledge, up to date no computation model for dynamic systems has been proposed. Nevertheless, there is a strong demand for the definition of such models as soon as one wants to develop provably correct protocols suited to dynamic systems. This paper proposes a model for (a class of) dynamic systems. That dynamic model is defined by (1) a parameter (an integer denoted a) and (2) two basic communication abstractions (query-response and persistent reliable broadcast). The new parameter is a threshold value introduced to capture the liveness part of the system (it is the counterpart of the minimal number of processes that do not crash in a static system). To show the relevance of the model, the paper adapts an eventual leader protocol designed for the static model, and proves that the resulting protocol is correct within the proposed dynamic model. In that sense, the paper has also a methodological flavor, as it shows that simple modifications to existing protocols can allow them to work in dynamic systems.},
  keywords={},
  doi={10.1109/RELDIS.2005.19},
  ISSN={1060-9857},
  month={Oct},}
@INPROCEEDINGS{1542749,
  author={Abu-Ghazaleh, N. and Lewis, M.J.},
  booktitle={The 6th IEEE/ACM International Workshop on Grid Computing, 2005.}, 
  title={Differential checkpointing for reducing memory requirements in optimized SOAP deserialization}, 
  year={2005},
  volume={},
  number={},
  pages={6 pp.-},
  abstract={Differential serialization (DDS) is a SOAP optimization technique wherein servers save checkpoints and parser states associated with portions of previously received messages, and use them to avoid full parsing and deserialization of similar new messages. In this paper, we characterize DDS's memory requirements and memory overhead, introduce a new technique for storing only the differences between successive parser states for a message, and demonstrate how this optimization, which we call differential checkpointing, speeds up the DDS optimization and reduces its memory requirements.},
  keywords={},
  doi={10.1109/GRID.2005.1542749},
  ISSN={2152-1093},
  month={Nov},}
@INPROCEEDINGS{1542752,
  author={Dury, A.},
  booktitle={The 6th IEEE/ACM International Workshop on Grid Computing, 2005.}, 
  title={Auto-adaptive distributed hash tables}, 
  year={2005},
  volume={},
  number={},
  pages={6 pp.-},
  abstract={In this paper we propose a new distributed hash table model called auto-adaptive distributed hash table (AA-DHT). This model uses a distributed profiling of the nodes of the DHT to dynamically adapt the size of the index tables in order to reduce both the message cost and the request latency. This work is an evolution of the architecture for a P2P computing model described by Dury (2004), We detail the auto-adaptive model, the protocols we implemented and tested and we give experimental results of the architecture in simulated networks of up to 640 nodes.},
  keywords={},
  doi={10.1109/GRID.2005.1542752},
  ISSN={2152-1093},
  month={Nov},}
@INPROCEEDINGS{1543375,
  author={Paolini, E. and Chiani, M.},
  booktitle={2005 IEEE 61st Vehicular Technology Conference}, 
  title={On the threshold of right regular LDPC codes for the erasure channel}, 
  year={2005},
  volume={1},
  number={},
  pages={664-667 Vol. 1},
  abstract={We provide an analytical expression for the threshold for right regular low-density parity-check (LDPC) codes for the erasure channel (EC), under message passing decoding. We first develop an expression for the threshold for regular LDPC codes, alternative to that already available in the literature; then we generalize it for the class of right regular codes. Thus, we show that the problem of computing the threshold can be reduced to the search for the fixed points of a function depending only on the variable nodes degree distribution, /spl lambda/(x), and on the uniform weight, d/sub c/, of check nodes. Finally, we show the application of our analysis to a class of capacity-approaching right regular LDPC codes.},
  keywords={},
  doi={10.1109/VETECS.2005.1543375},
  ISSN={1550-2252},
  month={May},}
@INPROCEEDINGS{1552966,
  author={Guo, L. and Robertson, D. and Chen-Burger, Y.-H.},
  booktitle={IEEE International Conference on e-Business Engineering (ICEBE'05)}, 
  title={A novel approach for enacting the distributed business workflows using BPEL4WS on the multi-agent platform}, 
  year={2005},
  volume={},
  number={},
  pages={657-664},
  abstract={This paper describes the development of a distributed multi-agent workflow enactment mechanism using BPEL4WS specification. It demonstrates that a multi-agent protocol (lightweight coordination calculus (LCC)) can be used to interpret a BPEL4WS specification to enable distributed business workflow using Web services composition. The key difference between our system and other existing multi-agent based Web services composition systems is that with our approach, a business process model (system requirement) can be adopted directly in the multi-agent system, thus reduce the effort on the validation and verification of interaction protocol (system specification). This approach also provides us with a lightweight way of re-design of large components based system},
  keywords={},
  doi={10.1109/ICEBE.2005.13},
  ISSN={},
  month={Oct},}
@INPROCEEDINGS{1554720,
  author={Wiese, K.C. and Hendriks, A. and Deschenes, A. and Youssef, B.B.},
  booktitle={2005 IEEE Congress on Evolutionary Computation}, 
  title={Significance of randomness in P-RnaPredict - a parallel evolutionary algorithm for RNA folding}, 
  year={2005},
  volume={1},
  number={},
  pages={467-474 Vol.1},
  abstract={This paper presents an extension to P-RnaPredict, a parallel evolutionary algorithm (EA) for RNA folding. The impact of three pseudorandom number generators (PRNGs) on the EA's performance is evaluated. The generators tested included the C standard library PRNG RAND, a parallelized multiplicative congruential generator (MCG), and a parallelized Mersenne Twister (MT). P-RnaPredict was implemented using the message passing interface (MPI) and tested on a 128 node Beowulf cluster. The PRNG comparison testing was performed with four known structures that are 118, 122, 543, and 556 nucleotides in length. PRNGs effects were investigated and predicted structures compared to known structures},
  keywords={},
  doi={10.1109/CEC.2005.1554720},
  ISSN={1941-0026},
  month={Sep.},}
@INPROCEEDINGS{1562926,
  author={Dingjun Chen and Chung-Yeol Lee and Cheol Hoon Park},
  booktitle={17th IEEE International Conference on Tools with Artificial Intelligence (ICTAI'05)}, 
  title={Hybrid genetic algorithm and simulated annealing (HGASA) in global function optimization}, 
  year={2005},
  volume={},
  number={},
  pages={5 pp.-133},
  abstract={We have implemented the sequential HGASA on a Sun Workstation machine; its performance seems to be very good in finding the global optimum of a sample function optimization problem as compared with some sequential optimization algorithms that offer low efficiency and limited reliability. However, the sequential HGASA generally needs a long run time cost. So we implemented a parallel HGASA using message passing interface (MPI) on a high performance computer and performed many tests using a set of frequently used function optimization problems. The performance analysis of this parallel approach has been done on IBM Beowulf PCs cluster in terms of program execution time, relative speed up and efficiency.},
  keywords={},
  doi={10.1109/ICTAI.2005.72},
  ISSN={2375-0197},
  month={Nov},}
@INPROCEEDINGS{1563154,
  author={Le, T.T.},
  booktitle={Third ACIS Int'l Conference on Software Engineering Research, Management and Applications (SERA'05)}, 
  title={Tuning system-dependent applications with alternative MPI calls: a case study}, 
  year={2005},
  volume={},
  number={},
  pages={137-143},
  abstract={This paper shows the effectiveness of using optimized MPI calls for MPI based applications on different architectures. Using optimized MPI calls can result in reasonable performance gain for most of MPI based applications running on most of high-performance distributed systems. Since relative performance of different MPI function calls and system architectures can be uncorrelated, tuning system-dependent MPI applications by exploring the alternatives of using different MPI calls is the simplest but most effective optimization method. The paper first shows that for a particular system, there are noticeable performance differences between using various MPI calls that result in the same communication pattern. These performance differences are in fact not similar across different systems. The paper then shows that good performance optimization for an MPI application on different systems can be obtained by using different MPI calls for different systems. The communication patterns that were experimented in this paper include the point-to-point and collective communications. The MPI based application used for this study is the general-purpose transient dynamic finite element application and the benchmark problems are the public domain 3D car crash problems. The experiment results show that for the same communication purpose, using alternative MPI calls can result in quite different communication performance on the Fujitsu HPC2500 system and the 8-node AMD Athlon cluster, but very much the same performance on the other systems such as the Intel Itanium2 and the AMD Opteron clusters.},
  keywords={},
  doi={10.1109/SERA.2005.67},
  ISSN={},
  month={Aug},}
@INPROCEEDINGS{1564562,
  author={Gorodetsky, D.A. and Wilsey, P.A.},
  booktitle={Proceedings of Xth International Seminar/Workshop on Direct and Inverse Problems of Electromagnetic and Acoustic Wave Theory}, 
  title={Innovative approaches to parallelizing finite-difference time-domain computations}, 
  year={2005},
  volume={},
  number={},
  pages={43-47},
  abstract={We investigate the Linux implementation of the finite-difference time- domain (FDTD) algorithm on a Beowulf cluster of parallel workstations. We discuss synchronization and domain decomposition alternatives. To obtain performance characteristics the algorithm is applied to a test scattering problem. The computation has been done using varying numbers of identical dual-processor AMD Athlon MP- 1800 workstations with the Message Passing Interface (MPI) used to handle the inter- processor communications and the parallel runtime.},
  keywords={},
  doi={10.1109/DIPED.2005.201581},
  ISSN={2165-3593},
  month={Sep.},}
@INPROCEEDINGS{1575810,
  author={Miura, S. and Okamoto, T. and Boku, T. and Sato, M. and Takahashi, D.},
  booktitle={8th International Symposium on Parallel Architectures,Algorithms and Networks (ISPAN'05)}, 
  title={Low-cost high-bandwidth tree network for PC clusters based on tagged-VLAN technology}, 
  year={2005},
  volume={},
  number={},
  pages={8 pp.-},
  abstract={In the present paper, we propose a practical and feasible method to construct VLAN-based fat tree network that provides wide bisection bandwidth on a tree network constructed with cheap Layer-2 Gigabit Ethernet switches for high-performance PC clusters. The proposed method provides a complete flat IP address space with multiple upper-level links and switches to configure a fat tree based on simple routing by IEEE 802.1q tagged VLAN. We modified the pseudo device driver for tagged VLAN on the Linux operating system so as to implement an enhanced control feature in IEEE 802.1q frames in order to build a large-scale fat tree. As a result of preliminary performance evaluation on a small cluster, we confirmed that the proposed system works correctly without increasing the overhead and an ordinary MPI library can be applied without modification to provide wide bisection bandwidth on the system.},
  keywords={},
  doi={10.1109/ISPAN.2005.57},
  ISSN={2375-527X},
  month={Dec},}
@INPROCEEDINGS{1575830,
  author={Ojima, Y. and Sato, M. and Boku, T. and Takahashi, D.},
  booktitle={8th International Symposium on Parallel Architectures,Algorithms and Networks (ISPAN'05)}, 
  title={Design of a software distributed shared memory system using an MPI communication layer}, 
  year={2005},
  volume={},
  number={},
  pages={8 pp.-},
  abstract={We designed and implemented a software distributed shared memory (DSM) system, SCASH-MPI, by using MPI as the communication layer of the SCASH DSM. With MPI as the communication layer, we could use high-speed networks with several clusters and high portability. Furthermore, SCASH-MPI can use high-speed networks with MPI, which is the most commonly available communication library. On the other hand, existing software DSM systems usually use a dedicated communication layer, TCP, or UDP-Ethernet. SCASH-MPI avoids the need for a large amount of pin-down memory for shared memory use that has limited the applications of the original SCASH. In SCASH-MPI, a thread is created to support remote memory communication using MPI. An experiment on a 4-node Itanium cluster showed that the Laplace Solver benchmark using SCASH-MPI achieves a performance comparable to the original SCASH. Performance degradation is only 6.3% in the NPB BT benchmark Class B test. In SCASH-MPI, page transfer does not start until a page fault is detected. To hide the latency of page transmission, we implemented a prefetch function. The latency in BT Class B was reduced by 64% when the prefetch function was used.},
  keywords={},
  doi={10.1109/ISPAN.2005.90},
  ISSN={2375-527X},
  month={Dec},}
@INPROCEEDINGS{1575823,
  author={Wei, Z. and Li, H.F. and Goswami, D.},
  booktitle={8th International Symposium on Parallel Architectures,Algorithms and Networks (ISPAN'05)}, 
  title={Cloning-based checkpoint for localized recovery}, 
  year={2005},
  volume={},
  number={},
  pages={8 pp.-},
  abstract={This paper studies the use of process clones towards localizing recovery in large-scale distributed systems. A clone is a virtual recovery process with a limited life, and is useful for decoupling recovery dependencies among checkpoints. A generic checkpoint dependency graph (CDG) model is used to capture the dependency relations among checkpoints. A Non-atomic Group Checkpoint (NGC) protocol is presented. It is proved that the protocol can result in localized recovery involving a single group when clones are employed. To limit recovery spread, the size of a group should be limited. This paper presents a few interesting results in this aspect: (i) there is no embedded protocol for atomic group formation with a bounded group-size (k-bounded protocol); (ii) a k-bounded atomic group checkpoint protocol requires at least m-1 explicit messages for checkpoint synchronization in a system consisting of m processes. Lastly, a simple k-bounded atomic group checkpoint protocol is presented and proved.},
  keywords={},
  doi={10.1109/ISPAN.2005.26},
  ISSN={2375-527X},
  month={Dec},}
@INPROCEEDINGS{1575851,
  author={Fertre, M. and Morin, C.},
  booktitle={8th International Symposium on Parallel Architectures,Algorithms and Networks (ISPAN'05)}, 
  title={Extending a cluster SSI OS for transparently checkpointing message-passing parallel applications}, 
  year={2005},
  volume={},
  number={},
  pages={6 pp.-},
  abstract={Nowadays, clusters are widely used to execute scientific applications. These applications are often message-passing parallel applications with long execution times. Since the number of nodes in clusters is growing, faults are more frequent. Thus the application execution time may be greater than the mean time before failure (MTBF) of the cluster. To avoid restarting application from the beginning, it is desirable that cluster systems provide some fault tolerant mechanisms such as checkpoint/restart. An approach to implement efficiently this mechanism is to implement it directly in the application or in the communication library. Another approach is to implement it in an operating system dedicated to clusters. This is more complex but let you checkpoint/restart any message-passing application whatever the communication library. This paper presents basic mechanisms for system initiated checkpoint of message-passing parallel applications running on top of a cluster. Performance results obtained from a prototype implemented in KERRIGHED Single System Image cluster Operating System based on LINUX are presented.},
  keywords={},
  doi={10.1109/ISPAN.2005.46},
  ISSN={2375-527X},
  month={Dec},}
@INPROCEEDINGS{1578092,
  author={Yongmei Dai and Zhiyuan Yan},
  booktitle={GLOBECOM '05. IEEE Global Telecommunications Conference, 2005.}, 
  title={Optimal overlapped message passing decoding for quasi-cyclic low-density parity-check codes}, 
  year={2005},
  volume={4},
  number={},
  pages={5 pp.-2399},
  abstract={In this paper, we first present a general scheduling model for the overlapped message passing (OMP) decoding of LDPC codes, and show that maximizing the throughput amounts to minimizing the intra- and inter-iteration waiting times. Then we focus on maximizing the throughput for OMP decoders of quasi-cyclic (QC) LDPC codes using a partly parallel hardware structure, which can be modelled as a data dependency and hardware constrained optimization problem. Finally, we propose a scheduling scheme, which gives the optimal solution to the optimization problem under certain conditions. In comparison to previously proposed scheduling schemes, our new scheduling scheme leads to both higher hardware utilization efficiency (HUE) and greater throughput gain.},
  keywords={},
  doi={10.1109/GLOCOM.2005.1578092},
  ISSN={1930-529X},
  month={Nov},}
@INPROCEEDINGS{1579850,
  author={Glikiotis, G. and Paliouras, V.},
  booktitle={IEEE Workshop on Signal Processing Systems Design and Implementation, 2005.}, 
  title={A low-power termination criterion for iterative LDPC code decoders}, 
  year={2005},
  volume={},
  number={},
  pages={122-127},
  abstract={This paper introduces a novel criterion for the termination of iterations in iterative LDPC Code decoders. The proposed criterion is amenable for VLSI implementation, and it is here shown that it can enhance previously reported LDPC code decoder architectures substantially, by reducing the corresponding power dissipation. The concept of the proposed criterion is the detection of cycles in the sequences of soft words. The soft-word cycles occur in some cases of low signal-to-noise ratios and indicate that the decoder is unable to decide on a codeword, which in turn results in unnecessary power consumption due to iterations that do not improve the bit error rate. The proposed architecture terminates the decoding process when a soft-word cycle occurs, allowing for substantial power savings at a minimal performance penalty. The proposed criterion is applied to hardware-sharing and parallel decoder architectures.},
  keywords={},
  doi={10.1109/SIPS.2005.1579850},
  ISSN={2162-3570},
  month={Nov},}
@INPROCEEDINGS{1592561,
  author={Silva, R.E. and Pezzi, G. and Maillard, N. and Diverio, T.},
  booktitle={17th International Symposium on Computer Architecture and High Performance Computing (SBAC-PAD'05)}, 
  title={Automatic data-flow graph generation of MPI programs}, 
  year={2005},
  volume={},
  number={},
  pages={93-100},
  abstract={The data-flow graph (DFG) of a parallel application is frequently used to take scheduling decisions, based on the information that it models (dependencies among the tasks and volume of exchanged data). In the case of MPI-based programs, the DFG may be built at run-time by overloading the data exchange primitives. This article presents a library that enables the generation of the DFG of a MPI program, and its use to analyze the network contention on a test-application: the Linpack benchmark. It is the first step towards automatic mapping of a MPI program on a distributed architecture.},
  keywords={},
  doi={10.1109/CAHPC.2005.15},
  ISSN={1550-6533},
  month={Oct},}
@INPROCEEDINGS{1592568,
  author={Rodrigues, E.R. and Preto, A.J. and Stephany, S.},
  booktitle={17th International Symposium on Computer Architecture and High Performance Computing (SBAC-PAD'05)}, 
  title={A new parallel environment for interactive simulations implementing safe multithreading with MPI}, 
  year={2005},
  volume={},
  number={},
  pages={151-158},
  abstract={This work presents a new parallel environment for interactive simulations. This environment integrates a MPI-based parallel simulation engine, a visualization module, and a user interface that supports modification of simulation parameters and visualization at runtime. This requires multiple threads, one to execute the simulation or the visualization, and other to receive user input. Since many MPI implementations are not thread-safe, it is proposed a new parallel extension of the Python environment that uses UDP sockets in addition to the calls to the MPI library functions. This approach preserves interactivity, which is required to allow researchers to modify simulation parameters and to visualize results at runtime. The ADKS simulator was chosen as a case study. It is a sequential interactive software for molecular dynamics simulations used in the study of defects in solid materials. The simulation engine was parallelized using non-blocking communication and speedups very close to linear were obtained in the test cases. The proposed approach can be extended to be employed in high performance distributed computing.},
  keywords={},
  doi={10.1109/CAHPC.2005.7},
  ISSN={1550-6533},
  month={Oct},}
@INPROCEEDINGS{1592302,
  author={Jing Chen and Linbo Zhang and Yunquan Zhang and Wei Yuan},
  booktitle={Eighth International Conference on High-Performance Computing in Asia-Pacific Region (HPCASIA'05)}, 
  title={Performance evaluation of Allgather algorithms on terascale Linux cluster with fast Ethernet}, 
  year={2005},
  volume={},
  number={},
  pages={6 pp.-442},
  abstract={We report our work on evaluating performance of several MPI Allgather algorithms on fast Ethernet. These algorithms are ring, recursive doubling, Bruck, and neighbor exchange. The first three algorithms are widely used today. The neighbor exchange algorithm which was proposed by the authors incorporates pair-wise exchange, and is expected to perform better with certain configurations, mainly when using TCP/IP over Ethernet. We tested the four algorithms on terascale Linux clusters DeepComp 6800 and DAWNING 4000A using TCP/IP over fast Ethernet. Results show that our neighbor exchange algorithm performs the best for long messages, the ring algorithm performs the best for medium-size messages and the recursive doubling algorithm performs the best for short messages},
  keywords={},
  doi={10.1109/HPCASIA.2005.75},
  ISSN={},
  month={Nov},}

@INPROCEEDINGS{1607170,
  author={Lallchandani, J.T. and Mall, R.},
  booktitle={12th Asia-Pacific Software Engineering Conference (APSEC'05)}, 
  title={Computation of dynamic slices for object-oriented concurrent programs}, 
  year={2005},
  volume={},
  number={},
  pages={8 pp.-},
  abstract={This paper proposes a novel dynamic slicing technique for object oriented concurrent programs. We introduce the notion of object oriented concurrent program dependence graph (OOCPDG). Our dynamic slicing technique uses OOCPDG as the intermediate representation and is based on marking and unmarking the dependence edges as and when the dependences arise and cease at runtime. Our approach eliminates the use of trace files and is more efficient than existing algorithms. Besides, it encompasses different aspects of object oriented programming paradigm viz. inheritance, polymorphism from the slicing arena. It can handle dynamically created object based processes. It can also handle process interactions through shared memory and message passing. The updating to the intermediate representation is truly concurrent. Multiple processors execute different object based processes concurrently and require special handling. We also report a dynamic slicing tool called CDSOOCP (concurrent dynamic sheer for object oriented concurrent programs) which implements our dynamic slicing technique.},
  keywords={},
  doi={10.1109/APSEC.2005.51},
  ISSN={1530-1362},
  month={Dec},}
@INPROCEEDINGS{1607443,
  author={Huimin Geng and Xutao Deng and Ali, H.},
  booktitle={Fourth International Conference on Machine Learning and Applications (ICMLA'05)}, 
  title={A new clustering algorithm using message passing and its applications in analyzing microarray data}, 
  year={2005},
  volume={},
  number={},
  pages={6 pp.-},
  abstract={In this paper, we proposed a new clustering algorithm that employs the concept of message passing to describe parallel and spontaneous biological processes. Inspired by real-life situations in which people in large gatherings form groups by exchanging messages, message passing clustering (MPC) allows data objects to communicate with each other and produces clusters in parallel, thereby making the clustering process intrinsic and improving the clustering performance. We have proved that MPC shares similarity with hierarchical clustering but offers significantly improved performance because it takes into account both local and global structure. MPC can be easily implemented in a parallel computing platform for the purpose of speed-up. To validate the MPC method, we applied MPC to microarray data from the Stanford yeast cell-cycle database. The results show that MPC gave better clustering solutions in terms of homogeneity and separation values than other clustering methods.},
  keywords={},
  doi={10.1109/ICMLA.2005.3},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{1609960,
  author={Tudruj, M. and Borkowski, J. and Kopanski, D.},
  booktitle={The 4th International Symposium on Parallel and Distributed Computing (ISPDC'05)}, 
  title={Load Balancing with Migration Based on Synchronizers in PS-GRADE Graphical Tool}, 
  year={2005},
  volume={},
  number={},
  pages={105-112},
  abstract={Parallel application control based on application global states is a new concept realized in PS-GRADE. PS-GRADE is a graphical environment for parallel programming, which unifies message passing programming style with control based on global application states. Special processes called synchronizers are responsible for gathering process states, constructing application global states and issuing control signals when necessary to application processes. In this paper, we show how this mechanism can be used as a framework for implementing load balancing with process migration using several methods. With some of these methods, synchronizers collect strongly consistent states of processor loads in the system and workout load balancing decisions including process migration. Asynchronous control signals from synchronizers break current computations and cause a process to migrate onto a less loaded host. Another signal activates a target process and activates restoring of the captured state in it. With other methods we use a special PVM library ynamite PVM instead of a standard version. It extends PVM by checkpointing and process migration with full restoration of the process state},
  keywords={},
  doi={10.1109/ISPDC.2005.33},
  ISSN={2379-5352},
  month={July},}
@INPROCEEDINGS{1616806,
  author={Zhou Rong and Ma Tianyu and Jin Yongjie},
  booktitle={2005 IEEE Engineering in Medicine and Biology 27th Annual Conference}, 
  title={Parallel OSEM Reconstruction Algorithm for Fully 3-D SPECT on a Beowulf Cluster}, 
  year={2005},
  volume={},
  number={},
  pages={1834-1837},
  abstract={In order to improve the computation speed of ordered subset expectation maximization (OSEM) algorithm for fully 3-D single photon emission computed tomography (SPECT) reconstruction, an experimental beowulf-type cluster was built and several parallel reconstruction schemes were described. We implemented a single-program-multiple-data (SPMD) parallel 3-D OSEM reconstruction algorithm based on message passing interface (MPI) and tested it with combinations of different number of calculating processors and different size of voxel grid in reconstruction (64 times 64 times 64 and 128 times 128 times 128). Performance of parallelization was evaluated in terms of the speedup factor and parallel efficiency. This parallel implementation methodology is expected to be helpful to make fully 3-D OSEM algorithms more feasible in clinical SPECT studies},
  keywords={},
  doi={10.1109/IEMBS.2005.1616806},
  ISSN={1558-4615},
  month={Jan},}
@INPROCEEDINGS{1626665,
  author={Xinqian Bian and Hai Zou and Zonghu Chang and Dehui Zhao and Zhiqiu Wang},
  booktitle={IEEE International Conference Mechatronics and Automation, 2005}, 
  title={Multi-thread technology's application in the decision-making system of AUV}, 
  year={2005},
  volume={2},
  number={},
  pages={868-873 Vol. 2},
  abstract={The decision-making system of AUV is very important for the safe and autonomous voyage of AUV during the long range travel. A kind of AUV decision-making system based on multi-thread technology under QNX is implemented in this paper. Hybrid system and supervisory control theory are introduced. A synchronization module combined with QNX message-passing is designed to realize the communication and synchronization between threads in the AUV decision-making software. Finally, we validate the software in a semi-physical computer simulation system.},
  keywords={},
  doi={10.1109/ICMA.2005.1626665},
  ISSN={2152-744X},
  month={July},}
@INPROCEEDINGS{4022225,
  author={Schubert, Tobias and Lewis, Matthew and Becker, Bernd},
  booktitle={2005 Sixth International Workshop on Microprocessor Test and Verification}, 
  title={PaMira - A Parallel SAT Solver with Knowledge Sharing}, 
  year={2005},
  volume={},
  number={},
  pages={29-36},
  abstract={In this paper we describe PaMira, a powerful distributed SAT solver. PaMira is based on the highly optimized, sequential SAT engine Mira, incorporating all essential optimization techniques modern algorithms utilize to maximize performance. For the distributed execution an efficient work stealing method has been implemented. PaMira also employs the exchange of conflict clauses between the processes to guide the search more efficiently. We provide experimental results showing linear speedup on a multiprocessor environment with four AMD Opteron processors},
  keywords={},
  doi={10.1109/MTV.2005.17},
  ISSN={2332-5674},
  month={Nov},}
@INPROCEEDINGS{4154114,
  author={Aouad, Lamine M. and Petiton, Serge G. and Sato, Mitsuhisa},
  booktitle={2005 IEEE International Conference on Cluster Computing}, 
  title={Grid and Cluster Matrix Computation with Persistent Storage and Out-of-core Programming}, 
  year={2005},
  volume={},
  number={},
  pages={1-9},
  abstract={In this paper we present a performance evaluation of a large-scale numerical application on a cluster and a global grid/cluster platform. The computational resources are a cluster of clusters (34 nodes, 84 processors) and a local area network grid (128 nodes), distributed on two geographic sites: Tsukuba University (Japan) and University of Lille I (France). We compare a classical MPI (message passing interface) version with global grid/cluster versions. We also present and test some techniques for numerical applications on a grid/cluster infrastructure based on out-of-core programming and an efficient data placement. We discuss the performances of a block-based Gauss-Jordan method for large matrix inversion. As experimental grid middleware we use the XtremWeb system to manage non-dedicated distributed resources},
  keywords={},
  doi={10.1109/CLUSTR.2005.347071},
  ISSN={2168-9253},
  month={Sep.},}
@INPROCEEDINGS{4154133,
  author={Brandt, J. M. and Gentile, A. C. and Marzouk, Y. M. and Pebay, P. P.},
  booktitle={2005 IEEE International Conference on Cluster Computing}, 
  title={Meaningful Automated Statistical Analysis of Large Computational Clusters}, 
  year={2005},
  volume={},
  number={},
  pages={1-2},
  abstract={As clusters utilizing commercial off-the-shelf technology have grown from tens to thousands of nodes and typical job sizes have likewise increased, much effort has been devoted to improving the scalability of message-passing fabrics, schedulers, and storage. Largely ignored, however, has been the issue of predicting node failure, which also has a large impact on scalability. In fact, more than ten years into cluster computing, we are still managing this issue on a node-by-node basis even though available diagnostic data has grown immensely. We have built a tool that uses the statistical similarity of the large number of nodes in a cluster to infer the health of each individual node. In the poster, we first present real data and statistical calculations as foundational material and justification for our claims of similarity. Next we present our methodology and its implications for early notification of deviation from normal behavior, problem diagnosis, automatic code restart via interaction with scheduler, and airflow distribution monitoring in the machine room. A framework addressing scalability is discussed briefly. Lastly, we present case studies showing how our methodology has been used to detect aberrant nodes whose deviations are still far below the detection level of traditional methods. A summary of the results of the case studies appears below},
  keywords={},
  doi={10.1109/CLUSTR.2005.347090},
  ISSN={2168-9253},
  month={Sep.},}
@ARTICLE{5388787,
  author={Bhanot, G. and Gara, A. and Heidelberger, P. and Lawless, E. and Sexton, J. C. and Walkup, R.},
  journal={IBM Journal of Research and Development}, 
  title={Optimizing task layout on the Blue Gene/L supercomputer}, 
  year={2005},
  volume={49},
  number={2.3},
  pages={489-500},
  abstract={A general method for optimizing problem layout on the Blue Gene®/L (BG/L) supercomputer is described. The method takes as input the communication matrix of an arbitrary problem as an array with entries C(i, j), which represents the data communicated from domain i to domain j. Given C(i, j), we implement a heuristic map that attempts to sequentially map a domain and its communication neighbors either to the same BG/L node or to near-neighbor nodes on the BG/L torus, while keeping the number of domains mapped to a BG/L node constant. We then generate a Markov chain of maps using Monte Carlo simulation with free energy F = ∑i,jC(i, j)H(i, j), where H(i, j) is the smallest number of hops on the BG/L torus between domain i and domain j. For two large parallel applications, SAGE and UMT2000, the method was tested against the default Message Passing Interface rank order layout on up to 2,048 BG/L nodes. It produced maps that improved communication efficiency by up to 45%.},
  keywords={},
  doi={10.1147/rd.492.0489},
  ISSN={0018-8646},
  month={March},}
@ARTICLE{1580411,
  author={Parastatidis, S. and Woodman, S. and Webber, J. and Kuo, D. and Greenfield, P.},
  journal={IEEE Internet Computing}, 
  title={Asynchronous messaging between Web services using SSDL}, 
  year={2006},
  volume={10},
  number={1},
  pages={26-39},
  abstract={The SOAP Service Description Language (SSDL) is designed for describing asynchronous, message-oriented, and multimessage interactions between Web services. SSDL provides the basis for a range of protocol description frameworks. At one end of the spectrum, such frameworks can be simple, SOAP-centric replacements for the Web Services Description Language. At the other end, they're a more expressive contract-definition language enabling formal verification of asynchronous application protocol properties. This is possible because SSDL focuses on the "message" abstraction as the building block for service-oriented applications.},
  keywords={},
  doi={10.1109/MIC.2006.3},
  ISSN={1941-0131},
  month={Jan},}
@INPROCEEDINGS{1581497,
  author={Sairaman, V. and Ranganathan, N. and Singh, N.S.},
  booktitle={19th International Conference on VLSI Design held jointly with 5th International Conference on Embedded Systems Design (VLSID'06)}, 
  title={An automatic code generation tool for partitioned software in distributed systems}, 
  year={2006},
  volume={},
  number={},
  pages={4 pp.-},
  abstract={In distributed heterogeneous systems, the target application is partitioned and the partitions are executed in different computing units while satisfying the dependencies between the code partitions. Code generation is the process of converting the code partitions into individually executable code clusters and satisfying the code dependencies by adding communication primitives to send and receive data between dependent the code clusters. In this work, we describe a code generation tool that is applicable to procedural language based applications for distributed processing. The application programs along with the partition primitives are converted into independently executable concrete implementations. The process consists of two steps, first translating the primitives of the application program into equivalent code clusters, and then scheduling the implementations of these code clusters according to the inherent data dependencies. Further, the original source code needs to be reverse engineered in order to create a meta-data table describing the program elements and dependency trees. This data gathered, is used along with parallel virtual machine (PVM) primitives for enabling the communication between the partitioned programs in the distributed environment. The proposed code generation model has been implemented using C and tested for various application programs for functional verification.},
  keywords={},
  doi={10.1109/VLSID.2006.41},
  ISSN={2380-6923},
  month={Jan},}
@INPROCEEDINGS{1598125,
  author={Yu, H. and Sahoo, R.K. and Howson, C. and Almasi, G. and Castanos, J.G. and Gupta, M. and Moreira, J.E. and Parker, J.J. and Engelsiepen, T.E. and Ross, R.B. and Thakur, R. and Latham, R. and Gropp, W.D.},
  booktitle={The Twelfth International Symposium on High-Performance Computer Architecture, 2006.}, 
  title={High performance file I/O for the Blue Gene/L supercomputer}, 
  year={2006},
  volume={},
  number={},
  pages={187-196},
  abstract={Parallel I/O plays a crucial role for most data-intensive applications running on massively parallel systems like Blue Gene/L that provides the promise of delivering enormous computational capability. We designed and implemented a highly scalable parallel file I/O architecture for Blue Gene/L, which leverages the benefit of the hierarchical and functional partitioning design of the system software with separate computational and I/O cores. The architecture exploits the scalability aspect of GPFS (General Parallel File System) at the backend, while using MPI I/O as an interface between the application I/O and the file system. We demonstrate the impact of our high performance I/O solution for Blue Gene/L with a comprehensive evaluation that consists of a number of widely used parallel I/O benchmarks and I/O intensive applications. Our design and implementation is not only able to deliver at least one order of magnitude speed up in terms of I/O bandwidth for a real-scale application HOMME (achieving aggregate bandwidth of 1.8 GB/Sec and 2.3 GB/Sec for write and read accesses, respectively), but also supports high-level parallel I/O data interfaces such as parallel HDF5 and parallel NetCDF scaling up to a large number of processors.},
  keywords={},
  doi={10.1109/HPCA.2006.1598125},
  ISSN={2378-203X},
  month={Feb},}
@ARTICLE{1621020,
  author={Alfonsi, B.},
  journal={IEEE Distributed Systems Online}, 
  title={In brief: TRECC tackles on-demand computing}, 
  year={2006},
  volume={7},
  number={3},
  pages={7-7},
  abstract={As more and more researchers turn to cluster-based systems to handle intensive computing tasks, the need to prioritize those tasks also increases. We are developing system software for scheduling computing cycles on demand. TRECC's approach to secure cluster computing on demand is a matter of managing workflow. TRECC's work in virtualization is in step with one of the hottest trends in cluster computing. Virtualization works by effectively splitting one or more cluster nodes into a greater number of virtual nodes. To do this, the scheduler needs additional information that lets it decide whether a given job can even run effectively under a virtual environment. The virtualization component currently lets researchers start and stop virtual machines on demand and launch as well as successfully run MPI (message passing interface) jobs inside a virtual machine.},
  keywords={},
  doi={10.1109/MDSO.2006.18},
  ISSN={1541-4922},
  month={March},}
@INPROCEEDINGS{1620445,
  author={Yiming Li and Shao-Ming Yu},
  booktitle={20th International Conference on Advanced Information Networking and Applications - Volume 1 (AINA'06)}, 
  title={Parallel numerical solution to large-scale eigenvalue problem in master equation of protein folding kinetics}, 
  year={2006},
  volume={2},
  number={},
  pages={5 pp.-},
  abstract={A master equation characterizes the time-evolution of trajectories, the transition of states in protein folding kinetics. Numerical solution of the master equation requires calculating eigenvalues for the corresponding large scale eigenvalue problem. In this paper, we present a parallel computing technique to compute the eigenvalues of the matrix with an N-dimensional vector of the instantaneous probability of the N conformations. Parallelization of the implicitly restarted Arnoldi method is successfully implemented on a PC-based Linux cluster. The parallelization scheme used in this work mainly partitions the operations of the matrix. For the Arnoldi factorization, we replicate the upper Hessenberg matrix H/sub m/ for each processor, and distribute the set of Arnoldi vectors V/sub m/ among processors. Each processor performs its own operations. This algorithm is implemented on a PC-based Linux cluster with message passing interface (MPI) libraries. Our preliminary numerical experiment performing on the 32-nodes PC-based Linux cluster has shown that the maximum difference among CPUs is within 10%. A 23 times speedup and 72% parallel efficiency are also attained for the tested cases. This approach enables us to explore large scale dynamics of protein folding.},
  keywords={},
  doi={10.1109/AINA.2006.257},
  ISSN={2332-5658},
  month={April},}
@INPROCEEDINGS{1630793,
  author={Aarestad, P.M. and Ching, A. and Thiruvathukal, G.K. and Choudhary, A.N.},
  booktitle={Sixth IEEE International Symposium on Cluster Computing and the Grid (CCGRID'06)}, 
  title={Scalable Approaches for Supporting MPI-IO Atomicity}, 
  year={2006},
  volume={1},
  number={},
  pages={35-42},
  abstract={Scalable atomic and parallel access to noncontiguous regions of a file is essential to exploit high performance I/O as required by large-scale applications. Parallel I/O frameworks such as MPI I/O conceptually allow I/O to be defined on regions of a file using derived datatypes. Access to regions of a file can be automatically computed on a perprocessor basis using the datatype, resulting in a list of (offset, length) pairs. We describe three approaches for implementing lock serving (whole file, region locking, and byterange locking) and compare the various approaches using three noncontiguous I/O benchmarks. We present the details of the lock server architecture and describe the implementation of a fully-functional prototype that makes use of a lightweight message passing library and red/black trees.},
  keywords={},
  doi={10.1109/CCGRID.2006.88},
  ISSN={},
  month={May},}
@INPROCEEDINGS{1633194,
  author={Fischborn, M. and Kuo-Peng, P. and Sadoswki, N. and Bastos, J.P.A. and Trevisan, J.},
  booktitle={2006 12th Biennial IEEE Conference on Electromagnetic Field Computation}, 
  title={LU Parallel Preconditioning with Block Intersection Applied to FEM on Computer Clusters}, 
  year={2006},
  volume={},
  number={},
  pages={404-404},
  abstract={This work describes the use of a solver with a modified LU preconditioner using an additional intersection parameter among the blocks in order to minimize the weakness due to the blocks decoupling. The LU preconditioning is tested on a cluster computer linked by a Gigabit switch. The program uses SPMD model and MPI library},
  keywords={},
  doi={10.1109/CEFC-06.2006.1633194},
  ISSN={},
  month={April},}
@ARTICLE{1642640,
  author={Marchetti, C. and Baldoni, R. and Tucci-Piergiovanni, S. and Virgillito, A.},
  journal={IEEE Transactions on Parallel and Distributed Systems}, 
  title={Fully distributed three-tier active software replication}, 
  year={2006},
  volume={17},
  number={7},
  pages={633-645},
  abstract={Keeping strongly consistent the state of the replicas of a software service deployed across a distributed system prone to crashes and with highly unstable message transfer delays (e.g., the Internet), is a real practical challenge. The solution to this problem is subject to the FLP impossibility result, and thus there is a need for "long enough" periods of synchrony with time bounds on process speeds and message transfer delays to ensure deterministic termination of any run of agreement protocols executed by replicas. This behavior can be abstracted by a partially synchronous computational model. In this setting, before reaching a period of synchrony, the underlying network can arbitrarily delay messages and these delays can be perceived as false failures by some timeout-based failure detection mechanism leading to unexpected service unavailability. This paper proposes a fully distributed solution for active software replication based on a three-tier software architecture well-suited to such a difficult setting. The formal correctness of the solution is proved by assuming the middle-tier runs in a partially synchronous distributed system. This architecture separates the ordering of the requests coming from clients, executed by the middle-tier, from their actual execution, done by replicas, i.e., the end-tier. In this way, clients can show up in any part of the distributed system and replica placement is simplified, since only the middle-tier has to be deployed on a well-behaving part of the distributed system that frequently respects synchrony bounds. This deployment permits a rapid timeout tuning reducing thus unexpected service unavailability.},
  keywords={},
  doi={10.1109/TPDS.2006.89},
  ISSN={1558-2183},
  month={July},}
@ARTICLE{1642642,
  author={Mostefaoui, A. and Raynal, M. and Travers, C.},
  journal={IEEE Transactions on Parallel and Distributed Systems}, 
  title={Time-free and timer-based assumptions can be combined to obtain eventual leadership}, 
  year={2006},
  volume={17},
  number={7},
  pages={656-666},
  abstract={Leader-based protocols rest on a primitive able to provide the processes with the same unique leader. Such protocols are very common in distributed computing to solve synchronization or coordination problems. Unfortunately, providing such a primitive is far from being trivial in asynchronous distributed systems prone to process crashes. (It is even impossible in fault-prone purely asynchronous systems.) To circumvent this difficulty, several protocols have been proposed that build a leader facility on top of an asynchronous distributed system enriched with additional assumptions. The protocols proposed so far consider either additional assumptions based on synchrony or additional assumptions on the pattern of the messages that are exchanged. Considering systems with n processes and up to f process crashes, 1lesf<n, this paper investigates the combination of a time-free assumption on the message pattern with a synchrony assumption on process speed and message delay. It shows that both types of assumptions can be combined to obtain a hybrid eventual leader protocol benefiting from the best of both worlds. This combined assumption considers a star communication structure involving f+1 processes. Its noteworthy feature lies in the level of combination of both types of assumption that is "as fine as possible" in the sense that each of the f channels of the star has to satisfy a property independently of the property satisfied by each of the f-1 other channels (the f channels do not have to satisfy the same assumption). More precisely, this combined assumption is the following: There is a correct process p (center of the star) and a set Q of f processes q (pnotinQ) such that, eventually, either 1) each time it broadcasts a query, q receives a response from p among the (n-f) first responses to that query, or 2) the channel from p to q is timely. (The processes in the set Q can crash.) A surprisingly simple eventual leader protocol based on this fine grain hybrid assumption is proposed and proved correct. An improvement is also presented},
  keywords={},
  doi={10.1109/TPDS.2006.95},
  ISSN={1558-2183},
  month={July},}
@INPROCEEDINGS{1639316,
  author={Mahawar, H. and Sarin, V.},
  booktitle={Proceedings 20th IEEE International Parallel & Distributed Processing Symposium}, 
  title={Parallel algorithms for inductance extraction of VLSI circuits}, 
  year={2006},
  volume={},
  number={},
  pages={9 pp.-},
  abstract={Inductance extraction involves estimating the mutual inductance in a VLSI circuit. Due to increasing clock speed and diminishing feature sizes of modern VLSI circuits, the effects of inductance are increasingly felt during the testing and verification stages. Hence, there is a need for fast and accurate inductance extraction software. A generalized approach for inductance extraction requires the solution of a dense complex symmetric linear system that models mutual inductive effects among circuit elements. Iterative methods are used to solve the system without explicit computation of the matrix itself. Fast hierarchical techniques are used to compute approximate matrix-vector products with the dense system matrix. This work presents an overview of a new parallel software package for inductance extraction of large VLSI circuits. The technique uses a combination of the solenoidal basis method and effective preconditioning schemes to solve the linear system. Fast multipole method (FMM) is used to compute approximate matrix-vector products with the inductance matrix. By formulating the pre-conditioner as a dense matrix similar to the coefficient matrix, we are able to use FMM for the preconditioning step as well. A two-tier parallelization scheme allows an efficient parallel implementation using both OpenMP and MPI directives simultaneously. The experiments conducted on various multiprocessor machines demonstrate the portability and parallel performance of the software.},
  keywords={},
  doi={10.1109/IPDPS.2006.1639316},
  ISSN={1530-2075},
  month={April},}
@INPROCEEDINGS{1639322,
  author={Shuyi Shao and Jones, A.K. and Melhem, R.},
  booktitle={Proceedings 20th IEEE International Parallel & Distributed Processing Symposium}, 
  title={A compiler-based communication analysis approach for multiprocessor systems}, 
  year={2006},
  volume={},
  number={},
  pages={10 pp.-},
  abstract={In this paper we describe a compiler framework which can identify communication patterns for MPI-based parallel applications. This has the potential of providing significant performance benefits when connections can be established in the network prior to the actual communication operation. Our compiler uses a flexible and powerful communication pattern representation scheme that can capture the property of communication patterns and allows manipulations of these patterns. In this way, communication phases can be detected and logically separated within the application. Additionally, we extend the classification of static and dynamic communication patterns and operations to include persistent communications. Persistent communications appear dynamically, however, they remain unchanged for large segments of the application execution. Our compiler is capable of detecting both static and persistent communication patterns within an application. We show that for the NAS parallel benchmarks, 100% of the point-to-point communications can be classified as either static or persistent and, with the exception of IS, 100% of the collective were either static or persistent. By comparison to application trace data, the predicted LBMHD, CG and MG communication patterns have been verified.},
  keywords={},
  doi={10.1109/IPDPS.2006.1639322},
  ISSN={1530-2075},
  month={April},}
@INPROCEEDINGS{1639567,
  author={Riesen, R.},
  booktitle={Proceedings 20th IEEE International Parallel & Distributed Processing Symposium}, 
  title={Communication patterns [message-passing patterns]}, 
  year={2006},
  volume={},
  number={},
  pages={8 pp.-},
  abstract={Parallel applications have message-passing patterns that are important to understand. Network topology, routing decisions, and connection and buffer management need to match the communication patterns of an application for it to run efficiently and scale well. These patterns are not easily discerned from the source code of an application, and even when the data is available it is not easy to categorize it appropriately such that meaningful knowledge emerges. We describe a novel system to gather the information we need to discover an application's communication pattern. We create five categories that help us analyze that data and explain how information from each category can be useful in the design of networking hardware and software. We use the NAS parallel benchmarks as examples on how to apply our techniques},
  keywords={},
  doi={10.1109/IPDPS.2006.1639567},
  ISSN={1530-2075},
  month={April},}
@INPROCEEDINGS{1639552,
  author={Loulergue, F.},
  booktitle={Proceedings 20th IEEE International Parallel & Distributed Processing Symposium}, 
  title={A calculus of functional BSP programs with projection}, 
  year={2006},
  volume={},
  number={},
  pages={8 pp.-},
  abstract={Bulk synchronous parallel ML (BSML) is an extension of the functional language Objective Caml to program bulk synchronous parallel (BSP) algorithms. It is deterministic, deadlock free and performances are good and predictable. Parallelism is expressed with a set of 4 primitives on a parallel data structure called parallel vector. These primitives are pure functional ones: they have no side-effect. It is thus possible, and we did it, to prove the correctness of BSML programs using a proof assistant like Coq. The BSlambda-calculus is an extension of the lambda-calculus which models the core semantics of BSML. Nevertheless some principles of BSML are not well captured by this calculus. This paper presents a new calculus, with a projection primitive, which provides a better model of the core semantics of BSML},
  keywords={},
  doi={10.1109/IPDPS.2006.1639552},
  ISSN={1530-2075},
  month={April},}
@INPROCEEDINGS{1639578,
  author={Gopalakrishnan, G. and Kirby, R.},
  booktitle={Proceedings 20th IEEE International Parallel & Distributed Processing Symposium}, 
  title={Toward reliable and efficient message passing software through formal analysis}, 
  year={2006},
  volume={},
  number={},
  pages={7 pp.-},
  abstract={The quest for high performance drives parallel scientific computing software design. Well over 60% of the high-performance computing (HPC) community writes programs using the MPI library; to gain performance, they are known to perform many manual optimizations. Even tools that accept high level descriptions often generate MPI code, due to its eminent portability. However, since the overall performance of a program does not usually port (due to variations in the target architecture, cluster size, etc.), manual changes to the code are inevitable in today's approaches to MPI programming and optimization. This, together with the vastness and evolving nature of the MPI standard, and the innate complexity of concurrent programming introduces costly bugs. Our research addresses these challenges through specific efforts in the following broad areas: (i) high level expression of the parallel algorithm and compilation thereof into optimized MPI programs, (ii) optimizations of user-written detailed MPI programs through localized transformations such as barrier removal, (iii) formal modeling of complex communication standards, such as the MPI-2 standard and a facility for answering putative queries (this need arises when standard documents are impossibly difficult to manually study in order to answer questions that are not explicitly addressed in the standard), (iv) formal modeling of new (and hence relatively less well understood) features of communication libraries, such as the one-sided communication facility of MPI-2, and (v) formal modeling of intricate control algorithms in these libraries such as the progress engine for TCP and/or shared memory in MPICH2 (a formal model can explicate commonalities, help formally verify, as well as help create better future implementations). Our research gains focus through numerous collaborations},
  keywords={},
  doi={10.1109/IPDPS.2006.1639578},
  ISSN={1530-2075},
  month={April},}
@INPROCEEDINGS{1639575,
  author={Bronevetsky, G. and Fernandes, R. and Marques, D. and Pingali, K. and Stodghill, P.},
  booktitle={Proceedings 20th IEEE International Parallel & Distributed Processing Symposium}, 
  title={Recent advances in checkpoint/recovery systems}, 
  year={2006},
  volume={},
  number={},
  pages={8 pp.-},
  abstract={Checkpoint and recovery (CPR) systems have many uses in high-performance computing. Because of this, many developers have implemented it, by hand, into their applications. One of the uses of checkpointing is to help mitigate the effects of interruptions in computational service (both planned and unplanned) In fact, some supercomputing centers expect their users to use checkpointing as a matter of policy. And yet, few centers provide fully automatic checkpointing systems for their high-end production machines. The paper is a status report on our work on the family of C3 systems for (almost) fully automatic checkpointing for scientific applications. To date, we have shown that our techniques can be used for checkpointing sequential, MPI and OpenMP applications written in C, Fortran, and several other languages. A novel aspect of our work is that we have not built a single checkpointing system, rather, we have developed a methodology and a set of techniques that have enabled us to develop a number of systems, each meeting different design goals and efficiency requirements},
  keywords={},
  doi={10.1109/IPDPS.2006.1639575},
  ISSN={1530-2075},
  month={April},}
@INPROCEEDINGS{1639619,
  author={Aminian, M. and Akbari, M.K. and Javadi, B.},
  booktitle={Proceedings 20th IEEE International Parallel & Distributed Processing Symposium}, 
  title={Coordinated checkpoint from message payload in pessimistic sender-based message logging}, 
  year={2006},
  volume={},
  number={},
  pages={6 pp.-},
  abstract={Execution of MPI applications on clusters and grid deployments suffers from node and network failure that motivates the use of fault tolerant MPI implementations. Two category techniques have been introduced to make these systems fault-tolerant. The first one is checkpoint-based technique and the other one is called log-based recovery protocol. Sender-based pessimistic logging which falls in the second category is harnessing from huge amount of messages payloads which must be kept in volatile memory. In this paper, we present a coordinated checkpoint from message payload (CCMP) to reduce the aforementioned overhead. The proposed method was examined by MPICH-V2, a public domain platform implementing pessimistic logging with uncoordinated checkpoint. Experimental results demonstrated the reduction of run-time for NPB benchmarks in both fault-free and faulty environments.},
  keywords={},
  doi={10.1109/IPDPS.2006.1639619},
  ISSN={1530-2075},
  month={April},}
@INPROCEEDINGS{1639631,
  author={Hamid, N.A.W.A. and Coddington, P. and Vaughan, F.},
  booktitle={Proceedings 20th IEEE International Parallel & Distributed Processing Symposium}, 
  title={Comparison of MPI benchmark programs on an SGI Altix ccNUMA shared memory machine}, 
  year={2006},
  volume={},
  number={},
  pages={8 pp.-},
  abstract={The results produced by five different MPI benchmark programs on an SGI Altix 3700 are analyzed and compared. There are significant differences in the results for some MPI operations. We investigate the reasons for these discrepancies, which are due to differences in the measurement techniques, implementation details and default configurations of the different benchmarks. The variation in results on the Altix are generally much greater than on a distributed memory machine, due primarily to the ccNUMA architecture and the importance of cache effects, as well as some implementation details of the SGI MPI libraries},
  keywords={},
  doi={10.1109/IPDPS.2006.1639631},
  ISSN={1530-2075},
  month={April},}
@INPROCEEDINGS{1639657,
  author={Herrera, J. and Huedo, E. and Montero, R.S. and Llorente, I.M.},
  booktitle={Proceedings 20th IEEE International Parallel & Distributed Processing Symposium}, 
  title={Loosely-coupled loop scheduling in computational grids}, 
  year={2006},
  volume={},
  number={},
  pages={6 pp.-},
  abstract={Loop distribution is one of the most useful techniques to reduce the execution time of parallel applications. Traditionally, loop scheduling algorithms are implemented based on parallel programming paradigms such as MPI. This approximation presents three main disadvantages when applied in a grid environment, namely: (i) all resources must be simultaneously allocated to begin execution of the application; (ii) it is necessary to restart the whole application when a resource fails; (iii) it is not possible to add new resources to a currently running application. To overcome these limitations, we propose a new approach to implement loop distribution schemes in computational Grids. This approach is implemented using the distributed resource management application API (DRMAA) standard and the GridWay meta-scheduling framework. The efficiency of this approach to solve the Mandelbrot set problem is analyzed in a Globus-based research testbed},
  keywords={},
  doi={10.1109/IPDPS.2006.1639657},
  ISSN={1530-2075},
  month={April},}
@INPROCEEDINGS{1649198,
  author={Challenger, M. and Bayat, P. and Meybodi, M.R.},
  booktitle={2nd International Conference on Testbeds and Research Infrastructures for the Development of Networks and Communities, 2006. TRIDENTCOM 2006.}, 
  title={A reliable optimization on distributed mutual exclusion algorithm}, 
  year={2006},
  volume={},
  number={},
  pages={8 pp.-566},
  abstract={This paper presents a reliable decentralized mutual exclusion algorithm for distributed systems in which processes communicate by asynchronous message passing. When any failure happens in system, the algorithm protects the distributed system against any crash. It also makes possible the recovery of lost data in system. It requires between (N-1) and 2(N-1) messages per critical section access, where N is the number of processes in the system. The exact message complexity can be expressed as a order function of clients in computation. The algorithm does not introduce any other overhead over Lamport's and Ricart-Agrawala's algorithms, which require 3(N-1) and 2(N-1) messages per critical section access, respectively.},
  keywords={},
  doi={10.1109/TRIDNT.2006.1649198},
  ISSN={},
  month={March},}
@INPROCEEDINGS{1633505,
  author={Ekwall, R. and Schiper, A.},
  booktitle={International Conference on Dependable Systems and Networks (DSN'06)}, 
  title={Solving Atomic Broadcast with Indirect Consensus}, 
  year={2006},
  volume={},
  number={},
  pages={156-165},
  abstract={In previous work, it has been shown how to solve atomic broadcast by reduction to consensus on messages. While this solution is theoretically correct, it has its limitations in practice, since executing consensus on large messages can quickly saturate the system. The problem can be addressed by executing consensus on message identifiers instead of the full messages, in order to decouple the size of the messages from the size of the data sent by the consensus algorithm. In this paper, we study the impact of executing consensus on message identifiers instead of on the full messages, in the context of solving atomic broadcast. We also discuss the implications of executing consensus on message identifiers on the consensus and atomic broadcast algorithms},
  keywords={},
  doi={10.1109/DSN.2006.65},
  ISSN={2158-3927},
  month={June},}
@INPROCEEDINGS{1652189,
  author={Lei Ni and Harwood, A.},
  booktitle={2006 15th IEEE International Conference on High Performance Distributed Computing}, 
  title={An Implementation of the Message Passing Interface over an Adaptive Peer-to-Peer Network}, 
  year={2006},
  volume={},
  number={},
  pages={371-372},
  abstract={Achieving high performance parallel computing requires both a large scale and reliable system. We describe our design and implementation of the message passing interface, called MPICH-OPeN, for parallel computing over a peer-to-peer network to address this challenge. Our implementation uses the Condor standalone checkpoint library and the Chandy-Lamport algorithm, for reliability, with extensions to make it decentralized. We use the OPeN architecture with an adaptive peer-to-peer protocol that caches connections between peers according to communication requirements of the parallel processes. We used PlanetLab to compare the performance of our implementation to MPICH-P4 and to measure the impact of dynamic peers on parallel program execution},
  keywords={},
  doi={10.1109/HPDC.2006.1652189},
  ISSN={1082-8907},
  month={June},}
@INPROCEEDINGS{1654595,
  author={Javadi, B. and Abawajy, J.H. and Akbari, M.K.},
  booktitle={12th International Conference on Parallel and Distributed Systems - (ICPADS'06)}, 
  title={Analytical modeling of communication latency in multi-cluster systems}, 
  year={2006},
  volume={2},
  number={},
  pages={6 pp.-},
  abstract={This paper addresses the problem of performance modeling of large-scale distributed systems with emphasis on communication networks in heterogeneous multi-cluster systems. The study of interconnection networks is important because the overall performance of a distributed system is often critically hinged on the effectiveness of this part. We present an analytical model to predict message latency in multi-cluster systems in the presence of processor heterogeneity. The model is validated through comprehensive simulation, which demonstrates that the proposed model exhibits a good degree of accuracy for various system sizes and under different operating conditions},
  keywords={},
  doi={10.1109/ICPADS.2006.26},
  ISSN={1521-9097},
  month={July},}
@INPROCEEDINGS{1656979,
  author={Izosimov, V. and Pop, P. and Eles, P. and Zebo Peng},
  booktitle={Proceedings of the Design Automation & Test in Europe Conference}, 
  title={Synthesis of Fault-Tolerant Schedules with Transparency/Performance Trade-offs for Distributed Embedded Systems}, 
  year={2006},
  volume={1},
  number={},
  pages={1-6},
  abstract={In this paper we present an approach to the scheduling of fault-tolerant embedded systems for safety-critical applications. Processes and messages are statically scheduled, and we use process re-execution for recovering from multiple transient faults. If process recovery is performed such that the operation of other processes is not affected, we call it transparent recovery. Although transparent recovery has the advantages of fault containment, improved debugability and less memory needed to store the fault-tolerant schedules, it will introduce delays that can violate the timing constraints of the application. We propose a novel algorithm for the synthesis of fault-tolerant schedules that can handle the transparency/performance trade-offs imposed by the designer, and makes use of the fault-occurrence information to reduce the overhead due to fault tolerance. We model the application as a conditional process graph, where the fault occurrence information is represented as conditional edges and the transparent recovery is captured using synchronization nodes.},
  keywords={},
  doi={10.1109/DATE.2006.244067},
  ISSN={1558-1101},
  month={March},}
@ARTICLE{1687843,
  author={Schelfthout, K. and Weyns, D. and Holvoet, T.},
  journal={IEEE Distributed Systems Online}, 
  title={Middleware for Protocol-Based Coordination in Mobile Applications}, 
  year={2006},
  volume={7},
  number={8},
  pages={1-1},
  abstract={In distributed mobile applications, component interaction is complicated by dynamics in the environment. In mobile applications, nodes continuously come and go and change interaction partners, complicating this exchange. For protocol-based coordination, existing middleware approaches - such as publish/subscribe systems or tuplespaces-based systems - support the initial interaction partner discovery, but don't support interaction partner maintenance over prolonged interaction sessions or easy protocol modularization. We propose extending these middleware approaches with suitable abstractions to better support protocol-based interaction in mobile applications. To test our approach, we created ObjectPlaces, a middleware that uses roles as its main abstraction. ObjectPlaces middleware supports the development of interaction protocols in dynamic, mobile environments to facilitate component coordination},
  keywords={},
  doi={10.1109/MDSO.2006.50},
  ISSN={1541-4922},
  month={Aug},}
@INPROCEEDINGS{1690689,
  author={Guisado, J.L. and de Vega, F.F. and Iskra, K.},
  booktitle={2006 International Conference on Parallel Processing Workshops (ICPPW'06)}, 
  title={Performance analysis of a parallel discrete model for the simulation of laser dynamics}, 
  year={2006},
  volume={},
  number={},
  pages={7 pp.-99},
  abstract={This paper presents an analysis on the performance of a parallel implementation of a discrete model of laser dynamics, which is based on cellular automata. The performance of a 2D parallel version of the model is studied as a first step to test the feasibility of a parallel 3D version, which is needed to simulate specific laser systems. The 3D version will have to run on a parallel computer due to its runtime and memory requirements. The model has been implemented on a Beowulf cluster using the message passing paradigm. The parallel implementation is found to exhibit a good speedup, allowing us to run realistic simulations of laser systems on clusters of workstations, which could not be afforded on an individual machine due to the extensive runtime and memory size needed.},
  keywords={},
  doi={10.1109/ICPPW.2006.62},
  ISSN={2332-5690},
  month={Aug},}
@INPROCEEDINGS{1690688,
  author={Yong Wei and Hongyu Wang and Bhandarkar, S.M. and Kang Li},
  booktitle={2006 International Conference on Parallel Processing Workshops (ICPPW'06)}, 
  title={Parallel algorithms for motion panorama construction}, 
  year={2006},
  volume={},
  number={},
  pages={8 pp.-92},
  abstract={A motion panorama is an efficient and compact representation of the underlying video. However, the motion panorama construction process is computationally intensive and hence extremely time consuming. Addressing this issue is crucial when one considers using motion panoramas in a real-time environment such as live video transmission. We present two parallel algorithms for motion panorama construction, namely, the shared memory parallel algorithm (SMPA) that uses POSIX threads and the distributed memory parallel algorithm (DMPA) that uses MPI. The parallel algorithms are tested on real videos. Experimental results show that the SMPA achieves linear speedup in most cases whereas the DMPA suffers from reduced efficiency when the number of processors exceeds 8},
  keywords={},
  doi={10.1109/ICPPW.2006.59},
  ISSN={2332-5690},
  month={Aug},}
@INPROCEEDINGS{1693779,
  author={Shimizu, K. and Ishikawa, T. and Togawa, N. and Ikenaga, T. and Goto, S.},
  booktitle={2006 IEEE International Symposium on Circuits and Systems}, 
  title={A parallel LSI architecture for LDPC decoder improving message-passing schedule}, 
  year={2006},
  volume={},
  number={},
  pages={4 pp.-},
  abstract={This paper proposes a parallel LSI architecture for LDPC decoder which improves a message-passing schedule. The proposed LDPC decoder is characterized as follows: (i) the column operations follow the row operations in a pipelined architecture to ensure that the row and column operations are performed concurrently; and (ii) the proposed parallel pipelined bit functional unit enables the decoder to perform every column operation using the messages which is updated by the row operations. These column operations can be performed without extending the single iterative decoding delay. Hardware implementation and simulation results show that the proposed decoder improves the decoding throughput and bit error performance with a small hardware overhead},
  keywords={},
  doi={10.1109/ISCAS.2006.1693779},
  ISSN={2158-1525},
  month={May},}
@ARTICLE{1710383,
  author={Mansour, M.M.},
  journal={IEEE Transactions on Signal Processing}, 
  title={A Turbo-Decoding Message-Passing Algorithm for Sparse Parity-Check Matrix Codes}, 
  year={2006},
  volume={54},
  number={11},
  pages={4376-4392},
  abstract={A turbo-decoding message-passing (TDMP) algorithm for sparse parity-check matrix (SPCM) codes such as low-density parity-check, repeat-accumulate, and turbo-like codes is presented. The main advantages of the proposed algorithm over the standard decoding algorithm are 1) its faster convergence speed by a factor of two in terms of decoding iterations, 2) improvement in coding gain by an order of magnitude at high signal-to-noise ratio (SNR), 3) reduced memory requirements, and 4) reduced decoder complexity. In addition, an efficient algorithm for message computation using simple “max” operations is also presented. Analysis using EXIT charts shows that the TDMP algorithm offers a better performance–complexity tradeoff when the number of decoding iterations is small, which is attractive for high-speed applications. A parallel version of the TDMP algorithm in conjunction with architecture-aware (AA) SPCM codes, which have embedded structure that enables efficient high-throughput decoder implementation, are presented. Design examples of AA-SPCM codes based on graphs with large girth demonstrate that AA-SPCM codes have very good error-correcting capability using the TDMP algorithm.},
  keywords={},
  doi={10.1109/TSP.2006.880240},
  ISSN={1941-0476},
  month={Nov},}
@INPROCEEDINGS{1684774,
  author={Muller, O. and Baghdadi, A. and Jezequel, M.},
  booktitle={2006 2nd International Conference on Information & Communication Technologies}, 
  title={Exploring Parallel Processing Levels for Convolutional Turbo Decoding}, 
  year={2006},
  volume={2},
  number={},
  pages={2353-2358},
  abstract={In forward error correction, convolutional turbo codes were introduced to increase error correction capability approaching the Shannon bound. Decoding of these codes, however, is an iterative process requiring high computation rate and latency. Thus, in order to achieve high throughput and to reduce latency, crucial in emerging digital communication applications, parallel implementations become mandatory. In this paper, we explore the parallelism in convolutional turbo decoding with the BCJR algorithm and propose a multi-level classification of the explored parallelism techniques. We also present promising results on sub-block and component-decoder levels of parallelism. Sub-block parallelism results show that for sub-block initializations, message passing technique outperforms the acquisition approach. Furthermore, sub-block parallelism becomes quite inefficient in terms of speed gain for high sub-block parallelism degree. Conversely component-decoder parallelism efficiency, which only depends on interleaving rules, increases with sub-block parallelism degree},
  keywords={},
  doi={10.1109/ICTTA.2006.1684774},
  ISSN={},
  month={April},}
@INPROCEEDINGS{1690651,
  author={Gao, Qi and Yu, Weikuan and Huang, Wei and Panda, Dhabaleswar K.},
  booktitle={2006 International Conference on Parallel Processing (ICPP'06)}, 
  title={Application-Transparent Checkpoint/Restart for MPI Programs over InfiniBand}, 
  year={2006},
  volume={},
  number={},
  pages={471-478},
  abstract={Ultra-scale computer clusters with high speed interconnects, such as InfiniBand, are being widely deployed for their excellent performance and cost effectiveness. However, the failure rate on these clusters also increases along with their augmented number of components. Thus, it becomes critical for such systems to be equipped with fault tolerance support. In this paper, we present our design and implementation of checkpoint/restart framework for MPI programs running over InfiniBand clusters. Our design enables low-overhead, application-transparent checkpointing. It uses coordinated protocol to save the current state of the whole MPI job to reliable storage, which allows users to perform rollback recovery if the system runs into faulty states later. Our solution has been incorporated into MVAPICH2, an open-source high performance MPI-2 implementation over InfiniBand. Performance evaluation of this implementation has been carried out using NAS benchmarks, HPL benchmark, and a real-world application called GROMACS. Experimental results indicate that in our design, the overhead to take checkpoints is low, and the performance impact for checkpointing applications periodically is insignificant. For example, time for checkpointing GROMACS is less than 0.3% of the execution time, and its performance only decreases by 4% with checkpoints taken every minute. To the best of our knowledge, this work is the first report of checkpoint/restart support for MPI over InfiniBand clusters in the literature},
  keywords={},
  doi={10.1109/ICPP.2006.26},
  ISSN={2332-5690},
  month={Aug},}
@INPROCEEDINGS{1698648,
  author={Kozakiewicz, A. and Karbowski, A.},
  booktitle={International Symposium on Parallel Computing in Electrical Engineering (PARELEC'06)}, 
  title={A Two-Level Approach to Building a Campus Grid}, 
  year={2006},
  volume={},
  number={},
  pages={121-126},
  abstract={The article proposes a two-layered system for distributed computation. The setup combines two different tools - Globus and Mosix - in order to harness the computing power wasted in unused student laboratories. The system is easy to set up and use. We present the results of experiments on a simple testbed, using the Google PageRank algorithm as an example task},
  keywords={},
  doi={10.1109/PARELEC.2006.11},
  ISSN={},
  month={Sep.},}
@INPROCEEDINGS{1698665,
  author={Hoefler, T. and Viertel, C. and Mehlan, T. and Mietke, F. and Rehm, W.},
  booktitle={International Symposium on Parallel Computing in Electrical Engineering (PARELEC'06)}, 
  title={Assessing Single-Message and Multi-Node Communication Performance of InfiniBand}, 
  year={2006},
  volume={},
  number={},
  pages={227-232},
  abstract={We present a micro benchmark suite to evaluate InfiniBandTM implementations with regards to single message performance and the addressing of many hosts. We use a 1:n communication pattern to assess the latency and bandwidth for all different combinations of InfiniBandsTM transport services and functions. The results gathered in this study are used to optimize MPI collective communication operations where 1:n communication schemes are not used widely today. We show that applications as well as collective algorithms can benefit from sending multiple messages in a single round. Moreover, the results will be used to choose the transport service and function to develop InfiniBandTM optimized collective communication functions. Our study compares all available transport options and shows that single packet sends can be very expensive compared to multi packet sends.},
  keywords={},
  doi={10.1109/PARELEC.2006.16},
  ISSN={},
  month={Sep.},}
@INPROCEEDINGS{1698696,
  author={Qi Huang and Jianbo Yi and Shi Jing and Ke Huang},
  booktitle={International Symposium on Parallel Computing in Electrical Engineering (PARELEC'06)}, 
  title={Development of an MPI for Power System Distributed Parallel Computing in Wide Area Network with P2P Technology}, 
  year={2006},
  volume={},
  number={},
  pages={411-416},
  abstract={The analysis of modern power system becomes more computation intensive, and has to be performed in a dispersed IT infrastructure due to the inherently distributed topology of power system. Grid computing is potentially an ideal solution for electric power system and power network infrastructure also provides potential application field for grid computing because grid computing is most efficient in a large organization. This paper presents a new version of MPI (message passing interface) based on P2P, WD-MPI, in order to exploit the maximum performance in a heterogeneous environment for power system distributed computing. The problems of traditional MPI and some versions of modified MPI to improve its performance on heterogeneous and wide area network are analyzed. The system structure is presented and the design of the system, including asynchronous iterative algorithm, task and resource partition, is presented. The power flow calculation problem of an IEEE 300 bus system is used to compare the performances of the proposed scheme and previous solutions. The test is performed in a grid environment built in campus, which can simulate the behavior of wide area network to some extent. The test results show that the P2P based WD-MPI can give better performance than that of MPICH, MPICH-G2 and Globus solution},
  keywords={},
  doi={10.1109/PARELEC.2006.30},
  ISSN={},
  month={Sep.},}
@INPROCEEDINGS{4020109,
  author={Michlmayr, Anton and Fenkam, Pascal and Dustdar, Schahram},
  booktitle={30th Annual International Computer Software and Applications Conference (COMPSAC'06)}, 
  title={Architecting a Testing Framework for Publish/Subscribe Applications}, 
  year={2006},
  volume={1},
  number={},
  pages={467-474},
  abstract={The publish/subscribe style is an emerging paradigm for the construction of loosely coupled systems. Yet, the verification of such systems remains difficult. We have constructed a framework called RAY for testing publish/subscribe applications. This framework is implemented as an Eclipse plug-in. In this paper, we present the detailed architecture of RAY, as well as the interaction with its supporting components. In addition to the presented architecture for a testing framework for publish/subscribe applications, the contribution of this paper includes the experience gained during the development of this framework},
  keywords={},
  doi={10.1109/COMPSAC.2006.28},
  ISSN={0730-3157},
  month={Sep.},}
@INPROCEEDINGS{4021912,
  author={Bruda, Stefan D. and Haggholm, Petter and Stoddard, Scott},
  booktitle={2006 Fifth International Symposium on Parallel and Distributed Computing}, 
  title={Distributed, Real-Time Programming on Commodity POSIX Systems: A Preliminary Report}, 
  year={2006},
  volume={},
  number={},
  pages={74-81},
  abstract={We present an incipient implementation of a programming language that allows programming of real-time applications distributed over a network. We have several goals in mind: First, the language should be built on a sound semantics and offer support for model-based conformance testing. At the same time the language should place the normal programmer (who tends to shy away from exceedingly formal constructs) in a comfortable environment. Thirdly, programs written in this language should run on commodity systems, without relying on real-time support from the kernel. Finally, the language separates the code from timing restrictions, thus allowing for code re-use},
  keywords={},
  doi={10.1109/ISPDC.2006.21},
  ISSN={2379-5352},
  month={July},}
@INPROCEEDINGS{4021939,
  author={Keller, Rainer and Resch, Michael},
  booktitle={2006 Fifth International Symposium on Parallel and Distributed Computing}, 
  title={Testing the Correctness of MPI Implementations}, 
  year={2006},
  volume={},
  number={},
  pages={291-295},
  abstract={This paper introduces an MPI test suite to thoroughly test the correctness of an MPI-implementation. Scientific applications require stable tools and libraries for portable and efficient programming, e. g. when depending on the single-sided communication on multiple platforms. This test suite was originally used to check the correct transmission of data in the PACX-MPI implementation, but has been mainly used and extended to test the development of the new Open MPI implementation. The tool has been designed to be easily extendible in order to integrate new tests using the underlying functionality},
  keywords={},
  doi={10.1109/ISPDC.2006.47},
  ISSN={2379-5352},
  month={July},}
@INPROCEEDINGS{4021942,
  author={Borkowski, J. and Kopanski, D. and Tudruj, M.},
  booktitle={2006 Fifth International Symposium on Parallel and Distributed Computing}, 
  title={Usage of Global States-Based Application Control}, 
  year={2006},
  volume={},
  number={},
  pages={309-316},
  abstract={The novel parallel/distributed application control method, discussed in this paper, is based on the use of global states monitoring. Application processes report their local states to monitors. The monitors construct global states, analyze them and send control signals to processes to stimulate necessary actions. A number of application areas of this control method are examined. Tests results and gained experience are presented for irregular computation, load balancing and dynamic workflow implementations. It is shown, that the new control method can lead to a better performance than message passing and that it provides a useful and convenient framework, facilitating program development and maintenance.},
  keywords={},
  doi={10.1109/ISPDC.2006.53},
  ISSN={2379-5352},
  month={July},}
@INPROCEEDINGS{4022071,
  author={Lirkov, Ivan and Magenov, Svetozar and Paprzycki, Marcin},
  booktitle={IEEE John Vincent Atanasoff 2006 International Symposium on Modern Computing (JVA'06)}, 
  title={Benchmarking Performance of an MPI-based Solver for 3D Elasticity Problems}, 
  year={2006},
  volume={},
  number={},
  pages={260-265},
  abstract={Numerical solution of 3D linear elasticity equations is considered. Problem is described by a coupled system of second order elliptic partial differential equations. This system is discretized by trilinear parallelepipedal finite elements. Preconditioned conjugate gradient iterative method is used for solving large-scale linear algebraic systems arising after the finite element method (FEM) discretization of the problem. The displacement decomposition technique is applied at the first step to construct a preconditioner using the decoupled block-diagonal part of the original matrix. Then circulant block-factorization is used to precondition thus obtained block-diagonal matrix. Since both preconditioning techniques, displacement decomposition and circulant block-factorization, are highly parallelizable, a portable parallel FEM code based on MPI is developed. Results of numerical tests performed on a number of modern parallel computers using real-life engineering problems from the geomechanics in geosciences are reported and discussed},
  keywords={},
  doi={10.1109/JVA.2006.9},
  ISSN={},
  month={Oct},}
@INPROCEEDINGS{4026106,
  author={Wu, Qinmu and Li, Yesong and Qin, Yi},
  booktitle={2006 International Conference on Mechatronics and Automation}, 
  title={A Scheduling Method Based on Deadline for CAN-based Networked Control Systems}, 
  year={2006},
  volume={},
  number={},
  pages={345-350},
  abstract={In order to satisfy timeliness of messages and improve system's flexibility in networked control systems (NCS) based on controller area network (CAN), a distributed dynamic message scheduling method based on deadline of message (DM) was proposed. In this method, provided that a message is successfully transmitted, transmission requirement of the next message immediately occurs in the same node. If only a node obtains a chance of sending message, the message can be successfully transmitted to the destination. Identifier of message is dynamically changed in this method, the change does rely on elapsed time (since the preceding message can be transmitted) and the DM. The longer the elapsed time is or the shorter DM is, the higher priority level of message is. When the DM satisfies a certain condition, the method can guarantee that all messages are transmitted within given DM and fairly allocate network bandwidth to message streams. Nodes using this scheduling method also have high flexibility. A necessary condition of full schedulability of messages is obtained and the condition is proved, some examples verify its correctness},
  keywords={},
  doi={10.1109/ICMA.2006.257539},
  ISSN={2152-744X},
  month={June},}
@INPROCEEDINGS{4027166,
  author={Wang, Wei and Yang, Wu and Zhang, Lejun and Guo, Lin},
  booktitle={2006 Seventh International Conference on Web-Age Information Management Workshops}, 
  title={Testing Path Generation Algorithm with Network Performance Constraints for Nondeterministic Parallel Programs}, 
  year={2006},
  volume={},
  number={},
  pages={6-6},
  abstract={Nondeterministic behaviors of parallel programs require dedication software testing functionality. It is very difficult to test nondeterministic parallel programs systematically. Although plain reachability testing method can deal with the non-determinism, it may generate huge number of execution paths during the testing procedure. This condition is intractable to cope with in practice. Adding some appropriate constraints to plain reachability testing strategy can improve its efficiency. By analyzing the relationship between message passing behavior and the network performance, the present study proposes a limited reachability testing algorithm for message-passing parallel programs by considering network performance constraints. The number of execution paths is reduced greatly by only considering those execution paths with higher happening possibility according to the network performance constraints. In this way, large-scale parallel programs can be tested more efficiently, and the testing completeness is reasonable.},
  keywords={},
  doi={10.1109/WAIMW.2006.29},
  ISSN={},
  month={June},}
@INPROCEEDINGS{4031220,
  author={Dijkman, Remco and Dirgahayu, Teduh and Quartel, Dick},
  booktitle={2006 10th IEEE International Enterprise Distributed Object Computing Conference (EDOC'06)}, 
  title={Towards Advanced Interaction Design Concepts}, 
  year={2006},
  volume={},
  number={},
  pages={331-344},
  abstract={In this paper we analyse the interaction mechanisms provided by Web services technology and by CORBA. Specifically we analyse the request/response, callback, polling and (multicast) message passing mechanisms. As a result we present coloured Petri nets that capture the behaviour of these mechanisms precisely. Based on our analysis we define concepts for representing the Web services and CORBA interactions in a suitable and platform independent manner. These concepts can be used for platform independent design of distributed applications, while they (provably) maintain the consistency with platform specific implementations. Because their behaviour is defined by Petri nets, the concepts also support simulation, validation and verification of designs. We also evaluate the suitability of UML's concepts for representing the mechanisms and the degree of platform independence that these concepts can achieve},
  keywords={},
  doi={10.1109/EDOC.2006.71},
  ISSN={1541-7719},
  month={Oct},}
@INPROCEEDINGS{4032165,
  author={Gong, Xue-rong and Sheng, Yong-hong and Lu, Lin-sheng and Zhang, Ping},
  booktitle={2006 Seventh International Conference on Parallel and Distributed Computing, Applications and Technologies (PDCAT'06)}, 
  title={An Improved Automatic MPI Code Generation Algorithm for Distributed Memory Machine}, 
  year={2006},
  volume={},
  number={},
  pages={132-137},
  abstract={This paper presents an overview of our ongoing project KAP, which aims to build a message-passing parallelizing compiler for distributed-memory machines. In this paper, an improved automatic code generation algorithm is discussed. Our algorithm uses the data and computation decomposition, and the reading and writing access functions to create the communication code. We can not only solve the problems which the conventional algorithm can do but also can solve another kind of problem. In such cases: there is no data dependence and the read access is not aligned in the loop nest, or the exact data-flow analysis is not given because of the limitation of the algorithm of LWT, the conventional algorithm can not create communication code correctly while our improved algorithm can resolve this problem. Experiments prove that the novel algorithm can achieve satisfactory effect},
  keywords={},
  doi={10.1109/PDCAT.2006.32},
  ISSN={2379-5352},
  month={Dec},}
@INPROCEEDINGS{4032478,
  author={Baldoni, R. and Malek, M. and Milani, A. and Piergiovanni, S. Tucci},
  booktitle={2006 25th IEEE Symposium on Reliable Distributed Systems (SRDS'06)}, 
  title={Weakly-Persistent Causal Objects in Dynamic Distributed Systems}, 
  year={2006},
  volume={},
  number={},
  pages={165-174},
  abstract={In the context of clients accessing a read/write shared object, persistency of a written value is a property stating that a value written into the object is always available unless overwritten by a successive write operation. This property can be easily guaranteed in a static distributed system provided that either a subset of processes implementing the object does not crash or processes can crash and then recover being able to retrieve their last state. Unfortunately the enforcing of this property in a potentially large scale and dynamic distributed system (e.g. a P2P system) is far from being trivial when considering the case in which processes implementing the object may fail or leave at any time without notifying any other process (i.e., the last state might not be retrievable). The paper introduces the notion of weak persistency that guarantees persistency of values when a system becomes quiescent (arrivals and departures subside). An implementation of a weakly-persistent object ensuring causal consistency is provided along with its correctness proof. The interest of causal consistency lies in the fact that, contrarily to atomic consistency, it can be maintained even during non-quiescent periods of the distributed system (i.e., when persistency is not guaranteed)},
  keywords={},
  doi={10.1109/SRDS.2006.47},
  ISSN={1060-9857},
  month={Oct},}
@INPROCEEDINGS{4036259,
  author={Nimbalker, Ajit and Blankenship, Yufei and Classon, Brian},
  booktitle={2006 IEEE International Symposium on Information Theory}, 
  title={Turbo-like Decoding Algorithm for Structured LDPC codes}, 
  year={2006},
  volume={},
  number={},
  pages={1708-1712},
  abstract={This paper presents a high-speed "turbo-like" decoding algorithm for certain structured LDPC codes such as those adopted in IEEE 802.16e and in the draft 802.11n standards. It is shown that after a key modification, such LDPC codes may be processed as generalized repeat accumulate codes, codes which are known to support "turbo-like" decoding. A GRA-like encoder of structured LDPC codes is derived, which in turn leads to the decoding algorithm. It is also shown that the "structured" properties result in an inherent parallelism, leading to an efficient high speed decoder implementation},
  keywords={},
  doi={10.1109/ISIT.2006.261646},
  ISSN={2157-8117},
  month={July},}
@INPROCEEDINGS{4036189,
  author={Smarandache, Roxana and Pusane, Ali Emre and Vontobel, Pascal O. and Costello, Daniel J.},
  booktitle={2006 IEEE International Symposium on Information Theory}, 
  title={Pseudo-Codewords in LDPC Convolutional Codes}, 
  year={2006},
  volume={},
  number={},
  pages={1364-1368},
  abstract={Iterative message-passing decoders for low-density parity-check (LDPC) block codes are known to be subject to decoding failures due to so-called pseudo-codewords. These failures can cause the large signal-to-noise ratio performance of message-passing decoding to be worse than that predicted by the maximum-likelihood decoding union bound. In this paper we study the pseudo-codeword problem for the class of LDPC convolutional codes decoded continuously using an iterative, sliding window, message-passing decoder. In particular, for an LDPC convolutional code derived by unwrapping a quasi-cyclic LDPC block code, we show that the free pseudo-weight of the convolutional code is at least as large as the minimum pseudo-weight of the underlying quasi-cyclic code. This result parallels the well-known relationship between the free Hamming distance of convolutional codes and the minimum Hamming distance of their quasi-cyclic counterparts. Finally, simulation results are included that show improved performance for unwrapped LDPC convolutional codes compared to their underlying quasi-cyclic codes},
  keywords={},
  doi={10.1109/ISIT.2006.262069},
  ISSN={2157-8117},
  month={July},}
@INPROCEEDINGS{4036460,
  author={Ruttik, Kalle},
  booktitle={2006 IEEE International Symposium on Information Theory}, 
  title={Calculation of Mutual Information between Messages in Loops of a Tanner Graph}, 
  year={2006},
  volume={},
  number={},
  pages={2685-2688},
  abstract={This paper introduces a method for calculating the mutual information between the messages sent to a loop and returning from a loop in a Tanner graph. This mutual information is defined as the difference between the cases when the loop is open and the loop is closed. The proposed method suggests to track the change of information in each node in the loop. The paper explains in detail how to calculate the amount of information change in a node},
  keywords={},
  doi={10.1109/ISIT.2006.262141},
  ISSN={2157-8117},
  month={July},}
@INPROCEEDINGS{4036590,
  author={Velipasalar, Senem and Schlessman, Jason and Chen, Cheng-yao and Wolf, Wayne and Singh, Jaswinder Pal},
  booktitle={2006 IEEE International Conference on Multimedia and Expo}, 
  title={SCCS: A Scalable Clustered Camera System for Multiple Object Tracking Communicating Via Message Passing Interface}, 
  year={2006},
  volume={},
  number={},
  pages={277-280},
  abstract={We introduce the scalable clustered camera system, a peer-to-peer multi-camera system for multi-object tracking, where different CPUs are used to process inputs from distinct cameras. Instead of transferring control of tracking jobs from one camera to another, each camera in our system performs its own tracking and keeps its own tracks for each target object, thus providing fault tolerance. A fast and robust tracking method is proposed to perform tracking on each camera view, while maintaining consistent labeling. In addition, we introduce a new communication protocol, where the decisions about when and with whom to communicate are made such that frequency and size of transmitted messages are minimized. This protocol incorporates variable synchronization capabilities, so as to allow flexibility with accuracy tradeoffs. We discuss our implementation, consisting of a parallel computing cluster, with communication between the cameras performed by MPI. We present experimental results which demonstrate the success of the proposed peer-to-peer multi-camera tracking system, with accuracy of 95% for a high frequency of synchronization, as well as a worst-case of 15 frames of latency in recovering correct labels at low synchronization frequencies},
  keywords={},
  doi={10.1109/ICME.2006.262452},
  ISSN={1945-788X},
  month={July},}
@INPROCEEDINGS{4054886,
  author={Carter, J. and Gardner, W.B.},
  booktitle={2006 Canadian Conference on Electrical and Computer Engineering}, 
  title={A Formal CSP Framework for Message-Passing HPC Programming}, 
  year={2006},
  volume={},
  number={},
  pages={1466-1470},
  abstract={To help programmers of high-performance computing (HPC) systems avoid communication-related errors, we employ a formal process algebra, communicating sequential processes (CSP), which has a strict semantics for interprocess communication and synchronization. Verification tools are available for CSP-specified programs to prove the absence of failures such as deadlock, and to explore potential multiprocess interactions. By introducing a CSP abstraction layer on top of the popular MPI message-passing primitives, we create a framework, called CSP4MPI, designed to largely hide the complexity of parallel programming for HPC. CSP4MPI is comprised of a C++ class library that provides a CSP-based process model, and a "cookbook" of candidate solutions for HPC programmers not trained in CSP. Developers can prototype their systems using CSP, and use verification tools to examine possible points of failure before implementing via the CSP4MPI library. Alternatively, they may choose an existing, verified solution from a number of common parallel application archetypes. By using CSP4MPI, HPC developers leverage the benefits of formal specification and verification in their work, in addition to obtaining an alternate method to developing HPC applications},
  keywords={},
  doi={10.1109/CCECE.2006.277495},
  ISSN={0840-7789},
  month={May},}
@INPROCEEDINGS{4054648,
  author={Monwar, Md. Maruf and Rezaei, Siamak},
  booktitle={2006 Canadian Conference on Electrical and Computer Engineering}, 
  title={A Parallel Processing Approach for Information Extraction from Microarray Images}, 
  year={2006},
  volume={},
  number={},
  pages={123-126},
  abstract={DNA microarray experiments generate a substantial amount of information about global gene expression. Information extracted from images of microarray data can be used for clustering or the identification of differentially expressed genes which can be used in determining the function of cells, comparing healthy and unhealthy tissues and observing changes after the application of drugs. The proposed system introduces parallelism in the intensity extraction and clustering method using message passing interface technique. Due to the huge volume of microarray data, the serial version of microarray image analysis method takes longer time. The proposed system reduces the overall time complexity by processing many pixels of the spatial images of the microarray data simultaneously},
  keywords={},
  doi={10.1109/CCECE.2006.277628},
  ISSN={0840-7789},
  month={May},}
@INPROCEEDINGS{4062535,
  author={Ahmed, Dewan Tanvir and Shirmohammadi, Shervin and Kazem, Ihab},
  booktitle={2006 IEEE International Workshop on Haptic Audio Visual Environments and their Applications (HAVE 2006)}, 
  title={Zone Based Messaging in Collaborative Virtual Environments}, 
  year={2006},
  volume={},
  number={},
  pages={165-170},
  abstract={Massively multi-user simulation requires synchronous communication among the parties. In this paper, we present a multiuser collaboration architecture that divides the virtual world in multiple adjacent hexagonal regions in order to properly organize the entities and efficiently manage their liaison. An especial node, named hybrid node, be in charge of each hexagonal region and constructs a data distribution tree at the application layer rather at the network layer. While constructing the data distribution pathways among the end-hosts, protocol focuses to reflect the physical topology onto the overlay network to enhance the system performance. To control the excessive message overhead, necessary messages of a foreign region are only imported when needed to a particular region through a hybrid node. Dynamic adjustment of cheek-in and check-out marks reduces frequent connections and disconnections between a hybrid and an ordinary node, and provides resilience to the system. The effectiveness of this collaboration architecture is tested through the implementation},
  keywords={},
  doi={10.1109/HAVE.2006.283794},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{4067926,
  author={Akhlaghi, Soroush and Khandani, Amir K. and Falahati, Abolfazl},
  booktitle={2006 40th Annual Conference on Information Sciences and Systems}, 
  title={A New Fast Density Evolution Method for LDPC Codes Using Higher Order Statistics}, 
  year={2006},
  volume={},
  number={},
  pages={845-850},
  abstract={Density evolution (DE) is a technique for tracking the distribution of the log likelihood ratio (LLR) messages exchanged between the variable nodes and the check nodes in a bipartite graph. It is widely assumed that these distributions are close to Gaussian. However, in many scenarios, this assumption is not valid, e.g., the case that the signal to noise ratio (SNR) is low, or the degree of variable nodes exceeds a certain threshold. This article introduces a new (suboptimal) method for DE algorithm in low-density parity-check (LDPC) codes. We provide a more accurate model for the distribution of message bits (as compared to Gaussian) through matching the first n statistical moments. An iterative message passing algorithm is proposed to compute these moments from the graphical representation of the underlying code. We show that the proposed algorithm results in an improved estimate of the underlying EXIT chart as compared to using a Gaussian assumption. In this respect, the proposed method achieves a performance very close to that of the best earlier methods, while it offers a much lower complexity.},
  keywords={},
  doi={10.1109/CISS.2006.286585},
  ISSN={},
  month={March},}
@INPROCEEDINGS{4067922,
  author={Cole, Chad A. and Wilson, Stephen G. and Hall, Eric. K. and Giallorenzi, Thomas R.},
  booktitle={2006 40th Annual Conference on Information Sciences and Systems}, 
  title={Analysis and Design of Moderate Length Regular LDPC Codes with Low Error Floors}, 
  year={2006},
  volume={},
  number={},
  pages={823-828},
  abstract={The traditional method to estimate code performance in the higher SNR region is to use a sum of the contributions of the most dominant error events to the probability of error. If an ML decoder is used, these events will be minimum distance codewords; the traditional decoder used in LDPC codes, some variant of the message passing algorithm, will introduce non-codeword error events known as trapping sets. For long LDPC codes it is difficult to enumerate all of these dominant error events. A procedure to efficiently find dominant error events by using the regular low-density structure of an LDPC code is presented here. The search method can be adapted to work with LDPC codes of various regular and irregular degree distributions, but is especially suited to a very practical subset of LDPC known as regular {3, 6} codes of moderate block length. We also show how codes with very low error floors can be created by utilizing this search method.},
  keywords={},
  doi={10.1109/CISS.2006.286581},
  ISSN={},
  month={March},}
@INPROCEEDINGS{4067994,
  author={Zhong, Wei and Garcia-Frias, Javier},
  booktitle={2006 40th Annual Conference on Information Sciences and Systems}, 
  title={Parallel LDGM Codes for the Transmission of Highly Correlated Senders over Rayleigh Fading Multiple Access Channels}, 
  year={2006},
  volume={},
  number={},
  pages={1230-1235},
  abstract={We investigate the use of LDGM codes for the transmission of two highly correlated senders over a Rayleigh fading multiple access channel. Each one of the senders is encoded independently, and without knowledge of the correlation parameters, using an LDGM code. Decoding is performed in a common receiver, which exploits the correlation between the senders by performing message passing in a graph jointly describing the correlation model and the channel codes. The resulting performance surpasses the theoretical limits obtained when separation between source and channel coding is assumed. As opposed to the case of uncorrelated senders, the performance loss when the channel state information is not available at the decoder is practically non-existent.},
  keywords={},
  doi={10.1109/CISS.2006.286653},
  ISSN={},
  month={March},}
@INPROCEEDINGS{4086892,
  author={Cole, Chad A. and Wilson, Stephen G. and Hall, Eric K. and Giallorenzi, Thomas R.},
  booktitle={MILCOM 2006 - 2006 IEEE Military Communications conference}, 
  title={Regular {4, 8} LDPC Codes and Their Lowerror Floors}, 
  year={2006},
  volume={},
  number={},
  pages={1-7},
  abstract={Regular LDPC codes are a special class of low-density codes having an equal number of ones in each row and column of the parity check matrix describing the linear code. The uniform structure of regular LDPC codes allows a practical hardware implementation which can efficiently utilize the inherent parallelism of the message passing algorithm (MPA) commonly used to decode low-density codes. The class of {3,6} LDPC codes has been extensively studied and they have been proven to provide very good error performance, especially at lower SNR. {4,8} codes have not been analyzed nearly as much in the literature, mainly because their 'threshold,' the SNR where the waterfall region of the error performance curve begins, is typically a quarter of a dB or so worse than for comparable-length {3,6} codes. It has been proposed that {4,8} codes have better high SNR behavior, but until recently it was not possible to verify this conjecture. A new technique which can efficiently find error floors of LDPC codes now has the ability to illuminate just how good {4,8} codes are in the high SNR region-a result which is of great interest for many practical applications. This paper will analyze the error floor characteristics of some {4,8} codes and provide a simple algorithm for designing {4,8} codes with low error floors. A newly-designed rate-1/2 (1200,600) {4,8} code with a vastly superior error floor compared to codes of similar parameters is introduced},
  keywords={},
  doi={10.1109/MILCOM.2006.302365},
  ISSN={2155-7586},
  month={Oct},}
@INPROCEEDINGS{4090192,
  author={Coti, Camille and Herault, Thomas and Lemarinier, Pierre and Pilard, Laurence and Rezmerita, Ala and Rodriguez, Eric and Cappello, Franck},
  booktitle={SC '06: Proceedings of the 2006 ACM/IEEE Conference on Supercomputing}, 
  title={Blocking vs. Non-Blocking Coordinated Checkpointing for Large-Scale Fault Tolerant MPI}, 
  year={2006},
  volume={},
  number={},
  pages={18-18},
  abstract={A long-term trend in high-performance computing is the increasing number of nodes in parallel computing platforms, which entails a higher failure probability. Fault programming environments should be used to guarantee the safe execution of critical applications. Research in fault tolerant MPI has led to the development of several fault tolerant MPI environments. Different approaches are being proposed using a variety of fault tolerant message passing protocols based on coordinated checkpointing or message logging. The most popular approach is with coordinated checkpointing. In the literature, two different concepts of coordinated checkpointing have been proposed: blocking and non-blocking. However they have never been compared quantitatively and their respective scalability remains unknown. The contribution of this paper is to provide the first comparison between these two approaches and a study of their scalability. We have implemented the two approaches within the MPICH environments and evaluate their performance using the NAS parallel benchmarks},
  keywords={},
  doi={10.1109/SC.2006.15},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{4100365,
  author={Plimpton, Steven J. and Brightwell, Ron and Vaughan, Courtenay and Underwood, Keith and Davis, Mike},
  booktitle={2006 IEEE International Conference on Cluster Computing}, 
  title={A Simple Synchronous Distributed-Memory Algorithm for the HPCC RandomAccess Benchmark}, 
  year={2006},
  volume={},
  number={},
  pages={1-7},
  abstract={The RandomAccess benchmark as defined by the High Performance Computing Challenge (HPCC) tests the speed at which a machine can update the elements of a table spread across global system memory, as measured in billions (giga) of updates per second (GUPS). The parallel implementation provided by HPCC typically performs poorly on distributed-memory machines, due to updates requiring numerous small point-to-point messages between processors. We present an alternative algorithm which treats the collection of P processors as a hypercube, aggregating data so that larger messages are sent, and routing individual datums through dimensions of the hypercube to their destination processor. The algorithm's computation (the GUP count) scales linearly with P while its communication overhead scales as log2(P), thus enabling better performance on large numbers of processors. The new algorithm achieves a GUPS rate of 19.98 on 8192 processors of Sandia's Red Storm machine, compared to 1.02 for the HPCCprovided algorithm on 10350 processors. We also illustrate how GUPS performance varies with the benchmark's specification of its "look-ahead" parameter. As expected, parallel performance degrades for small look-ahead values, and improves dramatically for large values.},
  keywords={},
  doi={10.1109/CLUSTR.2006.311859},
  ISSN={2168-9253},
  month={Sep.},}
@INPROCEEDINGS{4100357,
  author={Hoarau, William and Lemarinier, Pierre and Herault, Thomas and Rodriguez, Eric and Tixeuil, Sebastien and Cappello, Franck},
  booktitle={2006 IEEE International Conference on Cluster Computing}, 
  title={FAIL-MPI: How Fault-Tolerant Is Fault-Tolerant MPI?}, 
  year={2006},
  volume={},
  number={},
  pages={1-10},
  abstract={One of the topics of paramount importance in the development of cluster and grid middleware is the impact of faults since their occurrence in grid infrastructures and in large-scale distributed systems is common. MPI (message passing interface) is a popular abstraction for programming distributed and parallel applications. FAIL (FAult Injection Language) is an abstract language for fault occurrence description capable of expressing complex and realistic fault scenarios. In this paper, we investigate the possibility of using FAIL to inject faults in a fault-tolerant MPI implementation. Our middleware, FAIL-MPI, is used to carry quantitative and qualitative faults and stress testing},
  keywords={},
  doi={10.1109/CLUSTR.2006.311851},
  ISSN={2168-9253},
  month={Sep.},}
@INPROCEEDINGS{4100383,
  author={Zhang, Yueyue and Apon, Amy},
  booktitle={2006 IEEE International Conference on Cluster Computing}, 
  title={Implementation Tradeoffs of the Array Files Library for Out-of-Core Computations}, 
  year={2006},
  volume={},
  number={},
  pages={1-8},
  abstract={The array files (AF) API facilitates the manipulation of a large number of records in a message-passing cluster application. Three AF implementations are studied. AFv1 and AFv2 assume the existence of an underlying parallel file system and can be used by PVM or MPI message passing programs. Testing over NSF, PVFS, and Lustre were performed. AFv1 uses separate files on the parallel file system to store different records. AFv2 uses a large file on the parallel file system to store all the records. File locking is used to enforce POSIX file access semantics, and AFv1 and AFv2 provide an application-level locking service for parallel file systems that do not support a native lock subsystem. AFv3 is implemented using MPI-2 and can be used by MPI-2 applications. AFv3 implements parallel I/O with an object-based striping strategy, has no central server, uses a hash function to locate an I/O server, and provides POSIX file access semantics to the user application. AFv2 over PVFS shows somewhat better performance for some workloads with very large records. AFv3 is shown to have better performance than both AFv1 and AFv2 for the broadest range of workloads},
  keywords={},
  doi={10.1109/CLUSTR.2006.311877},
  ISSN={2168-9253},
  month={Sep.},}
@INPROCEEDINGS{4100380,
  author={Gruber, Ralf and Keller, Vincent and Leriche, Emmanuel and Habisreutinger, Marc-antoine},
  booktitle={2006 IEEE International Conference on Cluster Computing}, 
  title={Can a Helmholtz solver run on a cluster?}, 
  year={2006},
  volume={},
  number={},
  pages={1-8},
  abstract={Our vectorized Helmholtz solver runs at 85% efficiency on a NEC SX-5. The most time-consuming parts have been ported on SMP, NUMA, and cluster architectures. It is shown that an OpenMP version can deliver similar performance when running it on a 16 processor SGI Altix. A partial parallelisation using MPI is made to validate the Gamma model to predict application behaviours on parallel machines. This model is then applied to simulate the behaviour of a hypothetical full MPI version on different distributed memory machines. It is found that only the Cray XT3 with its very fast internode communication network will be able to deliver the performance of a NEC SX-8 with the advantage that bigger case could be handled},
  keywords={},
  doi={10.1109/CLUSTR.2006.311874},
  ISSN={2168-9253},
  month={Sep.},}
@INPROCEEDINGS{4100378,
  author={Duarte, Angelo and Rexachs, Dolores and Luque, Emilio},
  booktitle={2006 IEEE International Conference on Cluster Computing}, 
  title={Increasing the cluster availability using RADIC}, 
  year={2006},
  volume={},
  number={},
  pages={1-8},
  abstract={The redundant array of distributed independent checkpoints (RADIC) is a fault tolerant architecture based on a fully distributed array of dedicated process. These processes collaborate to create a fault tolerance controller which transparently manages all fault tolerance activities. The architecture is designed as a software layer between the application and the cluster structure and it was developed to attend to the requirements of scalability, user transparency and independency of dedicated/stable cluster resources. RADIC only requires the resources already available in the nodes used by the parallel application and it uses a pessimistic message-log rollback-recovery protocol in order to operate without any global synchronization. Such protocol, together with the independence of central elements, makes RADIC a scalable architecture that works transparently to the user. We tested the functionality and performance of the architecture in a real scenario using a prototype based on the MPI standard (RADICMPI)},
  keywords={},
  doi={10.1109/CLUSTR.2006.311872},
  ISSN={2168-9253},
  month={Sep.},}
@INPROCEEDINGS{4100414,
  author={Alonso, Pedro and Vidal, Antonio M. and Lastovetsky, Alexey L.},
  booktitle={2006 IEEE International Conference on Cluster Computing}, 
  title={A Parallel Algorithm for the Solution of the Deconvolution Problem on Heterogeneous Networks}, 
  year={2006},
  volume={},
  number={},
  pages={1-9},
  abstract={In this work we present a parallel algorithm for the solution of a least squares problem with structured matrices. This problem arises in many applications mainly related to digital signal processing. The parallel algorithm is designed to speed up the sequential one on heterogeneous networks of computers. The parallel algorithm follows the HeHo strategy (Heterogeneous distribution of processes over processors with homogeneous distribution of computations over the processes) and is implemented using HeteroMPI, a recently developed extension of MPI for programming high performance computations on heterogeneous networks of computers. The obtained results validate HeteroMPI as a very useful tool for portable implementation of parallel algorithms for heterogeneous environments},
  keywords={},
  doi={10.1109/CLUSTR.2006.311908},
  ISSN={2168-9253},
  month={Sep.},}
@INPROCEEDINGS{4100399,
  author={Baker, Mark and Grove, Matthew},
  booktitle={2006 IEEE International Conference on Cluster Computing}, 
  title={A Virtual Registry For Wide-Area Messaging}, 
  year={2006},
  volume={},
  number={},
  pages={1-10},
  abstract={Tycho is a reference implementation of a combined extensible wide-area messaging framework with a built in distributed registry for publishing and discovering remote end-points. This paper describes the architecture of Tycho as well as the design and functionality of its virtual registry (VR). We explain why we have designed Tycho to reuse existing infrastructure where possible and the advantages of a messaging system with a built in registry. We discuss the pluggable design of the VR and how that can be used to provide inter-operation with other systems. After highlighting our innovative use of the Internet relay chat protocol within the VR, we present the results of a series of tests designed to measure the performance of the VR. We then compare the performance of Tycho with R-GMA and Globus's MDS4, which have similar functionality. The paper concludes with a number of observations about Tycho's VR performance, functionality, and how these can be enhanced in the future},
  keywords={},
  doi={10.1109/CLUSTR.2006.311893},
  ISSN={2168-9253},
  month={Sep.},}
@INPROCEEDINGS{4106581,
  author={Yang, You and Jiang, Gangyi and Yu, Mei and Zhu, Dingju},
  booktitle={2006 International Conference on Image Processing}, 
  title={Parallel Process of Hyper-Space-Based Multiview Video Compression}, 
  year={2006},
  volume={},
  number={},
  pages={521-524},
  abstract={Multiview video coding (MVC) is a key technology in free-viewpoint television. MVC based on traditional existing codec system has been studied widely, but all of them need powerful computational capacity in processing. Parallel process of MVC can facilitate the efficient implementation of encoder and decoder and has been required as a function by MPEG. In this paper, a parallelization methodology for MVC based on hyper-space theory is presented and tested on the local area multi-computer - message passing interface (LAM-MPI) parallel platform and modified H.264 codec. Experimental results show that the proposed method can speed up processing of multiview video compression and obtain high rate-distortion results.},
  keywords={},
  doi={10.1109/ICIP.2006.312391},
  ISSN={2381-8549},
  month={Oct},}
@INPROCEEDINGS{4106518,
  author={Schonberg, Daniel and Draper, Stark and Ramchandran, Kannan},
  booktitle={2006 International Conference on Image Processing}, 
  title={On Compression of Encrypted Images}, 
  year={2006},
  volume={},
  number={},
  pages={269-272},
  abstract={Coding schemes for secure and efficient communication over noiseless public channels traditionally compress and then encrypt the source data. In some cases reversing the ordering of compression and encryption would be useful, e.g., in enabling the efficient distribution of protected media content. Indeed, not only is it possible to reverse the order, but under some conditions neither security nor compression efficiency need be sacrificed. In earlier work on this problem we have assumed that the source data is either memoryless or has a 1-D Markov structure. Such models are poor matches for the 2-D structure of images. In this work, we use a 2-D source model, and develop a scheme to compress encrypted images based on LDPC codes. We present practical simulation results for compressing bi-level images. In tests, we are able to compress an encrypted 10, 000 bit bi-level image to 4, 299 bits and successfully recover the image exactly. In previous works, the best analogous 1-D model (operating on a raster scanned data sequence of the same source) could only compress the image to 7, 710 bits.},
  keywords={},
  doi={10.1109/ICIP.2006.313177},
  ISSN={2381-8549},
  month={Oct},}
@INPROCEEDINGS{4119258,
  author={Flanagan, Mark F. and Craddock, John and Fewer, Colm P. and Redmond, Stephen J.},
  booktitle={2006 IEEE Information Theory Workshop - ITW '06 Chengdu}, 
  title={A Euclidean Geometry Based Algebraic Construction Technique for Girth-8 Gallager LDPC Codes}, 
  year={2006},
  volume={},
  number={},
  pages={76-80},
  abstract={A construction technique is proposed for low-density parity-check (LDPC) codes based on finite Euclidean geometries EG(m,2s). These codes are shown to be regular Gallager codes with Tanner graphs of girth eight. The minimum distance of these codes is shown to be lower-bounded by 2m. The codes are also amenable to an efficient partly parallel decoder implementation, which may be used in conjunction with the turbo decoding message passing (TDMP) algorithm for LDPC decoding. Finally, simulation results show that these codes have very good error-correcting performance},
  keywords={},
  doi={10.1109/ITW2.2006.323760},
  ISSN={},
  month={Oct},}
@INPROCEEDINGS{4119254,
  author={Mohajer, Soheil and Shokrollahi, Amin},
  booktitle={2006 IEEE Information Theory Workshop - ITW '06 Chengdu}, 
  title={Raptor Codes with Fast Hard Decision Decoding Algorithms}, 
  year={2006},
  volume={},
  number={},
  pages={56-60},
  abstract={In this paper we will investigate the performance of Raptor codes using Gallager's majority decoding algorithm on the binary symmetric channels. We obtain equations which relate the error probability to the outputnode degree distribution and then we design good degree distributions using the differential evolution (DE) method},
  keywords={},
  doi={10.1109/ITW2.2006.323756},
  ISSN={},
  month={Oct},}
@INPROCEEDINGS{4134036,
  author={Tracy, Fred T.},
  booktitle={2006 HPCMP Users Group Conference (HPCMP-UGC'06)}, 
  title={Accuracy and Performance Testing of Three-Dimensional Unsaturated Flow Finite Element Groundwater Programs on the Cray XT3 Using Analytical Solutions}, 
  year={2006},
  volume={},
  number={},
  pages={73-79},
  abstract={Because Richards' equation for describing unsaturated groundwater flow is highly nonlinear, it is challenging to test the accuracy and efficiency of parallel three-dimensional finite element groundwater programs used to model such activities as remediation of military sites and computing flows and pressures in levees broken by Hurricane Katrina. To aid in this testing, the author has derived steady-state and transient analytical solutions for unsaturated flow. With these solutions, both accuracy of the numerical solutions and the performance of the parallel versions of the computer programs may be easily tested. The other significant feature of these analytical solutions is that the amount of nonlinearity of the equation may be easily adjusted by a parameter a. This paper first presents the equations for the analytical solutions of steady-state and transient flow into a rectangular block of initially dry soil. It then uses the program FEMWATER as a benchmark to compute the numerical solutions corresponding to these analytical solutions. Accuracy results for various sizes of the mesh and numbers of processing elements (PEs) on the Cray XT3 are computed for different values of a. The number of nonlinear iterations for the steady-state problem is also reported. The result of the accuracy assessment is that as a is increased, the errors also increase significantly with even 512 PEs not being enough compute power to adequately solve the problem. Overall parallel performance and performance of the message passing interface calls for updating the ghost nodes and are also tested with results given. The result of this study is that scaling of a 1,000,000-element problem was good up to 256 PEs (64 PEs is the typical sweet spot for FEMWATER), and the performance of the ghost-node updating routine met or exceeded expectations},
  keywords={},
  doi={10.1109/HPCMP-UGC.2006.2},
  ISSN={},
  month={June},}
@INPROCEEDINGS{4134093,
  author={Gardiner, Judy and Nehrbass, John and Chaves, Juan Carlos and Guilfoos, Brian and Ahalt, Stanley and Krishnamurthy, Ashok and Unpingco, Jose and Chalker, Alan and Samsi, Siddharth},
  booktitle={2006 HPCMP Users Group Conference (HPCMP-UGC'06)}, 
  title={Enhancements to MatlabMPI: Easier Compilation, Collective Communication, and Profiling}, 
  year={2006},
  volume={},
  number={},
  pages={435-439},
  abstract={This paper provides a brief overview of several enhancements made to the MatlabMPI suite. MatlabMPI is a pure MATLAB code implementation of the core parts of the MPI specifications. The enhancements provide a more attractive option for HPCMP users to design parallel MATLAB code. Intelligent compiler configuration tools have also been delivered to further isolate MatlabMPI users from the complexities of the UNIX environments on the various HPCMP systems. Users are now able to install and use MatlabMPI with less difficulty, greater flexibility, and increased portability. Collective communication functions were added to MatlabMPI to expand functionality beyond the core implementation. Profiling capabilities, producing TAU (tuning and analysis utility) trace files, are now offered to support parallel code optimization. All of these enhancements have been tested and documented on a variety of HPCMP systems. All material, including commented example code to demonstrate the usefulness of MatlabMPI, is available by contacting the authors},
  keywords={},
  doi={10.1109/HPCMP-UGC.2006.24},
  ISSN={},
  month={June},}
@INPROCEEDINGS{4150746,
  author={Spencer, Quentin H.},
  booktitle={IEEE Globecom 2006}, 
  title={CTH14-6: Error Correction Using a Message-Passing Decoder to Process Cyclic Redundancy Checks}, 
  year={2006},
  volume={},
  number={},
  pages={1-5},
  abstract={This paper proposes a method for correcting errors in messages encoded using cyclic redundancy checks (CRCs), which are typically only used for error detection. This is accomplished for messages of a known length by deriving a parity-check matrix representation of the CRC. The parity-check matrix can then be used to correct errors using the message-passing decoder (MPD) commonly used to decode LDPC codes. The CRC parity-check matrix is not sparse, which inhibits performance of the MPD, but this effect can be reduced by modifying the matrix using recently proposed sparsification techniques to eliminate short cycles. The technique is practical mainly for codes with short block sizes, and can also be applied to coding schemes that concatenate a CRC with an outer error correcting code. Simulation results demonstrate some performance gains, although less than what can be gained using custom-designed LDPC codes for the same rate and message length.},
  keywords={},
  doi={10.1109/GLOCOM.2006.116},
  ISSN={1930-529X},
  month={Nov},}
@INPROCEEDINGS{4150790,
  author={Zhang, Zhengya and Dolecek, Lara and Nikolic, Borivoje and Anantharam, Venkat and Wainwright, Martin},
  booktitle={IEEE Globecom 2006}, 
  title={GEN03-6: Investigation of Error Floors of Structured Low-Density Parity-Check Codes by Hardware Emulation}, 
  year={2006},
  volume={},
  number={},
  pages={1-6},
  abstract={Several high performance LDPC codes have parity-check matrices composed of permutation submatrices. We design a parallel-serial architecture to map the decoder of any structured LDPC code in this large family to a hardware emulation platform. A peak throughput of 240 Mb/s is achieved in decoding the (2048,1723) Reed-Solomon based LDPC (RS-LDPC) code. Experiments in the low bit error rate (BER) region provide statistics of the error traces, which are used to investigate the causes of the error floor. In a low precision implementation, the error floors are dominated by the fixed-point decoding effects, whereas in a higher precision implementation the errors are attributed to special configurations within the code, whose effect is exacerbated in a fixed-point decoder. This new characterization leads to an improved decoding strategy and higher performance.},
  keywords={},
  doi={10.1109/GLOCOM.2006.160},
  ISSN={1930-529X},
  month={Nov},}
@INPROCEEDINGS{4151182,
  author={Kashima, Tsuyoshi and Fukawa, Kazuhiko and Suzuki, Hiroshi},
  booktitle={IEEE Globecom 2006}, 
  title={SPC04-3: Parallel Channel Estimator for Iterative MAP Receiver using Message-Passing Algorithm}, 
  year={2006},
  volume={},
  number={},
  pages={1-5},
  abstract={This paper proposes a parallel recursive least square (P-RLS) channel estimator for the iterative maximum a posteriori (MAP) receiver. The targeted system is the low-density-parity-check (LDPC) coded multiple-input-multiple-output (MIMO) and orthogonal frequency-division multiplexing (OFDM) system. The proposed estimator, which can be theoretically derived from the message-passing algorithm, can track a fast fading channel, and allows the parallel implementation of the whole receiver. A simplified version of P-RLS (SP-RLS) that can reduce the computational complexity is also proposed. Compared to the RLS with smoothing and removing (SR-RLS), P-RLS can reduce the computational time by parallelization, and SP-RLS can further reduce the computational time and complexity. Computer simulations show that SP-RLS achieves almost the same packet error rate (PER) performance as that of P-RLS. It also achieves almost the same PER performance as that of SR-RLS with double iterations. Even in this case, the computational time and complexity of SP-RLS are smaller than those of SR-RLS.},
  keywords={},
  doi={10.1109/GLOCOM.2006.552},
  ISSN={1930-529X},
  month={Nov},}
@INPROCEEDINGS{4179613,
  author={Musmann, Patrick and Pietrzyk, Uwe and Schramm, Nils and Weber, Simone},
  booktitle={2006 IEEE Nuclear Science Symposium Conference Record}, 
  title={Parallel List-Mode Reconstruction and Calculation of the System Matrix for the High-Resolution ClearPET Neuro}, 
  year={2006},
  volume={5},
  number={},
  pages={2783-2786},
  abstract={The list-mode format is particularly suitable for high-resolution tomographic systems, where the precision of the data have not to be compromised, but also claims new demands on data processing and image reconstruction. We apply a ray-tracing algorithm to calculate the three-dimensional coincidence response function. The algorithm is embedded in a list-mode reconstruction framework and has been previously assessed with data from the small-animal ClearPETtrade Neuro scanner. In order to compare and verify our algorithm, exemplary response functions are simulated using GATE. Long reconstruction time has been overcome by implementing a reconstruction framework for distributed computing. The implementation uses the message passing interface for communication and a simple master/slave model with dynamical load balancing of the slaves.},
  keywords={},
  doi={10.1109/NSSMIC.2006.356456},
  ISSN={1082-3654},
  month={Oct},}
@INPROCEEDINGS{4267186,
  author={Fields, Scott and Elhanany, Itamar},
  booktitle={2006 49th IEEE International Midwest Symposium on Circuits and Systems}, 
  title={A Symmetric Multiprocessor Architecture for Multi-Agent Temporal Difference Learning}, 
  year={2006},
  volume={1},
  number={},
  pages={505-509},
  abstract={Temporal difference learning methods have been successfully applied to a wide range of stochastic learning and control problems. In addition to correctness, one metric of a technique's performance is its learning rate - the number of iterations required to converge to an optimal solution. The learning rate can be increased by using multiple agents that can share experience. In a software environment, the potential speedup from additional agents is limited, since adding agents significantly increases the burden of computation and/or hinders real-time processing. To address this problem, this paper presents a parameterized hardware model of a multi-agent system based on a shared-memory Symmetric Multiprocessor (SMP). To the author's knowledge, this is the first application of an SMP architecture to a multi-agent reinforcement learning system. The control model employed is a multi-agent variation of the Sarsa(λ) algorithm. Several hardware optimizations schemes are investigated with respect to feasibility and expected performance. The system is modeled using a cycle-accurate simulation in SystemC. The results indicate that real-time learning rates can be significantly improved by employing the proposed parallel hardware implementation.},
  keywords={},
  doi={10.1109/MWSCAS.2006.382109},
  ISSN={1558-3899},
  month={Aug},}
@INPROCEEDINGS{4289931,
  author={Rajan, A.V.S. and Bavan, S. and Abeysinghe, G.},
  booktitle={2006 International Conference on Advanced Computing and Communications}, 
  title={Semantics for a Distributed Programming Language Using SACS and Weakest Pre-Conditions}, 
  year={2006},
  volume={},
  number={},
  pages={434-439},
  abstract={This paper describes the semantics for a distributed programming language called LIPS (language for implementing parallel systems). The formalism presented is used for the specification and verification of LIPS programs for the successful point-to-point intercommunication in distributed systems. The main focus of the paper is to define the semantics of the computational part of LIPS using Dijkstra's weakest preconditions and demonstrate the integration of SACS(specification of asynchronous communication systems) with GCL(guarded command language) using an example. SACS is a variant of SCCS specially developed for specifying point-to-point asynchronous message passing systems.},
  keywords={},
  doi={10.1109/ADCOM.2006.4289931},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{4673586,
  author={Bennett, Matthew and Stone, Julie and Zhang, Chaoyang},
  booktitle={First International Multi-Symposiums on Computer and Computational Sciences (IMSCCS'06)}, 
  title={A Scalable Parallel HITS Algorithm for Page Ranking}, 
  year={2006},
  volume={1},
  number={},
  pages={437-442},
  abstract={The hypertext induced topic search (HITS) algorithm is a method of ranking authority of information sources in a hyperlinked environment HITS uses only topological properties of the hyperlinked network to determine rankings. We present an efficient and scalable implementation of the HITS algorithm that uses MPI as an underlying means of communication. We then analyze the performance on a shared memory supercomputer, and use our results to verify the optimal number of processors needed to rank a large number of pages for the link structure of the total University of Southern Mississippi (usm.edu domain) Web sites},
  keywords={},
  doi={10.1109/IMSCCS.2006.22},
  ISSN={},
  month={June},}
@INPROCEEDINGS{4673604,
  author={Shi, Hao and Zhang, Yanchun and Zhang, Jingyuan and Beal, Elizabeth and Moustakas, Nick},
  booktitle={First International Multi-Symposiums on Computer and Computational Sciences (IMSCCS'06)}, 
  title={Collaborative Peer-to-Peer Service for Information Sharing Using JXTA}, 
  year={2006},
  volume={1},
  number={},
  pages={552-559},
  abstract={Peer-to-peer (P2P) file sharing networks attract much attention from legal and research communities. The success and popularity of P2P networks provides a new paradigm for sharing and distributing information. However, the widespread illegal distribution of the copyright protected works and anonymous malicious attacks to the network raise serious concerns for the future of P2P applications. Legal and research professionals face a challenge to collaboratively develop a P2P application that reduces these concerns. Our research aims to develop a P2P collaborative research network, named vuCRN, for legal academics and researchers to facilitate document sharing. In this paper, we present our vuCRN prototype based on JXTA technology. JXTA provides services to let peers find each other in the group, and exchange messages across firewalls and NATs (network address translators). vuCRN allows, peers to freely download shared files but their upload permission is controlled by decentralized user authentication, using local LDAP (lightweight directory access protocol) servers. This ensures that peers in vuCRN network obtain only reliable information and protects the quality of resources. This prototype is fully tested in LAN (local area network), Internet and inter-university networks. The testing results, conclusions and future work are also presented in this paper},
  keywords={},
  doi={10.1109/IMSCCS.2006.45},
  ISSN={},
  month={June},}
@INPROCEEDINGS{5755847,
  author={Sason, Igal and Wiechman, Gil},
  booktitle={4th International Symposium on Turbo Codes & Related Topics; 6th International ITG-Conference on Source and Channel Coding}, 
  title={Performance versus Complexity Per Iteration for Low-Density Parity-Check Codes: An Information-Theoretic Approach}, 
  year={2006},
  volume={},
  number={},
  pages={1-6},
  abstract={The paper is focused on the tradeoff between performance and decoding complexity per iteration for LDPC codes in terms of their gap (in rate) to capacity. The study of this tradeoff is done via information-theoretic bounds which also enable to get an indication on the sub-optimality of message-passing iterative decoding algorithms (as compared to optimal ML decoding). The bounds are generalized for parallel channels, and are applied to ensembles of punctured LDPC codes where both intentional and random puncturing are addressed. This work suggests an improvement in the tightness of some information-theoretic bounds which were previously derived by Burshtein et al. and by Sason and Urbanke.},
  keywords={},
  doi={},
  ISSN={},
  month={April},}
@INPROCEEDINGS{7071470,
  author={Popescu, Vladimir and Burileanu, Corneliu and Rafaila, Monica and Calimanescu, Ramona},
  booktitle={2006 14th European Signal Processing Conference}, 
  title={Parallel training algorithms for continuous speech recognition, implemented in a message passing framework}, 
  year={2006},
  volume={},
  number={},
  pages={1-5},
  abstract={A way of improving the performance of continuous speech recognition systems with respect to the training time will be presented. The gain in performance is accomplished using multiprocessor architectures that provide a certain processing redundancy. Several ways to achieve the announced performance gain, without affecting precision, will be pointed out. More specifically, parallel programming features are added to training algorithms for continuous speech recognition systems based on hidden Markov models (HMM). Several parallelizing techniques are analyzed and the most effective ones are taken into consideration. Performance tests, with respect to the size of the training data base and to the convergence factor of the training algorithms, give hints about the pertinence of the use of parallel processing when HMM training is concerned. Finally, further developments in this respect are suggested.},
  keywords={},
  doi={},
  ISSN={2219-5491},
  month={Sep.},}
@INPROCEEDINGS{4092129,
  author={Gunnam, Kiran K. and Choi, Gwan S. and Yeary, Mark B.},
  booktitle={20th International Conference on VLSI Design held jointly with 6th International Conference on Embedded Systems (VLSID'07)}, 
  title={A Parallel VLSI Architecture for Layered Decoding for Array LDPC Codes}, 
  year={2007},
  volume={},
  number={},
  pages={738-743},
  abstract={The VLSI implementation complexity of a low density parity check (LDPC) decoder is largely influenced by interconnect and the storage requirements. Here, the proposed layout-aware layered decoder architecture utilizes the data-reuse properties of min-sum, layered decoding and structured properties of array LDPC codes. This results in a significant reduction of logic and interconnects requirements of the decoder when compared to the state-of-the-art LDPC decoders. The ASIC implementation of the proposed fully parallel architecture achieves throughput of 4.6 Gbps (for a maximum of 15 iterations). The chip size is 2.3 mm times 2.3 mm in 0.13 micron technology},
  keywords={},
  doi={10.1109/VLSID.2007.19},
  ISSN={2380-6923},
  month={Jan},}
@ARTICLE{4100917,
  author={Zarrinkhat, Pirouz and Banihashemi, Amir H.},
  journal={IEEE Transactions on Communications}, 
  title={Hybrid Hard-Decision Iterative Decoding of Irregular Low-Density Parity-Check Codes}, 
  year={2007},
  volume={55},
  number={2},
  pages={292-302},
  abstract={Time-invariant hybrid (HscrTI) decoding of irregular low-density parity-check (LDPC) codes is studied. Focusing on HscrTI algorithms with majority-based (MB) binary message-passing constituents, we use density evolution (DE) and finite-length simulation to analyze the performance and the convergence properties of these algorithms over (memoryless) binary symmetric channels. To apply DE, we generalize degree distributions to have the irregularity of both the code and the decoding algorithm embedded in them. A tight upper bound on the threshold of MB HscrTI algorithms is derived, and it is proven that the asymptotic error probability for these algorithms tends to zero, at least exponentially, with the number of iterations. We devise optimal MB HscrTI algorithms for irregular LDPC codes, and show that these algorithms outperform Gallager's algorithm A applied to optimized irregular LDPC codes. We also show that compared to switch-type algorithms, such as Gallager's algorithm B, where a comparable improvement is obtained by switching between different MB algorithms, MB HscrTI algorithms are more robust and can better cope with unknown channel conditions, and thus can be practically more attractive.},
  keywords={},
  doi={10.1109/TCOMM.2006.888584},
  ISSN={1558-0857},
  month={Feb},}
@INPROCEEDINGS{4127340,
  author={Mandal, Partha Sarathi and Mukhopadhyaya, Krishnendu},
  booktitle={2007 International Conference on Computing: Theory and Applications (ICCTA'07)}, 
  title={Checkpointing Using Mobile Agents in Distributed Systems}, 
  year={2007},
  volume={},
  number={},
  pages={39-45},
  abstract={Traditional message passing based checkpointing and rollback recovery algorithms perform well for tightly coupled systems. In wide area distributed systems these algorithms may suffer from large overhead due to message passing delay and network traffic. Mobile agents offer an attractive option for designing checkpointing schemes for wide area distributed systems. Network topology is assumed to be arbitrary. Processes are mobile agent enabled. When a process wants to take a checkpoint, it just creates one mobile agent. Concurrent initiations by multiple processes are allowed. Synchronization and creation of a consistent global state (CGS) for checkpointing is managed by the mobile agent(s). In the worst case, for k concurrent initiations among n processes, checkpointing algorithm requires a total of O(kn) hops by all the mobile agents. A mobile agent carries O(n/k) (on the average) size data},
  keywords={},
  doi={10.1109/ICCTA.2007.37},
  ISSN={},
  month={March},}
@INPROCEEDINGS{4135270,
  author={Padron, E. J. and Amor, M. and Boo, M. and Doallo, R.},
  booktitle={15th EUROMICRO International Conference on Parallel, Distributed and Network-Based Processing (PDP'07)}, 
  title={A Hierarchical Radiosity Method with Scene Distribution}, 
  year={2007},
  volume={},
  number={},
  pages={134-138},
  abstract={Nowadays, one of the most active areas of research in computer graphics is focused on improving the performance of global illumination methods. In this paper we present a new parallel method for hierarchical radiosity computation. Contrary to usual solutions in the literature our approach carries out an effective partitioning and distribution of the input geometry among the processors. Thus, the memory constraint is reduced when processing large scenes. The method presented in this paper also introduces a multi-thread scheduling to improve interaction between processors. This solution replaces the polling strategy usually used in parallel computing, when several independent tasks need to establish asynchronous communication. The great flexibility of our parallel implementation has been demonstrated by the good results achieved on a testbed with different computing systems and test scenes},
  keywords={},
  doi={10.1109/PDP.2007.8},
  ISSN={1066-6192},
  month={Feb},}
@INPROCEEDINGS{4135268,
  author={Almeida, F. and Gomez, J.A. and Badia, J.M.},
  booktitle={15th EUROMICRO International Conference on Parallel, Distributed and Network-Based Processing (PDP'07)}, 
  title={Performance analysis for clusters of symmetric multiprocessors}, 
  year={2007},
  volume={},
  number={},
  pages={121-128},
  abstract={In this article we analyze and model the performance of a symmetrical multiprocessor cluster. The obtained model takes into account the heterogeneity of the architecture's communications, which allows for a better adjustment and predictive ability of the performance. We used diverse applications with different parallel schemes to check the quality of the adjustments. The adjustment of the theoretical model and the experimental results is clearly improved when we take into account the combination of various mechanisms of communication},
  keywords={},
  doi={10.1109/PDP.2007.63},
  ISSN={1066-6192},
  month={Feb},}
@INPROCEEDINGS{4135288,
  author={Duarte, Angelo and Rexachs, Dolores and Luque, Emilio},
  booktitle={15th EUROMICRO International Conference on Parallel, Distributed and Network-Based Processing (PDP'07)}, 
  title={Functional Tests of the RADIC Fault Tolerance Architecture}, 
  year={2007},
  volume={},
  number={},
  pages={278-287},
  abstract={Clusters with thousand of nodes are a reality and the current trend indicates that they are becoming larger. Such large clusters are subject to a relatively high fault frequency so a fault-tolerance scheme is mandatory to assure the correct application completion. Message passing is the programming model often used in large clusters and the current implementations used to achieve fault tolerance in message passing systems do not focus in an architecture that simultaneously attends to scalability, transparency and independence of stable/central elements. The RADIC architecture was proposed and design as a fully distributed structure in order to achieve such requirements. Such architecture defines a fully distributed fault tolerance controller implemented by a set of system processes, which collaborate in order to perform all the basic functions of a fault tolerance protocol. This paper presents the test methodology used to verify the functionality of the RADIC architecture using RADICMPI, a prototype on the MPI semantic},
  keywords={},
  doi={10.1109/PDP.2007.45},
  ISSN={1066-6192},
  month={Feb},}
@INPROCEEDINGS{4135284,
  author={Mourino, J.C. and Martin, M.J. and Gonzalez, P. and Doallo, R.},
  booktitle={15th EUROMICRO International Conference on Parallel, Distributed and Network-Based Processing (PDP'07)}, 
  title={Fault-tolerant solutions for a MPI compute intensive application}, 
  year={2007},
  volume={},
  number={},
  pages={246-253},
  abstract={The running times of large-scale computational science and engineering parallel applications, executed on clusters or grid platforms, are usually longer than the mean-time-between-failures (MTBF). Hardware failures must be tolerated by the parallel applications to ensure that no all computation done is lost on machine failures. Checkpointing and rollback recovery is a very useful technique to implement fault-tolerant applications. Although extensive research has been carried out in this field, there are few available tools to help parallel programmers to enhance with fault tolerant capability their applications. This work presents two different approaches to endow with fault tolerance the MPI version of an air quality simulation. A segment-level solution has been implemented by means of the extension of a checkpointing library for sequential codes. A variable-level solution has been implemented manually in the code. The main differences between both approaches are portability, transparency-level and checkpointing overheads. Experimental results comparing both strategies on a cluster of PCs are shown in the paper},
  keywords={},
  doi={10.1109/PDP.2007.44},
  ISSN={1066-6192},
  month={Feb},}
@ARTICLE{4137898,
  author={Soriaga, Joseph B. and Pfister, Henry D. and Siegel, Paul H.},
  journal={IEEE Transactions on Information Theory}, 
  title={Determining and Approaching Achievable Rates of Binary Intersymbol Interference Channels Using Multistage Decoding}, 
  year={2007},
  volume={53},
  number={4},
  pages={1416-1429},
  abstract={By examining the achievable rates of a multistage decoding system on stationary ergodic channels, we derive lower bounds on the mutual information rate corresponding to independent and uniformly distributed (i.u.d.) inputs, also referred to as the i.u.d. information rate. For binary intersymbol interference (ISI) channels, we show that these bounds become tight as the number of decoding stages increases. Our analysis, which focuses on the marginal conditional output densities at each stage of decoding, provides an information rate corresponding to each stage. These rates underlie the design of multilevel coding schemes, based upon low-density parity-check (LDPC) codes and message passing, that in combination with multistage decoding approach the i.u.d. information rate for binary ISI channels. We give example constructions for channel models that have been commonly used in magnetic recording. These examples demonstrate that the technique is very effective even for a small number of decoding stages},
  keywords={},
  doi={10.1109/TIT.2007.892778},
  ISSN={1557-9654},
  month={April},}
@ARTICLE{4182391,
  author={Kwon, Yung-Keun and Moon, Byung-Ro},
  journal={IEEE Transactions on Neural Networks}, 
  title={A Hybrid Neurogenetic Approach for Stock Forecasting}, 
  year={2007},
  volume={18},
  number={3},
  pages={851-864},
  abstract={In this paper, we propose a hybrid neurogenetic system for stock trading. A recurrent neural network (NN) having one hidden layer is used for the prediction model. The input features are generated from a number of technical indicators being used by financial experts. The genetic algorithm (GA) optimizes the NN's weights under a 2-D encoding and crossover. We devised a context-based ensemble method of NNs which dynamically changes on the basis of the test day's context. To reduce the time in processing mass data, we parallelized the GA on a Linux cluster system using message passing interface. We tested the proposed method with 36 companies in NYSE and NASDAQ for 13 years from 1992 to 2004. The neurogenetic hybrid showed notable improvement on the average over the buy-and-hold strategy and the context-based ensemble further improved the results. We also observed that some companies were more predictable than others, which implies that the proposed neurogenetic hybrid can be used for financial portfolio construction},
  keywords={},
  doi={10.1109/TNN.2007.891629},
  ISSN={1941-0093},
  month={May},}
@INPROCEEDINGS{4215427,
  author={El Maghraoui, Kaoutar and Desell, Travis J. and Szymanski, Boleslaw K. and Varela, Carlos A.},
  booktitle={Seventh IEEE International Symposium on Cluster Computing and the Grid (CCGrid '07)}, 
  title={Dynamic Malleability in Iterative MPI Applications}, 
  year={2007},
  volume={},
  number={},
  pages={591-598},
  abstract={Malleability enables a parallel application's execution system to split or merge processes modifying granularity. While process migration is widely used to adapt applications to dynamic execution environments, it is limited by the granularity of the application's processes. Malleability empowers process migration by allowing the application's processes to expand or shrink following the availability of resources. We have implemented malleability as an extension to the PCM (process checkpointing and migration) library, a user-level library for iterative MPI applications. PCM is integrated with the Internet operating system (IOS), a framework for middleware-driven dynamic application reconfiguration. Our approach requires minimal code modifications and enables transparent middleware- triggered reconfiguration. Experimental results using a two-dimensional data parallel program that has a regular communication structure demonstrate the usefulness of malleability.},
  keywords={},
  doi={10.1109/CCGRID.2007.45},
  ISSN={},
  month={May},}
@INPROCEEDINGS{4217333,
  author={Mohsenin, T. and Baas, B. M.},
  booktitle={2007 IEEE International Conference on Acoustics, Speech and Signal Processing - ICASSP '07}, 
  title={High-Throughput LDPC Decoders Using A Multiple Split-Row Method}, 
  year={2007},
  volume={2},
  number={},
  pages={II-13-II-16},
  abstract={We propose the "multi-split-row'" LDPC decoding method which allows further reductions in routing complexity, greater throughput, and smaller circuit area implementations compared to the previously proposed split-row decoding method. Multi-split-row is especially useful for regular high row weight LDPC codes. A 2048-bit full parallel decoder is implemented in a 0.18 μm CMOS technology using standard MinSum, split-row-2 and split-row-4 methods. The split-row-4 decoder delivers 7.1 Gbps throughput with 15 decoding iterations, and has 3.2 times smaller circuit area and 5.2 times higher throughput than the standard MinSum decoder.},
  keywords={},
  doi={10.1109/ICASSP.2007.366160},
  ISSN={2379-190X},
  month={April},}
@INPROCEEDINGS{4221427,
  author={Tait, Roger J. and Schaefer, Gerald and Hopgood, Adrian A. and Nakashima, Tomoharu},
  booktitle={2007 IEEE Symposium on Computational Intelligence in Image and Signal Processing}, 
  title={High Performance Medical Image Registration Using a Distributed Blackboard Architecture}, 
  year={2007},
  volume={},
  number={},
  pages={252-257},
  abstract={A major drawback of medical image registration techniques is the performance bottleneck associated with similarity computation. Such bottlenecks limit registration applications in situations where fast execution times are required. In this paper a novel framework for high performance intensity-based medical image registration is presented. Geometric alignment of both reference and sensed images is achieved through a combination of scaling, translation, and rotation. Crucially, similarity computation is performed intelligently by knowledge sources (KSs) organised in a worker/manager model. The KSs work in parallel and communicate with each other by means of a distributed blackboard architecture. Partitioning of the blackboard is used to balance communication and processing workloads. The registration framework presented demonstrates the flexibility of the coarse-grained parallelism employed and shows how high performance medical image registration can be achieved with non-specialised architectures. Experimental results obtained during testing show that substantial speedups can be achieved},
  keywords={},
  doi={10.1109/CIISP.2007.369177},
  ISSN={},
  month={April},}
@INPROCEEDINGS{4221813,
  author={Cavendish, Dirceu and Candan, K. Selcuk},
  booktitle={2007 IEEE 23rd International Conference on Data Engineering}, 
  title={PASS Middleware for Distributed and Autonomous XML Message Processing}, 
  year={2007},
  volume={},
  number={},
  pages={1410-1413},
  abstract={Basic message processing tasks, such as well-formedness checking and grammar validation, can be off-loaded from the service providers' own infrastructures. To enable effective off-loading of processing tasks, we introduce the Prefix Automata SyStem - PASS, a middleware architecture which distributively processes XML payloads of Web service SOAP messages during their routing towards Web servers. PASS is based on a network of automata, where PASS-nodes independently but cooperatively process parts of the SOAP message XML payload.},
  keywords={},
  doi={10.1109/ICDE.2007.369023},
  ISSN={2375-026X},
  month={April},}

@INPROCEEDINGS{4220984,
  author={Gilchrist, Jeff and Cuhadar, Aysegul},
  booktitle={21st International Conference on Advanced Information Networking and Applications (AINA '07)}, 
  title={Parallel Lossless Data Compression Based on the Burrows-Wheeler Transform}, 
  year={2007},
  volume={},
  number={},
  pages={877-884},
  abstract={In this paper, we present parallel algorithms for lossless data compression based on the Burrows-Wheeler transform (BWT) block-sorting technique. We investigate the performance of using data parallelism and task parallelism for both multi-threaded and message-passing programming. The output produced by the parallel algorithms is fully compatible with their sequential counterparts. To balance the workload among processors we develop a task scheduling strategy. An extensive set of experiments is performed with a shared memory NUMA system using up to 120 processors and on a distributed memory cluster using up to 100 processors. Our experimental results show that significant speedup can be achieved with both data parallel and task parallel methodologies. These algorithms will greatly reduce the amount of time it takes to compress large amounts of data while the compressed data remains in a form that users without access to multiple processor systems can still use.},
  keywords={},
  doi={10.1109/AINA.2007.109},
  ISSN={2332-5658},
  month={May},}
@INPROCEEDINGS{4228215,
  author={Gopalakrishnan, Ganesh L. and Kirby, Robert M.},
  booktitle={2007 IEEE International Parallel and Distributed Processing Symposium}, 
  title={Formal Analysis for Debugging and Performance Optimization of MPI}, 
  year={2007},
  volume={},
  number={},
  pages={1-6},
  abstract={High-end computing is universally recognized to be a strategic tool for leadership in science and technology. A significant portion of high-end computing is conducted on clusters running the message passing interface (MPI) library. MPI has become a de facto standard in HPC. MPI programs, as well as MPI library implementations can be buggy, especially when aiming high performance, and running on or porting onto new platforms. Our recent work has addressed the following areas: A TLA+ formal semantics of a large subset of MPI-1; A Microsoft Phoenix based model extraction and analysis framework for MPI programs; integration into the visual studio environment for error-trace visualization; A new dynamic partial order reduction algorithm (DPOR) tailored to MPI so that the number of interleavings examined during MPI program verification are dramatically reduced; A program called 'inspector' for analyzing C++ programs that has found bugs in publicly distributed threaded programs (Inspector automatically instruments Pthread programs and searches for races based on a new DPOR); verified byte-range locking protocols using MPI one-sided communication - a case study where we found bugs in published byte-range locking protocols, and designed and verified improved versions of these protocols; A new in-situ model checker for MPI programs, that traps MPI calls using its profiling interface (PMPI) and orchestrates control to maximize coverage with minimal state saving overhead. The progress made in exploring these directions, our publications, and associated software tools are described, as are our future plans.},
  keywords={},
  doi={10.1109/IPDPS.2007.370487},
  ISSN={1530-2075},
  month={March},}
@INPROCEEDINGS{4228037,
  author={Ruscio, Joseph F. and Heffner, Michael A. and Varadarajan, Srinidhi},
  booktitle={2007 IEEE International Parallel and Distributed Processing Symposium}, 
  title={DejaVu: Transparent User-Level Checkpointing, Migration, and Recovery for Distributed Systems}, 
  year={2007},
  volume={},
  number={},
  pages={1-10},
  abstract={In this paper, we present a new fault tolerance system called DejaVu for transparent and automatic checkpointing, migration, and recovery of parallel and distributed applications. DejaVu provides a transparent parallel checkpointing and recovery mechanism that recovers from any combination of systems failures without any modification to parallel applications or the OS. It uses a new runtime mechanism for transparent incremental checkpointing that captures the least amount of state needed to maintain global consistency and provides a novel communication architecture that enables transparent migration of existing MPI codes, without source-code modifications. Performance results from the production-ready implementation show less than 5% overhead in real-world parallel applications with large memory footprints.},
  keywords={},
  doi={10.1109/IPDPS.2007.370309},
  ISSN={1530-2075},
  month={March},}
@INPROCEEDINGS{4228036,
  author={Jiang, Qiangfeng and Manivannan, D.},
  booktitle={2007 IEEE International Parallel and Distributed Processing Symposium}, 
  title={An optimistic checkpointing and selective message logging approach for consistent global checkpoint collection in distributed systems}, 
  year={2007},
  volume={},
  number={},
  pages={1-10},
  abstract={In this paper, we present an asynchronous consistent global checkpoint collection algorithm which prevents contention for network storage at the file server and hence reduces the checkpointing overhead. The algorithm has two phases: In the first phase, a process initiates consistent global checkpoint collection by saving its state tentatively and asynchronously (called tentative checkpoint) in local memory or remote stable storage if there is no contention for stable storage while saving the state; in the second phase, the message log associated with the tentative checkpoint is stored in stable storage (checkpoint finalization phase). The tentative checkpoint together with the associated message log stored in the stable storage becomes part of a consistent global checkpoint. Under our algorithm, two or more processes can concurrently initiate consistent global checkpoint collection. Every tentative checkpoint will be finalized successfully unless a failure occurs. The finalized checkpoints of each process is assigned a unique sequence number in ascending order. Finalized checkpoints with same sequence number form a consistent global checkpoint.},
  keywords={},
  doi={10.1109/IPDPS.2007.370308},
  ISSN={1530-2075},
  month={March},}
@INPROCEEDINGS{4228038,
  author={Chakravorty, Sayantan and Kale, Laxmikant V.},
  booktitle={2007 IEEE International Parallel and Distributed Processing Symposium}, 
  title={A Fault Tolerance Protocol with Fast Fault Recovery}, 
  year={2007},
  volume={},
  number={},
  pages={1-10},
  abstract={Fault tolerance is an important issue for large machines with tens or hundreds of thousands of processors. Checkpoint-based methods, currently used on most machines, rollback all processors to previous checkpoints after a crash. This wastes a significant amount of computation as all processors have to redo all the computation from that checkpoint onwards. In addition, recovery time is bound by the time between the last checkpoint and the crash. Protocols based on message logging avoid the problem of rolling back all processors to their earlier state. However, the recovery time of existing message logging protocols is no smaller than the time between the last checkpoint and crash. We present a fault tolerance protocol, in this paper, that provides fast restarts by using the ideas of message logging and object-based processor virtualization. We evaluate our implementation of the protocol in the Charm++/adaptive MPI runtime system. We show that our protocol provides fast restarts and, for many applications, has low fault-free overhead.},
  keywords={},
  doi={10.1109/IPDPS.2007.370310},
  ISSN={1530-2075},
  month={March},}
@INPROCEEDINGS{4228035,
  author={Wang, Chao and Mueller, Frank and Engelmann, Christian and Scott, Stephen L.},
  booktitle={2007 IEEE International Parallel and Distributed Processing Symposium}, 
  title={A Job Pause Service under LAM/MPI+BLCR for Transparent Fault Tolerance}, 
  year={2007},
  volume={},
  number={},
  pages={1-10},
  abstract={Checkpoint/restart (C/R) has become a requirement for long-running jobs in large-scale clusters due to a meantime-to-failure (MTTF) in the order of hours. After a failure, C/R mechanisms generally require a complete restart of an MPI job from the last checkpoint. A complete restart, however, is unnecessary since all but one node is typically still alive. Furthermore, a restart may result in lengthy job requeuing even though the original job had not exceeded its time quantum. In this paper, we overcome these shortcomings. Instead of job restart, we have developed a transparent mechanism for job pause within LAM/MPI+BLCR. This mechanism allows live nodes to remain active and roll back to the last checkpoint while failed nodes are dynamically replaced by spares before resuming from the last checkpoint. Our methodology includes LAM/MPI enhancements in support of scalable group communication with fluctuating number of nodes, reuse of network connections, transparent coordinated checkpoint scheduling and a BLCR enhancement for job pause. Experiments in a cluster with the NAS parallel benchmark suite show that our overhead for job pause is comparable to that of a complete job restart. A minimal overhead of 5.6% is only incurred in case migration takes place while the regular checkpoint overhead remains unchanged. Yet, our approach alleviates the need to reboot the LAM run-time environment, which accounts for considerable overhead resulting in net savings of our scheme in the experiments. Our solution further provides full transparency and automation with the additional benefit of reusing existing resources. Executing continues after failures within the scheduled job, i.e., the application staging overhead is not incurred again in contrast to a restart. Our scheme offers additional potential for savings through incremental checkpointing and proactive diskless live migration, which we are currently working on.},
  keywords={},
  doi={10.1109/IPDPS.2007.370307},
  ISSN={1530-2075},
  month={March},}
@INPROCEEDINGS{4228213,
  author={Liao, Wei-keng and Ching, Avery and Coloma, Kenin and Choudhary, Alok and Kandemir, Mahmut},
  booktitle={2007 IEEE International Parallel and Distributed Processing Symposium}, 
  title={Improving MPI Independent Write Performance Using A Two-Stage Write-Behind Buffering Method}, 
  year={2007},
  volume={},
  number={},
  pages={1-6},
  abstract={Many large-scale production applications often have very long executions times and require periodic data checkpoints in order to save the state of the computation for program restart and/or tracing application progress. These write-only operations often dominate the overall application runtime, which makes them a good optimization target. Existing approaches for write-behind data buffering at the MPI I/O level have been proposed, but challenges still exist for addressing system-level I/O issues. We propose a two-stage write-behind buffering scheme for handing checkpoint operations. The first-stage of buffering accumulates write data for better network utilization and the second-stage of buffering enables the alignment for the write requests to the file stripe boundaries. Aligned I/O requests avoid file lock contention that can seriously degrade I/O performance. We present our performance evaluation using BTIO benchmarks on both GPFS and Lustre file systems. With the two-stage buffering, the performance of BTIO through MPI independent I/O is significantly improved and even surpasses that of collective I/O.},
  keywords={},
  doi={10.1109/IPDPS.2007.370485},
  ISSN={1530-2075},
  month={March},}
@INPROCEEDINGS{4228135,
  author={Vishnu, Abhinav and Benton, Brad and Panda, Dhabaleswar K.},
  booktitle={2007 IEEE International Parallel and Distributed Processing Symposium}, 
  title={High Performance MPI on IBM 12x InfiniBand Architecture}, 
  year={2007},
  volume={},
  number={},
  pages={1-8},
  abstract={InfiniBand is becoming increasingly popular in the area of cluster computing due to its open standard and high performance. I/O interfaces like PCI-express and GX+ are being introduced as next generation technologies to drive InfiniBand with very high throughput. HCAs with throughput of 8x on PCI-express have become available. Recently, support for HCAs with 12x throughput on GX+ has been announced. In this paper, we design a message passing interface (MPI) on IBM 12x dual-port HCAs, which consist of multiple send/recv engines per port. We propose and study the impact of various communication scheduling policies (binding, striping and round robin). Based on this study, we present a new policy, EPC (enhanced point-to-point and collective), which incorporates different kinds of communication patterns; point-to-point (blocking, non-blocking) and collective communication, for data transfer. We implement our design and evaluate it with micro-benchmarks, collective communication and NAS parallel benchmarks. Using EPC on a 12x InfiniBand cluster with one HCA and one port, we can improve the performance by 41% with pingpong latency test and 63-65% with the unidirectional and bi-directional bandwidth tests, compared with the default single-rail MPI implementation. Our evaluation on NAS parallel benchmarks shows an improvement of 7-13% in execution time for integer sort and Fourier transform.},
  keywords={},
  doi={10.1109/IPDPS.2007.370407},
  ISSN={1530-2075},
  month={March},}
@INPROCEEDINGS{4228137,
  author={Schaeli, Basile and Gerlach, Sebastian and Hersch, Roger D.},
  booktitle={2007 IEEE International Parallel and Distributed Processing Symposium}, 
  title={Decomposing Partial Order Execution Graphs to Improve Message Race Detection}, 
  year={2007},
  volume={},
  number={},
  pages={1-8},
  abstract={In message-passing parallel applications, messages are not delivered in a strict order. In most applications, the computation results and the set of messages produced during the execution should be the same for all distinct orderings of messages delivery. Finding an ordering that produces a different outcome then reveals a message race. Assuming that the partial order execution graph (POEG) capturing the causality between events is known for a reference execution, the present paper describes techniques for identifying independent sets of messages and within each set equivalent message orderings. Orderings of messages belonging to different sets may then be re-executed independently from each other, thereby reducing the number of orderings that must be tested to detect message races. We integrated the presented techniques into the dynamic parallel schedules parallelization framework, and applied our approach on an image processing, a linear algebra, and a neighborhood-dependent parallel computation. In all cases, the number of possible orderings is reduced by several orders of magnitudes. In order to further reduce this number, we describe an algorithm that generates a subset of orderings that are likely to reveal existing message races.},
  keywords={},
  doi={10.1109/IPDPS.2007.370409},
  ISSN={1530-2075},
  month={March},}
@INPROCEEDINGS{4228148,
  author={Bahi, Jacques M. and Couturier, Raphael and Laiymani, David and Mazouzi, Kamel},
  booktitle={2007 IEEE International Parallel and Distributed Processing Symposium}, 
  title={Java and asynchronous iterative applications: large scale experiments}, 
  year={2007},
  volume={},
  number={},
  pages={1-7},
  abstract={This paper focuses on large scale experiments with Java and asynchronous iterative applications. In those applications, tasks are dependent and the use of distant clusters may be difficult, for example, because of latencies, heterogeneity, and synchronizations. Experiments have been conducted on the Grid'5000 platform using a new version of the Jace environment. We study the behavior of an application (the Poisson problem) with the following experimentation conditions: one and several sites, large number of processors (from 80 to 500), different communication protocols (RMI, sockets and NIO), synchronous and asynchronous model. The results we obtained, demonstrate both the scalability of the Jace environment and its ability to support wide-area deployments and the robustness of asynchronous iterative algorithms in a large scale context.},
  keywords={},
  doi={10.1109/IPDPS.2007.370420},
  ISSN={1530-2075},
  month={March},}
@INPROCEEDINGS{4228272,
  author={Genaud, Stephane and Grunberg, Marc and Mongenet, Catherine},
  booktitle={2007 IEEE International Parallel and Distributed Processing Symposium}, 
  title={Experiments in running a scientific MPI application on Grid'5000}, 
  year={2007},
  volume={},
  number={},
  pages={1-7},
  abstract={Over the last couple of years, several dedicated grid platforms have been set up to test applications and middleware for grids. Among these is Grid'5000, a reconfigurable platform gathering resources at nine remote geographical sites in France. This paper presents one of the eight experiments that have tested software scalability at the scale of a thousand processors (i.e. 500-1000) on this grid testbed. The experiment aims at analyzing the behavior of a geophysical application (a seismic ray tracing in a 3D mesh of the Earth). The application is computationally intensive but requires an all-to-all communication phase during which processors exchange their results, which has shown to be a real bottleneck on many hardware platforms. We analyze various runs and show that this application scales well up to about 500 processors on such a grid.},
  keywords={},
  doi={10.1109/IPDPS.2007.370544},
  ISSN={1530-2075},
  month={March},}
@INPROCEEDINGS{4228278,
  author={Huang, Chenxi and Hobson, Peter R. and Taylor, Gareth A. and Kyberd, Paul},
  booktitle={2007 IEEE International Parallel and Distributed Processing Symposium}, 
  title={A Study of Publish/Subscribe Systems for Real-Time Grid Monitoring}, 
  year={2007},
  volume={},
  number={},
  pages={1-8},
  abstract={Monitoring and controlling a large number of geographically distributed scientific instruments is a challenging task. Some operations on these instruments require real-time (or quasi real-time) response which make it even more difficult. In this paper, we describe the requirements of distributed monitoring for a possible future electrical power grid based on real-time extensions to grid computing. We examine several standards and publish/subscribe middleware candidates, some of which were specially designed and developed for grid monitoring. We analyze their architecture and functionality, and discuss the advantages and disadvantages. We report on a series of tests to measure their real-time performance and scalability.},
  keywords={},
  doi={10.1109/IPDPS.2007.370550},
  ISSN={1530-2075},
  month={March},}
@INPROCEEDINGS{4228291,
  author={Passos, Lorena B. C. and Pfitscher, Gerson H. and Filho, Tarcisio M. Rocha},
  booktitle={2007 IEEE International Parallel and Distributed Processing Symposium}, 
  title={Performance Evaluation of two Parallel Programming Paradigms Applied to the Symplectic Integrator Running on COTS PC Cluster}, 
  year={2007},
  volume={},
  number={},
  pages={1-8},
  abstract={There are two popular parallel programming paradigms available to high performance computing users such as engineering and physics professionals: message passing and distributed shared memory. It is interesting to have a comparative evaluation of these paradigms to choose the most adequate one. In this work, we present a performance comparison of these two programming paradigms using a computational physics problem as a case study. The self-gravitating ring model (Hamiltonian mean field model) for N particles is extensively studied in the literature as a simplified model for long range interacting systems in Physics. We parallelized and evaluated the performance of a simulation that uses the symplectic integrator to model an N particle system. From the obtained results it is possible to observe that message passing implementation of the symplectic integrator presents better results than distributed shared memory implementation.},
  keywords={},
  doi={10.1109/IPDPS.2007.370563},
  ISSN={1530-2075},
  month={March},}
@INPROCEEDINGS{4228285,
  author={Martins, Antonio S. and Goncalves, Ronaldo A.L.},
  booktitle={2007 IEEE International Parallel and Distributed Processing Symposium}, 
  title={Implementing and Evaluating Automatic Checkpointing}, 
  year={2007},
  volume={},
  number={},
  pages={1-8},
  abstract={As the size and popularity of computer clusters go on growing, fault tolerance is becoming a crucial factor to ensure high performance and reliability for applications. To provide this facility, a checkpoint mechanism is used to recover a failed parallel application rolling it back to an execution moment prior to occurrence of the failure. In this work we present a mechanism for managing checkpoint operations during the failures automatically. This mechanism records periodically the application's context, identifies failed nodes and restarts MPI processes on the remaining nodes, allowing the continuity of the application and taking advantage of the computing accomplished previously. We describe a lot of changes inside source of the LAM/MPI. Experiments with an application for recognizing DNA similarity showed that despite the overhead caused by periodic checkpoints, the benefits can reach about 50% on a small cluster.},
  keywords={},
  doi={10.1109/IPDPS.2007.370557},
  ISSN={1530-2075},
  month={March},}
@INPROCEEDINGS{4228333,
  author={Hursey, Joshua and Squyres, Jeffrey M. and Mattox, Timothy I. and Lumsdaine, Andrew},
  booktitle={2007 IEEE International Parallel and Distributed Processing Symposium}, 
  title={The Design and Implementation of Checkpoint/Restart Process Fault Tolerance for Open MPI}, 
  year={2007},
  volume={},
  number={},
  pages={1-8},
  abstract={To be able to fully exploit ever larger computing platforms, modern HPC applications and system software must be able to tolerate inevitable faults. Historically, MPI implementations that incorporated fault tolerance capabilities have been limited by lack of modularity, scalability and usability. This paper presents the design and implementation of an infrastructure to support checkpoint/restart fault tolerance in the Open MPI project. We identify the general capabilities required for distributed checkpoint/restart and realize these capabilities as extensible frameworks within Open MPI's modular component architecture. Our design features an abstract interface for providing and accessing fault tolerance services without sacrificing performance, robustness, or flexibility. Although our implementation includes support for some initial checkpoint/restart mechanisms, the framework is meant to be extensible and to encourage experimentation of alternative techniques within a production quality MPI implementation.},
  keywords={},
  doi={10.1109/IPDPS.2007.370605},
  ISSN={1530-2075},
  month={March},}
@INPROCEEDINGS{4228490,
  author={Drusinsky, Doron and Shing, Man-Tak},
  booktitle={18th IEEE/IFIP International Workshop on Rapid System Prototyping (RSP '07)}, 
  title={Verifying Distributed Protocols using MSC-Assertions, Run-time Monitoring, and Automatic Test Generation}, 
  year={2007},
  volume={},
  number={},
  pages={82-88},
  abstract={This paper addresses the need for formal specification and runtime verification of system-level requirements of distributed reactive systems. It describes a formalism for specifying global system behaviors in terms of message sequence chart assertions and a technique for the evaluation of the likelihood of success of a distributed protocol under non-trivial communication conditions via discrete event simulation and runtime execution monitoring. We constructed a proof-of-concept prototype for the leader-election algorithm within a 4-node ring network. The prototype consists of the following components: (i) an OMNeT++ model of the network using non-trivial communication conditions, (ii) C+ + code for the network agents, (Hi) a system-level assertion stipulating the formal requirement for a correct, time- bound, leader election, (iv) simulation of the formal assertion, (v) automatic scenario generation, and (vi) run-time monitoring of the formal assertion and stochastic-based estimation of the likelihood of success of this assertion under the specified communication conditions.},
  keywords={},
  doi={10.1109/RSP.2007.39},
  ISSN={2150-5519},
  month={May},}
@INPROCEEDINGS{4233695,
  author={Zheng, Yongyan and Krause, Paul},
  booktitle={2007 Inaugural IEEE-IES Digital EcoSystems and Technologies Conference}, 
  title={Automata Semantics and Analysis of BPEL}, 
  year={2007},
  volume={},
  number={},
  pages={147-152},
  abstract={Web service is an emerging paradigm for distributed computing. In order to verify web services rigorously, it is important to provide a formal semantics for flow-based web service languages such as BPEL. A suitable formal model should cover most features of BPEL. The existing formal models either abstract from data, cover a simple subset of BPEL, or omit the interactions between BPEL activities. This paper presents Web Service Automata, an extension of Mealy machines, to fulfil the formal model requirements of the web service domain. Secondly, the paper analyses the control handling and data handling of BPEL, so that these can be verified in a clear manner.},
  keywords={},
  doi={10.1109/DEST.2007.371961},
  ISSN={2150-4946},
  month={Feb},}
@INPROCEEDINGS{4253499,
  author={Kakoee, Mohammad Reza and Shojaei, Hamid and Ghasemzadeh, Hassan and Sirjani, Marjan and Navabi, Zainalabedin},
  booktitle={2007 IEEE International Symposium on Circuits and Systems}, 
  title={A New Approach for Design and Verification of Transaction Level Models}, 
  year={2007},
  volume={},
  number={},
  pages={3760-3763},
  abstract={Transaction level modeling allows exploring several SoC design architectures leading to better performance and easier verification of the final product. In this paper, we present an approach for design and verification of transaction level models. Verification is integrated as part of the design-flow. In the proposed method, we first model the design in UML. Then, we translate it into the reactive objects language, Rebeca (Marjan Sirjani et al., 2004), which is an actor-based language with formal foundation. A model in Rebeca is a set of concurrently executed reactive objects (called rebecs) interacted by asynchronous message passing. After mapping UML to Rebeca, Rebeca code will be translated into Promela which is a language for formal verification. Checking the correctness of the design is performed on-the-fly with the LTL properties using the SPIN model checker. Finally, we translate the verified design to SystemC and map the properties to a set of assertions that can be re-used to validate the design at lower levels through simulation.},
  keywords={},
  doi={10.1109/ISCAS.2007.378779},
  ISSN={2158-1525},
  month={May},}
@INPROCEEDINGS{4252972,
  author={Chien, Yi-Hsing and Ku, Mong-Kai},
  booktitle={2007 IEEE International Symposium on Circuits and Systems}, 
  title={A High Throughput H-QC LDPC Decoder}, 
  year={2007},
  volume={},
  number={},
  pages={1649-1652},
  abstract={In this paper, design of a high throughput low-density parity-check (LDPC) decoder using overlapped message passing scheduling algorithm is presented. Regular hierarchical quasi-cyclic (H-QC) LDPC code is used in this design to provide good coding performance at long code length. The two-level regular H-QC LDPC code matrix structure is exploited to parallelize the row and column decoding operations. Our scheduling algorithm re-arranges these operations across iteration boundaries to avoid memory access conflicts. The memory requirement is reduced by half compared to pipelined decoders without scheduling. A (12288, 6144) LDPC decoder implemented in FPGA achieves 298 Mbps throughput performance.},
  keywords={},
  doi={10.1109/ISCAS.2007.378836},
  ISSN={2158-1525},
  month={May},}
@INPROCEEDINGS{4259766,
  author={Potluri, Madhurima and Chilumuru, Suma and Kambhampati, Sumakanth and Namuduri, Kamesh R.},
  booktitle={2007 10th Canadian Workshop on Information Theory (CWIT)}, 
  title={Distributed Source Coding using non-binary LDPC codes for sensor network applications}, 
  year={2007},
  volume={},
  number={},
  pages={105-109},
  abstract={Recent revolution in sensor networks has resulted in the development of many enabling techniques, one of which being distributed source coding (DSC). DSC allows a low-complexity encoder, shifting the high complexity to the decoder, making this scheme appropriate for sensor networks. In this paper, we have extended the non-binary low-density parity-check (LDPC) codes, developed for channel coding, to be used for distributed source coding of correlated non-binary sources. The system consists of an equiprobable memoryless non-binary source with side information at the decoder. The correlation between the sources is modelled as a virtual channel. The results obtained through simulations demonstrate that for rates 1/2 and 3/4, the non-binary compression scheme performs better the equivalent binary compression scheme. This scheme makes it extremely suitable for sensor networks.},
  keywords={},
  doi={10.1109/CWIT.2007.375712},
  ISSN={},
  month={June},}
@INPROCEEDINGS{4272957,
  author={Zielinski, Piotr},
  booktitle={37th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN'07)}, 
  title={Automatic Verification and Discovery of Byzantine Consensus Protocols}, 
  year={2007},
  volume={},
  number={},
  pages={72-81},
  abstract={Model-checking of asynchronous distributed protocols is challenging because of the large size of the state and solution spaces. This paper tackles this problem in the context of low-latency Byzantine Consensus protocols. It reduces the state space by focusing on the latency-determining first round only, ignoring the order of messages in this round, and distinguishing between state-modifying actions and state-preserving predicates. In addition, the monotonicity of the predicates and verified properties allows one to use a Tarski-style fixpoint algorithm, which results in an exponential verification speed-up. This model checker has been applied to scan the space of possible Consensus algorithms in order to discover new ones. The search automatically discovered not only many familiar patterns but also several interesting improvements to known algorithms. Due to its speed and reliability, automatic protocol design is an attractive paradigm, especially in the notoriously difficult Byzantine case.},
  keywords={},
  doi={10.1109/DSN.2007.22},
  ISSN={2158-3927},
  month={June},}
@INPROCEEDINGS{4272960,
  author={Widder, Josef and Gridling, Gunther and Weiss, Bettina and Blanquart, Jean-Paul},
  booktitle={37th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN'07)}, 
  title={Synchronous Consensus with Mortal Byzantines}, 
  year={2007},
  volume={},
  number={},
  pages={102-112},
  abstract={We consider the problem of reaching agreement in synchronous systems under a fault model whose severity lies between Byzantine and crash faults. For these "mortal" Byzantine faults, we assume that faulty processes take a finite number of arbitrary steps before they eventually crash. After discussing several application examples where this model is justified, we present and prove correct a consensus algorithm that tolerates a minority of faulty processes; i.e., more faults can be tolerated compared to classic Byzantine faults. We also show that the algorithm is optimal regarding the required number of processes and that no algorithm can solve consensus with just a majority of correct processes in a bounded number of rounds under our fault assumption. Finally, we consider more restricted fault models that allow to further reduce the required number of processes.},
  keywords={},
  doi={10.1109/DSN.2007.91},
  ISSN={2158-3927},
  month={June},}
@INPROCEEDINGS{4273113,
  author={Pallickara, Shrideep and Bulut, Hasan and Fox, Geoffrey},
  booktitle={Fourth International Conference on Autonomic Computing (ICAC'07)}, 
  title={Fault-Tolerant Reliable Delivery of Messages in Distributed Publish/Subscribe Systems}, 
  year={2007},
  volume={},
  number={},
  pages={19-19},
  abstract={Reliable delivery of messages is an important problem that needs to be addressed in distributed systems. In this paper we briefly describe our basic strategy to enable reliable delivery of messages in the presence of link and node failures. This is facilitated by a specialized repository node. We then present our strategy to make this scheme even more failure resilient, by incorporating support for repository redundancy. Each repository functions autonomously. The scheme enables updates to the redundancy scheme depending on the failure resiliency requirements. If there are N available repositories, reliable delivery guarantees will be met even if N-1 repositories fail.},
  keywords={},
  doi={10.1109/ICAC.2007.18},
  ISSN={},
  month={June},}
@INPROCEEDINGS{4276271,
  author={Yu, Guan and Lafruit, Gauthier and Schelkens, Peter},
  booktitle={Seventh International Conference on Application of Concurrency to System Design (ACSD 2007)}, 
  title={Platform-scalable Task Partition and Multilevel Buffering in Multi-processor Plessey Corner Detector}, 
  year={2007},
  volume={},
  number={},
  pages={120-126},
  abstract={The Plessey corner detector is a key technological component in scene analysis, stereo matching, and object tracking. Due to its high computation complexity, earlier fast implementations mainly focused on hardware implementations. This paper explores the viability of a multi-processor software implementation. A scalable task partitioning for efficiently mapping the Plessey algorithm on a multi-processor platform is proposed. The task partition ensures platform scalability, low inter-processor communication overhead and a well-balanced workload in each task. In addition, a multilevel buffering scheme is presented, minimizing the external memory accesses in each task to one image pixel read per calculated corner response value. The effectiveness of the proposed task partition and buffering scheme has been verified on (i) a cycle accurate simulator with shared memory and (ii) a multiple-TI-C64 DSP board using a message passing paradigm. The proposed solution combines good platform scalability with an additional 30% speedup gain over straightforward parallelization schemes.},
  keywords={},
  doi={10.1109/ACSD.2007.58},
  ISSN={1550-4808},
  month={July},}
@INPROCEEDINGS{4276281,
  author={Hojjat, H. and Sirjani, M. and Mousavi, M. R. and Groote, J. F.},
  booktitle={Seventh International Conference on Application of Concurrency to System Design (ACSD 2007)}, 
  title={Sarir: A Rebeca to mCRL2 Translator}, 
  year={2007},
  volume={},
  number={},
  pages={216-222},
  abstract={We describe a translation from Rebeca, an actor-based language, to mCRL2, a process algebra enhanced with data types. The main motivation is to exploit the verification tools and theories developed for mCRL2 in Rebeca. The mapping is applied to several case-studies including the tree identify phase of the IEEE 1394 standard. The results of the experiment show that the minimization tools of mCRL2 can be very effective and the outcome of the present translation outperforms that of the translation to the input language of the Spin model-checker.},
  keywords={},
  doi={10.1109/ACSD.2007.24},
  ISSN={1550-4808},
  month={July},}
@ARTICLE{4275027,
  author={Lee, Jang-Won and Chiang, Mung and Calderbank, A. Robert},
  journal={IEEE Transactions on Wireless Communications}, 
  title={Utility-optimal random-access control}, 
  year={2007},
  volume={6},
  number={7},
  pages={2741-2751},
  abstract={This paper designs medium access control (MAC) protocols for wireless networks through the network utility maximization (NUM) framework. A network-wide utility maximization problem is formulated, using a collision/persistence-probabilistic model and aligning selfish utility with total social welfare. By adjusting the parameters in the utility objective functions of the NUM problem, we can also control the tradeoff between efficiency and fairness of radio resource allocation. We develop two distributed algorithms to solve the utility-optimal random-access control problem, which lead to random access protocols that have slightly more message passing overhead than the exponential-backoff protocols, but significant potential for efficiency and fairness improvement. We provide readily-verifiable sufficient conditions under which convergence of the proposed algorithms to a global optimality of network utility can be guaranteed, and numerical experiments that illustrate the value of the NUM approach to the complexity-performance tradeoff in MAC design.},
  keywords={},
  doi={10.1109/TWC.2007.05991},
  ISSN={1558-2248},
  month={July},}
@INPROCEEDINGS{4279073,
  author={Kumar SD, Madhu and Bellur, Umesh},
  booktitle={27th International Conference on Distributed Computing Systems Workshops (ICDCSW'07)}, 
  title={A Distributed Algorithm for Underlay Aware and Available Overlay Formation in Event Broker Networks for Publish/Subscribe Systems}, 
  year={2007},
  volume={},
  number={},
  pages={69-69},
  abstract={Event broker networks are basically overlay networks formed over the underlying physical network. In modern distributed applications, ensuring high availability in the face of the runtime failures is a major issue. This paper presents an asynchronous distributed algorithm for constructing and maintaining an underlay aware overlay which ensures high availability in the presence of node and link failures in the underlying physical network. We prove theoretically that our algorithm is correct. The time complexity of the algorithm is estimated to be O(diameter*degree)2 of the network and the message complexity is O(diameter*degree). A model for availability of an underlay aware overlay network and a classification of available overlays are the other important contributions of this paper.},
  keywords={},
  doi={10.1109/ICDCSW.2007.9},
  ISSN={1545-0678},
  month={June},}
@ARTICLE{4282133,
  author={Vucetic, Branka and Li, Yonghui and Perez, Lance C. and Jiang, Fan},
  journal={Proceedings of the IEEE}, 
  title={Recent Advances in Turbo Code Design and Theory}, 
  year={2007},
  volume={95},
  number={6},
  pages={1323-1344},
  abstract={ The discovery of turbo codes and the subsequent rediscovery of low-density parity-check (LDPC) codes represent major milestones in the field of channel coding. Recent advances in the design and theory of turbo codes and their relationship to LDPC codes are discussed. Several new interleaver designs for turbo codes are presented which illustrate the important role that the interleaver plays in these codes. The relationship between turbo codes and LDPC codes is explored via an explicit formulation of the parity-check matrix of a turbo code, and simulation results are given for sum product decoding of a turbo code. },
  keywords={},
  doi={10.1109/JPROC.2007.897975},
  ISSN={1558-2256},
  month={June},}
@INPROCEEDINGS{4301339,
  author={Kreidl, O. Patrick and Willsky, Alan S.},
  booktitle={2007 IEEE/SP 14th Workshop on Statistical Signal Processing}, 
  title={Decentralized Detection in Undirected Network Topologies}, 
  year={2007},
  volume={},
  number={},
  pages={650-654},
  abstract={Consider the well-studied decentralized Bayesian detection problem with the twist of an undirected network topology, each edge representing a bidirectional (and perhaps unreliable) finite-rate communication link between two distributed sensor nodes. Every node operates in parallel, processing any particular local measurement in two (discrete) decision stages: the first selects the symbols (if any) transmitted to its immediate neighbors and the second, upon receiving the symbols (or lack thereof) from the same neighbors, decides the value of its local state. We adapt the team solution already known for directed acyclic networks and establish conditions such that the iterative numerical algorithm to collectively optimize the local decision rules admits an efficient message-passing interpretation, featuring an asynchronous distributed implementation in which total computation and communication overhead scales only linearly with the number of nodes. In sharp contrast to the directed case, this message-passing algorithm retains its global correctness and convergence guarantees without restrictions on the network topology.},
  keywords={},
  doi={10.1109/SSP.2007.4301339},
  ISSN={2373-0803},
  month={Aug},}
@ARTICLE{4302730,
  author={Pakin, Scott},
  journal={IEEE Transactions on Parallel and Distributed Systems}, 
  title={The Design and Implementation of a Domain-Specific Language for Network Performance Testing}, 
  year={2007},
  volume={18},
  number={10},
  pages={1436-1449},
  abstract={CONCEPTUAL is a toolset designed specifically to help measure the performance of high-speed interconnection networks such as those used in workstation clusters and parallel computers. It centers around a high-level domain-specific language, which makes it easy for a programmer to express, measure, and report the performance of complex communication patterns. The primary challenge in implementing a compiler for such a language is that the generated code must be extremely efficient so as not to misattribute overhead costs to the messaging library. At the same time, the language itself must not sacrifice expressiveness for compiler efficiency, or there would be little point in using a high-level language for performance testing. This paper describes the CONCEPTUAL language and the CONCEPTUAL compiler's novel code-generation framework. The language provides primitives for a wide variety of idioms needed for performance testing and emphasizes a readable syntax. The core code-generation technique, based on unrolling CONCEPTUAL programs into sequences of communication events, is simple yet enables the efficient implementation of a variety of high-level constructs. The paper further explains how CONCEPTUAL implements time-bounded loops - even those that comprise blocking communication - in the absence of a time-out mechanism as this is a somewhat unique language/implementation feature.},
  keywords={},
  doi={10.1109/TPDS.2007.1065},
  ISSN={1558-2183},
  month={Oct},}
@INPROCEEDINGS{4318516,
  author={Zhang, Jingjun and Lou, Kanghua and Liu, Guangyuan and Sun, Yang and Gao, Ruizhen},
  booktitle={2007 2nd IEEE Conference on Industrial Electronics and Applications}, 
  title={Application of a Parallel Genetic Algorithm for the Optimal Design of the Flexible Multi-body Model Vehicle Suspensions}, 
  year={2007},
  volume={},
  number={},
  pages={793-796},
  abstract={A parallel genetic algorithm based master-slave module for the optimal design of the flexible multi-body model vehicle suspensions is presented. This paper tests the algorithm on the cluster system based MPI. The results show that the application of the algorithm presented in this paper is better for the optimization and also improves the efficiency of the computing time.},
  keywords={},
  doi={10.1109/ICIEA.2007.4318516},
  ISSN={2158-2297},
  month={May},}
@INPROCEEDINGS{4313072,
  author={Bhattad, Kapil and Rathi, Vishwambhar and Urbanke, Ruediger},
  booktitle={2007 IEEE Information Theory Workshop}, 
  title={Degree Optimization and Stability Condition for the Min-Sum Decoder}, 
  year={2007},
  volume={},
  number={},
  pages={190-195},
  abstract={The min-sum (MS) algorithm is arguably the second most fundamental algorithm in the realm of message passing due to its optimality (for a tree code) with respect to the block error probability [1]. There also seems to be a fundamental relationship of MS decoding with the linear programming decoder [2]. Despite its importance, its fundamental properties have not nearly been studied as well as those of the sum-product (also known as BP) algorithm. We address two questions related to the MS rule. First, we characterize the stability condition under MS decoding. It turns out to be essentially the same condition as under BP decoding. Second, we perform a degree distribution optimization. Contrary to the case of BP decoding, under MS decoding the thresholds of the best degree distributions for standard irregular LDPC ensembles are significantly bounded away from the Shannon threshold. More precisely, on the AWGN channel, for the best codes that we find, the gap to capacity is 1 dB for a rate 0.3 code and it is 0.4 dB when the rate is 0.9 (the gap decreases monotonically as we increase the rate). We also used the optimization procedure to design codes for modified MS algorithm where the output of the check node is scaled by a constant 1/alpha. For alpha = 1.25, we observed that the gap to capacity was lesser for the modified MS algorithm when compared with the MS algorithm. However, it was still quite large, varying from 0.75 dB to 0.2 dB for rates between 0.3 and 0.9. We conclude by posing what we consider to be the most important open questions related to the MS algorithm.},
  keywords={},
  doi={10.1109/ITW.2007.4313072},
  ISSN={},
  month={Sep.},}
@INPROCEEDINGS{4313081,
  author={Sanghavi, Sujay},
  booktitle={2007 IEEE Information Theory Workshop}, 
  title={Equivalence of LP Relaxation and Max-Product for Weighted Matching in General Graphs}, 
  year={2007},
  volume={},
  number={},
  pages={242-247},
  abstract={Max-product belief propagation is a local, iterative algorithm find the mode/MAP estimate of a probability distribution. While it has been successfully employed in a wide variety of applications, there are relatively few theoretical guarantees of convergence and correctness for general loopy graphs that may have many short cycles. Of these, even fewer provide exact "necessary and sufficient" characterizations. In this paper we investigate the problem of using max-product to find the maximum weight matching in an arbitrary graph with edge weights. This is done by first constructing a probability distribution whose mode corresponds to the optimal matching, and then running max-product. Weighted matching can also be posed as an integer program, for which there is an LP relaxation. This relaxation is not always tight. In this paper we show that 1) If the LP relaxation is tight, then max-product always converges, and that too to the correct answer. 2) If the LP relaxation is loose, then max-product does not converge. This provides an exact, data-dependent characterization of max-product performance, and a precise connection to LP relaxation, which is a well-studied optimization technique. Also, since LP relaxation is known to be tight for bipartite graphs, our results generalize other recent results on using max-product to find weighted matching in bipartite graphs.},
  keywords={},
  doi={10.1109/ITW.2007.4313081},
  ISSN={},
  month={Sep.},}
@INPROCEEDINGS{4313139,
  author={Truhachev, Dmitri and Schlegel, Christian and Krzymien, Lukasz},
  booktitle={2007 IEEE Information Theory Workshop}, 
  title={Low-Complexity Capacity Achieving Two-Stage Demodulation/Decoding for Random Matrix Channels}, 
  year={2007},
  volume={},
  number={},
  pages={584-589},
  abstract={Iterative processing for linear matrix channels, aka turbo equalization, turbo demodulation, or turbo CDMA, has traditionally been studied as the concatenation of conventional error control codes with the linear (matrix) channel. However, in several situations, such as CDMA, multiple-input multiple- output channels, OFDM, and intersymbol-interference channels, the channel itself either contains inherent signal redundancy or such redundancy can readily be introduced at the transmitter, for example, the direct-spread signature sequences of CDMA form inherent repetition codes. For such systems, iterative demodulation of the linear channel exploiting this redundancy using simple iterative cancellation demodulators, followed by conventional feed-forward error control decoding provides a low-complexity, but extremely efficient decoding alternative. It is shown that this two-stage demodulator/decoder, which outperforms more complex turbo CDMA methods for equal power modes (users), can support an arbitrary number of modes if an unequal power distribution is adopted, and that the capacity of the Gaussian multiple access channel can be approached to at least within less than one bit everywhere.},
  keywords={},
  doi={10.1109/ITW.2007.4313139},
  ISSN={},
  month={Sep.},}
@INPROCEEDINGS{4317812,
  author={Ratnayake, Ruwan N.S. and Haratsch, Erich F. and Wei, Gu-Yeon},
  booktitle={2007 16th International Conference on Computer Communications and Networks}, 
  title={Serial Sum-Product Architecture for Low-Density Parity-Check Codes}, 
  year={2007},
  volume={},
  number={},
  pages={154-158},
  abstract={A serial sum-product architecture for low-density parity-check (LDPC) codes is presented. In the proposed architecture, a standard bit node processing unit computes the bit to check node messages sequentially, while the check node computations are broken up into several steps and computed on the fly. This bit node centric architecture requires considerably less memory compared to other serial architectures, including the check node centric architecture.},
  keywords={},
  doi={10.1109/ICCCN.2007.4317812},
  ISSN={1095-2055},
  month={Aug},}
@INPROCEEDINGS{4336245,
  author={Macariu, Georgiana and Frincu, Marc and Carstea, Alexandru and Petcu, Dana and Eckstein, Andrei},
  booktitle={16th International Conference on Parallel Architecture and Compilation Techniques (PACT 2007)}, 
  title={Redesigning Parallel Symbolic Computations Packages}, 
  year={2007},
  volume={},
  number={},
  pages={417-417},
  abstract={The ability of multi-core processors to increase application performance depends on the use of multiple threads within applications. Symbolic computations, requiring both CPU power and large memory, are well-suited candidates for deriving advantages from multi-core parallel architectures. This is possible only if the specific libraries and tools are designed to allow multi-threading and multi-processes. In order to promote the changes needed to adapt these libraries and tools to the new architectures, the changes performed on two main algorithms for symbolic computations, parallel integer factorization and parallel Grobner base computation, are described and discussed.},
  keywords={},
  doi={10.1109/PACT.2007.4336245},
  ISSN={1089-795X},
  month={Sep.},}
@INPROCEEDINGS{4338420,
  author={Lobato, Daniel Correa and Freitas Bulcao Neto, Renato de and Barbosa, Matheus Qualio and Graca Pimentel, Maria da and Teixeira, Cesar Augusto},
  booktitle={International Conference on Semantic Computing (ICSC 2007)}, 
  title={S-MOJOHON: Towards a semantic architecture for message exchanging}, 
  year={2007},
  volume={},
  number={},
  pages={759-766},
  abstract={This paper presents our efforts on adding semantic information to our MOJOHON architecture creating S- MOJOHON - Semantic, Modular, Java-oriented and Hostile NAT-proof - middleware for message exchanging. We developed S-MOJOHON aiming at allowing the communication among two or more instances of a distributed application while maintaining a high level of abstraction with respect to the communication facilities available and exploiting context information provided by an ontology. In our proofof-concept implementation, we use S-MOJOHON to select a rendezvous point for a multimedia flow using information about which autonomous systems it belongs to and its uptime. We represent these information using an ontology developed by us, which produces RDF documents that are handled by a semantic web framework and a reasoning engine. In preliminary tests, S-MOJOHON were able to successfully select the best rendezvous point considering information provided by the knowledge base.},
  keywords={},
  doi={10.1109/ICSC.2007.40},
  ISSN={},
  month={Sep.},}
@INPROCEEDINGS{4340139,
  author={Asoodeh, S. and Ramezani, H. and Samimi, H.},
  booktitle={2007 International Conference on Wireless Communications, Networking and Mobile Computing}, 
  title={Gaussian Approximation for LDPC Codes}, 
  year={2007},
  volume={},
  number={},
  pages={1437-1440},
  abstract={Today, LDPC codes have become one of the hottest topics in coding theory. Unlike many other classes of cods LDPC codes are already equipped with very fast (probabilistic) encoding and decoding algorithm. The decoding of LDPC codes are implemented through message-passing algorithm. Passed messages can be modeled as Gaussian variables. In this paper, the new approximate method for calculation of statistical parameters of these Gaussian variables is proposed. Based on proposed method, we can be able to estimate the threshold level of noise of regular LDPC codes over AWGN channels.},
  keywords={},
  doi={10.1109/WICOM.2007.364},
  ISSN={2161-9654},
  month={Sep.},}
@ARTICLE{4339197,
  author={DeMara, Ronald F. and Tseng, Yili and Ejnioui, Abdel},
  journal={IEEE Transactions on Parallel and Distributed Systems}, 
  title={Tiered Algorithm for Distributed Process Quiescence and Termination Detection}, 
  year={2007},
  volume={18},
  number={11},
  pages={1529-1538},
  abstract={The Tiered Algorithm is presented for time-efficient and message-efficient detection of process termination. It employs a global invariant of equality between process production and consumption at each level of process nesting to detect termination, regardless of execution interleaving order and network transit time. Correctness is validated for arbitrary process launching hierarchies, including launch-in-transit hazards, where processes are created dynamically based on runtime conditions for remote execution. The performance of the Tiered Algorithm is compared to three existing schemes with comparable capabilities, namely, the Chandrasekaran and Venkatesan (CV), Lai, Tseng, and Dong (LTD), and Credit termination detection algorithms. For synchronization of X tasks terminating in E epochs of idle processing, the tiered algorithm is shown to incur O(E) message count complexity and O(T lg T) message bit complexity while incurring detection latency corresponding to only integer addition and comparison. The synchronization performance in terms of message overhead, detection operations, and storage requirements are evaluated and compared across numerous task creation and termination hierarchies.},
  keywords={},
  doi={10.1109/TPDS.2007.1066},
  ISSN={1558-2183},
  month={Nov},}
@INPROCEEDINGS{4343854,
  author={Gao, Qi and Huang, Wei and Koop, Matthew J. and Panda, Dhabaleswar K.},
  booktitle={2007 International Conference on Parallel Processing (ICPP 2007)}, 
  title={Group-based Coordinated Checkpointing for MPI: A Case Study on InfiniBand}, 
  year={2007},
  volume={},
  number={},
  pages={47-47},
  abstract={As more and more clusters with thousands of nodes are being deployed for high performance computing (HPC), fault tolerance in cluster environments has become a critical requirement. Checkpointing and rollback recovery is a common approach to achieve fault tolerance. Although widely adopted in practice, coordinated checkpointing has a known limitation on scalability. Severe contention for bandwidth to storage system can occur as a large number of processes take a checkpoint at the same time, resulting in an extremely long checkpointing delay for large parallel applications. In this paper, we propose a novel group-based checkpointing design to alleviate this scalability limitation. By carefully scheduling the MPI processes to take checkpoints in smaller groups, our design reduces the number of processes simultaneously taking checkpoints, while allowing those processes not taking checkpoints to proceed with computation. We implement our design and carry out a detailed evaluation with micro-benchmarks, HPL, and the parallel version of a data mining toolkit, MotifMiner. Experimental results show our group-based checkpointing design can reduce the effective delay for checkpointing significantly, up to 78% for HPL and up to 70% for MotifMiner.},
  keywords={},
  doi={10.1109/ICPP.2007.44},
  ISSN={2332-5690},
  month={Sep.},}
@INPROCEEDINGS{4349877,
  author={Jacobsen, Noah and Soni, Robert},
  booktitle={2007 IEEE 66th Vehicular Technology Conference}, 
  title={Design of Rate-Compatible Irregular LDPC Codes Based on Edge Growth and Parity Splitting}, 
  year={2007},
  volume={},
  number={},
  pages={1052-1056},
  abstract={This paper considers the design of rate-compatible low-density parity-check (LDPC) codes with optimized degree distributions for their corresponding rates. The proposed design technique is based on extension, where a high-rate base code, or daughter code, is progressively extended to lower and lower rates such that each extension code is compatible with the previously obtained codes. Specifically, two well-known parity matrix construction methodologies, edge growth and parity splitting, are adapted to yield a flexible framework for constructing rate- compatible parity check matrices with a uniform performance characteristic. The design examples provided are based on extrinsic information transfer (EXIT) chart optimizations and demonstrate good performance up to rates as low as 1/5.},
  keywords={},
  doi={10.1109/VETECF.2007.228},
  ISSN={1090-3038},
  month={Sep.},}
@INPROCEEDINGS{4349918,
  author={Ueng, Yeong-Luh and Cheng, Chung-Chao},
  booktitle={2007 IEEE 66th Vehicular Technology Conference}, 
  title={A Fast-Convergence Decoding Method and Memory-Efficient VLSI Decoder Architecture for Irregular LDPC Codes in the IEEE 802.16e Standards}, 
  year={2007},
  volume={},
  number={},
  pages={1255-1259},
  abstract={In this paper, we propose a modified iterative decoding algorithm to decode a special class of quasi-cyclic low- density parity-check (QC-LDPC) codes such as QC-LDPC codes used in the IEEE 802.16e standards. The proposed decoding is implemented by serially decoding block codes with identical parity-check matrix H1 derived from the parity-check matrix H of the QC-LDPC codes. The dimensions of H1 are much smaller than those of H. Extrinsic values can be passed among these block codes since the code bits of these block codes are overlapped. Hence, the proposed decoding can reduce the number of iterations required by up to forty percent without error performance loss as compared to the conventional message- passing decoding algorithm. A partially-parallel very large-scale integration (VLSI) architecture is proposed to implement such a decoding algorithm. The proposed VLSI decoder can fully take advantage of the proposed decoding to increase its throughput. In addition, the proposed decoder only needs to store check-to- variable messages and hence is memory efficient.},
  keywords={},
  doi={10.1109/VETECF.2007.269},
  ISSN={1090-3038},
  month={Sep.},}
@INPROCEEDINGS{4357523,
  author={Daniels, Mark and Muldawer, Kate and Schlessman, Jason and Ozer, Burak and Wolf, Wayne},
  booktitle={2007 First ACM/IEEE International Conference on Distributed Smart Cameras}, 
  title={Real-Time Human Motion Detection with Distributed Smart Cameras}, 
  year={2007},
  volume={},
  number={},
  pages={187-194},
  abstract={Many smart camera security systems employ a single camera model; this makes depth perception impossible and the occlusion of objects (either by fixtures or by other body parts of the subject) prevents meaningful task automation. Multi-camera systems have significant overhead in communication and three-dimensional modeling. We have developed a multi-camera system capable of overcoming this issue. Two cameras observing the same space from different vantage points provide depth perception of a subject so that the positions of the hands and face can be mapped in three dimensions. Unlike other three-dimensional modeling programs, we use an ultra-compression method and build on existing message passing interface (MPI) middleware for communication, allowing for real-time performance. Our application provides a framework for robust motion detection and gesture recognition.},
  keywords={},
  doi={10.1109/ICDSC.2007.4357523},
  ISSN={},
  month={Sep.},}
@INPROCEEDINGS{4357586,
  author={Kurkoski, Brian M. and Yamaguchi, Kazuhiko and Kobayashi, Kingo},
  booktitle={2007 Information Theory and Applications Workshop}, 
  title={Density Evolution for GF(q) LDPC Codes Via Simplified Message-passing Sets}, 
  year={2007},
  volume={},
  number={},
  pages={237-244},
  abstract={A message-passing decoder for GF(q) low-density parity-check codes is defined, which uses discrete messages from a subset of all possible binary vectors of length q. The proposed algorithm is a generalization to GF(q) of Richardson and Urbanke's decoding "Algorithm E" for binary codes. Density evolution requires a mapping between the probability distribution spaces for the channel, variable and check messages, and under the proposed algorithm, exact density evolution is possible. Symmetries in the message densities permit reduction in the size of the probability distribution space. Noise thresholds are obtained for LDPC codes on discrete memoryless channels, and as with Algorithm E, are remarkably close to noise thresholds under more complex belief propagation decoding.},
  keywords={},
  doi={10.1109/ITA.2007.4357586},
  ISSN={},
  month={Jan},}
@INPROCEEDINGS{4351391,
  author={Li, H.F. and Maghayreh, Eslam Al and Goswami, D.},
  booktitle={Third IEEE International Symposium on Dependable, Autonomic and Secure Computing (DASC 2007)}, 
  title={Using Atoms to Simplify Distributed Programs Checking}, 
  year={2007},
  volume={},
  number={},
  pages={75-83},
  abstract={The execution of a distributed program generates a large state space which needs to be checked in testing and debugging. This state space can be reduced by using atoms corresponding to code blocks before performing the checking of the required program properties. This paper presents our results in using atoms which are known at program design time for this purpose. We consider the impact of incomplete or incorrect knowledge of atoms on the validity of checking if a run is indeed atomic with respect to the identified atoms and if it satisfies the required program properties.},
  keywords={},
  doi={10.1109/DASC.2007.24},
  ISSN={},
  month={Sep.},}
@INPROCEEDINGS{4351577,
  author={Zhang, Zhihong and Meng, Dan and Zhan, Jianfeng and Wang, Lei and Jin, Yi and Wen, Yu and Wang, Hui},
  booktitle={2007 IFIP International Conference on Network and Parallel Computing Workshops (NPC 2007)}, 
  title={Gingko: correlating causal paths in distributed systems}, 
  year={2007},
  volume={},
  number={},
  pages={762-767},
  abstract={Many large-scale systems are distributed systems of multiple communicating components. Finding causal paths of message traces between components throughout these systems is important to uncover runtime behaviors and identify the root cause of failures, but this "art" often hides in the heads of developers or domain experts. Our goal is to design tools and algorithms to help developers record this art into logs and help the modestly-skilled users and system administrators master it to make better use and management of distributed systems. In this paper, we present a methodology that automatically builds the causal paths of message traces by 1) an agreement with programmers on the style and content of logs produced by operational distributed systems they develop and 2) a correlation algorithm to build message causal paths with the clues from these logs. To validate this mechanism, we have implemented Gingko, a prototype providing a tool chain for users to gain better comprehensions of distributed systems and to debug them efficiently when errors happen.},
  keywords={},
  doi={10.1109/NPC.2007.46},
  ISSN={},
  month={Sep.},}
@ARTICLE{4350320,
  author={Zheng, Yan-Xiu and Su, Yu T.},
  journal={IEEE Transactions on Wireless Communications}, 
  title={A Turbo Coding System for High Speed Communications}, 
  year={2007},
  volume={6},
  number={10},
  pages={3700-3711},
  abstract={This paper presents a new turbo coding scheme for high data rate applications. It uses a special interleaver structure that is naturally suited for parallel processing and a multiple-round early stopping test involving both sign check and a CRC code. A memory (storage) management mechanism is included as a critical part of the decoder. The proposed coding scheme offers new design options and tradeoffs that are not available to conventional convolutional turbo codes (CTCs). In particular, it becomes possible for the decoder to employ an efficient inter-block collaborative decoding algorithm, passing the information obtained from stopping test proved blocks to other unproved blocks. It also becomes important to have a proper decoding schedule. The combined effect is improved performance and reduction in the average decoding latency. We show that the memory manager has a modular-like effect in that additional memory units render enhanced performance due not only to less forced early stopping but to possible increases of the interleaving depth. It also provides additional design tradeoff amongst performance, speed and required memory size. Depending on the decoding schedule, the degree of parallelism and other decoding resources available, the proposed scheme admits a variety of decoder architectures that meet a large range of speed and performance demands.},
  keywords={},
  doi={10.1109/TWC.2007.060086},
  ISSN={1558-2248},
  month={October},}
@ARTICLE{4349145,
  author={Li, Xiao and Zhao, Qianchuan},
  journal={IEEE Transactions on Power Systems}, 
  title={Parallel Implementation of OBDD-Based Splitting Surface Search for Power System}, 
  year={2007},
  volume={22},
  number={4},
  pages={1583-1593},
  abstract={ Parallel computational structure is helpful for many complicated problems, especially those which can be divided into multiple independent simpler sub-problems. The ordered binary decision diagrams (OBDD)-based splitting surface search algorithm owns this kind of dividability, derived from the associative law of Boolean expression and the dividability of matrix operation. We have implemented the algorithm with the parallel computation structure MPI to save up computing time. Customized verification is available on our interactive illustrative website http://obdd.cfins.au.tsinghua.edu.cn/ (login user name: mag, password: 199707). },
  keywords={},
  doi={10.1109/TPWRS.2007.907956},
  ISSN={1558-0679},
  month={Nov},}
@INPROCEEDINGS{4380728,
  author={Syed, Irfan and Williams, John A. and Bergmann, Neil W.},
  booktitle={2007 International Conference on Field Programmable Logic and Applications}, 
  title={A Hybrid Reconfigurable Cluster-on-Chip Architecture with Message Passing Interface for Image Processing Applications}, 
  year={2007},
  volume={},
  number={},
  pages={609-612},
  abstract={We demonstrate a hybrid reconfigurable cluster-on-chip architecture with a cross-platform Message Passing Interface (MPI), a cross-platform parallel image processing library and a sample application. We describe the system, network architecture, MPI library and the parallel image processing library implementations. We validate the performance, scalability and suitability of MPI as a software interface to enable cross-platform application parallelism on reconfigurable hybrid cluster-on-chip systems and desktop cluster systems. The presented results are promising, showing the suitability, scalability and performance of parallelisation of image processing algorithms with a cross-platform MPI implementation.},
  keywords={},
  doi={10.1109/FPL.2007.4380728},
  ISSN={1946-1488},
  month={Aug},}
@INPROCEEDINGS{4381602,
  author={Rykalova, Yelena and Levitin, Lev B. and Brower, Richard},
  booktitle={2007 12th IEEE Symposium on Computers and Communications}, 
  title={Modeling of Latency and Saturation Phenomena in Interconnection Networks}, 
  year={2007},
  volume={},
  number={},
  pages={1001-1006},
  abstract={A multiprocessor networks modeled as a ring and as a 2D toroidal lattice of nodes are considered. Each node generates messages with probability lambda per clock cycle per output port. Once an output buffer is not empty, the output port sends out exactly one message every clock cycle. We derive analytical expressions for the queue length distribution, the average number of messages in buffers, and the latency. The network experiences a phase transition from equilibrium to the saturation regime, and the critical exponent is equal to 1. Simulations demonstrate an excellent agreement with theoretical predictions and validate the assumption of independent queues. A model of a ring network where the message generating rate depends on the intensity of the incoming messages is studied by simulation. The results show the emergence of dependences between queues in closely located nodes, and changes in the values of the critical load and critical exponent.},
  keywords={},
  doi={10.1109/ISCC.2007.4381602},
  ISSN={1530-1346},
  month={July},}
@ARTICLE{4358702,
  author={Khanna, Gunjan and Yu Cheng, Mike and Varadharajan, Padma and Bagchi, Saurabh and Correia, Miguel P. and Veríssimo, Paulo J.},
  journal={IEEE Transactions on Dependable and Secure Computing}, 
  title={Automated Rule-Based Diagnosis Through a Distributed Monitor System}, 
  year={2007},
  volume={4},
  number={4},
  pages={266-279},
  abstract={In today's world where distributed systems form many of our critical infrastructures, dependability outagesare becoming increasingly common. In many situations, it is necessary to not just detect a failure, but alsoto diagnose the failure, i.e., to identify the source of the failure. Diagnosis is challenging since highthroughput applications with frequent interactions between the different components allow fast errorpropagation. It is desirable to consider applications as black-boxes for the diagnostic process. In thispaper, we propose a Monitor architecture for diagnosing failures in large-scale network protocols. TheMonitor only observes the message exchanges between the protocol entities (PEs) remotely and doesnot access internal protocol state. At runtime, it builds a causal graph between the PEs based on theircommunication and uses this together with a rule base of allowed state transition paths to diagnose thefailure. The tests used for the diagnosis are based on the rule base and are assumed to have imperfectcoverage. The hierarchical Monitor framework allows distributed diagnosis handling failures at individualMonitors. The framework is implemented and applied to a reliable multicast protocol executing on ourcampus-wide network. Fault injection experiments are carried out to evaluate the accuracy and latency ofthe diagnosis.},
  keywords={},
  doi={10.1109/TDSC.2007.70211},
  ISSN={1941-0018},
  month={Oct},}
@ARTICLE{4359942,
  author={Serafini, Marco and Bondavalli, Andrea and Suri, Neeraj},
  journal={IEEE Transactions on Dependable and Secure Computing}, 
  title={On-Line Diagnosis and Recovery: On the Choice and Impact of Tuning Parameters}, 
  year={2007},
  volume={4},
  number={4},
  pages={295-312},
  abstract={A sequenced process of Fault Detection followed by the erroneous node's Isolation and system Reconfiguration (node exclusion or recovery), that is, the FDIR process, characterizes the sustained operations of a fault-tolerant system. For distributed systems utilizing message passing, a number of diagnostic (and associated FDIR) approaches, including our prior algorithms, exist in literature and practice. Invariably, the focus is on proving the completeness and correctness (all and only the faulty nodes are isolated) for the chosen fault model, without explicitly segregating permanent from transient faulty nodes. To capture diagnostic issues related to the persistence of errors (transient, intermittent, and permanent), we advocate the integration of count-and-threshold mechanisms into the FDIR framework. Targeting pragmatic system issues, we develop an adaptive online FDIR framework that handles a continuum of fault models and diagnostic protocols and comprehensively characterizes the role of various probabilistic parameters that, due to the count-and-threshold approach, influence the correctness and completeness of diagnosis and system reliability such as the fault detection frequency. The FDIR framework has been implemented on two prototypes for automotive and aerospace applications. The tuning of the protocol parameters at design time allows a significant improvement with respect to prior design choices.},
  keywords={},
  doi={10.1109/TDSC.2007.70210},
  ISSN={1941-0018},
  month={Oct},}
@INPROCEEDINGS{4383981,
  author={Molina-Jimenez, Carlos and Shrivastava, Santosh and Cook, Nick},
  booktitle={11th IEEE International Enterprise Distributed Object Computing Conference (EDOC 2007)}, 
  title={Implementing Business Conversations with Consistency Guarantees Using Message-Oriented Middleware}, 
  year={2007},
  volume={},
  number={},
  pages={51-51},
  abstract={The paper considers distributed applications where interactions between constituent services take place via messages in an asynchronous environment with unpredictable communication and processing delays; further, interacting parties are not required to be online at the same time. Message-oriented middleware (MoM) is commonly used for connecting such loosely coupled distributed applications. Despite loose coupling, many service interactions have temporal and message validation constraints. A failure to deliver a valid message within its time constraint could cause mutually conflicting views of an interaction (one party regarding it as timely whilst the other party regarding it as untimely) leading to application level inconsistencies. In a loosely coupled system, such inconsistencies could remain undetected for a long time, requiring costly application level recovery procedures. This paper describes how synchronisation support providing multilateral consistency guarantees can be provided using the underlying MoM to prevent inconsistencies from reaching application level.},
  keywords={},
  doi={10.1109/EDOC.2007.21},
  ISSN={1541-7719},
  month={Oct},}
@INPROCEEDINGS{4384036,
  author={Xavier, Carolina and Sachetto, Rafael and Vieira, Vinicius and Weber dos Santos, Rodrigo and Meira Jr., Wagner},
  booktitle={19th International Symposium on Computer Architecture and High Performance Computing (SBAC-PAD'07)}, 
  title={Multi-level Parallelism in the Computational Modeling of the Heart}, 
  year={2007},
  volume={},
  number={},
  pages={3-10},
  abstract={Computational modeling of the heart has demonstrated to be a useful tool for the investigation and comprehension of the complex biophysical processes that underlie cardiac function. Unfortunately, large scale simulations, such as those resulting from the discretization of an entire heart, remain a computational challenge. In order to reduce simulation execution times, parallel implementations have traditionally exploited data parallelism via numerical schemes based on domain-decomposition. However, it has been verified that the parallel efficiency of these implementations severely degrades as the number of processors increases. In this work, we propose and implement a new parallel algorithm for the solution of cardiac models. By relaxing the coherence of the execution, a new level of parallelism could be identified and exploited: pipelining. A synchronous parallel algorithm that uses both pipelining and data decomposition techniques was implemented and used the MPI library for communication. Numerical tests were performed in a 8-node linux-cluster. Our preliminary results indicate that the proposed algorithm is able to increase the parallel efficiency up to 20% when compared to the traditional approach that uses pure data-level parallelism. In addition, the numerical precision was kept under control (relative errors under 4%) when the relaxed coherence execution was adopted.},
  keywords={},
  doi={10.1109/SBAC-PAD.2007.19},
  ISSN={1550-6533},
  month={Oct},}
@INPROCEEDINGS{4393792,
  author={Zhang, G. H. and Xia, M. Y.},
  booktitle={2007 International Symposium on Microwave, Antenna, Propagation and EMC Technologies for Wireless Communications}, 
  title={Parallel Analysis of Transient Scattering by 3D Conducting Objects Using Time Domain Integral Equation Method}, 
  year={2007},
  volume={},
  number={},
  pages={970-973},
  abstract={A parallel time domain integral equation (TDIE) solver for analysis of transient scattering by large 3D objects is implemented in this paper. The surface is modelled using triangle patches to suit RWG spatial basis functions, and the quadratic B-spline functions are adopted as the temporal basis functions. The present parallelism uses the MPI (message passing interface) communicator. To verify the formulation and codes, a sphere and a cross-plate structure are analysed, and numerical results are compared in good agreements with analytical and moment method solutions.},
  keywords={},
  doi={10.1109/MAPE.2007.4393792},
  ISSN={},
  month={Aug},}
@INPROCEEDINGS{4392186,
  author={Jun Ning and Jinhong Yuan},
  booktitle={2007 International Symposium on Communications and Information Technologies}, 
  title={Design of fully-source-involved LDPC codes with tripartite graph}, 
  year={2007},
  volume={},
  number={},
  pages={1125-1130},
  abstract={In this paper we consider a class of fully-sourceinvolved low-density parity-check (FSI-LDPC) codes. We show that the code designed based on the conventional bipartite graph may not be feasible or implementable. We investigate the applicability of the bipartite graph as a representation of an FSILDPC code for density evolution. We discuss the applicable range of the bipartite representation. Then we introduce tripartite graph for FSI-LDPC codes as a modification of the conventional bipartite representation. In this graph, we consider the degree distributions for source nodes and redundancy nodes separately. For design of FSI-LDPC codes, we show that, when code rate is low, possible performance degradation originated from the conventional bipartite representation can be prevented by adopting the tripartite representation.},
  keywords={},
  doi={10.1109/ISCIT.2007.4392186},
  ISSN={},
  month={Oct},}
@INPROCEEDINGS{4401322,
  author={MacLaren Walsh, John and Regalia, Phillip A.},
  booktitle={2007 IEEE 8th Workshop on Signal Processing Advances in Wireless Communications}, 
  title={Expectation propagation for distributed estimation in sensor networks}, 
  year={2007},
  volume={},
  number={},
  pages={1-5},
  abstract={We show that the expectation propagation (EP) family of algorithms constitute a natural choice for distributed estimation and detection in sensor networks. In particular, random sleep strategies, which are commonly chosen to ensure robustness, equal power dissipation across the network, and ease of deployment, espouse a sparse dependence structure among the parameters to be estimated. This sparse dependence structure mimics the structure which belief and expectation propagation exploited in the decoding of turbo and low density parity check (LDPC) codes to bring the performance of physical layer communications systems to the fundamental limits set out by Shannon. We provide examples of practical sensor network tasks which fall into the framework set out in this paper. By applying extensions of the extrinsic information transfer (EXIT) chart theory to EP in these distributed estimation applications, we can predict the performance and convergence of the distributed estimation algorithm in very large networks with an easy to obtain plot.},
  keywords={},
  doi={10.1109/SPAWC.2007.4401322},
  ISSN={1948-3252},
  month={June},}
@INPROCEEDINGS{4403199,
  author={Park, Mi-Young and Kim, Seok Young and Park, Hyuk-Ro},
  booktitle={2007 IEEE International Conference on Granular Computing (GRC 2007)}, 
  title={Visualization of Affect-Relations of Message Races for Debugging MPI Programs}, 
  year={2007},
  volume={},
  number={},
  pages={745-745},
  abstract={Detecting unaffected races is important for debugging MPI parallel programs, because unaffected races can cause the occurrence of affected races which do not need to be debugged. However, the previous techniques can not dis- cern unaffected races from affected races so that program- mers will be easily overwhelmed by the vast information of race detection. In this paper, we present a new visualiza- tion which lets programmers know which race is affected or not. For this, our technique checks whether any message racing toward a race is affected or not based on happen- before relation, and also checks which process influences a race during an execution. After the execution, it visualizes the affect-relations of the detected races. Therefore, our vi- sualization helps for programmers to effectively distinguish unaffected races from affected races, and to debug MPI par- allel programs.},
  keywords={},
  doi={10.1109/GrC.2007.120},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{4410967,
  author={Ratnayake, Ruwan N. S. and Haratsch, Erich F. and Wei, Gu-Yeon},
  booktitle={IEEE GLOBECOM 2007 - IEEE Global Telecommunications Conference}, 
  title={A Bit-Node Centric Architecture for Low-Density Parity-Check Decoders}, 
  year={2007},
  volume={},
  number={},
  pages={265-270},
  abstract={A bit-node centric decoder architecture for low- density parity-check codes is proposed. This architecture performs the optimum sum-product algorithm. A bit node processing unit computes the bit-to-check node messages sequentially, while the computation of the check-to-bit node messages is broken up into several steps. A stand-alone decoder architecture, and a decoder architecture for a concatenated detector-decoder system are presented. The proposed stand-alone decoder architecture requires significantly less memory compared to other known serial architectures. The hardware requirements are reduced even further for the concatenated detector-decoder system.},
  keywords={},
  doi={10.1109/GLOCOM.2007.57},
  ISSN={1930-529X},
  month={Nov},}
@INPROCEEDINGS{4410970,
  author={Zhang, Fan and Pfister, Henry D.},
  booktitle={IEEE GLOBECOM 2007 - IEEE Global Telecommunications Conference}, 
  title={List-Message Passing Achieves Capacity on the q-ary Symmetric Channel for Large q}, 
  year={2007},
  volume={},
  number={},
  pages={283-287},
  abstract={We discuss and analyze a list-message-passing decoder with verification for low-density parity-check (LDPC) codes on the q-ary symmetric channel (q-SC). Rather than passing messages consisting of symbol probabilities, we pass lists of possible symbols and mark very likely symbols as verified. The density evolution (DE) equations for this decoder are derived and used to compute decoding thresholds. If the maximum list-size is unbounded, then we find that any capacity-achieving LDPC code for the binary erasure channel can be used to achieve capacity on the q-SC for large q. The decoding thresholds are also computed via DE for the case where each list is truncated to satisfy a maximum list-size constraint. The probability of false verification is considered for this case, and techniques are discussed to mitigate the problem. Optimization of the degree distribution is also used to improve the threshold for a fixed maximum list size. Finally, the proposed algorithm is compared with a variety of other algorithms using both density evolution thresholds and simulation results.},
  keywords={},
  doi={10.1109/GLOCOM.2007.60},
  ISSN={1930-529X},
  month={Nov},}
@INPROCEEDINGS{4411018,
  author={Zarubica, Radivoje and Wilson, Stephen G. and Hall, Eric},
  booktitle={IEEE GLOBECOM 2007 - IEEE Global Telecommunications Conference}, 
  title={Multi-Gbps FPGA-Based Low Density Parity Check (LDPC) Decoder Design}, 
  year={2007},
  volume={},
  number={},
  pages={548-552},
  abstract={A novel high-throughput (6 Gb/s), fully-parallel FPGA-based 1200-bit rate-1/2 Low Density Parity Check (LDPC) decoder design is presented. The decoder features a PEG- based regular (6,3) code and a modified min-sum algorithm that improves performance without any additional hardware overhead.},
  keywords={},
  doi={10.1109/GLOCOM.2007.108},
  ISSN={1930-529X},
  month={Nov},}
@INPROCEEDINGS{4411215,
  author={Fresia, M. and Vandendorpe, L.},
  booktitle={IEEE GLOBECOM 2007 - IEEE Global Telecommunications Conference}, 
  title={Distributed Source Coding Using Raptor Codes}, 
  year={2007},
  volume={},
  number={},
  pages={1587-1591},
  abstract={In this paper the problem of distributed source coding (DSC) of binary sources with side information at the decoder is addressed. We propose a scheme based on Raptor codes which are a new class of rateless codes. We adapt the decoding scheme to this problem by implementing the message passing strategy between the constituent decoders of Raptor codes at each decoding iteration. The proposed approach enables to achieve better performances than those achieved by the solutions based on turbo codes, and by the solutions based on regular low density parity check codes (LDPC) codes.},
  keywords={},
  doi={10.1109/GLOCOM.2007.305},
  ISSN={1930-529X},
  month={Nov},}
@INPROCEEDINGS{4419854,
  author={Evans, Gareth E. and Keith, Jonathan M. and Kroese, Dirk P.},
  booktitle={2007 Winter Simulation Conference}, 
  title={Parallel cross-entropy optimization}, 
  year={2007},
  volume={},
  number={},
  pages={2196-2202},
  abstract={The cross-entropy (CE) method is a modern and effective optimization method well suited to parallel implementations. There is a vast array of problems today, some of which are highly complex and can take weeks or even longer to solve using current optimization techniques. This paper presents a general method for designing parallel CE algorithms for multiple instruction multiple data (MIVID) distributed memory machines using the message passing interface (MPI) library routines. We provide examples of its performance for two well-known test-cases: the (discrete) Max-Cut problem and (continuous) Rosenbrock problem. Speedup factors and a comparison to sequential CE methods are reported.},
  keywords={},
  doi={10.1109/WSC.2007.4419854},
  ISSN={1558-4305},
  month={Dec},}
@INPROCEEDINGS{4420171,
  author={Li, H. F. and Maghayreh, Eslam Al and Goswami, D.},
  booktitle={Eighth International Conference on Parallel and Distributed Computing, Applications and Technologies (PDCAT 2007)}, 
  title={Detecting Atomicity Errors in Message Passing Programs}, 
  year={2007},
  volume={},
  number={},
  pages={193-200},
  abstract={A distributed application can be viewed as a collection of processes that execute a number of atomic actions. Atomicity is the basis for reasoning about the correctness of a program. Atomicity errors in a run typically indicate the presence of program errors. This paper formalizes the notion of atomicity of an action in a message passing program based on a weak-order relation among atoms. An atom can be a single statement or a sequence of statements in a program. Knowing the atoms, the atomicity of a run can be monitored and checked. Serialization of conflicting atoms is another generic correctness requirement. When atoms affect a common property, such as in sharing resources or maintaining a common constraint, they must be serialized in a run. This paper presents two efficient algorithms for dynamically detecting atomicity and serialization errors, accompanied with their proof of correctness.},
  keywords={},
  doi={10.1109/PDCAT.2007.56},
  ISSN={2379-5352},
  month={Dec},}
@INPROCEEDINGS{4425876,
  author={Suetsugu, Ryo and Yuen, Shoji and Agusa, Kiyoshi},
  booktitle={14th Asia-Pacific Software Engineering Conference (APSEC'07)}, 
  title={A Synchronization Flow Analysis of Concurrent Objects in AIBO OPEN-R Programs Based on Communicating Processes}, 
  year={2007},
  volume={},
  number={},
  pages={366-373},
  abstract={We propose a compositional analysis method for synchronization flow in AIBO OPEN-R programs based on communicating processes. Concurrent objects of AIBO programs with the OPEN-RAPI are synchronized by two types of signals: ready and notify. Focusing on these signals, we describe abstract behavior of AIBO programs in the pi-calculus preserving the source code structure. We model-check deadlock freeness and interactions order of AIBO programs based on this abstract behavior. Since a primary issue in model-checking is the state space explosion in the behavioral model, we present a decomposing method to reduce the combination of states of concurrent objects. Since our translation to the pi-calculus preserves the syntactical structure of source code, when a counter-example is pointed out, our method enables not only to detect the violation of property of the whole system, but also to point out which component may cause the violation. We developed a prototype translator from AIBO OPEN-R programs to abstract description in the pi-calculus. We show that an application of our decomposing method enables to practically model- check properties by existing tools in two examples of AIBO programs.},
  keywords={},
  doi={10.1109/ASPEC.2007.70},
  ISSN={1530-1362},
  month={Dec},}
@INPROCEEDINGS{4426905,
  author={Desell, Travis and Cole, Nathan and Magdon-Ismail, Malik and Newberg, Heidi and Szymanski, Boleslaw and Varela, Carlos},
  booktitle={Third IEEE International Conference on e-Science and Grid Computing (e-Science 2007)}, 
  title={Distributed and Generic Maximum Likelihood Evaluation}, 
  year={2007},
  volume={},
  number={},
  pages={337-344},
  abstract={This paper presents GMLE 1, a generic and distributed framework for maximum likelihood evaluation. GMLE is currently being applied to astroinformatics for determining the shape of star streams in the Milky Way galaxy, and to particle physics in a search for theory-predicted but yet unobserved sub-atomic particles. GMLE is designed to enable parallel and distributed executions on platforms ranging from supercomputers and high-performance homogeneous computing clusters to more heterogeneous Grid and Internet computing environments. GMLE's modular implementation seperates concerns of developers into the distributed evaluation frameworks, scientific models, and search methods, which interact through a simple API. This allows us to compare the benefits and drawbacks of different scientific models using different search methods on different computing environments. We describe and compare the performance of two implementations of the GMLE framework: an MPI version that more effectively uses homogeneous environments such as IBM's BlueGene, and a SALSA version that more easily accommodates heterogeneous environments such as the Rensselaer Grid. We have shown GMLE to scale well in terms of computation as well as communication over a wide range of environments. We expect that scientific computing frameworks, such as GMLE, will help bridge the gap between scientists needing to analyze ever larger amounts of data and ever more complex distributed computing environments.},
  keywords={},
  doi={10.1109/E-SCIENCE.2007.30},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{4437996,
  author={Unpingco, J. and Gardiner, J. and Humphrey, L. and Ahalt, S.},
  booktitle={2007 DoD High Performance Computing Modernization Program Users Group Conference}, 
  title={Computationally Intensive SIP Algorithms on HPC}, 
  year={2007},
  volume={},
  number={},
  pages={271-276},
  abstract={algorithms that are computationally or memory intensive were implemented in MATLAB and parallelized using MatlabMPI. The parallel algorithms were tested on selected high performance clusters. Significant performance improvements were noted in the parallel versions of two of the algorithms and in one variant of the third.},
  keywords={},
  doi={10.1109/HPCMP-UGC.2007.22},
  ISSN={},
  month={June},}
@INPROCEEDINGS{4441910,
  author={Li, Xing and Abe, Yuta and Shimizu, Kazunori and Qiu, Zhen and Ikenaga, Takeshi and Goto, Satoshi},
  booktitle={2007 International Symposium on Integrated Circuits}, 
  title={Cost-Efficient Partially-Parallel Irregular LDPC Decoder with Message Passing Schedule}, 
  year={2007},
  volume={},
  number={},
  pages={508-511},
  abstract={This paper proposes an improved message passing schedule for irregular LDPC decoder. Redundant memory accesses and column operations are removed by utilizing the characteristics of partial-parallel irregular LDPC decoding algorithm. As a result, the memory access frequency and hardware cost are efficiently reduced. According to the experimental results and comparison with existing work, proposed decoder provides a 30% hardware area reduction and a 36% power consumption saving with the same error correcting performance.},
  keywords={},
  doi={10.1109/ISICIR.2007.4441910},
  ISSN={2325-0631},
  month={Sep.},}
@INPROCEEDINGS{4446102,
  author={Bandi, Samuele and Tralli, Velio and Conti, Andrea and Nonato, Maddalena},
  booktitle={2007 15th International Conference on Software, Telecommunications and Computer Networks}, 
  title={Girth conditioning of LDPC codes through modified breadth first search algorithm}, 
  year={2007},
  volume={},
  number={},
  pages={1-6},
  abstract={This paper proposes a method to improve the performance of a low-density parity-check code, by selectively removing some cycles from the associated bipartite graph. The method is based on a modified version of breadth-first search (BFS) algorithm, that we call modified BFS (MBFS). Throughout the paper we will give a detailed description of the algorithm and analytically study its complexity. Simulation results will show that applying MBFS to a given code leads to significant improvement of its performance.},
  keywords={},
  doi={10.1109/SOFTCOM.2007.4446102},
  ISSN={},
  month={Sep.},}
@INPROCEEDINGS{4458927,
  author={Stefanski, T. and Drysdale, T. D.},
  booktitle={The Second European Conference on Antennas and Propagation, EuCAP 2007}, 
  title={Parallel Implementation of ADI-FDTD on Shared and Distributed Memory Computers}, 
  year={2007},
  volume={},
  number={},
  pages={1-6},
  abstract={We present results of a parallel ADI-FDTD implementation on shared and distributed memory computers using the Message Passing Interface (MPI) library. The ADI-FDTD method involves solving in every time step a tridiagonal matrix system of equations over the xy, xz, yz planes of the domain to update the electric field components. In our parallel implementation, the three-dimensional computational domain was spatially decomposed in two directions. Each tridiagonal matrix system is solved by a single processor, with the parallel computer architecture being exploited to solve multiple systems at the same time. This avoids inefficiency associated with using parallelised tridiagonal solver on a small matrices. The amount of data exchanged between processes was proportional to the volume of the local sub- domain. The code was developed in C programming language using the Message Passing Interface (MPI) library and tested on two high performance computers (IBM p690 symmetric multi-processor and a general purpose distributed memory cluster). Benchmarking simulations ran faster as the number of processors was increased, with a maximum speedup factor of 11 for the shared memory system and 4 for the distributed memory system. For the particular simulations that we ran, the speedup factor did not significantly improve with the use of more than 10 processors for the shared memory system and 7 processors for the distributed memory system.},
  keywords={},
  doi={10.1049/ic.2007.1206},
  ISSN={0537-9989},
  month={Nov},}
@INPROCEEDINGS{4487366,
  author={Zarubica, Radivoje and Wilson, Stephen G.},
  booktitle={2007 Conference Record of the Forty-First Asilomar Conference on Signals, Systems and Computers}, 
  title={A solution for memory collision in semi-parallel FPGA-based LDPC decoder design}, 
  year={2007},
  volume={},
  number={},
  pages={982-986},
  abstract={Low Density Parity Check (LDPC) decoders implementing long blocklength codes require semi-parallel design. One challenge when implementing these codes on Field Programmable Gate Arrays (FPGAs) is efficiently storing messages needed in the iteration process. To meet this challenge, a new class of LDPC codes is presented. They combine regularity of implementation with reduction of time needed for decoding process, and do not suffer of any significant performance loss due to their structure.},
  keywords={},
  doi={10.1109/ACSSC.2007.4487366},
  ISSN={1058-6393},
  month={Nov},}
@INPROCEEDINGS{4488394,
  author={Logan, Jeremy and Dickens, Phillip M.},
  booktitle={2007 4th IEEE Workshop on Intelligent Data Acquisition and Advanced Computing Systems: Technology and Applications}, 
  title={Using Object Based Files for High Performance Parallel I/O}, 
  year={2007},
  volume={},
  number={},
  pages={149-154},
  abstract={We contend that the scalable I/O problem in high performance computing is largely due to the legacy view of a file as a linear sequence of bytes. In this paper we introduce an alternative to the traditional "flat file " that uses the information contained in file views to partition a file into an optimal set of objects, minimizing locking contention and simplifying the lock management strategy. We illustrate the use of an object based cache added to ROMIO to efficiently and transparently add object-based file capabilities to MPI-IO. We analyze the performance of our system using the FLASH-IO benchmark, and demonstrate a substantial performance improvement over the standard ROMIO implementation.},
  keywords={},
  doi={10.1109/IDAACS.2007.4488394},
  ISSN={},
  month={Sep.},}
@INPROCEEDINGS{4488821,
  author={Li, Xing and Shimizu, Kazunori and Qiu, Zhen and Ikenaga, Takeshi and Goto, Satoshi},
  booktitle={2007 50th Midwest Symposium on Circuits and Systems}, 
  title={Partially-parallel irregular LDPC decoder based on improved message passing schedule}, 
  year={2007},
  volume={},
  number={},
  pages={1473-1476},
  abstract={In this paper, we propose a new efficient message-passing schedule for irregular LPDC code. Our approach is based on the schedule designed for regular LDPC code. We have modified the original schedule for regular LDPC code and improved it particularly for the irregular LDPC coder realization. The experimental results show that our method could achieve better performance than conventional one, and improve the converging rate as well.},
  keywords={},
  doi={10.1109/MWSCAS.2007.4488821},
  ISSN={1558-3899},
  month={Aug},}
@INPROCEEDINGS{4557334,
  author={Lechner, Gottfried and Pedersen, Troels and Kramer, Gerhard},
  booktitle={2007 IEEE International Symposium on Information Theory}, 
  title={EXIT Chart Analysis of Binary Message-Passing Decoders}, 
  year={2007},
  volume={},
  number={},
  pages={871-875},
  abstract={Binary message-passing decoders for LDPC codes are analyzed using EXIT charts. For the analysis, the variable node decoder performs all computations in the L-value domain. For the special case of a hard decision channel, this leads to the well-know Gallager B algorithm, while the analysis can be extended to channels with larger output alphabets. By increasing the output alphabet from hard decisions to four symbols, a gain of more than 1.0 dB is achieved using optimized codes. For this code optimization, the mixing property of EXIT functions has to be modified to the case of binary message-passing decoders.},
  keywords={},
  doi={10.1109/ISIT.2007.4557334},
  ISSN={2157-8117},
  month={June},}
@INPROCEEDINGS{4557230,
  author={Savin, Valentin},
  booktitle={2007 IEEE International Symposium on Information Theory}, 
  title={Iterative LDPC decoding using neighborhood reliabilities}, 
  year={2007},
  volume={},
  number={},
  pages={221-225},
  abstract={In this paper we study the impact of the processing order of nodes of a bipartite graph, on the performance of an iterative message-passing decoding. To this end, we introduce the concept of neighborhood reliabilities of graph's nodes. Nodes reliabilities are calculated at each iteration and then are used to obtain a processing order within a serial or serial/parallel scheduling. The basic idea is that by processing first the most reliable data, the decoder is reinforced before processing the less reliable one. Using neighborhood reliabilities, the min-sum decoder of LDPC codes approaches the performance of the sum-product decoder.},
  keywords={},
  doi={10.1109/ISIT.2007.4557230},
  ISSN={2157-8117},
  month={June},}
@INPROCEEDINGS{4557461,
  author={Wu, Xiaofu and Ling, Cong and Jiang, Ming and Xu, Enyang and Zhao, Chunming and You, Xiaohu},
  booktitle={2007 IEEE International Symposium on Information Theory}, 
  title={Towards Understanding Weighted Bit-Flipping Decoding}, 
  year={2007},
  volume={},
  number={},
  pages={1666-1670},
  abstract={A natural relationship between weighted bit-flipping (WBF) decoding and message-passing decoding is explored. This understanding can help us develop a dual WBF decoding algorithm from one type of message-passing decoding algorithm and vice versa. For min-sum decoding, one can find that its dual WBF algorithm is the algorithm proposed by Jiang et al. For belief-propagation (BP) decoding, we propose a new WBF algorithm and show its performance advantage. For some high-rate low-density parity-check (LDPC) codes of large row weight, it is shown that the WBF algorithm proposed by Liu and Pados performs extraordinarily well. However, its dual message- passing decoding does not work well. Furthermore, we propose a parallel implementation framework for various WBF algorithms. Compared to serial implementations, various WBF algorithms in their parallel form converge significantly faster and often perform better.},
  keywords={},
  doi={10.1109/ISIT.2007.4557461},
  ISSN={2157-8117},
  month={June},}
@INPROCEEDINGS{4557603,
  author={Zia, Amin and Reilly, James P. and Shirani, Shahram},
  booktitle={2007 IEEE International Symposium on Information Theory}, 
  title={Distributed Parameter Estimation with Side Information: A Factor Graph Approach}, 
  year={2007},
  volume={},
  number={},
  pages={2556-2560},
  abstract={In this paper, a low complexity algorithm for distributed maximum likelihood estimation of a binary symmetric source (BSS) using side-information is proposed. The estimation is formulated as an incomplete-data problem and is solved by the expectation-maximization (EM) algorithm. A low-complexity implementation of the algorithm using coset codes and LDPC-based syndrome decoding with message passing over factor-graph is also proposed. The algorithm is a generalization of the LDPC-based syndrome decoding algorithm for the case when the probability distribution of the source is not known a-priori. Hence, the algorithm may be considered as a tool for achieving the corner points of the Slepian-Wolf (SW) region in distributed coding when the correlation channel information is not available. The estimation efficiency is studied by comparing the mean square error with the achievable Fisher information.},
  keywords={},
  doi={10.1109/ISIT.2007.4557603},
  ISSN={2157-8117},
  month={June},}
@INPROCEEDINGS{4629218,
  author={Wong, Adam K.L. and Goscinski, Andrzej M.},
  booktitle={2007 IEEE International Conference on Cluster Computing}, 
  title={Evaluating the EASY-backfill job scheduling of static workloads on clusters}, 
  year={2007},
  volume={},
  number={},
  pages={64-73},
  abstract={This research aims at improving our understanding of backfilling job scheduling algorithms. The most frequently used algorithm, EASY-backfilling, was selected for a performance evaluation by scheduling static workloads of parallel jobs on a computer cluster. To achieve the aim, we have developed a batch job scheduler for Linux clusters, implemented several scheduling algorithms including ARCA and EASY-Backfilling, and carried out their performance evaluation by running well known MPI applications on a real cluster. Our performance evaluation carried out for EASY-Backfilling serves two purposes. First, the performance results obtained from our evaluation can be used to validate other researcherspsila results generated by simulation, and second, the methodology used in our evaluation has alleviated many problems existed in the simulations presented in the current literature.},
  keywords={},
  doi={10.1109/CLUSTR.2007.4629218},
  ISSN={2168-9253},
  month={Sep.},}
@INPROCEEDINGS{4629253,
  author={Takano, Ryousei and Matsuda, Motohiko and Kudoh, Tomohiro and Kodama, Yuetsu and Okazaki, Fumihiro and Ishikawa, Yutaka},
  booktitle={2007 IEEE International Conference on Cluster Computing}, 
  title={Effects of packet pacing for MPI programs in a Grid environment}, 
  year={2007},
  volume={},
  number={},
  pages={382-391},
  abstract={Improving the performance of TCP communication is the key to the successful deployment of MPI programs in a Grid environment in which multiple clusters are connected through high performance dedicated networks. To efficiently utilize the inter-cluster bandwidth, a traffic control mechanism is required so as not to allow the aggregate transmission bandwidth to exceed the inter-cluster bandwidth when multiple nodes communicate at one time. In this paper, we propose a traffic control method for MPI programs, in which an application or the MPI runtime controls the transmission rate based on the communication pattern by using certain MPI attributes. Packet pacing is used at each node preventing microscopic burst transmission to thus avoid congestion. We confirm the effectiveness of the proposed method by experiments using a 10 Gbps emulated WAN environment. We show most of the NAS Parallel benchmarks improve the performance, since the proposed method reduces packet losses due to traffic congestion on the inter-cluster network. The results have indicated that it is feasible to connect multiple clusters and run large-scale scientific applications over distances up to 1000 kilometers, if an appropriate network is available.},
  keywords={},
  doi={10.1109/CLUSTR.2007.4629253},
  ISSN={2168-9253},
  month={Sep.},}
@INPROCEEDINGS{4447838,
  author={Bani-Mohammad, S. and Ould-Khaoua, M. and Ababneh, I. and Mackenzie, Lewis M.},
  booktitle={2007 International Conference on Parallel and Distributed Systems}, 
  title={Comparative evaluation of the non-contiguous processor allocation strategies based on a real workload and a stochastic workload on multicomputers}, 
  year={2007},
  volume={},
  number={},
  pages={1-7},
  abstract={The performance study of the existing noncontiguous processor allocation strategies has been traditionally carried out by means of simulation based on a stochastic workload model to generate a stream of incoming jobs that are submitted to and run on a given message passing parallel machine for a period of time. To validate the performance of the existing allocation algorithms, there has been need to evaluate the algorithms' performance based on a real workload trace. In this study, we evaluate the performance of several well-known processor allocation and job scheduling strategies based on a real workload trace and compare the results against those obtained from using a stochastic workload. Our results reveal that the conclusions reached on the relative performance merits of the allocation strategies when a real workload trace is used are in general compatible with those obtained when a stochastic workload is used.},
  keywords={},
  doi={10.1109/ICPADS.2007.4447838},
  ISSN={1521-9097},
  month={Dec},}
@INPROCEEDINGS{4447747,
  author={Li, H. F. and Eslam Al Maghayreh},
  booktitle={2007 International Conference on Parallel and Distributed Systems}, 
  title={Using synchronized atoms to check distributed programs}, 
  year={2007},
  volume={},
  number={},
  pages={1-8},
  abstract={The execution of a distributed program generates a large state space which needs to be checked in testing and debugging. Atoms are useful abstractions in reducing the state lattice of a distributed computation; we refer to the reduced lattice as the atomic state lattice. However, general predicates remain difficult to check if they are asserted over all states. This paper presents a formulation to attack this problem involving separation of two different concerns: (a) order/synchronization requirement, and (b) computational dependency among atoms. Order requirement is modeled by the serialization of the global states reached by a synchronized set of atoms. Synchrony among atoms is specified by a synchronization predicate. Computational dependency among synchronized states is modeled by a general predicate. With this modeling assumption, the number of the states where a general predicate needs to be checked will be bounded by the number of atoms executed. Two efficient algorithms for checking a general predicate, in the cases where the synchronization predicate is conjunctive or disjunctive, are presented along with their proof of correctness.},
  keywords={},
  doi={10.1109/ICPADS.2007.4447747},
  ISSN={1521-9097},
  month={Dec},}
@INPROCEEDINGS{4447844,
  author={Badrinath, R. and Krishnakumar, R. and Palanivel Rajan, R.K.},
  booktitle={2007 International Conference on Parallel and Distributed Systems}, 
  title={Virtualization aware job schedulers for checkpoint-restart}, 
  year={2007},
  volume={},
  number={},
  pages={1-7},
  abstract={Application checkpoint and restart has been a widely studied problem over the last several decades. Despite immense volume of theory and several research project level implementations, there is very little by way of working solutions for the case of parallel distributed applications (such as MPI programs on a cluster). We describe our experiences in enhancing a job scheduler to leverage mechanisms of a virtual machine environment to support checkpoint-restart. We also describe the basic coordinated checkpoint-restart framework that we implemented on which this solution is based.},
  keywords={},
  doi={10.1109/ICPADS.2007.4447844},
  ISSN={1521-9097},
  month={Dec},}
@INPROCEEDINGS{5348831,
  author={Liao, Wei-keng and Ching, Avery and Coloma, Kenin and Nisar, Arifa and Choudhary, Alok and Chen, Jacqueline and Sankaran, Ramanan and Klasky, Scott},
  booktitle={SC '07: Proceedings of the 2007 ACM/IEEE Conference on Supercomputing}, 
  title={Using MPI file caching to improve parallel write performance for large-scale scientific applications}, 
  year={2007},
  volume={},
  number={},
  pages={1-11},
  abstract={Typical large-scale scientific applications periodically write checkpoint files to save the computational state throughout execution. Existing parallel file systems improve such write-only I/O patterns through the use of client-side file caching and write-behind strategies. In distributed environments where files are rarely accessed by more than one client concurrently, file caching has achieved significant success; however, in parallel applications where multiple clients manipulate a shared file, cache coherence control can serialize I/O. We have designed a thread based caching layer for the MPI I/O library, which adds a portable caching system closer to user applications so more information about the application's I/O patterns is available for better coherence control. We demonstrate the impact of our caching solution on parallel write performance with a comprehensive evaluation that includes a set of widely used I/O benchmarks and production application I/O kernels.},
  keywords={},
  doi={10.1145/1362622.1362634},
  ISSN={},
  month={Nov},}
@ARTICLE{4389924,
  author={Darabiha, Ahmad and Carusone, Anthony Chan and Kschischang, Frank R.},
  journal={IEEE Transactions on Circuits and Systems II: Express Briefs}, 
  title={Block-Interlaced LDPC Decoders With Reduced Interconnect Complexity}, 
  year={2008},
  volume={55},
  number={1},
  pages={74-78},
  abstract={Two design techniques are proposed for high-throughput low-density parity-check (LDPC) decoders. A broadcasting technique mitigates routing congestion by reducing the total global wirelength. An interlacing technique increases the decoder throughput by processing two consecutive frames simultaneously. The brief discusses how these techniques can be used for both fully parallel and partially parallel LDPC decoders. For fully parallel decoders with code lengths in the range of a few thousand bits, the half-broadcasting technique reduces the total global wirelength by about 26% without any hardware overhead. The block interlacing scheme is applied to the design of two fully parallel decoders, increasing the throughput by 60% and 71% at the cost of 5.5% and 9.5% gate count overhead, respectively.},
  keywords={},
  doi={10.1109/TCSII.2007.905328},
  ISSN={1558-3791},
  month={Jan},}
@ARTICLE{4444762,
  author={Guo, Qinghua and Ping, Li},
  journal={IEEE Journal on Selected Areas in Communications}, 
  title={LMMSE turbo equalization based on factor graphs}, 
  year={2008},
  volume={26},
  number={2},
  pages={311-319},
  abstract={In this paper, a vector-form factor graph representation is derived for intersymbol interference (ISI) channels. The resultant graphs have a tree-structure that avoids the short cycle problem in existing graph approaches. Based on a joint Gaussian approximation, we establish a connection between the LLR (log-likelihood ratio) estimator for a linear system driven by binary inputs and the LMMSE (linear minimum mean-square error) estimator for a linear system driven by Gaussian inputs. This connection facilitates the application of the recently proposed Gaussian message passing technique to the cycle-free graphs for ISI channels. We also show the equivalence between the proposed approach and the Wang-Poor approach based on the LMMSE principle. An attractive advantage of the proposed approach is its intrinsic parallel structure. Simulation results are provided to demonstrate this property.},
  keywords={},
  doi={10.1109/JSAC.2008.080208},
  ISSN={1558-0008},
  month={February},}
@ARTICLE{4455730,
  author={Bayati, Mohsen and Shah, Devavrat and Sharma, Mayank},
  journal={IEEE Transactions on Information Theory}, 
  title={Max-Product for Maximum Weight Matching: Convergence, Correctness, and LP Duality}, 
  year={2008},
  volume={54},
  number={3},
  pages={1241-1251},
  abstract={Max-product "belief propagation" (BP) is an iterative, message-passing algorithm for finding the maximum a posteriori (MAP) assignment of a discrete probability distribution specified by a graphical model. Despite the spectacular success of the algorithm in many application areas such as iterative decoding and combinatorial optimization, which involve graphs with many cycles, theoretical results about both the correctness and convergence of the algorithm are known in only a few cases (see section I for references). In this paper, we prove the correctness and convergence of max-product for finding the maximum weight matching (MWM) in bipartite graphs. Even though the underlying graph of the MWM problem has many cycles, somewhat surprisingly we show that the max-product algorithm converges to the correct MWM as long as the MWM is unique. We provide a bound on the number of iterations required and show that for a graph of size n, the computational cost of the algorithm scales as O(n3), which is the same as the computational cost of the best known algorithms for finding the MWM. We also provide an interesting relation between the dynamics of the max-product algorithm and the auction algorithm, which is a well-known distributed algorithm for solving the MWM problem.},
  keywords={},
  doi={10.1109/TIT.2007.915695},
  ISSN={1557-9654},
  month={March},}
@ARTICLE{4455743,
  author={Goldberger, Jacob and Kfir, Haggai},
  journal={IEEE Transactions on Information Theory}, 
  title={Serial Schedules for Belief-Propagation: Analysis of Convergence Time}, 
  year={2008},
  volume={54},
  number={3},
  pages={1316-1319},
  abstract={Low-density parity-check (LDPC) codes are usually decoded by running an iterative belief-propagation algorithm over the factor graph of the code. In the traditional message-passing schedule, in each iteration all the variable nodes, and subsequently all the factor nodes, pass new messages to their neighbors. Recently several studies show that serial scheduling, in which messages are generated using the latest available information, significantly improves the convergence speed in terms of number of iterations. It was observed experimentally in several studies that the serial schedule converges in exactly half the number of iterations compared to the standard parallel schedule. In this correspondence we provide a theoretical motivation for this observation by proving it for single-path graphs.},
  keywords={},
  doi={10.1109/TIT.2007.915702},
  ISSN={1557-9654},
  month={March},}
@INPROCEEDINGS{4457117,
  author={Joven, Jaume and Font-Bach, Oriol and Castells-Rufas, David and Martinez, Ricardo and Teres, Lluis and Carrabina, Jordi},
  booktitle={16th Euromicro Conference on Parallel, Distributed and Network-Based Processing (PDP 2008)}, 
  title={xENoC - An eXperimental Network-On-Chip Environment for Parallel Distributed Computing on NoC-based MPSoC Architectures}, 
  year={2008},
  volume={},
  number={},
  pages={141-148},
  abstract={This paper describes xENoC, an automatic and component re-use HW-SW environment to build simulatable and synthesizable Network-on-Chip-based MPSoC architectures. xENoC is based on a tool, named NoCWizard, which uses an eXtensible Markup Language (XML) specification, and a set of modularized components and templates to generate many types of NoC instances by using Verilog HDL. This NoC models can be customized in terms of topology, tile location/mapping, RNIs generation, different types of routers, FIFO and packet/flit sizes, by simply modifying the XML specifications. Furthermore, xENoC is also composed of software components, i.e. RNI drivers and a parallel programming model, embedded Message Passing Interface (eMPI), which let us to carry out a complete HW-SW co-design methodology to design distributed-memory NoC-based MPSoCs parallel applications. Through xENoC different distributed-memory NoC-based MPSoCs designs have been created simulated and prototyped in physical platforms (e.g. FPGA boards), and some parallel multiprocessor test traffic applications are running there as system level demonstrators.},
  keywords={},
  doi={10.1109/PDP.2008.24},
  ISSN={2377-5750},
  month={Feb},}
@INPROCEEDINGS{4457129,
  author={Fernandes, Gabriel Falcao Paiva and Silva, Vitor Manuel Mendes da and Gomes, Marco Alexandre Cravo and Sousa, Leonel Augusto Pires Seabra de},
  booktitle={16th Euromicro Conference on Parallel, Distributed and Network-Based Processing (PDP 2008)}, 
  title={Edge Stream Oriented LDPC Decoding}, 
  year={2008},
  volume={},
  number={},
  pages={237-244},
  abstract={Low-Density Parity-Check (LDPC) codes are among the best error correcting codes known and have been adopted by data transmission standards, such as DVB-S2 or WiMax. They are based on binary sparse parity check matrices and usually represented by Tanner graphs. LDPC decoders require very intensive message-passing algorithms, also known as belief propagation. This paper proposes a very compact stream-based data structure to represent such a bipartite Tanner graph, which supports both regular and irregular codes. This compact data structure not only reduces the memory required to represent the graph but also puts it in an appropriate format to gather data into streams. This representation also allows to map the irregular processing behavior of the Sum Product Algorithm (SPA) used in LDPC decoding into the stream-based computing model. Stream programs were developed for LDPC decoding and the results show significant speedups obtained either using general purpose processors, or graphics processing units. The simultaneous decoding of several codewords was performed using the SIMD capabilities of modern stream-based architectures available on recent processing units.},
  keywords={},
  doi={10.1109/PDP.2008.12},
  ISSN={2377-5750},
  month={Feb},}
@ARTICLE{4456784,
  author={Liu, Chih-Hao and Yen, Shau-Wei and Chen, Chih-Lung and Chang, Hsie-Chia and Lee, Chen-Yi and Hsu, Yar-Sun and Jou, Shyh-Jye},
  journal={IEEE Journal of Solid-State Circuits}, 
  title={An LDPC Decoder Chip Based on Self-Routing Network for IEEE 802.16e Applications}, 
  year={2008},
  volume={43},
  number={3},
  pages={684-694},
  abstract={An LDPC decoder chip fully compliant to IEEE 802.16e applications is presented. Since the parity check matrix can be decomposed into sub-matrices which are either a zero-matrix or a cyclic shifted matrix, a phase-overlapping message passing scheme is applied to update messages immediately, leading to enhance decoding throughput. With only one shifter-based permutation structure, a self-routing switch network is proposed to merge 19 different sub-matrix sizes as defined in IEEE 802.16e and enable parallel message to be routed without congestion. Fabricated in the 90 nm 1P9M CMOS process, this chip achieves 105 Mb/s at 20 iterations while decoding the rate-5/6 2304-bit code at 150 MHz operation frequency. To meet the maximum data rate in IEEE 802.16e, this chip operates at 109 MHz frequency and dissipates 186 mW at 1.0 V supply.},
  keywords={},
  doi={10.1109/JSSC.2007.916610},
  ISSN={1558-173X},
  month={March},}
@INPROCEEDINGS{4460838,
  author={Jun Ning and Jinhong Yuan},
  booktitle={2008 Australian Communications Theory Workshop}, 
  title={Design of systematic LDPC codes using density evolution based on tripartite graph}, 
  year={2008},
  volume={},
  number={},
  pages={150-155},
  abstract={In this paper we consider the design of systematic low-density parity-check (LDPC) codes using density evolution. We show that systematic LDPC codes can be well represented by tripartite graphs, where the edges in the code graph are divided into two types, source edges and redundancy edges. Using the tripartite code graph representation, we consider the degree distributions for source edges and redundancy edges separately. In particular, we discuss the necessary conditions for the two types of edges to be viewed as a single type in terms of specifying the LDPC codes properly. Then we discuss the relationship between the conventional bipartite graph representation and the tripartite graph representation. For the design of systematic LDPC codes, we show that the tripartite representation can specify the ensembles that are not available for the bipartite representation. Furthermore, we show that codes optimized by deploying the tripartite representation can achieve better performance with respect to the bipartite representation.},
  keywords={},
  doi={10.1109/AUSCTW.2008.4460838},
  ISSN={},
  month={Jan},}
@INPROCEEDINGS{4470358,
  author={Wang, Xiao-lin and Yin, Zheng-jie},
  booktitle={First International Workshop on Knowledge Discovery and Data Mining (WKDD 2008)}, 
  title={Operating Rules Classification System of Water Supply Reservoir Based on LCS}, 
  year={2008},
  volume={},
  number={},
  pages={100-107},
  abstract={Genetic algorithm-based learning classifier system (LCS) is a massively parallel, message-passing and rule-based machine learning system. But its potential self-adaptive learning capability has not been paid enough attention in reservoir operation research. In this paper, an operating rule classification system based on LCS , which learns through credit assignment (the bucket brigade algorithm) and rule discovery (the genetic algorithm), is established to extract water-supply reservoir operating rules. The proposed system acquires the online identification rate 95% for training samples and offline rate 85% for testing samples in a case study, and further discussions are made about the impacts on the performances or behaviors of the rule classification system from three aspects of obtained rules, training or testing samples and the comparisons between the rule classification system and the artificial neural network (ANN). The results indicate the learning classifier system is feasible and effective for the system to obtain the reservoir supply operating rules.},
  keywords={},
  doi={10.1109/WKDD.2008.146},
  ISSN={},
  month={Jan},}
@ARTICLE{4471932,
  author={Srinivasan, Rajan and Wang, Nuo},
  journal={IEEE Transactions on Communications}, 
  title={Fast performance estimation of block codes}, 
  year={2008},
  volume={56},
  number={3},
  pages={369-377},
  abstract={Importance sampling is used in this paper to address the classical yet important problem of performance estimation of block codes. Simulation distributions that comprise discrete- and continuous-mixture probability densities are motivated and used for this application. These mixtures are employed in concert with the so-called g-method, which is a conditional importance sampling technique that more effectively exploits knowledge of underlying input distributions. For performance estimation, the emphasis is on bit by bit maximum a-posteriori probability decoding, but message passing algorithms for certain codes have also been investigated. Considered here are single parity check codes, multidimensional product codes, and briefly, low-density parity-check codes. Several error rate results are presented for these various codes, together with performances of the simulation techniques.},
  keywords={},
  doi={10.1109/TCOMM.2008.040674},
  ISSN={1558-0857},
  month={March},}
@ARTICLE{4407713,
  author={Khude, Nilesh and Kumar, Anurag and Karnik, Aditya},
  journal={IEEE Transactions on Mobile Computing}, 
  title={Time and Energy Complexity of Distributed Computation of a Class of Functions in Wireless Sensor Networks}, 
  year={2008},
  volume={7},
  number={5},
  pages={617-632},
  abstract={We consider a scenario in which a wireless sensor network is formed by randomly deploying n sensors to measure some spatial function over a field, with the objective of computing a function of the measurements and communicating it to an operator station. We restrict ourselves to the class of type-threshold functions (as defined in the work of Giridhar and Kumar, 2005), of which max, min, and indicator functions are important examples: our discussions are couched in terms of the max function. We view the problem as one of message-passing distributed computation over a geometric random graph. The network is assumed to be synchronous, and the sensors synchronously measure values and then collaborate to compute and deliver the function computed with these values to the operator station. Computation algorithms differ in (1) the communication topology assumed and (2) the messages that the nodes need to exchange in order to carry out the computation. The focus of our paper is to establish (in probability) scaling laws for the time and energy complexity of the distributed function computation over random wireless networks, under the assumption of centralized contention-free scheduling of packet transmissions. First, without any constraint on the computation algorithm, we establish scaling laws for the computation time and energy expenditure for one-time maximum computation. We show that for an optimal algorithm, the computation time and energy expenditure scale, respectively, as Theta(radicn/log n) and Theta(n) asymptotically as the number of sensors n rarr infin. Second, we analyze the performance of three specific computation algorithms that may be used in specific practical situations, namely, the tree algorithm, multihop transmission, and the Ripple algorithm (a type of gossip algorithm), and obtain scaling laws for the computation time and energy expenditure as n rarr infin. In particular, we show that the computation time for these algorithms scales as Theta(radicn/log n), Theta(n), and Theta(radicn log n), respectively, whereas the energy expended scales as , Theta(n), Theta(radicn/log n), and Theta(radicn log n), respectively. Finally, simulation results are provided to show that our analysis indeed captures the correct scaling. The simulations also yield estimates of the constant multipliers in the scaling laws. Our analyses throughout assume a centralized optimal scheduler, and hence, our results can be viewed as providing bounds for the performance with practical distributed schedulers.},
  keywords={},
  doi={10.1109/TMC.2007.70785},
  ISSN={1558-0660},
  month={May},}
@INPROCEEDINGS{4484701,
  author={Gailliard, Gregory and Balp, Hugues and Sarlotte, Michel and Verdier, Francois},
  booktitle={2008 Design, Automation and Test in Europe}, 
  title={Mapping Semantics of CORBA IDL and GIOP to Open Core Protocol for Portability and Interoperability of SDR Waveform Components}, 
  year={2008},
  volume={},
  number={},
  pages={330-335},
  abstract={Patterns, middlewares and frameworks have been used for decades in software architecture to address the main problems encountered today by the MPSoC and NoC communities: heterogeneity of languages, programming models, simulation/execution environments, interaction semantics and communication protocols. A complete semantics mapping of CORBA interface definition language (IDL) and general inter-ORB protocol (GIOP) on the open core protocol (OCP) has been investigated for hardware components. This mapping is generic, highly configurable and illustrated through our target application: software defined radio.},
  keywords={},
  doi={10.1109/DATE.2008.4484701},
  ISSN={1558-1101},
  month={March},}
@INPROCEEDINGS{4484845,
  author={Saha, Sankalita and Schlessman, Jason and Puthenpurayil, Sebastian and Bhattacharyya, Shuvra S. and Wolf, Wayne},
  booktitle={2008 Design, Automation and Test in Europe}, 
  title={An Optimized Message Passing Framework for Parallel Implementation of Signal Processing Applications}, 
  year={2008},
  volume={},
  number={},
  pages={1220-1225},
  abstract={Novel reconfigurable computing platforms enable efficient realizations of complex signal processing applications by allowing exploitation of parallelization resulting in high throughput in a cost-efficient way. However, the design of such systems poses various challenges due to the complexities posed by the applications themselves as well as the heterogeneous nature of the targeted platforms. One of the most significant challenges is communication between the various computing elements for parallel implementation. In this paper, we present a communication interface, called the signal passing interface (SPI), that attempts to overcome this challenge by integrating relevant properties of two different yet important paradigms in this context - dataflow and the message passing interface (MPI). SPI is targeted towards signal processing applications and, due to its careful specialization, more performance-efficient for their embedded implementation. It is also more easier and intuitive to use. Earlier, a preliminary version of SPI was presented [12] which was restricted to static dataflow behavior. Here, we present a more complete version of SPI with new features to address both static and dynamic dataflow behavior, and to provide new optimization techniques. We develop a hardware description language (HDL) realization of the SPI library, and demonstrate its functionality on the Xilinx Virtex-4 FPGA. Details of the HDL-based SPI library along with experiments with two signal processing applications on the FPGA are also presented.},
  keywords={},
  doi={10.1109/DATE.2008.4484845},
  ISSN={1558-1101},
  month={March},}
@INPROCEEDINGS{4484886,
  author={Edwards, Stephen A. and Vasudevan, Nalini and Tardieu, Olivier},
  booktitle={2008 Design, Automation and Test in Europe}, 
  title={Programming Shared Memory Multiprocessors with Deterministic Message-Passing Concurrency: Compiling SHIM to Pthreads}, 
  year={2008},
  volume={},
  number={},
  pages={1498-1503},
  abstract={Multicore shared-memory architectures are becoming prevalent and bring many programming challenges. Among the biggest are data races: accesses to shared resources that make a program's behavior depend on scheduling decisions beyond its control. To eliminate such races, the SHIM concurrent programming language adopts deterministic message passing as it sole communication mechanism. We demonstrate such language restrictions are practical by presenting a SHIM to C-plus-Pthreads compiler that can produce efficient code for shared-memory multiprocessors. We present a parallel JPEG decoder and FFT exhibiting 3.05 and 3.3times speedups on a four-core processor.},
  keywords={},
  doi={10.1109/DATE.2008.4484886},
  ISSN={1558-1101},
  month={March},}
@INPROCEEDINGS{4489079,
  author={Nguyen, T. D. and Yang, L. L. and Ng, S. X. and Hanzo, L.},
  booktitle={2008 IEEE Wireless Communications and Networking Conference}, 
  title={An Optimal Degree Distribution Design and a Conditional Random Integer Generator for the Systematic Luby Transform Coded Wireless Internet}, 
  year={2008},
  volume={},
  number={},
  pages={243-248},
  abstract={Recently, the authors of this paper proposed systematic Luby transform (SLT) codes and their soft decoding using the classic loglikelihood message passing algorithm for transmission over hostile Wireless Internet channels, where the transmitted data is affected by both packet loss events and random Gaussian noise. This scheme is further improved here with the aid of a new degree distribution and a novel random integer generator, which are termed as the truncated degree distribution and the conditional random integer generator. The SLT code using the new design is capable of achieving BER les 10-5 at low Eb/N0 values. For example, the SLT(1200,3600) code attains BER < lCT5 in excess of an Eb/No value of 1.5 dB for transmission over the AWGN channel and above 3.5 dB over the uncorrelated Rayleigh channel if additionally a packet erasure probability Pe of 0.1 is inflicted, an Eb/No value above 2 dB is required for transmission over the AWGN channel and in excess of 4 dB over the uncorrelated Rayleigh channel, when using a maximum of Iter = 20 iterations and quadrature phase- shift keying.},
  keywords={},
  doi={10.1109/WCNC.2008.48},
  ISSN={1558-2612},
  month={March},}
@ARTICLE{4479869,
  author={Dai, Yongmei and Yan, Zhiyuan and Chen, Ning},
  journal={IEEE Transactions on Very Large Scale Integration (VLSI) Systems}, 
  title={Optimal Overlapped Message Passing Decoding of Quasi-Cyclic LDPC Codes}, 
  year={2008},
  volume={16},
  number={5},
  pages={565-578},
  abstract={Efficient hardware implementation of low-density parity-check (LDPC) codes is of great interest since LDPC codes are being considered for a wide range of applications. Recently, overlapped message passing (OMP) decoding has been proposed to improve the throughput and hardware utilization efficiency (HUE) of decoder architectures for LDPC codes. In this paper, we first study the scheduling for the OMP decoding of LDPC codes, and show that maximizing the throughput gain amounts to minimizing the intra- and inter-iteration waiting times. We then focus on the OMP decoding of quasi-cyclic (QC) LDPC codes. We propose a partly parallel OMP decoder architecture and implement it using FPGA. For any QC LDPC code, our OMP decoder achieves the maximum throughput gain and HUE due to overlapping, hence has higher throughput and HUE than previously proposed OMP decoders while maintaining the same hardware requirements. We also show that the maximum throughput gain and HUE achieved by our OMP decoder are ultimately determined by the given code. Thus, we propose a coset-based construction method, which results in QC LDPC codes that allow our optimal OMP decoder to achieve higher throughput and HUE.},
  keywords={},
  doi={10.1109/TVLSI.2008.917540},
  ISSN={1557-9999},
  month={May},}
@INPROCEEDINGS{4492877,
  author={Mousavi, Abdolmajid and Far, Behrouz H.},
  booktitle={13th IEEE International Conference on Engineering of Complex Computer Systems (iceccs 2008)}, 
  title={Revisiting Safe Realizability of Message Sequence Charts Specifications}, 
  year={2008},
  volume={},
  number={},
  pages={37-45},
  abstract={Safe realizability of Message Sequence Charts (MSCs) specifications is a measure of whether or not there exists a distributed implementation of the specification such that it is deadlock free and shows exactly the behaviours specified in the specification. There are also some works that given a specification, can answer whether it is safely realizable or not. However, while these works are restricted by certain assumptions such as synchronous message passing in the system, they also cannot answer why given two specifications, one is safely realizable and the other is not. In this paper, we present a property of MSC specifications that explains implementation problems for them. Using this result, we show how we can effectively correct a specification to avoid implementation problems such as deadlocks and implied scenarios.},
  keywords={},
  doi={10.1109/ICECCS.2008.9},
  ISSN={},
  month={March},}

@INPROCEEDINGS{4493654,
  author={Bouabache, Fatiha and Herault, Thomas and Fedak, Gilles and Cappello, Franck},
  booktitle={2008 IEEE/ACS International Conference on Computer Systems and Applications}, 
  title={Hierarchical replication techniques to ensure checkpoint storage reliability in grid environment}, 
  year={2008},
  volume={},
  number={},
  pages={939-940},
  abstract={High performance computing has an important role in scientific and engineering researches. As the size of high performance systems increases continuously, the average time between failures becomes increasingly small. So fault tolerance becomes a critical property for parallel applications running on these systems. MPI (message passing interface) paradigm is actually the most used to write parallel applications. However, in traditional implementations, when a failure occurs, the whole distributed application is shutdown and restarted. To avoid this, many solutions have been proposed, but the most used is rollback recovery. Rollback recovery is based upon the concept of a checkpoint. A checkpoint describes the state of one or more components of the system at a given time of its execution.},
  keywords={},
  doi={10.1109/AICCSA.2008.4493654},
  ISSN={2161-5330},
  month={March},}
@INPROCEEDINGS{4493571,
  author={Subba Rao, Ch. D. V. and Naidu, M. M.},
  booktitle={2008 IEEE/ACS International Conference on Computer Systems and Applications}, 
  title={A new, efficient coordinated checkpointing protocol combined with selective sender-based message logging}, 
  year={2008},
  volume={},
  number={},
  pages={444-447},
  abstract={Checkpointing and message logging are the popular and general-purpose tools for providing fault-tolerance in distributed systems. The most of the Coordinated checkpointing algorithms available in the literature have not addressed about treatment of the lost messages and these algorithms suffer from high output commit latency. To overcome the above limitations, we propose a new coordinated checkpointing protocol combined with selective sender-based message logging. The protocol is free from the problem of lost messages. The term ‘selective’ implies that messages are logged only within a specified interval known as active interval, thereby reducing message logging overhead. All processes take checkpoints at the end of their respective active intervals forming a consistent global state. Outside the active interval there is no checkpointing of process state. This protocol minimizes different overheads i.e. checkpointing overhead, message logging overhead, recovery overhead and blocking overhead. Unlike blocking coordinated checkpointing, the disk contentions are less in the proposed protocol.},
  keywords={},
  doi={10.1109/AICCSA.2008.4493571},
  ISSN={2161-5330},
  month={March},}
@INPROCEEDINGS{4509828,
  author={Castelli, S. and Costa, P. and Picco, G. P.},
  booktitle={IEEE INFOCOM 2008 - The 27th Conference on Computer Communications}, 
  title={HyperCBR: Large-Scale Content-Based Routing in a Multidimensional Space}, 
  year={2008},
  volume={},
  number={},
  pages={1714-1722},
  abstract={Content-based routing (CBR) is becoming increasingly popular as a building block for distributed applications. CBR differs from classical routing paradigms as messages are routed based on their content rather than their destination address, which fosters decoupling and flexibility in the application's distributed architecture. However, most available systems realize CBR by relying on a tree-shaped overlay network and adopt a routing strategy based on broadcasting subscription requests, thus hampering applicability in very large-scale networks. We observe that a fundamental underpinning of any CBR protocol is for messages and subscriptions to "meet" at some points in the network. In the approach we propose here, called HyperCBR1, we enforce this topological property in a multidimensional space, by routing messages and subscriptions on different, albeit intersecting, partitions. We derive an analytical model of HyperCBR, validated through simulation, and use it to evaluate our approach in two relevant CBR contexts - content-based searches in peer-to-peer networks, and content- based publish-subscribe. The results show that our protocol achieves efficient CBR even in very large scale settings (e.g., millions of nodes) while at the same time opening up intriguing opportunities for deployment-time tuning based on the expected traffic profiles. The analytical evaluation is complemented by simulation results relying on a CAN-based implementation, showing that HyperCBR generates a small forwarding and matching load, and that it is able to tolerate high churn with low overhead.},
  keywords={},
  doi={10.1109/INFOCOM.2008.233},
  ISSN={0743-166X},
  month={April},}
@INPROCEEDINGS{4517891,
  author={Rovini, Massimo and Principe, Fabio and Fanucci, Luca and Luise, Marco},
  booktitle={2008 IEEE International Conference on Acoustics, Speech and Signal Processing}, 
  title={Implementation of message-passing algorithms for the acquisition of spreading codes}, 
  year={2008},
  volume={},
  number={},
  pages={1441-1444},
  abstract={A new technique to acquire pseudo-noise (PN) sequences has been recently proposed in [1] and [2]. It is based on the paradigm of iterative message passing (iMP) to be run on loopy graph. This technique approximates the maximum-likelihood (ML) estimator, providing a sub-optimal algorithm that searches all possible code phases in parallel, at low complexity and fast acquisition time. This work is addressed to the design of the architecture of an iMP detector, following the implementation methodologies typical of standard low-density parity-check (LDPC) decoders, and demonstrates its benefits in terms of acquisition time and complexity, compared with standard techniques.},
  keywords={},
  doi={10.1109/ICASSP.2008.4517891},
  ISSN={2379-190X},
  month={March},}
@INPROCEEDINGS{4518325,
  author={Cheng-Zhou Zhan and Xin-Yu Shih and An-Yeu Wu},
  booktitle={2008 IEEE International Conference on Acoustics, Speech and Signal Processing}, 
  title={High-performance scheduling algorithm for partially parallel LDPC decoder}, 
  year={2008},
  volume={},
  number={},
  pages={3177-3180},
  abstract={In this paper, we propose a new scheduling algorithm for the overlapped message passing decoding, which can be applied to general low-density parity check (LDPC) codes. The partially parallel LDPC architecture is commonly used for reducing the area cost of the processing units. The dependency of two kinds of processing units, check node unit (CNU) and bit node unit (BNU), should be considered to enhance the hardware utilization efficiency (HUE). Based on the properties of the parity check matrix of LDPC codes, the updating calculation of the CNU and BNU can be overlapped to reduce the decoding latency by enhancing the HUE with the matrix scheduling algorithm. By applying our proposed LDPC scheduling algorithm to a (1944, 972)-irregular LDPC code, we can get about 60% throughput gain in average without any performance degradation.},
  keywords={},
  doi={10.1109/ICASSP.2008.4518325},
  ISSN={2379-190X},
  month={March},}
@ARTICLE{4526909,
  author={Kanai, Yasushi and Saiki, Masahiko and Hirasawa, Kazunori and Tsukamomo, Toshio and Yoshida, Kazuetsu},
  journal={IEEE Transactions on Magnetics}, 
  title={Landau–Lifshitz–Gilbert Micromagnetic Analysis of Single-Pole-Type Write Head for Perpendicular Magnetic Recording Using Full-FFT Program on PC Cluster System}, 
  year={2008},
  volume={44},
  number={6},
  pages={1602-1605},
  abstract={A Landau-Lifshitz-Gilbert (LLG) micromagnetic analysis using a parallelized program on a PC cluster is investigated. In the analysis, the whole magnetic material is treated micromagnetically using the LLG equation. The fast Fourier transform (FFT) algorithm is incorporated in the head region in addition to the medium region to derive the demagnetization field and the program is parallelized using the message passing interface (MPI). The PC cluster system with 8 CPU has achieved a calculation speed 4800 times faster than our original program on a single 64-bit processor system. Quasi-static field distributions for a single-pole type (SPT) are derived and the accuracy is validated by comparison with the finite-element method (FEM). Finally, dynamic responses are derived for various head structures and materials.},
  keywords={},
  doi={10.1109/TMAG.2007.916254},
  ISSN={1941-0069},
  month={June},}
@INPROCEEDINGS{4530466,
  author={Yang, Wenjing and Yang, Canqun},
  booktitle={2008 Second Asia International Conference on Modelling & Simulation (AMS)}, 
  title={Exploiting Energy Saving Opportunity of Barrier Operation in MPI Programs}, 
  year={2008},
  volume={},
  number={},
  pages={144-149},
  abstract={In high performance parallel computing, energy consumption has become a more and more important problem. Under the support of the voltage scaling- available processors, reducing CPU voltage/frequency in the non-critical path is an efficient energy reduction method. This paper exploited the energy saving opportunities in MPI_Barrier operation. Through testing NPB3.2-MPI programs on 256-process cluster system, we found that the busy time of each process has the big difference each other when the cluster is connected by a 100 Mbps network. We proposed two low-power methods: one is shut-down based MPI_Barrier (SDMB) and the other is dynamic voltage/frequency scaling based MPI_Barrier (DVSMB). Experimental results show that average 4.95% energy saving is obtained through SDMB and average 12.28% energy saving is obtained through DVSMB. SDMB avoids the performance loss through pre-activation strategy and the performance loss of DVSMB is less than 1%.},
  keywords={},
  doi={10.1109/AMS.2008.80},
  ISSN={2376-1172},
  month={May},}
@INPROCEEDINGS{4534137,
  author={Zhang, H. and Ganguly, S. and Bhatnagar, S. and Izmailov, R. and Sharma, A.},
  booktitle={2008 IEEE International Conference on Communications}, 
  title={Optimal Load Balancing in Publish/Subscribe Broker Networks Using Active Workload Management}, 
  year={2008},
  volume={},
  number={},
  pages={5892-5896},
  abstract={Load balancing in publish/subscribe (pub/sub) broker networks is challenging as the workload is multi-dimensional and content-dependent. In this paper we present the framework design of a middleware, called Shuffle, to achieve optimal load balancing in a pub/sub broker network. Shuffle features a suite of active workload management schemes within a single overlay topology on message parsing, matching, delivery, and forwarding, the four types of workload in a publish/subscribe service affected by two inputs-streaming events and stored subscriptions. Shuffle leverages its traffic randomization scheme and Chord, a DHT substrate, to build overlay trees for active workload aggregation and distribution, and we show the optimality property of the load balancing scheme upon any input traffic distribution on individual Shuffle aggregation trees. We also show the NP-hardness of the workload management problem when it has to be done among multiple correlated aggregation trees, and present a heuristic accordingly. Through extensive simulations we validated the design of Shuffle upon dynamic and heavy workload.},
  keywords={},
  doi={10.1109/ICC.2008.1101},
  ISSN={1938-1883},
  month={May},}
@INPROCEEDINGS{4534252,
  author={Bouabache, Fatiha and Herault, Thomas and Fedak, Gilles and Cappello, Franck},
  booktitle={2008 Eighth IEEE International Symposium on Cluster Computing and the Grid (CCGRID)}, 
  title={Hierarchical Replication Techniques to Ensure Checkpoint Storage Reliability in Grid Environment}, 
  year={2008},
  volume={},
  number={},
  pages={475-483},
  abstract={As high performance platforms (Clusters, Grids, etc.) continue to grow in size, the average time between failures decreases to a critical level. An efficient and reliable fault tolerance protocol plays a key role in high performance computing. Rollback recovery is the most common fault tolerance technique used in high performance computing and especially in MPI applications. This technique relies on the reliability of the checkpoint storage. Most of the rollback recovery protocols assume that the checkpoint servers machines are reliable. However, in a grid environment any unit can fail at any moment, including components used to connect different administrative domains. Such failures lead to the loss of a whole set of machines, including the more reliable machines used to store the checkpoints in this administrative domain. Thus it is not safe to rely on the high MTBF (mean time between failures) of specific machines to store the checkpoint images. This paper introduces a new coordinated checkpoint protocol, which tolerates checkpoint server failures and clusters failures, and ensures a checkpoint storage reliability in a grid environment. To provide this reliability the protocol is based on a replication process. We propose new hierarchical replication strategies, with two different degrees of hierarchy, adapted to the topology of cluster of clusters. Our solution exploits the locality of checkpoint images in order to minimize inter-cluster communication. We evaluate the effectiveness of our two hierarchical replication strategies through simulations against several criteria such as topology and scalability .},
  keywords={},
  doi={10.1109/CCGRID.2008.95},
  ISSN={},
  month={May},}
@INPROCEEDINGS{4534262,
  author={Díaz, Daniel and Pardo, Xoán C. and Martín, María J. and González, Patricia},
  booktitle={2008 Eighth IEEE International Symposium on Cluster Computing and the Grid (CCGRID)}, 
  title={Application-Level Fault-Tolerance Solutions for Grid Computing}, 
  year={2008},
  volume={},
  number={},
  pages={554-559},
  abstract={One of the key functionalities provided by Grid systems is the remote execution of applications. This paper introduces a research proposal on fault-tolerance mechanisms for the execution of sequential and message-passing parallel applications on the Grid. A service-based architecture called CPPC-G is proposed. The CPPC (Controller/Precompiler for Portable Checkpointing) framework is used to insert checkpointing instrumentation into the application code. CPPC-G services will be in charge of the submission and monitoring of the application execution, management of checkpoint files generated by CPPC-enabled applications, and detection and automatic restart of failed executions. The development of the CPPC-G architecture will involve research in different areas such as storage and management of data files (checkpoint files); automatic selection of suitable computing resources; reliable detection of execution failures and robustness issues to make the architecture fault-tolerant itself.},
  keywords={},
  doi={10.1109/CCGRID.2008.38},
  ISSN={},
  month={May},}
@INPROCEEDINGS{4536337,
  author={Amedro, Brian and Caromel, Denis and Huet, Fabrice and Bodnartchouk, Vladimir},
  booktitle={2008 IEEE International Symposium on Parallel and Distributed Processing}, 
  title={Java ProActive vs. Fortran MPI: Looking at the future of parallel Java}, 
  year={2008},
  volume={},
  number={},
  pages={1-7},
  abstract={About ten years after the Java Grande effort, this paper aims at providing a snapshot of the comparison of Fortran MPI, with Java performance for parallel computing, using the ProActive library. We first analyze some performance details about ProActive behaviors, and then compare its global performance from the MPI library. This comparative is based on the five kernels of the NAS parallel benchmarks. From those experiments we identify benchmarks where parallel Java performs as well as Fortran MPI, and lack of performance on others, together with clues for improvement.},
  keywords={},
  doi={10.1109/IPDPS.2008.4536337},
  ISSN={1530-2075},
  month={April},}
@INPROCEEDINGS{4536478,
  author={Wadsworth, Daniel M. and Chen, Zizhong},
  booktitle={2008 IEEE International Symposium on Parallel and Distributed Processing}, 
  title={Performance of MPI broadcast algorithms}, 
  year={2008},
  volume={},
  number={},
  pages={1-7},
  abstract={As cluster computing has gotten cheaper and more powerful, ever larger clusters are being built and ever larger problems are being tackled. Many, if not most, of these problems require the broadcast of data not only at the beginning of the computation but also as it progresses. Given the comparative slowness of communication as opposed to computation, any improvement in communication time can have a significant impact on the time required to complete a computation. This paper looks at the broadcast function of MPI and explores some alternative implementations for the common cluster architecture in which some number of computing nodes are connected via an Ethernet switch. It then compares these implementations to the built-in implementation of broadcast in MPICH2 and suggests a new implementation.},
  keywords={},
  doi={10.1109/IPDPS.2008.4536478},
  ISSN={1530-2075},
  month={April},}
@INPROCEEDINGS{4536494,
  author={Hoefler, Torsten and Schneider, Timo and Lumsdaine, Andrew},
  booktitle={2008 IEEE International Symposium on Parallel and Distributed Processing}, 
  title={Accurately measuring collective operations at massive scale}, 
  year={2008},
  volume={},
  number={},
  pages={1-8},
  abstract={Accurate, reproducible and comparable measurement of collective operations is a complicated task. Although different measurement schemes are implemented in well- known benchmarks, many of these schemes introduce different systematic errors in their measurements. We characterize these errors and select a window-based approach as the most accurate method. However, this approach complicates measurements significantly and introduces a clock synchronization as a new source of systematic errors. We analyze approaches to avoid or correct those errors and develop a scalable synchronization scheme to conduct benchmarks on massively parallel systems. Our results are compared to the window-based scheme implemented in the SKaMPI benchmarks and show a reduction of the synchronization overhead by a factor of 16 on 128 processes.},
  keywords={},
  doi={10.1109/IPDPS.2008.4536494},
  ISSN={1530-2075},
  month={April},}
@INPROCEEDINGS{4536243,
  author={Mudalige, Gihan R. and Vernon, Mary K. and Jarvis, Stephen A.},
  booktitle={2008 IEEE International Symposium on Parallel and Distributed Processing}, 
  title={A plug-and-play model for evaluating wavefront computations on parallel architectures}, 
  year={2008},
  volume={},
  number={},
  pages={1-14},
  abstract={This paper develops a plug-and-play reusable LogGP model that can be used to predict the runtime and scaling behavior of different MPI-based pipelined wavefront applications running on modern parallel platforms with multi-core nodes. A key new feature of the model is that it requires only a few simple input parameters to project performance for wavefront codes with different structure to the sweeps in each iteration as well as different behavior during each wavefront computation and/or between iterations. We apply the model to three key benchmark applications that are used in high performance computing procurement, illustrating that the model parameters yield insight into the key differences among the codes. We also develop new, simple and highly accurate models of MPI send, receive, and group communication primitives on the dual-core Cray XT system. We validate the reusable model applied to each benchmark on up to 8192 processors on the XT3/XT4. Results show excellent accuracy for all high performance application and platform configurations that we were able to measure. Finally we use the model to assess application and hardware configurations, develop new metrics for procurement and configuration, identify bottlenecks, and assess new application design modifications that, to our knowledge, have not previously been explored.},
  keywords={},
  doi={10.1109/IPDPS.2008.4536243},
  ISSN={1530-2075},
  month={April},}
@INPROCEEDINGS{4536138,
  author={Hoefler, Torsten and Lumsdaine, Andrew},
  booktitle={2008 IEEE International Symposium on Parallel and Distributed Processing}, 
  title={Optimizing non-blocking collective operations for infiniband}, 
  year={2008},
  volume={},
  number={},
  pages={1-8},
  abstract={Non-blocking collective operations have recently been shown to be a promising complementary approach for overlapping communication and computation in parallel applications. However, in order to maximize the performance and usability of these operations it is important that they progress concurrently with the application without introducing CPU overhead and without requiring explicit user intervention. While studying non- blocking collective operations in the context of our portable library (libNBC), we found that most MPI implementations do not sufficiently support overlap over the InfiniBand network. To address this issue, we developed a low-level communication layer for libNBC based on the Open Fabrics InfiniBand verbs API. With this layer we are able to achieve high degrees of overlap without the need to explicitly progress the communication operations. We show that the communication overhead of parallel application kernels can be reduced up to 92% while not requiring user intervention to make progress.},
  keywords={},
  doi={10.1109/IPDPS.2008.4536138},
  ISSN={1530-2075},
  month={April},}
@INPROCEEDINGS{4536174,
  author={Saeed, Fahad and Khokhar, Ashfaq},
  booktitle={2008 IEEE International Symposium on Parallel and Distributed Processing}, 
  title={Sample-Align-D: A high performance Multiple Sequence Alignment system using phylogenetic sampling and domain decomposition}, 
  year={2008},
  volume={},
  number={},
  pages={1-9},
  abstract={Multiple sequence alignment (MSA) is one of the most computationally intensive tasks in Computational Biology. Existing best known solutions for multiple sequence alignment take several hours (in some cases days) of computation time to align, for example, 2000 homologous sequences of average length 300. Inspired by the Sample Sort approach in parallel processing, in this paper we propose a highly scalable multiprocessor solution for the MSA problem in phylogenetically diverse sequences. Our method employs an intelligent scheme to partition the set of sequences into smaller subsets using k- mer count based similarity index, referred to as k-mer rank. Each subset is then independently aligned in parallel using any sequential approach. Further fine tuning of the local alignments is achieved using constraints derived from a global ancestor of the entire set. The proposed sample-align-D algorithm has been implemented on a cluster of workstations using MPI message passing library. The accuracy of the proposed solution has been tested on standard benchmarks such as PREFAB. The accuracy of the alignment produced by our methods is comparable to that of well known sequential MSA techniques. We were able to align 2000 randomly selected sequences from the Methanosarcina acetivorans genome in less than 10 minutes using sample-align-D on a 16 node cluster, compared to over 23 hours on sequential MUSCLE system running on a single cluster node.},
  keywords={},
  doi={10.1109/IPDPS.2008.4536174},
  ISSN={1530-2075},
  month={April},}
@INPROCEEDINGS{4536302,
  author={Ho, Justin C. Y. and Cho-Li Wang and Lau, Francis C. M.},
  booktitle={2008 IEEE International Symposium on Parallel and Distributed Processing}, 
  title={Scalable group-based checkpoint/restart for large-scale message-passing systems}, 
  year={2008},
  volume={},
  number={},
  pages={1-12},
  abstract={The ever increasing number of processors used in parallel computers is making fault tolerance support in large-scale parallel systems more and more important. We discuss the inadequacies of existing system-level checkpointing solutions for message-passing applications as the system scales up. We analyze the coordination cost and blocking behavior of two current MPI implementations with checkpointing support. A group-based solution combining coordinated checkpointing and message logging is then proposed. Experiment results demonstrate its better performance and scalability than LAM/MPI and MPICH-VCL. To assist group formation, a method to analyze the communication behaviors of the application is proposed.},
  keywords={},
  doi={10.1109/IPDPS.2008.4536302},
  ISSN={1530-2075},
  month={April},}
@INPROCEEDINGS{4536192,
  author={Patel, Imran and Gilbert, John R.},
  booktitle={2008 IEEE International Symposium on Parallel and Distributed Processing}, 
  title={An empirical study of the performance and productivity of two parallel programming models}, 
  year={2008},
  volume={},
  number={},
  pages={1-7},
  abstract={The choice of parallel programming models and languages is a major factor in program performance and programmer productivity in HPC. However, evaluation of their relative merits is usually done based on conventional wisdom and subjective beliefs. We present a quantitative approach to evaluate such hypotheses statistically and validate them with empirical data. We apply this approach to compare two languages representing the message passing (MPI) and shared memory programming (UPC) paradigms. We formulate hypothesis tests for comparing the performance and productivity of these two models and evaluate them with data from observational studies of HPC programmers. We present and analyze several results, some of which are statistically significant, that demonstrate the promise of empirical evaluation in HPC development.},
  keywords={},
  doi={10.1109/IPDPS.2008.4536192},
  ISSN={1530-2075},
  month={April},}
@INPROCEEDINGS{4536307,
  author={Tansey, Wesley and Tilevich, Eli},
  booktitle={2008 IEEE International Symposium on Parallel and Distributed Processing}, 
  title={Efficient automated marshaling of C++ data structures for MPI applications}, 
  year={2008},
  volume={},
  number={},
  pages={1-12},
  abstract={We present an automated approach for marshaling C++ data structures in high performance computing (HPC) applications. Our approach utilizes a graphical editor through which the user can express a subset of an object's state to be marshaled and sent across a network. Our tool, MPI serializer, then automatically generates efficient marshaling and unmarshaling code for use with the message passing interface (MPI), the predominant communication middleware for HPC systems. Our approach provides a more comprehensive level of support for C++ language features than the existing state of the art, and does so in full compliance with the C++ language standard. Specifically, we can marshal effectively and efficiently non-trivial language constructs such as polymorphic pointers, dynamically allocated arrays, non-public member fields, inherited members, and STL container classes. Additionally, our marshaling approach is also applicable to third party libraries, as it does not require any modifications to the existing C++ source code. We validate our approach through two case studies of applying our tool to automatically generate the marshaling functionality of two realistic HPC applications. The case studies demonstrate that the automatically generated code matches the performance of typical hand-written implementations and surpasses current state-of-the-art C++ marshaling libraries, in some cases by more than an order of magnitude. The results of our case studies indicate that our approach can be beneficial for both the initial construction of HPC applications as well as for the refactoring of sequential applications for parallel execution.},
  keywords={},
  doi={10.1109/IPDPS.2008.4536307},
  ISSN={1530-2075},
  month={April},}
@INPROCEEDINGS{4536707,
  author={Chen, Zhengang and Bates, Stephen and Krzymien, Witold},
  booktitle={2008 4th IEEE International Conference on Circuits and Systems for Communications}, 
  title={High Throughput Parallel Decoder Design for LDPC Convolutional Codes}, 
  year={2008},
  volume={},
  number={},
  pages={35-39},
  abstract={LDPC convolutional code (LDPC-CC) decoders are composed of processors, making them parallel in the iteration dimension. However, for time-varying LDPC-CCs, each individual processor is serial in the node dimension, hindering the throughput increase for such decoders. We propose a joint code-decoder design, which generates architecture-aware LDPC- CCs of good performance, as well as an LDPC-CC decoder architecture parallel in the node dimension. Without increase in the memory bits used, the parallel decoder can achieve throughputs at the level of Gb/s with small parallelization factors.},
  keywords={},
  doi={10.1109/ICCSC.2008.15},
  ISSN={},
  month={May},}
@INPROCEEDINGS{4537269,
  author={Abrardo, Andrea and Ferrari, Gianluigi and Martalo, Marco},
  booktitle={2008 3rd International Symposium on Communications, Control and Signal Processing}, 
  title={Non-cooperative wireless orthogonal multiple access schemes with and without relaying}, 
  year={2008},
  volume={},
  number={},
  pages={455-460},
  abstract={In this paper, we study the performance of non-cooperative wireless multiple access systems with noisy separated channels, where correlated sources communicate to an access point (AP) directly or, possibly, by using a relay. In particular: if no relay is used, then the sources may make use of channel coding; if the relay is used, then the sources transmit uncoded information and the relay may add redundancy (i.e., parity bits). In all cases (coded and uncoded, with and without relay), scenarios with block-faded links are considered. Our goal is to explore the potential benefits which can be obtained when source correlation is exploited at the AP. In uncoded communication scenarios (without relay), we quantify the improvement, with respect to distributed source coding (DSC) schemes, of the proposed schemes. In coded scenarios, we consider the use of low-density parity-check (LDPC) codes, and compare different systems (with and without relay) by keeping fixed the overall coding rate.},
  keywords={},
  doi={10.1109/ISCCSP.2008.4537269},
  ISSN={},
  month={March},}
@ARTICLE{4539703,
  author={Liu, Lingzhi and Shi, C.-J. Richard},
  journal={IEEE Transactions on Circuits and Systems I: Regular Papers}, 
  title={Sliced Message Passing: High Throughput Overlapped Decoding of High-Rate Low-Density Parity-Check Codes}, 
  year={2008},
  volume={55},
  number={11},
  pages={3697-3710},
  abstract={The efficient implementation of high-rate high-throughout low-density parity-check (LDPC) code decoding presents challenges to both fully parallel decoding and memory-sharing partially parallel decoding schemes. In this paper, a new decoding scheme, sliced message passing (SMP), is introduced. The key idea is to slice the total set of N variable-to-check messages into equal-sized p chunks, then to perform check-node computation sequentially chunk by chunk. This new decoding scheme can break the sequential tie between the check- and variable-node update stages and thus greatly improve the throughput. The hardware architectures of SMP decoding are introduced. Each check-node processing unit of the proposed register-based architecture has only c/p inputs instead of c inputs. By remapping the variable-node and check-node processing unit decoding blocks, the optimized SMP decoding units can reduce the overall hardware cost, shorten the critical-path delay, and improve the hardware-usage efficiency. An optimized SMP decoder has been further implemented for a 2048-bit (6, 32) LDPC decoder of the emerging IEEE 10 GBase-T standard in an IBM CMOS 90-nm process. Implementation results from synthesis and post layout simulation have shown the effectiveness of the proposed SMP scheme.},
  keywords={},
  doi={10.1109/TCSI.2008.926995},
  ISSN={1558-0806},
  month={Dec},}
@ARTICLE{4493448,
  author={Chernyavskiy, Igor A. and Cooke, Simon J. and Vlasov, Alexander N. and Antonsen, Thomas M. and Abe, David K. and Levush, Baruch and Nguyen, Khanh T.},
  journal={IEEE Transactions on Plasma Science}, 
  title={Parallel Simulation of Independent Beam-Tunnels in Multiple-Beam Klystrons Using TESLA}, 
  year={2008},
  volume={36},
  number={3},
  pages={670-681},
  abstract={We present an extension of the klystron simulation code TESLA to model multiple-beam klystrons (MBKs) in which interaction parameters may vary significantly from beam-tunnel to beam-tunnel. In earlier work, the single-beam code was applied to model the MBK by assuming that all electron beams and beam-tunnels were identical and all electron beams interacted identically with the fields of the resonant cavities, using averaged values of R/Q to represent interaction with each resonant cavity. To overcome the limitations of this approach and to take into account the effects from nonidentical beams and/or beam-tunnels, we have modified the code to use a parallel algorithm for multiple beams. The implementation of the parallel version of TESLA is based on the latest Fortran-95 version of the serial code and uses the message-passing interface library for communication. For testing and verification purposes, the new version of the code is applied to simulate an experimental four-cavity, eight-beam klystron amplifier, which was designed and successfully tested last year at the Naval Research Laboratory. The results of modeling using the new parallel TESLA and their comparison with experimental data are discussed in detail.},
  keywords={},
  doi={10.1109/TPS.2008.920270},
  ISSN={1939-9375},
  month={June},}
@INPROCEEDINGS{4542452,
  author={Ji, Wen and Li, Xing and Ikenaga, Takeshi and Goto, Satoshi},
  booktitle={2008 IEEE International Symposium on VLSI Design, Automation and Test (VLSI-DAT)}, 
  title={High throughput partially-parallel irregular LDPC decoder based on delta-value message-passing schedule}, 
  year={2008},
  volume={},
  number={},
  pages={220-223},
  abstract={In this paper, we propose a partially-parallel decoder architecture for irregular LDPC code targeting high throughput applications. The proposed decoder is based on a novel delta-value message-passing algorithm to facilitate the decoding throughput by removing redundant computations using the difference between the updated value and the original value. Techniques such as binary sorting, high performance pipelining are used to further speed up the message-passing procedure. The synthesis result in TSMC 0.18 CMOS technology shows that for (648,324) irregular LDPC code, our decoder can increase 8 times in throughput, which reaches 418 Mbps at the frequency of 200MHz.},
  keywords={},
  doi={10.1109/VDAT.2008.4542452},
  ISSN={},
  month={April},}
@INPROCEEDINGS{4541527,
  author={Chih-Hao Liu and Chien-Ching Lin and Hsie-Chia Chang and Chen-Yi Lee and Yarsun Hsu},
  booktitle={2008 IEEE International Symposium on Circuits and Systems (ISCAS)}, 
  title={Multi-mode message passing switch networks applied for QC-LDPC decoder}, 
  year={2008},
  volume={},
  number={},
  pages={752-755},
  abstract={The multi-mode message passing switch networks for multi-standard QC-LDPC decoder are presented. An enhanced self-routing switch network with only one barrel shifter permutation structure and a shifter-based two-way duplicated switch network are proposed to support 19 and 3 different sub-matrices defined in IEEE 802.16e and IEEE 802.11n. These proposed switch networks can route the decoding message in parallel by different sizes without signal congestion. The enhanced self-routing switch network can switch the messages at different expansion factors with the lowest hardware complexity. Under the condition of a smaller expansion factor, the decoder throughput can be enhanced from the two-way duplicated switch network by increasing the parallelism. In the 130 nm CMOS synthesis result, the proposed enhanced self-routing and the two-way duplicated switch network gate counts are 21.9 k and 37.4 k at 384 MHz operation frequency.},
  keywords={},
  doi={10.1109/ISCAS.2008.4541527},
  ISSN={2158-1525},
  month={May},}
@INPROCEEDINGS{4541471,
  author={Shu-Cheng Chou and Mong-Kai Ku and Chia-Yu Lin},
  booktitle={2008 IEEE International Symposium on Circuits and Systems (ISCAS)}, 
  title={Switching activity reducing layered decoding algorithm for LDPC codes}, 
  year={2008},
  volume={},
  number={},
  pages={528-531},
  abstract={A switching activity reducing decoding algorithm for Low-Density Parity Check (LDPC) codes is proposed. Our modified horizontal layered decoding algorithm reduces active node switching activities to lower LDPC decoder power consumption. Layered nodes are periodically refreshed to minimize coding gain degradation. A low hardware overhead partially parallel LDPC decoder architecture is also described. Simulation results show that our algorithm reduces the number of LDPC decoder operations up to 62.5% compared to the original layered decoding and improves the original vertical layered Lazy Scheduling much with little performance loss.},
  keywords={},
  doi={10.1109/ISCAS.2008.4541471},
  ISSN={2158-1525},
  month={May},}
@INPROCEEDINGS{4555826,
  author={Swarup Mohalik and Rajeev, A. C. and Dixit, Manoj G. and Ramesh, S. and Vijay Suman, P. and Pandya, Paritosh K. and Shengbing Jiang},
  booktitle={2008 45th ACM/IEEE Design Automation Conference}, 
  title={Model checking based analysis of end-to-end latency in embedded, real-time systems with clock drifts}, 
  year={2008},
  volume={},
  number={},
  pages={296-299},
  abstract={End-to-end latency of messages is an important design parameter that needs to be within specified bounds for the correct functioning of distributed real-time control systems. In this paper we give a formal definition of end-to-end latency, and use this as the basis for checking whether a stipulated deadline is violated within a bounded time. For unbounded verification, we model the system as a set of communicating Timed Automata, and perform reachability analysis. The proposed method takes into account the drift of clocks which is shown to affect the latency appreciably. The method has been tested on a medium sized automotive example.},
  keywords={},
  doi={10.1145/1391469.1391544},
  ISSN={0738-100X},
  month={June},}
@INPROCEEDINGS{4556263,
  author={Ehsaei, Mahshid S. and Heydarzadeh, Yasaman and Aslani, Siavash and Haghighat, Abolfazl T.},
  booktitle={2008 3rd International Symposium on Wireless Pervasive Computing}, 
  title={Pattern-Based Planning System (PBPS): A novel approach for uncertain dynamic multi-agent environments}, 
  year={2008},
  volume={},
  number={},
  pages={524-528},
  abstract={Coordination among agents in a dynamic uncertain environment to achieve a specified goal is a complicated task. Common approaches such as centralized techniques need high speed computations and are brittle to single points of failure. Distributed approaches have improved these problems, but they can be highly sub-optimal. Market-Based techniques are one of the best approaches and are more responsive than two other techniques to change, but they need high message passing ability. In this paper, taking advantages of Market-Based architecture, we introduce a novel approach called Pattern-Based Planning System (PBPS) that can be used in environments with forcible limitations on message passing. On the other hand, PBPS reduces search space using some patterns as input to generate a plan that determines each agent’s tasks and the sequence of execution of those tasks. It also monitors the plan during its execution and updates it whenever is needed. As a test-bed, we chose Robocup 3D soccer simulation environment and implemented our planner in MRL 3D soccer simulation team’s agents. The simulation results show that our approach increase the probability of achieving the goal.},
  keywords={},
  doi={10.1109/ISWPC.2008.4556263},
  ISSN={},
  month={May},}
@INPROCEEDINGS{4556070,
  author={Buntinas, Darius and Bosilca, George and Graham, Richard L. and Vallée, Geoffroy and Watson, Gregory R.},
  booktitle={2008 22nd International Symposium on High Performance Computing Systems and Applications}, 
  title={A Scalable Tools Communications Infrastructure}, 
  year={2008},
  volume={},
  number={},
  pages={33-39},
  abstract={The Scalable Tools Communication Infrastructure (STCI) is an open  source collaborative effort intended to provide high-performance,  scalable, resilient, and portable communications and process control  services for a wide variety of user and system tools.  STCI is aimed   specifically at tools for  ultrascale computing  and uses a component architecture to simplify tailoring the  infrastructure to a wide range of scenarios.  This paper  describes STCI's design philosophy, the various  components that will be used to provide an STCI implementation for a  range of ultrascale platforms, and a range of tool types.  These  include tools supporting parallel run-time  environments, such as MPI, parallel application correctness tools and  performance analysis tools, as well as system monitoring and  management tools.},
  keywords={},
  doi={10.1109/HPCS.2008.24},
  ISSN={2378-2099},
  month={June},}
@INPROCEEDINGS{4556085,
  author={Singh, Rajendra and Graham, Peter},
  booktitle={2008 22nd International Symposium on High Performance Computing Systems and Applications}, 
  title={Performance Driven Partial Checkpoint/Migrate for LAM-MPI}, 
  year={2008},
  volume={},
  number={},
  pages={110-116},
  abstract={Using idle compute resources is cost-effective and systems like Condor have successfully exploited such resources in limited contexts (e.g. bag of tasks problems). Increasingly, networks in large organizations are becoming more capable and, when combined with latency tolerance mechanisms, can now provide an attractive platform for running some cluster-based parallel programs. In environments where machines are shared, however, load guarantees cannot be made. If one or more machines running an application become overloaded it may negatively impact the performance of the entire application. This provides a strong motivation to be able to checkpoint and migrate processes to new machines. Such performance driven migration normally involves the entire set of application processes. This, however, is wasteful both in terms of lost progress (if other processes can still execute) and overhead (since moving unnecessary processes is costly). To address these issues, we describe an extension of LAM/MPI that provides a partial checkpoint and migrate ability. Our system checkpoints only the subset of MPIprocesses that need to migrate. For long running applications exhibiting moderate communications, this can enhance the usefulness of shared machines for "cluster" computing.},
  keywords={},
  doi={10.1109/HPCS.2008.16},
  ISSN={2378-2099},
  month={June},}
@INPROCEEDINGS{4556590,
  author={Eyers, David M. and Srinivasan, Sriram and Moody, Ken and Bacon, Jean},
  booktitle={2008 IEEE Workshop on Policies for Distributed Systems and Networks}, 
  title={Compile-Time Enforcement of Dynamic Security Policies}, 
  year={2008},
  volume={},
  number={},
  pages={119-126},
  abstract={Dynamic separation of duties, delegation and other dynamic security constraints require the state of the security system to be managed explicitly at run-time in software. The majority of this software is still programmed directly by humans, and is thus susceptible to errors that will impact the overall functionality and security of the system. In this paper we demonstrate a technique for statically checking properties of the software that manages dynamic security policies. We base our work on Kilim, a shared-nothing, message-passing Java framework that provides a faster, safer alternative to the dominant shared-memory and locking paradigm. We demonstrate that Kilim's static, compile- time verification of type linearity can also effect validation of aspects of dynamic security systems. We describe our initial steps toward the use of Kilim to support active, distributed security infrastructure.},
  keywords={},
  doi={10.1109/POLICY.2008.24},
  ISSN={},
  month={June},}
@INPROCEEDINGS{4558588,
  author={Garcia-Frias, Javier and Kejing Liu},
  booktitle={2008 42nd Annual Conference on Information Sciences and Systems}, 
  title={Design of near-optimum quantum error-correcting codes based on generator and parity-check matrices of LDGM codes}, 
  year={2008},
  volume={},
  number={},
  pages={562-567},
  abstract={We study the design of near-optimum quantum error correcting codes based on the use of sparse matrices. The basic idea is to construct a Calderbank-Shor-Steane (CSS) code based on the generator and parity-check matrices of a classical channel code with low density generator matrix (LDGM code), which is designed with a specific structure inspired in the parallel concatenation of regular LDGM codes. Then, row operations are performed in both matrices to achieve the desired quantum rate. Decoding is performed in an iterative manner, by applying message passing over the corresponding graphs. The proposed codes allow greater flexibility and are easier to design than existing sparse-graph quantum codes, while leading to better performance.},
  keywords={},
  doi={10.1109/CISS.2008.4558588},
  ISSN={},
  month={March},}
@INPROCEEDINGS{4558672,
  author={Soedarmadji, Edwin},
  booktitle={2008 42nd Annual Conference on Information Sciences and Systems}, 
  title={The Chinese Generals Problem}, 
  year={2008},
  volume={},
  number={},
  pages={1042-1047},
  abstract={To achieve higher reliability, safety, and fault-tolerance, many mission-critical detection and decision systems implement consensus algorithms that force the system's underlying sensor networks to reach the states of consensus and unanimous decision among the sensor nodes. Most consensus algorithms presented in the literature utilize local averaging (for continuous values) and majority voting (for discrete values) operators combined with iterative message passing and other similar nearest-neighbor information propagation schemes. Although very simple to implement, such schemes can be very prone to noise because individual detection and decision errors can be amplified and propagated many times throughout the network. For this reason, in this paper we propose a novel consensus algorithm for binary systems that requires each sensor node to participate in message propagation only if its input exceeds a predetermined threshold. This algorithm is a solution to what we call The Chinese Generals Problem, a wide generalization of The Byzantine Generals Problem by Lamport et al [1]. The threshold function used in the algorithm leads to an adjustable network-wide threshold level that defines the minimum number of nodes initially reporting positive detection required in order for all the nodes to reach the correct consensus.},
  keywords={},
  doi={10.1109/CISS.2008.4558672},
  ISSN={},
  month={March},}
@INPROCEEDINGS{4563209,
  author={Zhibin Sun and Mingkai Shao and Jun Chen and Kon Max Wong and Xiaolin Wu},
  booktitle={2008 24th Biennial Symposium on Communications}, 
  title={Lossy source coding for non-uniform sources using LDGM codes}, 
  year={2008},
  volume={},
  number={},
  pages={76-79},
  abstract={Recently low-density generator matrix (LDGM) codes along with various message-passing algorithms (e.g., survey propagation algorithm) have been used for lossy source coding. In contrast with most prior work which has focused exclusively on uniformly distributed sources, we address the problem of lossy coding for sources with arbitrary distributions. Built upon the idea of approximating the optimal output distribution indicated by the rate-distortion theory with a uniform distribution over a larger alphabet, two multilevel coding schemes are proposed: one uses multiple linear codes while the other requires a single linear code of extended length. The simulation results show that both schemes can significantly outperform the existing LDGM codes based methods.},
  keywords={},
  doi={10.1109/BSC.2008.4563209},
  ISSN={},
  month={June},}
@INPROCEEDINGS{4561131,
  author={Shankaranarayanan, Avinash and Amaldas, Christine and Pears, Russel},
  booktitle={2008 International Conference on Biocomputation, Bioinformatics, and Biomedical Technologies}, 
  title={"Blast Those Sequences': A Gridified Framework for Bioinformatics Blast Using the A3pviGrid}, 
  year={2008},
  volume={},
  number={},
  pages={35-40},
  abstract={Probably the single most important concern of the biotechnology industry is to improve existing biotechnology applications and tools due to the exponential increase in the size of the datasets. Improving application specific performance, pertaining to sudden and dynamic changes in the execution environment has been a widely researched problem. This research was undertaken to find application specific performance problems in the field of applied Bioinformatics. We specifically narrow down on an important everyday bioinformatics application namely Blast, used commonly by biologists for everyday research. A detailed literature study was undertaken to observe the gaps specific to the applications performance subjected to different quality of service constraints and system specific parameters under the confluence of a dynamic mini grid test bed. A number of gaps were identified; throughput in terms of latency (message passing); scalability (load balancing) and application performance (reliability) needs to be addressed. An experimental mini grid test bed was implemented to simulate various conditions and to test the proposed hypotheses. The implemented architecture utilizes game theoretic optimization and agent based team formation (Coalition) algorithms to improve upon scalability with respect to team formation. Due to the dynamic nature of distributed systems (as discussed in previous works) all interactions are made local within a team transparently. This paper is a proof of concept of an experimental mini-Grid test-bed aimed at improving performances of bioinformatics Blast application in terms of scalability and stability. Experimental results and detailed literature on current approaches are explored to conduct a set of generic experiments to validate our claims.},
  keywords={},
  doi={10.1109/BIOTECHNO.2008.32},
  ISSN={},
  month={June},}
@INPROCEEDINGS{4578241,
  author={Teixeira, H. Z. and Alvarenga, D. J. and Almeida, A. C. G. and Rodrigues, A. M. and Duarte, M. A.},
  booktitle={2008 11th IEEE International Conference on Computational Science and Engineering}, 
  title={Parallelization of the Electrodiffusion Mechanism of the Computational Model of Spreading Depression}, 
  year={2008},
  volume={},
  number={},
  pages={261-266},
  abstract={The simulation of cerebral phenomena, such spreading depression wave (SD), involves the modeling of large-scale neuronal populations. Consequently, the processing time and the computational resource costs become elevate. The goal of this work is to apply the parallel programming techniques on the simulation of SD in a three-dimensional representation of the neuronal tissue. The model consists in the description of synaptic terminals and glial cells coupled by means of the extracellular space, where the ionic movements are described by electrodiffusion. The parallelization strategy is achieved by means of the Message Passing Interface. The code performance in a parallel environment is compared with serial processing. The results point out the model is highly parallelized and justify the use of parallel programming in this kind of modeling. Furthermore, the reproduction of the main characteristics of SD, such the propagation velocity and the extracellular ionic dynamic profiles, close to what is observed experimentally, validates the model.},
  keywords={},
  doi={10.1109/CSE.2008.12},
  ISSN={},
  month={July},}
@ARTICLE{4578752,
  author={Darabiha, Ahmad and Chan Carusone, Anthony and Kschischang, Frank R.},
  journal={IEEE Journal of Solid-State Circuits}, 
  title={Power Reduction Techniques for LDPC Decoders}, 
  year={2008},
  volume={43},
  number={8},
  pages={1835-1845},
  abstract={ This paper investigates VLSI architectures for low-density parity-check (LDPC) decoders amenable to low- voltage and low-power operation. First, a highly-parallel decoder architecture with low routing overhead is described. Second, we propose an efficient method to detect early convergence of the iterative decoder and terminate the computations, thereby reducing dynamic power. We report on a bit-serial fully-parallel LDPC decoder fabricated in a 0.13-$\mu{\hbox{m}}$  CMOS process and show how the above techniques affect the power consumption. With early termination, the prototype is capable of decoding with 10.4 pJ/bit/iteration, while performing within 3 dB of the Shannon limit at a BER of 10$^{-5}$  and with 3.3 Gb/s total throughput. If operated from a 0.6 V supply, the energy consumption can be further reduced to 2.7 pJ/bit/iteration while maintaining a total throughput of 648 Mb/s, due to the highly-parallel architecture. To demonstrate the applicability of the proposed architecture for longer codes, we also report on a bit-serial fully-parallel decoder for the (2048, 1723) LDPC code in 10GBase-T standard synthesized with a 90-nm CMOS library. },
  keywords={},
  doi={10.1109/JSSC.2008.925402},
  ISSN={1558-173X},
  month={Aug},}
@INPROCEEDINGS{4579928,
  author={Mujumdar, Manik and Bheevgade, Meenakshi and Malik, Latesh and Patrikar, Rajendra},
  booktitle={2008 First International Conference on Emerging Trends in Engineering and Technology}, 
  title={High Performance Computational Grids Fault Tolerance at System Level}, 
  year={2008},
  volume={},
  number={},
  pages={379-383},
  abstract={Many complex scientific, mathematical applications require large time for completion. To deal with this issue, parallelization is popularly used. Distributing an application onto several machines is one of the key aspects of grid-computing. This paper focuses on a check point/restart mechanism used to overcome the problem of job suspension at a failed node in a computational Grid. The ability to checkpoint a running application and restart it later can provide many useful benefits including fault recovery by rolling back an application to a previous checkpoint, advanced resources sharing, better application response time by restarting applications from checkpoints instead of from scratch, and improved system utilization, efficient high performance computing and improved service availability.},
  keywords={},
  doi={10.1109/ICETET.2008.21},
  ISSN={2157-0485},
  month={July},}
@INPROCEEDINGS{4582841,
  author={Xiaoxin Zou and Zhiliang Qin and Kui Cai},
  booktitle={2008 3rd IEEE Conference on Industrial Electronics and Applications}, 
  title={TPCSPC decoding over coded partial-response channels}, 
  year={2008},
  volume={},
  number={},
  pages={1853-1857},
  abstract={In this paper, we consider turbo product codes with single-parity-check component codes as an low-complexity coding scheme for magnetic recording systems. Based on the observation that TPCSPC can be viewed as a special type of regular LDPC codes, three message-passing schedules of the sum-product algorithm (SPA) are studied. It is shown that the standard row-column decoding algorithm in the literature is essentially the same as the serial check-updating schedule. By viewing the code graph from a different perspective, we propose a serial bit-updating schedule that uses the MacLaurin Series expansion to approximate the computationally intensive check operation. The proposed algorithm converges faster than the parallel decoding schedule and can be implemented efficiently in hardware by using high-speed adders, comparators, and shift registers.},
  keywords={},
  doi={10.1109/ICIEA.2008.4582841},
  ISSN={2158-2297},
  month={June},}
@INPROCEEDINGS{4595890,
  author={Yang, Xuejun and Wang, Panfeng and Fu, Hongyi and Du, Yunfei and Wang, Zhiyuan and Jia, Jia},
  booktitle={2008 The 28th International Conference on Distributed Computing Systems}, 
  title={Compiler-Assisted Application-Level Checkpointing for MPI Programs}, 
  year={2008},
  volume={},
  number={},
  pages={251-259},
  abstract={Application-level checkpointing can decrease the overhead of fault tolerance by minimizing the amount of checkpoint data. However this technique requires the programmer to manually choose the critical data that should be saved. In this paper, we firstly propose a live-variable analysis method for MPI programs. Then, we provide an optimization method of data saving for application-level checkpointing based on the analysis method. Based on the theoretical foundation, we implement a source-to-source precompiler (ALEC) to automate application-level checkpointing. Finally, we evaluate the performance of five FORTRAN/MPI programs which are transformed and integrated checkpointing features by ALEC on a 512-CPU cluster system. The experimental results show that i) the application-level checkpointing based on live-variable analysis for MPI programs can efficiently reduce the amount of checkpoint data, thereby decrease the overhead of checkpoint and restart; ii) ALEC is capable of automating application-level checkpointing correctly and effectively.},
  keywords={},
  doi={10.1109/ICDCS.2008.25},
  ISSN={1063-6927},
  month={June},}
@INPROCEEDINGS{4603395,
  author={Hu, Zhang},
  booktitle={2008 3rd International Conference on Innovative Computing Information and Control}, 
  title={Notice of Violation of IEEE Publication Principles: Algorithm for the GME Problem in Real-Time Distributed Systems Based on Token}, 
  year={2008},
  volume={},
  number={},
  pages={206-206},
  abstract={The GME problem is an interesting generalization of the mutual exclusion problems. A few solutions of the GME problem have been studied for message passing distributed systems. However, none of these solutions is totally suitable for the real-time distributed systems. In this paper, we propose a new algorithm for the GME problem in the real-time distributed systems based on Token. The algorithm uses the concepts of priority queue, dynamic request set and the process state. The algorithm uses the approach in which first come first serve in selecting the next session type between the same priority levels and satisfies the concurrent occupancy property. The algorithm allows all n processors to be inside their CS provided they request for the same session. The performance analysis and correctness proof of the algorithm has also been included in the paper.},
  keywords={},
  doi={10.1109/ICICIC.2008.124},
  ISSN={},
  month={June},}
@INPROCEEDINGS{4618580,
  author={Koop, Matthew J. and Huang, Wei and Gopalakrishnan, Karthik and Panda, Dhabaleswar K.},
  booktitle={2008 16th IEEE Symposium on High Performance Interconnects}, 
  title={Performance Analysis and Evaluation of PCIe 2.0 and Quad-Data Rate InfiniBand}, 
  year={2008},
  volume={},
  number={},
  pages={85-92},
  abstract={High-performance systems are undergoing a major shift as commodity multi-core systems become increasingly prevalent. As the number of processes per compute node increase, the other parts of the system must also scale appropriately to maintain a balanced system. In the area of high-performance computing, one very important element of the overall system is the network interconnect that connects compute nodes in the system. InfiniBand is a popular interconnect for high- performance clusters. Unfortunately, due to limited bandwidth of the PCI-Express fabric, InfiniBand performance has remained limited. PCI-Express (PCIe) 2.0 has become available and has doubled the transfer rates available. This additional I/O bandwidth balances the system and makes higher data rates for external interconnects such as InfiniBand feasible. As a result, InfiniBand quad-data rate (QDR) mode has become available on the Mellanox InfiniBand host channel adapter (HCA) with a 40 Gb/sec signaling rate. In this paper we perform an in-depth performance analysis of PCIe 2.0 and the effect of increased InfiniBand signaling rates. We show that even using the double data rate (DDR) interface, PCIe 2.0 enables a 25% improvement in NAS parallel benchmark IS performance. Furthermore, we show that when using QDR on PCIe 2.0, network loopback can outperform a shared memory message passing implementation. We show that increased interconnection bandwidth significantly improves the overall system balance by lowering latency and increasing bandwidth.},
  keywords={},
  doi={10.1109/HOTI.2008.26},
  ISSN={2332-5569},
  month={Aug},}
@INPROCEEDINGS{4624391,
  author={Dietlmeier, Julia and Begley, Seán and Whelan, Paul F.},
  booktitle={2008 International Machine Vision and Image Processing Conference}, 
  title={Cost-Effective HPC Clustering for Computer Vision Applications}, 
  year={2008},
  volume={},
  number={},
  pages={97-102},
  abstract={We will present a cost-effective and flexible realization of High Performance Computing (HPC) clustering and its potential in solving computationally intensive problems incomputer vision. The featured software foundation to support the parallel programming is the GNU Parallel Knoppix package with Message Passing Interface (MPI) based Octave, Python and C interface capabilities. The implementation is especially of interest in applications where the main objective is to reuse the existing hardware infrastructure and to maintain the overall budget cost. We will present the benchmark results and compare and contrast the performances of Octave and MATLAB.},
  keywords={},
  doi={10.1109/IMVIP.2008.8},
  ISSN={},
  month={Sep.},}
@INPROCEEDINGS{4625735,
  author={Pinto, Luiz Carlos and Tomazella, Luiz H. B. and Dantas, M. A. R.},
  booktitle={2008 IEEE Symposium on Computers and Communications}, 
  title={Building efficient multi-core clusters for high performance computing}, 
  year={2008},
  volume={},
  number={},
  pages={474-479},
  abstract={Multi-core technology produces a new scenario for communicating processes in an MPI cluster environment and consequently the involved trade-offs need to be uncovered. This motivation guided our research and lead to a new approach for setting up more efficient clusters built with commodities. Thus, alternatively to the utilization of non-commodity interconnects such as Myrinet and Infiniband, we present a proposal based on leaving cores idle relatively to application processing in order to build economically more accessible clusters of commodities with higher performance. Execution of fine-grained IS algorithm from NAS parallel benchmark revealed a speedup of up to 25%. Interestingly, a cluster set up according to the proposal was able to outperform a single multi-core SMP host in which all processes communicate inside the host. Therefore, empirical results indicate that our proposal has been successful for medium and fine-grained algorithms.},
  keywords={},
  doi={10.1109/ISCC.2008.4625735},
  ISSN={1530-1346},
  month={July},}
@INPROCEEDINGS{4625853,
  author={Chai, Lei and Lai, Ping and Jin, Hyun-Wook and Panda, Dhabaleswar K.},
  booktitle={2008 37th International Conference on Parallel Processing}, 
  title={Designing an Efficient Kernel-Level and User-Level Hybrid Approach for MPI Intra-Node Communication on Multi-Core Systems}, 
  year={2008},
  volume={},
  number={},
  pages={222-229},
  abstract={The emergence of multi-core processors has made MPI intra-node communication a critical component in high performance computing. In this paper, we use a three-stepmethodology to design an efficient MPI intra-node communication scheme from two popular approaches: shared memory and OS kernel-assisted direct copy. We use an Intel quad-core cluster for our study. We first run microbenchmarks to analyze the advantages and limitations of these two approaches, including the impacts of processor topology, communication buffer reuse, process skew effects, and L2 cache utilization. Based on the results and the analysis, we propose topology-aware and skew-aware thresholds to build an optimized hybrid approach. Finally, we evaluate the impact of the hybrid approach on MPI collective operations and applications using IMB, NAS, PSTSWM, and HPL benchmarks. We observe that the optimized hybrid approach can improve the performance of MPI collective operations by up to 60%, and applications by up to 17%.},
  keywords={},
  doi={10.1109/ICPP.2008.16},
  ISSN={2332-5690},
  month={Sep.},}
@INPROCEEDINGS{4574602,
  author={Dubrovin, Jori and Junttila, Tommi},
  booktitle={2008 8th International Conference on Application of Concurrency to System Design}, 
  title={Symbolic model checking of hierarchical UML state machines}, 
  year={2008},
  volume={},
  number={},
  pages={108-117},
  abstract={A compact symbolic encoding is described for the transition relation of systems modeled with asynchronously executing, hierarchical UML state machines that communicate through message passing and attribute access. This enables the analysis of such systems by symbolic model checking techniques, such as BDD-based model checking and SAT-based bounded model checking. Message reception, completion events, and run-to-completion steps are handled in accordance with the UML specification. The size of the encoding for state machine control logic is linear in the size of the state machine even in the presence of composite states, orthogonal regions, and message deferring. The encoding is implemented for the NuSMV model checker, and preliminary experimental results are presented.},
  keywords={},
  doi={10.1109/ACSD.2008.4574602},
  ISSN={1550-4808},
  month={June},}
@INPROCEEDINGS{4626803,
  author={Becker, Daniel and Linford, John C. and Rabenseifner, Rolf and Wolf, Felix},
  booktitle={2008 International Conference on Parallel Processing - Workshops}, 
  title={Replay-Based Synchronization of Timestamps in Event Traces of Massively Parallel Applications}, 
  year={2008},
  volume={},
  number={},
  pages={212-219},
  abstract={Event traces are helpful in understanding the performance behavior of message-passing applications since they allow in-depth analyses of communication and synchronization patterns. However, the absence of synchronized hardware clocks may render the analysis ineffective because inaccurate relative event timings can misrepresent the logical event order and lead to errors when quantifying the impact of certain behaviors. Although linear offset interpolation can restore consistency to some degree, inaccuracies and time-dependent drifts may still disarrange the original succession of events - especially during longer runs. In our earlier work, we have presented an algorithm that removes the remaining violations of the logical event order postmortem and, in addition, have outlined the initial design of a parallel version. Here, we complete the parallel design and describe its implementation within the SCALASCA trace-analysis framework. We demonstrate its suitability for large-scale applications running on more than a thousand application processes and show how the correction can improve the trace analysis of a real-world application example.},
  keywords={},
  doi={10.1109/ICPP-W.2008.17},
  ISSN={2332-5690},
  month={Sep.},}
@INPROCEEDINGS{4629979,
  author={Creedon, Eoin and Manzke, Michael},
  booktitle={2008 International Conference on Field Programmable Logic and Applications}, 
  title={Scalable high performance computing on FPGA clusters using message passing}, 
  year={2008},
  volume={},
  number={},
  pages={443-446},
  abstract={The direct connection of application logic to network logic allows parallel applications to better leverage the network resources. We present a hardware description language message passing application programming interface (HDL MP API) for FPGAs. This allows an application to operate both local and network resources in a uniform, scalable and portable manner, independent of the interconnect. We use the message passing communication paradigm with all necessary communication operations performed by dedicated control hardware, independently of the interconnect. Ethernet has been used as the interconnect to demonstrate the HDL MP API functionality for this proof of concept system. Parallel linear array matrix multiplication has been implemented and tested using the HDL MP API. This application demonstrates the scalability provided by the HDL MP API.},
  keywords={},
  doi={10.1109/FPL.2008.4629979},
  ISSN={1946-1488},
  month={Sep.},}
@INPROCEEDINGS{4630612,
  author={Singh, Lotika and Narayan, Apurva and Kumar, Satish},
  booktitle={2008 IEEE International Conference on Fuzzy Systems (IEEE World Congress on Computational Intelligence)}, 
  title={Dynamic fuzzy load balancing on LAM/MPI clusters with applications in parallel master-slave implementations of an evolutionary neuro-fuzzy learning system}, 
  year={2008},
  volume={},
  number={},
  pages={1782-1788},
  abstract={In the context of parallel master-slave implementations of evolutionary learning in fuzzy-neural network models, a major issue that arises during runtime is how to balance the load-the number of strings assigned to a slave for evaluation during a generation-in order to achieve maximum speed up. Slave evaluation times can fluctuate drastically depending upon the local computational load on the slave (given fixed node specifications). Communication delays compound the problem of proper load assignment. In this paper we propose the design of a novel dynamic fuzzy load estimator for application to load balancing on heterogeneous LAM/MPI clusters. Using average evaluation time and communication delay feedback estimates from slaves, string assignments for evaluation to slaves are dynamically changed during runtime. Extensive tests on heterogenous clusters shows that considerable speedups can be achieved using the proposed fuzzy controller.},
  keywords={},
  doi={10.1109/FUZZY.2008.4630612},
  ISSN={1098-7584},
  month={June},}
@INPROCEEDINGS{4631592,
  author={Said, Mohamed Faidz Mohamed and Taib, Mohd Nasir and Yahya, Saadiah},
  booktitle={2008 International Symposium on Information Technology}, 
  title={Analysis of the CPU utilization for point-to-point communication operations in a Beowulf cluster system}, 
  year={2008},
  volume={1},
  number={},
  pages={1-6},
  abstract={Beowulf cluster computing involves the use of a network of computing resources to provide high-performance computing (HPC) platform which possesses comparatively economical capabilities once reserved for supercomputers. Certain applications of this cluster computing should be looked from the problem solving viewpoint. Point-to-point communication between the cluster’s nodes is fundamental to all communication subsystems as it forms a basis for efficient message implementation, especially those that involve software applications. The network latency, the time required to transmit the message across the network, may generally be contributed by several significant factors. These may include the network bandwidth, underlying switching mechanism, and blocking time. Based on the blocking time aspect, this parallel computing research attempts to analyze the CPU usage of the node by conducting a related benchmarking test.},
  keywords={},
  doi={10.1109/ITSIM.2008.4631592},
  ISSN={2155-899X},
  month={Aug},}
@INPROCEEDINGS{4637690,
  author={Chen, Juan and Dong, Yong and Yang, Xuejun and Wang, Panfeng},
  booktitle={2008 10th IEEE International Conference on High Performance Computing and Communications}, 
  title={Energy-Constrained OpenMP Static Loop Scheduling}, 
  year={2008},
  volume={},
  number={},
  pages={139-146},
  abstract={In high performance parallel computing, energy optimization for parallel loops becomes one key because the time of loops often takes a significant part of the whole execution time. Energy-constrained problem is one of the important research focuses. This paper studies energy-constrained problem based on OpenMP static loop scheduling. Firstly, we propose energy-constrained static scheduling algorithm (ECSS), which utilizes DVS to scale down voltage/frequency of the light-loaded processors in terms of energy constraint. Secondly, we propose Energy Constraint based Performance-Optimal Static Scheduling algorithm (ECPOSS), which combines loop rescheduling and DVS for the better performance under the same energy constraint. We prove ECPOSS can obtain the best performance under the same energy constraint. Through testing NPB3.2-OMP programs on 20-160 multiprocessor simulation environment, we evaluate the effectiveness of our algorithms. Experimental results show the performance of ECPOSS is better than that of ECSS by 4.81% under the 50% energy constraint on 100 processors.},
  keywords={},
  doi={10.1109/HPCC.2008.132},
  ISSN={},
  month={Sep.},}
@INPROCEEDINGS{4637745,
  author={Wang, Panfeng and Du, Yunfei and Fu, Hongyi and Yang, Xuejun and Zhou, Haifang},
  booktitle={2008 10th IEEE International Conference on High Performance Computing and Communications}, 
  title={Static Analysis for Application-Level Checkpointing of MPI Programs}, 
  year={2008},
  volume={},
  number={},
  pages={548-555},
  abstract={Application-level checkpointing is a promising technology in the domain of large-scale scientific computing. The consistency of global checkpoint must be carefully guaranteed in order to correctly restore the computation. Usually, some complex coordinated protocols are employed to ensure the consistency of global checkpoint, which require logging orphan or in-transit messages during checkpointing. These protocols complicate the recovery of the computation and increase the checkpoint overhead due to logging message. In this paper, a new method which ensures the consistency of global checkpoint by static analysis is proposed. The method identifies the safe checkpointing regions in MPI programs, where the global checkpoint is always strongly consistent. All checkpoints are located in those safe checkpoint regions. During checkpointing, the method will not log any messages and introduce no extra overhead. The method was implemented and integrated into ALEC, which is a source-to-source precompiler for automating application-level checkpointing. The experimental results show that our method is effective.},
  keywords={},
  doi={10.1109/HPCC.2008.39},
  ISSN={},
  month={Sep.},}
@INPROCEEDINGS{4637794,
  author={Tang, Yuan and Zhang, Yunquan},
  booktitle={2008 10th IEEE International Conference on High Performance Computing and Communications}, 
  title={Utilizing the Multi-threading Techniques to Improve the Two-Level Checkpoint/Rollback System for MPI Applications}, 
  year={2008},
  volume={},
  number={},
  pages={864-869},
  abstract={With the increasing number of processors in modern HPC (high performance computing) systems, there are two emergent problems to solve. One is scalability, the other is fault tolerance. In our previous work, we proposed an MPI operation level checkpoint/rollback system. The main benefits of the system is that it offers the opportunity to employ in-memory (disk-less) checkpoint/rollback techniques which has demonstrated a much better performance over its on-disk counterpart, and the opportunity to have a concurrent two level recover-and-continue MPI system which has been proven to have a high efficiency. To the scope of my knowledge, this is the first concurrent two-level checkpoint/recovery system in use. With the coming of multi-core era, it's time to utilize the multi-threading techniques to improve the performance of in-memory checkpointing algorithm. In this paper, we present two versions of MPI operation level checkpoint/rollback system, one is of single-threaded, the other is of multi-threaded. Also, we provide an in-depth performance analysis between these two approaches to illustrate the benefits of multi-threading techniques on multi-core platform. With the progress of our work, a picture of the hierarchy of future generation fault tolerant HPC system is gradually unrolled.},
  keywords={},
  doi={10.1109/HPCC.2008.58},
  ISSN={},
  month={Sep.},}
@INPROCEEDINGS{4641581,
  author={Kraidy, Ghassan M. and Savin, Valentin},
  booktitle={2008 IEEE 9th Workshop on Signal Processing Advances in Wireless Communications}, 
  title={Minimum-delay decoding of turbo codes for upper-layer FEC}, 
  year={2008},
  volume={},
  number={},
  pages={116-120},
  abstract={In this paper we investigate the decoding of parallel turbo codes over the binary erasure channel suited for upper-layer error correction. The proposed algorithm performs ldquoon-the-flyrdquo decoding, i.e. it starts decoding as soon as the first symbols are received. This algorithm compares with the iterative decoding of codes defined on graphs [1], in that it propagates in the trellises of the turbo code by removing transitions in the same way edges are removed in a bipartite graph under message-passing decoding. Performance comparison with LDPC codes for different coding rates is shown.},
  keywords={},
  doi={10.1109/SPAWC.2008.4641581},
  ISSN={1948-3252},
  month={July},}
@INPROCEEDINGS{4652153,
  author={Wang, Xiren and Jandhyala, Vikram},
  booktitle={2008 IEEE International Symposium on Electromagnetic Compatibility}, 
  title={Enhanced hybrid MPI-OpenMP parallel electromagnetic simulations based on low-rank compressions}, 
  year={2008},
  volume={},
  number={},
  pages={1-5},
  abstract={Existing and emerging parallel computing clusters have nodes with multiple-core CPUs. The distributed-memory property across nodes and shared-memory property within a node coexist with each other. The hybrid architecture can be well exploited by combining the MPI (message passing interface) and OpenMP libraries. This combination is able to reduce memory usage and communication costs compared with either individual approach. In addition, the proposed hybrid static-dynamic load scheduling can yield excellent load-balancing without introducing extra cost. Careful implementation of OpenMP threads can diminish parallel overhead significantly, and expedite the iterative solver in several ways. Numerical experiments validate the high performance of the presented hybrid approach.},
  keywords={},
  doi={10.1109/ISEMC.2008.4652153},
  ISSN={2158-1118},
  month={Aug},}
@ARTICLE{4653061,
  author={Saha, Sankalita and Puthenpurayil, Sebastian and Schlessman, Jason and Bhattacharyya, Shuvra S. and Wolf, Wayne},
  journal={Proceedings of the IEEE}, 
  title={The Signal Passing Interface and Its Application to Embedded Implementation of Smart Camera Applications}, 
  year={2008},
  volume={96},
  number={10},
  pages={1576-1587},
  abstract={Embedded smart camera systems comprise computation- and resource-hungry applications implemented on small, complex but resource-hardy platforms. Efficient implementation of such applications can benefit significantly from parallelization. However, communication between different processing units is a nontrivial task. In addition, new and emerging distributed smart cameras require efficient methods of communication for optimized distributed implementations. In this paper, a novel communication interface, called the signal passing interface (SPI), is presented that attempts to overcome this challenge by integrating relevant properties of two different, yet important, paradigms in this context-dataflow and message passing interface (MPI). Dataflow is a widely used modeling paradigm for signal processing applications, while MPI is an established communication interface in the general-purpose processor community. SPI is targeted toward computation-intensive signal processing applications, and due to its careful specialization, more performance-efficient for embedded implementation in this domain. SPI is also much easier and more intuitive to use. In this paper, successful application of this communication interface to two smart camera applications has been presented in detail to validate a new methodology for efficient distributed implementation for this domain.},
  keywords={},
  doi={10.1109/JPROC.2008.928744},
  ISSN={1558-2256},
  month={Oct},}
@INPROCEEDINGS{4653257,
  author={Quiroz-Fabian, José L. and Aguilar-Cornejo, Manuel and Román-Alonso, Graciela and Castro-García, Miguel A.},
  booktitle={2008 Mexican International Conference on Computer Science}, 
  title={Model Checking for Integrating Dynamic Load Distribution into Parallel Applications}, 
  year={2008},
  volume={},
  number={},
  pages={221-231},
  abstract={Many parallel applications running on a distributed memory cluster generate data dynamically  to process during their execution. In this case it is possible that some cluster nodes become overloaded. To improve performance  we can integrate  a  dynamic data distribution algorithm.The integration of a dynamic load distribution policy into an application must considerthe correct programming of several synchronisation/communication points in order toavoid dead-lock or data lost problems. In this work we show how a Model Checking technique can be used to verifyformally and automatically whether an application along with a load distribution algorithm work properly.We first propose a model for a parallel application thatuses a dynamic load distribution policy to transfer its generated datato other processors (when there are some processors that can help with dataprocessing). In our model in particular we defined a cyclic distributionpolicy. We also propose a set of functioning propertiesthat our model and all parallel application that uses dynamic loaddistribution must fulfill.Then we apply a formal verification technique using the Model Checker Spinto ensure that such properties are satisfied.To show an application of our model we used the MPI tool to implement itand solve the N-Queens problem, where milliards of possible solutions (data)are generated and processed. We show some results obtained by using a 16processors system.},
  keywords={},
  doi={10.1109/ENC.2008.19},
  ISSN={2332-5712},
  month={Oct},}
@INPROCEEDINGS{4663761,
  author={Wei Huang and Koop, Matthew J. and Panda, Dhabaleswar K.},
  booktitle={2008 IEEE International Conference on Cluster Computing}, 
  title={Efficient one-copy MPI shared memory communication in Virtual Machines}, 
  year={2008},
  volume={},
  number={},
  pages={107-115},
  abstract={Efficient intra-node shared memory communication is important for High Performance Computing (HPC), especially with the emergence of multi-core architectures. As clusters continue to grow in size and complexity, the use of Virtual Machine (VM) technologies has been suggested to ease the increasing number of management issues. As demonstrated by earlier research, shared memory communication must be optimized for VMs to attain the native-level performance required by HPC centers. In this paper, we enhance intra-node shared memory communication for VM environments. We propose a one-copy approach. Instead of following the traditional approach used in most MPI implementations, copying data in and out of a pre-allocated shared memory region, our approach dynamically maps user buffers between VMs, allowing data to be directly copied to its destination. We also propose a grant/mapping cache to reduce expensive buffer mapping cost in VM environment. We integrate this approach into MVAPICH2, our implementation of MPI-2 library. For intra-node communication, we are able to reduce the large message latency in VM-based environments by up to 35%, and increase bandwidth by up to 38% even as compared with unmodified MVAPICH2 running in a native environment. Evaluation with the NAS Parallel Benchmarks suite shows up to 15% improvement.},
  keywords={},
  doi={10.1109/CLUSTR.2008.4663761},
  ISSN={2168-9253},
  month={Sep.},}
@INPROCEEDINGS{4663773,
  author={Koop, Matthew J. and Sridhar, Jaidev K. and Panda, Dhabaleswar K.},
  booktitle={2008 IEEE International Conference on Cluster Computing}, 
  title={Scalable MPI design over InfiniBand using eXtended Reliable Connection}, 
  year={2008},
  volume={},
  number={},
  pages={203-212},
  abstract={A significant component of a high-performance cluster is the compute node interconnect. InfiniBand, is an interconnect of such systems that is enjoying wide success due to low latency (1.0-3.0 musec) and high bandwidth and other features. The Message Passing Interface (MPI) is the dominant programming model for parallel scientific applications. As a result, the MPI library and interconnect play a significant role in the scalability. These clusters continue to scale to ever-increasing levels making the role very important. As an example, the ldquoRangerrdquo system at the Texas Advanced Computing Center (TACC) includes over 60,000 cores with nearly 4000 InfiniBand ports. Previous work has shown that memory usage simply for connections when using the Reliable Connection (RC) transport of InfiniBand can reach hundreds of megabytes of memory per process at that level. To address these scalability problems a new InfiniBand transport, eXtended Reliable Connection, has been introduced. In this paper we describe XRC and design MPI over this new transport. We describe the variety of design choices that must be made as well as the various optimizations that XRC allows. We implement our designs and evaluate it on an InfiniBand cluster against RC-based designs. The memory scalability in terms of both connection memory and memory efficiency for communication buffers is evaluated for all of the configurations. Connection memory scalability evaluation shows a potential 100 times improvement over a similarly configured RC-based design. Evaluation using NAMD shows a 10% performance improvement for our XRC-based prototype for the jac2000 benchmark.},
  keywords={},
  doi={10.1109/CLUSTR.2008.4663773},
  ISSN={2168-9253},
  month={Sep.},}
@INPROCEEDINGS{4663808,
  author={Liqiang Cao and Hongbing Luo and Baoyin Zhang},
  booktitle={2008 IEEE International Conference on Cluster Computing}, 
  title={Jetter: a multi-pattern parallel I/O benchmark}, 
  year={2008},
  volume={},
  number={},
  pages={459-463},
  abstract={This paper proposes a new multi-pattern parallel I/O benchmark called Jetter, which evaluates parallel I/O throughput with either the contiguous I/O pattern or the non-contiguous I/O pattern, in either the share-one-file model or the file-per-process model, by either the POSIX interface or the MPI-I/O interface. Jetter helps end users make sense of the pattern performance law, and helps them develop efficient applications in a platform. We have evaluated the parallel I/O bandwidth in a 32 CPU shared memory computer with Jetter. The results show that I/O pattern determines throughput. Optimizing I/O model, interface, etc. in a pattern will improve bandwidth 2 or 3 times.},
  keywords={},
  doi={10.1109/CLUSTR.2008.4663808},
  ISSN={2168-9253},
  month={Sep.},}
@INPROCEEDINGS{4668100,
  author={Fowler, M. R. and Stipidis, E. and Ali, F. H.},
  booktitle={2008 The Third International Conference on Software Engineering Advances}, 
  title={Practical Verification of an Embedded Beowulf Architecture Using Standard Cluster Benchmarks}, 
  year={2008},
  volume={},
  number={},
  pages={140-145},
  abstract={The advent of embedded systems with greater capacity in terms of processing and general functionality has given rise to the recent use of embedded clusters, as seen in Singapore's satellite mission, X-Sat. This paper presents a Linux-based concurrent system of embedded network nodes, interconnected by Ethernet. It is formed of readily available components and is configured as a standard, commodity-based Beowulf class computer. It uses a free implementation of the message passing interface. Combining the inherent benefits of Beowulf and embedded systems forms a space-efficient distributed system. Thus a multiple node system can be comfortably housed on a developerpsilas desk, being programmed and administered in the same way as a conventional PC based cluster. To validate the system, standard benchmark results are shown for message passing protocol overhead and peak floating point rate of computation.},
  keywords={},
  doi={10.1109/ICSEA.2008.39},
  ISSN={},
  month={Oct},}
@INPROCEEDINGS{4669771,
  author={Jin, Karen H. and Wu, Dan},
  booktitle={2008 20th IEEE International Conference on Tools with Artificial Intelligence}, 
  title={Marginal Calibration in Multi-agent Probabilistic Systems}, 
  year={2008},
  volume={2},
  number={},
  pages={171-178},
  abstract={The multiply sectioned Bayesian network (MSBN) model successfully extends the traditional Bayesian network (BN) model for the support of probabilistic inference in distributed multi-agent systems. However, existing MSBN inference methods do not allow agents to reason about their own problem sub-domains right after the initialization process. Extensive amount of inter-agent message passings are needed to calibrate each agent's local subnet into a correct prior marginal distribution. In this paper, we introduce the concept of prior marginal factors to facilitate this process. Based on the analysis of the prior marginal factors, minimum message passing is required during calibration. Furthermore, we have removed the requirement of maintaining a consistent junction tree (JT) during message calculation. Therefore, our marginal calibration algorithm guarantees that a prior marginal in each MSBN subnet is formed with greatly reduced communication and computational cost. Our preliminary experiments have confirmed the improved time efficiency of the proposed algorithm.},
  keywords={},
  doi={10.1109/ICTAI.2008.70},
  ISSN={2375-0197},
  month={Nov},}
@INPROCEEDINGS{4670188,
  author={Takase, Toshiro and Tajima, Keishi},
  booktitle={2008 IEEE International Conference on Web Services}, 
  title={Lazy XML Parsing/Serialization Based on Literal and DOM Hybrid Representation}, 
  year={2008},
  volume={},
  number={},
  pages={295-303},
  abstract={Distributed SOA computing environments usually use SOAP intermediaries that sit between senders and receivers to mediate SOAP messages. The intermediaries may add support services to the SOAP message exchange, such as routing, logging, and security. The typical processing by a SOAP intermediary is parsing the incoming SOAP messages, checking the data in each message, and then serializing the messages to put them back into the network. DOM is one of the popular interfaces to navigate an XML tree. Existing DOM implementations are not efficient for SOAP intermediary processing. Existing DOM implementations parse XML data to create tree data and traverse the tree data for serialization. Typically, a SOAP intermediary rarely modifies the tree data. In such situations, creating the tree data and serializing it back into XML data is computationally expensive. We propose a DOM implementation based on a hybrid data representation that uses both literal XML and DOM objects. In our implementation, a SOAP intermediary stores the original literal XML representation and reuses it to avoid traversing all of the tree data during serialization. We prototyped the DOM implementation and evaluated its performance.},
  keywords={},
  doi={10.1109/ICWS.2008.89},
  ISSN={},
  month={Sep.},}
@INPROCEEDINGS{4670295,
  author={Endo, André Takeshi and Simão, Adenilso da Silva and Souza, Simone do Rocio Senger de and Souza, Paulo Sergio Lopes de},
  booktitle={Testing: Academic & Industrial Conference - Practice and Research Techniques (taic part 2008)}, 
  title={Web Services Composition Testing: A Strategy Based on Structural Testing of Parallel Programs}, 
  year={2008},
  volume={},
  number={},
  pages={3-12},
  abstract={Web Services have been used in the development of loosely coupled applications. Several Web Services are usually combined to create new services by a mechanism named Web Services Composition. In this paper, we present a strategy for Web Services Composition structural integration testing. Structural testing coverage criteria for serviceswritten in BPEL are also described. The concept of requiredelement groups is defined to improve the accuracy of criteria coverage. We present a case study for assessing the applicability of proposed strategy. ValiBPEL-Web, a tool that supports the test strategy is also presented.},
  keywords={},
  doi={10.1109/TAIC-PART.2008.9},
  ISSN={},
  month={Aug},}
@ARTICLE{4668361,
  author={Schonberg, Daniel and Draper, Stark C. and Yeo, Chuohao and Ramchandran, Kannan},
  journal={IEEE Transactions on Information Forensics and Security}, 
  title={Toward Compression of Encrypted Images and Video Sequences}, 
  year={2008},
  volume={3},
  number={4},
  pages={749-762},
  abstract={We present a framework for compressing encrypted media, such as images and videos. Encryption masks the source, rendering traditional compression algorithms ineffective. By conceiving of the problem as one of distributed source coding, it has been shown in prior work that encrypted data are as compressible as unencrypted data. However, there are two major challenges to realize these theoretical results. The first is the development of models that capture the underlying statistical structure and are compatible with our framework. The second is that since the source is masked by encryption, the compressor does not know what rate to target. We tackle these issues in this paper. We first develop statistical models for images before extending it to videos, where our techniques really gain traction. As an illustration, we compare our results to a state-of-the-art motion-compensated lossless video encoder that requires unencrypted video input. The latter compresses each unencrypted frame of the ldquoForemanrdquo test sequence by 59% on average. In comparison, our proof-of-concept implementation, working on encrypted data, compresses the same sequence by 33%. Next, we develop and present an adaptive protocol for universal compression and show that it converges to the entropy rate. Finally, we demonstrate a complete implementation for encrypted video.},
  keywords={},
  doi={10.1109/TIFS.2008.2007244},
  ISSN={1556-6021},
  month={Dec},}
@INPROCEEDINGS{4683127,
  author={James, Jeremiah and Mukhopadhyay, Supratik},
  booktitle={2008 12th IEEE International Workshop on Future Trends of Distributed Computing Systems}, 
  title={The Causal Order is Strict}, 
  year={2008},
  volume={},
  number={},
  pages={140-143},
  abstract={The causal order is central to many algorithms in both the message-passing and shared memory models. In the message-passing model, the causal order is clearly a strict, or irreflexive partial, order. However, some shared memory models are defined without reference to time. In those models, the causal order can fail to be a strict order. Existing works have either declared that all non-strict orders are not causal, or assumed that the causal order is strict without proof. We prove that, under a small number of reasonable assumptions about systems, the causal order is strict. In particular, we assume neither a global time model nor that processes issue a single shared memory operation at a time.},
  keywords={},
  doi={10.1109/FTDCS.2008.33},
  ISSN={1071-0485},
  month={Oct},}
@INPROCEEDINGS{4685804,
  author={Bhateja, Puneet and Mukund, Madhavan},
  booktitle={2008 Sixth IEEE International Conference on Software Engineering and Formal Methods}, 
  title={Tagging Make Local Testing of Message-Passing Systems Feasible}, 
  year={2008},
  volume={},
  number={},
  pages={171-180},
  abstract={The only practical way to test distributed message-passing systems is to use local testing. In this approach, used in formalisms such as concurrent TTCN-3, some components are replaced by test processes. Local testing consists of monitoring the interactions between these test processes and the rest of the system and comparing these observations with the specification, typically described in terms of message sequence charts. The main difficulty with this approach is that local observations can combine in unexpected ways to define implied scenarios not present in the original specification. Checking for implied scenarios is known to be undecidable for regular specifications, even if observations are made for all but one process at a time. We propose an approach where we append tags to the messages generated by the system under test. Our tags are generated in a uniform manner, without referring to or influencing the internal details of the underlying system. These enriched behaviours are then compared against a tagged version of the specification. Our main result is that detecting implied scenarios becomes decidable in the presence of tagging.},
  keywords={},
  doi={10.1109/SEFM.2008.33},
  ISSN={2160-7656},
  month={Nov},}
@INPROCEEDINGS{4690815,
  author={Caron, Eddy and Datta, Ajoy K. and Petit, Franck and Tedeschi, Cedric},
  booktitle={2008 Symposium on Reliable Distributed Systems}, 
  title={Self-Stabilization in Tree-Structured Peer-to-Peer Service Discovery Systems}, 
  year={2008},
  volume={},
  number={},
  pages={207-216},
  abstract={The efficiency of service discovery is critical in the development of fully decentralized middleware intended to manage large scale computational grids. This demand influenced the design of many peer-to-peer based approaches. The ability to cope with the expressiveness of the service discovery was behind the design of a new kind of overlay structures that is based on tries, or prefix trees. Although these overlays are well designed, one of their weaknesses is the lack of any concrete fault tolerant mechanism, especially in dynamic platforms; the faults are handled by using preventive and costly mechanisms, \eg using a high degree of replication. Moreover, those systems cannot handle any arbitrary transient failure. Self-stabilization, which is an efficient approach to designreliable solutions for dynamic systems, was recently suggested to be a good alternative to inject fault-tolerance in peer-to-peer systems. However, most of the previous research on self-stabilization in tree and/or P2P networks was designed in theoretical models, making these approaches hard to implement in practice. In this paper, we provide a self-stabilizing message passing protocol to maintain prefix trees over practical peer-to-peer networks. A complete correctness proof is provided, as well as simulation results to estimate the practical impact of our protocol.},
  keywords={},
  doi={10.1109/SRDS.2008.18},
  ISSN={1060-9857},
  month={Oct},}
@INPROCEEDINGS{4698546,
  author={Tapse, Hrishikesh and Borah, Deva K.},
  booktitle={IEEE GLOBECOM 2008 - 2008 IEEE Global Telecommunications Conference}, 
  title={Performance of Regular Low Density Parity Check Codes over Hybrid Optical/RF Channels}, 
  year={2008},
  volume={},
  number={},
  pages={1-6},
  abstract={A hybrid channel, consisting of a free space optical (FSO) link and a parallel radio frequency (RF) link, is considered. Information bits are first encoded by a low density parity check (LDPC) code and the coded bits are transmitted through both the FSO and the RF links. A density evolution (DE) technique to analyze the convergence of the message passing algorithm at the detector is described for the hybrid channel, and a Gaussian approximation (GA) technique is presented. Numerical results showing the benefits of the hybrid channel are discussed.},
  keywords={},
  doi={10.1109/GLOCOM.2008.ECP.771},
  ISSN={1930-529X},
  month={Nov},}
@INPROCEEDINGS{4700138,
  author={Arunachalan, Bhuvaneswari and Light, Janet},
  booktitle={2008 12th IEEE/ACM International Symposium on Distributed Simulation and Real-Time Applications}, 
  title={Agent-Based Mobile Middleware Architecture (AMMA) for Patient-Care Clinical Data Messaging Using Wireless Networks}, 
  year={2008},
  volume={},
  number={},
  pages={326-329},
  abstract={Mobile messaging in healthcare environment is asynchronous based on real-time events, set of contextual elements such as location of service, resource availability, and guaranteed message delivery. Due to the critical nature of the healthcare delivery system, the mobile messaging has two key issues: reliability of message passing and synchronization of message delivery. AMMA provides solution for reliable asynchronous message passing by implementing an event-based context-centric agent communication protocol, and Mobile Message Passing Protocol with synchronized message delivery using global checkpoint method. In this demo the AMMA, a mobile agent system for reliable clinical data mobile messaging is presented. HL7 clinical document architecture is used for defining agents. AMMA is designed as part of the electronic patient call report (e-PCR) project for the 911- emergency medical services. The demo also includes the e-PCR data capturing tool, the wireless communication protocol and the middleware.},
  keywords={},
  doi={10.1109/DS-RT.2008.50},
  ISSN={1550-6525},
  month={Oct},}
@INPROCEEDINGS{4699192,
  author={Changzheng Gao and Lin Li and Zhibin Zhao and Hongxia Huang},
  booktitle={2008 World Automation Congress}, 
  title={Parallel computation of the large grounding grids in multi-layer soil using moment method}, 
  year={2008},
  volume={},
  number={},
  pages={1-4},
  abstract={A parallel momet method is developed for the computation of large grounding grids in multi-layer soil. All of the time-consuming steps in this method are designed supporting parallel computing on a PC Cluster using message passing interface (MPI). Compared with the experimental results, this method is proved correct and because of the good speedup, it is practical for the analysis of large grounding grids efficiently.},
  keywords={},
  doi={},
  ISSN={2154-4824},
  month={Sep.},}
@INPROCEEDINGS{4651520,
  author={Li, Y. and Jiang, L. and Wu, Q.H. and Jiang, Q.Y. and Cao, Y.J.},
  booktitle={2008 43rd International Universities Power Engineering Conference}, 
  title={Distributed optimal reactive power dispatch based on parallel particle swarm optimisation algorithm}, 
  year={2008},
  volume={},
  number={},
  pages={1-5},
  abstract={This paper presents a parallel particle swarm optimisation (PPSO) approach for solving the distributed optimal reactive power dispatch (ORPD) problem. The proposed method is a combination of parallel computation based on message passing interface (MPI) and particle swarm optimisation algorithm. After dividing a large scale power system into a group of small subsystems, ORPD problem of each subsystem is solved paralleled. Due to the size of each ORPD problem is reduced, it become easier to solve the optimization problem. Results from each subsystem will be combined together to find solution of whole system. The algorithm is evaluated on the IEEE 118 bus test system on two platforms: a PC cluster and a supercomputer. Test results show that the quality of solutions to the ORPD problems is improved and the calculation time can be reduced enormously so as to fulfill the practical requirement for potential application in power systems operation.},
  keywords={},
  doi={10.1109/UPEC.2008.4651520},
  ISSN={},
  month={Sep.},}
@INPROCEEDINGS{4717867,
  author={Pourmahmoud, Solmaz and Asbaghi, Shabnam and Haghighat, Abolfazl T.},
  booktitle={2008 23rd International Symposium on Computer and Information Sciences}, 
  title={A new way of calculating the recovery line through eliminating useless checkpoints in distributed systems}, 
  year={2008},
  volume={},
  number={},
  pages={1-4},
  abstract={Uncoordinated checkpointing protocol is a simple protocol used in many distributed systems for fault tolerance. In this paper, we discuss on the size of rollback it has in the presence of failures. In order to determining the recovery line in checkpoint-based recovery, we first study to common approaches: dependency graph and checkpoint graph and provide some algorithms for these approaches. Then we introduce a new approach for calculating the recovery line and making a graph (independent graph). Finally we present a solution for reducing the cost of graph when calculating the recovery line, particularly when the domino effect is occurred.},
  keywords={},
  doi={10.1109/ISCIS.2008.4717867},
  ISSN={},
  month={Oct},}
@ARTICLE{4723356,
  author={Song, Min and Wang, Jun and Xing, Kai and Park, E. K.},
  journal={IEEE Transactions on Wireless Communications}, 
  title={Interference-aware broadcasting in multi-radio multi-channel mesh networks}, 
  year={2008},
  volume={7},
  number={12},
  pages={5473-5481},
  abstract={A vast number of broadcasting protocols have been developed for wireless networks. To the best of our knowledge, however, most of these protocols assume a single-radio single channel network model and/or a generalized physical model, which does not take into account the impact of interference. In this paper, we present a Distributed Interference-aware Broadcasting (DIB) protocol for multi-radio multi-channel mesh networks. The protocol has two phases. In the first phase, each node constructs a local structure by removing bad links and channels. In the second phase, a high-performance broadcasting tree is built by using message passing procedures. Our research distinguishes itself in a number of ways. First, a multi-radio multi-channel mesh network model is used. Second, comprehensive link and channel quality metrics are defined to fully take into account interferences. Third, four design principles have been identified in the tree building process to combat inter-node and intra-node interferences. Finally, a comprehensive performance metric, called power, is defined which includes reliability, receiving redundancy, latency, and goodput. Analytical and simulation studies verify that the DIB protocol is able to achieve 100% reliability, less broadcasting redundancy, low broadcasting latency, and high goodput.},
  keywords={},
  doi={10.1109/T-WC.2008.071433},
  ISSN={1558-2248},
  month={December},}
@INPROCEEDINGS{4724307,
  author={Fu, Hongyi and Du, Yunfei and Wang, Panfeng and Jia, Jia and Yang, Xuejun},
  booktitle={2008 14th IEEE International Conference on Parallel and Distributed Systems}, 
  title={GiFT: Automating FTPA Implementation for MPI Programs}, 
  year={2008},
  volume={},
  number={},
  pages={91-98},
  abstract={Fault tolerance is a critical issue in the arena of large-scale computing. The fault-tolerant parallel algorithm (FTPA) is an application-level technique for tolerating hardware failures. FTPA achieves fast failure recovery making use of parallel recomputing. However, it complicates the coding of the application program. This paper uses compiler technology to automate the design of FTPA, and introduces the implementation of a tool called GiFT (Get it Fault-Tolerant). GiFT utilizes the extended data-flow analysis to choose the state needed by failure recovery, exploits the parallel recomputing time model to compute the optimal number of recomputing processes, and uses parallelization technologies to generate parallel recomputing codes. The experimental results show that original MPI programs can be transformed into the FTPA counterparts by GiFT correctly, and the performance of GiFT-generated FTPA programs is comparable to the performance of hand-modified FTPA programs.},
  keywords={},
  doi={10.1109/ICPADS.2008.89},
  ISSN={1521-9097},
  month={Dec},}
@INPROCEEDINGS{4724305,
  author={Kahn, Daniel and Rezvoy, Clément and Vivien, Frédéric},
  booktitle={2008 14th IEEE International Conference on Parallel and Distributed Systems}, 
  title={Parallel Large Scale Inference of Protein Domain Families}, 
  year={2008},
  volume={},
  number={},
  pages={72-79},
  abstract={The resolution of combinatorial assortments of protein sequences into domains is a prerequisite for protein sequence interpretation. However the recognition and clustering of homologous domains from sequence databases typically scales quadratically with respect to their size which grows exponentially, making it essential to parallelize these complex bioinformatics applications. Here we demonstrate the parallelization of MKDOM2, the sequential program that has been instrumental in the construction of the PRODOM database of protein domain families. This was challenging because of (1) dependencies between program iterations, (2) their extremely heterogeneous run times and (3) communication bottlenecks that could arise because of the large size of the data. A large scale test of the new program, MPI_MKDOM2, demonstrated its robustness against heterogeneous run times, preparing the grounds for future releases of PRODOM that would otherwise be out of reach with MKDOM2 by several orders of magnitude.},
  keywords={},
  doi={10.1109/ICPADS.2008.115},
  ISSN={1521-9097},
  month={Dec},}
@INPROCEEDINGS{4724355,
  author={Ci, Yi-Wei and Zhang, Zhan and Zuo, De-Cheng and Wu, Zhi-Bo and Yang, Xiao-Zong},
  booktitle={2008 14th IEEE International Conference on Parallel and Distributed Systems}, 
  title={Area Difference Based Recovery Information Placement for Mobile Computing Systems}, 
  year={2008},
  volume={},
  number={},
  pages={478-484},
  abstract={In a mobile computing system, mobile hosts may move around cells, resulting in a considerable cost for locating and retrieving the recovery information, which is necessary for fault tolerance. To speed up the recovery, traditionally, recovery information is migrated according to the location of the mobile host. In this paper, a scheme for efficiently handling the recovery information is proposed. When a mobile host moves out of a certain range, only partial recovery information of the mobile host needs to be migrated to mobile support stations. It can avoid the unnecessary migration of recovery information. Moreover, the performance of the proposed scheme is evaluated and compared with the traditional movement based scheme.},
  keywords={},
  doi={10.1109/ICPADS.2008.79},
  ISSN={1521-9097},
  month={Dec},}
@INPROCEEDINGS{4725152,
  author={Bajpai, Ratan and Dhara, Krishna Kishore and Krishnaswamy, Venkatesh},
  booktitle={2008 IEEE International Symposium on Parallel and Distributed Processing with Applications}, 
  title={QPID: A Distributed Priority Queue with Item Locality}, 
  year={2008},
  volume={},
  number={},
  pages={215-223},
  abstract={Distributed systems have evolved from highly regular systems to irregular systems that are not based on any specific architecture. Highly optimized distributed algorithms that are often variants of classic data structures have been developed for these systems. However, such approaches may not be effective for applications built on loosely coupled irregular distributed systems. In this paper, we look at distributed priority queues for such systems, where the locality of items cannot be altered and bottlenecks at any one node should be avoided. We present QPID, a new distributed priority queue algorithm for irregular distributed systems in which nodes communicate via message passing only. We introduce mechanisms to track and update the head of a logical distributed priority queue without moving items between nodes and avoiding bottlenecks at any single node. A novel lazy update scheme is employed for improving the efficiency of our algorithm. We present our analysis of QPID and argue its correctness.},
  keywords={},
  doi={10.1109/ISPA.2008.90},
  ISSN={2158-9208},
  month={Dec},}
@INPROCEEDINGS{4725645,
  author={Hairui, Wang and Hua, Wang},
  booktitle={2008 International Symposium on Computational Intelligence and Design}, 
  title={Research and Design of Multi-agent Based Intrusion Detection System on Wireless Network}, 
  year={2008},
  volume={1},
  number={},
  pages={444-447},
  abstract={Intrusion detection system in distributed computing is one of the most important ways on wireless network. Although the issue has been argued long since, there is not a perfect solution to it so far. This paper proposed an innovative approach to successfully addressing such issue by multi-agent system The intrusion ways and intrusion connecting of wireless local area network were firstly defined for putting forward the design requests on intrusion detection system of WLAN, a multi-agent based model of a distributed intrusion detection system of WLAN, which is expected to be helpful to the research of the technology of WLAN intrusion detection were defined on the basis of the comparatively ripe technology of intrusion detection. To demonstrate the task execution flow and messages passing among agents, the activity diagram and sequence diagram were also shown. The WIDS model was described in detail. The results validated the feasibility of the proposed approach.},
  keywords={},
  doi={10.1109/ISCID.2008.43},
  ISSN={},
  month={Oct},}
@INPROCEEDINGS{4730615,
  author={Yongzhi Zhu and Yanling Wang and Jing Guo},
  booktitle={2008 9th International Conference on Computer-Aided Industrial Design and Conceptual Design}, 
  title={Application of HPJava in parallel computing}, 
  year={2008},
  volume={},
  number={},
  pages={481-483},
  abstract={The article discusses the application of HPJava language for parallel computing and various rules about use of distributed arrays in HPJava programes. We illustrated how to build a Beowulf system under Linux and HPJava and use matrix multiplication parallel algorithm module design to test this Beowulf system.},
  keywords={},
  doi={10.1109/CAIDCD.2008.4730615},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{4736024,
  author={Oguni, Naoki and Aasai, Hideki},
  booktitle={2008 Electrical Design of Advanced Packaging and Systems Symposium}, 
  title={Estimation of parallel FDTD-based electromagnetic field solver on PC cluster with multi-core CPUs}, 
  year={2008},
  volume={},
  number={},
  pages={159-162},
  abstract={In this paper, the parallel and distributed FDTD (Finite-Difference Time-Domain) -based electromagnetic field solver is implemented on the PC cluster and multi-core CPUs system with MPI(message passing interface). In the FDTD method, the space including the object to be analyzed is divided to an enormous number of meshes. Although in general, the FDTD-based transient simulation is a time consuming task for the large scale space, FDTD method is a suitable technique for parallel computing because the electric and magnetic fields are updated with time progress using only adjacent electromagnetic variables. In this research, some electromagnetic simulations of the 2-D free space are performed by parallel computing method and the validity of this method is verified.},
  keywords={},
  doi={10.1109/EDAPS.2008.4736024},
  ISSN={2151-1233},
  month={Dec},}
@INPROCEEDINGS{4731805,
  author={Saldana, Manuel and Ramalho, Emanuel and Chow, Paul},
  booktitle={2008 International Conference on Reconfigurable Computing and FPGAs}, 
  title={A Message-Passing Hardware/Software Co-simulation Environment to Aid in Reconfigurable Computing Design Using TMD-MPI}, 
  year={2008},
  volume={},
  number={},
  pages={265-270},
  abstract={High-performance reconfigurable computers (HPRC) provide a mix of standard processors and FPGAs to collectively accelerate applications. This introduces new design challenges, such as the need for portable programming models across HPRCs, and system-level verification tools. In this paper, we extend previous work on TMD-MPI to include an MPI-based approach to exchange data between X86 processors and hardware engines inside FPGAs that improves design portability by hiding vendor-specific communication details. Also, we have created a tool called the message-passing simulation framework (MSF) that we use to develop TMD-MPI itself as well as an application development tool that enables an FPGA in simulation to exchange messages with other X86 processors. As an example, we simulate a LINPACK benchmark hardware core using an Intel-FSB-FPGA platform to quickly prototype the hardware, to test the communications and to verify the benchmark results.},
  keywords={},
  doi={10.1109/ReConFig.2008.10},
  ISSN={2325-6532},
  month={Dec},}
@INPROCEEDINGS{4737241,
  author={Yan Zhuang and Dan Xu and Kailong Zhang and Jingui Pan and Jiming Chen},
  booktitle={2008 11th IEEE Singapore International Conference on Communication Systems}, 
  title={QoS-based Adaptive Access Control in Collaborative Virtual Enviroment}, 
  year={2008},
  volume={},
  number={},
  pages={532-537},
  abstract={Collaborative virtual environment (CVE) is a multi-user virtual environment that supports distributed collaboration. The two main issues that CVE is facing are how to improve system scalability and quality of service. Combining Active routing and content-based publish/subscribe and taking bi-directional shared multicast tree as the communication structure of Interest Management, Active interest management (AIM) can effectively improve system scalability. However, due to the lack of network monitoring, it can only provide same services, and consequently cannot guarantee services and alleviate system workload when it gets saturated. In this paper, we propose a QoS-based Adaptive Access control (QAAC) approach which includes dynamic system delay maintenance, active router verification and host low start. By QAAC, we dynamically control the access of hosts based on network status to improve services and scalability in AIM. Finally, experiment results show that this approach can stabilize network traffic, reduce system load and provide better collaboration services.},
  keywords={},
  doi={10.1109/ICCS.2008.4737241},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{4736761,
  author={Matsunaga, Andréa and Tsugawa, Maurício and Fortes, José},
  booktitle={2008 IEEE Fourth International Conference on eScience}, 
  title={CloudBLAST: Combining MapReduce and Virtualization on Distributed Resources for Bioinformatics Applications}, 
  year={2008},
  volume={},
  number={},
  pages={222-229},
  abstract={This paper proposes and evaluates an approach to the parallelization, deployment and management of bioinformatics applications that integrates several emerging technologies for distributed computing. The proposed approach uses the MapReduce paradigm to parallelize tools and manage their execution, machine virtualization to encapsulate their execution environments and commonly used data sets into flexibly deployable virtual machines, and network virtualization to connect resources behind firewalls/NATs while preserving the necessary performance and the communication environment. An implementation of this approach is described and used to demonstrate and evaluate the proposed approach. The implementation integrates Hadoop, Virtual Workspaces, and ViNe as the MapReduce, virtual machine and virtual network technologies, respectively, to deploy the commonly used bioinformatics tool NCBI BLAST on a WAN-based test bed consisting of clusters at two distinct locations, the University of Florida and the University of Chicago. This WAN-based implementation, called CloudBLAST, was evaluated against both non-virtualized and LAN-based implementations in order to assess the overheads of machine and network virtualization, which were shown to be insignificant. To compare the proposed approach against an MPI-based solution, CloudBLAST performance was experimentally contrasted against the publicly available mpiBLAST on the same WAN-based test bed. Both versions demonstrated performance gains as the number of available processors increased, with CloudBLAST delivering speedups of 57 against 52.4 of MPI version, when 64 processors on 2 sites were used. The results encourage the use of the proposed approach for the execution of large-scale bioinformatics applications on emerging distributed environments that provide access to computing resources as a service.},
  keywords={},
  doi={10.1109/eScience.2008.62},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{4753229,
  author={Cole, Chad A.},
  booktitle={MILCOM 2008 - 2008 IEEE Military Communications Conference}, 
  title={Error floor analysis for an ensemble of easily implementable irregular (2048, 1024) LDPC codes}, 
  year={2008},
  volume={},
  number={},
  pages={1-5},
  abstract={The following paper describes a design process for constructing semirandom LDPC codes with characteristics that are suitable for a relatively simple implementation for both the encoding and decoding operation. The paper will focus on two particular code ensembles - both rate-1/2 (2048, 1024) designs with a specified irregular degree distribution. These code parameters were chosen simply because they satisfied a project design constraint, but the process described can be extended to most other low-density designs. Some new insights into the codepsilas performance curve behavior in the low error region under message passing decoding are presented.},
  keywords={},
  doi={10.1109/MILCOM.2008.4753229},
  ISSN={2155-7586},
  month={Nov},}
@INPROCEEDINGS{4755901,
  author={Tucker, Scot and Spetka, Scott and Ramseyer, George and Emeny, Susan and Fitzgerald, Dennis and Linderman, Richard},
  booktitle={2008 DoD HPCMP Users Group Conference}, 
  title={High Performance Information Management for HPC Parallel Computing}, 
  year={2008},
  volume={},
  number={},
  pages={409-412},
  abstract={A new pub/sub/query (PSQ) paradigm has been developed for the information management of high performance computers. The main advantage of PSQ over Message Passing Interface (MPI) is the ability to adapt to dynamically changing requirements. Information management for high performance computing (HPC) applications also coordinates the distribution of data across processing nodes, both for initial data and for intermediate results distribution. Additionally, PSQ exhibits enhanced robustness. A matrix multiplication case study illustrates the advantages of the PSQ software development approach.},
  keywords={},
  doi={10.1109/DoD.HPCMP.UGC.2008.67},
  ISSN={},
  month={July},}
@INPROCEEDINGS{4762048,
  author={Tam, Tran Minh and Ngo, Hung Q. and Lee, Sungyoung and Kim, Miso},
  booktitle={2008 International Conference on Intelligent Sensors, Sensor Networks and Information Processing}, 
  title={Minimum cost hierarchical architecture for correlated data aggregation in sensor networks with mobile access}, 
  year={2008},
  volume={},
  number={},
  pages={557-562},
  abstract={We consider an energy-efficient data aggregation scheme for sensor networks with mobile access (SENMA), a design that opens the possibility of relieving low-power nodes from energy-consuming networking tasks. Specifically, we provide a novel distributed one-hop clustering algorithm to organize the network into a minimum cost hierarchical architecture (MCHA) for collecting all sensing data from the monitored area. For better load balancing and prolonged network lifetime, we exploit the joint effect of clustering and data correlation and provide a trade-off between communication cost and residual energy of sensor nodes. Our algorithm, which employs a message-passing algorithm for solving the min-sum optimization problem, is simple to implement and gives a near-optimal solution within a small number of iterations. Energy efficiency, scalability and robustness of the algorithm are also verified through extensive simulations.},
  keywords={},
  doi={10.1109/ISSNIP.2008.4762048},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{4762373,
  author={Nunes, Daniel and Saldana, Manuel and Chow, Paul},
  booktitle={2008 International Conference on Field-Programmable Technology}, 
  title={A profiler for a heterogeneous multi-core multi-FPGA system}, 
  year={2008},
  volume={},
  number={},
  pages={113-120},
  abstract={Understanding the behavior of an application is rarely a trivial task, due to the complexity of the system in which the application is executed, and the complexity of the application itself. The task becomes even more troublesome, if the application is being run in a parallel environment where relationships between each application execution are needed to grasp the necessary understanding of the application behavior. FPGA flexibility increases the complexity of such tasks by allowing not only changes to the application, to adapt to the hardware, but also to tailor the hardware for a specific application. To take full advantage of these systems, a tool that will help the user to understand an application is paramount. In this paper, we present a profiler for the TMD, a heterogeneous multicore multiFPGA system designed at the University of Toronto. The profiler can be configured for a specific application running on a specific hardware configuration. It allows retrieval of all communication calls and any user state defined by instrumentation of the source code. We test the profiler with two simple case studies: MPI Barrier, where we compare a sequential with a binary tree algorithm, and a heat equation solver that uses the Jacobi iterations method, where we compare blocking with non-blocking MPI calls.},
  keywords={},
  doi={10.1109/FPT.2008.4762373},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{4774198,
  author={Beisel, Tobias and Lietsch, Stefan and Thielemans, Kris},
  booktitle={2008 IEEE Nuclear Science Symposium Conference Record}, 
  title={A method for OSEM PET reconstruction on parallel architectures using STIR}, 
  year={2008},
  volume={},
  number={},
  pages={4161-4168},
  abstract={To accelerate image reconstruction of positron emission tomography (PET) data, we introduced an approach for parallel architectures by applying the message passing paradigm to an existing implementation of the ordered-subsets expectation-maximization (OSEM) algorithm for two- or three-dimensional (2D/3D) PET. To reduce the amount of time needed to complete a reconstruction, a cluster was used as well as different multi-core systems. A main focus was on the multi-core processors, as these systems are increasingly common and easy to use in medical environments.},
  keywords={},
  doi={10.1109/NSSMIC.2008.4774198},
  ISSN={1082-3654},
  month={Oct},}
@INPROCEEDINGS{4797702,
  author={Chilappagari, Shashi Kiran and Nguyen, Dung Viet and Vasic, Bane and Marcellin, Michael W.},
  booktitle={2008 46th Annual Allerton Conference on Communication, Control, and Computing}, 
  title={Girth of the Tanner graph and error correction capability of LDPC codes}, 
  year={2008},
  volume={},
  number={},
  pages={1238-1245},
  abstract={We investigate the relation between the girth and the guaranteed error correction capability of γ-left regular LDPC codes. For column-weight-three codes, we give upper and lower bounds on the number of errors correctable by the Gallager A algorithm. For higher column weight codes, we find the number of variable nodes which are guaranteed to expand by a factor of at least 3γ/4, hence giving a lower bound on the guaranteed correction capability under the bit flipping (serial and parallel) algorithms. We also establish upper bounds by studying the sizes of smallest possible trapping sets.},
  keywords={},
  doi={10.1109/ALLERTON.2008.4797702},
  ISSN={},
  month={Sep.},}
@INPROCEEDINGS{4735357,
  author={Yunfei Mao and Bin Chen and Bihua Zhou and Liwei Cheng and Qun Wu},
  booktitle={2008 8th International Symposium on Antennas, Propagation and EM Theory}, 
  title={Parallel implementation of the split-field FDTD method for the analysis of periodic structure}, 
  year={2008},
  volume={},
  number={},
  pages={875-878},
  abstract={The periodic structure can be analyzed by using the split-field FDTD method. But when the very fine grid is involved, more memory and time are required, sometimes it even canpsilat be calculated on single PC machine. In this paper we present the parallel implementation of the split-field FDTD method based on the message passing interface(MPI), which solves the memory and speed problems, and give out a new method based on the conversation of energy, so as to verify the accuracy and the efficiency. We also compare the results of the serial split-field method with the proposed method.},
  keywords={},
  doi={10.1109/ISAPE.2008.4735357},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{4812880,
  author={Harihara, S.G and Girish Chandra, M. and Uppalapati, Tarakapraveen and Adiga, B.S.},
  booktitle={2008 1st IFIP Wireless Days}, 
  title={Decoding architectures for Projective Geometry based LDPC codes}, 
  year={2008},
  volume={},
  number={},
  pages={1-5},
  abstract={Projective Geometry (PG) based Low Density Parity Check (LDPC) codes have many useful properties, including easy encoding and decoding by simple majority logic technique. With these useful features, they can be useful error control codes in future. In this paper, we present three novel architectures comprising of one parallel and two semi-parallel decoder architectures for popular PG-based LDPC codes. These architectures have no memory clash and further are reconfigurable for different lengths (and their corresponding rates). The three architectures can be configured either for the regular belief propagation based decoding or majority logic decoding (MLD).},
  keywords={},
  doi={10.1109/WD.2008.4812880},
  ISSN={2156-9711},
  month={Nov},}
@INPROCEEDINGS{5214358,
  author={Nisar, Arifa and Liao, Wei-keng and Choudhary, Alok},
  booktitle={SC '08: Proceedings of the 2008 ACM/IEEE Conference on Supercomputing}, 
  title={Scaling parallel I/O performance through I/O delegate and caching system}, 
  year={2008},
  volume={},
  number={},
  pages={1-12},
  abstract={Increasingly complex scientific applications require massive parallelism to achieve the goals of fidelity and high computational performance. Such applications periodically offload checkpointing data to file system for post-processing and program resumption. As a side effect of high degree of parallelism, I/O contention at servers doesn't allow overall performance to scale with increasing number of processors. To bridge the gap between parallel computational and I/O performance, we propose a portable MPI-IO layer where certain tasks, such as file caching, consistency control, and collective I/O optimization are delegated to a small set of compute nodes, collectively termed as I/O Delegate nodes. A collective cache design is incorporated to resolve cache coherence and hence alleviates the lock contention at I/O servers. By using popular parallel I/O benchmark and application I/O kernels, our experimental evaluation indicates considerable performance improvement with a small percentage of compute resources reserved for I/O.},
  keywords={},
  doi={10.1109/SC.2008.5214358},
  ISSN={2167-4337},
  month={Nov},}
@INPROCEEDINGS{5214713,
  author={Swaminarayan, Sriram and Germann, Timothy C. and Kadau, Kai and Fossum, Gordon C.},
  booktitle={SC '08: Proceedings of the 2008 ACM/IEEE Conference on Supercomputing}, 
  title={369 Tflop/s molecular dynamics simulations on the Roadrunner general-purpose heterogeneous supercomputer}, 
  year={2008},
  volume={},
  number={},
  pages={1-10},
  abstract={We present timing and performance numbers for a short-range parallel molecular dynamics (MD) code, SPaSM, that has been rewritten for the heterogeneous Roadrunner supercomputer. Each Roadrunner compute node consists of two AMD Opteron dualcore microprocessors and four PowerXCell 8i enhanced Cell microprocessors, so that there are four MPI ranks per node, each with one Opteron and one Cell. The interatomic forces are computed on the Cells (each with one PPU and eight SPU cores), while the Opterons are used to direct inter-rank communication and perform I/O-heavy periodic analysis, visualization, and checkpointing tasks. The performance measured for our initial implementation of a standard Lennard-Jones pair potential benchmark reached a peak of 369 Tflop/s double-precision floating-point performance on the full Roadrunner system (27.7% of peak), corresponding to 124 MFlop/Watt/s at a price of approximately 3.69 MFlops/dollar. We demonstrate an initial target application, the jetting and ejection of material from a shocked surface.},
  keywords={},
  doi={10.1109/SC.2008.5214713},
  ISSN={2167-4337},
  month={Nov},}
@INPROCEEDINGS{5213771,
  author={Hochstein, Lorin and Shull, Forrest and Reid, Lynn B.},
  booktitle={SC '08: Proceedings of the 2008 ACM/IEEE Conference on Supercomputing}, 
  title={The role of MPI in development time: A case study}, 
  year={2008},
  volume={},
  number={},
  pages={1-10},
  abstract={There is widespread belief in the computer science community that MPI is a difficult and time-intensive approach to developing parallel software. Nevertheless, MPI remains the dominant programming model for HPC systems, and many projects have made effective use of it. It remains unknown how much impact the use of MPI truly has on the productivity of computational scientists. In this paper, we examine a mature, ongoing HPC project, the Flash Center at the University of Chicago, to understand how MPI is used and to estimate the time that programmers spend on MPI-related issues during development. Our analysis is based on an examination of the source code, version control history, and regression testing history of the software. Based on our study, we estimate that about 20% of the development effort is related to MPI. This implies a maximum productivity improvement of 25% for switching to an alternate parallel programming model.},
  keywords={},
  doi={10.1109/SC.2008.5213771},
  ISSN={2167-4337},
  month={Nov},}
@INPROCEEDINGS{5222565,
  author={Saini, Subhash and Talcott, Dale and Jespersen, Dennis and Djomehri, Jahed and Jin, Haoqiang and Biswas, Rupak},
  booktitle={SC '08: Proceedings of the 2008 ACM/IEEE Conference on Supercomputing}, 
  title={Scientific application-based performance comparison of SGI Altix 4700, IBM POWER5+, and SGI ICE 8200 supercomputers}, 
  year={2008},
  volume={},
  number={},
  pages={1-12},
  abstract={The suitability of next-generation high-performance computing systems for petascale simulations will depend on various performance factors attributable to processor, memory, local and global network, and input/output characteristics. In this paper, we evaluate performance of new dual-core SGI Altix 4700, quad-core SGI Altix ICE 8200, and dual-core IBM POWER5+ systems. To measure performance, we used micro-benchmarks from High Performance Computing Challenge (HPCC), NAS Parallel Benchmarks (NPB), and four real-world applications- three from computational fluid dynamics (CFD) and one from climate modeling. We used the micro-benchmarks to develop a controlled understanding of individual system components, then analyzed and interpreted performance of the NPBs and applications. We also explored the hybrid programming model (MPI+OpenMP) using multi-zone NPBs and the CFD application OVERFLOW-2. Achievable application performance is compared across the systems. For the ICE platform, we also investigated the effect of memory bandwidth on performance by testing 1, 2, 4, and 8 cores per node.},
  keywords={},
  doi={10.1109/SC.2008.5222565},
  ISSN={2167-4337},
  month={Nov},}
@INPROCEEDINGS{5222634,
  author={Wang, Chao and Mueller, Frank and Engelmann, Christian and Scott, Stephen L.},
  booktitle={SC '08: Proceedings of the 2008 ACM/IEEE Conference on Supercomputing}, 
  title={Proactive process-level live migration in HPC environments}, 
  year={2008},
  volume={},
  number={},
  pages={1-12},
  abstract={As the number of nodes in high-performance computing environments keeps increasing, faults are becoming common place. Reactive fault tolerance (FT) often does not scale due to massive I/O requirements and relies on manual job resubmission. This work complements reactive with proactive FT at the process level. Through health monitoring, a subset of node failures can be anticipated when one's health deteriorates. A novel process-level live migration mechanism supports continued execution of applications during much of processes migration. This scheme is integrated into an MPI execution environment to transparently sustain health-inflicted node failures, which eradicates the need to restart and requeue MPI jobs. Experiments indicate that 1-6.5 seconds of prior warning are required to successfully trigger live process migration while similar operating system virtualization mechanisms require 13-24 seconds. This self-healing approach complements reactive FT by nearly cutting the number of checkpoints in half when 70% of the faults are handled proactively.},
  keywords={},
  doi={10.1109/SC.2008.5222634},
  ISSN={2167-4337},
  month={Nov},}
@INPROCEEDINGS{5529042,
  author={Jin, Jie and Tsui, Chi-Ying},
  booktitle={Proceeding of the 13th international symposium on Low power electronics and design (ISLPED '08)}, 
  title={A low power layered decoding architecture for LDPC decoder implementation for IEEE 802.11n LDPC codes}, 
  year={2008},
  volume={},
  number={},
  pages={253-258},
  abstract={This paper presents a low power LDPC decoder design based on reducing the amount of memory access. By utilizing the column overlapping of the LDPC parity check matrix, the amount of access for the memory storing the posterior values is minimized. In addition, a thresholding decoding scheme is proposed which reduces the memory access by trading off the error correcting performance. The decoder was implemented in TSMC 0.18μm CMOS process. Experimental results show that for a LDPC decoder targeting for IEEE 802.11n, the power consumption of the memory and the decoder can be reduced by 72% and 24%, respectively.},
  keywords={},
  doi={10.1145/1393921.1393989},
  ISSN={},
  month={Aug},}
@INPROCEEDINGS{5755776,
  author={Craddock, John T. and Flanagan, Mark F. and Fagan, Anthony D.},
  booktitle={7th International ITG Conference on Source and Channel Coding}, 
  title={On a Class of High-Girth LDPC Codes Based on Finite Multidimensional Lattices}, 
  year={2008},
  volume={},
  number={},
  pages={1-6},
  abstract={An LDPC code construction technique is proposed based on the structural properties of finite m-dimensional lattices. The Tanner graph of any code from this class is shown to have a girth of eight, and the number of proper eight-cycles in the graph is enumerated. The minimum distance of the codes is shown to be lower bounded by 2m. The codes are also shown to be highly flexible in terms of code length and rate, and compatible with a low-complexity serial-parallel decoder implementation based on the turbo-decoding message passing algorithm. Finally, simulation results over the AWGN channel demonstrate that these codes have good error-correcting performance.},
  keywords={},
  doi={},
  ISSN={},
  month={Jan},}
@ARTICLE{4633351,
  author={Yang, Xuejun and Yan, Xiaobo and Xing, Zuocheng and Deng, Yu and Jiang, Jiang and Du, Jing and Zhang, Ying},
  journal={IEEE Transactions on Parallel and Distributed Systems}, 
  title={Fei Teng 64 Stream Processing System: Architecture, Compiler, and Programming}, 
  year={2009},
  volume={20},
  number={8},
  pages={1142-1157},
  abstract={The stream architecture is a novel microprocessor architecture with wide application potential. It is critical to study how to use the stream architecture to accelerate scientific computing programs. However, existing stream processors and stream programming languages are not designed for scientific computing. To address this issue, we design and implement a 64-bit stream processor, Fei Teng 64 (FT64), which has a peak performance of 16 Gflops. FT64 supports two kinds of communications, message passing and stream communications, based on which, an interconnection architecture is designed for a FT64-based high-performance computer. This high-performance computer contains multiple modules, with each module containing eight FT64s. We also design a novel stream programming language, stream Fortran 95 (SF95), together with the compiler SF95 compiler, so as to facilitate the development of scientific applications. We test nine typical scientific application kernels on our FT64 platform to evaluate this design. The results demonstrate the effectiveness and efficiency of FT64 and its compiler for scientific computing.},
  keywords={},
  doi={10.1109/TPDS.2008.170},
  ISSN={1558-2183},
  month={Aug},}

@ARTICLE{4633353,
  author={Walters, John Paul and Chaudhary, Vipin},
  journal={IEEE Transactions on Parallel and Distributed Systems}, 
  title={Replication-Based Fault Tolerance for MPI Applications}, 
  year={2009},
  volume={20},
  number={7},
  pages={997-1010},
  abstract={As computational clusters increase in size, their mean time to failure reduces drastically. Typically, checkpointing is used to minimize the loss of computation. Most checkpointing techniques, however, require central storage for storing checkpoints. This results in a bottleneck and severely limits the scalability of checkpointing, while also proving to be too expensive for dedicated checkpointing networks and storage systems. We propose a scalable replication-based MPI checkpointing facility. Our reference implementation is based on LAM/MPI; however, it is directly applicable to any MPI implementation. We extend the existing state of fault-tolerant MPI with asynchronous replication, eliminating the need for central or network storage. We evaluate centralized storage, a Sun-X4500-based solution, an EMC storage area network (SAN), and the Ibrix commercial parallel file system and show that they are not scalable, particularly after 64 CPUs. We demonstrate the low overhead of our checkpointing and replication scheme with the NAS Parallel Benchmarks and the High-Performance LINPACK benchmark with tests up to 256 nodes while demonstrating that checkpointing and replication can be achieved with a much lower overhead than that provided by current techniques. Finally, we show that the monetary cost of our solution is as low as 25 percent of that of a typical SAN/parallel-file-system-equipped storage system.},
  keywords={},
  doi={10.1109/TPDS.2008.172},
  ISSN={1558-2183},
  month={July},}
@ARTICLE{4787613,
  author={Wainwright, Martin J. and Martinian, Emin},
  journal={IEEE Transactions on Information Theory}, 
  title={Low-Density Graph Codes That Are Optimal for Binning and Coding With Side Information}, 
  year={2009},
  volume={55},
  number={3},
  pages={1061-1079},
  abstract={In this paper, we describe and analyze the source and channel coding properties of a class of sparse graphical codes based on compounding a low-density generator matrix (LDGM) code with a low-density parity-check (LDPC) code. Our first pair of theorems establishes that there exist codes from this ensemble, with all degrees remaining bounded independently of block length, that are simultaneously optimal for both channel coding and source coding with binary data when encoding and decoding are performed optimally. More precisely, in the context of lossy compression, we prove that finite-degree constructions can achieve any pair (R, D) on the rate-distortion curve of the binary symmetric source. In the context of channel coding, we prove that the same finite-degree codes can achieve any pair (C, p) on the capacity-noise curve of the binary symmetric channel (BSC). Next, we show that our compound construction has a nested structure that can be exploited to achieve the Wyner-Ziv bound for source coding with side information (SCSI), as well as the Gelfand-Pinsker bound for channel coding with side information (CCSI). Although the results described here are based on optimal encoding and decoding, the proposed graphical codes have sparse structure and high girth that renders them well suited to message passing and other efficient decoding procedures.},
  keywords={},
  doi={10.1109/TIT.2008.2009815},
  ISSN={1557-9654},
  month={March},}
@INPROCEEDINGS{4796465,
  author={Wen Ji and Abe, Yuta and Ikenaga, Takeshi and Goto, Satoshi},
  booktitle={2009 Asia and South Pacific Design Automation Conference}, 
  title={A high performance LDPC decoder for IEEE802.11n standard}, 
  year={2009},
  volume={},
  number={},
  pages={127-128},
  abstract={In this paper, we propose a partially-parallel irregular LDPC decoder for IEEE 802.11n standard. The design is based on a novel sum-delta message passing schedule to achieve high throughput and low area cost design. We further improve the design with pipeline structure and parallel computation. The synthesis result in TSMC 0.18 CMOS technology demonstrates that for (648,324) irregular LDPC code, our decoder achieves 7.5X improvement in throughput, which reaches 402 Mbps at the frequency of 200MHz, with 11% area reduction.},
  keywords={},
  doi={10.1109/ASPDAC.2009.4796465},
  ISSN={2153-697X},
  month={Jan},}
@ARTICLE{4799775,
  author={Chen, Zizhong and Dongarra, Jack},
  journal={IEEE Transactions on Computers}, 
  title={Highly Scalable Self-Healing Algorithms for High Performance Scientific Computing}, 
  year={2009},
  volume={58},
  number={11},
  pages={1512-1524},
  abstract={As the number of processors in today's high-performance computers continues to grow, the mean-time-to-failure of these computers is becoming significantly shorter than the execution time of many current high-performance computing applications. Although today's architectures are usually robust enough to survive node failures without suffering complete system failure, most of today's high-performance computing applications cannot survive node failures. Therefore, whenever a node fails, all surviving processes on surviving nodes usually have to be aborted and the whole application has to be restarted. In this paper, we present a framework for building self-healing high-performance numerical computing applications so that they can adapt to node or link failures without aborting themselves. The framework is based on FT-MPI and diskless checkpointing. Our diskless checkpointing uses weighted checksum schemes, a variation of Reed-Solomon erasure codes over floating-point numbers. We introduce several scalable encoding strategies into the existing diskless checkpointing and reduce the overhead to survive k failures in p processes from 2[log p]. k ((beta + 2gamma) m + alpha) to (1 + O (radic(p)/radic(m)))2. k (beta + 2gamma)m, where alpha is the communication latency, 1/beta is the network bandwidth between processes, {1\over \gamma } is the rate to perform calculations, and m is the size of local checkpoint per process. When additional checkpoint processors are used, the overhead can be reduced to (1 + O (1/radic(m))). k (beta + 2gamma)m, which is independent of the total number of computational processors. The introduced self-healing algorithms are scalable in the sense that the overhead to survive k failures in p processes does not increase as the number of processes p increases. We evaluate the performance overhead of our self-healing approach by using a preconditioned conjugate gradient equation solver as an example. Experimental results demonstrate that our self-healing scheme can survive multiple simultaneous process failures with low-performance overhead and little numerical impact.},
  keywords={},
  doi={10.1109/TC.2009.42},
  ISSN={1557-9956},
  month={Nov},}
@ARTICLE{4803797,
  author={Fresia, M. and Vandendorpe, L. and Poor, H. V.},
  journal={IEEE Transactions on Signal Processing}, 
  title={Distributed Source Coding Using Raptor Codes for Hidden Markov Sources}, 
  year={2009},
  volume={57},
  number={7},
  pages={2868-2875},
  abstract={In this correspondence, the problem of distributed source coding (DSC) of binary sources with side information at the decoder is addressed. A scheme is proposed based on raptor codes which are a new class of rateless codes. The decoding scheme is adapted to this problem by implementing a message passing strategy between the constituent decoders of raptor codes at each decoding iteration. The case in which the sources are modeled as independent and identically distributed (i.i.d) processes as well as the more general case in which the sources are modeled as hidden Markov processes (HMPs) are considered. The proposed approach achieves better performance than those achieved by the solutions based on turbo codes, and by the solutions based on regular low density parity check (LDPC) codes when i.i.d. sources are considered. On the other hand, when modeling sources as HMPs, an additional module to exploit the underlying Markovian nature is necessary to achieve good performance.},
  keywords={},
  doi={10.1109/TSP.2009.2018603},
  ISSN={1941-0476},
  month={July},}
@ARTICLE{4814348,
  author={Dai, Yongmei and Yan, Zhiyuan and Chen, Ning},
  journal={IEEE Transactions on Communications}, 
  title={Memory-efficient and high-throughput decoding of quasi-cyclic LDPC codes}, 
  year={2009},
  volume={57},
  number={4},
  pages={879-883},
  abstract={We propose turbo-sum-product (TSP) and shuffled-sum-product (SSP) decoding algorithms for quasi-cyclic low-density parity-check codes, which not only achieve faster convergence and better error performance than the sum-product algorithm, but also require less memory in partly parallel decoder architectures. Compared with the turbo decoding algorithm, our TSP algorithm saves the same amount of memory and may achieve a higher decoding throughput. The convergence behaviors of our TSP and SSP algorithms are also compared with those of the SP, turbo, and shuffled algorithms by their extrinsic information transfer (EXIT) charts.},
  keywords={},
  doi={10.1109/TCOMM.2009.04.060349},
  ISSN={1558-0857},
  month={April},}
@INPROCEEDINGS{4906490,
  author={Paquin, Jean-Nicolas and Li, Wei and Belanger, Jean and Schoen, Loic and Peres, Irene and Olariu, Cristina and Kohmann, Hugo},
  booktitle={2009 IEEE Electric Ship Technologies Symposium}, 
  title={A modern and open real-time digital simulator of All-Electric Ships with a multi-platform co-simulation approach}, 
  year={2009},
  volume={},
  number={},
  pages={28-35},
  abstract={Designing an all-electric ship (AES) requires testing of the interaction between hundreds of interconnected power electronic subsystems built by different manufacturers. Such integration tests require large analog test benches or the use of actual equipment during system commissioning. Fully digital simulators can also be used to perform Hardware-in-the-Loop (HIL) integration tests to evaluate the performance of some parts of these very complex systems. This approach, in use for decades in the automotive and aerospace industries, can significantly reduce the costs, duration and risks related to the use of actual equipment to conduct integration tests. However the computational power required to conduct detailed simulation of such diverse and numerous power electronic components can only be achieved through the use of distributed parallel supercomputers, optimized for hard real-time performance with jitter in the order of a few microseconds. Such supercomputers have traditionally been built using expensive custom computer boards. This paper presents the technology and performance achieved by the eMEGAsim real-time digital simulator, which is capable of meeting these challenges through the use of standard commercial INTEL quad-core computers interconnected by DOLPHIN SCI communication fabric. The precision achieved in the simulation of a detailed power electronic model implemented with SIMULINK and SimPowerSystems, and executed in parallel with RT-LAB, will also be presented using a typical basic AES configuration. Furthermore, AES design implies the collaboration between several multidisciplinary teams using different tools to simulate all electrical, mechanical and fluid dynamic subsystems. The ORCHESTRA real-time co-simulation publish-and-subscribe framework enabling the integration of multi-domain simulation tools will also be presented.},
  keywords={},
  doi={10.1109/ESTS.2009.4906490},
  ISSN={},
  month={April},}
@ARTICLE{4909063,
  author={Sahuguede, StÉphanie and Julien-Vergonjanne, Anne and Cances, Jean-Pierre},
  journal={Journal of Lightwave Technology}, 
  title={Soft Decision LDPC Decoding Over Chi-Square Based Optical Channels}, 
  year={2009},
  volume={27},
  number={16},
  pages={3540-3545},
  abstract={In this paper, we consider low density parity check (LDPC) codes as a solution to enhance the optical transmission performance. The decoding algorithm based on message passing algorithm uses the probability density function of the received signal. Its efficiency thus depends on the right evaluation of the signal distribution. We do not make here the classical additive white Gaussian noise (AWGN) assumption, but we investigate a chi-square based channel model which is more accurate for the description of optical impairments. As opposed to previous chi-square based models, no assumption on the signal power of 0 and 1 data is done. The calculation of the logarithmic likelihood ratio (LLR) needed to implement soft LDPC decoder is thus developed for a chi-square channel in a general manner. Computer simulations validate the efficiency of the soft decoder for this type of channel. The results also confirm that the adaptation of LDPC decoder to the specific chi-square channel statistic is necessary to obtain the optimal performance.},
  keywords={},
  doi={10.1109/JLT.2009.2022194},
  ISSN={1558-2213},
  month={Aug},}
@INPROCEEDINGS{4912918,
  author={Hermanns, Marc-Andre and Geimer, Markus and Wolf, Felix and Wylie, Brian J.N.},
  booktitle={2009 17th Euromicro International Conference on Parallel, Distributed and Network-based Processing}, 
  title={Verifying Causality between Distant Performance Phenomena in Large-Scale MPI Applications}, 
  year={2009},
  volume={},
  number={},
  pages={78-84},
  abstract={In message-passing applications, the temporal or spatial distance between cause and symptom of a performance problem constitutes a major difficulty in deriving helpful conclusions from performance data. Just knowing the locations of wait states in the program is often insufficient to understand the reason for their occurrence. We present a method for verifying hypotheses on causality between temporally or spatially distant performance phenomena in message-passing applications without altering the application itself. The verification is accomplished by modifying MPI event traces and using them to simulate the hypothetical message-passing behavior. By performing a parallel real-time reenactment of the communication to be simulated using the original execution configuration, we can achieve high scalability and good predictive accuracy in relation to the measured behavior. Not relying on a potentially complex model of the message-passing subsystem, our method is also platform independent.},
  keywords={},
  doi={10.1109/PDP.2009.50},
  ISSN={2377-5750},
  month={Feb},}
@INPROCEEDINGS{4912912,
  author={Leon, Coromoto and Miranda, Gara and Segredo, Eduardo and Segura, Carlos},
  booktitle={2009 17th Euromicro International Conference on Parallel, Distributed and Network-based Processing}, 
  title={Parallel Library of Multi-objective Evolutionary Algorithms}, 
  year={2009},
  volume={},
  number={},
  pages={28-35},
  abstract={ULL∷A-Team tool is a library that provides a skeleton to solve multi-objective optimization problems by applying evolutionary algorithms. In addition to providing sequential implementations of some of the best-known evolutionary algorithms, the skeleton provides great flexibility in obtaining parallel schemes. This flexibility is achieved by specifying configurations that allow the execution of different parallel evolutionary models: homogeneous island-based model, heterogeneous island-based model and self-adaptive island-based model. To solve a particular problem, the user must specify all its properties by defining a set of C++ classes. Additionally, the user can also incorporate new evolutionary algorithms to the tool. This work explains how to carry out this task using IBEA algorithm as a case study. In order to check the contribution of the new algorithm, the computational results obtained for the multi-objective knapsack problem are presented.},
  keywords={},
  doi={10.1109/PDP.2009.38},
  ISSN={2377-5750},
  month={Feb},}
@INPROCEEDINGS{5054784,
  author={Lei, Jing and Yates, Roy and Spasojevic, Predrag and Greenstein, Larry},
  booktitle={2009 43rd Annual Conference on Information Sciences and Systems}, 
  title={Cooperative sensing of primary users in cognitive radio networks based on message passing}, 
  year={2009},
  volume={},
  number={},
  pages={568-573},
  abstract={Opportunistic access to temporarily unused licensed frequency bands has been recognized as a cost-effective solution to mitigate the scarcity of radio spectrum incurred by the proliferation and evolution of wireless devices. In order to accomplish a more efficient spectrum utilization across time, space and frequency. the functionality of spectral awareness is expected to be incorporated into transceivers of cognitive radios (CR) in the foreseeable future. However, the agility requirements imposed on an individual CR might be very stringent since the spectrum has to be monitored on a continuous basis and the spectral holes must be detected reliably in the presence of channel fading and/or hardware failure, especially in a broadband wireless network with multiple primary users. To remedy this problem, light-weight collaboration among CRs becomes attractive since distributed signal processing can exploit the spatial diversity through network cooperation to improve the sensing reliability. To this end, we extend the classical framework for distributed detection of a single user to the case of multiuser detection, and introduce a Tanner graph description of the network topology. We designate the transmission pattern of primaries by a binary space-frequency signature sequence and view all possible patterns collectively as a low-density parity check (LDPC) codebook. Then, we invoke belief propagation message passing algorithm across the entire CR network to infer the unknown pattern iteratively from the noisy observations of all spectrum sensors. Based on the pattern inferred, the fusion centers can determine the spectral and spatial access pattern of secondary users, without interfering with the normal functioning of incumbent primaries.},
  keywords={},
  doi={10.1109/CISS.2009.5054784},
  ISSN={},
  month={March},}
@INPROCEEDINGS{5067592,
  author={Parrot, Christian and Millot, Daniel and Letrou, Christine and Boag, Amir},
  booktitle={2009 3rd European Conference on Antennas and Propagation}, 
  title={A distributed memory MultiLevel fast Physical Optics algorithm}, 
  year={2009},
  volume={},
  number={},
  pages={141-144},
  abstract={The multilevel fast physical optics (MLPO) algorithm attains a computational complexity comparable to that of the fast Fourier transform (FFT) based techniques by using hierarchical domain decomposition and phase compensated interpolation approach. In this communication we present an optimized distributed memory algorithm, obtained by partitioning not only the radiating aperture but also the grid of far field directions. Such a scheme leads to improved speed and reduced memory requirements. The performance of the proposed approach is evaluated in terms of load balance and communication cost, and tested in the context of very large antenna problems.},
  keywords={},
  doi={},
  ISSN={2164-3342},
  month={March},}
@INPROCEEDINGS{5067595,
  author={Gonzalez, Ivan and Tayebi, Abdelhamid and Gomez, Josefa and Catedra, Felipe},
  booktitle={2009 3rd European Conference on Antennas and Propagation}, 
  title={MONURBS, a parallelized moment method code that combines FMLMP, CBF and MPI}, 
  year={2009},
  volume={},
  number={},
  pages={152-156},
  abstract={This paper presents an overview of a new version of computer code MONURBS based on method of moments (MM). The code provides low and high frequency analysis of arbitrary metallic or dielectric 3D structures and it is very useful to design antennas, to analyze antennas on board platforms, electromagnetic compatibility, periodical structures, radomes, etc. The structure under analysis is defined internally by means of non-uniform rational B-splines (NURBS) that can be generated by the most used computer aided geometrical design (CAGD) tools . The program includes a friendly graphical user interface (GUI) where the user can visualize the geometrical model from any point of view, build geometries, set the simulation options, display the results, etc. MONURBS can works on several operating systems and platforms including highly parallelized versions for multiprocessor computers or clusters. Also, the implementation of the optimizer allows robust and efficient electromagnetic optimization for a large number of optimization variables and goals. MONURBS has been validated in many applications and gives accurate predictions compared with measurements. The main features of MONURBS are compared to the characteristics of the most popular electromagnetic commercial solvers.},
  keywords={},
  doi={},
  ISSN={2164-3342},
  month={March},}
@INPROCEEDINGS{5068932,
  author={Ho, Chia-Lu},
  booktitle={2009 Wireless Telecommunications Symposium}, 
  title={Analysis of threshold of regular and irregular LDPC codes using Gaussian approximation}, 
  year={2009},
  volume={},
  number={},
  pages={1-7},
  abstract={We present the formulas for searching for the thresholds of regular and irregular low-density parity-check (LDPC) codes under message-passing (MP) algorithm. A Gaussian approximation is applied to studying the evolution of the means of the messages of the variable nodes and the check nodes. Accurate numerical integration methods by using transformations are shown for evaluating the expected values of the message of the check nodes. Tables are built first and interpolations are used for further evaluations. Two curves are used to locate the threshold. We utilize an iterative decoding tunnel between these two curves and study the decoding performance by evaluating conditions of the derivatives of these two curves. Using this method the performance of both regular and irregular LDPC codes can be studied in a unified manner without using simulation.},
  keywords={},
  doi={10.1109/WTS.2009.5068932},
  ISSN={1934-5070},
  month={April},}
@INPROCEEDINGS{5070852,
  author={Zhan-jun, Li and Yong-zhong, Huang and Shao-zhong, Guo},
  booktitle={2009 Sixth International Conference on Information Technology: New Generations}, 
  title={Using Pi-Calculus to Formalize Grid Workflow Parallel Computing Patterns}, 
  year={2009},
  volume={},
  number={},
  pages={1568-1571},
  abstract={The article analyzed the significance of formalizing grid workflow patterns and the advantage of using the Pi calculus to formalize. After that, it used the pi calculus to formalize the grid workflow patterns. On the foundation of lucubrating basic framework characteristics of grid workflow patterns and pi calculus theory, the paper proposed a rule of formalizing method. This method compared practicably with former ways in describing grid workflow, we can directly make use of the fruit of this paper with mature pi-tools to verify grid workflow system.},
  keywords={},
  doi={10.1109/ITNG.2009.63},
  ISSN={},
  month={April},}
@INPROCEEDINGS{5071380,
  author={Ayres, John and Eisenbach, Susan},
  booktitle={2009 ICSE Workshop on Multicore Software Engineering}, 
  title={Stage: Python with Actors}, 
  year={2009},
  volume={},
  number={},
  pages={25-32},
  abstract={Programmers hoping to exploit multi-core processors must split their applications into threads suitable for independent, concurrent execution. The lock-based concurrency of many existing languages is clumsy and error prone - a barrier to writing fast and correct concurrent code. The Actor model exudes concurrency - each entity in the model (an Actor) executes concurrently. Interaction is restricted to message passing which prevents many of the errors associated with shared mutable state and locking, the common alternative. By favouring message passing over method calling the Actor model makes distribution straightforward. Early Actor-based languages enjoyed only moderate success, probably because they were before their time. More recent Actor languages have enjoyed greater success, the most successful being ERLANG, but the language is functional; a paradigm unfamiliar to many programmers. There is a need for a language that presents a familiar and fast encoding of the Actor model. In this paper we present STAGE, our mobile Actor language based on PYTHON.},
  keywords={},
  doi={10.1109/IWMSE.2009.5071380},
  ISSN={},
  month={May},}
@ARTICLE{5076438,
  author={Holt, Jim and Agarwal, Anant and Brehmer, Sven and Domeika, Max and Griffin, Patrick and Schirrmeister, Frank},
  journal={IEEE Micro}, 
  title={Software Standards for the Multicore Era}, 
  year={2009},
  volume={29},
  number={3},
  pages={40-51},
  abstract={Systems architects commonly use multiple cores to improve system performance. Unfortunately, multicore hardware is evolving faster than software technologies. New multicore software standards are necessary in light of the new challenges and capabilities that embedded multicore systems provide. The newly released multicore communications API standard targets small-footprint, highly efficient intercore and interchip communications.},
  keywords={},
  doi={10.1109/MM.2009.48},
  ISSN={1937-4143},
  month={May},}
@INPROCEEDINGS{5090857,
  author={Kollig, Peter and Osborne, Colin and Henriksson, Tomas},
  booktitle={2009 Design, Automation & Test in Europe Conference & Exhibition}, 
  title={Heterogeneous multi-core platform for consumer multimedia applications}, 
  year={2009},
  volume={},
  number={},
  pages={1254-1259},
  abstract={This paper presents a multi-core SoC architecture for consumer multimedia applications. The comprehensive functionality of such multimedia systems is described using the example of a hybrid TV application. The successful usage of a heterogeneous multi-core SoC platform is presented and it is shown how specific challenges such as inter-processor communication and real-time performance guarantees in physically centralized memory systems are addressed.},
  keywords={},
  doi={10.1109/DATE.2009.5090857},
  ISSN={1558-1101},
  month={April},}
@INPROCEEDINGS{5137147,
  author={Pathak, Rohit and Joshi, Satyadhar and Ahmed, Salman and Mishr, Durgesh},
  booktitle={2009 6th International Conference on Electrical Engineering/Electronics, Computer, Telecommunications and Information Technology}, 
  title={Optimizing HPC and parallelization for computation Nanotechnology in MCCS environment}, 
  year={2009},
  volume={02},
  number={},
  pages={712-715},
  abstract={The essence of High performance computing (HPC) in the field of Nanotechnology and problems encountered by HPC arrangement in applying HPC to Nano-enabled calculations have been presented in the paper. A proposal to optimize computations in an HPC setup and distribution of work in various clusters has been formulated to make Nanotechnology computations more effective and realistic on a Windows Cluster Server based framework. Results and findings in the expected setup and the computation complexities that will be needed in its implementation have been suggested with an algorithm to take advantage of inbuilt powerful parallelization and distribution capabilities of Windows Server 2003 Compute Cluster Edition making large scale simulation possible. Connection of four nodes with the help of Microsoft Compute Cluster Server 2003 (MCCS 2003) has been carried out and algorithms were constructed in C# using Visual Studio IDE. In addition to the .NET Framework, Extreme Optimization Numerical Library for .NET has been used for performing high speed mathematical calculations. MPI .NET library has been employed to build parallel algorithms and breaking of computations into small tasks. Microsoft's implementation of Message Passing Interface (MPI) included in MCCS was used for running computation application tests. Implementation of HPC in measuring reliability of Nanotechnology-based devices and computations of certain complex techniques in Nanotechnology is presented with a significant improvement in performance as compared to the last work which was implemented using distributive computing toolbox in MATLAB. Besides its use in large-scale computations, C# also offers more control over programming, runtime and execution of the application. A description of the progress in this area of research, future works and an extended approach in the same field is shown.},
  keywords={},
  doi={10.1109/ECTICON.2009.5137147},
  ISSN={},
  month={May},}
@INPROCEEDINGS{5158478,
  author={Baldoni, Roberto and Bonomi, Silvia and Kermarrec, Anne-Marie and Raynal, Michel},
  booktitle={2009 29th IEEE International Conference on Distributed Computing Systems}, 
  title={Implementing a Register in a Dynamic Distributed System}, 
  year={2009},
  volume={},
  number={},
  pages={639-647},
  abstract={Providing distributed processes with concurrent objects is a fundamental service that has to be offered by any distributed system. The classical shared read/write register is one of the most basic ones. Several protocols have been proposed that build an atomic register on top of an asynchronous message-passing system prone to process crashes. In the same spirit, this paper addresses the implementation of a regular register (a weakened form of an atomic register) in an asynchronous dynamic message-passing system. The aim is here to cope with the net effect of the adversaries that are asynchrony and dynamicity (the fact that processes can enter and leave the system). The paper focuses on the class of dynamic systems the churn rate c of which is constant. It presents two protocols, one applicable to synchronous dynamic message passing systems, the other one to eventually synchronous dynamic systems. Both protocols rely on an appropriate broadcast communication service (similar to a reliable broadcast). Each requires a specific constraint on the churn rate c. Both protocols are first presented in an as intuitive as possible way, and are then proved correct.},
  keywords={},
  doi={10.1109/ICDCS.2009.46},
  ISSN={1063-6927},
  month={June},}
@INPROCEEDINGS{5158475,
  author={Strom, Rob and Dorai, Chitra and Feng, Thomas Huining and Zheng, Wei},
  booktitle={2009 29th IEEE International Conference on Distributed Computing Systems}, 
  title={Deterministic Replay for Transparent Recovery in Component-Oriented Middleware}, 
  year={2009},
  volume={},
  number={},
  pages={615-622},
  abstract={We present and evaluate a low-overhead approach for achieving high-availability in distributed event-processing middleware systems consisting of networks of stateful software components that communicate by either one-way (send) or two-way (call) messages. The approach is based on transparently augmenting each component to produce a deterministic component whose state can be recovered by checkpoint and replay. Determinism is achieved by augmenting messages with virtual times, and by scheduling message handling in virtual time order. Scheduling delays are reduced by computing virtual times with estimators: deterministic functions that approximate the expected real times of arrival. We describe our algorithms, show how Java components can be transparently augmented with checkpointing code and with good estimators, discuss how our deterministic runtime can be tuned to reduce overhead, and provide experimental results to measure the overhead of determinism relative to non-determinism.},
  keywords={},
  doi={10.1109/ICDCS.2009.79},
  ISSN={1063-6927},
  month={June},}
@INPROCEEDINGS{5161160,
  author={Vardon, P.J. and Banicescu, I. and Cleall, P.J. and Thomas, H.R. and Philp, R.N.},
  booktitle={2009 IEEE International Symposium on Parallel & Distributed Processing}, 
  title={Coupled thermo-hydro-mechanical modelling: A new parallel approach}, 
  year={2009},
  volume={},
  number={},
  pages={1-9},
  abstract={A hybrid MPI/OpenMP method of parallelising a bi-conjugate gradient iterative solver for coupled thermo-hydro-mechanical finite-element simulations in unsaturated soil is implemented and found to be efficient on modern parallel computers. In particular, a new method of parallelisation using a hybrid multi-threaded and message-passing approach depending on calculation size was implemented yielding better performance over more processing units. This was tested on both an Opteron 2218 2.6 GHz Dual-Core processor based system with a Gigabit Ethernet interconnect and an Intel Xeon (Harpertown/Seaburg) 3.0 GHz Quad-Core processor based system with an InfiniBand Connect-X interconnect. The impact of the experimental results reflect on the scalability of field-scale simulations with a higher resolution both spatially and temporally.},
  keywords={},
  doi={10.1109/IPDPS.2009.5161160},
  ISSN={1530-2075},
  month={May},}
@INPROCEEDINGS{5160891,
  author={Hoefler, Torsten and Schneider, Timo and Lumsdaine, Andrew},
  booktitle={2009 IEEE International Symposium on Parallel & Distributed Processing}, 
  title={A power-aware, application-based performance study of modern commodity cluster interconnection networks}, 
  year={2009},
  volume={},
  number={},
  pages={1-7},
  abstract={Microbenchmarks have long been used to assess the performance characteristics of high-performance networks. It is generally assumed that microbenchmark results indicate the parallel performance of real applications. This paper reports the results of performance studies using real applications in a strictly controlled environment with different networks. In particular, we compare the performance of Myrinet and InfiniBand, and analyze them with respect to microbenchmark performance, real application performance and power consumption.},
  keywords={},
  doi={10.1109/IPDPS.2009.5160891},
  ISSN={1530-2075},
  month={May},}
@INPROCEEDINGS{5160893,
  author={Trahay, Francois and Brunet, Elisabeth and Denis, Alexandre},
  booktitle={2009 IEEE International Symposium on Parallel & Distributed Processing}, 
  title={An analysis of the impact of multi-threading on communication performance}, 
  year={2009},
  volume={},
  number={},
  pages={1-7},
  abstract={Although processors become massively multicore and therefore new programming models mix message passing and multi-threading, the effects of threads on communication libraries remain neglected. Designing an efficient modern communication library requires precautions in order to limit the impact of thread-safety mechanisms on performance. In this paper, we present various approaches to building a thread-safe communication library and we study their benefit and impact on performance. We also describe and evaluate techniques used to exploit idle cores to balance the communication library load across multicore machines.},
  keywords={},
  doi={10.1109/IPDPS.2009.5160893},
  ISSN={1530-2075},
  month={May},}
@INPROCEEDINGS{5160892,
  author={Kaiser, Christian and Hoefler, Torsten and Bierbaum, Boris and Bemmerl, Thomas},
  booktitle={2009 IEEE International Symposium on Parallel & Distributed Processing}, 
  title={Implementation and analysis of nonblocking collective operations on SCI networks}, 
  year={2009},
  volume={},
  number={},
  pages={1-7},
  abstract={Nonblocking collective communication operations are currently being considered for inclusion into the MPI standard and are an area of active research. The benefits of such operations are documented by several recent publications, but so far, research concentrates on InfiniBand clusters. This paper describes an implementation of nonblocking collectives for clusters with the Scalable Coherent Interface (SCI) interconnect. We use synthetic and application kernel benchmarks to show that with nonblocking functions for collective communication performance enhancements can be achieved on SCI systems. Our results indicate that for the implementation of these nonblocking collectives data transfer methods other than those usually used for the blocking version should be considered to realize such improvements.},
  keywords={},
  doi={10.1109/IPDPS.2009.5160892},
  ISSN={1530-2075},
  month={May},}
@INPROCEEDINGS{5160935,
  author={Hoefler, Torsten and Traff, Jesper Larsson},
  booktitle={2009 IEEE International Symposium on Parallel & Distributed Processing}, 
  title={Sparse collective operations for MPI}, 
  year={2009},
  volume={},
  number={},
  pages={1-8},
  abstract={We discuss issues in designing sparse (nearest neighbor) collective operations for communication and reduction operations in small neighborhoods for the message passing interface (MPI). We propose three such operations, namely a sparse gather operation, a sparse all-to-all, and a sparse reduction operation in both regular and irregular (vector) variants. By two simple experiments we show a) that a collective handle for message scheduling and communication optimization is necessary for any such interface, b) that the possibly different amount of communication between neighbors need to be taken into account by the optimization, and c) illustrate the improvements that are possible by schedules that possess global information compared to implementations that can rely on only local information. We discuss different forms the interface and optimization handles could take. The paper is inspired by current discussion in the MPI Forum.},
  keywords={},
  doi={10.1109/IPDPS.2009.5160935},
  ISSN={1530-2075},
  month={May},}
@INPROCEEDINGS{5161065,
  author={Stuart, Jeff A. and Owens, John D.},
  booktitle={2009 IEEE International Symposium on Parallel & Distributed Processing}, 
  title={Message passing on data-parallel architectures}, 
  year={2009},
  volume={},
  number={},
  pages={1-12},
  abstract={This paper explores the challenges in implementing a message passing interface usable on systems with data-parallel processors. As a case study, we design and implement the ldquoDCGNrdquo API on NVIDIA GPUs that is similar to MPI and allows full access to the underlying architecture. We introduce the notion of data-parallel thread-groups as a way to map resources to MPI ranks. We use a method that also allows the data-parallel processors to run autonomously from user-written CPU code. In order to facilitate communication, we use a sleep-based polling system to store and retrieve messages. Unlike previous systems, our method provides both performance and flexibility. By running a test suite of applications with different communication requirements, we find that a tolerable amount of overhead is incurred, somewhere between one and five percent depending on the application, and indicate the locations where this overhead accumulates. We conclude that with innovations in chipsets and drivers, this overhead will be mitigated and provide similar performance to typical CPU-based MPI implementations while providing fully-dynamic communication.},
  keywords={},
  doi={10.1109/IPDPS.2009.5161065},
  ISSN={1530-2075},
  month={May},}
@INPROCEEDINGS{5161092,
  author={Dursun, Hikmet and Barker, Kevin J. and Kerbyson, Darren J. and Pakin, Scott},
  booktitle={2009 IEEE International Symposium on Parallel & Distributed Processing}, 
  title={Application profiling on Cell-based clusters}, 
  year={2009},
  volume={},
  number={},
  pages={1-8},
  abstract={In this paper, we present a methodology for profiling parallel applications executing on the IBM PowerXCell 8i (commonly referred to as the ldquoCellrdquo processor). Specifically, we examine Cell-centric MPI programs on hybrid clusters containing multiple Opteron and Cell processors per node such as those used in the petascale Roadrunner system. Our implementation incurs less than 3.2 mus of overhead per profile call while efficiently utilizing the limited local store of the Cell's SPE cores. We demonstrate the use of our profiler on a cluster of hybrid nodes running a suite of scientific applications. Our analyses of inter-SPE communication (across the entire cluster) and function call patterns provide valuable information that can be used to optimize application performance.},
  keywords={},
  doi={10.1109/IPDPS.2009.5161092},
  ISSN={1530-2075},
  month={May},}
@INPROCEEDINGS{5161144,
  author={Chancelier, Jean-Philippe and Lapeyre, Bernard and Lelong, Jerome},
  booktitle={2009 IEEE International Symposium on Parallel & Distributed Processing}, 
  title={Using Premia and Nsp for constructing a risk management benchmark for testing parallel architecture}, 
  year={2009},
  volume={},
  number={},
  pages={1-6},
  abstract={Financial institutions have massive computations to carry out overnight which are very demanding in terms of the consumed CPU. The challenge is to price many different products on a cluster-like architecture. We have used the Premia software to valuate the financial derivatives. In this work, we explain how Premia can be embedded into Nsp, a scientific software like Matlab, to provide a powerful tool to valuate a whole portfolio. Finally, we have integrated an MPI toolbox into Nsp to enable to use Premia to solve a bunch of pricing problems on a cluster. This unified framework can then be used to test different parallel architectures.},
  keywords={},
  doi={10.1109/IPDPS.2009.5161144},
  ISSN={1530-2075},
  month={May},}
@INPROCEEDINGS{5166989,
  author={Vrba, Željko and Halvorsen, Pål and Griwodz, Carsten and Beskow, Paul},
  booktitle={2009 11th IEEE International Conference on High Performance Computing and Communications}, 
  title={Kahn Process Networks are a Flexible Alternative to MapReduce}, 
  year={2009},
  volume={},
  number={},
  pages={154-162},
  abstract={Experience has shown that development using shared-memory concurrency, the  prevalent parallel programming paradigm today, is hard and synchronization  primitives nonintuitive because they are low-level and inherently  nondeterministic. To help developers, we propose Kahn process networks,  which are based on message-passing and shared-nothing model, as a simple and  flexible tool for modeling parallel applications.  We argue that they are  more flexible than MapReduce, which is widely recognized for its efficiency  and simplicity.  Nevertheless, Kahn process networks are equally intuitive  to use, and, indeed, MapReduce is implementable as a Kahn process network.  Our presented benchmarks (word count and k-means) show that a Kahn process  network framework permits alternative implementations that bring significant  performance advantages: the two programs run by a factor of up to $\sim 2.8$  (word-count) and $\sim 1.8$ (k-means) faster than their implementations for  Phoenix, which is a MapReduce framework specifically optimized for executing  on multicore machines.},
  keywords={},
  doi={10.1109/HPCC.2009.46},
  ISSN={},
  month={June},}
@INPROCEEDINGS{5171382,
  author={Tinetti, Fernando G. and Wolfmann, Gustavo},
  booktitle={2009 WRI World Congress on Computer Science and Information Engineering}, 
  title={Parallelization Analysis on Clusters of Multicore Nodes Using Shared and Distributed Memory Parallel Computing Models}, 
  year={2009},
  volume={2},
  number={},
  pages={466-470},
  abstract={This paper presents alternatives and performance results obtained by analyzing parallelization on a cluster of multicore nodes. The ultimate goal is to show if both shared and distributed memory parallel processing models need to be taken into account independently, or if one affects the other and both must be considered simultaneosly. The application used as a testbed is classical in the context of high performance computing: matrix multiplication. Results are shown in terms of the conditions under which performance is optimized and where to focus the parallelization efforts on clusters with nodes with multiple cores, based on experiments combining both kinds of parallel models. In any case, all processing units should be effectively used in order to optimize the performance of parallel applications.},
  keywords={},
  doi={10.1109/CSIE.2009.185},
  ISSN={},
  month={March},}
@ARTICLE{5173473,
  author={Amaral Holbig, Carlos and Asmuz Diverio, Tiaraju and Moraes Claudio, Dalcidio},
  journal={IEEE Latin America Transactions}, 
  title={Parallel Environment with High Accuracy for Resolution of Numerical Problems}, 
  year={2009},
  volume={7},
  number={1},
  pages={114-121},
  abstract={In this paper we describe a high performance environment, like cluster computers, with high accuracy obtained by use of C-XSC library. The C-XSC library is a (free) C++ class library for scientific computing for the development of numerical algorithms delivering highly accurate and automatically verified results by use of the interval arithmetic. These calculus in high accuracy must be available for some basic arithmetic operations, mainly the operations that accomplish the summation and dot product. Because of these aspects, we wish to use the high performance through a cluster environment where we have several nodes executing tasks or calculus. The communication will be done by message passing using the MPI communication library. To obtain the high accuracy in this environment extensions or changes in the parallel programs had done to guarantee that the quality of final result done on cluster, where several nodes collaborate for the final result of the calculus, maintain the same result quality obtained in one sequential high accuracy environment. To validate the environment developed in this work we done basic tests about the dot product, the matrix multiplications, the implementation of interval solvers for banded and dense matrices and the implementation of some numeric methods to solve linear systems with the high accuracy characteristic (some of the methods implemented are used in real life applications like hydrodynamic, agriculture and power electric systems). With these tests we done analysis and comparisons about the performance and accuracy obtained with and without the use of C-XSC library in sequential and parallel programs. With the implementation of these routines and methods will be open a large research field about the study of real life applications that need during their resolution (or in part of their resolution) to calculate arithmetic operations with more accuracy than the accuracy obtained by the traditional computational tools. Our software },
  keywords={},
  doi={10.1109/TLA.2009.5173473},
  ISSN={1548-0992},
  month={March},}
@ARTICLE{5174527,
  author={Zhang, Kai and Huang, Xinming and Wang, Zhongfeng},
  journal={IEEE Journal on Selected Areas in Communications}, 
  title={High-throughput layered decoder implementation for quasi-cyclic LDPC codes}, 
  year={2009},
  volume={27},
  number={6},
  pages={985-994},
  abstract={This paper presents a high-throughput decoder design for the Quasi-Cyclic (QC) Low-Density Parity-Check (LDPC) codes. Two new techniques are proposed, including parallel layered decoding architecture (PLDA) and critical path splitting. PLDA enables parallel processing for all layers by establishing dedicated message passing paths among them. The decoder avoids crossbar-based large interconnect network. Critical path splitting technique is based on articulate adjustment of the starting point of each layer to maximize the time intervals between adjacent layers, such that the critical path delay can be split into pipeline stages. Furthermore, min-sum and loosely coupled algorithms are employed for area efficiency. As a case study, a rate-1/2 2304-bit irregular LDPC decoder is implemented using ASIC design in 90 nm CMOS process. The decoder can achieve the maximum decoding throughput of 2.2 Gbps at 10 iterations. The operating frequency is 950 MHz after synthesis and the chip area is 2.9 mm2.},
  keywords={},
  doi={10.1109/JSAC.2009.090816},
  ISSN={1558-0008},
  month={August},}
@INPROCEEDINGS{5192804,
  author={Rubio, Gines and Guillen, Alberto and Pomares, Hector and Rojas, Ignacio and Paechter, Ben and Glosekotter, Peter and Torres-Ceballos, C. I.},
  booktitle={2009 International Conference on High Performance Computing & Simulation}, 
  title={Parallelization of the nearest-neighbour search and the cross-validation error evaluation for the kernel weighted k-nn algorithm applied to large data dets in matlab}, 
  year={2009},
  volume={},
  number={},
  pages={145-152},
  abstract={The kernel weighted k-nearest neighbours (KWKNN) algorithm is an efficient kernel regression method that achieves competitive results with lower computational complexity than least-squares support vector machines and Gaussian processes. This paper presents the parallel implementation on a cluster platform of the sequential KWKNN implemented in Matlab. This implies both the parallelization of the k nearest-neighbour search and the evaluation of the cross-validation error on a large distributed data set. The results demonstrate the good performances of the implementation.},
  keywords={},
  doi={10.1109/HPCSIM.2009.5192804},
  ISSN={},
  month={June},}
@INPROCEEDINGS{5195312,
  author={Marin, Paolo and Narizzano, Massimo and Giunchiglia, Enrico and Lewis, Matthew and Schubert, Tobias and Becker, Bernd},
  booktitle={2009 International Conference on High Performance Computing & Simulation}, 
  title={Comparison of knowledge sharing strategies in a parallel QBF solver}, 
  year={2009},
  volume={},
  number={},
  pages={161-167},
  abstract={In this paper we examine the effect that different knowledge sharing strategies have on the performance of our parallel QBF Solver PaQuBE. This new Master/Slave MPI based solver leverages the additional computational power that can be exploited from modern computer and system architectures, to solve more relevant instances and faster than previous generation solvers. Knowledge sharing plays a critical role in the performance of PaQuBE. However, due to the overhead associated with sending and receiving MPI messages, and the restricted communication/network bandwidth available between solvers, it is essential that we optimize not only which information is shared, but how it is shared. In this context, we compare multiple conflict clause and solution cube sharing strategies, and finally show that an adaptive method works best. Additionally, compression of solution cubes was explored which reduced the system time associated with message passing while also reducing network traffic.},
  keywords={},
  doi={10.1109/HPCSIM.2009.5195312},
  ISSN={},
  month={June},}
@INPROCEEDINGS{5195956,
  author={Sourlas, Vasilis and Flegkas, Paris and Paschos, Georgios S. and Tassiulas, Leandros},
  booktitle={2009 IFIP/IEEE International Symposium on Integrated Network Management-Workshops}, 
  title={Distribute, store and retrieve management policies in wireless ad-hoc networks using the content delivery publish/subscribe paradigm}, 
  year={2009},
  volume={},
  number={},
  pages={169-176},
  abstract={Policy management is a management paradigm that has been extensively studied for the case of fixed networks but limited work can be found for migrating it to mobile environments. It enables dynamic adaptation of the network behavior to current conditions based on high-level business and operational objectives. Publish/subscribe has become an important architectural style for designing distributed systems and especially for mobile environments due to the loose coupling of the components involved namely the publishers and the subscribers. In this paper, we present a policy-based management system for wireless ad-hoc networks using the publish/subscribe paradigm for distributing policies to the managed nodes ensuring this way that all nodes will receive the related defined policies, in an asynchronous and loosely coupled manner, achieving the desired network-wide behavior. Moreover, we enhance the publish/subscribe system with a novel request/response mechanism for tackling the problem of how newly joined nodes will retrieve previously introduced policies. Finally, we describe our initial design and implementation of the proposed mechanism, evaluate it through simulation and testbed experiments and give pointers to our future work.},
  keywords={},
  doi={10.1109/INMW.2009.5195956},
  ISSN={},
  month={June},}
@INPROCEEDINGS{5200142,
  author={Hangye, Liu and Xuelian, Sui and Jingchun, Zong},
  booktitle={2009 International Conference on Environmental Science and Information Application Technology}, 
  title={Study on Architecture of Photogrammetric Parallel Processing System Based on Cluster Computing}, 
  year={2009},
  volume={1},
  number={},
  pages={378-381},
  abstract={Comparing with the rapidly increasing acquiring technology for remotely sensed data, the data processing technologies have been following behind, especially in computing speed and efficiency. However, parallel computing technology provides an effective way to solve this problem. In this paper, based on the analysis of parallel computing system, the architecture of photogrammetric parallel processing system which is based on cluster computing is studied, and several key techniques such as distributed storage of massive remotely sensed data, design of parallel algorithms and load balancing are discussed.},
  keywords={},
  doi={10.1109/ESIAT.2009.283},
  ISSN={},
  month={July},}
@INPROCEEDINGS{5200019,
  author={Liu, Yongchao and Schmidt, Bertil and Maskell, Douglas L.},
  booktitle={2009 20th IEEE International Conference on Application-specific Systems, Architectures and Processors}, 
  title={MSA-CUDA: Multiple Sequence Alignment on Graphics Processing Units with CUDA}, 
  year={2009},
  volume={},
  number={},
  pages={121-128},
  abstract={Progressive alignment is a widely used approach for computing multiple sequence alignments (MSAs). However, aligning several hundred or thousand sequences with popular progressive alignment tools such as ClustalW requires hours or even days on state-of-the-art workstations. This paper presents MSA-CUDA, a parallel MSA program, which parallelizes all three stages of the ClustalW processing pipeline using CUDA and achieves significant speedups compared to the sequential ClustalW for a variety of large protein sequence datasets. Our tests on a GeForce GTX 280 GPU demonstrate average speedups of 36.91 (for long protein sequences), 18.74 (for average-length protein sequences), and 11.27 (for short protein sequences) compared to the sequential ClustalW running on a Pentium 4 3.0 GHz processor. Our MSA-CUDA outperforms ClustalW-MPI running on 32 cores of a high performance workstation cluster.},
  keywords={},
  doi={10.1109/ASAP.2009.14},
  ISSN={1063-6862},
  month={July},}
@INPROCEEDINGS{5202748,
  author={Koskela, Timo and Lahti, Janne and Pellikka, Jani and Jarvinen, Sari and Peltola, Johannes and Ylianttila, Mika},
  booktitle={2009 IEEE International Conference on Multimedia and Expo}, 
  title={Feasibility evaluation of context distribution in mobile environment}, 
  year={2009},
  volume={},
  number={},
  pages={1330-1333},
  abstract={Although mobile devices are rich sources of context information, the distribution of context in mobile environments is often hindered by the limited battery life, and wireless connections with low bandwidth. In this paper, we present two different implementations that enable context distribution in mobile environments. The first solution relies on a presence service architecture and publish-subscribe messaging, whereas the second solution is based on a mobile Web server architecture where the context information is fetched from the mobile device when needed. This paper evaluates the feasibility of the two implementations in mobile context distribution. The testing results show that the mobile server-based solution sets higher demands for the mobile device capabilities, but is able to provide more up-to-date context information. However, the solution based on the centralized context service provides higher interoperability as it utilizes the existing IETF standards.},
  keywords={},
  doi={10.1109/ICME.2009.5202748},
  ISSN={1945-788X},
  month={June},}
@INPROCEEDINGS{5205781,
  author={Chang, Chi-Yuan and Chen, Yu-Liang and Lee, Chang-Ming and Su, Yu T.},
  booktitle={2009 IEEE International Symposium on Information Theory}, 
  title={New group shuffled BP decoding algorithms for LDPC codes}, 
  year={2009},
  volume={},
  number={},
  pages={1664-1668},
  abstract={Implementing a belief propagation (BP) based LDPC decoder requires high degrees of parallelism using many component soft-in soft-output (SISO) decoding units to perform message passing from variable nodes to check nodes or vice versa. An obvious complexity-reduction solution is to serialize the decoding process, i.e., dividing a decoding iteration into several serial sub-iterations in which a sub-iteration performs only part of the complete parallel message-passing operation. The group horizontal shuffled BP (GHSBP) and vertical shuffled BP (GVSBP) algorithms respectively partition the check and variable nodes of the code graph into groups to perform group-by-group message-passing decoding. This paper proposes new techniques to improve three key elements of a GHSBP decoding algorithm, namely, the grouping method, the decoding schedule and the log-likelihood updating formulae. The (check nodes) grouping method and decoding schedule optimize certain design criterion. The new normalized min-sum updating formula with a self-adjustable correction (scaling) factor offers better nonlinear approximation. Numerical performance of new GHSBP algorithms that include part or all three new techniques indicate that the combination of the proposed grouping and decoding schedule yields a faster convergence rate and our modified min-sum algorithm gives performance superior to that of the conventional min-sum and normalized min-sum algorithm and is very close to that of the sum-product algorithm.},
  keywords={},
  doi={10.1109/ISIT.2009.5205781},
  ISSN={2157-8117},
  month={June},}
@INPROCEEDINGS{5205777,
  author={Johnson, Jason K. and Bickson, Danny and Dolev, Danny},
  booktitle={2009 IEEE International Symposium on Information Theory}, 
  title={Fixing convergence of Gaussian belief propagation}, 
  year={2009},
  volume={},
  number={},
  pages={1674-1678},
  abstract={Gaussian belief propagation (GaBP) is an iterative message-passing algorithm for inference in Gaussian graphical models. It is known that when GaBP converges it converges to the correct MAP estimate of the Gaussian random vector and simple sufficient conditions for its convergence have been established. In this paper we develop a double-loop algorithm for forcing convergence of GaBP. Our method computes the correct MAP estimate even in cases where standard GaBP would not have converged. We further extend this construction to compute least-squares solutions of over-constrained linear systems. We believe that our construction has numerous applications, since the GaBP algorithm is linked to solution of linear systems of equations, which is a fundamental problem in computer science and engineering. As a case study, we discuss the linear detection problem. We show that using our new construction, we are able to force convergence of Montanari's linear detection algorithm, in cases where it would originally fail. As a consequence, we are able to increase significantly the number of users that can transmit concurrently.},
  keywords={},
  doi={10.1109/ISIT.2009.5205777},
  ISSN={2157-8117},
  month={June},}
@INPROCEEDINGS{5206036,
  author={Aggarwal, Vaneet and Youjian Liu and Sabharwal, Ashutosh},
  booktitle={2009 IEEE International Symposium on Information Theory}, 
  title={Message passing in distributed wireless networks}, 
  year={2009},
  volume={},
  number={},
  pages={1090-1094},
  abstract={In distributed wireless networks, nodes often do not know the topology (network size, connectivity and the channel gains) of the network. Thus, they cannot compute their own maximum transmission rate and appropriate transmission scheme. In this paper, we address the inter-related problems of learning the network and the associated best achievable rates. To make progress, we will focus on K-user deterministic interference networks. First, we propose a message passing algorithm which allows nodes to incrementally learn the network topology. In each round of message passing, nodes forward what they believe is the new information to their neighbors and thus the network topology information trickles via broadcasts. Next, we consider two special examples of Z-channel and double-Z interference network and determine the sum-rate points with incomplete network information at different nodes. We show that the sum-rate point can in fact be achieved with less than full information at all the nodes but in general, less network information implies reduced set of achievable rates. In order to analyze the performance of a double-Z interference network with limited information, we find the capacity region of a deterministic double-Z interference network with full information, which is of independent interest.},
  keywords={},
  doi={10.1109/ISIT.2009.5206036},
  ISSN={2157-8117},
  month={June},}
@INPROCEEDINGS{5223117,
  author={Park, Mi-Young and Chung, Sang-Hwa},
  booktitle={2009 Eighth IEEE/ACIS International Conference on Computer and Information Science}, 
  title={Detecting Race Conditions in One-Sided Communication of MPI Programs}, 
  year={2009},
  volume={},
  number={},
  pages={867-872},
  abstract={While one-sided communication introduced in MPI-2 is convenient to access remote memory, it is easier for programmers to make serious errors such as race conditions. Although there are several tools for detecting race conditions in MPI programs, these tools do not provide any mechanism to detect race conditions occurring in one-sided communication. In this paper, we present a technique to detect race conditions caused by unsafe accesses of one-sided operations. Our technique creates a mirror window whenever a process creates a window memory for one-sided communication, and uses it to monitor and detect race conditions. Whenever any one-sided operation accesses a window memory, the corresponding mirror window will be marked and checked to see if the window memory is unsafely accessed by any concurrent operation. In our experiment, we evaluate our technique using two public benchmark programs, and the results show that our technique can precisely detect race conditions. Therefore our technique is effective to detect race conditions in MPI programs and helpful to develop reliable parallel programs.},
  keywords={},
  doi={10.1109/ICIS.2009.170},
  ISSN={},
  month={June},}
@ARTICLE{5233880,
  author={Liu, Chih-Hao and Lin, Chien-Ching and Yen, Shau-Wei and Chen, Chih-Lung and Chang, Hsie-Chia and Lee, Chen-Yi and Hsu, Yar-Sun and Jou, Shyh-Jye},
  journal={IEEE Transactions on Circuits and Systems II: Express Briefs}, 
  title={Design of a Multimode QC-LDPC Decoder Based on Shift-Routing Network}, 
  year={2009},
  volume={56},
  number={9},
  pages={734-738},
  abstract={A reconfigurable message-passing network is proposed to facilitate message transportation in decoding multimode quasi-cyclic low-density parity-check (QC-LDPC) codes. By exploiting the shift-routing network (SRN) features, the decoding messages are routed in parallel to fully support those specific 19 and 3 submatrix sizes defined in IEEE 802.16e and IEEE 802.11n applications with less hardware complexity. A 6.22- mm2 QC-LDPC decoder with SRN is implemented in a 90-nm 1-Poly 9-Metal (1P9M) CMOS process. Postlayout simulation results show that the operation frequency can achieve 300 MHz, which is sufficient to process the 212-Mb/s 2304-bit and 178-Mb/s 1944-bit codeword streams for IEEE 802.16e and IEEE 802.11n systems, respectively.},
  keywords={},
  doi={10.1109/TCSII.2009.2027967},
  ISSN={1558-3791},
  month={Sep.},}
@INPROCEEDINGS{5272157,
  author={Xiong, Congcong and Liu, Xianggang},
  booktitle={2009 First International Conference on Networked Digital Technologies}, 
  title={Study of transplanting MPI applications in grid environments}, 
  year={2009},
  volume={},
  number={},
  pages={552-554},
  abstract={Grid computing brings us a new high performance parallel computing solution. This article introduces the concept of grid computing and the use of MPICH-G2, a implementation of MPI in grid environments. It describes the significations to tranplant MPI applications into globus grid. An example of the mesoscale numerical weather prediction model MM5 is presented, and the test result is attached and analyzed. Finally, a conclusion is brought forward.},
  keywords={},
  doi={10.1109/NDT.2009.5272157},
  ISSN={2155-8736},
  month={July},}
@INPROCEEDINGS{5277322,
  author={Setia, Achint and Swarup, V. Mehar and Kumar, Satish and Singh, Lotika},
  booktitle={2009 IEEE International Conference on Fuzzy Systems}, 
  title={A novel adaptive fuzzy load balancer for heterogeneous LAM/MPI clusters applied to evolutionary learning in neuro-fuzzy systems}, 
  year={2009},
  volume={},
  number={},
  pages={68-73},
  abstract={Load balancing in parallel master-slave implementations on heterogeneous computing clusters is a pressing research problem. Proper load balancing can lead to dramatic speedups in program run times. This paper introduces a novel adaptive fuzzy load balancer which automatically senses cluster state through measurements of node evaluation times and network delays. Measured data are collected within a time window and then clustered using fuzzy c-means clustering. The optimal number of clusters are decided using the Xie-Beni index. Rule base extraction is facilitated by reverse projection of clusters (for antecedents) and a heuristic function (for consequents). Re-clustering is triggered on outlier point detection, and re-validation of clusters is performed depending on an FCM objective function-based cluster scattering threshold. The load balancer is deployed on the master to balance the load between various slaves. The algorithm is tested extensively on an evolutionary-neuro-fuzzy network learning application and implemented in a LAM/MPI computing environment. Results clearly bring out the efficacy of employing the adaptive load balancer in heterogeneous computing environments. Speedups ranging from 42% to 89% are observed when compared to parallel implementations without the fuzzy load balancer, and up to 448% when compared to the serial implementations.},
  keywords={},
  doi={10.1109/FUZZY.2009.5277322},
  ISSN={1098-7584},
  month={Aug},}
@INPROCEEDINGS{5276253,
  author={Hou, Chaojun and Wang, Guoli},
  booktitle={2009 7th Asian Control Conference}, 
  title={Cluster-based Jacobi iteration for distributed regression in wireless sensor networks}, 
  year={2009},
  volume={},
  number={},
  pages={366-371},
  abstract={This paper presents a Jacobi iterative based computational paradigm for solving the data regression in wireless sensor networks (WSNs). The in-network computational scheme is proposed to construct a mixture regression model through the cluster-based Jacobi distributed iteration, where the intersections among mixture structure of regression model are decoupled through a new cluster-based message passing protocol in an energy-efficient fashion. The cluster-based computational scheme proposed here contributes not only to easing network topology management, but also to speeding the convergent rate of distributed computation. Experimental results are reported to illustrate the validation of the proposed approach.},
  keywords={},
  doi={},
  ISSN={},
  month={Aug},}
@INPROCEEDINGS{5280011,
  author={Lange, Robert and Mancoridis, Spiros},
  booktitle={2009 Ninth IEEE International Working Conference on Source Code Analysis and Manipulation}, 
  title={thr2csp: Toward Transforming Threads into Communicating Sequential Processes}, 
  year={2009},
  volume={},
  number={},
  pages={3-12},
  abstract={As multicore and heterogeneous multiprocessor platforms replace uniprocessor systems, software programs must be designed with a greater emphasis on concurrency. Threading has become the dominant paradigm of concurrent computation in the most popular programming languages. Large threaded programs are known to be difficult to implement correctly, comprehend, and maintain, while concurrent programs written in process algebraic paradigms of concurrency, such as communicating sequential processes, are known to be easier to analyze. This paper presents our initial work on reverse engineering threaded source code and transforming the code into functionally-equivalent message-passing code. The paper also explores future work needed to convert the message-passing code into communicating sequential processes.},
  keywords={},
  doi={10.1109/SCAM.2009.10},
  ISSN={},
  month={Sep.},}
@ARTICLE{5281731,
  author={Berrou, Claude and I Amat, Alexandre Graell and Ould-Cheikh-Mouhamedou, Youssouf and Saouter, Yannick},
  journal={IEEE Transactions on Communications}, 
  title={Improving the distance properties of turbo codes using a third component code: 3D turbo codes - [transactions letters]}, 
  year={2009},
  volume={57},
  number={9},
  pages={2505-2509},
  abstract={Thanks to the probabilistic message passing performed between its component decoders, a turbo decoder is able to provide strong error correction close to the theoretical limit. However, the minimum Hamming distance (dmin) of a turbo code may not be sufficiently large to ensure large asymptotic gains at very low error rates (the so-called flattening effect). Increasing the dmin of a turbo code may involve using component encoders with a large number of states, devising more sophisticated internal permutations, or increasing the number of component encoders. This paper addresses the latter option and proposes a modified turbo code in which a fraction of the parity bits are encoded by a rate-1, third encoder. The result is a noticeably increased dmin, which improves turbo decoder performance at low error rates. Performance comparisons with turbo codes and serially concatenated convolutional codes are given.},
  keywords={},
  doi={10.1109/TCOMM.2009.09.070521},
  ISSN={1558-0857},
  month={Sep.},}
@INPROCEEDINGS{5289129,
  author={Lawlor, Orion Sky},
  booktitle={2009 IEEE International Conference on Cluster Computing and Workshops}, 
  title={Message passing for GPGPU clusters: CudaMPI}, 
  year={2009},
  volume={},
  number={},
  pages={1-8},
  abstract={We present and analyze two new communication libraries, cudaMPI and glMPI, that provide an MPI-like message passing interface to communicate data stored on the graphics cards of a distributed-memory parallel computer. These libraries can help applications that perform general purpose computations on these networked GPU clusters. We explore how to efficiently support both point-to-point and collective communication for either contiguous or noncontiguous data on modern graphics cards. Our software design is informed by a detailed analysis of the actual performance of modern graphics hardware, for which we develop and test a simple but useful performance model.},
  keywords={},
  doi={10.1109/CLUSTR.2009.5289129},
  ISSN={2168-9253},
  month={Aug},}
@INPROCEEDINGS{5289163,
  author={Santos, Guna and Fialho, Leonardo and Rexachs, Dolores and Luque, Emilio},
  booktitle={2009 IEEE International Conference on Cluster Computing and Workshops}, 
  title={Increasing the availability provided by RADIC with low overhead}, 
  year={2009},
  volume={},
  number={},
  pages={1-8},
  abstract={For machines composed of a large number of processing units, fault probability tends to increase linearly with this number. This makes the use of a fault tolerant solution a major issue. A fault tolerant solution provides certain level of availability, which is usually influenced by time overhead, performance degradation, resources or cost. In the rollback-recovery protocol, the availability increase is usually achieved by increasing the checkpoint frequency or by making several replicas of checkpoints and/or logs. Such a replication allows the solution to tolerate concurrent correlated faults, i.e., a fault in a computing node and in the stable storage. These faults are theoretically less probable, however recent studies have shown that faults are temporally and spatially correlated, consequently increasing the concurrent fault probability. The major concern replicating the checkpoints and logs is the overhead caused by storing these replicas over various repositories, which may disallow its use. In this paper we present how we increased the availability provided by RADIC, without significantly increase of its overhead. Our approach consists of parallelizing the storing of these replicas using the pipeline technique. Such a technique allows us to make low-overhead copies of checkpoints and logs over N protectors. Furthermore, as secondary benefit, the pipelining between observer and protector reduces more than four times (in the best case) the pessimistic message logging overhead.},
  keywords={},
  doi={10.1109/CLUSTR.2009.5289163},
  ISSN={2168-9253},
  month={Aug},}
@INPROCEEDINGS{5289165,
  author={Goglin, Brice and Furmento, Nathalie},
  booktitle={2009 IEEE International Conference on Cluster Computing and Workshops}, 
  title={Finding a tradeoff between host interrupt load and MPI latency over Ethernet}, 
  year={2009},
  volume={},
  number={},
  pages={1-9},
  abstract={Achieving high-performance message passing on top of generic Ethernet hardware suffers from the NIC interrupt-driven model where coalescing is usually involved. We present an in-depth study of the impact of interrupt coalescing on the Open-MX performance. It shows that disabling coalescing may not be relevant for most metrics except small-message latency. Two new coalescing strategies are then presented so as to efficiently support both latency-friendly and coalescing-friendly workloads thanks to the NIC looking at Open-MX messages and streams before deciding when to raise interrupts. The implementation of these strategies in the firmware of Myri-10G NICs shows that Open-MX is now able to achieve a low small-message latency, a high large-message throughput, and a satisfying message rate without having to manually tune the coalescing delay depending on the benchmark. Real application performance evaluation further shows that our modifications even improve the NAS parallel benchmark IS execution time by 7-8% thanks to our NIC firmware raising up to 20% of additional interrupts at the correct time.},
  keywords={},
  doi={10.1109/CLUSTR.2009.5289165},
  ISSN={2168-9253},
  month={Aug},}
@ARTICLE{5290304,
  author={Sanghavi, Sujay and Shah, Devavrat and Willsky, Alan S.},
  journal={IEEE Transactions on Information Theory}, 
  title={Message Passing for Maximum Weight Independent Set}, 
  year={2009},
  volume={55},
  number={11},
  pages={4822-4834},
  abstract={In this paper, we investigate the use of message-passing algorithms for the problem of finding the max-weight independent set (MWIS) in a graph. First, we study the performance of the classical loopy max-product belief propagation. We show that each fixed-point estimate of max product can be mapped in a natural way to an extreme point of the linear programming (LP) polytope associated with the MWIS problem. However, this extreme point may not be the one that maximizes the value of node weights; the particular extreme point at final convergence depends on the initialization of max product. We then show that if max product is started from the natural initialization of uninformative messages, it always solves the correct LP, if it converges. This result is obtained via a direct analysis of the iterative algorithm, and cannot be obtained by looking only at fixed points. The tightness of the LP relaxation is thus necessary for max-product optimality, but it is not sufficient. Motivated by this observation, we show that a simple modification of max product becomes gradient descent on (a smoothed version of) the dual of the LP, and converges to the dual optimum. We also develop a message-passing algorithm that recovers the primal MWIS solution from the output of the descent algorithm. We show that the MWIS estimate obtained using these two algorithms in conjunction is correct when the graph is bipartite and the MWIS is unique. Finally, we show that any problem of maximum a posteriori (MAP) estimation for probability distributions over finite domains can be reduced to an MWIS problem. We believe this reduction will yield new insights and algorithms for MAP estimation.},
  keywords={},
  doi={10.1109/TIT.2009.2030448},
  ISSN={1557-9654},
  month={Nov},}
@INPROCEEDINGS{5306840,
  author={Khamespanah, Ehsan and Razzazi, Mohamadreza},
  booktitle={SoftCOM 2009 - 17th International Conference on Software, Telecommunications & Computer Networks}, 
  title={Semi-distributed LTL model checking for actor based modeling languages}, 
  year={2009},
  volume={},
  number={},
  pages={265-269},
  abstract={The major difficulty of model checking is state space explosion. Many approaches have been suggested to postpone such explosion to achieve model checking of superior models. Some of these approaches distribute states among grid nodes. Therefore state space size can be enlarged according to the number of grid nodes. Complexity of distributed model checking algorithm and lack of distributed reduction techniques are obstacles of these approaches. In this paper, we introduce semi-distributed model checking algorithm which is developed for actor based modelling languages with asynchronous message passing. Semi-distributed algorithm is a kind of centralized algorithm that stores light weight states in a central node. As a result, the central node can store larger state spaces. Experimental results show substantial improvement for semi-distributed algorithm decreases response time over the past results.},
  keywords={},
  doi={},
  ISSN={},
  month={Sep.},}
@INPROCEEDINGS{5298836,
  author={Hadjikyriacou, Elias and Samaras, Nikolaos and Margaritis, Konstantinos},
  booktitle={2009 13th Panhellenic Conference on Informatics}, 
  title={An Experimental Evaluation of a Parallel Genetic Algorithm Using MPI}, 
  year={2009},
  volume={},
  number={},
  pages={75-79},
  abstract={The aim of this paper is to present an experimental evaluation of a parallel genetic algorithm using MPI. The performance of the algorithm is verified by computational experiments on a real world data set, ran in a cluster of workstations. MPI seems to be appropriate for these kind of experiments as the results are reliable and efficient.},
  keywords={},
  doi={10.1109/PCI.2009.38},
  ISSN={},
  month={Sep.},}
@INPROCEEDINGS{5298708,
  author={Barnat, Jiri and Brim, Lubos and Rockai, Petr},
  booktitle={2009 International Workshop on High Performance Computational Systems Biology}, 
  title={DiVinE 2.0: High-Performance Model Checking}, 
  year={2009},
  volume={},
  number={},
  pages={31-32},
  abstract={We present a tool for parallel enumerative LTL model-checking and reachability analysis. The tool brings model checking to high-powered multi-core systems, as well as high-performance clusters. Boasting pluggable modelling language framework, it is possible to leverage the available parallel algorithms for multiple problem domains, by using suitable input language.},
  keywords={},
  doi={10.1109/HiBi.2009.10},
  ISSN={},
  month={Oct},}
@INPROCEEDINGS{5301321,
  author={Zhou, Wengang and Yang, Jun and Wang, Peng},
  booktitle={2009 5th International Conference on Wireless Communications, Networking and Mobile Computing}, 
  title={VLSI Design for DVB-T2 LDPC Decoder}, 
  year={2009},
  volume={},
  number={},
  pages={1-4},
  abstract={DVB-T2 has adopted powerful LDPC as error correcting codes, which can perform within approximately 1 dB from the Shannon capacity limit, so DVB-S2 has much better communication speed than conventional DVB. In this paper, a low-complexity LDPC decoder for DVB-T2 was designed. With modified layered decoding algorithm, average iterative No. can be decreased by nearly half compared with traditional two-phase message-passing algorithms (TPMP), parallel MDU No. also can be set flexible. When set parallel-ratio=180, system complexity was decreased over 50% compared with conventional 360 parallel-ratio design, whole design have been implemented successfully on Stratix II EP2S130 devices of Altera Corp. Maximum frequency can come to the rate of over 90 MHz, which is significantly sufficient for real-time decoding of DVB-T2 standard.},
  keywords={},
  doi={10.1109/WICOM.2009.5301321},
  ISSN={2161-9654},
  month={Sep.},}
@INPROCEEDINGS{5337016,
  author={Li, Jung-Shian and Yang, Ching-Fang},
  booktitle={2009 IEEE 6th International Conference on Mobile Adhoc and Sensor Systems}, 
  title={Quantum communication in distributed wireless sensor networks}, 
  year={2009},
  volume={},
  number={},
  pages={1024-1029},
  abstract={In the wireless sensor networks (WSNs), sensor nodes may be deployed in the hostile areas. The eavesdropper can intercept the messages in the public channel and the communication between the nodes is easily monitored. Furthermore, any malicious intermediate node can act as a legal receiver to alter the passing messages. Hence, message protection and sensor node identification become important issues in WSN. In this paper, we propose a novel scheme providing unconditional secure communication based on the quantum characteristics, including no-cloning and teleportation. We present a random EPR-pair allocation scheme that is designed to overcome the vulnerability caused by possible compromised nodes. EPR pairs are pre-assigned to sensor nodes randomly and the entangled qubits are used by the nodes with the quantum teleportation scheme to form a secure link. We also show a scheme on how to resist the man-in-the-middle attack. In the framework, the qubits are allocated to each node before deployment and the adversary is unable to create the duplicated nodes. Even if the malicious nodes are added to the network to falsify the messages transmitting in the public channel, the legal nodes can easily detect the fake nodes that have no entangled qubits and verify the counterfeit messages. In addition, we prove that one node sharing EPR pairs with a certain amount of neighbor nodes can teleport information to any node in the sensor network if there are sufficient EPR pairs in the qubits pool. The proposal shows that the distributed quantum wireless sensor network gains better security than classical wireless sensor network and centralized quantum wireless network.},
  keywords={},
  doi={10.1109/MOBHOC.2009.5337016},
  ISSN={2155-6814},
  month={Oct},}
@INPROCEEDINGS{5328431,
  author={Wei, Xiaohui and Li, Hongliang and Li, Dexiong},
  booktitle={2009 Fourth ChinaGrid Annual Conference}, 
  title={MPICH-G-DM: An Enhanced MPICH-G with Supporting Dynamic Job Migration}, 
  year={2009},
  volume={},
  number={},
  pages={67-76},
  abstract={Grid is attracting more and more attentions by its massive computational capacity. Tools like Globus Toolkit and MPICH-G2 have been developed to help scientists to facilitate their researches. As a Grid-enabled implementation of MPI, MPICH-G2 helps developers to port parallel applications to cross-domain environment. Since the current computationally-intensive parallel applications, especially long-running tasks, require high availability as well as high performance computing platform, dynamic job migration in Grid environment has became an essential issue. In this study, we present a dynamic job migration enabled MPICH-G2 version, MPICH-G-DM. We use Virtual Job Model (VJM) to reserve resources for the migrating jobs in advance to improve the efficiency of the system. An Asynchronous Migration Protocol (AMP) is proposed to enable the migrating sub jobs to checkpoint/restart and update their new addresses concurrently without a global synchronization. In order to reduce the communicating overhead of job migration, MPICH-G-DM minimized the number of control messages among domains to O(N). Experiment results show that MPICH-G-DM is effective and reliable.},
  keywords={},
  doi={10.1109/ChinaGrid.2009.9},
  ISSN={1949-1328},
  month={Aug},}
@INPROCEEDINGS{5328326,
  author={Creedon, Eoin and Manzke, Michael},
  booktitle={2009 Sixth IFIP International Conference on Network and Parallel Computing}, 
  title={Impact of Fragmentation Strategy on Ethernet Performance}, 
  year={2009},
  volume={},
  number={},
  pages={30-37},
  abstract={Network fragmentation is the process of splitting a large amount of communication data into smaller fragments that comply with the Maximum Transmission Unit supported by the interconnect. We present a novel fragmentation approach which optimises communication fragmentation based on the amount of data remaining to be exchanged. Our fragmentation approach has up to 30% lower latency when exchanging data <2.MTU bytes across commodity store-and-forward networks than comparable other approaches. The fragmentation algorithm is employed as part of the communication system of a Message Passing FPGA cluster. Algorithm testing has been performed across this system as well as on standard PC computers in production network environments. These configurations show the applicability of the algorithm to real world systems and parallel computing platforms.},
  keywords={},
  doi={10.1109/NPC.2009.15},
  ISSN={},
  month={Oct},}
@INPROCEEDINGS{5336214,
  author={Hu, Wen-Hsiang and Bahn, Jun Ho and Bagherzadeh, Nader},
  booktitle={2009 21st International Symposium on Computer Architecture and High Performance Computing}, 
  title={Parallel LDPC Decoding on a Network-on-Chip Based Multiprocessor Platform}, 
  year={2009},
  volume={},
  number={},
  pages={35-40},
  abstract={Low Density Parity Check (LDPC) code is an error correction code that can achieve performance close to Shannon limit and inherently suitable for parallel implementation. It has been widely adopted in various communication standards such as DVB-S2, WiMAX, and Wi-Fi. However, the irregular message exchange pattern is a major challenge in LDPC decoder implementation In addition, faced with an era that diverse applications are integrated in a single system, a flexible, scalable, efficient and cost-effective implementation of LDPC decoder is highly preferable. In this paper, we proposed a multi-processor platform based on network-on-chip (NoC) interconnect as a solution to these problems. By using a distributed and cooperative way for LDPC decoding, the memory bottleneck commonly seen in LDPC decoder design is eliminated. Simulation results from long LDPC codes with various code rates show good scalability and speedups are obtained by our approach.},
  keywords={},
  doi={10.1109/SBAC-PAD.2009.9},
  ISSN={1550-6533},
  month={Oct},}
@INPROCEEDINGS{5336207,
  author={Kawabata, Celia Leiko Ogawa and Neto, Masaki Kawabata and Coda, Humberto Breves and Venturini, Wilson Sergio},
  booktitle={2009 21st International Symposium on Computer Architecture and High Performance Computing}, 
  title={Finite Element Nodal Approach for Parallel Processing of Non Linear Shell Analysis}, 
  year={2009},
  volume={},
  number={},
  pages={109-116},
  abstract={This study presents a new parallel Finite Element Method (FEM) strategy designed for coarse grain distributed memory systems. The adopted communication protocol is Message Passing Interface (MPI) and tests are carried out in a cluster of PCs. Compressed data structure is used to store the Hessian matrix in order to optimize memory usage and to use the parallel direct solver MUMPS. The new partitioning paradigm is based on structural finite element nodes, not elements (as usually done in references), resulting in an overlapping algorithm, where a reduced amount of information should be allocated and manipulated to integrate finite elements. The main advantage of the nodal partitioning is the performance improvement of the Hessian matrix assembly and the natural ordering to improve the system solution. Numerical examples are shown in order to demonstrate the efficiency and scalability of the proposed algorithm.},
  keywords={},
  doi={10.1109/SBAC-PAD.2009.20},
  ISSN={1550-6533},
  month={Oct},}
@INPROCEEDINGS{5340169,
  author={Sharma, Subodh and Gopalakrishnan, Ganesh and Mercer, Eric},
  booktitle={2009 IEEE International High Level Design Validation and Test Workshop}, 
  title={Dynamic verification of Multicore Communication applications in MCAPI}, 
  year={2009},
  volume={},
  number={},
  pages={100-105},
  abstract={We present a dynamic direct code verification tool called MCC (MCAPI Checker) for applications written in the newly proposed Multicore Communications API (MCAPI). MCAPI provides both message passing and threading constructs, making the concurrent programming involved in MCAPI application development a non-trivial challenge. MCC intercepts MCAPI calls issued by user applications. Then, using a verification scheduler, MCC orchestrates a dependency directed replay of all relevant thread interleavings. This paper presents the technical challenges in handling MCC's non-blocking constructs. This is the first dynamic model checker for MCAPI applications, and as such our work provides designers the opportunity to use a formal design tool in verifying MCAPI applications and evaluating MCAPI itself in the formative stages of MCAPI.},
  keywords={},
  doi={10.1109/HLDVT.2009.5340169},
  ISSN={1552-6674},
  month={Nov},}
@ARTICLE{5336848,
  author={Zhang, Zhengya and Dolecek, Lara and Nikolic, Borivoje and Anantharam, Venkat and Wainwright, Martin J.},
  journal={IEEE Transactions on Communications}, 
  title={Design of LDPC decoders for improved low error rate performance: quantization and algorithm choices}, 
  year={2009},
  volume={57},
  number={11},
  pages={3258-3268},
  abstract={Many classes of high-performance low-density parity-check (LDPC) codes are based on parity check matrices composed of permutation submatrices. We describe the design of a parallel-serial decoder architecture that can be used to map any LDPC code with such a structure to a hardware emulation platform. High-throughput emulation allows for the exploration of the low bit-error rate (BER) region and provides statistics of the error traces, which illuminate the causes of the error floors of the (2048, 1723) Reed-Solomon based LDPC (RS-LDPC) code and the (2209, 1978) array-based LDPC code. Two classes of error events are observed: oscillatory behavior and convergence to a class of non-codewords, termed absorbing sets. The influence of absorbing sets can be exacerbated by message quantization and decoder implementation. In particular, quantization and the log-tanh function approximation in sum-product decoders strongly affect which absorbing sets dominate in the errorfloor region. We show that conventional sum-product decoder implementations of the (2209, 1978) array-based LDPC code allow low-weight absorbing sets to have a strong effect, and, as a result, elevate the error floor. Dually-quantized sum-product decoders and approximate sum-product decoders alleviate the effects of low-weight absorbing sets, thereby lowering the error floor.},
  keywords={},
  doi={10.1109/TCOMM.2009.11.080105},
  ISSN={1558-0857},
  month={Nov},}
@ARTICLE{5336851,
  author={Tapse, Hrishikesh and Borah, Deva K.},
  journal={IEEE Transactions on Communications}, 
  title={Hybrid optical/RF channels: characterization and performance study using low density parity check codes}, 
  year={2009},
  volume={57},
  number={11},
  pages={3288-3297},
  abstract={A hybrid channel, consisting of a free space optical (FSO) link and a parallel radio frequency (RF) link, is considered. The FSO link carries most of the transmitted data while leaving only a small fraction of the data to be carried by the RF link. It is first shown that the capacity of the proposed hybrid structure is much higher than the capacity of a single FSO link. Next the performance of the hybrid channel is studied using a low density parity check code. A density evolution strategy for the hybrid channel is derived and a Gaussian approximation technique is presented. Using these techniques, the conditions for the convergence of the message passing algorithm in terms of minimum data carrying rate through the RF link are derived. Finally, numerical results showing the benefits of the hybrid channel under various channel conditions are presented.},
  keywords={},
  doi={10.1109/TCOMM.2009.11.080170},
  ISSN={1558-0857},
  month={Nov},}
@INPROCEEDINGS{5348281,
  author={Jikeng, Lin and Xudong, Wang and Xinyu, Tong},
  booktitle={2009 International Conference on Sustainable Power Generation and Supply}, 
  title={Asynchronous parallel simulation of transient stability based on equivalence}, 
  year={2009},
  volume={},
  number={},
  pages={1-5},
  abstract={An asynchronous parallel method based on equivalence is proposed for transient stability simulation of power system. In the method, the system is partitioned into several interconnected subsystems by geographical location, and the subsystems are equivalent each other at each integration step. Each subsystem utilizes equivalent information from other subsystems to calculate independently. At each integration step, a subsystem only needs the predictive equivalence and correctional equivalence once. Additionally, asynchronous parallel technology based on the MPI on the PC-Cluster platform is designed to speed up the convergence. Several cases demonstrate that the proposed method has fast calculation speed and efficiency, as well as the simulation precision accepted for engineering application. For some large scale real system, the real-time or even super-real-time simulation will be realized.},
  keywords={},
  doi={10.1109/SUPERGEN.2009.5348281},
  ISSN={2156-969X},
  month={April},}
@INPROCEEDINGS{5350172,
  author={Vacca, Fabrizio and Masera, Guido and Moussa, Hazem and Baghdadi, Amer and Jezequel, Michel},
  booktitle={2009 12th Euromicro Conference on Digital System Design, Architectures, Methods and Tools}, 
  title={Flexible Architectures for LDPC Decoders Based on Network on Chip Paradigm}, 
  year={2009},
  volume={},
  number={},
  pages={582-589},
  abstract={This paper explores the possibility of building a flexible Low Density Parity Check (LDPC) decoder using a network on chip communication infrastructure. Even if this idea is not completely new, previously published works suffered from an excessive area occupation and their practical impact has been very limited. In the following we analyze two possible NOCs specifically designed for the LDPC case. From synthesis results it can be observed how the proposed networks outperform previous implementations in terms of active area with no significant bandwidth loss. Finally to prove the effectiveness of the proposed approach a complete, partially parallel LDPC decoder design is presented and characterized in terms of throughput and area occupation.},
  keywords={},
  doi={10.1109/DSD.2009.235},
  ISSN={},
  month={Aug},}
@INPROCEEDINGS{5351145,
  author={Sharma, Subodh and Gopalakrishnan, Ganesh and Mercer, Eric and Holt, Jim},
  booktitle={2009 Formal Methods in Computer-Aided Design}, 
  title={MCC: A runtime verification tool for MCAPI user applications}, 
  year={2009},
  volume={},
  number={},
  pages={41-44},
  abstract={We present a dynamic verification tool MCC for Multicore Communication API applications - a new API for communication among cores. MCC systematically explores all relevant interleavings of an MCAPI application using a tailor-made dynamic partial order reduction algorithm (DPOR). Our contributions are (i) a way to model the non-overtaking message matching relation underlying MCAPI calls with a high level algorithm to effect DPOR for MCAPI that controls the lower level details so that the intended executions happen at runtime; and (ii) a list of default safety properties that can be utilized in the process of verification. To our knowledge, this is the first push button model checker for MCAPI application writers that, at present, deals with an interesting subset of MCAPI calls. Our result is the demonstration that we can indeed develop a dynamic model checker for MCAPI that can directly control the non-deterministic behavior at runtime that is inherent in any implementation of the library without additional API modifications or additions.},
  keywords={},
  doi={10.1109/FMCAD.2009.5351145},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{5357768,
  author={Wu, Yuping},
  booktitle={2009 IEEE International Conference on Intelligent Computing and Intelligent Systems}, 
  title={Parallel hybrid evolutionary algorithm based on chaos-GA-PSO for SPICE model parameter extraction}, 
  year={2009},
  volume={1},
  number={},
  pages={688-692},
  abstract={SPICE model is one of the key technical connections between the integrated-circuit technology community and the design community. Design community requires accurate SPICE model parameters so as to make the difference between design spec and practical spec minimized as possible. To get accurate model parameters, optimization algorithms are used for parameter extraction. A parallel hybrid evolutionary algorithm based chaos-GA-PSO is presented for SPICE model parameter extraction, which gets leverage of the advantages from chaos algorithm, genetic algorithm, and particle swarm optimization, overcomes their respective disadvantages, passes good individuals among them, avoids local area optimization efficiently, and gets more accurate global optimized parameter extraction results. Also such algorithm based SPICE model parameter extraction architecture is presented with model convergence checking and derivate ability checking supported.},
  keywords={},
  doi={10.1109/ICICISYS.2009.5357768},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{5361259,
  author={Thornquist, Heidi K. and Keiter, Eric R. and Hoekstra, Robert J. and Day, David M. and Boman, Erik G.},
  booktitle={2009 IEEE/ACM International Conference on Computer-Aided Design - Digest of Technical Papers}, 
  title={A parallel preconditioning strategy for efficient transistor-level circuit simulation}, 
  year={2009},
  volume={},
  number={},
  pages={410-417},
  abstract={We describe a parallel computing approach for large-scale SPICE-accurate circuit simulation, which is based on a new strategy for the parallel preconditioned iterative solution of circuit matrices. This strategy consists of several steps, including singleton removal, block triangular form (BTF) reordering, hypergraph partitioning, and a block Jacobi pre-conditioner. Our parallel implementation makes use of a mixed load balance, employing a different parallel partition for the matrix load and solve. Based on message-passing, our circuit simulation code was originally designed for large parallel computers, but for the purposes of this paper we demonstrate that it also gives good parallel speedup in modern multi-core environments. We show that our new parallel solver outperforms a serial direct solver, a parallel direct solver and an alternative iterative solver on a set of circuit test problems.},
  keywords={},
  doi={10.1145/1687399.1687477},
  ISSN={1558-2434},
  month={Nov},}
@INPROCEEDINGS{5361799,
  author={Ouyang, Xiangyong and Gopalakrishnan, Karthik and Panda, Dhabaleswar K.},
  booktitle={2009 International Conference on Parallel Processing}, 
  title={Accelerating Checkpoint Operation by Node-Level Write Aggregation on Multicore Systems}, 
  year={2009},
  volume={},
  number={},
  pages={34-41},
  abstract={Clusters and applications continue to grow in size while their mean time between failure (MTBF) is getting smaller. Checkpoint/restart is becoming increasingly important for large scale parallel jobs. However, the performance of the checkpoint/restart mechanism does not scale well with increasing job size due to constraints within the file system. Furthermore, with the advent of multi-core architecture, the situation is aggravated due to larger number of processes running on the same node, trying to checkpoint simultaneously. This results in increased number of file writes at the time of checkpointing which leads to performance degradation. As a result, deployment of checkpoint/restart mechanisms for large scale parallel applications is limited. In this work, we explore the checkpoint/restart mechanism in MVAPICH2, which uses BLCR as the checkpointing library. Our profiling of the checkpoints for the NAS parallel benchmarks revealed a large number of small file writes interspersed with large writes. Based on these observation we propose to optimize checkpoint creation by classifying checkpoint file writes into small writes, medium writes and large writes based on their size of data to write, and use write aggregation to optimize the small and medium writes. At the aggregation threshold of 512 KB, the implementation of our design in BLCR shows improvements from 27% to 32% over the original BLCR in terms of time cost to checkpoint an MPI application.},
  keywords={},
  doi={10.1109/ICPP.2009.73},
  ISSN={2332-5690},
  month={Sep.},}
@INPROCEEDINGS{5365794,
  author={Liu, Wenjun and Luo, Yufeng},
  booktitle={2009 International Conference on Computational Intelligence and Software Engineering}, 
  title={Cluster Computing and Its Application on Kinematics Analysis of Parallel Manipulator}, 
  year={2009},
  volume={},
  number={},
  pages={1-4},
  abstract={The paper describe a detailed study into the object-oriented design and implementation of distributed and parallel computing environment for the forward kinematics analysis of parallel manipulator on desktop computers cluster using message passing while communication are needed among related computing nodes. The solution routines were blind to whether the objects were local or remote. Numerical tests were carried out and reasonable speed-up was achieved, particularly for direction solution methods. It is concluded that message passing provides a viable mechanism for computing nodes coordination while implementing distributed parallel computing environment based on personal computer(PC) cluster.},
  keywords={},
  doi={10.1109/CISE.2009.5365794},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{5365259,
  author={Wu, Yuping and Chen, Lan and Ye, Tianchun},
  booktitle={2009 International Conference on Computational Intelligence and Software Engineering}, 
  title={Parallel on Analog Circuit Synthesis}, 
  year={2009},
  volume={},
  number={},
  pages={1-5},
  abstract={Analog circuit synthesis is a very important step of analog design automation flow. Due to the great effects on circuit performance degradation from the parasitic, it is a great time-consuming task, especially when the feature size is becoming smaller and smaller, operation frequency is becoming higher and higher, and the circuit scale is becoming larger and larger. In this paper, we present a parallel analog circuit synthesis flow with combination of functionality analysis based circuit partitioning, performance spec decomposition, test bench generation, and performance evaluation equation generation; it makes the high complex large scale circuit synthesis problem become multi low complex circuit synthesis problems of small scales, which enables parallel computing and speeds up the optimization process with full leverage of state-of-art computing resources through efficient task partitioning, management, and scheduling.},
  keywords={},
  doi={10.1109/CISE.2009.5365259},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{5365193,
  author={Nakajima, Kengo},
  booktitle={2009 International Conference on Parallel Processing Workshops}, 
  title={Flat MPI vs. Hybrid: Evaluation of Parallel Programming Models for Preconditioned Iterative Solvers on “T2K Open Supercomputer”}, 
  year={2009},
  volume={},
  number={},
  pages={73-80},
  abstract={In this work, parallel preconditioning methods based on ¿hierarchical interface decomposition (HID)¿ and hybrid parallel programming models were applied to finite-element based simulations of linear elasticity problems in media with heterogeneous material properties. Reverse Cuthill-McKee reordering with cyclic multicoloring (CM-RCM) was applied for parallelism through OpenMP. The developed code has been tested on the ¿T2K open supercomputer (Todai combined cluster)¿ using up to 512 cores. Performance of Hybrid 4 x 4 parallel programming model is competitive with that of flat MPI using appropriate command lines for NUMA control. Furthermore, reordering of the mesh data for contiguous access to memory with first touch data placement provides excellent improvement on performance of Hybrid 8 x 2 and 16 x 1, especially if the problem size for each core is relatively small. Thus, hybrid parallel programming model could be a reasonable choice for large-scale computing of sparse linear solvers on multi-core/multi-socket architectures, such as ¿T2K open supercomputer¿.},
  keywords={},
  doi={10.1109/ICPPW.2009.68},
  ISSN={2332-5690},
  month={Sep.},}
@INPROCEEDINGS{5364252,
  author={Tsuji, Miwako and Sato, Mitsuhisa},
  booktitle={2009 International Conference on Parallel Processing Workshops}, 
  title={Performance Evaluation of OpenMP and MPI Hybrid Programs on a Large Scale Multi-core Multi-socket Cluster, T2K Open Supercomputer}, 
  year={2009},
  volume={},
  number={},
  pages={206-213},
  abstract={Non-uniform memory access (NUMA) systems, where each processor has its own memory, have been popular platform in high-end computing. While some early studies had reported that a flat-MPI programming model outperformed an OpenMP/MPI hybrid programming model on SMP clusters, the hybrid of a shared-memory, thread-based programming and a distributed-memory, message passing programming is considered to be a promising programming model on the multi-core multi-socket NUMA clusters. We explore the performance of the OpenMP/MPI hybrid programming model on a large scale multi-core multi-socket cluster called T2K Open Supercomputer. Both of benchmark (NPB, NAS Parallel Benchmarks) and application (RSDFT, Real-Space Density Function Theory) codes are considered. The hybridization for the RSDFT code is also shown. Our experiments show that the multi-core multi-socket cluster can take advantage of the hybrid programming model when it uses MPI across sockets and OpenMP within sockets.},
  keywords={},
  doi={10.1109/ICPPW.2009.73},
  ISSN={2332-5690},
  month={Sep.},}
@INPROCEEDINGS{5364479,
  author={Berthold, Jost and Marlow, Simon and Hammond, Kevin and Al Zain, Abdallah},
  booktitle={2009 International Conference on Parallel Processing Workshops}, 
  title={Comparing and Optimising Parallel Haskell Implementations for Multicore Machines}, 
  year={2009},
  volume={},
  number={},
  pages={386-393},
  abstract={In this paper, we investigate the differences and tradeoffs imposed by two parallel Haskell dialects running on multicore machines. GpH and Eden are both constructed using the highly-optimising sequential GHC compiler, and share thread scheduling, and other elements, from a common code base. The GpH implementation investigated here uses a physically-shared heap, which should be well-suited to multicore architectures. In contrast, the Eden implementation adopts an approach that has been designed for use on distributed-memory parallel machines: a system of multiple, independent heaps (one per core), with inter-core communication handled by message-passing rather than through shared heap cells. We report two main results. Firstly, we report on the effect of a number of optimisations that we applied to the shared-memory GpH implementation in order to address some performance issues that were revealed by our testing: for example, we implemented a work-stealing approach to task allocation. Our optimisations improved the performance of the shared-heap GpH implementation by as much as 30% on eight cores. Secondly, the shared heap approach is, rather surprisingly, not superior to a distributed heap implementation: both give similar performance results.},
  keywords={},
  doi={10.1109/ICPPW.2009.10},
  ISSN={2332-5690},
  month={Sep.},}
@INPROCEEDINGS{5368724,
  author={Liu, Tiantian and Ma, Zhong and Ou, Zhonghong},
  booktitle={2009 15th IEEE Pacific Rim International Symposium on Dependable Computing}, 
  title={A Novel Process Migration Method for MPI Applications}, 
  year={2009},
  volume={},
  number={},
  pages={247-251},
  abstract={Though a lot of research has been done on fault tolerance for MPI applications, process migration has not gained widespread use because the complexity of the requirement that the knowledge about the location of a migrated process has to be made known to every other process in the MPI application. In this paper, we present a novel and effective process migration method for MPI application. We implement a prototype called LAM/Migration which based on LAM/MPI + BLCR to provide transparent process migration for MPI application and the migration mechanism is built into LAM/MPI. All processes in MPI application including mpirun and MPI processes can be migrated to any different set of spare nodes in cluster under user specified in case of nodes failure in our method. Performance evaluation results showed that the checkpoint overhead is similar to plain LAM/MPI + BLCR, and the migration method is feasible and promising for overcoming nodes failure in large-scale parallel computing. By using LAM/Migration, the high availability and reliability of parallel computation can be achieved.},
  keywords={},
  doi={10.1109/PRDC.2009.46},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{5380884,
  author={Tsugawa, Maurício and Matsunaga, Andréa and Fortes, José},
  booktitle={2009 Fifth IEEE International Conference on e-Science}, 
  title={User-Level Virtual Network Support for Sky Computing}, 
  year={2009},
  volume={},
  number={},
  pages={72-79},
  abstract={With the emergence of multiple cloud providers of Infrastructure-as-a-Service, it becomes possible to envision a near-future when high-performance computing users could combine services from different clouds to access huge numbers of resources. However, as more administrative privileges are exposed to end users, providers are required to deploy network security measures that present challenges to the network virtualization technologies that are needed to enable inter-cloud communication. This paper studies these challenges and proposes techniques to enable unmodified applications on resources across distinct clouds. The techniques are implemented in TinyViNe, an extension to ViNe, a virtual networking technology for distributed resources in different administrative domains. The results of evaluating TinyViNe on a WAN-based testbed across three sites are reported for a bioinformatics application (BLAST) and MPI benchmarks. The results confirm that TinyViNe enables cross-cloud computing while having little impact on application performance. TinyViNe also has auto-configuration and ¿download-and-run¿ capabilities for easy deployment by users who are not knowledgeable about networking.},
  keywords={},
  doi={10.1109/e-Science.2009.19},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{5385120,
  author={Qi, Shen and Yishan, Wang},
  booktitle={2009 International Forum on Computer Science-Technology and Applications}, 
  title={Detection and Analysis of ECG Based on Parallel Computing Technology}, 
  year={2009},
  volume={1},
  number={},
  pages={106-109},
  abstract={In this paper, a parallel model for the detection and analysis of electrocardiogram (ECG) will be defined. First of all, the parameters of digital FIR filter are worked out, with the help of MATLAB. Before any parallel model being defined, the serial algorithms of detection and analysis of ECG are discussed. Then each serial algorithm will be parallelized to build our parallel model. At the end of this paper, an parallel program based on Message Passing Interface (MPI) would be used to validate the parallel model. The parallel computer, which we worked on, is an IBM cluster with 15 nodes. As shown in the experimental results, the efficiency of detection and analysis of ECG will be significantly improved, by using the parallel model.},
  keywords={},
  doi={10.1109/IFCSTA.2009.33},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{5394917,
  author={Chen, Xiaoheng and Huang, Qin and Lin, Shu and Akella, Venkatesh},
  booktitle={2009 47th Annual Allerton Conference on Communication, Control, and Computing (Allerton)}, 
  title={FPGA-based low-complexity high-throughput tri-mode decoder for quasi-cyclic LDPC codes}, 
  year={2009},
  volume={},
  number={},
  pages={600-606},
  abstract={This paper presents an FPGA-based implementation of a tri-mode decoder for decoding the cyclic (4095,3367) Euclidean geometry LDPC code which has minimum distance 65 and no trapping set of size less than 65. The implementation integrates three compatible decoding algorithms in a single decoder. The three decoding algorithms are the one-step majority-logic decoding (OS-MLGD) algorithm and two iterative binary message passing algorithms (IBMP) derived from the OS-MLGD algorithm, one based on soft reliability information and the other on hard reliability information. All three algorithms requires only binary logical operations, integer additions, and single-bit messages, which makes them significantly less complex in terms of hardware requirements than sum-product algorithm, with a very modest loss in performance. The implementation is based on the partially parallel architecture and is optimized to take advantage of the high-speed dual-ported block RAMs in a Xilinx Virtex-4 FPGA. An optimization called memory sharing is introduced to take advantage of the configurable data width (word size) of the block RAMs to accommodate the 262080 edges in the Tanner graph of the (4095,3367) code. A technique is introduced to decode two codewords simultaneously to take advantage of the depth of the block RAMs. As a result, the proposed implementation achieves a throughput of 1.9 Gbps on a Virtex-4 LX160 FPGA and supports bit-error rate simulation down to 10-11 in a day or so.},
  keywords={},
  doi={10.1109/ALLERTON.2009.5394917},
  ISSN={},
  month={Sep.},}
@INPROCEEDINGS{5393602,
  author={Singhal, Gagan and Jain, Abhishek and Patnaik, Amalendu},
  booktitle={2009 World Congress on Nature & Biologically Inspired Computing (NaBIC)}, 
  title={Parallelization of particle swarm optimization using message passing interfaces (MPIs)}, 
  year={2009},
  volume={},
  number={},
  pages={67-71},
  abstract={Motivated by the growing demand of accuracy and low computational time in optimizing functions in various fields of engineering, an approach has been presented using the technique of parallel computing. The parallelization has been carried out on one of the simplest and flexible optimization algorithms, namely the particle swarm optimization (PSO) algorithm. PSO is a stochastic population global optimizer and the initial population may be provided with random values and later convergence may be achieved. The use of message passing interfaces (MPIs) for the parallelization of the asynchronous version of PSO is proposed. In this approach, initial population has been divided between the processors chosen at run time. Numerical values obtained using above approach are at last compared for standard test functions.},
  keywords={},
  doi={10.1109/NABIC.2009.5393602},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{5395291,
  author={Lu, Li and Wang, Xiaoge},
  booktitle={2009 15th International Conference on Parallel and Distributed Systems}, 
  title={A Process Fusion Approach for MPI Performance Enhancement on Multi-core Systems}, 
  year={2009},
  volume={},
  number={},
  pages={967-972},
  abstract={With the growing popularity of multi-core technology, traditional MPI programs are facing great challenges in fully exploit the computing power of this kind of chipsets. In this paper, we change the run time orgnaization of a MPI program and use some newly designed communication methods to enhance the performance of MPI programs on a multicore system without changing the code. We have evaluated the test results and the potential "side effects'' of this technique is discussed in the paper as well. The remarks on the related and possible future research work is also given in the end of the paper.},
  keywords={},
  doi={10.1109/ICPADS.2009.23},
  ISSN={1521-9097},
  month={Dec},}
@INPROCEEDINGS{5395320,
  author={Penoff, Brad and Wagner, Alan and Tüxen, Michael and Rüngeler, Irene},
  booktitle={2009 15th International Conference on Parallel and Distributed Systems}, 
  title={MPI-NeTSim: A Network Simulation Module for MPI}, 
  year={2009},
  volume={},
  number={},
  pages={464-471},
  abstract={Programs that execute in parallel across a network often use the Message Passing Interface (MPI) library for communication. The network requirements of an MPI program are often unclear because of the difficulty in exploring alternative network configurations as well as obtaining packet level information about the communication. MPI-NeTSim is an execution environment to emulate MPI programs on simulated networks to allow users to better explore the impact of the network on the performance of MPI programs. We describe the design of MPI-NeTSim and the integration of OMNeT++’s INET framework into MPICH2’s MPI middleware. We introduce a novel technique for uniformly slowing down the execution of the system to allow the discrete event network simulator to keep up with the execution and provide a consistent view of the communication. We validate our technique with synthetic programs as well as the standard NAS benchmarks. We demonstrate MPI-NeTSim’s usefulness in analyzing the effect of the network on communication by using our environment to study the impact of a slow-link on the NAS benchmarks.},
  keywords={},
  doi={10.1109/ICPADS.2009.116},
  ISSN={1521-9097},
  month={Dec},}
@INPROCEEDINGS{5395359,
  author={Shen, Siqi and Wang, Ji and Shen, Rui and Zhang, Shengdong and Fan, Pei},
  booktitle={2009 15th International Conference on Parallel and Distributed Systems}, 
  title={Mobility of Internet-Based Virtual Computing Environment}, 
  year={2009},
  volume={},
  number={},
  pages={770-775},
  abstract={The Internet-based Virtual Computing Environment (iVCE) provides on-demand aggregation and autonomic collaboration mechanisms to facilitate the utilization of autonomous and dynamic Internet resources. Load balancing and fault tolerance are important issues when scheduling those transient resources. In this paper, we propose a mobility mechanism for the migration of various roles of agents in the iVCE platform. The mobility mechanism involves two parts of the iVCE platform: role container layer and event service layer. At the role container layer, a novel approach is proposed to handle the code and data mobility issue. At the event service layer, an efficient routing reconfiguration protocol is proposed based on a publish/subscribe system over DHTs to facilitate task migrations. Certain conditions must be satisfied before the migration of an agent to ensure the correctness of the whole process. Experiments are conducted to evaluate the performance of the mobility mechanism, and the experimental results show that it is suitable for implementing load balancing and fault tolerance in the iVCE.},
  keywords={},
  doi={10.1109/ICPADS.2009.136},
  ISSN={1521-9097},
  month={Dec},}
@INPROCEEDINGS{5407301,
  author={Sultana, Shamima and Jabiullah, Md. Ismail and Rahman, Md. Lutfar},
  booktitle={2009 12th International Conference on Computers and Information Technology}, 
  title={Improved Needham-Schroeder protocol for secured and efficient key distributions}, 
  year={2009},
  volume={},
  number={},
  pages={564-569},
  abstract={A key distribution procedure is an essential constituent of secured exchange of information between the participants. In this paper, a fast symmetric key distribution technique with additional security services is presented. The aim of the proposed technique is to improve the conventional Needham and Schroeder five-message protocol in four aspects. First aspect is to introduce an additional authentication level in originator's identity. Second aspect is to provide the integrity of the originator's message. Third aspect is to reduce the time needed to distribute session-key between pair of entities. And the fourth aspect is to develop the key freshness security issue. A comparative analysis between conventional and proposed technique is presented to visualize the improvements of the proposed one. C programming language is used to implement the technique and running time is measured by using the time function and it is found that proposed technique is faster than the conventional one. For the purpose of threat analysis, several attacks, such as altering the message information, are applied by force on the proposed technique to check whether it will provide the security services or not. And the result of threat analysis is that the proposed technique provides all the security services. Hence, the proposed technique will bring a new dimension in key distribution paradigm.},
  keywords={},
  doi={10.1109/ICCIT.2009.5407301},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{5420193,
  author={Junior, Augusto Mendes Gomes and Kakugawa, Fernando Ryoji and de Paula Bianchini, Calebe and Massetto, Francisco Isidro},
  booktitle={2009 Joint Conferences on Pervasive Computing (JCPC)}, 
  title={A thread-safe communication mechanism for message-passing interface based on MPI Standard}, 
  year={2009},
  volume={},
  number={},
  pages={173-178},
  abstract={Current high-performance applications development is increasing due to breakthrough advances in microprocessor and power management technologies, network speed and reliability. By this way, distributed parallel applications make use of message-passing interface and multithreaded programming libraries. Nevertheless, drawbacks in message-passing implementations limit the use of thread-safe network communication. This paper presents a thread-safe message-passing interface based on MPI Standard assuring correct message ordering and sender/receiver synchronization.},
  keywords={},
  doi={10.1109/JCPC.2009.5420193},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{5442699,
  author={Pandey, Seema N. and Tapaswi, S. and Srivastava, Laxmi},
  booktitle={2009 International Conference on Power Systems}, 
  title={System ATC estimation using Distributed Computing}, 
  year={2009},
  volume={},
  number={},
  pages={1-6},
  abstract={Accurate and instant information about available transfer capability (ATC) is important in competitive electric power markets for providing non discriminatory open access transmission facility. ATC information conveys how much power can be transmitted through the power network over and above already committed uses. This paper presents, a Levenberg-Marquardt algorithm based neural network (LMANN) approach for fast and accurate estimation of system ATC with Distributed Computing. Effective input variables for neural network have been selected using entropy concept. For accurate estimation of ATC various contingency clusters were formed using Euclidean distance based clustering technique. For each contingency cluster separate LMANNs have been developed. All the proposed LMANNs have been trained and tested under distributed computing environment and a significant speed up in the training is obtained. The proposed approach has been examined on IEEE - 30 bus test system and found significantly efficient.},
  keywords={},
  doi={10.1109/ICPWS.2009.5442699},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{5449721,
  author={Ismail, Mohamed and Coon, Justin and Ahmed, Imran and Armour, Simon and Kocak, Taskin},
  booktitle={2009 IEEE 20th International Symposium on Personal, Indoor and Mobile Radio Communications}, 
  title={High throughput layered decoding of LDPC codes}, 
  year={2009},
  volume={},
  number={},
  pages={1727-1731},
  abstract={Layered decoding of Low Density Parity Check (LDPC) codes has been shown to give faster convergence and use less storage than the conventional Two Phase Message Passing (TPMP) algorithm in decoding such codes. To achieve higher throughput, multiple rows of the parity check matrix may be decoded in parallel, as in the Parallel-Turbo Decoding Message Passing (P-TDMP) algorithm. However, contention for globally shared memory permits only a subset of rows to be decoded in parallel thus limiting overall throughput. This paper uses a near optimal scheduling algorithm, based on graph colouring, to overcome memory contention, allowing processing of multiple rows without code modification, resulting in significant throughput gains over the standard P-TDMP algorithm. For the LDPC codes studied, throughput gains compared to the P-TDMP algorithm, of between ten and fifteen are shown to be possible.},
  keywords={},
  doi={10.1109/PIMRC.2009.5449721},
  ISSN={2166-9589},
  month={Sep.},}
@INPROCEEDINGS{5455343,
  author={Liu, Wenjun and Wang, Rongqiao},
  booktitle={2009 First International Conference on Information Science and Engineering}, 
  title={Parallel Computing Based Finite Element Analysis}, 
  year={2009},
  volume={},
  number={},
  pages={295-298},
  abstract={The paper describe a detailed study into the object-oriented design and implementation of distributed and parallel computing environment for Finite element analysis of parallel manipulator on desktop computers cluster using message passing while communication are needed among related computing nodes. The solution routines were blind to whether the objects were local or remote. Numerical tests were carried out and reasonable speed-up was achieved, particularly for direction solution methods. It is concluded that message passing provides a viable mechanism for computing nodes coordination while implementing distributed parallel computing environment based on personal computer (PC) cluster.},
  keywords={},
  doi={10.1109/ICISE.2009.818},
  ISSN={2160-1291},
  month={Dec},}
@INPROCEEDINGS{5455782,
  author={Chen, Qing-kui and Zhang, Jia-kang},
  booktitle={2009 First International Conference on Information Science and Engineering}, 
  title={A Stream Processor Cluster Architecture Model with the Hybrid Technology of MPI and CUDA}, 
  year={2009},
  volume={},
  number={},
  pages={86-89},
  abstract={Nowadays, the compute capability of traditional cluster system can't keep up with the computing needs of a practical application, and these aspects of energy, space technology, etc. have become a huge problem. However, as parallel computing equipment, the stream processor (SP) has a high performance of floating-point operations. NVIDIA GPUs is a typical stream processor device, CUDA technology enables the way to develop a better parallel program on GPUs to become flexible. In this paper, we make use of the hybrid parallel computing programming environment (HPCPE) with MPI and CUDA technology to build the simple CPU + GPU-based stream processor cluster system. In addition, we also proposed the "Two Level Model (TLM)" to separate the intensive computing tasks and controlling tasks, and exploit the compute capability of contemporary GPUs to accelerate computing tasks. Finally, we conducted a relevant experiment about the calculation of N-Body problem, and verified the better performance that stream processor cluster system has than the traditional one.},
  keywords={},
  doi={10.1109/ICISE.2009.171},
  ISSN={2160-1291},
  month={Dec},}
@INPROCEEDINGS{5460850,
  author={Caraiman, Simona and Archip, Alexandru and Manta, Vasile},
  booktitle={2009 11th International Symposium on Symbolic and Numeric Algorithms for Scientific Computing}, 
  title={A Grid Enabled Quantum Computer Simulator}, 
  year={2009},
  volume={},
  number={},
  pages={189-196},
  abstract={Simulation of quantum computers using classical computers is a computationally hard problem, requiring a huge amount of operations and storage. Grid systems are a good choice for simulating quantum algorithms, since they provide access to high-performance computer clusters. In this paper we present the design of a message passing parallel version of the quantum computer simulator, QCL, deployed as a grid service. After describing the architecture of our grid service and the parallelization strategy for the general single qubit operator, we present the performance measurements for some test cases, showing the speedups obtained.},
  keywords={},
  doi={10.1109/SYNASC.2009.57},
  ISSN={},
  month={Sep.},}
@INPROCEEDINGS{5470059,
  author={Severi, Stefano and Abreu, Giuseppe and Destino, Giuseppe and Dardari, Davide},
  booktitle={2009 Conference Record of the Forty-Third Asilomar Conference on Signals, Systems and Computers}, 
  title={Efficient and accurate localization in multihop networks}, 
  year={2009},
  volume={},
  number={},
  pages={1071-1076},
  abstract={We present evidence that multihop node-to-anchor distance information is sufficient to allow accurate self-localization in multihop wireless networks (such as ad hoc and sensor networks, as well as future cellular systems based on LTE). To this purpose we have implemented two new distance-based source localization algorithms, which prove highly robust to inaccurate range information characterized by distance estimates exceeding the correct ones. Our contribution is a contrasting alternative to current distributed self-localization algorithms, which are founded on the idea of ¿diffusing¿ the known location of a few nodes (anchor) to the entire the network via a typically large number of message exchanges amongst neighbors, resulting in high communications costs, low robustness to mobility, and little (location) privacy to end users. To the best of our knowledge, this work is the first example that the aforementioned disadvantages are not an unavoidable price to be payed for accurate location information in multihop networks.},
  keywords={},
  doi={10.1109/ACSSC.2009.5470059},
  ISSN={1058-6393},
  month={Nov},}
@INPROCEEDINGS{5521580,
  author={Ming, Pingjian and Zhu, Minggang and Hou, Peng and Zhang, Wenping},
  booktitle={2009 Fourth International Conference on Internet Computing for Science and Engineering}, 
  title={A Parallel 2D/3D Aero-acoustics Numerical Algorithm and Implementation}, 
  year={2009},
  volume={},
  number={},
  pages={308-312},
  abstract={This article introduces a numerical scheme to simulate aero acoustics propagation. The wave equation is discrete spatially with collocated finite volume method and Eulerian implicit method in time domain. The performance of the PC is greatly developed, so as expected the network can provide great computational capability. Based on this point, we developed a data structure system and parallel code. Two simple test cases have been done with the program and reasonable results were obtained.},
  keywords={},
  doi={10.1109/ICICSE.2009.33},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{5729480,
  author={Chaves, Juan C. and Chalker, Alan and Hudak, David and Gadepally, Vijay and Escobar, Fernando and Longhini, Patrick},
  booktitle={2009 DoD High Performance Computing Modernization Program Users Group Conference}, 
  title={Enabling High-Productivity SIP Application Development: Modeling and Simulation of Superconducting Quantum Interference Filters}, 
  year={2009},
  volume={},
  number={},
  pages={302-306},
  abstract={The inherent complexity in utilizing and programming high performance computing (HPC) systems is the main obstacle to widespread exploitation of HPC resources and technologies in the Department of Defense (DoD). Consequently, there is the persistent need to simplify the programming interface for the generic user. This need is particularly acute in the Signal/Image Processing (SIP), Integrated Modeling and Test Environments (IMT), and related DoD communities where typical users have heterogeneous unconsolidated needs. Mastering the complexity of traditional programming tools (C, MPI, etc.) is often seen as a diversion of energy that could be applied to the study of the given scientific domain. Many SIP users instead prefer high-level languages (HLLs) within integrated development environments, such as MATLAB. We report on our collaborative effort to use a HLL distribution for HPC systems called ParaM to optimize and parallelize a compute-intensive Superconducting Quantum Interference Filter (SQIF) application provided by the Navy SPAWAR Systems Center in San Diego, CA. ParaM is an open-source HLL distribution developed at the Ohio Supercomputer Center (OSC), and includes support for processor architectures not supported by MATLAB (e.g., Itanium and POWER5) as well as support for high-speed interconnects (e.g., InfiniBand and Myrinet). We make use of ParaM installations available at the Army Research Laboratory (ARL) DoD Supercomputing Resource Center (DSRC) and OSC to perform a successful optimization/parallelization of the SQIF application. This optimization/parallelization may be used to assess the feasibility of using SQIF devices as extremely sensitive detectors for electromagnetic radiation which is of great importance to the Navy and DoD in general.},
  keywords={},
  doi={10.1109/HPCMP-UGC.2009.49},
  ISSN={},
  month={June},}
@INPROCEEDINGS{5729503,
  author={Wright, Nicholas J. and Smallen, Shava and Olschanowsky, Catherine Mills and Hayes, Jim and Snavely, Allan},
  booktitle={2009 DoD High Performance Computing Modernization Program Users Group Conference}, 
  title={Measuring and Understanding Variation in Benchmark Performance}, 
  year={2009},
  volume={},
  number={},
  pages={438-443},
  abstract={Runtime irreproducibility complicates application performance evaluation on today's high performance computers. Performance can vary significantly between seemingly identical runs; this presents a challenge to benchmarking as well as a user, who is trying to determine whether the change they made to their code is an actual improvement. In order to gain a better understanding of this phenomenon, we measure the runtime variation of two applications, PARAllel Total Energy Code (PARATEC) and Weather Research and Forecasting (WRF), on three different machines. Key associated metrics are also recorded. The data is then used to 1) quantify the magnitude and distribution of the variations and 2) gain an understanding as why the variations occur. Using our lightweight framework, Integrated Performance Monitoring (IPM), to understand the performance characteristics of individual runs, and the Inca framework to automate the procedure measurements were collected over a month's time. The results indicate that performance can vary up to 25% and is almost always due to contention for network resources. We also found that the variation differs between machines and is almost always greater on machines with lower performing networks.},
  keywords={},
  doi={10.1109/HPCMP-UGC.2009.72},
  ISSN={},
  month={June},}
@ARTICLE{6073167,
  author={Liu, Binbin and Bai, Dong and Ge, Qihong and Mel, Shunliang},
  journal={Tsinghua Science and Technology}, 
  title={Code design and shuffled iterative decoding of a quasi-cyclic LDPC coded OFDM system}, 
  year={2009},
  volume={14},
  number={1},
  pages={106-112},
  abstract={In multipath environments, the error rate performance of orthogonal frequency division multiplexing (OFDM) is severely degraded by the deep fading subcarriers. Powerful error-correcting codes must be used with OFDM. This paper presents a quasi-cyclic low-density parity-check (LDPC) coded OFDM system, in which the redundant bits of each codeword are mapped to a higher-order modulation constellation. The optimal degree distribution was calculated using density evolution. The corresponding quasi-cyclic LDPC code was then constructed using circulant permutation matrices. Group shuffled message passing scheduling was used in the iterative decoding. Simulation results show that the system achieves better error rate performance and faster decoding convergence than conventional approaches on both additive white Gaussian noise (AWGN) and Rayleigh fading channels.},
  keywords={},
  doi={10.1016/S1007-0214(09)70015-X},
  ISSN={1007-0214},
  month={Feb},}
@INPROCEEDINGS{7077452,
  author={Beuschel, Christiane and Pfeiderer, Hans-Jörg},
  booktitle={2009 17th European Signal Processing Conference}, 
  title={Fully programmable layered LDPC decoder architecture}, 
  year={2009},
  volume={},
  number={},
  pages={1156-1160},
  abstract={We present a fully programmable layered LDPC decoder architecture together with an optimum mapping and scheduling algorithm. In contrast to other designs proposed in the literature, we use one-phase message passing. This allows for the first time the design of a fully programmable layered decoder. The proposed mapping and scheduling algorithm exploits the full parallelism of the architecture at any time for any code, which means that the mapping algorithm achieves collision-free memory access and 100% utilization of the architecture. Compared to existing programmable designs without layered decoding we double the data throughput. The parallelism of the architecture is unconstrained and fully scalable so that hardware cost and data throughput can be exchanged with fine granularity.},
  keywords={},
  doi={},
  ISSN={},
  month={Aug},}
@ARTICLE{8133430,
  author={Grossi, Giuliano and Marchi, Massimo and Pontelli, Enrico and Provetti, Alessandro},
  journal={Journal of Logic and Computation}, 
  title={Experimental Analysis of Graph-based Answer Set Computation over Parallel and Distributed Architectures}, 
  year={2009},
  volume={19},
  number={4},
  pages={697-715},
  abstract={This article presents a distributed version of the adjSolver algorithm for computing the answer sets of logic programs. adjSolver operates a classical branch-and-bound structure; its intrinsic parallelism is exploited to control, with a centralized architecture, the delegation of promising search subspaces to distributed handling agents. adjSolver has been implemented and tested on a Beowulf platform, using MPI message passing. The communication overhead was minimized by adopting a compact representation of the data exchanged among agents and by reusing previously-computed partial solutions.},
  keywords={},
  doi={10.1093/logcom/exn036},
  ISSN={1465-363X},
  month={Aug},}
@ARTICLE{5128903,
  author={Garg, Rahul and Garg, Vijay K. and Sabharwal, Yogish},
  journal={IEEE Transactions on Parallel and Distributed Systems}, 
  title={Efficient Algorithms for Global Snapshots in Large Distributed Systems}, 
  year={2010},
  volume={21},
  number={5},
  pages={620-630},
  abstract={Existing algorithms for global snapshots in distributed systems are not scalable when the underlying topology is complete. There are primarily two classes of existing algorithms for computing a global snapshot. Algorithms in the first class use control messages of size 0(1) but require O(N) space and O(N) messages per processor in a network with JV processors. Algorithms in the second class use control messages (such as rotating tokens with vector counter method) of size O(N), use multiple control messages per channel, or require recording of message history. As a result, algorithms in both of these classes are not efficient in large systems when the logical topology of the communication layer such as MPI is complete. In this paper, we propose three scalable algorithms for global snapshots: a grid-based, a tree-based, and a centralized algorithm. The grid-based algorithm uses O(N) space but only O(¿(N)) messages per processor each of size O(¿(N)). The tree-based and centralized algorithms use only O(1) size messages. The tree-based algorithm requires O(1) space and O(log N log(W/N)) messages per processor where W is the total number of messages in transit. The centralized algorithm requires O(1) space and O(log(W/N)) messages per processor. We also have a matching lower bound for this problem. We also present hybrid of centralized and tree-based algorithms that allow trade-off between the decentralization and the message complexity. Our algorithms have applications in checkpointing, detecting stable predicates, and implementing synchronizers.},
  keywords={},
  doi={10.1109/TPDS.2009.108},
  ISSN={1558-2183},
  month={May},}
@ARTICLE{5184825,
  author={Larsson Traff, Jesper and Gropp, William D. and Thakur, Rajeev},
  journal={IEEE Transactions on Parallel and Distributed Systems}, 
  title={Self-Consistent MPI Performance Guidelines}, 
  year={2010},
  volume={21},
  number={5},
  pages={698-709},
  abstract={Message passing using the Message-Passing Interface (MPI) is at present the most widely adopted framework for programming parallel applications for distributed memory and clustered parallel systems. For reasons of (universal) implementability, the MPI standard does not state any specific performance guarantees, but users expect MPI implementations to deliver good and consistent performance in the sense of efficient utilization of the underlying parallel (communication) system. For performance portability reasons, users also naturally desire communication optimizations performed on one parallel platform with one MPI implementation to be preserved when switching to another MPI implementation on another platform. We address the problem of ensuring performance consistency and portability by formulating performance guidelines and conditions that are desirable for good MPI implementations to fulfill. Instead of prescribing a specific performance model (which may be realistic on some systems, under some MPI protocol and algorithm assumptions, etc.), we formulate these guidelines by relating the performance of various aspects of the semantically strongly interrelated MPI standard to each other. Common-sense expectations, for instance, suggest that no MPI function should perform worse than a combination of other MPI functions that implement the same functionality, no specialized function should perform worse than a more general function that can implement the same functionality, no function with weak semantic guarantees should perform worse than a similar function with stronger semantics, and so on. Such guidelines may enable implementers to provide higher quality MPI implementations, minimize performance surprises, and eliminate the need for users to make special, nonportable optimizations by hand. We introduce and semiformalize the concept of self-consistent performance guidelines for MPI, and provide a (nonexhaustive) set of such guidelines in a form that could be automatically verified by benchmarks and experiment management tools. We present experimental results that show cases where guidelines are not satisfied in common MPI implementations, thereby indicating room for improvement in today's MPI implementations.},
  keywords={},
  doi={10.1109/TPDS.2009.120},
  ISSN={1558-2183},
  month={May},}

@ARTICLE{5229117,
  author={Jin, Jie and Tsui, Chi-ying},
  journal={IEEE Transactions on Very Large Scale Integration (VLSI) Systems}, 
  title={An Energy Efficient Layered Decoding Architecture for LDPC Decoder}, 
  year={2010},
  volume={18},
  number={8},
  pages={1185-1195},
  abstract={Low-density parity-check (LDPC) decoder requires large amount of memory access which leads to high energy consumption. To reduce the energy consumption of the LDPC decoder, memory-bypassing scheme has been proposed for the layered decoding architecture which reduces the amount of access to the memory storing the soft posterior reliability values. In this work, we present a scheme that achieves the optimal reduction of memory access for the memory bypassing scheme. The amount of achievable memory bypassing depends on the decoding order of the layers. We formulate the problem of finding the optimal decoding order and propose algorithm to obtain the optimal solution. We also present the corresponding architecture which combines some of memory components and results in reduction of memory area. The proposed decoder was implemented in TSMC 0.18 μm CMOS process. Experimental results show that for a LDPC decoder targeting IEEE 802.11 n specification, the amount of memory access values can be reduced by 12.9-19.3% compared with the state-of-the-art design. At the same time, 95.6%-100% hardware utilization rate is achieved.},
  keywords={},
  doi={10.1109/TVLSI.2009.2021479},
  ISSN={1557-9999},
  month={Aug},}
@ARTICLE{5401156,
  author={Kshemkalyani, Ajay D.},
  journal={IEEE Transactions on Parallel and Distributed Systems}, 
  title={Fast and Message-Efficient Global Snapshot Algorithms for Large-Scale Distributed Systems}, 
  year={2010},
  volume={21},
  number={9},
  pages={1281-1289},
  abstract={Large-scale distributed systems such as supercomputers and peer-to-peer systems typically have a fully connected logical topology over a large number of processors. Existing snapshot algorithms in such systems have high response time and/or require a large number of messages, typically O(n2), where n is the number of processes. In this paper, we present a suite of two algorithms: simple_tree, and hypercube, that are both fast and require a small number of messages. This makes the algorithms highly scalable. Simple_tree requires O(n) messages and has O(log n) response time. Hypercube requires O(n log n) messages and has O(log n) response time, in addition to having the property that the roles of all the processes are symmetrical. Process symmetry implies greater potential for balanced workload and congestion-freedom. All the algorithms assume non-FIFO channels.},
  keywords={},
  doi={10.1109/TPDS.2010.24},
  ISSN={1558-2183},
  month={Sep.},}
@ARTICLE{5407615,
  author={Smith, Benjamin and Ardakani, Masoud and Yu, Wei and Kschischang, Frank R.},
  journal={IEEE Transactions on Communications}, 
  title={Design of irregular LDPC codes with optimized performance-complexity tradeoff}, 
  year={2010},
  volume={58},
  number={2},
  pages={489-499},
  abstract={The optimal performance-complexity tradeoff for error-correcting codes at rates strictly below the Shannon limit is a central question in coding theory. This paper proposes a numerical approach for the minimization of decoding complexity for long-block-length irregular low-density parity-check (LDPC) codes. The proposed design methodology is applicable to any binary-input memoryless symmetric channel and any iterative message-passing decoding algorithm with a parallel-update schedule. A key feature of the proposed optimization method is a new complexity measure that incorporates both the number of operations required to carry out a single decoding iteration and the number of iterations required for convergence. This paper shows that the proposed complexity measure can be accurately estimated from a density-evolution and extrinsic-information transfer chart analysis of the code. A sufficient condition is presented for convexity of the complexity measure in the variable edge-degree distribution; when it is not satisfied, numerical experiments nevertheless suggest that the local minimum is unique. The results presented herein show that when the decoding complexity is constrained, the complexity-optimized codes significantly outperform threshold-optimized codes at long block lengths, within the ensemble of irregular codes.},
  keywords={},
  doi={10.1109/TCOMM.2010.02.080193},
  ISSN={1558-0857},
  month={February},}
@ARTICLE{5416684,
  author={Duarte, Filipa and Wong, Stephan},
  journal={IEEE Transactions on Computers}, 
  title={Cache-Based Memory Copy Hardware Accelerator for Multicore Systems}, 
  year={2010},
  volume={59},
  number={11},
  pages={1494-1507},
  abstract={In this paper, we present a new architecture of the cache-based memory copy hardware accelerator in a multicore system supporting message passing. The accelerator is able to accelerate memory data movements, in particular memory copies. We perform an analytical analysis based on open-queuing theory to study the utilization of our accelerator in a multicore system. In order to correctly model the system, we gather the necessary information by utilizing a full-system simulator. We present both the simulation results and the analytical analysis. We demonstrate the advantages of our solution based on a full-system simulator utilizing several applications: the STREAM benchmark and the receiver-side of the TCP/IP stack. Our accelerator provides speedups from 2.96 to 4.61 for the receiver-side of the TCP/IP stack, reduces the number of instructions from 26 percent to 44 percent and achieves a higher cache hit rate. Utilizing the analytical analysis, our accelerator reduces in the average number of cycles executed per instruction up to 50 percent for one of the CPUs in the multicore system.},
  keywords={},
  doi={10.1109/TC.2010.41},
  ISSN={1557-9956},
  month={Nov},}
@ARTICLE{5422626,
  author={Chang, Wu and Cruz, J. R.},
  journal={IEEE Transactions on Magnetics}, 
  title={An Improved Belief-Propagation Decoder for LDPC-Coded Partial-Response Channels}, 
  year={2010},
  volume={46},
  number={7},
  pages={2639-2648},
  abstract={The traditional belief-propagation (BP) decoder for low-density parity-check (LDPC) codes assumes that the soft input information for each bit is independent of all other bits. However, for partial-response (PR) channels, the log-likelihood ratios (LLRs) generated by the channel detector are correlated. In this paper, we propose an improved BP (IBP) decoder to take into account the dependence among the LLRs produced by channel detectors. The IBP decoder needs not only the LLR for each bit but also the probability distribution of the subblock that contains this bit. Therefore, we revise the Bahl-Cocke-Jelinek-Raviv (BCJR) algorithm accordingly to generate the additional information during channel detection. We apply the proposed decoder to an ideal PR channel and, as a practical example, to equalized perpendicular magnetic recording channels (PMRCs). The IBP decoder significantly outperforms the traditional BP decoder without turbo equalization, but this gain is substantially reduced when we introduce turbo equalization. Furthermore, we extend the IBP decoder to nonbinary LDPC codes, and show that we can achieve additional gains.},
  keywords={},
  doi={10.1109/TMAG.2010.2043679},
  ISSN={1941-0069},
  month={July},}
@INPROCEEDINGS{5426759,
  author={Lechner, Gottfried},
  booktitle={2010 Australian Communications Theory Workshop (AusCTW)}, 
  title={The effect of cycles on binary message-passing decoding of LDPC codes}, 
  year={2010},
  volume={},
  number={},
  pages={43-47},
  abstract={We study the error-floor behavior of binary message-passing decoders for low-density parity-check (LDPC) codes. We find that the stability condition is independent of the quality of the channel messages (i.e. soft or hard decision). Furthermore, we identify a structure in the graph where the involved variable nodes cannot be corrected by the binary message-passing decoder. This leads to an error floor for regular LDPC codes with variable node degree smaller than four. An additional constraint on the degree distribution is derived which allows to avoid this structure, leading to optimized LDPC codes without error floors.},
  keywords={},
  doi={10.1109/AUSCTW.2010.5426759},
  ISSN={},
  month={Feb},}
@ARTICLE{5429143,
  author={Hsu, Chun-Hao and Anastasopoulos, Achilleas},
  journal={IEEE Transactions on Information Theory}, 
  title={Capacity-Achieving Codes With Bounded Graphical Complexity and Maximum Likelihood Decoding}, 
  year={2010},
  volume={56},
  number={3},
  pages={992-1006},
  abstract={ In this paper, the existence of capacity-achieving codes for memoryless binary-input output-symmetric (MBIOS) channels under maximum-likelihood (ML) decoding with bounded graphical complexity is investigated. Graphical complexity of a code is defined as the number of edges in the graphical representation of the code per information bit and is proportional to the decoding complexity per information bit per iteration under iterative decoding. Irregular repeat-accumulate (IRA) codes are studied first. Utilizing the asymptotic average weight distribution (AAWD) of these codes and invoking Divsalar's bound on the binary-input additive white Gaussian noise (BIAWGN) channel, it is shown that simple nonsystematic IRA ensembles outperform systematic IRA and regular low-density parity-check (LDPC) ensembles with the same graphical complexity, and are at most 0.124 dB away from the Shannon limit. However, a conclusive result as to whether these nonsystematic IRA codes can really achieve capacity cannot be reached. Motivated by this inconclusive result, a new family of codes is proposed, called low-density parity-check and generator matrix (LDPC-GM) codes, which are serially concatenated codes with an outer LDPC code and an inner low-density generator matrix (LDGM) code. It is shown that these codes can achieve capacity on any MBIOS channel using ML decoding and also achieve capacity on any BEC using belief propagation (BP) decoding, both with bounded graphical complexity. Moreover, it is shown that, under certain conditions, these capacity-achieving codes have linearly increasing minimum distances and achieve the asymptotic Gilbert–Varshamov bound for all rates. },
  keywords={},
  doi={10.1109/TIT.2009.2039084},
  ISSN={1557-9654},
  month={March},}
@ARTICLE{5429117,
  author={Wainwright, Martin J. and Maneva, Elitza and Martinian, Emin},
  journal={IEEE Transactions on Information Theory}, 
  title={Lossy Source Compression Using Low-Density Generator Matrix Codes: Analysis and Algorithms}, 
  year={2010},
  volume={56},
  number={3},
  pages={1351-1368},
  abstract={We study the use of low-density generator matrix (LDGM) codes for lossy compression of the Bernoulli symmetric source. First, we establish rigorous upper bounds on the average distortion achieved by check-regular ensemble of LDGM codes under optimal minimum distance source encoding. These bounds establish that the average distortion using such bounded degree families rapidly approaches the Shannon limit as the degrees are increased. Second, we propose a family of message-passing algorithms, ranging from the standard belief propagation algorithm at one extreme to a variant of survey propagation algorithm at the other. When combined with a decimation subroutine and applied to LDGM codes with suitably irregular degree distributions, we show that such a message-passing/decimation algorithm yields distortion very close to the Shannon rate-distortion bound for the binary symmetric source.},
  keywords={},
  doi={10.1109/TIT.2009.2039160},
  ISSN={1557-9654},
  month={March},}
@INPROCEEDINGS{5430180,
  author={Paul, P. Viji and Rajbabu, V.},
  booktitle={2010 National Conference On Communications (NCC)}, 
  title={Nonparametric techniques for graphical model-based target tracking in collaborative sensor groups}, 
  year={2010},
  volume={},
  number={},
  pages={1-5},
  abstract={Target tracking using collaborative sensor groups is an effective mechanism for reducing the scalability issues in distributed sensor networks. Using graphical models for such a sensor group together with appropriate class of nonparametric message passing algorithms, we explore efficient approaches to handle the related data fusion problems characterized by spatially distributed observations. Messages consisting of multiple Gaussian components have been efficiently handled with the help of nonparametric belief propagation techniques. The advantage of such an approach in a myopic radar network has been verified here using Monte Carlo simulations by comparing the tracking performance obtained with centralized and distributed fusion schemes.},
  keywords={},
  doi={10.1109/NCC.2010.5430180},
  ISSN={},
  month={Jan},}
@ARTICLE{5432300,
  author={Chou, Yu-Cheng and Nestinger, Stephen S. and Cheng, Harry H.},
  journal={Computing in Science & Engineering}, 
  title={Ch MPI: Interpretive Parallel Computing in C}, 
  year={2010},
  volume={12},
  number={2},
  pages={54-67},
  abstract={The message passing interface lets users develop portable message passing programs for parallel computing in C, C++, and Fortran. When combined with an MPI C/C++ library, Ch, an embeddable C/C++ interpreter for executing C/C++ programs interpretively, lets developers rapidly prototype MPI C/C++ programs without having to compile and link.},
  keywords={},
  doi={10.1109/MCSE.2010.36},
  ISSN={1558-366X},
  month={March},}
@ARTICLE{5437420,
  author={Chilappagari, Shashi Kiran and Nguyen, Dung Viet and Vasic, Bane and Marcellin, Michael W.},
  journal={IEEE Transactions on Information Theory}, 
  title={On Trapping Sets and Guaranteed Error Correction Capability of LDPC Codes and GLDPC Codes}, 
  year={2010},
  volume={56},
  number={4},
  pages={1600-1611},
  abstract={The relation between the girth and the guaranteed error correction capability of ¿ -left-regular low-density parity-check (LDPC) codes when decoded using the bit flipping (serial and parallel) algorithms is investigated. A lower bound on the size of variable node sets which expand by a factor of at least 3 ¿/4 is found based on the Moore bound. This bound, combined with the well known expander based arguments, leads to a lower bound on the guaranteed error correction capability. The decoding failures of the bit flipping algorithms are characterized using the notions of trapping sets and fixed sets. The relation between fixed sets and a class of graphs known as cage graphs is studied. Upper bounds on the guaranteed error correction capability are then established based on the order of cage graphs. The results are extended to left-regular and right-uniform generalized LDPC codes. It is shown that this class of generalized LDPC codes can correct a linear number of worst case errors (in the code length) under the parallel bit flipping algorithm when the underlying Tanner graph is a good expander. A lower bound on the size of variable node sets which have the required expansion is established.},
  keywords={},
  doi={10.1109/TIT.2010.2040962},
  ISSN={1557-9654},
  month={April},}
@ARTICLE{5438858,
  author={Pandey, Seema N. and Pandey, Nirved K. and Tapaswi, Shashikala and Srivastava, Laxmi},
  journal={IEEE Transactions on Power Systems}, 
  title={Neural Network-Based Approach for ATC Estimation Using Distributed Computing}, 
  year={2010},
  volume={25},
  number={3},
  pages={1291-1300},
  abstract={In the competitive electric power market allowing open access transmission environment, the knowledge of available transfer capability (ATC) is very important for optimum utilization of existing transmission facility. ATC information conveys how much power can be transmitted through the power network over and above already committed usage without violation of system security limits. This paper presents a Levenberg-Marquardt algorithm neural network (LMANN)-based approach for fast and accurate estimation of system ATC. System ATC has been estimated for both varying load condition as well as for single line outage contingency condition by employing distributed computing. Principal component analysis (PCA) has been applied for effective input feature selection. Contingency clusters are formed such that each cluster contains almost similar ATC values. For each contingency clusters separate LMANNs have been developed. All the proposed LMANNs have been trained and tested under distributed computing environment and a considerable speed up in the training is obtained. The proposed approach has been examined on 75-bus Indian power system and IEEE 300-bus system and found significantly efficient.},
  keywords={},
  doi={10.1109/TPWRS.2010.2042978},
  ISSN={1558-0679},
  month={Aug},}
@INPROCEEDINGS{5440475,
  author={Faheem, H.M.},
  booktitle={2010 The 12th International Conference on Advanced Communication Technology (ICACT)}, 
  title={Accelerating motif finding problem using grid computing with enhanced Brute Force}, 
  year={2010},
  volume={1},
  number={},
  pages={197-202},
  abstract={Motif finding problem is a major task to understand the mechanisms of gene expression regulation. Motif is generally defined as a recurring pattern in the sequence of nucleotides or amino acids. In the DNA sequence, it is usually a short segment that occurs frequently, but not required to be an exact copy for each occurrence. This property of motif makes motif mining very difficult. In fact, motif finding problem is proven to be NP-Complete. Many algorithms fail to solve the well-known challenge problem of finding a motif of length 15 and has at most 4 mutations (15, 4) due to the huge runtime needed. Others fail to distinguish the motif from background sequences. Brute Force is one of the exact algorithms that never fail to find the motif, but it suffers from an intractable running time. In this paper, we present a novel approach to accelerate the motif finding problem using grid computing. As grid computing makes available low-cost high-performance computing (HPC) infrastructures, the best candidates for using such infrastructures are applications that require high computational power, large storage capacity, or fast and high-throughput networking. The nature of motif finding problem is considered one of the perfect scenarios for grid computing. We deployed an enhanced version of the Brute Force; skip-Brute Force running on EUMEDGRID infrastructure (Co-Funded project by the European Commission in the framework of FP6, with the aim of supporting the development of a Grid e-Infrastructure in the Mediterranean Area and promoting the porting of computationally intensive applications on the Grid platform). The idea behind our skip Brute Force algorithm is that it skips all the iterations that will not lead to a correct solution. The message passing programming paradigm is deployed since it assumes a partitioned address space and supports explicit parallelization. Our experimental results showed boosting in the performance without sacrificing the exactness of the Brute Force.},
  keywords={},
  doi={},
  ISSN={1738-9445},
  month={Feb},}
@INPROCEEDINGS{5440212,
  author={Weiqiang Kong and Shiraishi, Tomohiro and Mizushima, Yuki and Katahira, Noriyuki and Fukuda, Akira and Watanabe, Masahiko},
  booktitle={2010 The 12th International Conference on Advanced Communication Technology (ICACT)}, 
  title={Formal analysis of STM design with SAL infinite bounded model checker}, 
  year={2010},
  volume={2},
  number={},
  pages={1003-1008},
  abstract={State Transition Matrix (STM) is a flexible table-like modeling language that has been frequently used for specifying behavior of distributed systems. In this paper, we first present a formalization of the static and dynamic aspects of a STM design (i.e., design written in STM). Consequentially, based on this formalization, we investigate how a STM design can be formally analyzed using SAL, precisely SAL infinite bounded model checker, through a language translation. Specifically, the formal analysis is conducted focusing on four kinds of safety properties related to: (1) Invalid Cells, (2) Static Constraints, (3) Dynamic Constraints, and (4) Deadlock, respectively, since the fulfillment of these properties is commonly desired by industrial practitioners for a STM design. A simple Internet Connection Control system is used as our demonstration example.},
  keywords={},
  doi={},
  ISSN={1738-9445},
  month={Feb},}
@INPROCEEDINGS{5442623,
  author={Varghese, Blesson and McKee, Gerard and Alexandrov, Vassil},
  booktitle={2010 Sixth International Conference on Autonomic and Autonomous Systems}, 
  title={A Cluster-Based Implementation of a Fault Tolerant Parallel Reduction Algorithm Using Swarm-Array Computing}, 
  year={2010},
  volume={},
  number={},
  pages={30-36},
  abstract={Recent research in multi-agent systems incorporate fault tolerance concepts. However, the research does not explore the extension and implementation of such ideas for large scale parallel computing systems. The work reported in this paper investigates a swarm array computing approach, namely 'Intelligent Agents'. In the approach considered a task to be executed on a parallel computing system is decomposed to sub-tasks and mapped onto agents that traverse an abstracted hardware layer. The agents intercommunicate across processors to share information during the event of apredicted core/processor failure and for successfully completing the task. The agents hence contribute towards fault tolerance and towards building reliable systems. The feasibility of the approach is validated by simulations on an FPGA usinga multi-agent simulator and implementation of a parallel reduction algorithm on a computer cluster using the Message Passing Interface.},
  keywords={},
  doi={10.1109/ICAS.2010.13},
  ISSN={2168-1872},
  month={March},}
@INPROCEEDINGS{5447480,
  author={Mazouz, Abdelhafid and Touati, Sid-Ahmed-Ali and Barthou, Denis},
  booktitle={2010 International Conference on Complex, Intelligent and Software Intensive Systems}, 
  title={Study of Variations of Native Program Execution Times on Multi-Core Architectures}, 
  year={2010},
  volume={},
  number={},
  pages={919-924},
  abstract={Program performance optimisations, feedback-directed iterative compilation and auto-tuning systems all assume a fixed estimation of execution time given a fixed input data for the program. However, in practice we observe non-negligible program performance variations on hardware platforms. While these variations are insignificant for sequential applications, we show that parallel native OpenMP programs have less performance stability. This article does not try to quantify nor to qualify the factors influencing the variations of program execution times, that we let for a future work. This article demonstrates three observations: 1) The performance variations of sequential applications is insignificant. 2) OpenMP program execution times on multi-core platforms show important variations. 3) The distribution of the execution times is not a Gaussian distribution in almost all cases. We finish by a discussion explaining why considering the minimal or the mean execution time within a sample of experiments is not the best estimation of program performance.},
  keywords={},
  doi={10.1109/CISIS.2010.96},
  ISSN={},
  month={Feb},}
@INPROCEEDINGS{5453905,
  author={Watkins, Kera Z.},
  booktitle={Proceedings of the IEEE SoutheastCon 2010 (SoutheastCon)}, 
  title={Introducing fault-based combinatorial testing to web services}, 
  year={2010},
  volume={},
  number={},
  pages={131-134},
  abstract={Combinatorial testing is considered effective for finding software faults. It is also efficient, since it keeps the number of tests relatively small. However, there seems to be very little research that considers combinatorial testing as a testing approach for web services. They are commonly tested by injecting fault-causing data perturbations into the network. It may be worthwhile to see if combinatorial testing can complement existing perturbations with the benefits of combinatorial testing. The approach proposed in this paper is called combinatorial fault-based testing. This type of testing combines existing fault-based testing techniques, such as fault injection, with combinatorial testing to attempt to find faults of varying strength within a web service. Combinatorial fault-based testing uses fault injection and helps reduce the problem with combinatorial explosion by focusing solely on fault-based combinations. This raises the following research question: Is there a way to take advantage of the benefits of combinatorial testing for web services assuming that source code will not be available, while minimizing the possibility of a combinatorial explosion? Combinatorial fault-based testing looks very promising for answering this question. As a side effect, it could potentially offer a way to determine the maximum strength of interactions to test for web services.},
  keywords={},
  doi={10.1109/SECON.2010.5453905},
  ISSN={1558-058X},
  month={March},}
@INPROCEEDINGS{5452459,
  author={de Armas, Jesica and Leon, Coromoto and Miranda, Gara},
  booktitle={2010 18th Euromicro Conference on Parallel, Distributed and Network-based Processing}, 
  title={Fine and Coarse-grained Parallel Algorithms for the 2D Cutting Stock Problem}, 
  year={2010},
  volume={},
  number={},
  pages={255-262},
  abstract={This work analyses two different approaches to parallelise an exact algorithm for the solution of the Constrained Two-Dimensional Cutting Stock Problem. A fine-grained model based on the parallel execution of the generation loops is implemented through a shared-memory model using the OpenMP tool. Also, a coarse-grained model based on the parallel execution of the search loop and in the introduction of efficient synchronisation and load balancing schemes is implemented through a distributed-memory model using MPI. As a novelty, we have incorporated into the models the checking of dominance and duplication rules, thus affecting the search space and so, the operation of the parallelisations. In the experimental evaluation it is demonstrated that, even when the domination/duplication tests are applied to the parallel algorithms, they are able to obtain an important improvement over the sequential approach.},
  keywords={},
  doi={10.1109/PDP.2010.74},
  ISSN={2377-5750},
  month={Feb},}
@INPROCEEDINGS{5453535,
  author={Wu, Feng and Yu, Peiwen},
  booktitle={2010 Data Compression Conference}, 
  title={Theoretically Optimal Low-Density Parity-Check Code Ensemble for Gallager's Decoding Algorithm A}, 
  year={2010},
  volume={},
  number={},
  pages={558-558},
  abstract={For a class of low-density parity-check (LDPC) code ensembles with right node degrees as binomial distribution, this paper proves that the theoretically optimal LDPC code ensemble should be regular for a binary-symmetric channel (BSC) and Gallager’s decoding algorithm A. Our proof consists of two steps. First, with the assumption of right edge degrees as binomial, we prove that the LDPC threshold of single left edge degree is larger than that of multiple left edge degrees. Second, we verify that the LDPC threshold is the largest when binomial distribution of right node degrees degrades to single value. Very interestingly, although both right and left edge degrees are unique in the theoretically optimal LDPC code ensemble, they are floating values. When the floating degrees are approximated by a two-term binomial distribution, the threshold at half rate is exactly the same as Bazzi’s result via linear programming. It verifies our proof from another angle},
  keywords={},
  doi={10.1109/DCC.2010.84},
  ISSN={2375-0359},
  month={March},}
@INPROCEEDINGS{5453483,
  author={Xiong, Ruiqin and Gao, Wen},
  booktitle={2010 Data Compression Conference}, 
  title={Tanner Graph Based Image Interpolation}, 
  year={2010},
  volume={},
  number={},
  pages={376-385},
  abstract={This paper interprets image interpolation as a channel decoding problem and proposes a tanner graph based interpolation framework, which regards each pixel in an image as a variable node and the local image structure around each pixel as a check node. The pixels available from low-resolution image are "received" whereas other missing pixels of highresolution image are "erased", through an imaginary channel. Local image structures exhibited by the low-resolution image provide information on the joint distribution of pixels in a small neighborhood, and thus play the same role as parity symbols in the classic channel coding scenarios. We develop an efficient solution for the sum-product algorithm of belief propagation in this framework, based on a gaussian auto-regressive image model. Initial experiments show up to 3dB gain over other methods with the same image model. The proposed framework is flexible in message processing at each node and provides much room for incorporating more sophisticated image modelling techniques.},
  keywords={},
  doi={10.1109/DCC.2010.40},
  ISSN={2375-0359},
  month={March},}
@INPROCEEDINGS{5453735,
  author={Luo, Wen-lang and Xie, An-dong and Ruan, Wen},
  booktitle={2010 Third International Symposium on Intelligent Information Technology and Security Informatics}, 
  title={The Construction and Test for a Small Beowulf Parallel Computing System}, 
  year={2010},
  volume={},
  number={},
  pages={767-770},
  abstract={As a practical scheme carrying out the high performance computing tasks for small research groups and personal researchers, we propose a small Beowulf PC-cluster parallel system based on MPI and Windows by employing a set of PCs and 100 M Ethernet. The experimental evaluations on the classical case of computing ¿ show that the system has satisfactory speedup and parallel efficiency. Owing to the 100 M Ethernet which has less bandwidth and more communication delay, the speedup and parallel efficiency will come down with increasing working nodes, and a more excellent high speed network should be build.},
  keywords={},
  doi={10.1109/IITSI.2010.157},
  ISSN={},
  month={April},}
@INPROCEEDINGS{5457237,
  author={Tota, Sergio V. and Casu, Mario R. and Roch, Massimo Ruo and Rostagno, Luca and Zamboni, Maurizio},
  booktitle={2010 Design, Automation & Test in Europe Conference & Exhibition (DATE 2010)}, 
  title={MEDEA: a hybrid shared-memory/message-passing multiprocessor NoC-based architecture}, 
  year={2010},
  volume={},
  number={},
  pages={45-50},
  abstract={The shared-memory model has been adopted, both for data exchange as well as synchronization using semaphores in almost every on-chip multiprocessor implementation, ranging from general purpose chip multiprocessors (CMPs) to domain specific multi-core graphics processing units (GPUs). Low-latency synchronization is desirable but is hard to achieve in practice due to the memory hierarchy. On the contrary, an explicit exchange of synchronization tokens among the processing elements through dedicated on-chip links would be beneficial for the overall system performance. In this paper we propose the Medea NoC-based framework, a hybrid shared-memory/message-passing approach. Medea has been modeled with a fast, cycle-accurate SystemC implementation enabling a fast system exploration varying several parameters like number and types of cores, cache size and policy and NoC features. In addition, every SystemC block has its RTL counterpart for physical implementation on FPGAs and ASICs. A parallel version of the Jacobi algorithm has been used as a test application to validate the methodology. Results confirm expectations about performance and effectiveness of system exploration and design.},
  keywords={},
  doi={10.1109/DATE.2010.5457237},
  ISSN={1558-1101},
  month={March},}
@ARTICLE{5462985,
  author={Mohsenin, Tinoosh and Truong, Dean N. and Baas, Bevan M.},
  journal={IEEE Transactions on Circuits and Systems I: Regular Papers}, 
  title={A Low-Complexity Message-Passing Algorithm for Reduced Routing Congestion in LDPC Decoders}, 
  year={2010},
  volume={57},
  number={5},
  pages={1048-1061},
  abstract={A low-complexity message-passing algorithm, called Split-Row Threshold, is used to implement low-density parity-check (LDPC) decoders with reduced layout routing congestion. Five LDPC decoders that are compatible with the 10GBASE-T standard are implemented using MinSum Normalized and MinSum Split-Row Threshold algorithms. All decoders are built using a standard cell design flow and include all steps through the generation of GDS II layout. An Spn = 16 decoder achieves improvements in area, throughput, and energy efficiency of 4.1 times, 3.3 times, and 4.8 times, respectively, compared to a MinSum Normalized implementation. Postlayout results show that a fully parallel Spn = 16 decoder in 65-nm CMOS operates at 195 MHz at 1.3 V with an average throughput of 92.8 Gbits/s with early termination enabled. Low-power operation at 0.7 V gives a worst case throughput of 6.5 Gbits/s-just above the 10GBASE-T requirement-and an estimated average power of 62 mW, resulting in 9.5 pj/bit. At 0.7 V with early termination enabled, the throughput is 16.6 Gbits/s, and the energy is 3.7 pJ/bit, which is 5.8× lower than the previously reported lowest energy per bit. The decoder area is 4.84 mm2 with a final postlayout area utilization of 97%.},
  keywords={},
  doi={10.1109/TCSI.2010.2046957},
  ISSN={1558-0806},
  month={May},}
@INPROCEEDINGS{5464748,
  author={Ruozzi, Nicholas and Tatikonda, Sekhar},
  booktitle={2010 44th Annual Conference on Information Sciences and Systems (CISS)}, 
  title={Unconstrained minimization of quadratic functions via min-sum}, 
  year={2010},
  volume={},
  number={},
  pages={1-5},
  abstract={Gaussian belief propagation is an iterative algorithm for computing the mean of a multivariate Gaussian distribution. Equivalently, the min-sum algorithm can be used to compute the minimum of a multivariate positive definite quadratic function. Although simple sufficient conditions that guarantee the convergence and correctness of these algorithms are known, the algorithms may fail to converge to the correct solution even when restricted to only positive definite quadratic functions. In this work, we propose a novel change to the typical factorization used in GaBP that allows us to construct a variant of GaBP that can solve the minimization problem for arbitrary positive semidefinite matrices while still preserving the distributed message passing nature of GaBP. We prove that the new factorization avoids the major pitfalls of the standard factorization, and we demonstrate empirically that the algorithm can be used to solve problems for which the standard GaBP algorithm would have failed. As quadratic minimization is equivalent to solving a system of linear equations, this work can be applied to solve large positive semidefinite linear systems in many application areas.},
  keywords={},
  doi={10.1109/CISS.2010.5464748},
  ISSN={},
  month={March},}
@INPROCEEDINGS{5464755,
  author={Gómez, J. and Tayebi, A. and Gonzälez, I. and Cätedra, F.},
  booktitle={2010 International Workshop on Antenna Technology (iWAT)}, 
  title={Analysis of a dual-band reflectorarray by using a full wave moment method code}, 
  year={2010},
  volume={},
  number={},
  pages={1-4},
  abstract={This work presents an efficient and powerful approach for electromagnetic field analysis of complex 3D bodies. The method is able to provide fast and accurate analysis of arbitrary metallic and dielectric/magnetic structures, and combines the Moment Method (MM), the Multilevel Fast Multipole Algorithm (MLFMA), Physics Optics (PO) and the Characteristics Basis Function Method (CBFM) to solve very large scattering problems. Moreover, in order to minimize memory and time requirements, a parallelization process has been carried out by using the Message Passing Interface (MPI) algorithm. The code has been validated in many applications providing accurate predictions compared with measurements. As an example, a dual-band reflectarray is analyzed to check the performance of the proposed code.},
  keywords={},
  doi={10.1109/IWAT.2010.5464755},
  ISSN={},
  month={March},}
@INPROCEEDINGS{5463644,
  author={Jagannath, Vilas and Gligoric, Milos and Lauterburg, Steven and Marinov, Darko and Agha, Gul},
  booktitle={2010 Third International Conference on Software Testing, Verification, and Validation Workshops}, 
  title={Mutation Operators for Actor Systems}, 
  year={2010},
  volume={},
  number={},
  pages={157-162},
  abstract={Mutation testing is a well known technique for estimating and improving the quality of test suites. Given a test suite T for a system S, mutation testing systematically creates mutants of S and executes T to measure how many mutants T detects. If T does not detect some (non-equivalent) mutants, T can be improved by adding test cases that detect those mutants. Mutants are created by applying mutation operators. Mutation operators are important because they define the characteristics of the system that are tested as well as the characteristics that are improved in the test suite. While mutation operators are well defined for a number of programming paradigms such as sequential or multi-threaded, to the best of our knowledge, mutation operators have not been defined for the actor programming model. In this paper, we define and classify mutation operators that can be used for mutation testing of actor programs.},
  keywords={},
  doi={10.1109/ICSTW.2010.6},
  ISSN={},
  month={April},}
@ARTICLE{5464385,
  author={Ueng, Yeong-Luh and Yang, Chung-Jay and Wang, Kuan-Chieh and Chen, Chun-Jung},
  journal={IEEE Transactions on Circuits and Systems I: Regular Papers}, 
  title={A Multimode Shuffled Iterative Decoder Architecture for High-Rate RS-LDPC Codes}, 
  year={2010},
  volume={57},
  number={10},
  pages={2790-2803},
  abstract={For an efficient multimode low-density parity-check (LDPC) decoder, most hardware resources, such as permutators, should be shared among different modes. Although an LDPC code constructed based on a Reed-Solomon (RS) code with two information symbols is not quasi-cyclic, in this paper, we reveal that the structural properties inherent in its parity-check matrix can be adopted in the design of configurable permutators. A partially parallel architecture combined with the proposed permutators is used to mitigate the increase in implementation complexity for the multimode function. The high check-node degree of a high-rate RS-LDPC code leads to challenges in the efficient implementation of a high-throughput decoder. To overcome this difficulty, the variable nodes have been partitioned into several groups, and each group is processed sequentially in order to shorten the critical-path delay and hence increase the maximum operating frequency. In addition, shuffled message-passing decoding is adopted, since fewer iterations can be used to achieve the desired bit-error-rate performance. In order to demonstrate the usefulness of the proposed flexible-permutator-based architecture, one single-mode rate-0.84 decoder and two multimode decoders whose code rates range between 0.79 and 0.93 have been implemented. These decoders can achieve multigigabit-per-second throughput. Using the proposed architecture to support lower rate RS-LDPC codes, e.g., rate-0.568 code, is also investigated.},
  keywords={},
  doi={10.1109/TCSI.2010.2046964},
  ISSN={1558-0806},
  month={Oct},}
@INPROCEEDINGS{5470641,
  author={Lent, Ricardo and Abdelrahman, Omer H. and Gorbil, Gokce and Gelenbe, Erol},
  booktitle={2010 8th IEEE International Conference on Pervasive Computing and Communications Workshops (PERCOM Workshops)}, 
  title={Fast message dissemination for emergency communications}, 
  year={2010},
  volume={},
  number={},
  pages={370-375},
  abstract={This paper presents an emergency communication system that is able to quickly deliver emergency messages over an unreliable and best-effort network such as the Internet. The proposed architecture employs application-layer multicast to rapidly deliver emergency traffic without the support of a dedicated network infrastructure. We introduce a distributed overlay tree construction and maintenance mechanism that produces consistent, loop-free and self-adaptive trees that dynamically change over time to effectively deal with varying network conditions and offer low message delays to end nodes. We evaluate the performance of the proposed approach through an experimental study conducted on a real-life networking testbed.},
  keywords={},
  doi={10.1109/PERCOMW.2010.5470641},
  ISSN={},
  month={March},}
@INPROCEEDINGS{5470683,
  author={Vo, Anh and Gopalakrishnan, Ganesh},
  booktitle={2010 IEEE International Symposium on Parallel & Distributed Processing, Workshops and Phd Forum (IPDPSW)}, 
  title={Scalable verification of MPI programs}, 
  year={2010},
  volume={},
  number={},
  pages={1-4},
  abstract={Large message passing programs today are being deployed on clusters with hundreds, if not thousands of processors. Any programming bugs that happen will be very hard to debug and greatly affect productivity. Although there have been many tools aiming at helping developers debug MPI programs, many of them fail to catch bugs that are caused by non-determinism in MPI codes. In this work, we propose a distributed, scalable framework that can explore all relevant schedules of MPI programs to check for deadlocks, resource leaks, local assertion errors, and other common MPI bugs.},
  keywords={},
  doi={10.1109/IPDPSW.2010.5470683},
  ISSN={},
  month={April},}
@INPROCEEDINGS{5470757,
  author={Holder, Akintayo and Carothers, Christopher D. and Kalafala, Kerim},
  booktitle={2010 IEEE International Symposium on Parallel & Distributed Processing, Workshops and Phd Forum (IPDPSW)}, 
  title={Prototype for a large-scale static timing analyzer running on an IBM Blue Gene}, 
  year={2010},
  volume={},
  number={},
  pages={1-8},
  abstract={This paper focuses on parallelization of the classic static timing analysis (STA) algorithm for verifying timing characteristics of digital integrated circuits. Given ever-increasing circuit complexities, including the need to analyze circuits with billions of transistors, across potentially thousands of process corners, with accuracy tolerances down to the picosecond range, sequential execution of STA algorithms is quickly becoming a bottleneck to the overall chip design closure process. A message passing based parallel processing technique for performing STA leveraging an IBM Blue Gene/L supercomputing platform is presented. Results are collected for a small industrial 65 nm benchmarking design, where the algorithm demonstrates speedup of nearly 39 times on 64 processors and a peak of 119 times (without partitioning costs, speedup is 263 times) on 1024 processors. With an idealized synthetic circuit, the algorithm demonstrated 259 times speedup, 925 times speedup without partitioning overhead, on 1024 processors. To the best of our knowledge, this is the first result demonstrating scalable STA on the IBM Blue Gene.},
  keywords={},
  doi={10.1109/IPDPSW.2010.5470757},
  ISSN={},
  month={April},}
@INPROCEEDINGS{5470780,
  author={Schuff, Derek L. and Parsons, Benjamin S. and Pai, Vijay S.},
  booktitle={2010 IEEE International Symposium on Parallel & Distributed Processing, Workshops and Phd Forum (IPDPSW)}, 
  title={Multicore-aware reuse distance analysis}, 
  year={2010},
  volume={},
  number={},
  pages={1-8},
  abstract={This paper presents and validates methods to extend reuse distance analysis of application locality characteristics to shared-memory multicore platforms by accounting for invalidation-based cache-coherence and inter-core cache sharing. Existing reuse distance analysis methods track the number of distinct addresses referenced between reuses of the same address by a given thread, but do not model the effects of data references by other threads. This paper shows several methods to keep reuse stacks consistent so that they account for invalidations and cache sharing, either as references arise in a simulated execution or at synchronization points. These methods are evaluated against a Simics-based coherent cache simulator running several OpenMP and transaction-based benchmarks. The results show that adding multicore-awareness substantially improves the ability of reuse distance analysis to model cache behavior, reducing the error in miss ratio prediction (relative to cache simulation for a specific cache size) by an average of 70% for per-core caches and an average of 90% for shared caches.},
  keywords={},
  doi={10.1109/IPDPSW.2010.5470780},
  ISSN={},
  month={April},}
@INPROCEEDINGS{5470848,
  author={Tanabe, Noboru and Nakajo, Hironori},
  booktitle={2010 IEEE International Symposium on Parallel & Distributed Processing, Workshops and Phd Forum (IPDPSW)}, 
  title={Acceleration for MPI derived datatypes using an enhancer of memory and network}, 
  year={2010},
  volume={},
  number={},
  pages={1-6},
  abstract={This paper presents a support function for MPI derived datatypes on an enhancer of memory and network named DIMMnet-3. It is a network interface with vector access functions and multi-banked extended memory, which is under development. Semi-hardwired derived datatype communication based on RDMA with hardwired scatter and gather is proposed. This mechanism and MPI using it are implemented and validated on DIMMnet-2 which is a former prototype operating on DDR DIMM slot. The performance of scatter and gather transfer of 8byte elements with large interval by using vector commands of DIMMnet-2 is 6.8 compared with software on a host. Proprietary benchmark of MPI derived datatype communication for transferring a submatrix corresponding to a narrow HALO area is executed. Observed bandwidth on DIMMnet-2 is far higher than that for similar condition with VAPI based MPI implementation on InfniBand, even though very old generation FPGA, poorer CPU and motherboard are used. This function will avoid cache pollution and save CPU time for processing with local data which can be overlapped with communication. A new commercial machine with vector scatter/gather functions in NIC named SGI Altix UV is launched recently. It may be able to adopt our proposed concept partially, even though the capacity and fine grain access throughput of main memory attached with CPU are not enhanced on it.},
  keywords={},
  doi={10.1109/IPDPSW.2010.5470848},
  ISSN={},
  month={April},}
@INPROCEEDINGS{5470876,
  author={Slawinska, Magdalena and Slawinski, Jaroslaw and Sunderam, Vaidy},
  booktitle={2010 IEEE International Symposium on Parallel & Distributed Processing, Workshops and Phd Forum (IPDPSW)}, 
  title={Unibus: Aspects of heterogeneity and fault tolerance in cloud computing}, 
  year={2010},
  volume={},
  number={},
  pages={1-10},
  abstract={The paper describes our on-going project, termed Unibus, in the context of facilitating fault-tolerant executions of MPI applications on computing chunks in the cloud. In general, Unibus focuses on resource access virtualization and automatic, user-transparent resource provisioning that simplify use of heterogeneous resources available to users. In this work, we present the key Unibus concepts (the Capability Model, composite operations, mediators, soft and successive conditionings, metaapplications), and demonstrate how to employ Unibus to orchestrate resources provided by a commercial cloud provider into a fault-tolerant platform, capable of executing message passing applications. In order to support fault tolerance we use DMTCP (Distributed MultiThreaded CheckPointing) that enables checkpointing at the user's level. To demonstrate that the Unibus-created, FT-enabled platform allows to execute MPI applications we ran NAS Parallel Benchmarks and measured the overhead introduced by FT.},
  keywords={},
  doi={10.1109/IPDPSW.2010.5470876},
  ISSN={},
  month={April},}
@INPROCEEDINGS{5470399,
  author={Hood, Robert and Jin, Haoqiang and Mehrotra, Piyush and Chang, Johnny and Djomehri, Jahed and Gavali, Sharad and Jespersen, Dennis and Taylor, Kenichi and Biswas, Rupak},
  booktitle={2010 IEEE International Symposium on Parallel & Distributed Processing (IPDPS)}, 
  title={Performance impact of resource contention in multicore systems}, 
  year={2010},
  volume={},
  number={},
  pages={1-12},
  abstract={Resource sharing in commodity multicore processors can have a significant impact on the performance of production applications. In this paper we use a differential performance analysis methodology to quantify the costs of contention for resources in the memory hierarchy of several multicore processors used in high-end computers. In particular, by comparing runs that bind MPI processes to cores in different patterns, we can isolate the effects of resource sharing. We use this methodology to measure how such sharing affects the performance of four applications of interest to NASA-OVERFLOW, MITgcm, Cart3D, and NCC. We also use a subset of the HPCC benchmarks and hardware counter data to help interpret and validate our findings. We conduct our study on high-end computing platforms that use four different quad-core microprocessors-Intel Clovertown, Intel Harpertown, AMD Barcelona, and Intel Nehalem-EP. The results help further our understanding of the requirements these codes place on their production environments and also of each computer's ability to deliver performance.},
  keywords={},
  doi={10.1109/IPDPS.2010.5470399},
  ISSN={1530-2075},
  month={April},}
@INPROCEEDINGS{5470430,
  author={Deshmeh, Arash and Machina, Jacob and Sodan, Angela},
  booktitle={2010 IEEE International Symposium on Parallel & Distributed Processing (IPDPS)}, 
  title={ADEPT scalability predictor in support of adaptive resource allocation}, 
  year={2010},
  volume={},
  number={},
  pages={1-12},
  abstract={Adaptive resource allocation with different numbers of machine nodes provides more flexibility and significantly better potential performance for local job and grid scheduling. With the emergence of parallel computing in every-day life on multi-core systems, such schedulers will likely increase in practical relevance. A major reason why adaptive schedulers are not yet practically used is lacking knowledge of the scalability curves of the applications. Existing white-box approaches for scalability prediction are too expensive to apply them routinely. We present ADEPT, a speedup and runtime prediction tool, which is inexpensive and easy-to-use. ADEPT employs a black-box model and can be practically applied at large scale without user or administrator involvement. ADEPT requires neither program analysis and measurements nor user guesses but makes highly accurate predictions with only few observations of application runtime over different numbers of nodes/cores. ADEPT performs efficient model fitting by introducing an envelope-derivation technique to constrain the search. Additionally, ADEPT is capable of handling deviations from the underlying model by detection and automatic correction of anomalies via a fluctuation metric and by considering specific scalability patterns via multi-phase modeling. ADEPT also performs reliability judgment with potential proposal for placement of additional observations. Using MPI and OpenMP implementations of the NAS benchmarks and seven real applications, we demonstrate the effectiveness and high prediction accuracy of ADEPT for both speedup and runtime prediction, including interpolative and extrapolative cases, and show the capability of ADEPT to successfully handle special cases.},
  keywords={},
  doi={10.1109/IPDPS.2010.5470430},
  ISSN={1530-2075},
  month={April},}
@INPROCEEDINGS{5473525,
  author={Pan, Bin and Guo, Hong-xia and Liu, Kun},
  booktitle={2010 2nd International Conference on E-business and Information System Security}, 
  title={The Distributed Algorithm Design Based on Web Service}, 
  year={2010},
  volume={},
  number={},
  pages={1-3},
  abstract={Take the forward reasoning algorithm as an example, this paper describes how to design a distributed algorithm with WEB service technology. Based on message passing programming model, the partitioning, communication and the task-scheduling of distributed algorithm are discussed. Finally, the distributed algorithm has been implemented with .NET platform, and tested by the parallel performance measures, and then the results are analyzed.},
  keywords={},
  doi={10.1109/EBISS.2010.5473525},
  ISSN={2161-5977},
  month={May},}
@INPROCEEDINGS{5476638,
  author={Kong, Weiqiang and Shiraishi, Tomohiro and Mizushima, Yuki and Katahira, Noriyuki and Fukuda, Akira and Watanabe, Masahiko},
  booktitle={2010 International Conference on Computational Science and Its Applications}, 
  title={An SMT Approach to Bounded Model Checking of Design in State Transition Matrix}, 
  year={2010},
  volume={},
  number={},
  pages={231-238},
  abstract={State Transition Matrix (STM) is a table-based modeling language that has been frequently used in industry for specifying behavior of distributed systems. Functional correctness of a STM design (i.e., a design written in STM) could usually be expressed as invariant properties. In this paper, we first present a formalization of the static and dynamic aspects of a STM design. Consequentially, based on this formalization, we investigate a symbolic encoding approach for STM design, through which the design could be bounded model checked wrt. invariant properties by using Satisfiability Modulo Theories (SMT) solving technique. We have built a prototype implementation of the proposed encoding and the state-of-the-art SMT solver - Yices is used in our experiments to evaluate the effectiveness of our approach.},
  keywords={},
  doi={10.1109/ICCSA.2010.57},
  ISSN={},
  month={March},}
@INPROCEEDINGS{5480939,
  author={Varghese, Blesson and McKee, Gerard and Alexandrov, Vassil},
  booktitle={2010 IEEE 24th International Conference on Advanced Information Networking and Applications Workshops}, 
  title={Intelligent Agents for Fault Tolerance: From Multi-agent Simulation to Cluster-Based Implementation}, 
  year={2010},
  volume={},
  number={},
  pages={985-990},
  abstract={Recent research in multi-agent systems incorporate fault tolerance concepts, but does not explore the extension and implementation of such ideas for large scale parallel computing systems. The work reported in this paper investigates a swarm array computing approach, namely 'Intelligent Agents'. A task to be executed on a parallel computing system is decomposed to sub-tasks and mapped onto agents that traverse an abstracted hardware layer. The agents intercommunicate across processors to share information during the event of a predicted core/processor failure and for successfully completing the task. The feasibility of the approach is validated by simulations on an FPGA using a multi-agent simulator, and implementation of a parallel reduction algorithm on a computer cluster using the Message Passing Interface.},
  keywords={},
  doi={10.1109/WAINA.2010.21},
  ISSN={},
  month={April},}
@INPROCEEDINGS{5485357,
  author={EffatParvar, MohammadReza and Yazdani, Nasser and EffatParvar, Mehdi and Dadlani, Aresh and Khonsari, Ahmad},
  booktitle={2010 2nd International Conference on Computer Engineering and Technology}, 
  title={Improved algorithms for leader election in distributed systems}, 
  year={2010},
  volume={2},
  number={},
  pages={V2-6-V2-10},
  abstract={An important challenge confronted in distributed systems is the adoption of suitable and efficient algorithms for coordinator election. The main role of an elected coordinator is to manage the use of a shared resource in an optimal manner. Among all the algorithms reported in the literature, the Bully and Ring algorithms have gained more popularity. In this paper, we describe novel approaches towards improving the Bully and Ring algorithms and also propose the heap tree mechanism for electing the coordinator. The higher efficiency and better performance of our presented algorithms with respect to the existing algorithms is validated through extensive simulation results.},
  keywords={},
  doi={10.1109/ICCET.2010.5485357},
  ISSN={},
  month={April},}
@INPROCEEDINGS{5493465,
  author={Mancini, Emilio P. and Marsh, Gregory and Panda, Dhabaleswar K.},
  booktitle={2010 10th IEEE/ACM International Conference on Cluster, Cloud and Grid Computing}, 
  title={An MPI-Stream Hybrid Programming Model for Computational Clusters}, 
  year={2010},
  volume={},
  number={},
  pages={323-330},
  abstract={The MPI programming model hides network type and topology from developers, but also allows them to seamlessly distribute a computational job across multiple cores in both an intra and inter node fashion. This provides for high locality performance when the cores are either on the same node or on nodes closely connected by the same network type. The streaming model splits a computational job into a linear chain of decoupled units. This decoupling allows the placement of job units on optimal nodes according to network topology. Furthermore, the links between these units can be of varying protocols when the application is distributed across a heterogeneous network. In this paper we study how to integrate the MPI and Stream programming models in order to exploit network locality and topology. We present a hybrid MPI-Stream framework that aims to take advantage of each model's strengths. We test our framework with a financial application. This application simulates an electronic market for a single financial instrument. A stream of buy and sell orders is fed into a price matching engine. The matching engine creates a stream of order confirmations, trade confirmations, and quotes based on its attempts to match buyers with sellers. Our results show that the hybrid MPI-Stream framework can deliver a 32% performance improvement at certain order transmission rates.},
  keywords={},
  doi={10.1109/CCGRID.2010.33},
  ISSN={},
  month={May},}
@INPROCEEDINGS{5493386,
  author={Zhou, Shujia and Cruz, Carlos and Duffy, Daniel and Tucker, Robert and Purcell, Mark},
  booktitle={2010 10th IEEE/ACM International Conference on Cluster, Cloud and Grid Computing}, 
  title={Accelerating Climate and Weather Simulations Through Hybrid Computing}, 
  year={2010},
  volume={},
  number={},
  pages={797-801},
  abstract={Unconventional multi- and many-core processors (e.g., IBM® Cell B.E. ™ and NVIDIA® GPU) have emerged as effective accelerators in trial climate and weather simulations. Yet these climate and weather models typically run on parallel computers with conventional processors (e.g., Intel®, AMD®, and IBM) using Message Passing Interface (MPI). To address challenges involved in efficiently and easily connecting accelerators to parallel computers, we investigated using IBM's Dynamic Application Virtualization (DAV) software in a prototype hybrid computing system with representative climate and weather model components. The hybrid system comprises 2 Intel blades and 2 IBM QS22 Cell B.E. blades, connected with both InfiniBand® (IB) and 1-Gigabit Ethernet. The system significantly accelerates a solar radiation model component by offloading compute-intensive calculations to the Cell blades. Systematic tests show that DAV can seamlessly offload compute-intensive calculations from Intel blades to Cell B.E. blades in a scalable, load-balanced manner. However, noticeable communication overhead was observed, mainly due to IP over IB protocol. Full utilization of IB Sockets Direct Protocol (SDP) and the lower latency production version of DAV will reduce this overhead.},
  keywords={},
  doi={10.1109/CCGRID.2010.75},
  ISSN={},
  month={May},}
@INPROCEEDINGS{5493479,
  author={Muresano, Ronal and Rexachs, Dolores and Luque, Emilio},
  booktitle={2010 10th IEEE/ACM International Conference on Cluster, Cloud and Grid Computing}, 
  title={Methodology for Efficient Execution of SPMD Applications on Multicore Environments}, 
  year={2010},
  volume={},
  number={},
  pages={185-195},
  abstract={The need to efficiently execute applications in heterogeneous environments is a current challenge for parallel computing programmers. The communication heterogeneities found in multicore clusters need to be addressed to improve efficiency and speedup. This work presents a methodology developed for SPMD applications, which is centered on managing communication heterogeneities and improving system efficiency on multicore clusters. The methodology is composed of three phases: characterization, mapping strategy, and scheduling policy. We focus on SPMD applications which are designed through a message-passing library for communication, and selected according to their synchronicity and communications volume. The novel contribution of this methodology is it determines the approximate number of cores necessary to achieve a suitable solution with a good execution time, while the efficiency level is maintained over a threshold defined by users. Applying this methodology gave results showing a maximum improvement in efficiency of around 43% in the SPMD applications tested.},
  keywords={},
  doi={10.1109/CCGRID.2010.67},
  ISSN={},
  month={May},}
@INPROCEEDINGS{5496058,
  author={Oguz, Onur and Vandendorpe, Luc and Herzet, Cédric},
  booktitle={2010 IEEE International Conference on Acoustics, Speech and Signal Processing}, 
  title={Lowcomplexity iterative detection in the presence of nuisance parameters}, 
  year={2010},
  volume={},
  number={},
  pages={3194-3197},
  abstract={This work addresses the bit-wise optimal data detection problem when unknown nuisance parameters influence the observation at the receiver. For an arbitrary communications system, the optimal maximum a-posteriori detection problem is first defined as a marginalization of a joint distribution which statistically models the interaction of available sets of variables/parameters. Then, using a factor graph representation with an accompanying sum-product message passing algorithm, it is shown that the marginalization can be performed iteratively. To alleviate complexity due to the marginalization over continuous natured nuisance parameters, variational Bayesian approximation is introduced and it is shown that, if the nuisance parameters are constant for a period of time, the receiver has linear complexity.},
  keywords={},
  doi={10.1109/ICASSP.2010.5496058},
  ISSN={2379-190X},
  month={March},}
@INPROCEEDINGS{5497436,
  author={Huang, Wei and Wei, Gengyu and Hu, Nan and Yang, Yixian},
  booktitle={2010 2nd International Conference on Future Computer and Communication}, 
  title={Design and analysis of heartbeat protocol in NIDS cluster}, 
  year={2010},
  volume={2},
  number={},
  pages={V2-348-V2-352},
  abstract={Heartbeat mechanism is widely used in designing high availability distributed system, while publish-subscribe architectural style has recently emerged as a promising approach to build a NIDS cluster with high dynamism and plenty of computational resources. In comparison with the requirements of general distributed computing, frontend in NIDS cluster cannot redistribute tasks on nodes failure and parallel stateful intrusion detection additionally requires the integrity of received session packets on analyzers. Therefore, the contradictory requirements of immediate node failure notification and infrequent analyzer status variation should be both considered. In this contribution, we designed one heartbeat protocol with four variations in publish-subscribe framework. By applying probabilistic model checking on the proposed heartbeat protocol, uptime ratio of one node in different variations is computed and compared under different setups. Suggestions on how to choose a suitable heartbeat for a NIDS cluster is described as well.},
  keywords={},
  doi={10.1109/ICFCC.2010.5497436},
  ISSN={},
  month={May},}
@INPROCEEDINGS{5501463,
  author={Sindi, Mohamad},
  booktitle={2010 Seventh International Conference on Information Technology: New Generations}, 
  title={Evaluating MPI Implementations Using HPL on an Infiniband Nehalem Linux Cluster}, 
  year={2010},
  volume={},
  number={},
  pages={19-25},
  abstract={In conjunction with Moore's Law, computer speeds are expected to double approximately every two years, but with the current challenges that computer manufacturers are facing to double speeds of individual processors, due to various reasons, such as processor temperatures, multiprocessor architectures have become more popular nowadays. Eventually, this has led to an increased interest in standards for writing parallel applications. The Message Passing Interface (MPI) has become the de facto standard for writing parallel applications. Our growing needs for the latest high performance computing solutions in Saudi Aramco, the world's largest oil producing company, has given us the opportunity to evaluate three of the most commonly used MPI implementations, MVAPICH, Open MPI, and Intel MPI on Intel's latest Nehalem processor. In this paper, we describe our test bed environment along with the evaluations that we did using the High Performance Linpack (HPL) benchmark, which is the standard benchmark for ranking the world's Top 500 supercomputers. We also discuss our own developed Web tool that is used to suggest tuned input values for the HPL benchmark. We show the performance numbers in GFLOPS along with the run times and system efficiencies when running on 32, 64 and 128 Infiniband Nehalem Linux cluster nodes using the three implementations of MPI. We finally discuss our results in terms of performance and scalability and we share our interpretations and future work.},
  keywords={},
  doi={10.1109/ITNG.2010.164},
  ISSN={},
  month={April},}
@INPROCEEDINGS{5503171,
  author={Karimi, Mehdi and Banihashemi, Amir H.},
  booktitle={2010 IEEE Information Theory Workshop on Information Theory (ITW 2010, Cairo)}, 
  title={A message-passing algorithm for counting short cycles in a graph}, 
  year={2010},
  volume={},
  number={},
  pages={1-5},
  abstract={This paper presents a distributed message-passing algorithm for counting short cycles in a graph. For bipartite graphs, which are of particular interest in coding, the algorithm is capable of counting cycles of length g; g+2; ... ; 2g-2, where g is the girth of the graph. For a general (non-bipartite) graph, cycles of length g; g+1; ... ; 2g-1 can be counted. The algorithm is based on performing integer additions and subtractions in the nodes of the graph and passing extrinsic messages to adjacent nodes. The complexity of the proposed algorithm grows as O(g|E|2), where |E| is the number of edges in the graph. For sparse graphs, the proposed algorithm significantly outperforms the existing algorithms in terms of computational complexity and memory requirements.},
  keywords={},
  doi={10.1109/ITWKSPS.2010.5503171},
  ISSN={},
  month={Jan},}
@INPROCEEDINGS{5504232,
  author={Niu, Fan and Li, Dongmei and Peng, Shuai},
  booktitle={2010 Symposium on Photonics and Optoelectronics}, 
  title={Parallel Coding Efficiency Analysis of H.264 on PC Cluster}, 
  year={2010},
  volume={},
  number={},
  pages={1-4},
  abstract={In this paper, we investigate the parallel video coding efficiency on PC cluster. Some important factors that affect the parallel coding efficiency are analyzed: network performance, coding algorithm complexity and parallel mechanism. On Gigabit Ethernet PC cluster, a common MPI-based H.264 parallel video coding mechanism was designed, and a large number of tests and in-depth analysis were performed. Also this paper gives practical data analysis report and advice on how to build high-efficiency parallel video coding system on PC cluster.},
  keywords={},
  doi={10.1109/SOPO.2010.5504232},
  ISSN={2156-8480},
  month={June},}
@INPROCEEDINGS{5513589,
  author={Sayir, Jossy},
  booktitle={2010 IEEE International Symposium on Information Theory}, 
  title={EXIT chart approximations using the role model approach}, 
  year={2010},
  volume={},
  number={},
  pages={694-698},
  abstract={Extrinsic Information Transfer (EXIT) functions can be measured by statistical methods if the message alphabet size is moderate or if messages are true a-posteriori distributions. We propose an approximation we call mixed information that constitutes a lower bound for the true EXIT function and can be estimated by statistical methods even when the message alphabet is large and histogram-based approaches are impractical, or when messages are not true probability distributions and time-averaging approaches are not applicable. We illustrate this with the hypothetical example of a rank-only message passing decoder for which it is difficult to compute or measure EXIT functions in the conventional way. We show that the role model approach [9] can be used to optimize post-processing for the decoder and that it coincides with Monte Carlo integration in the non-parametric case. It is guaranteed to tend towards the optimal Bayesian post-processing estimator and can be applied in a blind setup with unknown code-symbols to optimize the check-node operation for non-binary Low-Density Parity-Check (LDPC) decoders.},
  keywords={},
  doi={10.1109/ISIT.2010.5513589},
  ISSN={2157-8117},
  month={June},}
@INPROCEEDINGS{5522667,
  author={Bombieri, Nicola and Fummi, Franco and Pravadelli, Graziano},
  booktitle={Design Automation Conference}, 
  title={Abstraction of RTL IPs into embedded software}, 
  year={2010},
  volume={},
  number={},
  pages={24-29},
  abstract={High performance provided by multi-processor System-on-Chips (MPSoCs) often induces designers to choose customized processors to execute specific functions rather than using dedicated hardware. On the other hand, reuse of pre-designed and pre-verified IP cores is the key strategy to meet time-to-market while at the same time reducing the error risk during the development of MPSoC designs. In this context, it becomes convenient to translate an existent RTL IP description, originally dedicated to implement an HW component, into pure SW code (i.e., C/C++) to be executed by one or more processors of the MPSoC. This work proposes a methodology to automatically generate SW code by abstracting RTL IP models implemented in hardware description language (HDL). The methodology exploits an abstraction algorithm to eliminate many implementation details typical of the HW descriptions, in order to improve the performance of the generated code.},
  keywords={},
  doi={10.1145/1837274.1837283},
  ISSN={0738-100X},
  month={June},}
@INPROCEEDINGS{5521561,
  author={Koltuksuz, Ahmet and Ozkan, Murat and Kulahcioglu, Burcu},
  booktitle={2010 Fourth International Conference on Secure Software Integration and Reliability Improvement Companion}, 
  title={Modeling Efficient Multi-chained Stream Signature Protocol Using Communicating Sequential Processes}, 
  year={2010},
  volume={},
  number={},
  pages={54-61},
  abstract={Communicating Sequential Processes (CSP) is a process algebra, designed for modeling and analyzing the behavior of concurrent systems. Several security protocols are modeled with CSP and verified using model-checking or theorem proving techniques successfully. Unlike other authentication protocols modeled using CSP, each of the Efficient Multi-chained Stream Signature (EMSS) protocol messages are linked to the previous messages, forming hash chains, which introduces difficulties for modeling and verification. In this paper, we model the EMSS stream authentication protocol using CSP and verify its authentication properties with model checking, by building an infinite state model of the protocol which is reduced into a finite state model.},
  keywords={},
  doi={10.1109/SSIRI-C.2010.23},
  ISSN={},
  month={June},}
@INPROCEEDINGS{5521506,
  author={Li, Baoli and Liu, Wei and Liu, Jiyuan and Zhang, Chunhua},
  booktitle={2010 11th ACIS International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing}, 
  title={Real-Time Implementation of Synthetic Aperture Sonar Imaging on High Performance Clusters}, 
  year={2010},
  volume={},
  number={},
  pages={89-92},
  abstract={A flexible and scalable architecture that implements real-time synthetic aperture sonar (SAS) imaging on high performance clusters (HPCs) is introduced in this paper. Combing HPCs with application of a hybrid MPI and OpenMP parallel programming model, the lookup table algorithm for SAS image reconstruction based on the time-domain correlation algorithm is realized in parallel. Considering the huge computation load of the lookup table algorithm, the pulse-compressed data is partitioned into strips along the range direction which are distributed to the nodes of HPCs. The scalability allows the lookup table imaging cluster nodes to be added or removed without needing to recompile the existing software, and automatic burden balancing is considered. The result of lake trial verifies that this parallel algorithm on HPCs can provide good quality images and meantime have highly real time rate.},
  keywords={},
  doi={10.1109/SNPD.2010.23},
  ISSN={},
  month={June},}
@INPROCEEDINGS{5522689,
  author={Yongmu, Tong and Xiaoyan, Zheng},
  booktitle={2010 International Conference on Intelligent Computation Technology and Automation}, 
  title={An Algorithm to Construct FP-Tree on VODCA}, 
  year={2010},
  volume={1},
  number={},
  pages={485-488},
  abstract={To construct FP-Tree in mining frequent pattern, we propose a parallel algorithm CFPV (Construct FP-Tree on VODCA) for construct FP-Tree. This method is based on a new parallel computing environment on the distributed shared memory, called View-Oriented, Distributed, Cluster-based Approach to parallel computing (VODCA). It discusses the fact of views division and the results when generate FP-Tree on VODCA, and discusses the dynamic task allocation strategy of the algorithm. The experimental results prove the correctness and effectiveness of CFPV algorithm.},
  keywords={},
  doi={10.1109/ICICTA.2010.280},
  ISSN={},
  month={May},}
@INPROCEEDINGS{5533683,
  author={Sović, Ivan and Antulov-Fantulin, Nino and Čanadi, Igor and Piškorec, Matija and Šikić, Mile},
  booktitle={The 33rd International Convention MIPRO}, 
  title={Parallel Protein Docking Tool}, 
  year={2010},
  volume={},
  number={},
  pages={1333-1338},
  abstract={Parallel Protein Docking Tool (PPDT) system is performing a shape based process of protein docking using spherical harmonics. The software is made from scratch in C++. Input data are two PDB (Protein Data Bank) files and desired docking parameters. The PDB files hold information about protein's atom coordinates in three dimensional space. Protein structures are transformed with spherical functions which allow fast rotation and translation of 3D shapes in space. By translation and rotation (with a given resolution of angles and distance) the surface complementarity is tested for each orientation of two proteins in 3D space. The orientations are then ranked according to the given scores. The output PDB file now holds orientations with best scores ready for visualization. As a part of the system a tool for visualization of molecules was developed. It's purpose is to provide a visualization of molecular structure in all phases of protein docking process. The visualizer also allows interactive translation and rotation of input proteins and evaluation of their complementarity in real time. Although docking tools that use spherical harmonics already exist, we implemented a parallel version using MPI (message passing interface). In this implementation any worker MPI process independently makes docking search on six dimensional subspace determined by parameters in its task. PPDT has high scalability, modularity, variable granularity of tasks and provides significant speedup comparing to a non-parallel version of software.},
  keywords={},
  doi={},
  ISSN={},
  month={May},}
@INPROCEEDINGS{5537618,
  author={Zhou, Shuai and Sha, Jin and Li, Li and Wang, Zhongfeng},
  booktitle={Proceedings of 2010 IEEE International Symposium on Circuits and Systems}, 
  title={Layered decoding for non-binary LDPC codes}, 
  year={2010},
  volume={},
  number={},
  pages={481-484},
  abstract={In this paper, we present a layered decoding algorithm for non-binary LDPC codes. Differing from the flooding message-passing schedule in conventional designs, the proposed scheme updates check node messages in serial. Furthermore, since fully serial decoding will lead to long latency, the locally-parallel globally-serial schedule is adopted. Basically the check nodes can be divided into several groups, i.e. layers. The layers are processed one by one while the check nodes in each layer are processed in parallel. Simulation results show that the proposed algorithm not only brings some improvement in error correcting performance but also gives some advantage in VLSI implementation of efficient partially parallel decoders.},
  keywords={},
  doi={10.1109/ISCAS.2010.5537618},
  ISSN={2158-1525},
  month={May},}
@INPROCEEDINGS{5537953,
  author={Gu, Ming and Liu, Yang and Chakrabartty, Shantanu},
  booktitle={Proceedings of 2010 IEEE International Symposium on Circuits and Systems}, 
  title={FAST: A simulation framework for solving large-scale probabilistic inverse problems in nano-biomolecular circuits}, 
  year={2010},
  volume={},
  number={},
  pages={3160-3163},
  abstract={Inverse problems in nano-biomolecular circuits typically involve stochastic functional elements that admit non-linear relationships between different circuit variables. In this regard, a factor graph representation serves as an important visualization and analysis tool that can be used to compute inferences over an arbitrary large-scale biomolecular circuit. Solving the inverse problem using a factor graph entails passing of messages/signals between the internal nodes of the biomolecular circuit, and the steady-state distribution of the messages can be used to determine the dynamics of the circuit and the final solution. In this paper, we present an open-source simulation tool that we have developed which can be used to verify the functionality of a generic nano-biomolecular circuit. As a representative example, we apply the simulation software to estimate the reliability of a 103 size biosensor array where each element of the array is comprised of our previously reported antigen-antibody based biomolecular circuit. This example will demonstrate the utility of the proposed software in emulating the functionality of micro and nano biosensor arrays without resorting to time-consuming and laborious fabrication procedure and laboratory experiments.},
  keywords={},
  doi={10.1109/ISCAS.2010.5537953},
  ISSN={2158-1525},
  month={May},}
@INPROCEEDINGS{5536695,
  author={Ouled Abdallah, Nesrine and Hadj Kacem, Hatem and Mosbah, Mohamed and Zemmari, Akka},
  booktitle={2010 10th Annual International Conference on New Technologies of Distributed Systems (NOTERE)}, 
  title={Broadcast in wireless mobile sensor networks with population protocols and extension with the rendezvous model}, 
  year={2010},
  volume={},
  number={},
  pages={219-226},
  abstract={Wireless sensor networks are a new generation of network which needs specific models and algorithms. We are interested specifically to mobile wireless sensor networks which are considered as anonymous asynchronous distributed mobile systems. As broadcast is one of the most important applications for this kind of networks, and as it depends on the communication model used in the network, we tried to find the most adequate one to make a distributed broadcast algorithm. We adopted the model presented by Angluin of pairwise interactions of anonymous finite-state agents to broadcast information: the population protocol. We tried to modify this model to avoid duplication of the information and calculate its complexity. Then, we extended it with the rendezvous one which made the stabilization faster. The implementation, the simulation and the validation of these algorithms and results were done with Visidia.},
  keywords={},
  doi={10.1109/NOTERE.2010.5536695},
  ISSN={2162-190X},
  month={May},}
@INPROCEEDINGS{5541537,
  author={Bocu, Razvan and Tabirca, Sabin},
  booktitle={9th RoEduNet IEEE International Conference}, 
  title={Protein communities detection optimization through an improved Parallel Newman-Girvan algorithm}, 
  year={2010},
  volume={},
  number={},
  pages={380-385},
  abstract={Proteins and the networks they determine, called interactome networks, have received attention at an important degree during the last years, because they have been discovered to have an influence on some complex biological phenomena, such as problematic disorders like cancer. This paper presents a contribution that aims to optimize the Newman-Girvan community detection algorithm through a parallel implementation that is based on the MPI C programming environment. The optimization involves a double improvement of the original Newman-Girvan algorithm, which is accomplished both at the algorithmic and programming level. The resulting parallel implementation's performance was carefully tested on real biological data and the results acknowledge the relevant speedup that the optimization determines. Moreover, the results are in line with the previous findings that our current research produced, as it reveals and confirms the existence of some important properties of those proteins that participate in the carcinogenesis process. Apart from being particularly useful for research purposes, the novel technique also speeds up the proteomic databases analysis process, as compared to some of the sequential community detection approaches, and also to the original sequential Newman-Girvan algorithm.},
  keywords={},
  doi={},
  ISSN={2247-5443},
  month={June},}
@INPROCEEDINGS{5541686,
  author={Onus, Melih and Richa, Andréa W.},
  booktitle={2010 IEEE 30th International Conference on Distributed Computing Systems}, 
  title={Parameterized Maximum and Average Degree Approximation in Topic-Based Publish-Subscribe Overlay Network Design}, 
  year={2010},
  volume={},
  number={},
  pages={644-652},
  abstract={Publish/subscribe communication systems where nodes subscribe to many different topics of interest are becoming increasingly more common. Designing overlay networks that connect the nodes subscribed to each distinct topic is hence a fundamental problem in these systems. For scalability and efficiency, it is important to keep the degree of the nodes in the publish/subscribe system low. Ideally one would like to be able not only to keep the average degree of the nodes low, but also to ensure that all nodes have equally the same degree, giving rise to the following problem: Given a collection of nodes and their topic subscriptions, connect the nodes into a graph with low average and maximum degree such that for each topic t, the graph induced by the nodes interested in t is connected. We present the first polynomial time parameterized sub linear approximation algorithm for this problem. We also propose two heuristics for constructing topic connected networks with low average degree and constant diameter and validate our results through simulations. In fact, the results in this section are a refinement of the preliminary results by Onus and Richa in INFOCOM'09.},
  keywords={},
  doi={10.1109/ICDCS.2010.54},
  ISSN={1063-6927},
  month={June},}
@INPROCEEDINGS{5541046,
  author={Juanjuan Bai and Ling Gao and Lidong He},
  booktitle={2010 International Conference On Computer Design and Applications}, 
  title={Constructing windows+gcc+mpi+omp and performance testing with Gauss-Jordan elimination method in finding the inverse of a matrix}, 
  year={2010},
  volume={2},
  number={},
  pages={V2-20-V2-23},
  abstract={In this paper the hybrid programming model is stated briefly, windows+gcc+mpi+omp is constructed in the multi-core cluster system, and the configuration is tested by the implementation of Gauss-Jordan elimination method in finding the inverse of a matrix. Experimental results show that we have successfully constructed windows+gcc+mpi+omp, and the running time of Gauss- Jordan elimination method in finding the inverse of a matrix is reduced significantly.},
  keywords={},
  doi={10.1109/ICCDA.2010.5541046},
  ISSN={},
  month={June},}
@INPROCEEDINGS{5543355,
  author={Kato, Toshiji and Inoue, Kaoru and Kumiki, Yudai and Yamane, Masashi},
  booktitle={The 2010 International Power Electronics Conference - ECCE ASIA -}, 
  title={Efficient steady-state computation of a power electronic converter system by the envelope following method}, 
  year={2010},
  volume={},
  number={},
  pages={672-679},
  abstract={A fast and efficient steady-state simulation method of a power electronic (PE) system is proposed. The conventional methods are efficient only for a single-rate periodic system. The proposed method is efficient also for a multi-rate periodic system including a PE system which has a short switch and a long system periods. Its principle is based on a new extended combination of the envelope-following and the conventional shooting methods which solve the steady-state boundary value condition set efficiently. Furthermore the multiple shooting technique is utilized to solve circuit and sensitivity equations efficiently in parallel by a cluster computing system based on MPI (Message-Passing-Interface). Examples of a motor drive system controlled by a converter are analyzed and their results are validated for accuracy and computational efficiency.},
  keywords={},
  doi={10.1109/IPEC.2010.5543355},
  ISSN={},
  month={June},}
@INPROCEEDINGS{5547147,
  author={Chen, T. Francis and Baranoski, Gladimir V. G.},
  booktitle={2010 International Conference on High Performance Computing & Simulation}, 
  title={Extending the educational scope of a particle-based simulation framework through parallelization}, 
  year={2010},
  volume={},
  number={},
  pages={115-124},
  abstract={Particle systems have been incorporated into a wide variety of applications in both academia and industry. They can be employed to investigate complex natural phenomena, illustrate scientific concepts and generate special effects for entertainment purposes. Recently, we implemented an educational simulation framework based on particle systems that can be used to perform interactive virtual experiments involving complex physical laws. The positive feedback received from a pilot deployment of this framework motivated us to look for strategies to increase its scope. However, more complex and engaging simulations require the use of a larger number of geometric primitives (particles), which results in higher computational costs. To mitigate these costs, we resorted to the implementation of parallel techniques through the use of the Message Passing Interface (MPI) standard. In this paper, we describe these techniques and discuss the performance gains resulting from their application to the simulation algorithm that forms the core of our framework. These results were obtained through practical test cases which are also described in detail in this paper.},
  keywords={},
  doi={10.1109/HPCS.2010.5547147},
  ISSN={},
  month={June},}
@INPROCEEDINGS{5552303,
  author={Chen, Yuting},
  booktitle={2010 IEEE International Conference on Software Engineering and Service Sciences}, 
  title={A case study of using SOFL to specify a concurrent software system}, 
  year={2010},
  volume={},
  number={},
  pages={79-82},
  abstract={SOFL, a formal engineering method which was designed by integrating different notations and techniques, can be used for specification and verification of large-scale software systems. Regions and channels can also be introduced to the SOFL language so that concurrency can be easily specified in the specification of a concurrent software system. In this paper we present a case study of using SOFL specification language for specifying a concurrent software system in order to show the usability of regions and channels in modeling. We also discuss some important issues about the specifications of concurrent software systems.},
  keywords={},
  doi={10.1109/ICSESS.2010.5552303},
  ISSN={2327-0594},
  month={July},}
@INPROCEEDINGS{5552534,
  author={González, I. and Gómez, J. and Tayebi, A. and Delgado, C. and Cátedra, F.},
  booktitle={2010 14th International Symposium on Antenna Technology and Applied Electromagnetics & the American Electromagnetics Conference}, 
  title={A domain decomposition moment method approach for analysis of complex reflectorarrays}, 
  year={2010},
  volume={},
  number={},
  pages={1-4},
  abstract={An efficient domain decomposition approach for electromagnetic field analysis of complex 3D antennas is presented. The method combines the Moment Method (MM), the Multilevel Fast Multipole Algorithm (MLFMA), Physics Optics (PO) and the Domain Decomposition Method to provide fast and accurate analysis of arbitrary metallic and dielectric/magnetic structures, and to solve very large scattering problems. Moreover, in order to minimize memory and time requirements, a parallelization process has been carried out by using the Message Passing Interface (MPI) algorithm. The code has been validated in many applications providing accurate predictions compared with measurements. As an example, a dual-band reflectarray is analyzed to check the performance of the proposed code.},
  keywords={},
  doi={10.1109/ANTEM.2010.5552534},
  ISSN={},
  month={July},}
@INPROCEEDINGS{5554179,
  author={Shuju Wang and Tianxia Zhang and Guosheng Zhang and Liquan Yao},
  booktitle={2010 8th World Congress on Intelligent Control and Automation}, 
  title={Scheduling design of automotive TTCAN Control system based on average loading}, 
  year={2010},
  volume={},
  number={},
  pages={6772-6775},
  abstract={To meet high performances of automotive time-triggered CAN (TTCAN) real-time control bus, a key problem is how to distribute time windows within system matrix of TTCAN, a new harmonic periods makeup (HPM) scheduling optimization algorithm based on average loading was proposed and the scheduling strategy was explained concretely. The HPM scheduling algorithm aimed to make event-triggered messages gain the maximum transmission times by minimizing the space occupied by time-triggered messages. A scheduling tool for TTCAN networks that generates a valid scheduling table using HPM was presented. Finally, a PSA message set is introduced to validate the algorithm,through optimization for the message set, the time performances of event triggered messages and then the whole system performances get improved.},
  keywords={},
  doi={10.1109/WCICA.2010.5554179},
  ISSN={},
  month={July},}
@INPROCEEDINGS{5554533,
  author={Chen, Xinquan},
  booktitle={2010 8th World Congress on Intelligent Control and Automation}, 
  title={An affinity propagation algorithm embedded in Optimizable Dissimilarity Measure}, 
  year={2010},
  volume={},
  number={},
  pages={5994-5998},
  abstract={It gives an Affinity Propagation Clustering algorithm embedded in Optimizable Dissimilarity Measure(APCODM), in order to find a more meaningful clustering distribution by searching a better dissimilarity measure in hybrid attributes data space. After some necessary discuss, it gives its time complexity and astringency analysis. The APCODM can some time get a better clustering quality validated by experiments of several data sets. At last, it indicates several valuable research expectations.},
  keywords={},
  doi={10.1109/WCICA.2010.5554533},
  ISSN={},
  month={July},}
@INPROCEEDINGS{5564524,
  author={Jiang Jian and He Yi},
  booktitle={2010 3rd International Conference on Computer Science and Information Technology}, 
  title={Grid-based parallel computing platform design and implementation}, 
  year={2010},
  volume={8},
  number={},
  pages={563-567},
  abstract={Based on the research on the existing grid and parallel computing technologies, this paper proposes a grid-based parallel computing platform design scheme, and implements the key modules in it. The test results show that the platform acceleration effect is very significant, and this platform is simple, fast and easy to implement.},
  keywords={},
  doi={10.1109/ICCSIT.2010.5564524},
  ISSN={},
  month={July},}
@INPROCEEDINGS{5562961,
  author={Chen, Yuting and Liu, Shaoying and Wang, Linzhang},
  booktitle={2010 10th International Conference on Quality Software}, 
  title={An Extension to Data-Flow-Oriented Formal Specification Language for Specifying Concurrent Software Systems}, 
  year={2010},
  volume={},
  number={},
  pages={214-219},
  abstract={Data-flow-oriented formal specification languages, such as SOFL, bridge formal methods to industrial applications, allowing software developers to effectively use formal methods in developing practical software systems. In this paper, we introduce an extension to SOFL specification language for specifying concurrent software systems. SOFL is designed by integrating different notations and techniques on the basis that they are all needed to work together effectively in a coherent manner for specification constructions and verifications. We mainly introduce two notions, region and channel, to the SOFL language so that concurrency can be specified both graphically and formally, thus making SOFL specifications both intuitive and precise.},
  keywords={},
  doi={10.1109/QSIC.2010.49},
  ISSN={2332-662X},
  month={July},}
@INPROCEEDINGS{5567904,
  author={Wang, Hongping and Zhang, Juan and Liu, Xiuguo and Huang, Xiaodong},
  booktitle={2010 18th International Conference on Geoinformatics}, 
  title={Parallel algorithm design for remote sensing image processing in the PC cluster environment}, 
  year={2010},
  volume={},
  number={},
  pages={1-5},
  abstract={In the PC cluster environment, parallel algorithms can significantly improve the efficiency of remote sensing image processing. The remote sensing dataset is the raster data stored by order of band, therefore, it is feasible to assign executable tasks to some computing nodes by band and complete the processing tasks together through communicating each other amount the computing nodes by MPI interface. In addition, the multi-thread processing algorithm is scheduled based on OpenMP library toward the single computing node with multi-core CPU. The experiment evaluates image radiation performance about the four-band HJ-1A CCD remote sensing image in the PC cluster environment which consists of 4 sets of dual-core computers. Its performance is increased by 6 times to 6.5 times comparing with a single PC. Through validating, the dual level design pattern is available based on integrating MPI and OpenMP to improve the efficiency of remote sensing image processing.},
  keywords={},
  doi={10.1109/GEOINFORMATICS.2010.5567904},
  ISSN={2161-0258},
  month={June},}
@INPROCEEDINGS{5578414,
  author={Che, Yonggang and Xu, Chuanfu and Lu, Pingjing},
  booktitle={2010 10th IEEE International Conference on Computer and Information Technology}, 
  title={Evaluating the Performance and Accuracy Impact of Trace Generation to the BigSim Emulator}, 
  year={2010},
  volume={},
  number={},
  pages={2908-2913},
  abstract={This paper quantitatively studies the trace effects to the performance and accuracy of the BigSim Emulator, a scalable parallel emulator for large-scale computers. To assess the accuracy effect we modify the emulator code to collect the predicted computation time. Four MPI programs with different computation to communication ratios are used as benchmarks. The emulation time and the predicted computation time, both when trace generation are enabled and disabled, are collected on two parallel host machines. The results show that although the BigSim Emulator only traces communication events and dependencies, trace generation still evidently degrades the emulation performance for programs with high communication to computation ratios. Trace generation also significantly affects the accuracy of the predicted computation time for communication intensive programs, which is an issue that can not be overlooked.},
  keywords={},
  doi={10.1109/CIT.2010.486},
  ISSN={},
  month={June},}
@INPROCEEDINGS{5577877,
  author={Wang, Zhiyuan and Yang, Xuejun and Zhou, Yun},
  booktitle={2010 10th IEEE International Conference on Computer and Information Technology}, 
  title={MMPI: A Scalable Fault Tolerance Mechanism for MPI Large Scale Parallel Computing}, 
  year={2010},
  volume={},
  number={},
  pages={1251-1256},
  abstract={At present, Checkpoint/Restart is one of the most popular fault tolerance mechanisms for large scale parallel computing. However, the time to save a global checkpoint reaches and even exceeds the mean-time-between-failures (MTBF) of the component when the performance of the system is between Peta(10^{15}) and Exa(10^{18}) flops, which limits the scalability of the parallel computing. In this paper, a scalable fault tolerance mechanism is designed for MPI-oriented large scale parallel computing, which not only can deal with the fail-stop faults concerned by Checkpoint/Restart, but also can deal with most data errors that are not perceived by hardware. Firstly, we define the concept of redundant-process cluster (RPC), design running techniques that support MMPI, and study the implementation of MMPI. Secondly, we present the models of fault tolerance parallel speedup, Lastly, we verify the validity and scalability of MMPI fault tolerance mechanism.},
  keywords={},
  doi={10.1109/CIT.2010.226},
  ISSN={},
  month={June},}
@INPROCEEDINGS{5584221,
  author={Zhang, Zhi-zeng and Li, Zhong-kui},
  booktitle={2010 Sixth International Conference on Natural Computation}, 
  title={Back analysis on mechanical parameters based on a master-slave parallel genetic algorithm}, 
  year={2010},
  volume={5},
  number={},
  pages={2301-2305},
  abstract={By combining the inherent parallelism of genetic algorithms with the high-speed parallelism of cluster system, a back analysis method of mechanical parameters based on a master-slave parallel genetic algorithm is presented. Several improved methods are adopted: real code is used to shorten the length of individual code and reduce the search space; dynamic tasks allocation is used to avoid uneven processor efficiency; loose coupling method is used to couple a master-slave parallel genetic algorithm with a numerical software. Besides theoretical analysis, the back analysis program is written and compiled in C, and it is also tested by a standard elastic problem. The test results indicate the back analysis program can get high precision and approach linear speedup ratio along with the increase of problem size. Therefore, this back analysis method is applicable and propagable, which can satisfy the timeliness of engineering.},
  keywords={},
  doi={10.1109/ICNC.2010.5584221},
  ISSN={2157-9563},
  month={Aug},}
@INPROCEEDINGS{5581594,
  author={Xu, Qiang and Subhlok, Jaspal and Hammen, Nathaniel},
  booktitle={2010 IEEE International Symposium on Modeling, Analysis and Simulation of Computer and Telecommunication Systems}, 
  title={Efficient Discovery of Loop Nests in Execution Traces}, 
  year={2010},
  volume={},
  number={},
  pages={193-202},
  abstract={Execution and communication traces are central to performance modeling and analysis. Since the traces can be very long, meaningful compression and extraction of representative behavior is important. Commonly used compression procedures identify repeating patterns in sections of the input string and replace each instance with a representative symbol. This can prevent the identification of long repeating sequences corresponding to outer loops in a trace. This paper introduces and analyzes a framework for identifying the maximal loop nest from a trace. The discovery of loop nests makes construction of compressed representative traces straightforward. The paper also introduces a greedy algorithm for fast ``near optimal'' loop nest discovery with well defined bounds. Results of compressing MPI communication traces of NAS parallel benchmarks show that both algorithms identified the basic loop structures correctly. The greedy algorithm was also very efficient with an average processing time of 16.5 seconds for an average trace length of 71695 MPI events.},
  keywords={},
  doi={10.1109/MASCOTS.2010.28},
  ISSN={2375-0227},
  month={Aug},}
@INPROCEEDINGS{5586549,
  author={Hernández, Luis Germán Pérez and Vázquez, Katya Rodríguez and Juárez, Ramón Garduño},
  booktitle={IEEE Congress on Evolutionary Computation}, 
  title={Estimation of 3D Protein Structure by means of parallel Particle Swarm Optimization}, 
  year={2010},
  volume={},
  number={},
  pages={1-8},
  abstract={This paper presents the Algorithm of Particle Swarm Optimization (PSO) implemented in a Distributed Computing Environment. The main objective of this PSO is to calculate the Protein 3D Structure reducing the computational time to carry out this task; this problem is also known as Protein Folding Problem (PFP). The parallel PSO works on a real conformation, considering structural restriction of the protein, where the conformation uses a representation of torsion angles of the skeleton and the side chains, applying the sequence of amino-acid of the protein for the prediction of 3D structure of minimum energy. In order to calculate the energy of the protein conformation, the energy empirical function ECEPP/3 is used. This program was implemented for running in a cluster with the libraries MPI for the processor communication. The quality of the results on the testing peptide (leuenkephalin) is compared with other techniques reported in literature, and also the PSO is used to predict the structure of unknown proteins.},
  keywords={},
  doi={10.1109/CEC.2010.5586549},
  ISSN={1941-0026},
  month={July},}
@INPROCEEDINGS{5581451,
  author={Diener, Matthias and Madruga, Felipe and Rodrigues, Eduardo and Alves, Marco and Schneider, Jorg and Navaux, Philippe and Heiss, Hans-Ulrich},
  booktitle={2010 IEEE 12th International Conference on High Performance Computing and Communications (HPCC)}, 
  title={Evaluating Thread Placement Based on Memory Access Patterns for Multi-core Processors}, 
  year={2010},
  volume={},
  number={},
  pages={491-496},
  abstract={Process placement is a technique widely used on parallel machines with heterogeneous interconnects to reduce the overall communication time. For instance, two processes which communicate frequently are mapped close to each other. Finding the optimal mapping between threads and cores in a shared-memory environment (for example, OpenMP and Pthreads) is an even more complex task due to implicit communication. In this work, we examine data sharing patterns between threads in different workloads and use those patterns in a similar way as messages are used to map processes in cluster computers. We evaluated our technique on a state-of-the-art multicore processor and achieved moderate improvements in the common case and considerable improvements in some cases, reducing execution time by up to 45%.},
  keywords={},
  doi={10.1109/HPCC.2010.114},
  ISSN={},
  month={Sep.},}
@INPROCEEDINGS{5581334,
  author={Ciechanowicz, Philipp and Kuchen, Herbert},
  booktitle={2010 IEEE 12th International Conference on High Performance Computing and Communications (HPCC)}, 
  title={Enhancing Muesli's Data Parallel Skeletons for Multi-core Computer Architectures}, 
  year={2010},
  volume={},
  number={},
  pages={108-113},
  abstract={Algorithmic skeletons encapsulate typical parallel programming patterns such that they can be easily applied by users. Existing skeleton libraries usually work on distributed memory machines. We present an extension of our skeleton library Muesli which now allows to use the same application without modifications on a variety of parallel machines ranging from multi-processor distributed memory to many-core shared memory machines and combinations of those such as clusters of multi-core nodes. Internally, the skeletons are based on MPI and Open MP. We demonstrate the efficiency of our approach by providing experimental results.},
  keywords={},
  doi={10.1109/HPCC.2010.23},
  ISSN={},
  month={Sep.},}
@INPROCEEDINGS{5581329,
  author={Liu, Zhiqiang and Ren, Kaijun and Song, Junqiang},
  booktitle={2010 IEEE 12th International Conference on High Performance Computing and Communications (HPCC)}, 
  title={MPIActor - A Multicore-Architecture Adaptive and Thread-Based MPI Program Accelerator}, 
  year={2010},
  volume={},
  number={},
  pages={98-107},
  abstract={Improving MPI foundational software to suit multicore systems is a key issue for developing effective parallel software on high performance communication domain. Towards this issue, in this paper, we propose a novel technique, called MPI Accelerator or MPIActor in short, which is a transparent middleware to enhance conventional MPI libraries. The main idea is to optimize MPI routines for multicore systems by adopting threaded MPI mechanism and multicore architecture aware collectives in MPIActor. With the join of MPIActor, on one hand, all MPI processes in each node are mapped to several threads in one process. As a result, the overhead of intra-node point-to-point communications can greatly decrease. On the other hand, the collective routines are implemented by the cooperation of individual intra - and inter-node collective subroutines, and the intra-node collective subroutines can be further optimized by multicore architecture aware collective algorithms. Based on above idea, a framework involving an MPI_Reduce routine and a set of point-to-point communication routines has been implemented and evaluated on a 256 cores Nehalem platform. When compared to the performance of MVAPICH2, the final experimental results show that the performance by MPIActor can be significantly improved whatever by using OSU_LATENCY benchmark for point-to-point communications or IMB Reduce benchmark for reduction collectives. Especially, the performance results of using OSU_LATENCY benchmark even can be improved up to 321%.},
  keywords={},
  doi={10.1109/HPCC.2010.89},
  ISSN={},
  month={Sep.},}
@INPROCEEDINGS{5592686,
  author={Harrison, Willie K. and Almeida, João and Klinc, Demijan and McLaughlin, Steven W. and Barros, João},
  booktitle={2010 IEEE Information Theory Workshop}, 
  title={Stopping sets for physical-layer security}, 
  year={2010},
  volume={},
  number={},
  pages={1-5},
  abstract={Physical-layer security based on wiretap codes can be used to complement cryptographic applications at higher layers of the protocol stack. We assume a passive eavesdropper that has access to noise-corrupted codewords with erasures that are statistically independent to those of the legitimate communication partners. Our goal is to minimize the information leaked to the eavesdropper. In this paper we present a low-complexity coding scheme for channels with feedback, which employs extensive interleaving of carefully punctured LDPC codewords. The key idea is to ensure that every transmitted packet is crucial for successful decoding. This is achieved by ensuring that stopping-set bit combinations for coded blocks are distributed among different packets and by enforcing that retransmission requests be restricted to the friendly parties. A probabilistic analysis reveals that an eavesdropper who uses a message-passing decoding algorithm will experience catastrophic decoding failure with high probability. This encoder thus provides physical-layer secrecy which is both independent from, and complementary of, the cryptographic layer. The proposed scheme works even when an eavesdropper has a better channel than the legitimate receiver.},
  keywords={},
  doi={10.1109/CIG.2010.5592686},
  ISSN={},
  month={Aug},}
@INPROCEEDINGS{5592821,
  author={Cappellari, Lorenzo},
  booktitle={2010 IEEE Information Theory Workshop}, 
  title={Lossy source compression of non-uniform binary sources using GQ-LDGM codes}, 
  year={2010},
  volume={},
  number={},
  pages={1-5},
  abstract={In this paper, we study the use of GF(q)-quantized LDGM codes for binary source coding. By employing quantization, it is possible to obtain binary codewords with a non-uniform distribution. The obtained statistics is hence suitable for optimal, direct quantization of non-uniform Bernoulli sources. We employ a message-passing algorithm combined with a decimation procedure in order to perform compression. The experimental results based on GF(q)-LDGM codes with regular degree distributions yield performances quite close to the theoretical rate-distortion bounds.},
  keywords={},
  doi={10.1109/CIG.2010.5592821},
  ISSN={},
  month={Aug},}
@INPROCEEDINGS{5589039,
  author={Wu, Qinmu and Liu, Jiangning and Li, Yesong},
  booktitle={2010 IEEE International Conference on Mechatronics and Automation}, 
  title={A study on message scheduling method based on delay time constraint}, 
  year={2010},
  volume={},
  number={},
  pages={783-787},
  abstract={A message scheduling method suitable for CAN-based bus networks is presented in this paper, it realizes message scheduling by dynamically changing identifier of message. The method can effectively guarantee that all messages can be successfully transmitted to destination nodes within given delay time, and the network bandwidth resources can also be fairly distributed to all message streams. In this method, the priority level of message waiting transmission is added by certain proportion value relating to the given delay time. This paper gives mathematical model of the proposed scheduling method, and analyses the condition of full schedulability of messages. The correctness of the condition and the validity of the scheduling method has been verified by some experimental results.},
  keywords={},
  doi={10.1109/ICMA.2010.5589039},
  ISSN={2152-744X},
  month={Aug},}
@INPROCEEDINGS{5588878,
  author={Varghese, Blesson and McKee, Gerard and Alexandrov, Vassil},
  booktitle={Proceedings of the 2010 International Symposium on Performance Evaluation of Computer and Telecommunication Systems (SPECTS '10)}, 
  title={Handling single node failures using agents in computer clusters}, 
  year={2010},
  volume={},
  number={},
  pages={96-101},
  abstract={The work reported in this paper is motivated towards handling single node failures for parallel summation algorithms in computer clusters. An agent based approach is proposed in which a task to be executed is decomposed to sub-tasks and mapped onto agents that traverse computing nodes. The agents intercommunicate across computing nodes to share information during the event of a predicted node failure. Two single node failure scenarios are considered. The Message Passing Interface is employed for implementing the proposed approach. Quantitative results obtained from experiments reveal that the agent based approach can handle failures more efficiently than traditional failure handling approaches.},
  keywords={},
  doi={},
  ISSN={},
  month={July},}
@INPROCEEDINGS{5598219,
  author={Moumen, Hamouma and Mostefaoui, Achour},
  booktitle={2010 Ninth IEEE International Symposium on Network Computing and Applications}, 
  title={Time-Free Authenticated Byzantine Consensus}, 
  year={2010},
  volume={},
  number={},
  pages={140-146},
  abstract={This paper presents a simple protocol that solves the authenticated Byzantine Consensus problem in asynchronous distributed systems. To circumvent the FLP impossibility result in a deterministic way, synchrony assumptions should be added. In the context of Byzantine failures for systems where at most t processes may exhibit a Byzantine behavior and where not all the system is assumed eventually synchronous, Moumen et al. provide the main result. They assume at least one correct process, called 2t-bisource, connected with 2t privileged neighbors with eventually timely outgoing and incoming links. The present paper shows that a deterministic solution for the authenticated byzantine consensus problem is possible if the system model satisfies an additional assumption that does not rely on physical time but on the pattern of messages that are exchanged. The basic message exchange between processes is the query-response mechanism. To solve the Consensus problem, we assume a correct process p, called 2t-winning process, and a set Q of 2t processes such that, eventually, for each query issued by p, any process q of Q receives a response from p among the (n - t) first responses to that query. The processes in the set Q can exhibit a Byzantine behavior and this set may change over time. Whereas many time-free solutions have been designed for the consensus problem in the crash model, this is, to our knowledge, the first time-free deterministic solution to the Byzantine consensus problem.},
  keywords={},
  doi={10.1109/NCA.2010.25},
  ISSN={},
  month={July},}
@INPROCEEDINGS{5598678,
  author={Antolini, Michele and Covarrubias, Mario and Bordegoni, Monica and Cugini, Umberto},
  booktitle={19th International Symposium in Robot and Human Interactive Communication}, 
  title={A framework for managing multiprocess applications based on distributed finite-state machine approach}, 
  year={2010},
  volume={},
  number={},
  pages={680-685},
  abstract={This paper describes a framework based on a publish/subscribe paradigm for interprocess communication based on XML messages sent over a TCP/IP connection. The framework manages the exchange of data within the clients of a system and permits the definition of a specific behavior for each client using a finite-state machine approach. Whilst the server-side of the framework is able to receive and dispatch events and data, the client-side of the framework is modeled as a finite-state machine able to perform state transitions after receiving the correct message. This architecture permits the loose-coupling between producers and consumers of data and the bidirectional mapping between the design of the behavior of a system and its implementation.},
  keywords={},
  doi={10.1109/ROMAN.2010.5598678},
  ISSN={1944-9437},
  month={Sep.},}
@INPROCEEDINGS{5599100,
  author={Lee, Jinpil and Sato, Mitsuhisa},
  booktitle={2010 39th International Conference on Parallel Processing Workshops}, 
  title={Implementation and Performance Evaluation of XcalableMP: A Parallel Programming Language for Distributed Memory Systems}, 
  year={2010},
  volume={},
  number={},
  pages={413-420},
  abstract={Although MPI is a de-facto standard for parallel programming on distributed memory systems, writing MPI programs is often a time-consuming and complicated process. XcalableMP is a language extension of C and Fortran for parallel programming on distributed memory systems that helps users to reduce those programming efforts. XcalableMP provides two programming models. The first one is the global view model, which supports typical parallelization based on the data and task parallel paradigm, and enables parallelizing the original sequential code using minimal modification with simple, OpenMP-like directives. The other one is the local view model, which allows using CAF-like expressions to describe inter-node communication. Users can even use MPI and OpenMP explicitly in our language to optimize performance explicitly. In this paper, we introduce XcalableMP, the implementation of the compiler, and the performance evaluation result. For the performance evaluation, we parallelized HPCC Benchmark in XcalableMP. It shows that users can describe the parallelization for distributed memory system with a small modification to the original sequential code.},
  keywords={},
  doi={10.1109/ICPPW.2010.62},
  ISSN={2332-5690},
  month={Sep.},}
@INPROCEEDINGS{5599207,
  author={Humphrey, Alan and Derrick, Christopher and Gopalakrishnan, Ganesh and Tibbitts, Beth},
  booktitle={2010 39th International Conference on Parallel Processing Workshops}, 
  title={GEM: Graphical Explorer of MPI Programs}, 
  year={2010},
  volume={},
  number={},
  pages={161-168},
  abstract={Formal dynamic verification can complement MPI program testing by detecting hard-to-find concurrency bugs. In previous work, we described our dynamic verifier called In-situ Partial Order (ISP) that can parsimoniously search the execution space of an MPI program while detecting important classes of bugs. One major limitation of ISP, when used by itself, is the lack of a powerful and widely usable graphical front-end. We now present a new tool called Graphical Explorer of MPI Programs (GEM) that overcomes this limitation. GEM is a plug-in architecture that greatly enhances the usability of ISP, and serves to bring ISP within reach of a wide array of programmers with its original release as part of the Eclipse Foundation’s Parallel Tools Platform (PTP) Version 3.0 in December, 2009. GEM is now a part of the PTP End-User Runtime. This paper describes GEM’s features, its architecture, and usage experience summary of the ISP/GEM combination. Recently, we applied this combination on a widely used parallel hypergraph partitioner. Even with modest amounts of computational resources, the ISP/GEM combination finished quickly and intuitively displayed a previously unknown resource leak in this code-base. Here, we also describe the process and benefits of using GEM throughout the development cycle of our own test case, an MPI implementation of the A* search. We conclude with a summary of our future plans.},
  keywords={},
  doi={10.1109/ICPPW.2010.33},
  ISSN={2332-5690},
  month={Sep.},}
@INPROCEEDINGS{5599170,
  author={Zhang, Shengdong and Wang, Ji and Shen, Rui and Xu, Jie},
  booktitle={2010 39th International Conference on Parallel Processing}, 
  title={Towards Building Efficient Content-Based Publish/Subscribe Systems over Structured P2P Overlays}, 
  year={2010},
  volume={},
  number={},
  pages={258-266},
  abstract={In this paper, we introduce a generic model to deal with the event matching problem of content-based publish/subscribe systems over structured P2P overlays. In this model, we claim that there are three methods (event-oriented, subscription-oriented and hybrid) to make all the matched pairs (event, subscription) meet in a system. By theoretically analyzing the inherent problem of both event-oriented and subscription-oriented methods, we propose PEM (Popularity-based Event Matching), a variant of hybrid method. PEM can achieve better trade-off between event processing load and subscription storage load of a system. PEM has been verified through both mathematical and simulation-based evaluation.},
  keywords={},
  doi={10.1109/ICPP.2010.33},
  ISSN={2332-5690},
  month={Sep.},}
@INPROCEEDINGS{5599220,
  author={Preissl, Robert and de Supinski, Bronis R and Schulz, Martin and Quinlan, Daniel J. and Kranzlmüller, Dieter and Panas, Thomas},
  booktitle={2010 39th International Conference on Parallel Processing}, 
  title={Exploitation of Dynamic Communication Patterns through Static Analysis}, 
  year={2010},
  volume={},
  number={},
  pages={51-60},
  abstract={Collective operations can have a large impact on the performance of parallel applications. However, the ideal implementation of a particular collective communication often depends on both the application and the targeted machine structure. Our approach combines dynamic and static analysis techniques to identify common collective communication patterns expressed as point-to-point calls and transforms them into equivalent MPI collectives. We first detect potential collective communication patterns in runtime traces and associate them with the corresponding source code regions. If our static analysis verifies that the introduction of collectives is safe for any program flow, we then replace the original communication primitives with their collective counterpart. In this paper we introduce the necessary algorithms to determine the safety of these transformations and we demonstrate several use cases, including automatic use of new extensions to the MPI standard such as nonblocking collective operations. The use of dynamic analysis significantly reduces compile times, resulting in a speed-up of about 50 for source transformations of HPL due to more directed analysis capabilities and also dramatically decreases complexity of the underlying static analysis.},
  keywords={},
  doi={10.1109/ICPP.2010.14},
  ISSN={2332-5690},
  month={Sep.},}
@INPROCEEDINGS{5600326,
  author={Goodell, David and Balaji, Pavan and Buntinas, Darius and Dózsa, Gábor and Gropp, William and Kumar, Sameer and de Supinski, Bronis R. and Thakur, Rajeev},
  booktitle={2010 IEEE International Conference on Cluster Computing}, 
  title={Minimizing MPI Resource Contention in Multithreaded Multicore Environments}, 
  year={2010},
  volume={},
  number={},
  pages={1-8},
  abstract={With the ever-increasing numbers of cores per node in high-performance computing systems, a growing number of applications are using threads to exploit shared memory within a node and MPI across nodes. This hybrid programming model needs efficient support for multithreaded MPI communication. In this paper, we describe the optimization of one aspect of a multithreaded MPI implementation: concurrent accesses from multiple threads to various MPI objects, such as communicators, datatypes, and requests. The semantics of the creation, usage, and destruction of these objects implies, but does not strictly require, the use of reference counting to prevent memory leaks and premature object destruction. We demonstrate how a naive multithreaded implementation of MPI object management via reference counting incurs a significant performance penalty. We then detail two solutions that we have implemented in MPICH2 to mitigate this problem almost entirely, including one based on a novel garbage collection scheme. In our performance experiments, this new scheme improved the multithreaded messaging rate by up to 31% over the naive reference counting method.},
  keywords={},
  doi={10.1109/CLUSTER.2010.11},
  ISSN={2168-9253},
  month={Sep.},}
@INPROCEEDINGS{5600325,
  author={Schmidl, Dirk and Terboven, Christian and Wolf, Andreas and Mey, Dieter an and Bischof, Christian},
  booktitle={2010 IEEE International Conference on Cluster Computing}, 
  title={How to Scale Nested OpenMP Applications on the ScaleMP vSMP Architecture}, 
  year={2010},
  volume={},
  number={},
  pages={29-37},
  abstract={The novel ScaleMP vSMP architecture employs commodity x86-based servers with an InfiniBand network to assemble a large shared memory system at an attractive price point. We examine this combined hardware- and software-approach of a DSM system using both system-level kernel benchmarks as well as real-world application codes. We compare this architecture with traditional shared memory machines and elaborate on strategies to tune application codes parallelized with OpenMP on multiple levels. Finally we summarize the necessary conditions which a scalable application has to fulfill in order to profit from the full potential of the ScaleMP approach.},
  keywords={},
  doi={10.1109/CLUSTER.2010.38},
  ISSN={2168-9253},
  month={Sep.},}
@INPROCEEDINGS{5613868,
  author={Sayir, Jossy},
  booktitle={2010 6th International Symposium on Turbo Codes & Iterative Information Processing}, 
  title={Design of non-binary decoders using the role model framework}, 
  year={2010},
  volume={},
  number={},
  pages={394-398},
  abstract={The concept of a message-passing decoder for non-binary low-density parity-check (LDPC) codes that operates on symbol rankings instead of probability distributions is investigated. The optimal Bayesian conversion from ranks back to probabilities is derived, and the hypothetical performance of a rank-based algorithm is measured by converting the rank-valued messages back to probabilities and implementing the node operations in the probability domain. While the performance of a pure rank-based decoder is disappointing, further analysis and performance evaluation shows that a hybrid decoder that switches to the probability domain for its final iteratons exhibits a performance at par with the best known low complexity decoders without causing a significant increase in the overall number of iterations.},
  keywords={},
  doi={10.1109/ISTC.2010.5613868},
  ISSN={2165-4719},
  month={Sep.},}
@INPROCEEDINGS{5613103,
  author={Paulavičius, Remigijus and Žilinskas, Julius and Grothey, Andreas},
  booktitle={2010 IEEE International Conference On Cluster Computing Workshops and Posters (CLUSTER WORKSHOPS)}, 
  title={Investigation of selection strategies in parallel branch and bound algorithm with simplicial partitions}, 
  year={2010},
  volume={},
  number={},
  pages={1-6},
  abstract={Efficiency of parallel branch and bound algorithms depends on the selection strategy. The influence to the performance of parallel MPI branch and bound algorithm with simplicial partitions and aggregate Lipschitz bound using different selection strategy is evaluated experimentally. The experiments have been performed solving a number of multidimensional test problems for global optimization.},
  keywords={},
  doi={10.1109/CLUSTERWKSP.2010.5613103},
  ISSN={},
  month={Sep.},}
@INPROCEEDINGS{5620672,
  author={Gao Dongdong and Gong Guanghong and Han Liang and Li Ni},
  booktitle={2010 International Conference on Computer Application and System Modeling (ICCASM 2010)}, 
  title={Application of multi-core parallel ant colony optimization in target assignment problem}, 
  year={2010},
  volume={3},
  number={},
  pages={V3-514-V3-518},
  abstract={Ant colony optimization(ACO) provides an effective way to solve combinatorial optimization problem. However, with the complexity of the problem increasing, the ACO algorithm needs considerable computational time and resources to improve the good quality of solution, and this rarely satisfies the requirement of real-time computing in M&S (Modeling and Simulation) area. Parallel implementation of ACO can reduce the computational time obviously for the large scale combinatorial optimization problem, and much of the previous work in this field focuses on parallel implementation using MPI which is executed on clusters. Meanwhile, great emphasis is placed on multi-core computing technology with the development of multi-processor architecture and multi-core architecture. A new parallel ant colony optimization (PACO) algorithm is proposed, which applies two kinds of typical multi-core computing technologies, the well-known OpenMP and the recently introduced TBB (Threading Building Blocks) library by Intel Corporation, to solve target assignment problem(TAP). Effectiveness and efficiency of proposed algorithm is validated by studying the convergence speed, problem size scalability and thread size scalability of it.},
  keywords={},
  doi={10.1109/ICCASM.2010.5620672},
  ISSN={2161-9077},
  month={Oct},}
@INPROCEEDINGS{5632490,
  author={Kononenko, V. M. and Stanchuk, L. A. and Aliekseyev, N. A.},
  booktitle={2010 20th International Crimean Conference "Microwave & Telecommunication Technology"}, 
  title={Heterogeneous educational cluster for high-performance MPI-computing}, 
  year={2010},
  volume={},
  number={},
  pages={480-481},
  abstract={The approach of high-performance platform design, based on the Message Passing Interface (MPI) implementation MPICH2, is proposed. It allows conducting the processing of hard processes on non-specialized equipment. The value of throughput depending of various parameters was analyzed.},
  keywords={},
  doi={10.1109/CRMICO.2010.5632490},
  ISSN={},
  month={Sep.},}
@INPROCEEDINGS{5628866,
  author={Cotroneo, Domenico and Martino, Catello Di},
  booktitle={2010 IEEE 30th International Conference on Distributed Computing Systems Workshops}, 
  title={Field Data Based Modeling of Sender Based Message Logging Protocols for Supercomputers Checkpointing}, 
  year={2010},
  volume={},
  number={},
  pages={294-301},
  abstract={Checkpointing is today’s common mean for dealing with transient failures in supercomputers. However, the effectiveness of checkpointing and recovery protocols under the assumption that failures may happen during their operation is not well understood. We present an evaluation of the checkpointing and recovery based on Sender Based Message Logging protocols (SBML). We evaluate it by means of a model which is gathered from an extensive field data campaign performed on the SCOPE supercomputer at the University of Naples. A comprehensive model is built to evaluate reliability, scalability and performance of SBML. The proposed model takes into account failures during the checkpointing and recovery. Result provide insights on the limit of the number of nodes that can be allocated to the same job considering i) the overhead for the distributed coordination for rollback, and ii) network resources (e.g. bandwidth).},
  keywords={},
  doi={10.1109/ICDCSW.2010.79},
  ISSN={2332-5666},
  month={June},}
@INPROCEEDINGS{5628781,
  author={Ristau, Petra and Topham, Shaun and Paganelli, Federica and Blasi, Lorenzo},
  booktitle={2010 IEEE 30th International Conference on Distributed Computing Systems Workshops}, 
  title={GEMOM Platform Prototype Validation through Case Studies - Main Results and Viewpoints to Exploitation}, 
  year={2010},
  volume={},
  number={},
  pages={290-291},
  abstract={I. Introduction GEMOM (Genetic Message Oriented Secure Middleware) is an EU FP7 ICT project. Its main contribution is the design and development of a secure, self-organizing and resilient messaging platform, enabling reliable message sourcing and delivery in business-critical application. The GEMOM middleware, with its secure, resilient, selfhealing and adaptive messaging infrastructure allows for flexible and robust messaging solutions and offers advanced monitoring, management and maintenance services. Specific and final project activities are focused on validating GEMOM key features through the above mentioned five application scenarios. Final results on ongoing testing activities will presented at the workshop.},
  keywords={},
  doi={10.1109/ICDCSW.2010.71},
  ISSN={2332-5666},
  month={June},}
@INPROCEEDINGS{5629921,
  author={Ao, Limin and Cheng, Bin and Li, Feifei},
  booktitle={2010 International Conference on Electrical and Control Engineering}, 
  title={Research of Power Flow Parallel Computing Based on MPI and P-Q Decomposition Method}, 
  year={2010},
  volume={},
  number={},
  pages={2925-2928},
  abstract={With the development of contemporary super scale power system, the method of traditional power flow computing can not meet the requirement in real-time process. This paper uses triangular decomposition parallel algorithms based on the characteristics of power flow calculation, introduces the concept of open systems into parallel computing and avoids deadlock which resulted from the order of matrix that can not be divisible by the number of processors, designs and achieves parallel algorithm combined with the features of P-Q decomposition method based on MPI(message passing interface), verifies the validity of the algorithm on pc-cluster system self-built, analyzing the performance of the algorithm taking IEEE30, IEEE118 and IEEE300 nodes system as examples and gets good results.},
  keywords={},
  doi={10.1109/iCECE.2010.714},
  ISSN={},
  month={June},}
@INPROCEEDINGS{5633600,
  author={Kawai, Hiroshi and Ogino, Masao and Shioya, Ryuji and Yoshimura, Shinobu},
  booktitle={2010 International Conference on Broadband, Wireless Computing, Communication and Applications}, 
  title={A Parallel Skyline Solver for Coarse Grid Correction of BDD Pre-conditioning in Domain Decomposition Method}, 
  year={2010},
  volume={},
  number={},
  pages={310-314},
  abstract={To shorten the computational time of the coarse grid correction stage of BDD pre-conditioner, we developed a parallel skyline solver based on a blocking algorithm. Performance benchmark of the solver shows 30 - 50 times speed up.},
  keywords={},
  doi={10.1109/BWCCA.2010.88},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{5634356,
  author={Du, Yanning and Zhao, Yinliang and Han, Bo and Li, Yuancheng},
  booktitle={International Symposium on Parallel and Distributed Processing with Applications}, 
  title={Optimistic Parallelism Based on Speculative Asynchronous Messages Passing}, 
  year={2010},
  volume={},
  number={},
  pages={382-391},
  abstract={This paper proposes a new speculative multithreading execution model which is suitable for object-oriented programs. Using this model, sequential object oriented programs are partitioned into multiple speculative object threads according to their structure and semantics by cooperated compiler and runtime system. Object threads as the basic units of parallel target code are mapped onto thread units of target machine dynamically. However, synchronous message passing between objects in source program prevents object threads in target code from execution in parallel at its synchronous points. By speculating the execution of message passing in object-oriented programs, we can convert synchronous message passing into speculative asynchronous message passing, then we can not only decrease the synchronization overhead in runtime but also exploit more parallelism for such programs. The runtime system verifies speculative asynchronous message passing by comparing it with non-speculative synchronous message passing in order to keep the parallel execution predicable and deterministic. This model is implemented as a prototype system Rope for evaluation. Experiments with Java version of Olden benchmark suite show that this model takes a good accelerating effect for object-oriented programs.},
  keywords={},
  doi={10.1109/ISPA.2010.43},
  ISSN={2158-9208},
  month={Sep.},}
@INPROCEEDINGS{5636701,
  author={Li, Zengxiang and Cai, Wentong and Turner, Stephen John and Pan, Ke},
  booktitle={2010 IEEE/ACM 14th International Symposium on Distributed Simulation and Real Time Applications}, 
  title={A Three-Phases Byzantine Fault Tolerance Mechanism for HLA-Based Simulation}, 
  year={2010},
  volume={},
  number={},
  pages={149-158},
  abstract={A large scale HLA-based simulation (federation) is composed of a large number of simulation components (federates), which may be developed by different participants and executed at different locations. Byzantine failures, caused by malicious attacks and software/hardware bugs, might happen to federates and propagate in the federation execution. In this paper, a three-phases (i.e., failure detection, failure location, and failure recovery) Byzantine Fault Tolerance (BFT) mechanism is proposed based on the decoupled federate architecture. By combining the replication, check pointing and message logging techniques, some redundant executions of federate replicas are avoided. The BFT mechanism is implemented using both Barrier and No-Barrier federate replication structures. Protocols are also developed to remove the epidemic effect caused by Byzantine failures. As the experiment results show, the BFT mechanism using No-Barrier replication outperforms that using Barrier replication significantly in the case that federate replicas have different runtime performance.},
  keywords={},
  doi={10.1109/DS-RT.2010.24},
  ISSN={1550-6525},
  month={Oct},}
@INPROCEEDINGS{5645280,
  author={Deep, Kusum and Sharma, Sunita and Pant, Millie},
  booktitle={2010 IEEE Fifth International Conference on Bio-Inspired Computing: Theories and Applications (BIC-TA)}, 
  title={Modified parallel particle swarm optimization for global optimization using Message Passing Interface}, 
  year={2010},
  volume={},
  number={},
  pages={1451-1458},
  abstract={PSO has emerged as a powerful heuristic technique for determining the global optimal solution of nonlinear optimization problems. Like all other evolutionary algorithms (EAs) it is also population based method. However, due to the inherent nature of PSO, it is desirable to parallelize it so as to get a better performance. In this paper, three versions of parallel PSO are presented. They are encoded using the Message Passing Interface (MPI) and are used to solve 16 benchmark scalable test problems available in literature. From the numerical and graphical analysis it is concluded that parallelization helps in enhancing the performance of basic PSO.},
  keywords={},
  doi={10.1109/BICTA.2010.5645280},
  ISSN={},
  month={Sep.},}
@INPROCEEDINGS{5644944,
  author={Schönherr, Jan H. and Richling, Jan and Heiss, Hans-Ulrich},
  booktitle={2010 22nd International Symposium on Computer Architecture and High Performance Computing}, 
  title={Dynamic Teams in OpenMP}, 
  year={2010},
  volume={},
  number={},
  pages={231-237},
  abstract={While OpenMP conceptually allows to vary the degree of parallelism from one parallel region to the next in order to adapt to the system load, this might still be too coarse-grained in certain scenarios. Especially applications designed for parallelism may stay within one parallel region for a long time. This may lead either to an oversubscribed system where individual applications are not restricted in their degree of parallelism, or to an underutilized system, because individual applications are restricted to a too small degree of parallelism. In this paper, we tackle both problems by dynamically restricting the number of active threads within a parallel region without violating the OpenMP specification.},
  keywords={},
  doi={10.1109/SBAC-PAD.2010.36},
  ISSN={1550-6533},
  month={Oct},}

@INPROCEEDINGS{5644949,
  author={Jones, Terry and Koenig, Gregory A.},
  booktitle={2010 22nd International Symposium on Computer Architecture and High Performance Computing}, 
  title={A Clock Synchronization Strategy for Minimizing Clock Variance at Runtime in High-End Computing Environments}, 
  year={2010},
  volume={},
  number={},
  pages={207-214},
  abstract={We present a new software-based clock synchronization scheme that provides high precision time agreement among distributed memory nodes. The technique is designed to minimize variance from a reference chimer during runtime and with minimal time-request latency. Our scheme permits initial unbounded variations in time and corrects both slow and fast chimers (clock skew). An implementation developed within the context of the MPI message passing interface is described and time coordination measurements are presented. Among our results, the mean time variance among a set of nodes improved from 20.0 milliseconds under standard Network Time Protocol (NTP) to 2.29 μsecs under our scheme.},
  keywords={},
  doi={10.1109/SBAC-PAD.2010.33},
  ISSN={1550-6533},
  month={Oct},}
@INPROCEEDINGS{5644885,
  author={Vo, Anh and Aananthakrishnan, Sriram and Gopalakrishnan, Ganesh and Supinski, Bronis R. de and Schulz, Martin and Bronevetsky, Greg},
  booktitle={SC '10: Proceedings of the 2010 ACM/IEEE International Conference for High Performance Computing, Networking, Storage and Analysis}, 
  title={A Scalable and Distributed Dynamic Formal Verifier for MPI Programs}, 
  year={2010},
  volume={},
  number={},
  pages={1-10},
  abstract={Standard testing methods of MPI programs do not guarantee coverage of all non-deterministic interactions (e.g., wildcard-receives). Programs tested by these methods can have untested paths (bugs) that may become manifest unexpectedly. Previous formal dynamic verifiers cover the space of non-determinism but do not scale, even for small applications. We present DAMPI, the first dynamic analyzer for MPI programs that guarantees scalable coverage of the space of non-determinism through a decentralized algorithm based on Lamport-clocks. DAMPI computes alternative non-deterministic matches and enforces them in subsequent program replays. To avoid interleaving explosion, DAMPI employs heuristics to focus coverage to regions of interest. We show that DAMPI can detect deadlocks and resource-leaks in real applications. Our results on a wide range of applications using over a thousand processes, which is an order of magnitude larger than any previously reported results for MPI dynamic verification tools, demonstrate that DAMPI provides scalable, user-configurable testing coverage.},
  keywords={},
  doi={10.1109/SC.2010.7},
  ISSN={2167-4337},
  month={Nov},}
@INPROCEEDINGS{5654381,
  author={Fan, K. T. and Tzeng, Y. C. and Lin, Y. F. and Su, Y. J. and Chen, K. S.},
  booktitle={2010 IEEE International Geoscience and Remote Sensing Symposium}, 
  title={Tree identification using a distributed K-mean clustering algorithm}, 
  year={2010},
  volume={},
  number={},
  pages={3446-3449},
  abstract={Trees play an important role in maintaining environmental conditions suitable for life on the earth. To classify the tree type is very important for the forest maintenance. With the advent of high spatial resolution remote sensing sensors, our ability has greatly increased for tree type identification. Considering the amount of data in need of processing and the high computational costs required by image processing algorithms, conventional computing environments are simply impractical. Therefore, it is necessary to develop techniques and models for efficiently processing large volume of remote sensing images. In this study, a cluster computing environment was adopted to speed up the computation time. The test image was first partitioned into hundreds of manageable sub-images. Scheduled by the head node, the sub-images were then distributed to compute nodes for processing. A distributed K-mean clustering algorithm with undetermined number of class was applied to each compute node. A promising result was obtained. Compared to the field investigations, tree types of the test site were properly identified. In addition, great improvement in computation time was obtained. The distributed K-mean clustering algorithm implemented on our cluster computing environment performed much faster than stand-alone alternatives. By adding more compute nodes to our cluster computing environment, further improvement in computation time is expected.},
  keywords={},
  doi={10.1109/IGARSS.2010.5654381},
  ISSN={2153-7003},
  month={July},}
@INPROCEEDINGS{5680462,
  author={Kennedy, Jawone A. and Noneaker, Daniel L.},
  booktitle={2010 - MILCOM 2010 MILITARY COMMUNICATIONS CONFERENCE}, 
  title={Decoding of a quasi-cyclic LDPC code on a stream processor}, 
  year={2010},
  volume={},
  number={},
  pages={2062-2067},
  abstract={The TDMP layered belief-propagation algorithm is investigated for decoding a quasi-cyclic low-density parity-check code on a stream processor using fixed-point arithmetic. The effect of the processor's fixed-point resolution on the decoder performance is determined, and a simple technique is described for minimizing the performance penalty incurred when using the (highest throughput) lowest-resolution arithmetic mode of the processor. A reordering of the decoder schedule and a modification of the parity checks are also considered which permit increased software pipelining and improved latency hiding, with a corresponding increase in the data throughput. The fixed-point Storm-1 stream processor is used for comparative throughput results.},
  keywords={},
  doi={10.1109/MILCOM.2010.5680462},
  ISSN={2155-7586},
  month={Oct},}
@INPROCEEDINGS{5682312,
  author={Ruan, Xiaojun and Yang, Qing and Mohammed, I. Alghamdi and Yin, Shu and Ding, Zhiyang and Xie, Jiong and Lewis, Joshua and Qin, Xiao},
  booktitle={International Performance Computing and Communications Conference}, 
  title={ES-MPICH2: A Message Passing Interface with enhanced security}, 
  year={2010},
  volume={},
  number={},
  pages={161-168},
  abstract={In largely distributed clusters, computing nodes are geographically deployed in various computing sites. Information processed in a distributed cluster is shared among a group of distributed processes or users by virtue of messages passing protocols (e.g. message passing interface - MPI) running on the Internet. Because of the open accessible nature of the Internet, data encryption for these large-scale distributed clusters becomes a non-trivial and challenging problem. To address this issue, we enhanced the security of the MPI (Message Passing Interface) protocol by encrypting and decrypting messages sent and received among computing nodes. In this study we focused on MPI rather than other protocols because MPI is one of the most popular communication protocols for cluster computing environments. From among a variety of MPI implementations, we picked MPICH2 developed by the Argonne National Laboratory. The design goal of MPICH2 - a widely used MPI implementation - is to combine portability with high performance. We integrated encryption algorithms into the MPICH2 library so that data confidentiality of MPI applications could be readily preserved without a need to change the source codes of the MPI applications. since we provide a security enhanced MPI-library with the standard MPI interfact, data communications of a conventional MPI program can be secured without converting the program into the corresponding secure version. We used Sandia Micro Benchmark and Intel MPI Benchmarks to evaluate and compared the performance of original MPICH2 and Enhanced Security MPICH2. According to the performance evaluation, ES-MPICH2 provides secured Message Passing Interface by sacrificing reasonable system performance.},
  keywords={},
  doi={10.1109/PCCC.2010.5682312},
  ISSN={2374-9628},
  month={Dec},}
@INPROCEEDINGS{5662504,
  author={Zhi, Yuzhe and Liu, Yi and Jiao, Lin and Zhang, Peng},
  booktitle={2010 Ninth International Conference on Grid and Cloud Computing}, 
  title={A Parallel Simulator for Large-Scale Parallel Computers}, 
  year={2010},
  volume={},
  number={},
  pages={196-200},
  abstract={This paper describes the design and application of an execution-driven parallel simulator for predicting performance of Large-Scale Parallel Computers. The simulator can be used in hardware validation and software development for large-scale parallel computers. It simulates processors of each node, network components and disk I/O components. To illustrate the capabilities of our simulator, we describe experiments running the High Performance Linpack Benchmark on a simulated parallel computer. It gains sound speedup and executes fast enough to run complex MPI codes.},
  keywords={},
  doi={10.1109/GCC.2010.48},
  ISSN={2160-4916},
  month={Nov},}
@INPROCEEDINGS{5688606,
  author={Taiqiu Tan and Yubai Li and Chang Wu},
  booktitle={The 2nd International Conference on Information Science and Engineering}, 
  title={Low-complexity high-performance LDPC decoder for CMMB}, 
  year={2010},
  volume={},
  number={},
  pages={3819-3822},
  abstract={A low-complexity semi-parallel low density parity check (LDPC) decoder for China Mobile Multimedia Broadcasting (CMMB) system is designed based on the structure of LDPC codes. The designed decoder utilizes turbo decoding message passing algorithm. A new memory compressing strategy for message updating was proposed, which can reduce more than 50% memories. By using them appropriately, two different code rates can reuse memories without increasing any hardware resource. The decoder is implemented on FPGA of Altera Stratix II. The throughput of the LDPC decoder is up to 40Mbps under CMMB work point, which can fulfill the request of real time decoding.},
  keywords={},
  doi={10.1109/ICISE.2010.5688606},
  ISSN={2160-1291},
  month={Dec},}
@INPROCEEDINGS{5690695,
  author={Yanxin Liu and Shuo Li and Zheying Li},
  booktitle={The 2nd International Conference on Information Science and Engineering}, 
  title={Prototyping distributed embedded operating system for NoC architecture}, 
  year={2010},
  volume={},
  number={},
  pages={6781-6784},
  abstract={In this paper, we propose a light-weighted embedded OS (EOS) for 8051 microcontrollers used in NoC. This EOS is developed in such way that it is able to be extended as a distributed OS for NoC. Along with the development of the NoC, an operating system is demanded for managing resources and task execution flow in computing systems based on NoC architecture. To build the EOS suitable for small C51 core, the model of the EOS is built and discussed first in this paper. With the model, the structure of the EOS mainly involves multi-task management and inter-task communication. Then we verify the model. By reserve interfaces, the tasks in distributed EOS are expected to communication with each other among NoC system via routers.},
  keywords={},
  doi={10.1109/ICISE.2010.5690695},
  ISSN={2160-1291},
  month={Dec},}
@INPROCEEDINGS{5697968,
  author={Abbes, Heithem and Cérin, Christophe and Jemni, Mohamed and Saad, Walid},
  booktitle={2010 11th IEEE/ACM International Conference on Grid Computing}, 
  title={Fault tolerance based on the publish-subscribe paradigm for the BonjourGrid middleware}, 
  year={2010},
  volume={},
  number={},
  pages={57-64},
  abstract={How to federate the machines of all Boinc, Condor and XtremWeb projects? If you believe in volunteer computing and want to share more than one project then BonjourGrid may help. In previous works, we proposed a novel approach, called BonjourGrid, to orchestrate multiple instances of Institutional Desktop Grid middleware. It is our way to remove the risk of bottleneck and failure, and to guarantee the continuity of services in a distributed manner. Indeed, BonjourGrid can create a specific environment for each user based on a given computing system of his choice such as XtremWeb, Condor or Boinc. This work investigates, first, the procedure to deploy Boinc and Condor on top of BonjourGrid and, second, proposes a fault tolerant approach based on passive replication and virtualization to tolerate the crash of coordinators. The novelty resides here in an integrated environment based on Bonjour (publication-subscription mecanism) for both the coordination protocol and for the fault tolerance issues. In particular, it is not so frequent to our knowledge to describe and to implement a fault tolerant protocol according to the pub-sub paradigm. Experiments, conducted on the Grid'5000 testbed, illustrate a comparative study between Boinc (respectively Condor) on top of BonjourGrid and a centralized system using Boinc (respectively Condor) and second prove the robustness of the fault tolerant mechanism.},
  keywords={},
  doi={10.1109/GRID.2010.5697968},
  ISSN={2152-1093},
  month={Oct},}
@INPROCEEDINGS{5693928,
  author={Weatherley, Dion K. and Boros, Vince E. and Hancock, William R. and Abe, Steffen},
  booktitle={2010 IEEE Sixth International Conference on e-Science}, 
  title={Scaling Benchmark of ESyS-Particle for Elastic Wave Propagation Simulations}, 
  year={2010},
  volume={},
  number={},
  pages={277-283},
  abstract={The Discrete Element Method (DEM) is a popular particle-based numerical method for simulating geophysical processes including earthquakes, rock breakage and granular flow. Often simulations consisting of thousands of particles have insufficient resolution to reproduce the micromechanics of many geophysical processes, requiring millions of particles in some instances. The high computational expense of the DEM precludes execution of such problem sizes on desktop PCs. ESyS-Particle is a parallel implementation of the DEM, designed for execution on cluster supercomputers. Three-dimensional spatial domain decomposition is implemented using the MPI for interprocess communications. We present results of scaling benchmarks in which problem size per worker remains constant. As the number of workers increases from 27 to 1000, execution time remains near-constant, permitting simulations of 8.7M particles in approximately the same real time as simulations comprising 240K particles.},
  keywords={},
  doi={10.1109/eScience.2010.40},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{5695681,
  author={Liao, Hao and Huang, Kuo-Chan and Hsiao, Hung-Chang},
  booktitle={2010 IEEE 16th International Conference on Parallel and Distributed Systems}, 
  title={Small-World Social Relationship Awareness in Unstructured Peer-to-Peer Networks}, 
  year={2010},
  volume={},
  number={},
  pages={770-775},
  abstract={Unstructured peer-to-peer (P2P) file-sharing networks are popular in the mass market. As the peers participating in unstructured networks interconnect randomly, they rely on flooding query messages to discover objects of interest. Empirical measurement studies indicate that the peers in P2P networks have similar preferences, and recently proposed unstructured P2P networks intend to organize the participating peers in a small-world (SW) fashion by exploiting the knowledge of contents stored in peers. As existing algorithms for constructing SW-based unstructured P2P networks may not precisely reveal the object sharing patterns, the resultant networks thus may not perform searches efficiently and effectively by exploiting the common interests among peers. In this paper, we suggest a novel P2P network formation algorithm to construct SW-based unstructured networks. We validate our proposal in simulations with an empirical data set, and the simulation results prove that our proposal greatly outperforms existing algorithms in terms of search efficiency and effectiveness.},
  keywords={},
  doi={10.1109/ICPADS.2010.37},
  ISSN={1521-9097},
  month={Dec},}
@INPROCEEDINGS{5698477,
  author={Bustamam, Alhadi and Burrage, Kevin and Hamilton, Nicholas A.},
  booktitle={2010 Ninth International Workshop on Parallel and Distributed Methods in Verification, and Second International Workshop on High Performance Computational Systems Biology}, 
  title={Fast Parallel Markov Clustering in Bioinformatics Using Massively Parallel Graphics Processing Unit Computing}, 
  year={2010},
  volume={},
  number={},
  pages={116-125},
  abstract={Markov clustering is becoming a key algorithm with in bioinformatics for determining clusters in networks. For instance, clustering protein interaction networks is helping find genes implicated in diseases such as cancer. However, with fast sequencing and other technologies generating vast amounts of data on biological networks, performance and scalability issues are becoming a critical limiting factorin applications. Meanwhile, Graphics Processing (GPU)computing, which uses a massively parallel computing environment in the GPU card, is becoming a very powerful, efficient and low cost option to achieve substantial performance gains over CPU approaches. This paper introduces a very fast Markov clustering algorithm (MCL) based on massive parallel computing in GPU. We use the Compute Unified Device Architecture (CUDA) to allow the GPU to perform parallel sparse matrix-matrix computations and parallel sparse Markov matrix normalizations, which are at the heart of the clustering algorithm. The key to optimizing our CUDA Markov Clustering (CUDAMCL) was utilizing ELLACK-R sparse data format to allow the effective and fine-grain massively parallel processing to cope with the sparse nature of interaction networks datasets in bioinformatics applications. CUDA also allows us to use on-chip memory on the GPU efficiently, to lower the latency time thus circumventing a major issue in other parallel computing environments, such as Message Passing Interface (MPI). Here we describe the GPU algorithm and its application to several real world problems as well as to artificial datasets. We find that the principle factor causing variation in performance of the GPU approach is the relative sparseness of networks. Comparing GPU computation times against a modern quad-core CPU on the published(relatively sparse) standard BIOGRID protein interaction networks with 5156 and 23175 nodes, speed factors of 4 times and 9 were obtained, respectively. On the Human Protein Reference Database, the speed of clustering of 19599 proteins was improved by a factor of 7 by the GPU algorithm. However, on artificially generated densely connected networks with 1600 to 4800 nodes, speedups by a factor in the range 40 to 120 times were readily obtained. As the results show, in all cases the GPU implementation is significantly faster than the original MCL running on CPU. Such approaches are allowing large-scale parallel computation on off-the-shelf desktop machines that were previously only possible on super-computing architectures, and have the potential to significantly change the way bioinformaticians and biologists compute and interact with their data.},
  keywords={},
  doi={10.1109/PDMC-HiBi.2010.23},
  ISSN={},
  month={Sep.},}
@INPROCEEDINGS{5700139,
  author={Penna, Federico and Garello, Roberto and Spirito, Maurizio A.},
  booktitle={2010 IEEE Globecom Workshops}, 
  title={Likelihood-ratio propagation and consensus in wireless networks with Markov Random Field models}, 
  year={2010},
  volume={},
  number={},
  pages={1259-1263},
  abstract={In this paper we address the problem of distributed Bayesian hypothesis testing in wireless networks where correlations among nodes are modeled as exponential Markov Random Fields (MRF). Applying distributed Belief Propagation (BP), we first derive message and belief update rules for the above model expressed under a likelihood ratio formulation. Then we analyze the properties of BP when the MRF correlation values tend to infinity, and we show that in this limit BP behaves as a consensus scheme. As a result, both problems of heterogeneous hypothesis testing (i.e., MRF estimation) and homogeneous hypothesis testing (i.e., consensus building) can be seen under a unified framework.},
  keywords={},
  doi={10.1109/GLOCOMW.2010.5700139},
  ISSN={2166-0077},
  month={Dec},}
@INPROCEEDINGS{5708452,
  author={Hasenkamp, D. and Sim, A. and Wehner, M. and Wu, K.},
  booktitle={2010 IEEE Second International Conference on Cloud Computing Technology and Science}, 
  title={Finding Tropical Cyclones on a Cloud Computing Cluster: Using Parallel Virtualization for Large-Scale Climate Simulation Analysis}, 
  year={2010},
  volume={},
  number={},
  pages={201-208},
  abstract={Extensive computing power has been used to tackle issues such as climate changes, fusion energy, and other pressing scientific challenges. These computations produce a tremendous amount of data, however, many of the data analysis programs currently only run a single processor. In this work, we explore the possibility of using the emerging cloud computing platform to parallelize such sequential data analysis tasks. As a proof of concept, we wrap a program for analyzing trends of tropical cyclones in a set of virtual machines (VMs). This approach allows the user to keep their familiar data analysis environment in the VMs, while we provide the coordination and data transfer services to ensure the necessary input and output are directed to the desired locations. This work extensively exercises the networking capability of the cloud computing systems and has revealed a number of weaknesses in the current cloud system software. In our tests, we are able to scale the parallel data analysis job to a modest number of VMs and achieve a speedup that is comparable to running the same analysis task using MPI. However, compared to MPI based parallelization, the cloud-based approach has a number of advantages. The cloud-based approach is more flexible because the VMs can capture arbitrary software dependencies without requiring the user to rewrite their programs. The cloud-based approach is also more resilient to failure, as long as a single VM is running, it can make progress while as soon as one MPI node fails the whole analysis job fails. In short, this initial work demonstrates that a cloud computing system is a viable platform for distributed scientific data analyses traditionally conducted on dedicated supercomputing systems.},
  keywords={},
  doi={10.1109/CloudCom.2010.68},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{5701954,
  author={Waghmare, Vivek N. and Kulkarni, Dinesh B.},
  booktitle={2010 International Conference on Computational Intelligence and Communication Networks}, 
  title={Convex Hull Using K-Means Clustering in Hybrid (MPI/OpenMP) Environment}, 
  year={2010},
  volume={},
  number={},
  pages={150-153},
  abstract={Parallel computing is the use of multiple compute resources to solve a computational problem. Parallel computers can be roughly classified as Multi-Core and Multi-Processor. In both these classifications, the hardware supports parallelism with computer node having multiple processing elements in a single machine. Parallel programming is the ability of program to run on this infrastructure which is still quite difficult and complex task to achieve. Two of the different approaches used in parallel environment are MPI and Open MP, each one of them have their own merits and demerits. Hybrid model combines both approaches in the pursuit of reducing the weaknesses in individual. In proposed approach k-Means Clustering algorithm used for solving the problem of Convex Hull in parallel environment. In this design, 2D points are grouped into different Cluster and then Convex hull for each of these Clusters are computed. Points defining these Convex hulls are used to construct the final Convex hull. This algorithm is implemented in MPI, OpenMP, and Hybrid mode. The algorithm is tested for number of Clusters with different set of points. The results indicates that the Hybrid approach out performs the MPI and OpenMP approach.},
  keywords={},
  doi={10.1109/CICN.2010.40},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{5716619,
  author={Cevrero, Alessandro and Leblebici, Yusuf and Ienne, Paolo and Burg, Andreas},
  booktitle={2010 IEEE Asian Solid-State Circuits Conference}, 
  title={A 5.35 mm2 10GBASE-T Ethernet LDPC decoder chip in 90 nm CMOS}, 
  year={2010},
  volume={},
  number={},
  pages={1-4},
  abstract={A partially parallel low density parity check (LDPC) decoder compliant with the IEEE 802.3an standard for 100BASE-T Ethernet is presented. The design is optimized for minimum silicon area and is based on the layered offset-min-sum algorithm which speeds up the convergence of the message passing decoding algorithm. To avoid routing congestion the decoder architecture employs a novel communication scheme that reduces the critical number of global wires by 50%. The prototype LDPC decoder ASIC, fabricated in 90 nm CMOS, occupies only 5.35 mm2 and achieves a decoding throughput of 11.69 Gb/s at 1.2 V with an energy efficiency of 133pJ/bit.},
  keywords={},
  doi={10.1109/ASSCC.2010.5716619},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{5719683,
  author={Shamaiah, Manohar and Sang Hyun Lee and Vikalo, Haris},
  booktitle={2010 IEEE International Workshop on Genomic Signal Processing and Statistics (GENSIPS)}, 
  title={Inference of gene-regulatory networks using message-passing algorithms}, 
  year={2010},
  volume={},
  number={},
  pages={1-4},
  abstract={We present an application of message-passing techniques to gene regulatory network inference. The network inference is posed as a constrained linear regression problem, and solved by a distributed computationally efficient message-passing algorithm. Performance of the proposed algorithm is tested on gold standard data sets and evaluated using metrics provided by the DREAM2 challenge. Performance of the proposed algorithm is comparable to that of the techniques which yielded the best results in the DREAM2 challenge competition.},
  keywords={},
  doi={10.1109/GENSIPS.2010.5719683},
  ISSN={2150-301X},
  month={Nov},}
@INPROCEEDINGS{5734160,
  author={Orooji, Fatemeh and Sarjoughian, Hessam S. and Taghiyareh, Fattaneh},
  booktitle={2010 5th International Symposium on Telecommunications}, 
  title={Modeling & simulation of educational multi-agent systems in DEVS-suite}, 
  year={2010},
  volume={},
  number={},
  pages={956-961},
  abstract={This paper introduces the capabilities of a general-purpose modeling and simulation approach named DEVS in multi-agent educational systems. Simulation provides both qualitative and quantitative information about correctness and efficiency which can help validate a multi-agent system (architectural) design before its actual implementation and thus deployment. Dynamic agent data helps designers to modify, refine or even propose new agent abstractions. DEVS-Suite simulator, a realization of Parallel DEVS, can model all components interacting in a multi-agent system, helping the designer and programmer to evaluate the system performance before the real implementation. This paper develops a description of a multi-agent system named MOMENT. A set of abstractions are formulated and their designs are realized in DEVS-Suite. A sample simulation study is conducted to illustrate the use of the MOMENT simulation in understanding some key design and performance aspects of educational multi-agent systems.},
  keywords={},
  doi={10.1109/ISTEL.2010.5734160},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{5750465,
  author={de la Peña, A. and Pacios, L. and Lapayese, F. and Carrasco, R.},
  booktitle={2010 17th IEEE-NPSS Real Time Conference}, 
  title={New middleware software for message distribution in the TJ-II control environment}, 
  year={2010},
  volume={},
  number={},
  pages={1-4},
  abstract={A real-time control system has been operating successfully for the TJ-II stellarator since 1997. It was designed and built as a set of distributed and autonomous systems based on VMEbus and OS9 RTOS. At present, an upgrade, based on the VxWorks operating system, is being undertaken. As this process is gradual, both current and future real-time control systems must work simultaneously until this upgrade is completed. A new communication middleware architecture that implements XML-based Messages Distribution Service has been developed and applied for this. It has been created in response to the need to standardize the message publish-subscribe programming model for the TJ-II distributed control systems. It permits data, events and commands to be sent and received between distributed control applications that run on different real-time operating systems (OS9 and VxWorks) as well as Java-based applications running on any Windows or Linux platform. It has been fully tested and found to be both reliable and safe. Specific software tools have been developed to create, manage and monitor any distributed control variables involved in TJ-II experiments.},
  keywords={},
  doi={10.1109/RTC.2010.5750465},
  ISSN={},
  month={May},}
@ARTICLE{6793952,
  author={Santana, Roberto and Larrañaga, Pedro and Lozano, José A.},
  journal={Evolutionary Computation}, 
  title={Learning Factorizations in Estimation of Distribution Algorithms Using Affinity Propagation}, 
  year={2010},
  volume={18},
  number={4},
  pages={515-546},
  abstract={Estimation of distribution algorithms (EDAs) that use marginal product model factorizations have been widely applied to a broad range of mainly binary optimization problems. In this paper, we introduce the affinity propagation EDA (AffEDA) which learns a marginal product model by clustering a matrix of mutual information learned from the data using a very efficient message-passing algorithm known as affinity propagation. The introduced algorithm is tested on a set of binary and nonbinary decomposable functions and using a hard combinatorial class of problem known as the HP protein model. The results show that the algorithm is a very efficient alternative to other EDAs that use marginal product model factorizations such as the extended compact genetic algorithm (ECGA) and improves the quality of the results achieved by ECGA when the cardinality of the variables is increased.},
  keywords={},
  doi={10.1162/EVCO_a_00002},
  ISSN={1063-6560},
  month={Dec},}
@ARTICLE{5432228,
  author={Baresi, Luciano and Ghezzi, Carlo and Mottola, Luca},
  journal={IEEE Transactions on Software Engineering}, 
  title={Loupe: Verifying Publish-Subscribe Architectures with a Magnifying Lens}, 
  year={2011},
  volume={37},
  number={2},
  pages={228-246},
  abstract={The Publish-Subscribe (P/S) communication paradigm fosters high decoupling among distributed components. This facilitates the design of dynamic applications, but also impacts negatively on their verification, making it difficult to reason on the overall federation of components. In addition, existing P/S infrastructures offer radically different features to the applications, e.g., in terms of message reliability. This further complicates the verification as its outcome depends on the specific guarantees provided by the underlying P/S system. Although model checking has been proposed as a tool for the verification of P/S architectures, existing solutions overlook many characteristics of the underlying communication infrastructure to avoid state explosion problems. To overcome these limitations, the Loupe domain-specific model checker adopts a different approach. The P/S infrastructure is not modeled on top of a general-purpose model checker. Instead, it is embedded within the checking engine, and the traditional P/S operations become part of the modeling language. In this paper, we describe Loupe's design and the dedicated state abstractions that enable accurate verification without incurring state explosion problems. We also illustrate our use of state-of-the-art software verification tools to assess some key functionality in Loupe's current implementation. A complete case study shows how Loupe eases the verification of P/S architectures. Finally, we quantitatively compare Loupe's performance against alternative approaches. The results indicate that Loupe is effective and efficient in enabling accurate verification of P/S architectures.},
  keywords={},
  doi={10.1109/TSE.2010.39},
  ISSN={1939-3520},
  month={March},}
@ARTICLE{5711699,
  author={Dall'Anese, Emiliano and Kim, Seung-Jun and Giannakis, Georgios B.},
  journal={IEEE Transactions on Vehicular Technology}, 
  title={Channel Gain Map Tracking via Distributed Kriging}, 
  year={2011},
  volume={60},
  number={3},
  pages={1205-1211},
  abstract={A collaborative algorithm is developed to estimate the channel gains of wireless links in a geographical area. The spatiotemporal evolution of shadow fading is characterized by judiciously extending an experimentally verified spatial-loss field model. Kriged Kalman filtering (KKF), which is a tool with widely appreciated merits in spatial statistics and geosciences, is adopted and implemented in a distributed fashion to track the time-varying shadowing field using a network of radiometers. The novel distributed KKF requires only local message passing yet achieves a global view of the radio frequency environment through consensus iterations. Numerical tests demonstrate superior tracking accuracy of the collaborative algorithm compared with its noncollaborative counterpart. Furthermore, the efficacy of the global channel gain knowledge obtained is showcased in the context of cognitive radio resource allocation.},
  keywords={},
  doi={10.1109/TVT.2011.2113195},
  ISSN={1939-9359},
  month={March},}
@ARTICLE{5710900,
  author={Jung, Hyungsoo and Han, Hyuck and Yeom, Heon Y. and Kang, Sooyong},
  journal={IEEE Transactions on Parallel and Distributed Systems}, 
  title={Athanasia: A User-Transparent and Fault-Tolerant System for Parallel Applications}, 
  year={2011},
  volume={22},
  number={10},
  pages={1653-1668},
  abstract={This article presents Athanasia, a user-transparent and fault-tolerant system, for parallel applications running on large-scale cluster systems. Cluster systems have been regarded as a de facto standard to achieve multitera-flop computing power. These cluster systems, as we know, have an inherent failure factor that can cause computation failure. The reliability issue in parallel computing systems, therefore, has been studied for a relatively long time in the literature, and we have seen many theoretical promises arise from the extensive research. However, despite the rigorous studies, practical and easily deployable fault-tolerant systems have not been successfully adopted commercially. Athanasia is a user-transparent checkpointing system for a fault-tolerant Message Passing Interface (MPI) implementation that is primarily based on the sync-and-stop protocol. Athanasia supports three critical functionalities that are necessary for fault tolerance: a light-weight failure detection mechanism, dynamic process management that includes process migration, and a consistent checkpoint and recovery mechanism. The main features of Athanasia are that it does not require any modifications to the application code and that it preserves many of the high performance characteristics of high-speed networks. Experimental results show that Athanasia can be a good candidate for practically deployable fault-tolerant systems in very-large and high-performance clusters and that its protocol can be applied to a variety of parallel communication libraries easily.},
  keywords={},
  doi={10.1109/TPDS.2011.63},
  ISSN={1558-2183},
  month={Oct},}
@ARTICLE{5719528,
  author={Huang, Chao-Wang and Ting, Pang-An and Huang, Chia-Chi},
  journal={IEEE Transactions on Wireless Communications}, 
  title={A Novel Message Passing Based MIMO-OFDM Data Detector with a Progressive Parallel ICI Canceller}, 
  year={2011},
  volume={10},
  number={4},
  pages={1260-1268},
  abstract={A joint design of message passing MIMO data detector/decoder with progressive parallel inter-carrier interference canceller (PPIC) based on factor graph for OFDM-based wireless communication systems is proposed. By exchanging messages both in space domain and frequency domain, the proposed algorithm can suppress inter-antenna interferences and cancel inter-carrier interferences iteratively and progressively. With a proper designed message passing schedule and random interleaver, the short cycle problem is solved. Computer simulations show that the performance of the proposed message passing MIMO detector outperforms MMSE-SIC MIMO detector. The performances of PPIC, both in perfect channel estimation and imperfect channel estimation cases, are compared with the standard PIC architecture and the ICI self-canceller. The proposed PPIC is superior to PIC both in computational complexity and system architecture. The parallel structure of PPIC is similar to a systolic array. The proposed algorithm potentially leads to a very-high-speed detector/decoder. It is very suitable for VLSI implementation and it is a potential candidate for data detection/decoding in future high data rate, high mobility, wireless MIMO-OFDM communication systems.},
  keywords={},
  doi={10.1109/TWC.2011.021611.101103},
  ISSN={1558-2248},
  month={April},}
@ARTICLE{5730581,
  author={Sanghavi, Sujay and Malioutov, Dmitry and Willsky, Alan},
  journal={IEEE Transactions on Information Theory}, 
  title={Belief Propagation and LP Relaxation for Weighted Matching in General Graphs}, 
  year={2011},
  volume={57},
  number={4},
  pages={2203-2212},
  abstract={Loopy belief propagation has been employed in a wide variety of applications with great empirical success, but it comes with few theoretical guarantees. In this paper, we analyze the performance of the max-product form of belief propagation for the weighted matching problem on general graphs. We show that the performance of max-product is exactly characterized by the natural linear programming (LP) relaxation of the problem. In particular, we first show that if the LP relaxation has no fractional optima then max-product always converges to the correct answer. This establishes the extension of the recent result by Bayati, Shah and Sharma, which considered bipartite graphs, to general graphs. Perhaps more interestingly, we also establish a tight converse, namely that the presence of any fractional LP optimum implies that max-product will fail to yield useful estimates on some of the edges. We extend our results to the weighted b-matching and r -edge-cover problems. We also demonstrate how to simplify the max-product message-update equations for weighted matching, making it easily deployable in distributed settings like wireless or sensor networks.},
  keywords={},
  doi={10.1109/TIT.2011.2110170},
  ISSN={1557-9654},
  month={April},}
@INPROCEEDINGS{5730357,
  author={Al-Mulhem, Muhammed and Al-Shaikh, Raed},
  booktitle={2011 Second International Conference on Intelligent Systems, Modelling and Simulation}, 
  title={Performance Evaluation of Intel and Portland Compilers Using Intel Westmere Processor}, 
  year={2011},
  volume={},
  number={},
  pages={261-266},
  abstract={In recent years, we have witnessed a growing interest in optimizing the parallel and distributed computing solutions using scaled-out hardware designs and scalable parallel programming paradigms. This interest is driven by the fact that the microchip technology is gradually reaching its physical limitations in terms of heat dissipation and power consumption. Therefore and as an extension to Moore's law, recent trends in high performance and grid computing have shown that future increases in performance can only be reached through increases in systems scale using a larger number of components, supported by scalable parallel programming models. In this paper, we evaluate the performance of two commonly used parallel compilers, Intel and Portland's PGI, using a state-of-the-art Intel West mere-based HPC cluster. The performance evaluation is based on two sets of experiments, once evaluating the compilers' performance using an MPI-based code, and another using OpenMP. Our results show that, for scientific applications that are matrices-dependant, the MPI and OpenMP features of the Intel compiler supersede PGI when using the defined HPC cluster.},
  keywords={},
  doi={10.1109/ISMS.2011.47},
  ISSN={2166-0670},
  month={Jan},}
@INPROCEEDINGS{5739003,
  author={Achour, Sami and Ammar, Meher and Khmili, Boubaker and Nasri, Wahid},
  booktitle={2011 19th International Euromicro Conference on Parallel, Distributed and Network-Based Processing}, 
  title={MPI-PERF-SIM: Towards an Automatic Performance Prediction Tool of MPI Programs on Hierarchical Clusters}, 
  year={2011},
  volume={},
  number={},
  pages={207-211},
  abstract={We present in this paper a framework for performance prediction of parallel programs on hierarchical clusters. This framework is mainly designed for the use by the switching functions in parallel adaptive applications. Indeed, the principal referred objectives by this framework are the accuracy of the prediction and the rapidity of the prediction process. To achieve these objectives, our framework is based on two principal steps, the first is at the installation moment of the parallel application, and the second is at runtime. In the first step, we profile two components which are sequential kernels of the program and network performances. In order to model accurately these two components we have developed new strategies of regression. In the second step, we use the generated models and the runtime variables to the completion time estimation via our fast simulator MPI-PERF-SIM. Our experimentations on the Grid'5000 platform demonstrate the interest of this approach that can be the basis of adaptivity for parallel numerical libraries on dedicated hierarchical platforms.},
  keywords={},
  doi={10.1109/PDP.2011.49},
  ISSN={2377-5750},
  month={Feb},}
@INPROCEEDINGS{5759165,
  author={Green, Robert C. and Wang, Lingfeng and Alam, Mansoor and Singh, Chanan},
  booktitle={ISGT 2011}, 
  title={Intelligent and parallel state space pruning for power system reliability analysis using MPI on a multicore platform}, 
  year={2011},
  volume={},
  number={},
  pages={1-8},
  abstract={State space pruning is a methodology that has been successfully applied to improve the computational efficiency and convergence of Monte Carlo Simulation (MCS) when computing the reliability indices of power systems. This methodology increases performance of MCS by pruning state spaces in such a manner that a conditional state space with a higher density of failure states than the original state space is created. A method that was previously proposed to increase the efficiency of MCS was the use of Population-based Intelligent Search (PIS) techniques including Genetic Algorithms (GA), Particle Swarm Optimization (PSO), and Ant Colony Optimization (ACO) to prune the state space. This paper improves upon these ideas by parallelizing the PIS techniques using the Open Message Passing Interface (Open MPI) in order to further improve the convergence time of MCS. The PIS algorithms and their parallel implementations are discussed and results are compared and contrasted. This method is tested using the IEEE reliability test system.},
  keywords={},
  doi={10.1109/ISGT.2011.5759165},
  ISSN={},
  month={Jan},}
@INPROCEEDINGS{5763272,
  author={Ziermann, Tobias and Teich, Jürgen and Salcic, Zoran},
  booktitle={2011 Design, Automation & Test in Europe}, 
  title={DynOAA — Dynamic offset adaptation algorithm for improving response times of CAN systems}, 
  year={2011},
  volume={},
  number={},
  pages={1-4},
  abstract={CAN bus systems are used in many industrial control applications, particularly automotive. Due to growing system and functional requirements, the low capacity of the CAN bus and usually strict conditions under which it is used in realtime applications, applicability of CAN bus is severely limited. The paper presents an approach for achieving high utilization and breathes new life to CAN bus based systems by proposing a dynamic offset adaptation algorithm for scheduling messages and improving message response times without any changes to a standard CAN bus. This simple algorithm, which runs on all nodes of the system, results in excellent average response times at all loads and makes the approach particularly attractive for soft real-time systems. We demonstrate the performance improvement of the proposed approach by comparisons to other approaches and introduce a new performance measure in the form of a rating function.},
  keywords={},
  doi={10.1109/DATE.2011.5763272},
  ISSN={1558-1101},
  month={March},}
@INPROCEEDINGS{5763299,
  author={Tendulkar, Pranav and Papaefstathiou, Vassilis and Nikiforos, George and Kavadias, Stamatis and Nikolopoulos, Dimitrios S. and Katevenis, Manolis},
  booktitle={2011 Design, Automation & Test in Europe}, 
  title={Fine-grain OpenMP runtime support with explicit communication hardware primitives}, 
  year={2011},
  volume={},
  number={},
  pages={1-4},
  abstract={We present a runtime system that uses the explicit on-chip communication mechanisms of the SARC multi-core architecture, to implement efficiently the OpenMP programming model and enable the exploitation of fine-grain parallelism in OpenMP programs. We explore the design space of implementation of OpenMP directives and runtime intrinsics, using a family of hardware primitives; remote stores, remote DMAs, hardware counters and hardware event queues with automatic responses, to support static and dynamic scheduling and data transfers in local memories. Using an FPGA prototype with four cores, we achieve OpenMP task creation latencies of 30-35 processor clock cycles, initiation of parallel contexts in 50 cycles and synchronization primitives in 65-210 cycles.},
  keywords={},
  doi={10.1109/DATE.2011.5763299},
  ISSN={1558-1101},
  month={March},}
@INPROCEEDINGS{5763591,
  author={Millman, E. and Arora, D. and Neville, S.W.},
  booktitle={2011 IEEE Workshops of International Conference on Advanced Information Networking and Applications}, 
  title={STARS: A Framework for Statistically Rigorous Simulation-Based Network Research}, 
  year={2011},
  volume={},
  number={},
  pages={733-739},
  abstract={Simulation has become one of the dominant tools in wired and wireless network research. With the advent of cloud, grid, and cluster computing it has become feasible to use parallelization to perform richer larger-scale simulations. Moreover, the computing resources needed to perform statistically rigorous simulations are now easily obtainable. Although a number of parallel network simulation frameworks exists, the issue of statistical rigorous testing has largely not been addressed. This work presents a parallel MPI-aware network simulation framework that is specifically designed to provide automated support for statistically rigorous experimentation, thereby offloading this significant researcher burden. Unlike prior frameworks, the proposed framework includes a distribution-free statistical analysis feedback loop that automatically deduces the next set of experiments that need to be run. The value of this new framework is highlighted by exploring the well known issue of assessing the true duration of start-up transients within mobile ad hoc networks (MANETs) simulations.},
  keywords={},
  doi={10.1109/WAINA.2011.147},
  ISSN={},
  month={March},}
@INPROCEEDINGS{5770393,
  author={Nittoor, Vivek S. and Suda, Reiji},
  booktitle={2011 Sixth International Symposium on Parallel Computing in Electrical Engineering}, 
  title={Parallelizing a Coarse Grain Graph Search Problem Based upon LDPC Codes on a Supercomputer}, 
  year={2011},
  volume={},
  number={},
  pages={7-12},
  abstract={Codes on graphs have become the most important way to reach channel capacity. A new problem for High Performance Computing has been constructed with this work. The graph search problem as posed in this work is the coarsest version of the problem which corresponds to the exhaustive search case. The coarse grain graph search (CGGS) problem chooses an optimal parity-check matrix, based on minimum value of BER objective function. Based upon the specified range of parity-check matrices and range of signal to noise ratio (SNR), the CGGS generates the parity-check matrices using the Modified PEG algorithm, performs LDPC encoding, adds noise to the encoder output, performs LDPC decoding, computes Bi terror rate (BER), and thus the BER objective function. The CGGS problem in its current implementation runs in an MPI implementation on the T2K supercomputer at The University Of Tokyo. Two scheduling strategies have been proposed, Generalized Max-Min pairing (GMMP) and random pairing(RP) scheduling algorithms have been proposed, and good parallel performance of CGGS over an MPI implementation on T2K has been achieved.},
  keywords={},
  doi={10.1109/PARELEC.2011.13},
  ISSN={},
  month={April},}
@INPROCEEDINGS{5771268,
  author={Schmidt, Andrew G. and Huang, Bin and Sass, Ron and French, Matthew},
  booktitle={2011 IEEE 19th Annual International Symposium on Field-Programmable Custom Computing Machines}, 
  title={Checkpoint/Restart and Beyond: Resilient High Performance Computing with FPGAs}, 
  year={2011},
  volume={},
  number={},
  pages={162-169},
  abstract={As FPGA resources continue to increase, FPGAs present attractive features to the High Performance Computing community. These include the power-efficient computation and application-specific acceleration benefits, as well as tighter integration between compute and I/O resources. This paper considers the ability of an FPGA to address another, increasingly important, feature - resiliency. Specifically, a minimally-invasive monitoring infrastructure operating over a sideband network is presented. This includes a multi-chip protocol, IP cores that implement the protocol, and a tool to instrument existing hardware accelerator FPGA designs. To demonstrate the functionality, the system has been implemented on a cluster of FPGA devices running off-the-shelf MPI and Linux. We demonstrate the ability to do integrated software and hardware accelerator check pointing with restart under a variety of injected faults.},
  keywords={},
  doi={10.1109/FCCM.2011.22},
  ISSN={},
  month={May},}
@INPROCEEDINGS{5898879,
  author={Rahim, Messaoud and Boukala, Mohand Cherif},
  booktitle={2011 10th International Symposium on Programming and Systems}, 
  title={Using processor virtualization to load balancing distributed state space construction}, 
  year={2011},
  volume={},
  number={},
  pages={156-162},
  abstract={Most distributed model-checking algorithms use global hash functions to partition state space. This creates load imbalance between computation processors. In this paper, we focus on the use of processor virtualization for parallelizing the state space construction algorithm. Our aim is to optimize the distributed model checking process by using load balancing techniques. We study the effectiveness of Charm++ runtime system and Adaptive Message Passing Interface that support processor virtualization for load balancing the distributed state space construction. The objective is to allow the verification of large and complex systems by maintaining equally loaded processors and achieving higher speed-up. Preliminary experiments are reported to show the benefits of constructing state space using processor virtualization.},
  keywords={},
  doi={10.1109/ISPS.2011.5898879},
  ISSN={},
  month={April},}
@INPROCEEDINGS{5937810,
  author={Zhang, Xinmiao and Cai, Fang},
  booktitle={2011 IEEE International Symposium of Circuits and Systems (ISCAS)}, 
  title={Low-complexity architectures for reliability-based message-passing non-binary LDPC decoding}, 
  year={2011},
  volume={},
  number={},
  pages={1303-1306},
  abstract={When the code is not long, non-binary low-density parity- check (NB-LDPC) codes can achieve better error-correcting performance than binary LDPC codes at the cost of higher decoding complexity. The recently developed iterative reliability-based majority-logic NB- LDPC decoding can achieve better performance-complexity tradeoffs than previous algorithms. Many existing NB-LDPC code construction schemes lead to quasi-cyclic or cyclic codes. In this paper, efficient low- complexity NB-LDPC decoder architectures are developed for these two types of codes based on the newly proposed iterative hard reliability-based majority-logic decoding (IHRB-MLGD). Particularly, novel schemes are designed to keep a small proportion of messages in order to reduce the memory requirement without causing noticeable performance loss. Moreover, a shift-message structure is proposed by using memories concatenated with variable node units to enable efficient partial-parallel decoding for cyclic NB-LDPC codes. Compared to previous decoders based on the Min-max algorithm, the proposed IHRB-MLGD decoder architectures can achieve tens of times higher efficiency for codes with similar length and rate with moderate coding gain loss.},
  keywords={},
  doi={10.1109/ISCAS.2011.5937810},
  ISSN={2158-1525},
  month={May},}
@INPROCEEDINGS{5947169,
  author={Chakareski, Jacob},
  booktitle={2011 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Content preference estimation in online social networks: Message passing versus sparse reconstruction on graphs}, 
  year={2011},
  volume={},
  number={},
  pages={3760-3763},
  abstract={We design two different strategies for computing the unknown content preferences in an online social network based on a small set of nodes in the corresponding social graph for which this information is available ahead of time. The techniques take advantage of the graph's structure and the additional affinity information between the social contacts, expressed through the graph's edge weights, to optimize the computation of the missing preference data. The first strategy is distributed and comprises a local computation step and a message passing step that are iteratively applied at each node in the graph, until convergence. We carry out a graph Laplacian based analysis of the performance of the algorithm and verify the analytical findings via numerical experiments involving sample social networks. The second strategy is centralized and involves a sparse transform of the content preference data represented as a function over the nodes of the social graph. We solve the related optimization problem of reconstructing the unknown preferences via an iterative algorithm based on variable splitting and alternating direction of multipliers. The algorithm takes into account the specifics of the data to be reconstructed by incorporating multiple regularization terms into the optimization. We investigate the underpinnings of the sparse reconstruction technique via numerical experiments that reveal its characteristics and how they affect its performance.},
  keywords={},
  doi={10.1109/ICASSP.2011.5947169},
  ISSN={2379-190X},
  month={May},}
@INPROCEEDINGS{5948577,
  author={Yu, Qiaoyan and Zhang, Meilin and Ampadu, Paul},
  booktitle={Proceedings of the Fifth ACM/IEEE International Symposium}, 
  title={A comprehensive Networks-on-Chip simulator for error control explorations}, 
  year={2011},
  volume={},
  number={},
  pages={263-264},
  abstract={Error control is imperative for reliable Networks-on-Chip (NoCs) design. In this demo session, we will present a CAD tool-a flexible and parallel NoC simulator. Our simulator evaluates the impact of different error control mechanisms on NoC performance and energy consumption in various noise and traffic injection scenarios. Our message passing interface language-based simulator can be executed on multiprocessors or server clusters. Multiple built-in blocks provide flexibility to evaluate different error control methods.},
  keywords={},
  doi={},
  ISSN={},
  month={May},}
@INPROCEEDINGS{5945431,
  author={Wu, Yizhi and Rowe, Anthony},
  booktitle={2011 IEEE/ACM Second International Conference on Cyber-Physical Systems}, 
  title={Logic-Based Programming for Wireless Sensor-Activator Networks}, 
  year={2011},
  volume={},
  number={},
  pages={163-173},
  abstract={In this paper we present SAN-Logic, a lightweight logic-based programming paradigm that enables the dynamic progammability and configuration of sensor-actuator interactions in wireless sensor networks used to support Cyber-Physical Systems (CPS). Our goal is to simplify complex CPS design by providing a structured model of interactions that can be automatically mapped and deployed to a sensor-actuator network in an efficient and scalable manner. In contrast to sensor networking paradigms that distribute an application into individual sub-programs, SAN-Logic models the system as a set of boolean expressions which can be partitioned across the network like gates in a circuit. The user defines interactions as timed asynchronous sequential logic expressions with sensors and actuators representing the inputs and outputs of the system. This approach is highly scalable since once deployed each interaction takes place as a sequence of independent and asynchronous events. This allows SAN-Logic to operate in a fully distributed manner without a central authority. Using this framework, optimization takes place across multiple tasks enabling sharing of resources within the network which will be an important part of future CPS. Redundant routes and the stateless nature of combinational logic (along with periodic state update messages) allow the system to easily cope with packet-loss and failed nodes. A major benefit of this approach is the ability to leverage existing hardware design and synthesis tools used by the VLSI design community. We demonstrate how boolean manipulation of the logic can be used to alter the mapping of expressions onto the network and hence can be used for optimization and verification. We provide an approach using logic simplification and mapping that reduces message passing by factoring common terms across different data paths within tasks and placing intermediate terms such that they benefit from shorter paths. In complex systems, we see on average a 40% reduction in message passing as compared to an implementation that does not optimize communication patterns within and across tasks.},
  keywords={},
  doi={10.1109/ICCPS.2011.31},
  ISSN={},
  month={April},}
@INPROCEEDINGS{5948657,
  author={Kimura, Hiroki and Tatebe, Osamu},
  booktitle={2011 11th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing}, 
  title={MPI-IO/Gfarm: An Optimized Implementation of MPI-IO for the Gfarm File System}, 
  year={2011},
  volume={},
  number={},
  pages={610-611},
  abstract={This paper proposes a design and implementation of an MPI-IO implementation of the Gfarm file system, called MPI-IO/Gfarm. The Gfarm file system is a global file system that federates the local storage of compute nodes among several clusters. It has a scale-out architecture designed to support distributed data-intensive computing. However Gfarm file system does not achieve scalable performance in the case of parallel writes to a single file, a typical file operation in MPI-IO. This paper proposes an optimization technique to improve the parallel write performance to a single file. In the evaluation, MPI-IO/Gfarm achieves scalable parallel I/O performance.},
  keywords={},
  doi={10.1109/CCGrid.2011.82},
  ISSN={},
  month={May},}
@INPROCEEDINGS{5952667,
  author={Thanagasundram, Suguna and Segan, Mark Amor and McMurran, Ross and Jones, R. Peter},
  booktitle={2011 IEEE International Conference on Computer Science and Automation Engineering}, 
  title={Failure management for reliable automotive start up process}, 
  year={2011},
  volume={3},
  number={},
  pages={215-219},
  abstract={This paper describes the work done on advanced fault management strategies at a system of systems level on the start authorization process in a vehicle. The start authorization system in a vehicle is a complicated and critical vehicle process. It manifests itself as a complex multi-stage process which involves several stages of verification and validation amongst various distributed automotive systems through the exchange of messages and signals on a common network. The behavior of the start-up process in a vehicle is inferred: 50% from interaction of signals in the data in a start up process and 50% from expert knowledge already gathered from vehicle specifications and functionality testing. A model is constructed to diagnose vehicle no-start faults in a vehicle. With data collected from real vehicles, the start authorization process is benchmarked and a nominal behavior is established. In a vehicle no-start condition, the start-up process differs greatly from this nominal behavior and the different failure modes are identified to advise the driver of the root cause of the problem.},
  keywords={},
  doi={10.1109/CSAE.2011.5952667},
  ISSN={},
  month={June},}
@INPROCEEDINGS{5951907,
  author={Glück, Olivier and Mignot, Jean-Christophe},
  booktitle={2011 IEEE Ninth International Symposium on Parallel and Distributed Processing with Applications}, 
  title={Splitting TCP for MPI Applications Executed on Grids}, 
  year={2011},
  volume={},
  number={},
  pages={207-212},
  abstract={In this paper, we first study the interaction between MPI applications and TCP on grids. Then, we propose MPI5000, a transparent applicative layer between MPI and TCP, using proxies to improve the execution of MPI applications on a grid. Proxies aim at splitting TCP connections in order to detect losses faster and avoid to return in a slow-start phase after an idle time. Finally, we evaluate our layer executing the NAS Parallel Benchmarks on Grid5000, the French research grid, using MPICH2. The results show that our architecture reduces the number of idle timeout and of long-distance retransmissions for BT, SP and LU benchmarks. Using MPI5000, these applications can decrease their execution time by 35%, 28%, and, 15% respectively. A comparison with MPICH-G2 performances shows that our layer can even outperform a grid enabled MPI implementation.},
  keywords={},
  doi={10.1109/ISPA.2011.11},
  ISSN={2158-9208},
  month={May},}
@INPROCEEDINGS{5961758,
  author={Cheung, Alex King Yeung and Jacobsen, Hans-Arno},
  booktitle={2011 31st International Conference on Distributed Computing Systems}, 
  title={Green Resource Allocation Algorithms for Publish/Subscribe Systems}, 
  year={2011},
  volume={},
  number={},
  pages={812-823},
  abstract={A popular trend in large enterprises today is the adoption of green IT strategies that use resources as efficiently as possible to reduce IT operational costs. With the publish/subscribe middleware playing a vital role in seamlessly integrating applications at large enterprises including Google and Yahoo, our goal is to search for resource allocation algorithms that enable publish/subscribe systems to use system resources as efficiently as possible. To meet this goal, we develop methodologies that minimize system-wide message rates, broker load, hop count, and the number of allocated brokers, while maximizing the resource utilization of allocated brokers to achieve maximum efficiency. Our contributions consist of developing a bit vector supported resource allocation framework, designing and comparing four different classes with a total of ten variations of subscription allocation algorithms, and developing a recursive overlay construction algorithm. A compelling feature of our work is that it works under any arbitrary workload distribution and is independent of the publish/subscribe language, which makes it easily applicable to any topic and content-based publish/subscribe system. Experiments on a cluster testbed and a high performance computing platform show that our approach reduces the average broker message rate by up to 92% and the number of allocated brokers by up to 91%.},
  keywords={},
  doi={10.1109/ICDCS.2011.82},
  ISSN={1063-6927},
  month={June},}
@ARTICLE{5963620,
  author={Gong, Yi and Liu, Xingcheng and Ye, Weicai and Han, Guojun},
  journal={IEEE Transactions on Communications}, 
  title={Effective Informed Dynamic Scheduling for Belief Propagation Decoding of LDPC Codes}, 
  year={2011},
  volume={59},
  number={10},
  pages={2683-2691},
  abstract={The simultaneous flooding scheduling is popular for Low-Density Parity-Check (LDPC) Belief Propagation (BP) decoding. Non-simultaneous sequential scheduling is superior to the flooding scheduling, and asynchronous dynamic scheduling has better FER performance than the sequential scheduling. However, all strategies encounter the trouble of locating the error variable node. This paper proposes an informed dynamic scheduling strategy, which utilizes the instability of the variable node and the residual of the variable-to-check message to locate the message to be updated first. The informed dynamic scheduling overcomes the trapping sets effectively. This paper also designs an informed dynamic scheduling strategy with adaptivity to pass more messages in parallel, which effectively postpones the influence of cycles in the Tanner graph. In some sense, the strategy lengthens cycles. Simulation results show that the two informed dynamic scheduling strategies outperform other algorithms.},
  keywords={},
  doi={10.1109/TCOMM.2011.072011.100438},
  ISSN={1558-0857},
  month={October},}
@INPROCEEDINGS{5967162,
  author={Jovalekić, Silvije and Rist, Bernd},
  booktitle={2011 Proceedings of the 34th International Convention MIPRO}, 
  title={Automated testing of distributed real-time systems regarding configuration information}, 
  year={2011},
  volume={},
  number={},
  pages={792-796},
  abstract={Time-dependent cause-effect graph extended by messages and communication channels is used to describe test cases for distributed discrete systems. Send messages stimulate test object through communications channels. Received messages from test object are used for test data comparison. We have improved significantly the test methods for distributed real-time systems by considering the configuration of the test object. It simplifies the test planning process and delivers more exact information during test execution and evaluation. To enable independency of system description from special Computer Aided Engineering (CAE) systems, we have defined a reference model for test objects, consisting of modules and connections. The description of test objects is used to identify and display messages from selected connections in context-sensitive protocol analysis, event lists and pulse diagrams. This supports the activities of development engineers during system verification.},
  keywords={},
  doi={},
  ISSN={},
  month={May},}
@INPROCEEDINGS{5964768,
  author={Xiaogang Han and Yuefeng Liu and Lei Yan and Yiwei Gao},
  booktitle={2011 International Conference on Remote Sensing, Environment and Transportation Engineering}, 
  title={Parallel map matching algorithm based on multi-core and MPI}, 
  year={2011},
  volume={},
  number={},
  pages={2291-2294},
  abstract={For the requirements of large-scale real-time vehicle GPS data map matching in application, this paper proposes a parallel algorithm for road matching based on multi-core and MPI(Massage Passing Interface). Several basic questions for road matching are discussed, such as maps storage structure, matching elements, and alternative road chain searching. Then, based on multi-core and MPI computing platform, the parallel algorithm for road matching is implemented, with actual road network and floating car data. The validation results show that the algorithm not only has high speedup rate and efficiency, but also the matching results are credible.},
  keywords={},
  doi={10.1109/RSETE.2011.5964768},
  ISSN={},
  month={June},}
@INPROCEEDINGS{5963988,
  author={Neamatollahi, Peyman and Taheri, Hoda and Naghibzadeh, Mahmoud},
  booktitle={2011 CSI International Symposium on Computer Science and Software Engineering (CSSE)}, 
  title={A distributed token-based scheme to allocate critical resources}, 
  year={2011},
  volume={},
  number={},
  pages={30-37},
  abstract={We propose an algorithm to allocate critical resources (mutual exclusion problem) in a computer network composed of N nodes that communicate by message exchanges. The algorithm uses a logical structure in the form of wraparound two-dimensional array which is imposed on the network. In this algorithm some nodes know the token-holding node and lead critical section requests to the token-holding node directly. Usually, a request is sent vertically down in the array, and eventually sent to the token-holding node with the assistant of an informed-node (common node between the row consisting of the token-holding node and the column consisting of the requester node). Therefore, the nodes invoking the critical section can obtain the token with fewer message exchanges in comparison with more other algorithms. Typically the number of message exchanges is 4√N +1 under light demand and reduces to approximately 2 message exchanges under heavy demand. A correctness proof is provided.},
  keywords={},
  doi={10.1109/CSICSSE.2011.5963988},
  ISSN={},
  month={June},}
@INPROCEEDINGS{5974857,
  author={Ying Guo and Li, Zeng-yuan and Chen, Er-xue and Xu Zhang},
  booktitle={2011 International Conference on Computer Science and Service System (CSSS)}, 
  title={The study of parallel KNN in the identification of forest type based on multi-spectral data}, 
  year={2011},
  volume={},
  number={},
  pages={4113-4115},
  abstract={Forest type identification is one of most important contents of forest inventory. K nearest-neighbour algorithm has already proven their use in forest mapping. However, as the remote sensing data was large scale, the efficiency of processing based on KNN decreased seriously. Therefore, the study implemented a tool which could have the feature of fast processing multi-spectral data based on KNN. For enhancing the efficiency of processing, the tool was implemented in the way of parallelization by using the message passing interface (MPI) technology and run on the high performance cluster environment. By segmenting the input large scale image in some small block and parallel processing all these block, the computing time was shorten greatly. To certain the suitable parameter automatically such as K and the appropriate distance measured method during the processing, the study used leave-one-out cross validation method to check the precision and selected the optimum model based on the accuracy. The result shows that the tool accelerated the computation speed as eight time as before while ensuring the treatment precision and improved the automatic degree of the treatment. To some extend, it solved the bottleneck of processing large scale remote sensing data.},
  keywords={},
  doi={10.1109/CSSS.2011.5974857},
  ISSN={},
  month={June},}
@INPROCEEDINGS{5982512,
  author={Soysal, Onur and Aydin, Bahadir Ismail and Demirbas, Murat},
  booktitle={2011 7th International Wireless Communications and Mobile Computing Conference}, 
  title={Optimistic Concurrency Control for multihop sensor networks}, 
  year={2011},
  volume={},
  number={},
  pages={89-94},
  abstract={In this study, we provide a lightweight singlehop primitive, Read-All-Write-Self (RAWS), that achieves optimistic concurrency control. RAWS guarantees serializability, which simplifies implementation and verification of distributed algorithms, compared to the low level message passing model. We also present a self-stabilizing multihop extension of RAWS, called Multihop Optimistic Concurrency Control Algorithm (MOCCA), to address the challenges of multihop networks. We implement RAWS on motes and investigate the effects of message loss over this novel primitive.},
  keywords={},
  doi={10.1109/IWCMC.2011.5982512},
  ISSN={2376-6506},
  month={July},}
@INPROCEEDINGS{5982559,
  author={Razavi, Razieh and Ali Imran, Muhammad and Tafazolli, Rahim},
  booktitle={2011 7th International Wireless Communications and Mobile Computing Conference}, 
  title={EXIT chart analysis for turbo LDS-OFDM receivers}, 
  year={2011},
  volume={},
  number={},
  pages={354-358},
  abstract={In this paper, the mutual information transfer characteristics of turbo Multiuser Detector (MUD) for a novel air interface scheme, called Low Density Signature Orthogonal Frequency Division Multiplexing (LDS-OFDM) are investigated using Extrinsic Information Transfer (EXIT) charts. LDS-OFDM uses Low Density Signature structure for spreading the data symbols in frequency domain. This technique benefits from frequency diversity besides its ability of supporting parallel data streams more than the number of subcarriers (overloaded condition). The turbo MUD couples the data symbols' detector of LDS scheme with users' FEC (Forward Error Correction) decoders through the message passing principle. The effect of overloading on LDS scheme's performance is evaluated using EXIT chart. The results show that at Eb/N0 as low as 0.3, LDS-OFDM can support loads up to 300%.},
  keywords={},
  doi={10.1109/IWCMC.2011.5982559},
  ISSN={2376-6506},
  month={July},}
@INPROCEEDINGS{5979048,
  author={Kalpana, R. and Thambidurai, P.},
  booktitle={2011 International Conference on Process Automation, Control and Computing}, 
  title={Parallelized Multilevel Arc Flags Improve Speedup in Shortest Path Queries}, 
  year={2011},
  volume={},
  number={},
  pages={1-7},
  abstract={Tremendous growth in online applications require shortest path queries to solve its problem where the data volume is very high. Among the various shortest path algorithms considered, Dijkstra's shortest path algorithm proves to have better performance compared to other algorithms. The speedup techniques when applied to these shortest path algorithms will improve the performance of the system. The combined speedup techniques have higher impact over the shortest path queries. In this paper a new combined speedup technique based on arc flags and multilevel method (COAM) is implemented and tested on random graphs, planar graphs, and real world graphs. The pre-processing phase of arc flag and multilevel method is parallelised using OpenMP parallel programming constructs and effect of that produces an improved speedup in the individual basic speedup techniques and combined speedup technique (COAM).},
  keywords={},
  doi={10.1109/PACC.2011.5979048},
  ISSN={},
  month={July},}
@INPROCEEDINGS{5984892,
  author={Battaglino, Donato and Bracciale, Lorenzo and Detti, Andrea and Piccolo, Francesca Lo and Bragagnini, Andrea and Turolla, Maura Santina and Blefari-Melazzi, Nicola},
  booktitle={2011 8th Annual IEEE Communications Society Conference on Sensor, Mesh and Ad Hoc Communications and Networks}, 
  title={Campus++: A publish-subscribe architecture for intermittently connected 802.15.4 networks}, 
  year={2011},
  volume={},
  number={},
  pages={164-166},
  abstract={The aim of this extended abstract is to present Campus++, a location-based publish-subscribe system for intermittently connected delay tolerant networks, exploiting IEEE 802.15.4 devices, and taking into due account the severe constraints deriving from their physical characteristics. We describe our proposed architectural model and how we implemented our solution in a real test-bed. We point out that our system can be easily adapted to operate in a fully distributed, infrastructure-less way, allowing free communications e.g. in disaster areas or in areas in which ”usual” communications means are either non existent or intentionally made unavailable.},
  keywords={},
  doi={10.1109/SAHCN.2011.5984892},
  ISSN={2155-5494},
  month={June},}
@INPROCEEDINGS{5987874,
  author={Hongmei Xie and Chunli Chen},
  booktitle={2011 Second International Conference on Mechanic Automation and Control Engineering}, 
  title={Design and implementation of parallel word occurrence frequency based on message passing interface}, 
  year={2011},
  volume={},
  number={},
  pages={3985-3988},
  abstract={For large files and files distributed all around the internet, this paper proposed and realized parallel word occurrence frequency counting using C and message passing interface programming. And to solve the specific word occurrence problems like how to extract word precisely, traverse file completely, eliminate redundant words, adapt to any text files, and count the number of letters and word. An improved serial word counting algorithm was designed and implemented. Then the parallel partition strategy based on both balanced file size and balanced task were discussed and a combined partition strategy was designed and implemented using C programming and MapReduce message passing interface (MR-MPI) library. After that the counting of word occurrence frequency for relatively small and very large text file were realized. And last we executed the same task in parallel computing environment. The test showed that the algorithm proposed implements word counting for files of large data set, both in parallel high performance computing and cloud environment with short runtime and high accuracy. Last, some discussion on the parallel implementation of the word counting problem in Google's cloud environment is given out.},
  keywords={},
  doi={10.1109/MACE.2011.5987874},
  ISSN={},
  month={July},}
@INPROCEEDINGS{5988914,
  author={Avellaneda, Florent and Morin, Remi},
  booktitle={2011 Eleventh International Conference on Application of Concurrency to System Design}, 
  title={Checking Non-divergence, Channel-Bound and Global Cooperation Using SAT-Solvers}, 
  year={2011},
  volume={},
  number={},
  pages={19-28},
  abstract={Divergence appears in message sequence chart specifications when an unbounded number of messages are pending within a communication channel. Several algorithms and tools have been already developed to detect this property. This paper explains why checking non-divergence is very close to the Boolean satisfiability problem and shows how SAT-solvers can be used to check this property efficiently. We show also how some other close properties can be checked similarly.},
  keywords={},
  doi={10.1109/ACSD.2011.31},
  ISSN={1550-4808},
  month={June},}
@INPROCEEDINGS{5995724,
  author={Ross, Stéphane and Munoz, Daniel and Hebert, Martial and Bagnell, J. Andrew},
  booktitle={CVPR 2011}, 
  title={Learning message-passing inference machines for structured prediction}, 
  year={2011},
  volume={},
  number={},
  pages={2737-2744},
  abstract={Nearly every structured prediction problem in computer vision requires approximate inference due to large and complex dependencies among output labels. While graphical models provide a clean separation between modeling and inference, learning these models with approximate inference is not well understood. Furthermore, even if a good model is learned, predictions are often inaccurate due to approximations. In this work, instead of performing inference over a graphical model, we instead consider the inference procedure as a composition of predictors. Specifically, we focus on message-passing algorithms, such as Belief Propagation, and show how they can be viewed as procedures that sequentially predict label distributions at each node over a graph. Given labeled graphs, we can then train the sequence of predictors to output the correct labeling s. The result no longer corresponds to a graphical model but simply defines an inference procedure, with strong theoretical properties, that can be used to classify new graphs. We demonstrate the scalability and efficacy of our approach on 3D point cloud classification and 3D surface estimation from single images.},
  keywords={},
  doi={10.1109/CVPR.2011.5995724},
  ISSN={1063-6919},
  month={June},}
@INPROCEEDINGS{5999842,
  author={Ahn, Jinho},
  booktitle={2011 International Conference on High Performance Computing & Simulation}, 
  title={Effective sender-based message logging algorithm with checkpointing considering transient communication errors}, 
  year={2011},
  volume={},
  number={},
  pages={330-335},
  abstract={Thanks to its beneficial features such as requiring no specialized hardware and lowering highly failure-free overhead of synchronous logging with volatile logging at sender's memory, sender-based message logging (SBML) with checkpointing might be applied into many distributed systems as a low-cost transparent rollback recovery technique. However, the original SBML recovery algorithm may no longer be progressing in some transient communication error cases. This paper proposes a consistent recovery algorithm to solve this problem by piggybacking small log information for unstable messages received on each acknowledgement message for returning the receive sequence number assigned to a message by its receiver. This feature also allows message send operations delayed after having performed some message receive operations during failure-free execution to begin executing much earlier compared with the existing ones.},
  keywords={},
  doi={10.1109/HPCSim.2011.5999842},
  ISSN={},
  month={July},}
@INPROCEEDINGS{5999835,
  author={Böhm, Swen and Engelmann, Christian},
  booktitle={2011 International Conference on High Performance Computing & Simulation}, 
  title={xSim: The extreme-scale simulator}, 
  year={2011},
  volume={},
  number={},
  pages={280-286},
  abstract={Investigating parallel application performance at scale is an important part of high-performance computing (UPC) application development. The Extreme-scale Simulator (xSim) is a performance toolkit that permits running an application in a controlled environment at extreme scale without the need for a respective extreme-scale HPC system. Using a lightweight parallel discrete event simulation, xSim executes a parallel application with a virtual wall clock time, such that performance data can be extracted based on a processor and a network model. This paper presents significant enhancements to the xSim toolkit that provide a more complete Message Passing Interface (MPI) support and improve its versatility. These enhancements include full virtual MPI group, communicator and collective communication support, and global variables support. The new capabilities are demonstrated by executing the entire NAS Parallel Benchmark suite in a simulated HPC environment.},
  keywords={},
  doi={10.1109/HPCSim.2011.5999835},
  ISSN={},
  month={July},}
@INPROCEEDINGS{5999896,
  author={Piotrowski, Michal and Forster, Thorsten and Dobrezelecki, Bartosz and Sloan, Terence M. and Mitchell, Lawrence and Ghazal, Peter and Mewsissen, Muriel and Petrou, Savvas and Trew, Arthur and Hill, Jon},
  booktitle={2011 International Conference on High Performance Computing & Simulation}, 
  title={Optimisation and parallelisation of the partitioning around medoids function in R}, 
  year={2011},
  volume={},
  number={},
  pages={707-713},
  abstract={R is a free statistical programming language commonly used for the analysis of high-throughput microarray and other data. It is currently unable to easily utilise multi processor architectures without substantial changes to existing R scripts. Further, working with large volumes of data often leads to slow processing and even memory allocation faults. A recent survey highlighted clustering algorithms as both computation and data intensive bottlenecks in post-genomic data analyses. These algorithms aim to sort numeric vectors (such as gene expression profiles) into groups by minimising vector distances within groups and maximising them between groups. This paper describes the optimisation and parallelisation of a popular clustering algorithm, partitioning around medoids (PAM), for the Simple Parallel R INTerface (SPRINT). SPRINT allows R users to exploit high performance computing systems without expert knowledge of such systems. This paper reports on a serial optimisation of the original code and a subsequent parallel implementation. The parallel implementation enables the processing of data sets that exceed the available physical memory and can yield, depending on the data set, over 100-fold increase in performance.},
  keywords={},
  doi={10.1109/HPCSim.2011.5999896},
  ISSN={},
  month={July},}
@INPROCEEDINGS{5999219,
  author={Wang, Gang and Wang, Lei},
  booktitle={2011 International Conference on Management and Service Science}, 
  title={A Parallel Vulnerability Detection Framework via MPI}, 
  year={2011},
  volume={},
  number={},
  pages={1-4},
  abstract={Open source applications have flourished recent years. Meanwhile, security vulnerabilities in such applications have grown. Since manual code auditing is error-prone, time-consuming and costly, it is necessary to find automatic solutions. To address this problem we propose an approach that combines constraint-based analysis and model checking together. Model checking technology as a constraint solver can be employed to solve the constraint-based system. CodeAuditor, the prototype implementation of our methods, is targeted at detecting vulnerabilities in C source code. With this tool, 9 previously unknown vulnerabilities in two open source applications were discovered and the observed false positive rate was at around 29%.},
  keywords={},
  doi={10.1109/ICMSS.2011.5999219},
  ISSN={},
  month={Aug},}
@INPROCEEDINGS{6004136,
  author={Karenos, Kyriakos and Pauw, Wim De and Lei, Hui},
  booktitle={2011 IEEE/IPSJ International Symposium on Applications and the Internet}, 
  title={A Topic-Based Visualization Tool for Distributed Publish/Subscribe Messaging}, 
  year={2011},
  volume={},
  number={},
  pages={65-74},
  abstract={Service Oriented Architecture (SOA) has become a central design philosophy across many enterprise and organizational domains. Communication within and across enterprises is critical to allow interconnection and interoperation across service components and providers. Enterprise messaging refers to the set of technologies that enables companies to interconnect several units of their business, forming a network typically deployed across multiple locations. For these enterprise messaging networks, publish/subscribe is a communication paradigm that is gaining significant popularity. Traditional network monitoring tools can show topologies, statistics and various low-level endpoint relationships. Publish/Subscribe systems however facilitate communications at a much higher level than traditional networks via producing and consuming messages that are identified by topics. In this paper we describe the design and implementation of a visual tool that takes a topic-centric approach to visualizing communications in a publish/subscribe network. We propose a novel combination of a compact visual syntax and interaction techniques to help publish/subscribe network administrators and application developers understand and manage topic-specific message flows and their performance on networks. Several users have applied our tool to real-world industrial settings and have validated its effectiveness.},
  keywords={},
  doi={10.1109/SAINT.2011.19},
  ISSN={},
  month={July},}
@INPROCEEDINGS{6005379,
  author={Li, Cheng-Hong and Park, Alfred J. and Schenfeld, Eugen},
  booktitle={2011 IEEE 19th Annual International Symposium on Modelling, Analysis, and Simulation of Computer and Telecommunication Systems}, 
  title={Analytical Performance Modeling for Null Message-Based Parallel Discrete Event Simulation}, 
  year={2011},
  volume={},
  number={},
  pages={349-358},
  abstract={This paper presents a new analytical performance analysis for null message-based parallel discrete event simulation(PDES). Our analysis builds upon the key operation of selecting simulation events for processing in the null message algorithms. The results not only explain the well-known facts of how the look ahead capability of individual simulation processes (called logical processes, or LPs) affect the simulation performance, but also reveals quantitatively how the look ahead, the communication topology, the computation and communication delays, and the flow control mechanism affect the simulation performance. We first show that all of the LPs in a strongly connected component in the communication topology asymptotically progress at the same speed, regardless of their individual characteristics and their share of computation resource. Second, we derive an analytical upper bound on the simulation performance. The derivation shows that the ratio between the sum of the look ahead and the sum of the event processing and communication delays of LPs in a cycle bounds the simulation speed from the above, and the cycle of LPs imposes the tightest upper bound becomes the bottleneck of the simulation. We conduct a series of simulation experiments to empirically validate our findings. Moreover, we show that by using the derived upper bound as an optimization guidance, we improve the partitioning of a simple parallel simulation example and achieve a four times speedup against the same simulation based on a classic min-cut partitioning strategy.},
  keywords={},
  doi={10.1109/MASCOTS.2011.60},
  ISSN={2375-0227},
  month={July},}
@INPROCEEDINGS{6005452,
  author={Yin, Wenxuan and Gao, Xiang and Zhu, Xiaojing and Guo, Deyuan},
  booktitle={2011 IEEE Sixth International Conference on Networking, Architecture, and Storage}, 
  title={An Efficient Shared Memory Based Virtual Communication System for Embedded SMP Cluster}, 
  year={2011},
  volume={},
  number={},
  pages={288-294},
  abstract={With the prevalence of multi-core processors, it is a trend that the embedded cluster deploys SMP nodes to gain more computing power. As a crucial issue, the MPI inter-process communication has been suffering the contradiction between high performance and embedded constraints. Moreover, there is a big performance gap between intra- and inter-node communication for different infrastructures. In this paper, we design a virtual communication system called SMVN, which extends the shared memory mechanism typically used in intra-node case into the inter-node case. The SMVN utilizes the HT inter-chip interconnect interface in Godson-3A SMP nodes to build a mesh topology. It is Ethernet compatible by simulating bottom layers of TCP/IP protocol. With the design, the node interconnection can get rid of NICs, cables and switches. Furthermore, we exploit the zero-copy scheme and other optimizations to improve the performance. We port the MPICH2 library by socket channel and formulate its process allocation. The MPI latency and bandwidth tests show that the performance difference between two levels is small. The inter-node bandwidth is 27.3 MB/s, which is more than twice the theoretical peak value of 100 Mb Ethernet and reaches 84% of the intra-node performance.},
  keywords={},
  doi={10.1109/NAS.2011.16},
  ISSN={},
  month={July},}
@INPROCEEDINGS{6008743,
  author={Fan, Pei and Wang, Ji and Zheng, Zibin and Lyu, Michael R.},
  booktitle={2011 IEEE 4th International Conference on Cloud Computing}, 
  title={Toward Optimal Deployment of Communication-Intensive Cloud Applications}, 
  year={2011},
  volume={},
  number={},
  pages={460-467},
  abstract={Strongly promoted by the leading industrial companies, cloud computing becomes increasingly popular in re-cent years. The growth rate of cloud computing surpasses even the most optimistic predictions. A cloud application is a large-scale distributed system that consist a lot of distributed cloud nodes. How to make optimal deployment of cloud applications is a challenging research problem. When deploying a cloud application to the cloud environment, cloud node ranking is one of the most important approaches for selecting optimal cloud nodes for the cloud application. Traditional ranking methods usually rank the cloud nodes based on their QoS values, without considering the communication performance between cloud nodes. However, such kind of node relationship is very important for the communication-intensive cloud applications (e.g., Message Passing Interface (MPI) programs), which have a lot of communications between the selected cloud nodes. In this paper, we propose a novel clustering-based method for selecting optimal cloud nodes for deploying communication-intensive applications to the cloud environment. Our method not only takes into account the cloud node qualities, but also the communication performance between different nodes. We deploy several well-known MPI programs on a real-world cloud and compare our method with other methods. The experimental results show the effectiveness of our cluster-based method.},
  keywords={},
  doi={10.1109/CLOUD.2011.54},
  ISSN={2159-6190},
  month={July},}
@INPROCEEDINGS{6008879,
  author={Adnan and Sato, Mitsuhisa},
  booktitle={2011 IEEE International Symposium on Parallel and Distributed Processing Workshops and Phd Forum}, 
  title={Efficient Work-Stealing Strategies for Fine-Grain Task Parallelism}, 
  year={2011},
  volume={},
  number={},
  pages={577-583},
  abstract={Herein, we describe extended work-stealing strategies for Stack Threads/MP, in which thieves steal from the bottom of a victim's logical stack not just the bottommost task but multiple chained tasks. These new strategies offer two advantages: reducing the total cost of stealing tasks and reducing the total idle time. In addition, these strategies attempt to preserve the sequential execution order of tasks in the chain. We evaluated these extended work-stealing strategies by using the unbalanced tree search (UTS) benchmark and could demonstrate its advantages over the original work-stealing strategy and other OpenMP task implementations and Cilk implementation as well. Extended work-stealing strategies exhibit significant improvement with respect to the UTS benchmark, even if the task is very fine-grain and non-uniform.},
  keywords={},
  doi={10.1109/IPDPS.2011.191},
  ISSN={1530-2075},
  month={May},}
@INPROCEEDINGS{6008891,
  author={Kobayashi, Kenji and Mikami, Shunsuke and Kimura, Hiroki and Tatebe, Osamu},
  booktitle={2011 IEEE International Symposium on Parallel and Distributed Processing Workshops and Phd Forum}, 
  title={The Gfarm File System on Compute Clouds}, 
  year={2011},
  volume={},
  number={},
  pages={1034-1041},
  abstract={Due to its ability to provide requested resources on demand, the use of cloud computing for data-intensive computing is expected to skyrocket in the coming years. The present IaaS cloud infrastructure is designed such that the compute cloud and the storage cloud are separate components. However, the design has one major problem, namely a trade-off has to be made between the network cost and storage performance. To cope with these problems, we are proposing high performance file system service in compute cloud that transparently utilizes file access locality on dynamic configuration of cloud computing infrastructure. We evaluated the system using micro benchmarks, MapReduce applications, and MPI-IO applications. Our system shows the scalable file I/O performance.},
  keywords={},
  doi={10.1109/IPDPS.2011.255},
  ISSN={1530-2075},
  month={May},}
@INPROCEEDINGS{6008920,
  author={Venkata, Manjunath Gorentla and Graham, Richard L. and Ladd, Joshua S. and Shamis, Pavel and Rabinovitz, Ishai and Filipov, Vasily and Shainer, Gilad},
  booktitle={2011 IEEE International Symposium on Parallel and Distributed Processing Workshops and Phd Forum}, 
  title={ConnectX-2 CORE-Direct Enabled Asynchronous Broadcast Collective Communications}, 
  year={2011},
  volume={},
  number={},
  pages={781-787},
  abstract={This paper describes the design and implementation of InfiniBand (IB) CORE-Direct based blocking and nonblocking broadcast operations within the Cheetah collective operation framework. It describes a novel approach that fully offloads collective operations and employs only user-supplied buffers. For a 64 rank communicator, the latency of CORE-Direct based hierarchical algorithm is better than production grade Message Passing Interface (MPI) implementations, 150% better than the default Open MPI algorithm and 115% better than the shared memory optimized MVAPICH implementation for a one kilo-byte (KB) message, and for eight mega-bytes (MB) it is 48% and 64% better, respectively. Flat-topology broadcast achieves 99.9% overlap in a polling based communication-computation test, and 95.1% overlap for a wait based test, compared with 92.4% and 17.0%, respectively, for a similar Central Processing Unit (CPU) based implementation.},
  keywords={},
  doi={10.1109/IPDPS.2011.221},
  ISSN={1530-2075},
  month={May},}
@INPROCEEDINGS{6008982,
  author={Speziale, Ettore and di Biagio, Andrea and Agosta, Giovanni},
  booktitle={2011 IEEE International Symposium on Parallel and Distributed Processing Workshops and Phd Forum}, 
  title={An Optimized Reduction Design to Minimize Atomic Operations in Shared Memory Multiprocessors}, 
  year={2011},
  volume={},
  number={},
  pages={1300-1309},
  abstract={Reduction operations play a key role in modern massively data parallel computation. However, current implementations in shared memory programming APIs such as OpenMP are often computation bottlenecks due to the high number of atomic operations involved. We propose a reduction design that exploits the coupling with a barrier synchronization to optimize the execution of the reduction. Experimental results show how the number of atomic operations involved is dramatically reduced, which can lead to significant improvement in scaling properties on large numbers of processing elements. We report a speedup of 1.53x on the emph{312.swim m} SPEC OMP2001 benchmark and a speedup of 4.02x on the emph{stream cluster} benchmark from the PARSEC suite over the baseline.},
  keywords={},
  doi={10.1109/IPDPS.2011.271},
  ISSN={1530-2075},
  month={May},}
@INPROCEEDINGS{6008951,
  author={Raponi, Pier Giorgio and Petrini, Fabrizio and Walkup, Robert and Checconi, Fabio},
  booktitle={2011 IEEE International Symposium on Parallel and Distributed Processing Workshops and Phd Forum}, 
  title={Characterization of the Communication Patterns of Scientific Applications on Blue Gene/P}, 
  year={2011},
  volume={},
  number={},
  pages={1017-1024},
  abstract={This paper examines the communication characteristics of a collection of scientific applications selected from the LLNL's Sequoia suite of benchmarks and the ANL's workload. By using an instrumentation library built on top of MPI we collect and characterize the applications's messaging behavior: the type of communication patterns and primitives used, the amount of time spent for communication, the message sizes, the total amount of data exchanged, and the impact of collective primitives, through communication matrices we visualize the actual communication patterns to highlight symmetries and other relevant peculiarities. Our analysis exposes several similarities between the applications -- namely the utilization of common low-dimensional stencils, and the use of a small set of collective primitives, in particular all-reduces with small vectors. Overall, our study provides a better understanding of the communication characteristics of several important scientific applications and benchmarks.},
  keywords={},
  doi={10.1109/IPDPS.2011.249},
  ISSN={1530-2075},
  month={May},}
@INPROCEEDINGS{6009019,
  author={Fiala, David},
  booktitle={2011 IEEE International Symposium on Parallel and Distributed Processing Workshops and Phd Forum}, 
  title={Detection and Correction of Silent Data Corruption for Large-Scale High-Performance Computing}, 
  year={2011},
  volume={},
  number={},
  pages={2069-2072},
  abstract={Faults have become the norm rather than the exception for high-end computing on clusters with 10s/100s of thousands of cores, and this situation will only become more dire as we reach exascale computing. Exacerbating this situation, some of these faults will not be detected, manifesting themselves as silent errors that will corrupt memory while applications continue to operate but report incorrect results. This paper introduces RedMPI, an MPI library residing in the profiling layer of any standards-compliant MPI implementation. RedMPI is capable of both online detection and correction of soft errors that occur in MPI applications without requiring code changes to application source code. By providing redundancy, RedMPI is capable of transparently detecting corrupt messages from MPI processes that become faulted during execution. Furthermore, with triple redundancy RedMPI "votes'' out MPI messages of a faulted process by replacing corrupted results with corrected results from unfaulted processes. We present an evaluation of RedMPI on an assortment of applications to demonstrate the effectiveness and assess associated overheads. Fault injection experiments establish that RedMPI is not only capable of successfully detecting injected faults, but can also correct these faults while carrying a corrupted application to successful completion without propagating invalid data.},
  keywords={},
  doi={10.1109/IPDPS.2011.379},
  ISSN={1530-2075},
  month={May},}
@INPROCEEDINGS{6009024,
  author={Wu, Xing and Mueller, Frank and Pakin, Scott},
  booktitle={2011 IEEE International Symposium on Parallel and Distributed Processing Workshops and Phd Forum}, 
  title={Automatic Generation of Executable Communication Specifications from Parallel Applications}, 
  year={2011},
  volume={},
  number={},
  pages={2089-2092},
  abstract={Portable parallel benchmarks are widely used and highly effective for (a) the evaluation, analysis and procurement of high-performance computing (HPC) systems and (b) quantifying the potential benefits of porting applications for new hardware platforms. Yet, past techniques to synthetically parametrized hand-coded HPC benchmarks prove insufficient for today's rapidly-evolving scientific codes particularly when subject to multi-scale science modeling or when utilizing domain-specific libraries. To address these problems, this work contributes novel methods to automatically generate highly portable and customizable communication benchmarks from HPC applications. We utilize ScalaTrace, a lossless, yet scalable, parallel application tracing framework to collect selected aspects of the run-time behavior of HPC applications. We subsequently generate benchmarks with identical run-time behavior from the collected traces in the CONCEPTUAL language, a domain-specific language that enables the expression of sophisticated communication patterns using a rich and easily understandable grammar yet compiles to ordinary C+MPI. Experimental results demonstrate that the generated benchmarks are able to preserve the run-time behavior of the original applications. This ability to automatically generate performance-accurate benchmarks from parallel applications is novel and without any precedence, to our knowledge.},
  keywords={},
  doi={10.1109/IPDPS.2011.384},
  ISSN={1530-2075},
  month={May},}
@INPROCEEDINGS{6009011,
  author={Okorafor, Ekpe},
  booktitle={2011 IEEE International Symposium on Parallel and Distributed Processing Workshops and Phd Forum}, 
  title={A Fault-Tolerant High Performance Cloud Strategy for Scientific Computing}, 
  year={2011},
  volume={},
  number={},
  pages={1525-1532},
  abstract={Scientific computing often requires the availability of a massive number of computers for performing large scale experiments. Traditionally, high-performance computing solutions and installed facilities such as clusters and super computers have been employed to address these needs. Cloud computing provides scientists with a completely new model of utilizing the computing infrastructure with the ability to perform parallel computations using large pools of virtual machines (VMs). The infrastructure services (Infrastructure-as-a-service), provided by these cloud vendors, allow any user to provision a large number of compute instances. However, scientific computing is typically characterized by complex communication patterns and requires optimized runtimes. Today, VMs are manually instantiated, configured and maintained by cloud users. These coupled with the latency, crash and omission failures in service providers, results in an inefficient use of VMs, increased complexity in VM-management tasks, a reduction in the overall computation power and increased time for task completion. In this paper, a high performance cloud computing strategy is proposed that combines the adaptation of a parallel processing framework, such as the Message Passing Interface (MPI) and an efficient checkpoint infrastructure for VMs, enabling its effective use for scientific computing. By developing such a mechanism, we can achieve optimized runtimes comparable to native clusters, improve checkpoints with low interference on task execution and provide efficient task recovery. In addition, check pointing is used to minimize the cost and volatility of resource provisioning, while improving overall reliability. Analysis and simulations show that the proposed approach compares favorably with the native cluster MPI implementations.},
  keywords={},
  doi={10.1109/IPDPS.2011.306},
  ISSN={1530-2075},
  month={May},}
@INPROCEEDINGS{6009042,
  author={Schubert, Gerald and Hager, Georg and Fehske, Holger and Wellein, Gerhard},
  booktitle={2011 IEEE International Symposium on Parallel and Distributed Processing Workshops and Phd Forum}, 
  title={Parallel Sparse Matrix-Vector Multiplication as a Test Case for Hybrid MPI+OpenMP Programming}, 
  year={2011},
  volume={},
  number={},
  pages={1751-1758},
  abstract={We evaluate optimized parallel sparse matrix-vector operations for two representative application areas on widespread multicore-based cluster configurations. First the single-socket baseline performance is analyzed and modeled with respect to basic architectural properties of standard multicore chips. Going beyond the single node, parallel sparse matrix-vector operations often suffer from an unfavorable communication to computation ratio. Starting from the observation that nonblocking MPI is not able to hide communication cost using standard MPI implementations, we demonstrate that explicit overlap of communication and computation can be achieved by using a dedicated communication thread, which may run on a virtual core. We compare our approach to pure MPI and the widely used "vector-like'' hybrid programming strategy.},
  keywords={},
  doi={10.1109/IPDPS.2011.332},
  ISSN={1530-2075},
  month={May},}
@INPROCEEDINGS{6009014,
  author={Hursey, Joshua and Graham, Richard L.},
  booktitle={2011 IEEE International Symposium on Parallel and Distributed Processing Workshops and Phd Forum}, 
  title={Building a Fault Tolerant MPI Application: A Ring Communication Example}, 
  year={2011},
  volume={},
  number={},
  pages={1549-1556},
  abstract={Process failure is projected to become a normal event for many long running and scalable High Performance Computing (HPC) applications. As such many application developers are investigating Algorithm Based Fault Tolerance (ABFT) techniques to improve the efficiency of application recovery beyond what existing checkpoint/restart techniques alone can provide. Unfortunately for these application developers the libraries that their applications depend upon, like Message Passing Interface (MPI), do not have standardized fault tolerance semantics. This paper introduces the reader to a set of run-through stabilization semantics being developed by the MPI Forum's Fault Tolerance Working Group to support ABFT. Using a well-known ring communication program as the running example, this paper illustrates to application developers new to ABFT some of the issues that arise when designing a fault tolerant application. The ring program allows the paper to focus on the communication-level issues rather than the data preservation mechanisms covered by existing literature. This paper highlights a common set of issues that application developers must address in their design including program control management, duplicate message detection, termination detection, and testing. The discussion provides application developers new to ABFT with an introduction to both new interfaces becoming available, and a range of design issues that they will likely need to address regardless of their research domain.},
  keywords={},
  doi={10.1109/IPDPS.2011.308},
  ISSN={1530-2075},
  month={May},}
@INPROCEEDINGS{6009006,
  author={Biely, Martin and Robinson, Peter and Schmid, Ulrich},
  booktitle={2011 IEEE International Symposium on Parallel and Distributed Processing Workshops and Phd Forum}, 
  title={Solving k-Set Agreement with Stable Skeleton Graphs}, 
  year={2011},
  volume={},
  number={},
  pages={1488-1495},
  abstract={In this paper we consider the k-set agreement problem in distributed message-passing systems using a round-based approach: Both synchrony of communication and failures are captured just by means of the messages that arrive within a round, resulting in round-by-round communication graphs that can be characterized by simple communication predicates. We introduce the weak communication predicate Psrcs(k) and show that it is tight for k-set agreement, in the following sense: We (i) prove that there is no algorithm for solving (k-1)-set agreement in systems characterized by Psrcs(k), and (ii) present a novel distributed algorithm that achieves k-set agreement in runs where Psrcs(k) holds. Our algorithm uses local approximations of the stable skeleton graph, which reflects the underlying perpetual synchrony of a run. We prove that this approximation is correct in all runs, regardless of the communication predicate, and show that graph-theoretic properties of the stable skeleton graph can be used to solve k-set agreement if Psrcs(k) holds.},
  keywords={},
  doi={10.1109/IPDPS.2011.301},
  ISSN={1530-2075},
  month={May},}
@INPROCEEDINGS{6009005,
  author={Cappello, Franck},
  booktitle={2011 IEEE International Symposium on Parallel and Distributed Processing Workshops and Phd Forum}, 
  title={DPDNS Keynote}, 
  year={2011},
  volume={},
  number={},
  pages={1487-1487},
  abstract={Summary form only given. In this talk, we will explore some recent results concern ing the execution of MPI applications on unstable environments. We will show that by extracting the fundamental characteristics of HPC application, we can design new fault tolerance approaches surpassing existing approaches. In particular, we will present a characterization of HPC applications and the design of a new family of fault tolerance protocols mixing the benefit of coordinated checkpointing and message logging protocols.},
  keywords={},
  doi={10.1109/IPDPS.2011.410},
  ISSN={1530-2075},
  month={May},}
@INPROCEEDINGS{6009081,
  author={Sharma, Subodh and Gopalakrishnan, Ganesh},
  booktitle={2011 IEEE International Symposium on Parallel and Distributed Processing Workshops and Phd Forum}, 
  title={Efficient Verification Solutions for Message Passing Systems}, 
  year={2011},
  volume={},
  number={},
  pages={2026-2029},
  abstract={We examine the problem of automatically and efficiently verifying the absence of communication related bugs in message passing systems, specifically in programs written using Message Passing Interface (MPI) API. A typical debugging or testing tool will fail to achieve this goal because they do not provide any guarantee of coverage of non-deterministic communication matches in a message passing program. While dynamic verification tools do provide such a guarantee, they are quickly rendered useless when an interleaving explosion is witnessed. The general problem is difficult to solve, though we propose that specialized techniques can be developed that can work on top of dynamic verification schedulers thus making them more efficient. In this work, we provide point solutions to deal with the interleaving explosion. Specifically, we present algorithms that accomplish the following tasks: (i) identifying irrelevant message passing operations (Barriers) in MPI programs that add to the verification complexity and degrade application's performance and (ii) reducing sub-stantially the relevant set of interleavings using symmetry patterns, that needs to be explored for the detection of refusal deadlocks in MPI programs.},
  keywords={},
  doi={10.1109/IPDPS.2011.368},
  ISSN={1530-2075},
  month={May},}
@INPROCEEDINGS{6009079,
  author={Friedley, Andrew and Lumsdaine, Andrew},
  booktitle={2011 IEEE International Symposium on Parallel and Distributed Processing Workshops and Phd Forum}, 
  title={Communication Optimization Beyond MPI}, 
  year={2011},
  volume={},
  number={},
  pages={2018-2021},
  abstract={The Message Passing Interface (MPI) is the de-facto standard for parallel processing on high-performance computing systems. As a result, significant research effort has been spent on optimizing the performance of MPI implementations. However, MPI's specific semantics can limit performance when using modern networks with Remote DMA capabilities. We propose a compiler-assisted approach to optimization of MPI-based applications by transforming MPI calls to a one-sided (as opposed to message passing) communication model. In this paper we present a research plan for developing new optimizations using this approach, then show preliminary results with up to a 40% increase in bandwidth over MPI by using a simpler one-sided communication model.},
  keywords={},
  doi={10.1109/IPDPS.2011.366},
  ISSN={1530-2075},
  month={May},}
@INPROCEEDINGS{6009080,
  author={Moise, Izabela},
  booktitle={2011 IEEE International Symposium on Parallel and Distributed Processing Workshops and Phd Forum}, 
  title={Efficient Agreement Protocols in Asynchronous Distributed Systems}, 
  year={2011},
  volume={},
  number={},
  pages={2022-2025},
  abstract={In an asynchronous distributed system prone to crash failures and message omissions, providing efficient solutions to agreement problems is a key issue when designing fault tolerant applications. The problem of making a unique and ever lasting sequence of decisions is crucial as it lies at the heart of important fault-tolerant techniques. The state machine approach [1] illustrates this concern. In this particular example, replicas of a critical server need to agree on a sequence of incoming requests. Such a sequence is usually constructed by repeatedly calling a Consensus service. Consensus is recognized as one of the most fundamental problems in distributed computing. We consider the context of asynchronous distributed systems in which processes can fail by crashing. By definition, a correct process is a process that never crashes. A process that deviates from its execution specification is considered to be faulty. The classical specification of the Consensus problem [2] requires that each participant proposes an initial value and, despite failures, all the correct processes decide on a single value selected out of these proposals.},
  keywords={},
  doi={10.1109/IPDPS.2011.367},
  ISSN={1530-2075},
  month={May},}
@INPROCEEDINGS{6008818,
  author={Meyer, Jan C. and Elster, Anne C.},
  booktitle={2011 IEEE International Symposium on Parallel and Distributed Processing Workshops and Phd Forum}, 
  title={Optimized Barriers for Heterogeneous Systems Using MPI}, 
  year={2011},
  volume={},
  number={},
  pages={20-33},
  abstract={The heterogeneous communication characteristics of clustered SMP systems create great potential for optimizations which favor physical locality. This paper describes a novel technique for automating such optimizations, applied to barrier operations. Portability poses a challenge when optimizing for locality, as costs are bound to variations in platform topology. This challenge is addressed through representing both platform structure and barrier algorithms as input data, and altering the algorithm based on benchmark results which can be easily obtained from a given platform. Our resulting optimization technique is empirically tested on two modern clusters, up to eight dual quad-core nodes on one, and up to ten dual hex-core nodes on another. Included test results show that the method captures performance advantages on both systems without any explicit customization, and produces specialized barriers of superior performance to a topology-neutral implementation.},
  keywords={},
  doi={10.1109/IPDPS.2011.124},
  ISSN={1530-2075},
  month={May},}
@INPROCEEDINGS{6008825,
  author={Nukada, Akira and Takizawa, Hiroyuki and Matsuoka, Satoshi},
  booktitle={2011 IEEE International Symposium on Parallel and Distributed Processing Workshops and Phd Forum}, 
  title={NVCR: A Transparent Checkpoint-Restart Library for NVIDIA CUDA}, 
  year={2011},
  volume={},
  number={},
  pages={104-113},
  abstract={Today, CUDA is the de facto standard programming framework to exploit the computational power of graphics processing units (GPUs) to accelerate various kinds of applications. For efficient use of a large GPU-accelerated system, one important mechanism is checkpoint-restart that can be used not only to improve fault tolerance but also to optimize node/slot allocation by suspending a job on one node and migrating the job to another node. Although several checkpoint-restart implementations have been developed so far, they do not support CUDA applications or have some severe limitations for CUDA support. Hence, we present a checkpoint-restart library for CUDA that first deletes all CUDA resources before check pointing and then restores them right after check pointing. It is necessary to restore each memory chunk at the same memory address. To this end, we propose a novel technique that replays memory related API calls. The library supports both CUDA runtime API and CUDA driver API. Moreover, the library is transparent to applications, it is not necessary to recompile the applications for check pointing. This paper demonstrates that the proposed library can achieve checkpoint-restart of various applications at acceptable overheads, and the library also works for MPI applications such as HPL.},
  keywords={},
  doi={10.1109/IPDPS.2011.131},
  ISSN={1530-2075},
  month={May},}
@INPROCEEDINGS{6008844,
  author={Marathe, Aniruddha and Lowenthal, David K. and Gu, Zheng and Small, Matthew and Yuan, Xin},
  booktitle={2011 IEEE International Symposium on Parallel and Distributed Processing Workshops and Phd Forum}, 
  title={Profile Guided MPI Protocol Selection for Point-to-Point Communication Calls}, 
  year={2011},
  volume={},
  number={},
  pages={733-739},
  abstract={Improving communication performance is critical to achieving high performance in message-passing programs. Designing new, efficient protocols to realize point-to-point and collective communication operations has therefore been an active area of research. However, the best protocol for a given communication routine is both application and architecture specific. This paper contributes a new method of selection of the optimal protocol for a given point-to-point communication pair. Our technique analyzes the MPI communication call profile of an application and uses a computation and communication model we have developed to choose the proper protocol for each communication phase. We have applied our system to MPI applications such as CG, Sweep3D and Sparse Matrix multiplication, as well as synthetic applications. Our scheme yields an improvement in total execution time of up to 20% compared to MVAPICH2 and up to 3.2% compared to the best, highly optimized communication protocol for the real applications. Furthermore, experiments on the synthetic applications show that the savings can be much more pronounced.},
  keywords={},
  doi={10.1109/IPDPS.2011.215},
  ISSN={1530-2075},
  month={May},}
@INPROCEEDINGS{6012826,
  author={Mitchell, Christopher and Ahrens, James and Wang, Jun},
  booktitle={2011 IEEE International Parallel & Distributed Processing Symposium}, 
  title={VisIO: Enabling Interactive Visualization of Ultra-Scale, Time Series Data via High-Bandwidth Distributed I/O Systems}, 
  year={2011},
  volume={},
  number={},
  pages={68-79},
  abstract={Petascale simulations compute at resolutions ranging into billions of cells and write terabytes of data for visualization and analysis. Interactive visualization of this time series is a desired step before starting a new run. The I/O subsystem and associated network often are a significant impediment to interactive visualization of time-varying data, as they are not configured or provisioned to provide necessary I/O read rates. In this paper, we propose a new I/O library for visualization applications: VisIO. Visualization applications commonly use N-to-N reads within their parallel enabled readers which provides an incentive for a shared-nothing approach to I/O, similar to other data-intensive approaches such as Hadoop. However, unlike other data-intensive applications, visualization requires: (1) interactive performance for large data volumes, (2) compatibility with MPI and POSIX file system semantics for compatibility with existing infrastructure, and (3) use of existing file formats and their stipulated data partitioning rules. VisIO, provides a mechanism for using a non-POSIX distributed file system to provide linear scaling of I/O bandwidth. In addition, we introduce a novel scheduling algorithm that helps to co-locate visualization processes on nodes with the requested data. Testing using VisIO integrated into Para View was conducted using the Hadoop Distributed File System (HDFS) on TACC's Longhorn cluster. A representative dataset, VPIC, across 128 nodes showed a 64.4% read performance improvement compared to the provided Lustre installation. Also tested, was a dataset representing a global ocean salinity simulation that showed a 51.4% improvement in read performance over Lustre when using our VisIO system. VisIO, provides powerful high-performance I/O services to visualization applications, allowing for interactive performance with ultra-scale, time-series data.},
  keywords={},
  doi={10.1109/IPDPS.2011.17},
  ISSN={1530-2075},
  month={May},}
@INPROCEEDINGS{6012825,
  author={White III, J.B. and Dongarra, J.J.},
  booktitle={2011 IEEE International Parallel & Distributed Processing Symposium}, 
  title={Overlapping Computation and Communication for Advection on Hybrid Parallel Computers}, 
  year={2011},
  volume={},
  number={},
  pages={59-67},
  abstract={We describe computational experiments exploring the performance improvements from overlapping computation and communication on hybrid parallel computers. Our test case is explicit time integration of linear advection with constant uniform velocity in a three-dimensional periodic domain. The test systems include a Cray XT5, a Cray XE6, and two multicore Infiniband clusters with different generations of NVIDIA graphics processing units (GPUs). We describe results for Fortran implementations using various combinations of MPI, OpenMP, and CUDA, with and without overlap of computation and communication. We find that overlapping CPU computation, GPU computation, parallel communication, and CPU-GPU communication can provide performance improvements of more than a factor of two.},
  keywords={},
  doi={10.1109/IPDPS.2011.16},
  ISSN={1530-2075},
  month={May},}
@INPROCEEDINGS{6012833,
  author={Biswas, Susmit and Supinski, Bronis R. de and Schulz, Martin and Franklin, Diana and Sherwood, Timothy and Chong, Frederic T.},
  booktitle={2011 IEEE International Parallel & Distributed Processing Symposium}, 
  title={Exploiting Data Similarity to Reduce Memory Footprints}, 
  year={2011},
  volume={},
  number={},
  pages={152-163},
  abstract={Memory size has long limited large-scale applications on high-performance computing (HPC) systems. Since compute nodes frequently do not have swap space, physical memory often limits problem sizes. Increasing core counts per chip and power density constraints, which limit the number of DIMMs per node, have exacerbated this problem. Further, DRAM constitutes a significant portion of overall HPC system cost. Therefore, instead of adding more DRAM to the nodes, mechanisms to manage memory usage more efficiently -- preferably transparently -- could increase effective DRAM capacity and thus the benefit of multicore nodes for HPC systems. MPI application processes often exhibit significant data similarity. These data regions occupy multiple physical locations across the individual rank processes within a multicore node and thus offer a potential savings in memory capacity. These regions, primarily residing in heap, are dynamic, which makes them difficult to manage statically. Our novel memory allocation library, {\it SBLLmallocShort}, automatically identifies identical memory blocks and merges them into a single copy. Our implementation is transparent to the application and does not require any kernel modifications. Overall, we demonstrate that {\it SBLLmalloc} reduces the memory footprint of a range of MPI applications by $32.03\%$ on average and up to $60.87\%$. Further, {\it SBLLmalloc} supports problem sizes for IRS over $21.36\%$ larger than using standard memory management techniques, thus significantly increasing effective system size. Similarly, {\it SBLLmalloc} requires $43.75\%$ fewer nodes than standard memory management techniques to solve an AMG problem.},
  keywords={},
  doi={10.1109/IPDPS.2011.24},
  ISSN={1530-2075},
  month={May},}
@INPROCEEDINGS{6012844,
  author={Baker, Allison H. and Gamblin, Todd and Schulz, Martin and Yang, Ulrike Meier},
  booktitle={2011 IEEE International Parallel & Distributed Processing Symposium}, 
  title={Challenges of Scaling Algebraic Multigrid Across Modern Multicore Architectures}, 
  year={2011},
  volume={},
  number={},
  pages={275-286},
  abstract={Algebraic multigrid (AMG) is a popular solver for large-scale scientific computing and an essential component of many simulation codes. AMG has shown to be extremely efficient on distributed-memory architectures. However, when executed on modern multicore architectures, we face new challenges that can significantly deteriorate AMG's performance. We examine its performance and scalability on three disparate multicore architectures: a cluster with four AMD Opteron Quad-core processors per node (Hera), a Cray XT5 with two AMD Opteron Hex-core processors per node (Jaguar), and an IBM Blue Gene/P system with a single Quad-core processor (Intrepid). We discuss our experiences on these platforms and present results using both an MPI-only and a hybrid MPI/OpenMP model. We also discuss a set of techniques that helped to overcome the associated problems, including thread and process pinning and correct memory associations.},
  keywords={},
  doi={10.1109/IPDPS.2011.35},
  ISSN={1530-2075},
  month={May},}
@INPROCEEDINGS{6012907,
  author={Guermouche, Amina and Ropars, Thomas and Brunet, Elisabeth and Snir, Marc and Cappello, Franck},
  booktitle={2011 IEEE International Parallel & Distributed Processing Symposium}, 
  title={Uncoordinated Checkpointing Without Domino Effect for Send-Deterministic MPI Applications}, 
  year={2011},
  volume={},
  number={},
  pages={989-1000},
  abstract={As reported by many recent studies, the mean time between failures of future post-petascale supercomputers is likely to reduce, compared to the current situation. The most popular fault tolerance approach for MPI applications on HPC Platforms relies on coordinated check pointing which raises two major issues: a) global restart wastes energy since all processes are forced to rollback even in the case of a single failure, b) checkpoint coordination may slow down the application execution because of congestions on I/O resources. Alternative approaches based on uncoordinated check pointing and message logging require logging all messages, imposing a high memory/storage occupation and a significant overhead on communications. It has recently been observed that many MPI HPC applications are send-deterministic, allowing to design new fault tolerance protocols. In this paper, we propose an uncoordinated check pointing protocol for send-deterministic MPI HPC applications that (i) logs only a subset of the application messages and (ii) does not require to restart systematically all processes when a failure occurs. We first describe our protocol and prove its correctness. Through experimental evaluations, we show that its implementation in MPICH2 has a negligible overhead on application performance. Then we perform a quantitative evaluation of the properties of our protocol using the NAS Benchmarks. Using a clustering approach, we demonstrate that this protocol actually succeeds to combine the two expected properties: a) it logs only a small fraction of the messages and b) it reduces by a factor approaching 2 the average number of processes to rollback compared to coordinated check pointing.},
  keywords={},
  doi={10.1109/IPDPS.2011.95},
  ISSN={1530-2075},
  month={May},}
@INPROCEEDINGS{6012895,
  author={Takizawa, Hiroyuki and Koyama, Kentaro and Sato, Katsuto and Komatsu, Kazuhiko and Kobayashi, Hiroaki},
  booktitle={2011 IEEE International Parallel & Distributed Processing Symposium}, 
  title={CheCL: Transparent Checkpointing and Process Migration of OpenCL Applications}, 
  year={2011},
  volume={},
  number={},
  pages={864-876},
  abstract={In this paper, we propose a new transparent checkpoint/restart (CPR) tool, named CheCL, for high-performance and dependable GPU computing. CheCL can perform CPR on an OpenCL application program without any modification and recompilation of its code. A conventional check pointing system fails to checkpoint a process if the process uses OpenCL. Therefore, in CheCL, every API call is forwarded to another process called an API proxy, and the API proxy invokes the API function, two processes, an application process and an API proxy, are launched for an OpenCL application. In this case, as the application process is not an OpenCL process but a standard process, it can be safely check pointed. While CheCL intercepts all API calls, it records the information necessary for restoring OpenCL objects. The application process does not hold any OpenCL handles, but CheCL handles to keep such information. Those handles are automatically converted to OpenCL handles and then passed to API functions. Upon restart, OpenCL objects are automatically restored based on the recorded information. This paper demonstrates the feasibility of transparent check pointing of OpenCL programs including MPI applications, and quantitatively evaluates the runtime overheads. It is also discussed that CheCL can enable process migration of OpenCL applications among distinct nodes, and among different kinds of compute devices such as a CPU and a GPU.},
  keywords={},
  doi={10.1109/IPDPS.2011.85},
  ISSN={1530-2075},
  month={May},}
@INPROCEEDINGS{6012878,
  author={Clauss, Pierre-Nicolas and Stillwell, Mark and Genaud, Stephane and Suter, Frederic and Casanova, Henri and Quinson, Martin},
  booktitle={2011 IEEE International Parallel & Distributed Processing Symposium}, 
  title={Single Node On-Line Simulation of MPI Applications with SMPI}, 
  year={2011},
  volume={},
  number={},
  pages={664-675},
  abstract={Simulation is a popular approach for predicting the performance of MPI applications for platforms that are not at one's disposal. It is also a way to teach the principles of parallel programming and high-performance computing to students without access to a parallel computer. In this work we present SMPI, a simulator for MPI applications that uses on-line simulation, i.e., the application is executed but part of the execution takes place within a simulation component. SMPI simulations account for network contention in a fast and scalable manner. SMPI also implements an original and validated piece-wise linear model for data transfer times between cluster nodes. Finally SMPI simulations of large-scale applications on large-scale platforms can be executed on a single node thanks to techniques to reduce the simulation's compute time and memory footprint. These contributions are validated via a large set of experiments in which SMPI is compared to popular MPI implementations with a view to assess its accuracy, scalability, and speed.},
  keywords={},
  doi={10.1109/IPDPS.2011.69},
  ISSN={1530-2075},
  month={May},}
@INPROCEEDINGS{6012917,
  author={Barik, Rajkishore and Zhao, Jisheng and Grove, David and Peshansky, Igor and Budimlic, Zoran and Sarkar, Vivek},
  booktitle={2011 IEEE International Parallel & Distributed Processing Symposium}, 
  title={Communication Optimizations for Distributed-Memory X10 Programs}, 
  year={2011},
  volume={},
  number={},
  pages={1101-1113},
  abstract={X10 is a new object-oriented PGAS (Partitioned Global Address Space) programming language with support for distributed asynchronous dynamic parallelism that goes beyond past SPMD message-passing models such as MPI and SPMD PGAS models such as UPC and Co-Array Fortran. The concurrency constructs in X10 make it possible to express complex computation and communication structures with higher productivity than other distributed-memory programming models. However, this productivity often comes at the cost of high performance overhead when the language is used in its full generality. This paper introduces high-level compiler optimizations and transformations to reduce communication and synchronization overheads in distributed-memory implementations of X10 programs. Specifically, we focus on locality optimizations such as scalar replacement and task localization, combined with supporting transformations such as loop distribution, scalar expansion, loop tiling, and loop splitting. We have completed a prototype implementation of these high-level optimizations, and performed a performance evaluation that shows significant improvements in performance, scalability, communication volume and number of tasks. We evaluated the communication optimizations on three platforms: a 128-node Blue Gene/P cluster, a 32-node Nehalem cluster, and a 16-node Power7 cluster. On the Blue Gene/P cluster, we observed a maximum performance improvement of 31.46x relative to the unoptimized case (for the MolDyn benchmark). On the Nehalem cluster, we observed a maximum performance improvement of 3.01x (for the NQueens benchmark) and on the Power7 cluster, we observed a maximum performance improvement of 2.73x (for the MolDyn benchmark). In addition, there was no case in which the optimized code was slower than the unoptimized case. We also believe that the optimizations presented in this paper will be necessary for any high-productivity PGAS language based on modern object-oriented principles, that is designed for execution on future Extreme Scale systems that place a high premium on locality improvement for performance and energy efficiency.},
  keywords={},
  doi={10.1109/IPDPS.2011.105},
  ISSN={1530-2075},
  month={May},}
@INPROCEEDINGS{6012916,
  author={Jin, Guohua and Mellor-Crummey, John and Adhianto, Laksono and Scherer III, William N. and Yang, Chaoran},
  booktitle={2011 IEEE International Parallel & Distributed Processing Symposium}, 
  title={Implementation and Performance Evaluation of the HPC Challenge Benchmarks in Coarray Fortran 2.0}, 
  year={2011},
  volume={},
  number={},
  pages={1089-1100},
  abstract={Today's largest supercomputers have over two hundred thousand CPU cores and even larger systems are under development. Typically, these systems are programmed using message passing. Over the past decade, there has been considerable interest in developing simpler and more expressive programming models for them. Partitioned global address space (PGAS) languages are viewed as perhaps the most promising alternative. In this paper, we report on our experience developing a set of PGAS extensions to Fortran that we call Co array Fortran 2.0 (CAF 2.0). Our design for CAF 2.0 goes well beyond the original 1998 design of Co array Fortran (CAF) by Numrich and Reid. CAF 2.0 includes language support for many features including teams, collective communication, asynchronous communication, function shipping, and synchronization. We describe the implementation of these features and our experiences using them to implement the High Performance Computing Challenge (HPCC) benchmarks, including High Performance Linpack (HPL), Random Access, Fast Fourier Transform (FFT), and STREAM triad. On 4096 CPU cores of a Cray XT with 2.3 GHz single socket quad-core Opteron processors, we achieved 18.3 TFLOP/s with HPL, 2.01 GUP/s with Random Access, 125 GFLOP/s with FFT, and a bandwidth of 8.73 TByte/s with STREAM triad. we call Co array Fortran 2.0 (CAF 2.0). Our design for CAF 2.0 goes well beyond the original 1998 design of Coarray Fortran (CAF) by Numrich and Reid. CAF 2.0 includes language support for many features including teams, collective communication, asynchronous communication, function shipping, and synchronization. We describe the implementation of these features and our experiences using them to implement the High Performance Computing Challenge (HPCC) benchmarks, including High Performance Linpack (HPL), Random Access, Fast Fourier Transform (FFT), and STREAM triad. On 4096 CPU cores of a Cray XT with 2.3 GHz single socket quad-core Opteron processors, we achieved 18.3 TFLOP/s with HPL, 2.01 GUP/s with Random Access, 125 GFLOP/s with FFT, and a bandwidth of 8.73 TByte/s with STREAM triad.},
  keywords={},
  doi={10.1109/IPDPS.2011.104},
  ISSN={1530-2075},
  month={May},}
@ARTICLE{6025245,
  author={Tehrani, Arash Saber and Dimakis, Alexandros G. and Neely, Michael J.},
  journal={IEEE Journal of Selected Topics in Signal Processing}, 
  title={SigSag: Iterative Detection Through Soft Message-Passing}, 
  year={2011},
  volume={5},
  number={8},
  pages={1512-1523},
  abstract={The multiple-access framework of ZigZag decoding (Gollakota and Katabi 2008) is a useful technique for combating interference via multiple repeated transmissions, and is known to be compatible with distributed random access protocols. However, in the presence of noise this type of decoding can magnify errors, particularly when packet sizes are large. We show that ZigZag decoding can be seen as an instance of belief propagation in the high signal-to-noise ratio (SNR) limit. Building on this observation, we present a simple soft-decoding version, called SigSag, that improves performance. We show that for two users, collisions result in a cycle-free factor graph that can be optimally decoded via belief propagation. For collisions between more than two users, we show that if a simple bit-permutation is used then the graph is locally tree-like with high probability, and hence belief propagation is near-optimal. Further, we introduce the joint channel-collision decoding which decodes the collided packets while the packets are coded by an LDPC code. Through simulations we show that our scheme performs better than coordinated collision-free time division multiple access (TDMA) and the ZigZag decoder. Furthermore, we investigate the performance of the joint channel-collision decoder in different scenarios and show that it performs better than TDMA and ZigZag decoder accompanied by sum-product decoding.},
  keywords={},
  doi={10.1109/JSTSP.2011.2169042},
  ISSN={1941-0484},
  month={Dec},}
@INPROCEEDINGS{6030585,
  author={Maghayreh, E. Al},
  booktitle={2011 24th Canadian Conference on Electrical and Computer Engineering(CCECE)}, 
  title={Block-based atomicity to simplify the verification of distributed applications}, 
  year={2011},
  volume={},
  number={},
  pages={000887-000891},
  abstract={Distributed applications are very hard to write and verify. Even with extensive testing and debugging, errors may persist. A distributed application can be viewed as a collection of processes that execute a number of atomic actions. The notion of atomicity can be employed to significantly reduce the state space to be considered in verification. Moreover, atomicity violations in a run typically indicate the presence of program bugs. In this paper, we exploit the notion of atomicity of a code block to simplify the debugging and verification of distributed applications. The notion of an atomic action has been formally defined and an algorithm to detect atomicity violations has been developed.},
  keywords={},
  doi={10.1109/CCECE.2011.6030585},
  ISSN={0840-7789},
  month={May},}
@INPROCEEDINGS{6033008,
  author={Ha, Viet Hai and Renault, Éric},
  booktitle={Proceedings of 2011 IEEE Pacific Rim Conference on Communications, Computers and Signal Processing}, 
  title={Design and performance analysis of CAPE based on discontinuous incremental checkpoints}, 
  year={2011},
  volume={},
  number={},
  pages={862-867},
  abstract={Checkpointing Aided Parallel Execution (CAPE) is a paradigm using checkpointing technique to distribute sequential programs equipped with OpenMP directives in distributed systems. In its first prototype, the use of a complete checkpointer strongly decreased global performance. This paper shows how the performance of the CAPE paradigm have been improved using discontinuous incremental checkpointing and provide an in-depth analysis of this performance.},
  keywords={},
  doi={10.1109/PACRIM.2011.6033008},
  ISSN={2154-5952},
  month={Aug},}
@INPROCEEDINGS{6033905,
  author={Wymeersch, Henk and Penna, Federico and Savić, Vladimir},
  booktitle={2011 IEEE International Symposium on Information Theory Proceedings}, 
  title={Uniformly reweighted belief propagation: A factor graph approach}, 
  year={2011},
  volume={},
  number={},
  pages={2000-2004},
  abstract={Tree-reweighted belief propagation is a message passing method that has certain advantages compared to traditional belief propagation (BP). However, it fails to outperform BP in a consistent manner, does not lend itself well to distributed implementation, and has not been applied to distributions with higher-order interactions. We propose a method called uniformly-reweighted belief propagation that mitigates these drawbacks. After having shown in previous works that this method can sub-stantially outperform BP in distributed inference with pairwise interaction models, in this paper we extend it to higher-order interactions and apply it to LDPC decoding, leading performance gains over BP.},
  keywords={},
  doi={10.1109/ISIT.2011.6033905},
  ISSN={2157-8117},
  month={July},}
@INPROCEEDINGS{6033855,
  author={Ye Wang and Ishwar, Prakash},
  booktitle={2011 IEEE International Symposium on Information Theory Proceedings}, 
  title={On unconditionally secure multi-party sampling from scratch1}, 
  year={2011},
  volume={},
  number={},
  pages={1782-1786},
  abstract={In the problem of secure multi-party sampling, n parties wish to securely sample an n-variate joint distribution, with each party receiving a sample of one of the correlated variables. The objective is to correctly produce the samples using a distributed message passing protocol, while maintaining privacy against a coalition of passively cheating parties. In the two-party case, we fully characterize the joint distributions that can be securely sampled under perfect correctness and privacy requirements as well as under weakened correctness and privacy requirements. Furthermore, we show that the distributions that can be securely sampled can be produced with a protocol that only uses one round of unidirectional communication. For the n-party case, any distribution can be securely sampled with privacy against a strict minority coalition, due to well-known results in secure multi-party computation. However, when privacy against a majority coalition is required, not all distributions can be securely sampled. We give necessary conditions and sufficient conditions for distributions that can be securely sampled. However, the exact characterization of the distributions that can be securely sampled remains open.},
  keywords={},
  doi={10.1109/ISIT.2011.6033855},
  ISSN={2157-8117},
  month={July},}
@ARTICLE{6034757,
  author={Zhang, Fan and Pfister, Henry D.},
  journal={IEEE Transactions on Information Theory}, 
  title={Analysis of Verification-Based Decoding on the $q$-ary Symmetric Channel for Large $q$ }, 
  year={2011},
  volume={57},
  number={10},
  pages={6754-6770},
  abstract={A new verification-based message-passing decoder for low-density parity-check (LDPC) codes is introduced and analyzed for the q-ary symmetric channel (q-SC). Rather than passing messages consisting of symbol probabilities, this decoder passes lists of possible symbols and marks some lists as verified. The density evolution (DE) equations for this decoder are derived and used to compute decoding thresholds. If the maximum list size is unbounded, then one finds that any capacity-achieving LDPC code for the binary erasure channel can be used to achieve capacity on the q -SC for large q. The decoding thresholds are also computed via DE for the case where each list is truncated to satisfy a maximum list-size constraint. Simulation results are also presented to confirm the DE results. During the simulations, we observed differences between two verification-based decoding algorithms, introduced by Luby and Mitzenmacher, that were implicitly assumed to be identical. In this paper, the node-based algorithms are evaluated via analysis and simulation. The probability of false verification (FV) is also considered and techniques are discussed to mitigate the FV. Optimization of the degree distribution is also used to improve the threshold for a fixed maximum list size. Finally, the proposed algorithm is compared with a variety of other algorithms using both density evolution thresholds and simulation results.},
  keywords={},
  doi={10.1109/TIT.2011.2165813},
  ISSN={1557-9654},
  month={Oct},}
@INPROCEEDINGS{6034972,
  author={Gibbs, Ivan and Ghazaleh, Husam and Dascalu, Sergiu},
  booktitle={2011 9th IEEE International Conference on Industrial Informatics}, 
  title={Message adaptor code generation}, 
  year={2011},
  volume={},
  number={},
  pages={676-681},
  abstract={This paper documents the design of a tool to create protocol adaptors. With the current emphasis in software engineering on using common off the shelf components, there are increasing interface mismatches. In addition to this, there is constant pressure to speed up the development process. And as the prevalence of distributed applications raises we are seeing an increase in the passing of messages among the components of a software system. Wrappers need to be written to deal with these protocol mismatches among different components. The tool documented herein allows developers to more easily create an adaptor component, which takes the place of a wrapper. This tool is meant to be used by developers to speed up the adaptor creation process. Automated checks are also included in the application.},
  keywords={},
  doi={10.1109/INDIN.2011.6034972},
  ISSN={2378-363X},
  month={July},}
@INPROCEEDINGS{6037266,
  author={Tso-Cho Chen},
  booktitle={Proceedings of 2011 Cross Strait Quad-Regional Radio Science and Wireless Technology Conference}, 
  title={Adaptive decoding of LDPC codes based on cross-entropy}, 
  year={2011},
  volume={2},
  number={},
  pages={1756-1760},
  abstract={An adaptive decoding scheme for low-density parity-check (LDPC) codes is proposed for accelerating the convergence of message-passing algorithms. The evolution of adaptive weighting factor with the number of decoding iterations and stopping criterion are based on the cross-entropy between two consecutive a posteriori probabilities distribution of the soft output of decoder. Information-theoretic support and extensive simulations are provided to demonstrate the efficiency of the proposed algorithm for LDPC decoding. The proposed adaptive decoding algorithm can reduce significantly the average number of iterations of decoder while having a comparable or even better performance than conventional message-passing algorithms.},
  keywords={},
  doi={10.1109/CSQRWC.2011.6037266},
  ISSN={},
  month={July},}
@INPROCEEDINGS{6041536,
  author={Vishnu, Abhinav and ten Bruggencate, Monika and Olson, Ryan},
  booktitle={2011 IEEE 19th Annual Symposium on High Performance Interconnects}, 
  title={Evaluating the Potential of Cray Gemini Interconnect for PGAS Communication Runtime Systems}, 
  year={2011},
  volume={},
  number={},
  pages={70-77},
  abstract={The Cray Gemini Interconnect has been recently introduced as the next generation network for building scalable multi-petascale supercomputers. The Cray XE6 systems, which use the Gemini Interconnect are becoming available with Message Passing Interface (MPI) and Partitioned Global Address Space (PGAS) Models such as as Global Arrays, Unified Parallel C, Co-Array Fortran and Cascade High Performance Language. These PGAS models use one-sided communication runtime systems such as MPI-Remote Memory Access, Aggregate Remote Memory Copy Interface and proprietary communication runtime systems. The primary objective of our work is to study the potential of Cray Gemini Interconnect by designing application specific micro-benchmarks using the DMAPP user space library. We design micro-benchmarks to study the performance of simple communication primitives and application specific micro-benchmarks to understand the behavior of Gemini Interconnect at scale. In our experiments, the Gemini Interconnect can achieve a peak bandwidth of 6911 MB/s and a latency of 1μs for get communication primitive. Scalability tests for atomic memory operations and shift communication operation up to 65536 processes show the efficacy of the Gemini Interconnect.},
  keywords={},
  doi={10.1109/HOTI.2011.19},
  ISSN={2332-5569},
  month={Aug},}
@INPROCEEDINGS{6047345,
  author={Al-Jarro, Ahmed and Bağci, Hakan},
  booktitle={CEM'11 Computational Electromagnetics International Workshop}, 
  title={Hybrid MPI/OpenMP parallelization of the explicit Volterra integral equation solver for multi-core computer architectures}, 
  year={2011},
  volume={},
  number={},
  pages={128-131},
  abstract={A hybrid MPI/OpenMP scheme for efficiently parallelizing the explicit marching-on-in-time (MOT)-based solution of the time-domain volume (Volterra) integral equation (TD-VIE) is presented. The proposed scheme equally distributes tested field values and operations pertinent to the computation of tested fields among the nodes using the MPI standard; while the source field values are stored in all nodes. Within each node, OpenMP standard is used to further accelerate the computation of the tested fields. Numerical results demonstrate that the proposed parallelization scheme scales well for problems involving three million or more spatial discretization elements.},
  keywords={},
  doi={10.1109/CEM.2011.6047345},
  ISSN={},
  month={Aug},}
@INPROCEEDINGS{6046521,
  author={Stefanski, T. P. and Chavannes, N. and Kuster, N.},
  booktitle={2011 International Conference on Electromagnetics in Advanced Applications}, 
  title={Hybrid OpenCL-MPI parallelization of the FDTD method}, 
  year={2011},
  volume={},
  number={},
  pages={1201-1204},
  abstract={This paper presents preliminary evaluation of the hybrid parallelization of the Finite-Difference Time-Domain (FDTD) method based on Open Computing Language (OpenCL) and the Message Passing Interface (MPI). Due to the portability of OpenCL, developed code targets not only distributed shared memory computer clusters based on multi-core central processing units (CPUs), but also clusters accelerated by graphics processing units (GPUs). The computational domain is decomposed along the slowest direction, and electromagnetic field boundary data is shared between neighboring subdomains using either OpenCL or MPI communication. The communication overhead between GPUs is proportional to the area of the boundary and represents the rate-limiting step of the method. This paper subsequently shows results of numerical tests aimed at evaluation of the hybrid OpenCL-MPI FDTD solver in electromagnetic simulations.},
  keywords={},
  doi={10.1109/ICEAA.2011.6046521},
  ISSN={},
  month={Sep.},}

@INPROCEEDINGS{6047253,
  author={Desprez, Frederic and Markomanolis, George S. and Quinson, Martin and Suter, Frederic},
  booktitle={2011 40th International Conference on Parallel Processing Workshops}, 
  title={Assessing the Performance of MPI Applications through Time-Independent Trace Replay}, 
  year={2011},
  volume={},
  number={},
  pages={467-476},
  abstract={Simulation is a popular approach to obtain objective performance indicators platforms that are not at one's disposal. It may help the dimensioning of compute clusters in large computing centers. In this work we present a framework for the off-line simulation of MPI applications. Its main originality with regard to the literature is to rely on time-independent execution traces. This allows us to completely decouple the acquisition process from the actual replay of the traces in a simulation context. Then we are able to acquire traces for large application instances without being limited to an execution on a single compute cluster. Finally our framework is built on top of a scalable, fast, and validated simulation kernel. In this paper, we introduce the used time-independent trace format, investigate several acquisition strategies, detail the developed trace replay tool, and assess the quality of our simulation framework in terms of accuracy, acquisition time, simulation time, and trace size.},
  keywords={},
  doi={10.1109/ICPPW.2011.33},
  ISSN={2332-5690},
  month={Sep.},}
@INPROCEEDINGS{6047312,
  author={Lu, Xiaoyi and Wang, Bing and Zha, Li and Xu, Zhiwei},
  booktitle={2011 40th International Conference on Parallel Processing Workshops}, 
  title={Can MPI Benefit Hadoop and MapReduce Applications?}, 
  year={2011},
  volume={},
  number={},
  pages={371-379},
  abstract={The Message Passing Interface (MPI) standard and its implementations (such as MPICH and OpenMPI) have been widely used in the high-performance computing area to provide an efficient communication infrastructure. This paper investigates whether MPI can be adapted to the data intensive computing area to substantially speed up Hadoop and MapReduce applications, by reducing communication overheads. Three specific issues are studied. First, is the potential for reducing communication overheads significant, if MPI is used? Second, what are the main technical challenges to adapt MPI to Hadoop? Third, what are the minimal extensions to the MPI standard that can help alleviate the challenges while promise to significantly improve performance? To answer the first question, we identify important and basic communication primitives in both MPI and Hadoop, and make fair comparisons of their performance through experiments. The results show that the potential for improvement could be high. To answer the second and the third questions, we analyze the Hadoop code base to identify communication related programmers' needs. Furthermore, we propose a minimal interface extension to the MPI standard (only one pair of library calls are added), which capture the key-value pair nature commonly found in data intensive computing. This extension is implemented in a prototype library called MPI-D. Benchmark tests based on simulation show that Hadoop augmented with MPI-D could significantly speed up MapReduce application performance.},
  keywords={},
  doi={10.1109/ICPPW.2011.56},
  ISSN={2332-5690},
  month={Sep.},}
@INPROCEEDINGS{6047908,
  author={Brăescu, Florin Cătălin and Ferariu, Lavinia and Nacu, Andrei},
  booktitle={2011 IEEE 7th International Conference on Intelligent Computer Communication and Processing}, 
  title={OSEK-based gateway algorithm for multi-domain CAN systems}, 
  year={2011},
  volume={},
  number={},
  pages={423-428},
  abstract={The paper presents a new gateway algorithm designed for multi-domain Controller Area Network (CAN) systems which require to exchange large amount of data between numerous CAN units. The approach is compliant with any hierarchical CAN based distributed architecture, being tailored to efficiently manage CAN domains interconnected by gateways. The communication topologies are encrypted as graphs, aiming a flexible further utilization, increased scalability and a reduce memory consumption. For every handled CAN message, the gateways are enabled to provide a dynamic determination of the fastest available path and to correct buses overloading by appropriate message routing. The gateway algorithm exploits the OSEK event driven scheduling algorithm with static priorities to handle the necessary communication tasks. As consequence, the proposed approach provides increased responsiveness, as well as a good traffic balance between the CAN domains, without the need of transmitting additional messages, as demonstrated on two study cases involving distributed architectures of different complexity orders.},
  keywords={},
  doi={10.1109/ICCP.2011.6047908},
  ISSN={},
  month={Aug},}
@INPROCEEDINGS{6057796,
  author={Wei, Xianmin},
  booktitle={2011 International Conference on Electrical and Control Engineering}, 
  title={Research and design of subscription / publishing system based on message middleware}, 
  year={2011},
  volume={},
  number={},
  pages={3091-3094},
  abstract={As to limitations of traditional subscription/publishing system based on message middleware, this paper performed a series of improvements for subscription / distribution system based on message middleware, and in detail introduced design ideas and implementation methods of improving the system. This system test is carried out simulation experimental environment, test results show the advantage is more obvious.},
  keywords={},
  doi={10.1109/ICECENG.2011.6057796},
  ISSN={},
  month={Sep.},}
@INPROCEEDINGS{6058742,
  author={McGoldrick, Michael},
  booktitle={2011 IEEE AUTOTESTCON}, 
  title={The impact of test instrumentation with distributed processing capabilities on test program set (TPS) architecture and development}, 
  year={2011},
  volume={},
  number={},
  pages={321-327},
  abstract={Modern digital interconnection methods have placed significant computational demands on computers controlling test systems, and adding dedicated computing resources for high performance digital test instrumentation to the test system can help meet these demands. This paper examines the impact of these additional computing resources on the design of a TPS, and proposes a software framework to assist developers in creating TPSs for multi-computer environments.},
  keywords={},
  doi={10.1109/AUTEST.2011.6058742},
  ISSN={1558-4550},
  month={Sep.},}
@INPROCEEDINGS{6061049,
  author={Gschwandtner, Philipp and Fahringer, Thomas and Prodan, Radu},
  booktitle={2011 IEEE International Conference on Cluster Computing}, 
  title={Performance Analysis and Benchmarking of the Intel SCC}, 
  year={2011},
  volume={},
  number={},
  pages={139-149},
  abstract={Over the past years there has been a steady change in CPU design towards both many-core processors and power-aware hardware architectures. These two trends are combined in the Intel Single-chip Cloud Computer (SCC), an experimental prototype with 48 Pentium cores created by Intel Labs. The SCC is a highly configurable many-core chip which provides unique opportunities to optimize run time, communication and memory access as well as power/energy consumption of parallel programs. The aim of this paper is to characterize the performance behavior of the chip with various power settings, mappings of processes/cores to memory controllers, etc through benchmarking. Analytical models are used to verify and interpret the results. Conclusions drawn from our benchmark outcomes are that data exchange based on message passing is faster than shared memory data exchange. Contrary to popular belief, lowest energy consumption is not achieved for the fastest execution time. Furthermore in order to improve the memory access behavior one should increase the clock frequency of both, mesh network and memory controllers. In general, the results of our investigations can be used to analyze the effect of power settings and architecture properties on the performance and energy consumption of parallel programs as well as assist in choosing appropriate settings for specific workloads.},
  keywords={},
  doi={10.1109/CLUSTER.2011.24},
  ISSN={2168-9253},
  month={Sep.},}
@INPROCEEDINGS{6063009,
  author={Saini, Subhash and Mehrotra, Piyush and Taylor, Kenichi and Aftosmis, Michael and Biswas, Rupak},
  booktitle={2011 IEEE International Conference on High Performance Computing and Communications}, 
  title={Performance Analysis of CFD Application Cart3D Using MPInside and Performance Monitor Unit Data on Nehalem and Westmere Based Supercomputers}, 
  year={2011},
  volume={},
  number={},
  pages={331-338},
  abstract={Cart3D is a computational fluid dynamics (CFD) application aimed at conceptual and preliminary design of aerospace vehicles with complex geometries. It is widely used by design engineers at NASA, Department of Defense and aerospace companies in the USA. We present detailed performance analysis of Cart3D using two tools SGI MPInside and op_scope that collects hardware counter data from Intel Performance Monitoring Unit (PMU) on supercomputers based on Nehalem micro-architecture. Using these tools, we have done dynamic profiling of Cart3D (compute time, communication time and I/O time), along with dynamic profiling of MPI functions (MPI_Sendrecv, MPI_Bcast, MPI_Isend, MPI_Irecv, MPI_Allreduce, MPI_Barrier, etc.) with respect to message size of each rank and time consumed by each function. MPI communication is further analyzed by studying the performance of MPI functions used in this application as a function of message size and number of cores. Using these tools we have also studied efficiency of the processor to measure its effective utilization, efficiency of the floating-point units, percentage of vectorization and percentage of data coming from L2 cache, L3 cache, and main memory. This study was performed on two computing sub-systems based on quad-core Nehalem-EP and hex-core West mere-EP processors that are part of Pleiades an SGI Altix ICE at NASA Ames Research Center.},
  keywords={},
  doi={10.1109/HPCC.2011.50},
  ISSN={},
  month={Sep.},}
@INPROCEEDINGS{6063006,
  author={Canillas, J. Martinez and Wong, A. and Rexachs, D. and Luque, E.},
  booktitle={2011 IEEE International Conference on High Performance Computing and Communications}, 
  title={Including the Workload Effect in the Parallel Program Signature}, 
  year={2011},
  volume={},
  number={},
  pages={304-311},
  abstract={Performance prediction and application behavior modeling have been the subject of extensive research that aims to estimate applications performance with acceptable precision. In this paper we present a novel approach to model the behavior of message passing parallel applications. There are many dimensions to consider while predicting a deterministic application behavior. Two dimensions that affect an application performance are the computational resources available and the size of its input data used in the computation. Based on the concept of signatures, we are able to build a model that allows us to predict applications execution time in different systems with variable input data size within a predefined range. Our approach generates signatures, which consist of the most relevant parts of an application (phases). Executing these phases for different workloads partially defines a program's behavior function. By using regression analysis we are able to generalize this behavior function to predict an application performance in a target system with any input data size within a predefined range. We explain our methodology and in order to validate the proposal, we present results using a synthetic program and well-known applications. We were able to estimate the total execution time for a input data size range with an average error of 4 % executing, at most, three signatures that represent less than the 10 % of the total application execution time.},
  keywords={},
  doi={10.1109/HPCC.2011.47},
  ISSN={},
  month={Sep.},}
@INPROCEEDINGS{6063016,
  author={Rivera, Orlando and Furlinger, Karl},
  booktitle={2011 IEEE International Conference on High Performance Computing and Communications}, 
  title={Parallel Aspects of OpenFOAM with Large Eddy Simulations}, 
  year={2011},
  volume={},
  number={},
  pages={389-396},
  abstract={Open FOAM is a mainstream open-source frame-work for the simulation in several areas of CFD and engineering whose syntax is a high level representation of the mathematical notation of physical models, internal details like parallelization, tensor algebra, and mesh manipulation are hidden and automatically integrated. We used the back-facing step geometry with Large Eddy Simulations and semi-implicit methods to investigate the scalability and important MPI characteristics of Open FOAM. Moreover, this geometry provides a configuration with representative features found in current engineering and HPC problems. The algebraic multigrid solver, for example, was found to be a very powerful and fast iterative solver for the solution of PDEs compared to the BiGC during the weak and strong scaling tests. It was also determined strong relations between the sizes and shapes of sud domains with the footprint of the inter-domains communications subroutines using a graph-based partitioner. Thus, setting the bases for optimal domain decompositions. However, it was also found that the master-slave strategy introduces an unexpected bottleneck in the communication of scalar values when more than a hundred of MPI tasks were deployed. An extensive analysis revealed that this anomaly was present in few MPI tasks resulting in an severe performance reduction. Finally, we highlight the importance of tracing and profiling tools, IPM is a novel implementation that could instrument Open FOAM successfully.},
  keywords={},
  doi={10.1109/HPCC.2011.57},
  ISSN={},
  month={Sep.},}
@INPROCEEDINGS{6063556,
  author={Jamali, Mohammad Ali Jabraeil and Shabestar, Hamid Entezari},
  booktitle={2011 12th ACIS International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing}, 
  title={A New Approach for a Fault Tolerant Mobile Agent System}, 
  year={2011},
  volume={},
  number={},
  pages={133-138},
  abstract={Improving the survivability of mobile agents in the presence of agent server failures with unreliable underlying networks is a challenging issue. In this paper, we address a fault tolerance approach of deploying cooperating agents to detect agent failures as well as to recover services in mobile agent systems. Three types of agents are involved, which are the actual agent, the supervisor agent and the replicas. We introduce a failure detection and recovery protocol by employing a message-passing mechanism among these three kinds of agents. Different failure scenarios and their corresponding recovery procedures are discussed. We choose Fatomas approach as a basic method. Message complexity of this approach is O (m2). Cooperative agents haven't been considered in this approach. We are going to improve this message complexity in a system of cooperative agents.},
  keywords={},
  doi={10.1109/SNPD.2011.44},
  ISSN={},
  month={July},}
@INPROCEEDINGS{6063484,
  author={Hu, Shun-Yun and Chen, Kuan-Ta},
  booktitle={2011 IEEE Fifth International Conference on Self-Adaptive and Self-Organizing Systems}, 
  title={VSO: Self-Organizing Spatial Publish Subscribe}, 
  year={2011},
  volume={},
  number={},
  pages={21-30},
  abstract={Spatial publish subscribe (SPS) is a basic primitive underlying many real-time, interactive applications such as online games or discrete-time simulations. Supporting SPS on a large-scale, however, requires sufficient resources and proper load distribution among the simulation units. For load distribution, existing mechanisms either use a static partitioning, such that over-provisioning or overloading are bound to occur, or require manual adjustments unsuitable for massive workloads. We describe Voronoi Self-organizing Overlay (VSO), which extends a Voronoi-based Overlay network (VON) to automatically partition and manage a logical space to support SPS. Efficient resource usage thus is possible as only the units necessary to maintain the system are used. Load is also balanced among the resource units so that overloading or over-provisioning can be avoided. We use simulations to verify our design and describe some preliminary results.},
  keywords={},
  doi={10.1109/SASO.2011.13},
  ISSN={1949-3681},
  month={Oct},}
@INPROCEEDINGS{6072788,
  author={Sadykhov, Rauf and Doudkin, Alexander and Ganchenko, Valentin and Petrovsky, Albert and Pawlowski, Tadeusz},
  booktitle={Proceedings of the 6th IEEE International Conference on Intelligent Data Acquisition and Advanced Computing Systems}, 
  title={Special areas detection on agricultural fields images using evaluations of local brightness variability}, 
  year={2011},
  volume={1},
  number={},
  pages={421-425},
  abstract={Problems of practical using of aerial photograph processing methods based on textural and fractal characteristics of images are considered in the paper (on an example of agricultural field images). ASM, Contrast and Entropy are used as textural characteristics. Calculation of fractal signature is based on fractal dimension. Results of joint segmentation based on proposed methods are tested at processing potato field aerial photographs. Also computational speedup problem using MPI are considered.},
  keywords={},
  doi={10.1109/IDAACS.2011.6072788},
  ISSN={},
  month={Sep.},}
@INPROCEEDINGS{6079302,
  author={Ismail, Roswan and Hamid, Nor Asila Wati Abdul and Othman, Mohamed and Latip, Rohaya and Sanwani, Mohd Azizi},
  booktitle={2011 IEEE Conference on Open Systems}, 
  title={MPI communication benchmarking on intel Xeon dual quad-core processor cluster}, 
  year={2011},
  volume={},
  number={},
  pages={208-213},
  abstract={This paper reports the measurements of MPI communication benchmarking on Khaldun cluster which ran on Linux-based IBM Blade HS21 Servers with Intel Xeon dual quad-core processor and Gigabit Ethernet interconnect. The measurements were done by using SKaMPI and IMB benchmark programs. Significantly, these were the first results produced by using SKaMPI and IMB to analyze the performance of Open MPI implementation on Khaldun cluster. The comparison and analysis of the results of point to point and collective communication from these two benchmark programs were then provided. It showed that different MPI benchmark programs rendered different results since they used different measurement techniques. The results were then compared to the experiment's results that were done on cluster with Opteron dual quad-core processor and Gigabit Ethernet interconnect. The analysis indicated that the architecture of machines used also affected the results.},
  keywords={},
  doi={10.1109/ICOS.2011.6079302},
  ISSN={},
  month={Sep.},}
@INPROCEEDINGS{6079383,
  author={Tsin, Yung H.},
  booktitle={2011 International Conference on Cyber-Enabled Distributed Computing and Knowledge Discovery}, 
  title={Recognizing and Embedding Outerplanar Distributed Computer Networks}, 
  year={2011},
  volume={},
  number={},
  pages={212-219},
  abstract={A new distributed algorithm for outerplanar network recognition and embedding is presented. The algorithm requires 2n-2 time and transmits at most 5m messages of O(lg n) length, where m is the number of links and n is the number of nodes in the network. In addition, if the network is indeed outerplanar, the algorithm will run in 2n-2 time and transmit at most 10n-15 messages. This time bound is the best one could ever achieve with a depth-first-search based algorithm. The previously best known algorithm achieves O(n) time and message bounds by using messages of O(n) length and running on a stronger model, making multiple passes over the network.},
  keywords={},
  doi={10.1109/CyberC.2011.43},
  ISSN={},
  month={Oct},}
@INPROCEEDINGS{6085136,
  author={Cui, Ying and Peng, Xiao and Chen, Zhixiang and Zhao, Xiongxin and Lu, Yichao and Zhou, Dajiang and Goto, Satoshi},
  booktitle={2011 IEEE International SOC Conference}, 
  title={Ultra low power QC-LDPC decoder with high parallelism}, 
  year={2011},
  volume={},
  number={},
  pages={142-145},
  abstract={This paper presents a novel high parallel decoder architecture for the quasi-cyclic low-density parity-check (QC-LDPC) codes defined in WiMAX system. Based on the turbo-decoding message passing (TDMP) algorithm, this architecture costs 8~16 clock cycles for each iteration in the decoding process. In the normalized comparison with the state-of-art work, this design achieves up to 6.5× higher parallelism and 76% power reduction. The energy/bit/iteration of this design is only 1/5 of the previous work.},
  keywords={},
  doi={10.1109/SOCC.2011.6085136},
  ISSN={2164-1706},
  month={Sep.},}
@INPROCEEDINGS{6089363,
  author={Sengupta, Ayan and Brahma, Siddhartha and Özgür, Ayfer and Fragouli, Christina and Diggavi, Suhas},
  booktitle={2011 IEEE Information Theory Workshop}, 
  title={Graph-based codes for Quantize-Map-and-Forward relaying}, 
  year={2011},
  volume={},
  number={},
  pages={140-144},
  abstract={We present a structured Quantize-Map-and-Forward (QMF) scheme for cooperative communication over wireless networks, that employs LDPC ensembles for the node operations and message-passing algorithms for decoding. We demonstrate through extensive simulation results over the full-duplex parallel relay network, that our scheme, with no transmit channel state information, offers a robust performance over fading channels and achieves the full diversity order of our network at moderate SNRs.},
  keywords={},
  doi={10.1109/ITW.2011.6089363},
  ISSN={},
  month={Oct},}
@INPROCEEDINGS{6092316,
  author={Wei, Jishang and Yu, Hongfeng and Chen, Jacqueline H. and Ma, Kwan-Liu},
  booktitle={2011 IEEE Symposium on Large Data Analysis and Visualization}, 
  title={Parallel clustering for visualizing large scientific line data}, 
  year={2011},
  volume={},
  number={},
  pages={47-55},
  abstract={Scientists often need to extract, visualize and analyze lines from vast amounts of data to understand dynamic structures and interactions. The effectiveness of such a visual validation and analysis process mainly relies on a good strategy to categorize and visualize the lines. However, the sheer size of line data produced by state-of-the-art scientific simulations poses great challenges to preparing the data for visualization. In this paper, we present a parallelization design of regression model-based clustering to categorize large line data derived from detailed scientific simulations by leveraging the power of heterogeneous computers. This parallel clustering method employs the Expectation Maximization algorithm to iteratively approximate the optimal data partitioning. First, we use a sorted-balance algorithm to partition and distribute the lines with various lengths among multiple compute nodes. During the following iterative clustering process, regression model parameters are recovered based on the local lines on each individual node, with only a few inter-node message exchanges involved. Meanwhile, the workload of regression model computing is well balanced across the nodes. The experimental results demonstrate that our approach can effectively categorize large line data in a scalable manner to concisely convey dynamic structures and interactions, leading to a visualization that captures salient features and suppresses visual clutter to facilitate scientific exploration of large line data.},
  keywords={},
  doi={10.1109/LDAV.2011.6092316},
  ISSN={},
  month={Oct},}
@INPROCEEDINGS{6095244,
  author={Battaglino, D. and Bracciale, L. and Detti, A. and Piccolo, F. Lo and Bragagnini, A. and Turolla, M. and Melazzi, N. Blefari},
  booktitle={2011 Future Network & Mobile Summit}, 
  title={A topic-based, publish-subscribe architecture for intermittently connected 802.15.4 networks}, 
  year={2011},
  volume={},
  number={},
  pages={1-8},
  abstract={The small size and power consumption of IEEE 802.15.4 devices allows embedding them in GSM/UMTS U-SIM cards and/or SD cards. The availability of such technology for data exchange within mobile phones is very useful to complement GSM/UMTS services, providing proximity services, such as chat and advertisements in a shopping mall, configuration data, micro-payments, access control. In addition, once that we have the availability of a free communication radio link, we can enlarge the assortment of offered services, supporting not only ”direct” data exchanges between two users within the 802.15.4 connectivity range, but also communication among intermittently connected users. This is a typical scenario of so-called Delay Tolerant Networks (DTN) and we argue that a communication paradigm well suited to this environment is publish-subscribe. On the other hand, publish-subscribe is also well suited to satisfy the requirements of a community of users such as the one of an university campus, accompanying other services such as voice and Internet access. The aim of this paper is to present a topic-based, publish-subscribe architecture for intermittently connected networks exploiting IEEE 802.15.4 devices, and taking into due account the severe constraints deriving from their physical characteristics. We describe the architectural model, the protocol design, the system analysis, and the implementation of our solution in a real test-bed, which we carried out in cooperation with Telecom Italia, that financed this work. We point out that our system can be easily adapted to operate in a fully distributed, infrastructure-less way, allowing free communications e.g. in disaster areas or in areas in which ”usual” communications means are either non existent or intentionally made unavailable. For instance, we could realize a server-less version of Twitter able to epidemically distribute information very quickly, provided that we have a high-enough density of devices implementing our solution.},
  keywords={},
  doi={},
  ISSN={},
  month={June},}
@INPROCEEDINGS{6100044,
  author={Bokor, Péter and Kinder, Johannes and Serafini, Marco and Suri, Neeraj},
  booktitle={2011 26th IEEE/ACM International Conference on Automated Software Engineering (ASE 2011)}, 
  title={Supporting domain-specific state space reductions through local partial-order reduction}, 
  year={2011},
  volume={},
  number={},
  pages={113-122},
  abstract={Model checkers offer to automatically prove safety and liveness properties of complex concurrent software systems, but they are limited by state space explosion. Partial-Order Reduction (POR) is an effective technique to mitigate this burden. However, applying existing notions of POR requires to verify conditions based on execution paths of unbounded length, a difficult task in general. To enable a more intuitive and still flexible application of POR, we propose local POR (LPOR). LPOR is based on the existing notion of statically computed stubborn sets, but its locality allows to verify conditions in single states rather than over long paths. As a case study, we apply LPOR to message-passing systems. We implement it within the Java Pathfinder model checker using our general Java-based LPOR library. Our experiments show significant reductions achieved by LPOR for model checking representative message-passing protocols and, maybe surprisingly, that LPOR can outperform dynamic POR.},
  keywords={},
  doi={10.1109/ASE.2011.6100044},
  ISSN={1938-4300},
  month={Nov},}
@INPROCEEDINGS{6105404,
  author={Qian, Hao and Deng, Yangdong},
  booktitle={2011 IEEE/ACM International Conference on Computer-Aided Design (ICCAD)}, 
  title={Accelerating RTL simulation with GPUs}, 
  year={2011},
  volume={},
  number={},
  pages={687-693},
  abstract={With the fast increasing complexity of integrated circuits, verification has become the bottleneck of today's IC design flow. In fact, over 70% of the IC design turn-around time can be spent on the verification process in a typical IC design project. Among various verification tasks, Register Transfer Level (RTL) simulation is the most widely used method to validate the correctness of digital IC designs. When simulating a large IC design with complicated internal behaviors (e.g., CPU cores running embedded software), RTL simulation can be extremely time consuming. Since RTL-to-layout is still the most prevalent IC design methodology, it is essential to speedup the RTL simulation process. Recently, General Purpose computing on Graphics Processing Units (GPGPU) is becoming a promising paradigm to accelerate computing-intensive workloads. A few recent works have demonstrated the effectiveness of using GPU to expedite gate and system level simulation tasks. In this work, we proposed an efficient GPU-accelerated RTL simulation framework. We introduce a methodology to translate Verilog RTL description into equivalent GPU source code so as to simulate circuit behavior on GPUs. In addition, a CMB based parallel simulation protocol is also adopted to provide a sufficient level of parallelism. Because RTL simulation lacks data-level parallelism, we also present a novel solution to use GPU as an efficient task-level parallel processor. Experimental results prove that our GPU based simulator outperforms a commercial sequential RTL simulator by over 20 fold.},
  keywords={},
  doi={10.1109/ICCAD.2011.6105404},
  ISSN={1558-2434},
  month={Nov},}
@INPROCEEDINGS{6103137,
  author={Shioda, Shigeo and Hieungmany, Phouvieng},
  booktitle={2011 International Conference on P2P, Parallel, Grid, Cloud and Internet Computing}, 
  title={Random Walk Search on Concatenated Hop-Limited Trees Embedded into Unstructured P2Ps}, 
  year={2011},
  volume={},
  number={},
  pages={43-50},
  abstract={We propose a random-walk-based file search for unstructured P2P networks. In the proposal, each node keeps two pieces of information, one is the hop-limited routing tables, storing the route information to nodes within a small number (say n) hops from each node. The hop-limited routing table is substantially equivalent to the hop-limited shortest path tree, which is made of nodes within limited hop distance from the root. The other is the file list, which is an index over files kept by nodes within n hops from each node. To find a file, a node first checks its file list. If the requested file is found in the list, the node sends a file request message to the file owner, otherwise, it sends a file-search message to a randomly-selected leaf node on the hop-limited shortest path tree rooted at itself. Numerical examples show that our proposal has much smaller search latency and lower file-search failure ratio than the primitive random-walk-based search, while it wastes much less network bandwidth than network-broadcast-based searches.},
  keywords={},
  doi={10.1109/3PGCIC.2011.17},
  ISSN={},
  month={Oct},}
@INPROCEEDINGS{6107199,
  author={Mak, Jason and Choboter, Paul and Lupo, Chris},
  booktitle={OCEANS'11 MTS/IEEE KONA}, 
  title={Numerical ocean modeling and simulation with CUDA}, 
  year={2011},
  volume={},
  number={},
  pages={1-6},
  abstract={ROMS is software that models and simulates an ocean region using a finite difference grid and time stepping. ROMS simulations can take from hours to days to complete due to the compute-intensive nature of the software. As a result, the size and resolution of simulations are constrained by the performance limitations of modern computing hardware. To address these issues, the existing ROMS code can be run in parallel with either OpenMP or MPI. In this work, we implement a new parallelization of ROMS on a graphics processing unit (GPU) using CUDA Fortran. We exploit the massive parallelism offered by modern GPUs to gain a performance benefit at a lower cost and with less power. To test our implementation, we benchmark with idealistic marine conditions as well as real data collected from coastal waters near central California. Our implementation yields a speedup of up to 8× over a serial implementation and 2.5× over an OpenMP implementation, while demonstrating comparable performance to a MPI implementation.},
  keywords={},
  doi={10.23919/OCEANS.2011.6107199},
  ISSN={0197-7385},
  month={Sep.},}
@INPROCEEDINGS{6106562,
  author={Buenabad-Chávez, Jorge and Castro-García, Miguel Alfonso and Quiroz-Fabián, José Luis and Hernández-Ventura, Edgar F. and Román-Alonso, Graciela and Yellin, Daniel M. and Aguilar-Cornejo, Manuel},
  booktitle={2011 8th International Conference on Electrical Engineering, Computing Science and Automatic Control}, 
  title={Reducing communication overhead under parallel list processing in multicore clusters}, 
  year={2011},
  volume={},
  number={},
  pages={1-6},
  abstract={The Data List Management Library (DLML) processes data lists in parallel, balancing the workload transparently to programmers. Its first design was targeted at clusters of uniprocessor nodes, and based on multiprocess parallelism and on message-passing communication. This paper presents a multithreaded design of DLML aimed at clusters of multicore nodes to better capitalise on intra-node parallelism. On applications tested, MultiCore DLML runs twice as fast as DLML when message-passing communication is not excessive. Good performance was achieved only after addressing issues relating to MPI communication overhead, cache locality and memory consumption.},
  keywords={},
  doi={10.1109/ICEEE.2011.6106562},
  ISSN={},
  month={Oct},}
@INPROCEEDINGS{6112033,
  author={Stojanović, Natalija and Stojanović, Dragan},
  booktitle={2011 10th International Conference on Telecommunication in Modern Satellite Cable and Broadcasting Services (TELSIKS)}, 
  title={High-performance processing of geospatial data on network of workstations}, 
  year={2011},
  volume={1},
  number={},
  pages={200-203},
  abstract={In this paper, high-performance processing of geospatial data on network of workstations is considered. We use MPI (Message Passing Interface) to implement distributed application for map-matching computation over large spatial datasets consisting of moving points and a road network. Experimental evaluation validates our approach and shows feasibility of high-performance computing in Geographic Information Systems (GIS).},
  keywords={},
  doi={10.1109/TELSKS.2011.6112033},
  ISSN={},
  month={Oct},}
@INPROCEEDINGS{6114469,
  author={Park, Chang-Seo and Sen, Koushik and Hargrove, Paul and Iancu, Costin},
  booktitle={SC '11: Proceedings of 2011 International Conference for High Performance Computing, Networking, Storage and Analysis}, 
  title={Efficient data race detection for distributed memory parallel programs}, 
  year={2011},
  volume={},
  number={},
  pages={1-12},
  abstract={In this paper we present a precise data race detection technique for distributed memory parallel programs. Our technique, which we call Active Testing, builds on our previous work on race detection for shared memory Java and C pro- grams and it handles programs written using shared memory approaches as well as bulk communication. Active testing works in two phases: in the first phase, it performs an im- precise dynamic analysis of an execution of the program and finds potential data races that could happen if the program is executed with a different thread schedule. In the second phase, active testing re-executes the program by actively controlling the thread schedule so that the data races re- ported in the first phase can be confirmed. A key highlight of our technique is that it can scalably handle distributed programs with bulk communication and single- and split- phase barriers. Another key feature of our technique is that it is precise-a data race confirmed by active testing is an actual data race present in the program; however, being a testing approach, our technique can miss actual data races. We implement the framework for the UPC programming language and demonstrate scalability up to a thousand cores for programs with both fine-grained and bulk (MPI style) communication. The tool confirms previously known bugs and uncovers several unknown ones. Our extensions capture constructs proposed in several modern programming languages for High Performance Computing, most notably non-blocking barriers and collectives.},
  keywords={},
  doi={},
  ISSN={2167-4337},
  month={Nov},}
@INPROCEEDINGS{6114493,
  author={Idomura, Yasuhiro and Jolliet, Sébastien},
  booktitle={SC '11: Proceedings of 2011 International Conference for High Performance Computing, Networking, Storage and Analysis}, 
  title={Performance evaluations of gyrokinetic Eulerian code GT5D on massively parallel multi-core platforms}, 
  year={2011},
  volume={},
  number={},
  pages={1-9},
  abstract={A gyrokinetic toroidal five dimensional Eulerian code GT5D [Y.Idomura et. al., Comput. Phys. Commun 179, 391 (2008)] is ported on five advanced massively parallel plat- forms and comprehensive benchmark tests are performed. Sustained performances of the GT5D kernel and their dependency on the memory bandwidth are discussed. By using a novel multi-layer hybrid parallelization model, the size of MPI communicators can be suppressed below ~ 100 up to ~ 107 cores, and the scalability is improved on multi-core platforms. In strong scaling tests, a good scalability is confirmed up to several thousands cores on every platforms, and the maximum sustained performance of ~ 19.4 Tflops (the peak ratio of ~ 10.1%) is achieved using 16384 cores of BX900.},
  keywords={},
  doi={10.1145/2063348.2063354},
  ISSN={2167-4337},
  month={Nov},}
@INPROCEEDINGS{6114491,
  author={Zhai, Yan and Liu, Mingliang and Zhai, Jidong and Ma, Xiaosong and Chen, Wenguang},
  booktitle={SC '11: Proceedings of 2011 International Conference for High Performance Computing, Networking, Storage and Analysis}, 
  title={Cloud versus in-house cluster: Evaluating Amazon cluster compute instances for running MPI applications}, 
  year={2011},
  volume={},
  number={},
  pages={1-10},
  abstract={The emergence of cloud services brings new possibilities for constructing and using HPC platforms. However, while cloud services provide the flexibility and convenience of customized, pay-as-you-go parallel computing, multiple previous studies in the past three years have indicated that cloud- based clusters need a significant performance boost to be- come a competitive choice, especially for tightly coupled parallel applications. In this work, we examine the feasibility of running HPC applications in clouds. This study distinguishes itself from existing investigations in several ways: 1) We carry out a comprehensive examination of issues relevant to the HPC community, including performance, cost, user experience, and range of user activities. 2) We compare an Amazon EC2-based platform built upon its newly available HPC- oriented virtual machines with typical local cluster and supercomputer options, using benchmarks and applications with scale and problem size unprecedented in previous cloud HPC studies. 3) We perform detailed performance and scalability analysis to locate the chief limiting factors of the state-of-the-art cloud based clusters. 4) We present a case study on the impact of per-application parallel I/O system configuration uniquely enabled by cloud services. Our results reveal that though the scalability of EC2-based virtual clusters still lags behind traditional HPC alternatives, they are rapidly gaining in overall performance and cost-effectiveness, making them feasible candidates for per- forming tightly coupled scientific computing. In addition, our detailed benchmarking and profiling discloses and analyzes several problems regarding the performance and performance stability on EC2.},
  keywords={},
  doi={},
  ISSN={2167-4337},
  month={Nov},}
@INPROCEEDINGS{6113797,
  author={Choi, Byn and Komuravelli, Rakesh and Sung, Hyojin and Smolinski, Robert and Honarmand, Nima and Adve, Sarita V. and Adve, Vikram S. and Carter, Nicholas P. and Chou, Ching-Tsun},
  booktitle={2011 International Conference on Parallel Architectures and Compilation Techniques}, 
  title={DeNovo: Rethinking the Memory Hierarchy for Disciplined Parallelism}, 
  year={2011},
  volume={},
  number={},
  pages={155-166},
  abstract={For parallelism to become tractable for mass programmers, shared-memory languages and environments must evolve to enforce disciplined practices that ban "wild shared-memory behaviors;'' e.g., unstructured parallelism, arbitrary data races, and ubiquitous non-determinism. This software evolution is a rare opportunity for hardware designers to rethink hardware from the ground up to exploit opportunities exposed by such disciplined software models. Such a co-designed effort is more likely to achieve many-core scalability than a software-oblivious hardware evolution. This paper presents DeNovo, a hardware architecture motivated by these observations. We show how a disciplined parallel programming model greatly simplifies cache coherence and consistency, while enabling a more efficient communication and cache architecture. The DeNovo coherence protocol is simple because it eliminates transient states - verification using model checking shows 15X fewer reachable states than a state-of-the-art implementation of the conventional MESI protocol. The DeNovo protocol is also more extensible. Adding two sophisticated optimizations, flexible communication granularity and direct cache-to-cache transfers, did not introduce additional protocol states (unlike MESI). Finally, DeNovo shows better cache hit rates and network traffic, translating to better performance and energy. Overall, a disciplined shared-memory programming model allows DeNovo to seamlessly integrate message passing-like interactions within a global address space for improved design complexity, performance, and efficiency.},
  keywords={},
  doi={10.1109/PACT.2011.21},
  ISSN={1089-795X},
  month={Oct},}
@INPROCEEDINGS{6113841,
  author={Vo, Anh and Gopalakrishnan, Ganesh and Kirby, Robert M. and de Supinski, Bronis R. and Schulz, Martin and Bronevetsky, Greg},
  booktitle={2011 International Conference on Parallel Architectures and Compilation Techniques}, 
  title={Large Scale Verification of MPI Programs Using Lamport Clocks with Lazy Update}, 
  year={2011},
  volume={},
  number={},
  pages={330-339},
  abstract={We propose a dynamic verification approach for large-scale message passing programs to locate correctness bugs caused by unforeseen nondeterministic interactions. This approach hinges on an efficient protocol to track the causality between nondeterministic message receive operations and potentially matching send operations. We show that causality tracking protocols that rely solely on logical clocks fail to capture all nuances of MPI program behavior, including the variety of ways in which nonblocking calls can complete. Our approach is hinged on formally defining the matches-before relation underlying the MPI standard, and devising lazy update logical clock based algorithms that can correctly discover all potential outcomes of nondeterministic receives in practice. can achieve the same coverage as a vector clock based algorithm while maintaining good scalability. LLCP allows us to analyze realistic MPI programs involving a thousand MPI processes, incurring only modest overheads in terms of communication bandwidth, latency, and memory consumption.},
  keywords={},
  doi={10.1109/PACT.2011.64},
  ISSN={1089-795X},
  month={Oct},}
@INPROCEEDINGS{6114812,
  author={Ribeiro, Leila and Dotti, Fernando Luis},
  booktitle={2011 Workshop-School on Theoretical Computer Science}, 
  title={Specification and Analysis of Concurrent Systems Using Object-Based Graph Grammars}, 
  year={2011},
  volume={},
  number={},
  pages={15-20},
  abstract={Building correct software systems is commonly accepted as both important and difficult. To achieve this, one has to address two basic issues: (i) offer suitable abstractions to formally specify specific classes of systems, (ii) allow the formal analysis of systems built using those abstractions. In this paper we review our results in this direction: we have proposed Object-Based Graph-Grammars (OBGGs) as a suitable set of abstractions to model concurrent, distributed, message passing and object-based based systems, coping with (i), and, coping with (ii), a set of transformations for OBGGs was proposed allowing one to employ several analysis methods, such as: model checking both functional and real-time properties, quantitative analysis using analytical methods, and verification through theorem proving.},
  keywords={},
  doi={10.1109/WEIT.2011.33},
  ISSN={},
  month={Aug},}
@INPROCEEDINGS{6118549,
  author={Cores, Iv´n and Rodriguez, Gabriel and Gonz´lez, Patricia and Martin, Maria J.},
  booktitle={2011 12th International Conference on Parallel and Distributed Computing, Applications and Technologies}, 
  title={An Application Level Approach for Proactive Process Migration in MPI Applications}, 
  year={2011},
  volume={},
  number={},
  pages={400-405},
  abstract={The running times of large-scale computational science and engineering parallel applications are usually longer than the mean-time-between-failures (MTBF). Hardware failures must be tolerated by the parallel applications to ensure that not all computation done is lost on machine failures. Check pointing and rollback recovery is a very useful technique to implement fault-tolerant applications. However, when a failure occurs, most check pointing mechanisms require a complete restart of the parallel application from the last checkpoint. This affects the efficiency of the solution, leading to an unnecessary overhead that can be avoided through a single process migration in case of failure. Although research has been carried out in this field, the solutions proposed in the literature are commonly tied to specific implementations of the parallel communication APIs or to specific runtime environments. The approach presented in this work extends an application level check pointing framework to proactively migrate MPI processes from processors when impending failures are notified, without having to restart the entire application. The main features of the proposed solution are: transparency for the user, achieved through the use of a compiler tool and a runtime library, and portability since it is not locked into a particular MPI implementation.},
  keywords={},
  doi={10.1109/PDCAT.2011.16},
  ISSN={2379-5352},
  month={Oct},}
@INPROCEEDINGS{6118924,
  author={Li, Qiang and Huo, Zhigang and Sun, Ninghui},
  booktitle={2011 12th International Conference on Parallel and Distributed Computing, Applications and Technologies}, 
  title={Optimizing MPI Alltoall Communication of Large Messages in Multicore Clusters}, 
  year={2011},
  volume={},
  number={},
  pages={257-262},
  abstract={MPI All to all communication is widely used in many high performance computing (HPC) applications. In All to all communication, each process sends a distinct message to all other participating processes. In multicore clusters, processes within a node simultaneously contend for the same network resource of the node in All to all communication. However, many small synchronization messages are required in All to all communication of large messages. With the contention, their latency is orders of magnitude larger than that without contention. As a result, the synchronization overhead is significantly increased and accounts for a large proportion to the whole latency of All to all communication. In this paper, we analyse the considerable overhead of synchronization messages. Base on the analysis, an optimization is presented to reduce the number of synchronization messages from 3N to 2¡ÌN. Evaluations on a 240-core cluster show that the performance is improved by almost constant ratio, which is mainly determined by message size and independent of system scale. The performance of All to all communication is improved by 25% for 32K and 64K bytes messages. For FFT application, performance is improved by 20%.},
  keywords={},
  doi={10.1109/PDCAT.2011.60},
  ISSN={2379-5352},
  month={Oct},}
@INPROCEEDINGS{6118945,
  author={Yang, Zhi and Jones, Richard T. and Yin, Changqin},
  booktitle={2011 12th International Conference on Parallel and Distributed Computing, Applications and Technologies}, 
  title={Grid Based Analysis Toolkit for Partial Wave Analysis}, 
  year={2011},
  volume={},
  number={},
  pages={161-166},
  abstract={To get the physics out of the data, GlueX relies entirely on an amplitude-based analysisâ€"PWA(Partial Wave Analysis). We build a grid test platform to verify how computational and data grid can be used to process large scale dataset in PWA, and make PWA toolkit to be grid-enable. The work we did has demonstrated that grid is a promising computing architecture for PWA in GlueX project. We setup grid computational platform, which consists of three clusters. We also setup data grid platform using dCache and evaluate the file access performance of dCache. A new Condor wrapper for Open MPI is presented in this grid platform. Through revising ruby-PWA package, we parallel ruby-PWA in grid environment. We run some scaling test benchmarks, and the results show grid-enabled ruby-PWA gets high performance in multi-node amplitude analysis.},
  keywords={},
  doi={10.1109/PDCAT.2011.43},
  ISSN={2379-5352},
  month={Oct},}
@INPROCEEDINGS{6118967,
  author={Graebin, Lucas and da Rosa Righi, Rodrigo},
  booktitle={2011 12th International Conference on Parallel and Distributed Computing, Applications and Technologies}, 
  title={jMigBSP: Object Migration and Asynchronous One-Sided Communication for BSP Applications}, 
  year={2011},
  volume={},
  number={},
  pages={35-38},
  abstract={This paper describes the rationale for developing jMigBSP - a Java programming library that offers object rescheduling. It was designed to work on grid computing environments and offers an interface that follows the BSP (Bulk Synchronous Parallel) style. jMigBSP's main contribution focuses on the rescheduling facility in two different ways: (i) by using migration directives on the application code directly and (ii) through automatic load balancing at middleware level. Especially, this second idea is feasible thanks to the Java's inheritance feature, in which transforms a simple jMigBSP application in a migratable one only by changing a single line of code. In addition, the presented library makes the object interaction easier by providing one-sided message passing directives and hides network latency through asynchronous communications. Finally, a BSP-based FFT application was developed and its execution shows jMigBSP as a competitive library when comparing performance with a C-based library called BSPlib. Besides its user-friendly Java interface, the strengths of jMigBSP also considers the migration tests where it outperforms the time spent with BSPlib.},
  keywords={},
  doi={10.1109/PDCAT.2011.48},
  ISSN={2379-5352},
  month={Oct},}
@INPROCEEDINGS{6121279,
  author={Anbar, Ahmad and Serres, Olivier and El-Ghazawi, Tarek},
  booktitle={2011 IEEE 17th International Conference on Parallel and Distributed Systems}, 
  title={Reflex Barrier: A Scalable Network-Based Synchronization Barrier}, 
  year={2011},
  volume={},
  number={},
  pages={204-211},
  abstract={High-performance computing is witnessing the proliferation of multi-core processors in parallel architectures, and the trend is expected to increase further with the emerging many-core technology, leading to hundreds of processing cores within each compute node in the near future. Along side with this trend, it is also clear that total number of cores within the whole system is increasing. To be able to harvest the fruits of this massive parallelism, inter-process synchronization and communication should be as lightweight as they can be, and should be relying on as limited involvement as possible of the participating processors/cores. The synchronization algorithms that target shared memory processors are expected not to be able to scale on many-cores as they rely on atomics, locks, and/or cache coherence protocols, which all should be very costly operations on many-cores. In the same time, some many core architectures provide user space networks on chip (NoCs) that operate similar to regular networks. In this paper, we are introducing the Reflex barrier, a new synchronization barrier algorithm that relies on fundamental networking concepts. As the barrier relies on the characteristics of the network, it requires very little intervention from the participating processors/cores. The algorithm can also be implemented as split phase, which furnish an opportunity to reduce the synchronization cost. We implemented the algorithm using Unified Parallel C (UPC), MPI and pThreads. We tested our implementation on TILE64, a 64-core processor. The performance of the Reflex barrier is also analyzed and compared to other algorithms using performance models.},
  keywords={},
  doi={10.1109/ICPADS.2011.106},
  ISSN={1521-9097},
  month={Dec},}
@INPROCEEDINGS{6122723,
  author={Salleh, Nur Shakirah Md and Suliman, Azizah and Ahmad, Abdul Rahim},
  booktitle={ICIMU 2011 : Proceedings of the 5th international Conference on Information Technology & Multimedia}, 
  title={Parallel execution of distributed SVM using MPI (CoDLib)}, 
  year={2011},
  volume={},
  number={},
  pages={1-4},
  abstract={Support Vector Machine (SVM) is an efficient data mining approach for data classification. However, SVM algorithm requires very large memory requirement and computational time to deal with very large dataset. To reduce the computational time during the process of training the SVM, a combination of distributed and parallel computing method, CoDLib have been proposed. Instead of using a single machine for parallel computing, multiple machines in a cluster are used. Message Passing Interface (MPI) is used in the communication between machines in the cluster. The original dataset is split and distributed to the respective machines. Experiments results shows a great speed up on the training of the MNIST dataset where training time has been significantly reduced compared with standard LIBSVM without affecting the quality of the SVM.},
  keywords={},
  doi={10.1109/ICIMU.2011.6122723},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{6123487,
  author={Garg, Saurabh Kumar and Buyya, Rajkumar},
  booktitle={2011 Fourth IEEE International Conference on Utility and Cloud Computing}, 
  title={NetworkCloudSim: Modelling Parallel Applications in Cloud Simulations}, 
  year={2011},
  volume={},
  number={},
  pages={105-113},
  abstract={As interest in adopting Cloud computing for various applications is rapidly growing, it is important to understand how these applications and systems will perform when deployed on Clouds. Due to the scale and complexity of shared resources, it is often hard to analyze the performance of new scheduling and provisioning algorithms on actual Cloud test beds. Therefore, simulation tools are becoming more and more important in the evaluation of the Cloud computing model. Simulation tools allow researchers to rapidly evaluate the efficiency, performance and reliability of their new algorithms on a large heterogeneous Cloud infrastructure. However, current solutions lack either advanced application models such as message passing applications and workflows or scalable network model of data center. To fill this gap, we have extended a popular Cloud simulator (CloudSim) with a scalable network and generalized application model, which allows more accurate evaluation of scheduling and resource provisioning policies to optimize the performance of a Cloud infrastructure.},
  keywords={},
  doi={10.1109/UCC.2011.24},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{6123441,
  author={Zaspel, Peter and Griebel, Michael},
  booktitle={2011 First International Symposium on Network Cloud Computing and Applications}, 
  title={Massively Parallel Fluid Simulations on Amazon's HPC Cloud}, 
  year={2011},
  volume={},
  number={},
  pages={73-78},
  abstract={In this paper, we report on the results of numerical experiments in the field of computational fluid dynamics (CFD) on Amazon's HPC cloud. To this end, we benchmarked our MPI-parallel fluid solver NaSt3DGPF on several HPC compute nodes of the cloud system. Our solver can use CPUs and GPUs to calculate the simulation results. With a pre-requested number of instances we observe for both, CPUs and GPUs, good scalability even for a larger number of parallel processes, provided that the GPUs run in the non-ECC mode. Furthermore, we see a high potential for medium sized parallel compute problems which are typically present in industrial engineering applications.},
  keywords={},
  doi={10.1109/NCCA.2011.19},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{6126624,
  author={Canillas, J. Martinez and Wong, A. and Rexachs, D. and Luque, E.},
  booktitle={2011 9th IEEE/ACS International Conference on Computer Systems and Applications (AICCSA)}, 
  title={Predicting parallel applications performance using signatures: The workload effect}, 
  year={2011},
  volume={},
  number={},
  pages={299-300},
  abstract={Being able to accurately estimate how an application will perform in a specific computational system provides many useful benefits and can result in smarter decisions. In this work we present a novel approach to model the behavior of message passing parallel applications. Based in the concept of signatures, which are the most relevant parts of an application (phases), we are able to build a model that allows us to predict the application execution time in different systems with variable input data size. Executing these signatures with different input data sizes defines a program's behavior partial function. Using regression we can generalize this behavior function to predict an application performance in a target system with other input data size within a predefined range. We explain our methodology and in order to validate the proposal present results using a synthetic program and well known applications.},
  keywords={},
  doi={10.1109/AICCSA.2011.6126624},
  ISSN={2161-5330},
  month={Dec},}
@INPROCEEDINGS{6126618,
  author={Balladini, Javier and Suppi, Remo and Rexachs, Dolores and Luque, Emilio},
  booktitle={2011 9th IEEE/ACS International Conference on Computer Systems and Applications (AICCSA)}, 
  title={Impact of parallel programming models and CPUs clock frequency on energy consumption of HPC systems}, 
  year={2011},
  volume={},
  number={},
  pages={16-21},
  abstract={Energy consumption has become one of the greatest challenges in the field of high performance computing (HPC). The energy cost produced by supercomputers during the lifetime of the installation is similar to acquisition. Thus, besides its impact on the environment, energy is a limiting factor for the HPC. Our research aims to reduce the energy consumption of computer systems to run parallel HPC applications. In this article we analyse the possible influence on the energy consumption of parallel programming paradigms of shared memory (OpenMP) and message passing (MPI), and the behaviour of systems at different clock frequencies of CPUs. The results show that the programming model has a major impact on the energy consumption of computer systems. It was found that the impact of reduced clock frequencies on the execution time, energy efficiency, and maximum power consumption depends not only on the type of application but also on its implementation in a specific programming model. We believe that another criteria to consider when choosing a parallel programming model is the impact on energy consumption.},
  keywords={},
  doi={10.1109/AICCSA.2011.6126618},
  ISSN={2161-5330},
  month={Dec},}
@INPROCEEDINGS{6128494,
  author={Zhou, Huan and Zheng, Qi-long and Wang, Rui},
  booktitle={2011 Fourth International Symposium on Parallel Architectures, Algorithms and Programming}, 
  title={Estimation of BSP Network Parameters Based on MPI-2 One-Sided Operation}, 
  year={2011},
  volume={},
  number={},
  pages={151-155},
  abstract={The BSP network parameters are usually measured by one-sided communication functions in BSPlib standard, which can't reflect the communication performance of the message passing parallel machines effectively. Furthermore, the one-sided operation is becoming more and more popular with high-performance communication as the release of MPI-2 version. This paper further investigates the implementation of MPI-2 one-sided operation, and proposes a new estimation scheme that using the one-sided operation for BSP network parameters g and L, they are measured on the DOWNING 4000A Cluster machine under the condition of different number of processes which adopts the all-to-all total change communication mode. And it validates the correctness and the validity of the MPI program cost analysis, which makes use of the BSP model and a parallel radix-2 FFT algorithm based on the BSP model. The results prove that the new estimation scheme is effective and practical for the DOWNING Cluster machine and other similar message passing parallel machines.},
  keywords={},
  doi={10.1109/PAAP.2011.66},
  ISSN={2168-3042},
  month={Dec},}
@INPROCEEDINGS{6128518,
  author={Chen, Jun and Zou, You and Liu, Zhongyu and Wu, Qing},
  booktitle={2011 Fourth International Symposium on Parallel Architectures, Algorithms and Programming}, 
  title={Enabling Grid Computing over IPv6 within a Campus Network}, 
  year={2011},
  volume={},
  number={},
  pages={285-288},
  abstract={The biggest problem to be solved in grid computing is data transmission and communication efficiency and stability. For computing grid composed of small local area network(LAN), this problem can be solved by properly building LAN with the use of IPv4 network or high-speed computing network such as Infiniband. However, when the computing resources are distributed in different physical regions, data transmission and communication will be affected by various factors such as time period and load. On the one hand, the stability of transmission cannot be guaranteed; On the other hand, the speed of cross-regional data transmission is not optimistic. As the next generation of Internet protocol, IPv6 is at a transitional stage, and the load is far less than the IPv4-based network. So, it has a better stability and higher bandwidth. With the help of IPv6 network, cross-regional computing grids can be constructed to connect the computing resources in different physical regions in order to deal with some complex computing problems. This paper studies and tests the feasibility of transplanting MPI application (which is more commonly used in distributed computing) into IPv6 network for grid computing, and presents its implementation process in detail.},
  keywords={},
  doi={10.1109/PAAP.2011.71},
  ISSN={2168-3042},
  month={Dec},}
@INPROCEEDINGS{6131868,
  author={Chen, Zhixiang and Peng, Xiao and Zhao, Xiongxin and Xie, Qian and Okamura, Leona and Zhou, Dajiang and Goto, Satoshi},
  booktitle={2011 International Symposium on Integrated Circuits}, 
  title={A 6.72-Gb/s 8pJ/bit/iteration IEEE 802.15.3c LDPC decoder chip}, 
  year={2011},
  volume={},
  number={},
  pages={7-12},
  abstract={In this paper, we introduce an LDPC decoder design for decoding length-672 code adopted in IEEE 802.15.3c standard. The proposed decoder features high performance in both data rate and power efficiency. A macro-layer level fully parallel layered decoding architecture is proposed to support the throughput requirement in the standard. The decoder takes only 4 clock cycles to process one decoding iteration. While parallelism increases, the chip routing congestion problem becomes more severe because of the more complicated interconnection network used for message passing. This problem is nicely solved by our proposed efficient message permutation scheme utilizing the parity check matrix features. The proposed message permutation network features high compatibility and zero-logic-gate VLSI implementation, which contribute to the remarkable improvements in both area utilization ratio and total gate count. To verify the above techniques, the proposed decoder is implemented on a chip fabricated using Fujitsu 65nm 1P12L LVT CMOS process. The chip occupies a core area of 1.30mm2 with area utilization ratio 86.3%. According to the measurement results, working at 1.2V, 400 MHz and 10 iterations the proposed decoder delivers a 6.72Gb/s data throughput and dissipates a power of 537.6mW, resulting in an energy efficiency 8.0pJ/bit/iteration.},
  keywords={},
  doi={10.1109/ISICir.2011.6131868},
  ISSN={2325-0631},
  month={Dec},}
@INPROCEEDINGS{6133127,
  author={Tamano, Hiroshi and Nakadai, Shinji and Araki, Takuya},
  booktitle={2011 IEEE Third International Conference on Cloud Computing Technology and Science}, 
  title={Optimizing Multiple Machine Learning Jobs on MapReduce}, 
  year={2011},
  volume={},
  number={},
  pages={59-66},
  abstract={Recently, MapReduce has been used to parallelize machine learning algorithms. To obtain the best performance for these algorithms, tuning the parameters of the algorithms is required. However, this is time consuming because it requires executing a MapReduce program multiple times using various parameters. Such multiple executions can be assigned to a cluster in various ways, and the execution time varies depending on the assignments. To achieve the shortest execution time, we propose a method for optimizing the assignment of MapReduce jobs to a cluster assuming machine learning targeted runtime. We developed an execution cost model to predict the total execution time of jobs and obtained the optimal assignment by minimizing the cost model. To evaluate the proposed method, we implemented an experimental MapReduce runtime based on Message Passing Interface and executed logistic regression in four cases. The results showed that the proposed method can correctly predict the optimal job assignment. We also confirmed that the optimal assignment reduced execution time by a maximum 77% compared to the worst assignment.},
  keywords={},
  doi={10.1109/CloudCom.2011.18},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{6133168,
  author={Tran, Nam-Luc and Skhiri, Sabri and Zim´nyi, Esteban},
  booktitle={2011 IEEE Third International Conference on Cloud Computing Technology and Science}, 
  title={EQS: An Elastic and Scalable Message Queue for the Cloud}, 
  year={2011},
  volume={},
  number={},
  pages={391-398},
  abstract={With the emergence of cloud computing, on-demand resources usage is made possible. This allows applications to elastically scale out according to the load. One design pattern that suits this paradigm is the event-driven architecture (EDA) in which messages are sent asynchronously between distributed application instances using message queues. However, existing message queues are only able to scale for a certain number of clients and are not able to scale out elastically. We present the Elastic Queue Service (EQS), an elastic message queue architecture and a scaling algorithm which can be adapted to any message queue in order to make it scale elastically. EQS architecture is layered onto multiple distributed components and its management components can be integrated with the cloud infrastructure management. We have implemented a prototype of EQS and deployed it on a cloud infrastructure. A series of load testings have validated our elastic scaling algorithm and show that EQS is able to scale out in order to adapt to an applied load. We then discuss about the elastic scaling of the management layers of EQS and their possible integration with the cloud infrastructure management.},
  keywords={},
  doi={10.1109/CloudCom.2011.59},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{6138747,
  author={Eom, Ki-woong and Chung, Won-young and Lee, Yong-surk},
  booktitle={2011 International SoC Design Conference}, 
  title={A novel sequential tree algorithm based on the status of the processing nodes to reduce congestion}, 
  year={2011},
  volume={},
  number={},
  pages={211-214},
  abstract={In recent years, consumers' demand for high-performance IT equipment has grown rapidly. Thus, the Multiple-Processor System on a Chip (MPSoC) and the distributed memory system are widely researched for improvement in the performance of the embedded system. The Message Passing Interface (MPI) specification is the software platform for using the distributed memory system on MPSoC. In addition, MPI_Bcast function is one of the most frequently used functions. Thus, we proposed a novel MPI broadcasting algorithm and hardware architecture for performance improvement. Since the proposed algorithm checks the status of processing nodes and reschedules the order of transmission, processing time can be reduced. In simulation, the proposed algorithm reduced the processing time a maximum of 286605ns (general sequential tree algorithm: 2851160ns, proposed sequential algorithm: 2294355ns) and improved the performance up to 71.3% with an 8-processing-node system.},
  keywords={},
  doi={10.1109/ISOCC.2011.6138747},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{6146855,
  author={Sharma, Rajkumar and Kanungo, Priyesh},
  booktitle={2011 International Conference on Recent Trends in Information Systems}, 
  title={Performance evaluation of MPI and hybrid MPI+OpenMP programming paradigms on multi-core processors cluster}, 
  year={2011},
  volume={},
  number={},
  pages={137-140},
  abstract={Processors design is now switched to multi-core architecture in a direction that minimizes energy consumption. A decade ago CPUs speed could not accelerate without extra ordinary cooling and consequently hit a clock speed barrier. The multi-core architecture is introduced to improve computing performance by providing hardware parallelism through more CPU cores, each having restrained clock speed. This has been a break through in High Performance Computing (HPC). While more processor cores rendered effective execution results, multi-core technology inaugurated an extra layer of complexity for programming issues. To exploit each core in a multi-core environment, application software should be optimized by using multithreading. Multi-core processors can even degrade the performance for single threaded application due to reduction in clock speed. In this paper we compare performance of multithreading fine-grained and course-grained computational problems further flavored as computation-intensive and data-intensive problems by using MPI and hybrid MPI+OpenMP approach and evaluate suitability of multi-core cluster depending on the nature of the problems.},
  keywords={},
  doi={10.1109/ReTIS.2011.6146855},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{6151468,
  author={Ali, Amjad and Syed, Khalid S. and Hassan, Ahmad and Ahmad, Idrees and Ismail, Muhammad Ali},
  booktitle={2011 IEEE 14th International Multitopic Conference}, 
  title={On parallel performance of an implicit discontinuous Galerkin compressible flow solver based on different linear solvers}, 
  year={2011},
  volume={},
  number={},
  pages={182-187},
  abstract={Parallelization of an Implicit discontinuous Galerkin method based on Taylor series basis for the compressible flows on unstructured meshes is developed for distributed memory architectures, specifically for cost effective compute clusters. The system of linear equations arising from the implicit time integration is solved using three choices of linear solvers: SGS(k) (Symmetric Gauss-Seidel with k iterations), LU-SGS (Lower-Upper Symmetric Gauss-Seidel), and a well known Krylov subspace iterative solver GMRES (Generalized Minimum Residual) preconditioned with LUSGS. The comparative study of the parallel performance of the flow solver based on the different linear solvers is tested on a number of parallel platforms; ranging from compute clusters to multicore machines. The parallelization is based on computational domain partitioning using the well-known mesh partitioning software, METIS, and SPMD (Single Program Multiple Data) message-passing programming paradigm using MPI (Message Passing Interface) library, which is a de facto industry standard for portable programming.},
  keywords={},
  doi={10.1109/INMIC.2011.6151468},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{6152936,
  author={Park, Sang-su and Yun, Hee-jun and Chung, Won-young and Lee, Yong-surk},
  booktitle={The 17th Asia Pacific Conference on Communications}, 
  title={Implementing and optimizing ROM table for broadcast message used in MPI unit}, 
  year={2011},
  volume={},
  number={},
  pages={894-898},
  abstract={In this paper, we propose to implement and optimize a ROM table which contains a set of point-to-point communications for broadcast communication in message passing interface (MPI) systems in multi-processors that use distributed memory. MPI broadcast communication is one of the most frequently used collective functions. The contents of the ROM table are part of message packets about a set of point-to-point communications for broadcast communication determined by considering the states of every processing node. Thus, it can prevent the sending node from communicating the data to another node in a busy state. This minimizes the performance degradation caused by conflict. Also, the broadcast communication is based on a binary tree algorithm. Since each processing node owns the same ROM table, we need to optimize the size of the ROM table. The states of all the processing nodes and their own identification number are required to index the ROM table correctly. Consequently, by optimizing the ROM table, the bit size is reduced about 25% with four nodes, about 75% with eight nodes, and about 81% with 16 nodes.},
  keywords={},
  doi={10.1109/APCC.2011.6152936},
  ISSN={2163-0771},
  month={Oct},}
@INPROCEEDINGS{6151976,
  author={Neville, Stephen W. and Horie, Michael},
  booktitle={2011 eCrime Researchers Summit}, 
  title={Controlling spam and spear phishing via peered network overlays and non-repudiable traceback}, 
  year={2011},
  volume={},
  number={},
  pages={1-13},
  abstract={Despite 30 years of on-going effort, spam remains a significant problem. While technology has abated the deluge of spam invading the average user's email inbox, spam still facilitates the sale of counterfeited products, distribution of malware, and other criminal activities - as well as the more insidious use of spear phishing to leverage attacks into corporate and government networks. The value of email arises directly from its anyone-to-anyone message-passing capability. Hence, anti-spam techniques based on end-point encryption have met with limited success. Furthermore, due to geopolitical concerns, most traceback techniques only work effectively within - and not across - geopolitical boundaries; and while targeted removal of spam-friendly ISPs and botnets has had significant impacts on spam rates, these gains have tended to be short lived. This work proposes a novel approach to control spam and spear phishing through combining peer-level quality-of-service (QoS) agreements with a ProVerif verified, non-repudiable traceback protocol to enact spam resistant overlays that are: i) scalable, ii) enforceable over geopolitical boundaries, and iii) do not require technological sea changes. Simulation results on an Internet-style network of 3,000 ISPs show that even in the presence of aggressive spammers, it is possible to reduce the spam versus normal email equilibrium from 90:10 to 20:80. Furthermore, this approach can be used to aid in controlling spear phishing attacks targeting federated organizations.},
  keywords={},
  doi={10.1109/eCrime.2011.6151976},
  ISSN={2159-1245},
  month={Nov},}
@INPROCEEDINGS{6152716,
  author={Wang, Rui and Yao, Erlin and Chen, Mingyu and Tan, Guangming and Balaji, Pavan and Buntinas, Darius},
  booktitle={2011 18th International Conference on High Performance Computing}, 
  title={Building algorithmically nonstop fault tolerant MPI programs}, 
  year={2011},
  volume={},
  number={},
  pages={1-9},
  abstract={With the growing scale of high-performance computing (HPC) systems, today and more so tomorrow, faults are a norm rather than an exception. HPC applications typically tolerate fail-stop failures under the stop-and-wait scheme, where even if only one processor fails, the whole system has to stop and wait for the recovery of the corrupted data. It is now a more-or-less accepted fact that the stop-and-wait scheme will not scale to the next generation of HPC systems. Inspired by the previous stop-and-wait algorithm-based fault tolerance (ABFT) recovery technique, we propose in this paper a nonstop fault tolerance scheme at the application level and describe its implementation. When failure occurs during the execution of applications, we do not stop to wait for the recovery of the corrupted node; instead, we replace it with the corresponding redundant node and continue the execution. At the end of execution, the correct solution can be recovered algorithmically at a very low cost. In order to implement the scheme, some new fault-tolerant features of the Message Passing Interface (MPI) have been investigated and utilized in the MPICH implementation of MPI. We also describe a case study using High Performance Linpack (HPL) with these new features and evaluate the performance of both our new scheme and ABFT recovery. Experimental results show the advantage of our new scheme over ABFT recovery even in a small scale.},
  keywords={},
  doi={10.1109/HiPC.2011.6152716},
  ISSN={1094-7256},
  month={Dec},}
@ARTICLE{6157461,
  author={Mingche, Lai and Lei, Gao},
  journal={Journal of Communications and Networks}, 
  title={Two-level tries: A general acceleration structure for parallel routing table accesses}, 
  year={2011},
  volume={13},
  number={4},
  pages={408-417},
  abstract={The stringent performance requirement for the high efficiency of routing protocols on the Internet can be satisfied by exploiting the threaded border gateway protocol (TBGP) on multi- cores, but the state-of-the-art TBGP performance is restricted by a mass of contentions when racing to access the routing table. To this end, the highly-efficient parallel access approach appears to be a promising solution to achieve ultra-high route processing speed. This study proposes a general routing table structure consisting of two-level tries for fast parallel access, and it presents a heuristic-based divide-and-recombine algorithm to solve a mass of contentions, thereby accelerating the parallel route updates of multi-threading and boosting the TBGP performance. As a projected TBGP, this study also modifies the table operations such as insert and lookup, and validates their correctness according to the behaviors of the traditional routing table. Our evaluations on a dual quad-core Xeon server show that the parallel access contentions decrease sharply by 92.5% versus the traditional routing table, and the maximal update time of a thread is reduced by 56.8% on average with little overhead. The convergence time of update messages are improved by 49.7%.},
  keywords={},
  doi={10.1109/JCN.2011.6157461},
  ISSN={1976-5541},
  month={Aug},}
@INPROCEEDINGS{6158295,
  author={Xuan Sun and Zheng Zhou and Lei Shi and Weixia Zou},
  booktitle={2011 6th International ICST Conference on Communications and Networking in China (CHINACOM)}, 
  title={A novel compressed collaborative sensing scheme using LDPC technique}, 
  year={2011},
  volume={},
  number={},
  pages={959-963},
  abstract={Collaborative spectrum sensing (CSS) can significantly improve the performance of spectrum sensing based on the spatial diversity gain of different cognitive radio (CR). In wideband spectrum sensing scenario, since there might not be enough CRs in the network, or due to hardware limitations, each CR node can only sense a relatively narrow band of radio spectrum. Consequently, the available channel sensing information is far from being sufficient for precisely recognizing the wide range of unoccupied channels. Based on the fact that the spectrum usage information the CR nodes collect has a common sparsity pattern, in this paper, we present a compressed collaborative wideband spectrum sensing scheme in cognitive radio networks. Under the hypothesis of joint sparsity, the CRs need to randomly detect a very small number of sub-channels according to a measurement matrix and send the results to a fusion center. To make the compressed sensing more effective, the scheme uses LDPC-like measurement matrix. Then the whole channel status can be recoverd by the fusion center through a low-complexity message passing algorithm. Numerical results shows that under a joint sparsity model, using the proposed distributed compressed sensing scheme, the CRs make a small number of measurements and get a high probability of detection.},
  keywords={},
  doi={10.1109/ChinaCom.2011.6158295},
  ISSN={},
  month={Aug},}
@INPROCEEDINGS{6162459,
  author={Rath, Hemant Kumar and Rajan, M A and Balamuralidhar, P},
  booktitle={2011 IEEE GLOBECOM Workshops (GC Wkshps)}, 
  title={Monotonic Signed Graph approach for cross-layer congestion control in wireless ad-hoc networks}, 
  year={2011},
  volume={},
  number={},
  pages={309-314},
  abstract={In this paper, we propose a Monotonic Signed Graph (MSG)-based cross-layer congestion control technique for wireless ad-hoc networks. This is a practically implementable self re-configurable distributed solution which runs independently on each wireless nodes. Moreover, it is an alternative approach to Joint Optimal Congestion control and Power control (JOCP) which solves a dual of social optimization problem in-terms of individual optimization functions. Our simulation results demonstrate that the proposed MSG scheme performs at-par (in-terms of throughput and transmission power) with JOCP scheme. Our scheme is a novel scalable approach as there is no message passing involved which is prevalent in JOCP. Though the rate of convergence of MSG approach is bit slower as compared to that of JOCP, it is within 4-5 Round Trip Times (RTTs). Hence it is a major candidate for implementing cross-layer congestion control in wireless ad-hoc networks, where long-flows are of importance. We also verify the robustness of our scheme.},
  keywords={},
  doi={10.1109/GLOCOMW.2011.6162459},
  ISSN={2166-0077},
  month={Dec},}
@INPROCEEDINGS{6166223,
  author={Paul, Tamal and Kimball, Jonathan W. and Zawodniok, Maciej and Roth, Thomas P. and McMillin, Bruce},
  booktitle={2011 IEEE International Conference on Service-Oriented Computing and Applications (SOCA)}, 
  title={Invariants as a unified knowledge model for Cyber-Physical Systems}, 
  year={2011},
  volume={},
  number={},
  pages={1-8},
  abstract={Cyber-Physical Systems (CPS) consist of distributed computation interconnected by computer networks that monitor and control switched physical entities interconnected by physical infrastructures. Finding a common semantic among these diverse components that facilitates system synthesis, verification, and monitoring is a significant challenge of a CPS research program. In the emerging smart grid, for example, system state provides input into distributed computer algorithms that manage power and energy via local computation with messaging passing over a computer network collectively resulting in control signals to advanced power electronics. Computational correctness, network timing, and frequency response are all system aspects that conspire to impede design, verification, and monitoring. This paper seeks to unify the knowledge present in these diverse aspects through developing common semantics that span each aspect of a CPS. Specifically, a “smart grid” type system is considered. Power commands to various loads and alternative energy sources are stepped in response to cyber controllers that are networked. This paper shows the development of a physical invariant, based on the theory of Lyapunov-like functions, and a cyber invariant, the governs the correctness of a power dispatch algorithm, and couples the two to develop an overall system stability invariant. The invariant approach is tested with two scenarios. In the first case, the system is subjected to two commanded pulses beyond the stable limit, with the second perturbing pulse being of a magnitude greater than the first, which makes the system unstable. In the second case, the system is subjected to two commanded pulses beyond its stable limit but with a comparatively smaller magnitude of the perturbing second pulse, which allowed the system to remain stable. The measure of stability is an energy function which, under certain conditions, serves as a Lyapunov-like invariant that is used to prove stability.},
  keywords={},
  doi={10.1109/SOCA.2011.6166223},
  ISSN={2163-2871},
  month={Dec},}
@INPROCEEDINGS{6169606,
  author={Frisch, Jerome and Mundani, Ralf-Peter and Rank, Ernst},
  booktitle={2011 13th International Symposium on Symbolic and Numeric Algorithms for Scientific Computing}, 
  title={Communication Schemes of a Parallel Fluid Solver for Multi-scale Environmental Simulations}, 
  year={2011},
  volume={},
  number={},
  pages={391-397},
  abstract={A lot of different environmental simulations use computational fluid dynamics for detailed airflow computation and pollution transportation. Unfortunately, a multi-scale computational fluid dynamics simulation is very time consuming and computational intensive, as a high geometric discretisation has to be chosen in order to capture all required physical phenomena, so that without any parallelisation strategies, these computations tend to be impossible to perform. In this paper, we will discuss communication schemes using the message passing paradigm implemented in a previously validated fluid simulation code. Advantages and disadvantages of the current implementation will be discussed and improvements will be proposed.},
  keywords={},
  doi={10.1109/SYNASC.2011.7},
  ISSN={},
  month={Sep.},}
@INPROCEEDINGS{6182396,
  author={Wang Weihong and Chen Jiechen and Gu Guomin and Wu Wei},
  booktitle={Proceedings of 2011 International Conference on Computer Science and Network Technology}, 
  title={Design and implementation of cluster-based platform for Remote Sensing Information Computation}, 
  year={2011},
  volume={4},
  number={},
  pages={2122-2125},
  abstract={Remote Sensing Information Computation has features of large amount of image data and complex algorithms, many applications require real-time response, but mainstream computers are often unable to meet their performance requirements. Regarding to this problem, a cluster-based computing platform for remote sensing information computation was designed and implemented through interconnecting the existing computing devices by network, and in support of MPI and other communication software, cluster management module which enables node management, task management, and real-time monitoring and other functions was developed. On this basis, the parallel algorithms of re-projection, mean-shift multi-scale segmentation were achieved; the efficiency and performance of the cluster were tested. Experiment results show that the system can significantly improve the efficiency of remote sensing information computation with a low price.},
  keywords={},
  doi={10.1109/ICCSNT.2011.6182396},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{6190250,
  author={Kim, Seung-Jun and Jain, Nitin and Giannakis, Georgios B. and Forero, Pedro A.},
  booktitle={2011 Conference Record of the Forty Fifth Asilomar Conference on Signals, Systems and Computers (ASILOMAR)}, 
  title={Joint link learning and cognitive radio sensing}, 
  year={2011},
  volume={},
  number={},
  pages={1415-1419},
  abstract={Novel cooperative spectrum sensing algorithms for cognitive radios (CRs) are developed, which can blindly learn the channel gains between CRs and licensed primary users (PUs), while jointly detecting active PU transmitters at each time instant. A dictionary learning approach is taken to decompose the received signal energy samples per CR into linear combinations of channel gains and PU transmit-powers, up to scaling ambiguity. In addition to a batch baseline algorithm, an efficient online implementation that can track slow variation of channel gains is developed, as well as a distributed alternative, which requires only local message passing among neighbors in CR networks. Numerical tests verify the proposed design.},
  keywords={},
  doi={10.1109/ACSSC.2011.6190250},
  ISSN={1058-6393},
  month={Nov},}
@INPROCEEDINGS{6190321,
  author={Lee, Sang Hyun and Shamaiah, Manohar and Vishwanath, Sriram and Vikalo, Haris},
  booktitle={2011 Conference Record of the Forty Fifth Asilomar Conference on Signals, Systems and Computers (ASILOMAR)}, 
  title={A message-passing algorithm for spectrum access in cognitive radio relay networks}, 
  year={2011},
  volume={},
  number={},
  pages={1753-1757},
  abstract={This work addresses the spectrum access problem in cognitive radio relay networks. In our setup, primary users allow secondary users access to the channel (spectrum) as long as they agree to relay primary users' data in addition to their own. We desire to maximize the network usage by determining the best configuration of matching between primary users and secondary users. This problem can be formulated in a form similar to maximum weighted matching. Given this formulation, we develop an algorithm for this problem using affinity propagation that is fully distributed. We test its performance and demonstrate convergence.},
  keywords={},
  doi={10.1109/ACSSC.2011.6190321},
  ISSN={1058-6393},
  month={Nov},}
@INPROCEEDINGS{6190029,
  author={Mardani, Morteza and Mateos, Gonzalo and Giannakis, Georgios B.},
  booktitle={2011 Conference Record of the Forty Fifth Asilomar Conference on Signals, Systems and Computers (ASILOMAR)}, 
  title={Unveiling anomalies in large-scale networks via sparsity and low rank}, 
  year={2011},
  volume={},
  number={},
  pages={403-407},
  abstract={In the backbone of large-scale networks, traffic flows experience abrupt unusual changes which can result in congestion, and limit the extent to which end-user quality of service requirements are met. Diagnosing such traffic volume anomalies is a crucial task towards engineering the traffic in the network. This is challenging however, since the available data are the superposition of unobservable origin-to-destination (OD) flows per link. Leveraging the low intrinsic-dimensionality of OD flows and the sparse nature of anomalies, a convex program is formulated to unveil anomalies across flows and time. A centralized solver is developed using the proximal gradient algorithm, which offers provable iteration complexity guarantees. An equivalent nonconvex but separable criterion enables in-network processing of link-load measurements, when optimized via the alternating-direction method of multipliers. The novel distributed iterations entail reduced-complexity local tasks, and affordable message passing between neighboring nodes. Interestingly, under mild conditions the distributed algorithm approaches its centralized counterpart. Numerical tests with synthetic and real network data corroborate the effectiveness of the novel scheme.},
  keywords={},
  doi={10.1109/ACSSC.2011.6190029},
  ISSN={1058-6393},
  month={Nov},}
@INPROCEEDINGS{6206896,
  author={Chia-Lu Ho},
  booktitle={International Conference on Advanced Infocom Technology 2011 (ICAIT 2011)}, 
  title={Particle swarm optimization applied to designing LDPC codes for wireless communications}, 
  year={2011},
  volume={},
  number={},
  pages={1-5},
  abstract={A particle swarm optimization (PSO) method is applied to finding the optimum degree distributions of check and bit nodes of an irregular low-density parity-check (LDPC) code. This population based optimization method can efficiently reduce the number of evaluations of the computation demanding fitness function. We also show how to find the thresholds under message-passing (MP) algorithm.},
  keywords={},
  doi={10.1049/cp.2011.1088},
  ISSN={},
  month={July},}
@ARTICLE{8155720,
  author={Rodríguez, Gabriel and Martín, María J. and González, Patricia and Touriño, Juan},
  journal={The Computer Journal}, 
  title={Analysis of Performance-impacting Factors on Checkpointing Frameworks: The CPPC Case Study}, 
  year={2011},
  volume={54},
  number={11},
  pages={1821-1837},
  abstract={This paper focuses on the performance evaluation of Compiler for Portable Checkpointing (CPPC), a tool for the checkpointing of parallel message-passing applications. Its performance and the factors that impact it are transparently and rigorously identified and assessed. The tests were performed on a public supercomputing infrastructure, using a large number of very different applications and showing excellent results in terms of performance and effort required for integration into user codes. Statistical analysis techniques have been used to better approximate the performance of the tool. Quantitative and qualitative comparisons with other rollback-recovery approaches to fault tolerance are also included. All these data and comparisons are then discussed in an effort to extract meaningful conclusions about the state-of-the-art and future research trends in the rollback-recovery field.},
  keywords={},
  doi={10.1093/comjnl/bxr018},
  ISSN={1460-2067},
  month={Nov},}
@ARTICLE{5733353,
  author={Baldoni, Roberto and Bonomi, Silvia and Raynal, Michel},
  journal={IEEE Transactions on Parallel and Distributed Systems}, 
  title={Implementing a Regular Register in an Eventually Synchronous Distributed System Prone to Continuous Churn}, 
  year={2012},
  volume={23},
  number={1},
  pages={102-109},
  abstract={Due to their capability to hide the complexity generated by the messages exchanged between processes, shared objects are one of the main abstractions provided to developers of distributed applications. Implementations of such objects, in modern distributed systems, have to take into account the fact that almost all services, implemented on top of distributed infrastructures, are no longer fully managed due to either their size or their maintenance cost. Therefore, these infrastructures exhibit several autonomic behaviors in order to, for example, tolerate failures and continuous arrival and departure of nodes (churn phenomenon). Among all the shared objects, the register object is a fundamental one. Several protocols have been proposed to build fault resilient registers on top of message-passing system, but, unfortunately, failures are not the only challenge in modern distributed systems and new issues arise in the presence of churn. This paper addresses the construction of a multiwriter/multireader regular register in an eventually synchronous distributed system affected by the continuous arrival/departure of participants. In particular, a general protocol implementing a regular register is proposed and feasibility conditions associated with the arrival and departure of the processes are given. The protocol is proved correct under the assumption that a constraint on the churn is satisfied.},
  keywords={},
  doi={10.1109/TPDS.2011.97},
  ISSN={1558-2183},
  month={Jan},}
@ARTICLE{6018324,
  author={Zhang, Xinmiao and Cai, Fang and Lin, Shu},
  journal={IEEE Transactions on Very Large Scale Integration (VLSI) Systems}, 
  title={Low-Complexity Reliability-Based Message-Passing Decoder Architectures for Non-Binary LDPC Codes}, 
  year={2012},
  volume={20},
  number={11},
  pages={1938-1950},
  abstract={Non-binary low-density parity-check (NB-LDPC) codes can achieve better error-correcting performance than their binary counterparts at the cost of higher decoding complexity when the codeword length is moderate. The recently developed iterative reliability-based majority-logic NB-LDPC decoding has better performance-complexity tradeoffs than previous algorithms. This paper first proposes enhancement schemes to the iterative hard reliability-based majority-logic decoding (IHRB-MLGD). Compared to the IHRB algorithm, our enhanced (E-)IHRB algorithm can achieve significant coding gain with small hardware overhead. Then low-complexity partial-parallel NB-LDPC decoder architectures are developed based on these two algorithms. Many existing NB-LDPC code construction methods lead to quasi-cyclic or cyclic codes. Both types of codes are considered in our design. Moreover, novel schemes are developed to keep a small proportion of messages in order to reduce the memory requirement without causing noticeable performance loss. In addition, a shift-message structure is proposed by using memories concatenated with variable node units to enable efficient partial-parallel decoding for cyclic NB-LDPC codes. Compared to previous designs based on the Min-max decoding algorithm, our proposed decoders have at least tens of times lower complexity with moderate coding gain loss.},
  keywords={},
  doi={10.1109/TVLSI.2011.2164951},
  ISSN={1557-9999},
  month={Nov},}
@ARTICLE{6062675,
  author={Wang, Guojian and Tao, Linmi and Di, Huijun and Ye, Xiyong and Shi, Yuanchun},
  journal={IEEE Transactions on Industrial Informatics}, 
  title={A Scalable Distributed Architecture for Intelligent Vision System}, 
  year={2012},
  volume={8},
  number={1},
  pages={91-99},
  abstract={The complexity of intelligent computer vision systems demands novel system architectures that are capable of integrating various computer vision algorithms into a working system with high scalability. The real-time applications of human-centered computing are based on multiple cameras in current systems, which require a transparent distributed architecture. This paper presents an application-oriented service share model for the generalization of vision processing. Based on the model, a vision system architecture is presented that can readily integrate computer vision processing and make application modules share services and exchange messages transparently. The architecture provides a standard interface for loading various modules and a mechanism for modules to acquire inputs and publish processing results that can be used as inputs by others. Using this architecture, a system can load specific applications without considering the common low-layer data processing. We have implemented a prototype vision system based on the proposed architecture. The latency performance and 3-D track function were tested with the prototype system. The architecture is scalable and open, so it will be useful for supporting the development of an intelligent vision system, as well as a distributed sensor system.},
  keywords={},
  doi={10.1109/TII.2011.2173945},
  ISSN={1941-0050},
  month={Feb},}
@ARTICLE{6136741,
  author={Ren, Da Qi and Bracken, Eric and Polstyanko, Sergey and Lambert, Nancy and Suda, Reiji and Giannacopulos, Dennis D.},
  journal={IEEE Transactions on Magnetics}, 
  title={Power Aware Parallel 3-D Finite Element Mesh Refinement Performance Modeling and Analysis With CUDA/MPI on GPU and Multi-Core Architecture}, 
  year={2012},
  volume={48},
  number={2},
  pages={335-338},
  abstract={Software power performance tuning handles the critical design constraints of software running on hardware platforms composed of large numbers of power-hungry components. The power dissipation of a Single Program/Instruction Multiple Data (SPMD/SIMD) computation such as finite element method (FEM) mesh refinement is highly dependent on the underlying algorithm and the power-consuming features of hardware Processing Elements (PE). This contribution presents a practical methodology for modeling and analyzing the power performance of parallel 3-D FEM mesh refinement on CUDA/MPI architecture based on detailed software prototypes and power parameters in order to predict the power functionality and runtime behavior of the algorithm, optimize the program design and thus achieve the best power efficiency. In detail, we have proposed approaches for GPU parallelization, dynamic CPU frequency scaling and dynamic load scheduling among PEs. The performance improvement of our designs has been demonstrated and the results have been validated on a real multi-core and GPU cluster.},
  keywords={},
  doi={10.1109/TMAG.2011.2177814},
  ISSN={1941-0069},
  month={Feb},}
@ARTICLE{6151757,
  author={Montorsi, Guido},
  journal={IEEE Communications Letters}, 
  title={Analog Digital Belief Propagation}, 
  year={2012},
  volume={16},
  number={7},
  pages={1106-1109},
  abstract={We introduce a message passing belief propagation (BP) algorithm for factor graph over linear models that uses messages in the form of Gaussian-like distributions. With respect to the regular Gaussian BP, the proposed algorithm adds two operations to the model, namely the wrapping and the discretization of variables. This addition requires the derivation of proper modifications of message representations and updating rules at the BP nodes. We named the new algorithm Analog-Digital-Belief-Propagation (ADBP). The ADBP allows to construct iterative decoders for mod-M ring encoders that have a complexity independent from the size M of the alphabets, thus yielding efficient decoders for very high spectral efficiencies.},
  keywords={},
  doi={10.1109/LCOMM.2012.020712.112133},
  ISSN={1558-2558},
  month={July},}
@ARTICLE{6153324,
  author={Wymeersch, Henk and Penna, Federico and Savic, Vladimir},
  journal={IEEE Transactions on Wireless Communications}, 
  title={Uniformly Reweighted Belief Propagation for Estimation and Detection in Wireless Networks}, 
  year={2012},
  volume={11},
  number={4},
  pages={1587-1595},
  abstract={In this paper, we propose a new inference algorithm, suitable for distributed processing over wireless networks. The algorithm, called uniformly reweighted belief propagation (URW-BP), combines the local nature of belief propagation with the improved performance of tree-reweighted belief propagation (TRW-BP) in graphs with cycles. It reduces the degrees of freedom in the latter algorithm to a single scalar variable, the uniform edge appearance probability ρ. We provide a variational interpretation of URW-BP, give insights into good choices of ρ, develop an extension to higher-order potentials, and complement our work with numerical performance results on three inference problems in wireless communication systems: spectrum sensing in cognitive radio, cooperative positioning, and decoding of a low-density parity-check (LDPC) code.},
  keywords={},
  doi={10.1109/TWC.2012.021412.111509},
  ISSN={1558-2248},
  month={April},}
@INPROCEEDINGS{6169539,
  author={Achour, Sami and Nasri, Wahid},
  booktitle={2012 20th Euromicro International Conference on Parallel, Distributed and Network-based Processing}, 
  title={A Performance Prediction Approach for MPI Routines on Multi-clusters}, 
  year={2012},
  volume={},
  number={},
  pages={125-129},
  abstract={Performance is one of the key features of parallel and distributed computing systems. For that reason, a significant research effort was invested in the development of approaches in the area of performance modeling and prediction. Since many parallel applications from scientific computing use MPI communication operations to distribute or collect data, we present in this paper a novel (off-line) approach that addresses the performance prediction of MPI routines in multi-clusters platforms. The main objective of this approach is to predict accurately and efficiently the performance of a given routine. Our solution is based principally on models for point to point (P2P) MPI routines which are obtained after a short profiling procedure. Since collective communication routines are composed of P2P routines, the performance prediction of the formers is done on the basis of a rapid emulation of these routines and on an evaluation of P2P routines models. Experimental results obtained on a grid platform demonstrated the interest of the proposed approach.},
  keywords={},
  doi={10.1109/PDP.2012.92},
  ISSN={2377-5750},
  month={Feb},}
@INPROCEEDINGS{6169533,
  author={Kharbas, Kishor and Kim, Donghoon and Hoefler, Torsten and Mueller, Frank},
  booktitle={2012 20th Euromicro International Conference on Parallel, Distributed and Network-based Processing}, 
  title={Assessing HPC Failure Detectors for MPI Jobs}, 
  year={2012},
  volume={},
  number={},
  pages={81-88},
  abstract={Reliability is one of the challenges faced by exascale computing. Components are poised to fail during large-scale executions given current mean time between failure (MTBF) projections. To cope with failures, resilience methods have been proposed as explicit or transparent techniques. For the latter techniques, this paper studies the challenge of fault detection. This work contributes a study on generic fault detection capabilities at the MPI level and beyond. The objective is to assess different detectors, which ultimately may or may not be implemented within the application's runtime layer. A first approach utilizes a periodic liveness check while a second method promotes sporadic checks upon communication activities. The contributions of this paper are two-fold: (a) We provide generic interposing of MPI applications for fault detection. (b) We experimentally compare periodic and sporadic methods for liveness checking. We show that the sporadic approach, even though it imposes lower bandwidth requirements and utilizes lower frequency checking, results in equal or worse application performance than a periodic liveness test for larger number of nodes. We further show that performing liveness checks in separation from MPI applications results in lower overhead than inter-positioning, as demonstrated by our prototypes. Hence, we promote separate periodic fault detection as the superior approach for fault detection.},
  keywords={},
  doi={10.1109/PDP.2012.11},
  ISSN={2377-5750},
  month={Feb},}
@INPROCEEDINGS{6169537,
  author={Bohm, Swen and Engelmann, Christian},
  booktitle={2012 20th Euromicro International Conference on Parallel, Distributed and Network-based Processing}, 
  title={File I/O for MPI Applications in Redundant Execution Scenarios}, 
  year={2012},
  volume={},
  number={},
  pages={112-119},
  abstract={As multi-petascale and exa-scale high-performance computing (HPC) systems inevitably have to deal with a number of resilience challenges, such as a significant growth in component count and smaller circuit sizes with lower circuit voltages, redundancy may offer an acceptable level of resilience that traditional fault tolerance techniques, such as checkpoint/restart, do not. Although redundancy in HPC is quite controversial due to the associated cost for redundant components, the constantly increasing number of cores-per-processor is tilting this cost calculation toward a system design where computation, such as for redundancy, is much cheaper and communication, needed for checkpoint/restart, is much more expensive. Recent research and development activities in redundancy for Message Passing Interface (MPI) applications focused on availability/reliability models and replication algorithms. This paper takes a first step toward solving an open research problem associated with running a parallel application redundantly, which is file I/O under redundancy. The approach intercepts file I/O calls made by a redundant application to employ coordination protocols that execute file I/O operations in a redundancy-oblivious fashion when accessing a node-local file system, or in a redundancy-aware fashion when accessing a shared networked file system. A proof-of concept prototype is presented and a number of coordination protocols are described and evaluated. The results show the performance impact for redundantly accessing a shared networked file system, but also demonstrate the capability to regain performance by utilizing MPI communication between replicas and parallel file I/O.},
  keywords={},
  doi={10.1109/PDP.2012.22},
  ISSN={2377-5750},
  month={Feb},}
@INPROCEEDINGS{6169555,
  author={Makassikis, Constantinos and Vialle, Stephane and Warin, Xavier},
  booktitle={2012 20th Euromicro International Conference on Parallel, Distributed and Network-based Processing}, 
  title={FT-GReLoSSS: A Skeletal-Based Approach towards Application Parallelization and Low-Overhead Fault Tolerance}, 
  year={2012},
  volume={},
  number={},
  pages={237-244},
  abstract={FT-GReLoSSS (FTG) is a C++/MPI framework to ease the development of fault-tolerant parallel applications belonging to a SPMD family termed GReLoSSS. The originality of FTG is to rely on the MoLOToF programming model principles to facilitate the addition of an efficient checkpoint-based fault tolerance at the application level. Main features of MoLOToF encompass a structured application development based on fault-tolerant "skeletons" and lay emphasis on collaborations. The latter exist between the programmer, the framework and the underlying runtime middleware/environment. Together with the structured approach they contribute into achieving reduced checkpoint sizes, as well as reduced checkpoint and recovery overhead at runtime. This paper introduces the main principles of MoLOToF and the design of the FTG framework. To properly assess the framework's ease of use for a programmer as well as fault tolerance efficiency, a series of benchmarks were conducted up to 128 nodes on a multicore PC cluster. These benchmarks involved an existing parallel financial application for gas storage valuation, originally developed in collaboration with EDF company, and a rewritten version which made use of the FTG framework and its features. Experiments results display low-overhead compared to existing system-level counterparts.},
  keywords={},
  doi={10.1109/PDP.2012.18},
  ISSN={2377-5750},
  month={Feb},}
@INPROCEEDINGS{6176471,
  author={Deniz, Etem and Sen, Alper and Holt, Jim},
  booktitle={2012 Design, Automation & Test in Europe Conference & Exhibition (DATE)}, 
  title={Verification coverage of embedded multicore applications}, 
  year={2012},
  volume={},
  number={},
  pages={252-255},
  abstract={Verification of embedded multicore applications is crucial as these applications are deployed in many safety critical systems. Verification task is complicated by concurrency inherent in such applications. We use mutation testing to obtain a quantitative verification coverage metric for mullticore applications developed using the new Multicore Communication API (MCAPI) standard. MCAPI is a lightweight API that targets heterogeneous multicore embedded systems. We developed a mutation coverage tool and performed several experiments on MCAPI applications. Our experiments show that mutation coverage is useful in measuring and improving the quality of the test suites and ultimately the quality of the multicore application.},
  keywords={},
  doi={10.1109/DATE.2012.6176471},
  ISSN={1558-1101},
  month={March},}
@INPROCEEDINGS{6175239,
  author={Columbus, C. Christopher and Simon, Sishaj P},
  booktitle={2012 International Conference on Power, Signals, Controls and Computation}, 
  title={A parallel ABC for security constrained economic dispatch using shared memory model}, 
  year={2012},
  volume={},
  number={},
  pages={1-6},
  abstract={This paper proposes security constrained economic power dispatch (SCED) of the generators using parallel artificial bee colony (PABC) algorithm for electricity markets. The proposed non-linear optimization problem considers simultaneous minimization of deviations from scheduled transactions and minimization of fuel cost of the generators. The problem is formulated as a constrained optimization problem in a way that insures a secure-economic system operation. Incorporation of economic load dispatch (ELD) with voltages and lineflow constraints significantly relieves the assumptions imposed on the optimized objective function. The proposed approach has been tested on two representative systems, i.e. IEEE 14 bus and IEEE 30 bus systems respectively. Here, the message passing interface based technique is used in the PABC algorithm in a shared memory model. The time complexity and the solution quality with respect to the number of processors in a cluster are thoroughly analyzed.},
  keywords={},
  doi={10.1109/EPSCICON.2012.6175239},
  ISSN={},
  month={Jan},}
@INPROCEEDINGS{6181824,
  author={Declercq, David and Vasić, Bane and Planjery, Shiva K. and Li, Erbao},
  booktitle={2012 Information Theory and Applications Workshop}, 
  title={Finite alphabet iterative decoders approaching maximum likelihood performance on the Binary Symmetric Channel}, 
  year={2012},
  volume={},
  number={},
  pages={23-32},
  abstract={We introduce a generic approach for improving the guaranteed error correction capability of regular low-density parity check codes. The method relies on operating (in serial or in parallel) a set of finite alphabet iterative decoders. The message passing update rules are judiciously chosen to ensure that decoders have different dynamics on a specific finite-length code. The idea is that for the Binary Symmetric Channel, if some error pattern cannot be corrected by one particular decoder, there exists in the set of decoders, another decoder which can correct this pattern. We show how to select a plurality of message update rules so that the set of decoders can collectively correct error patterns on the dominant trapping sets. We also show that a set of decoders with dynamic re-initializations can approach the performance of maximum likelihood decoding for finite-length regular column-weight three codes.},
  keywords={},
  doi={10.1109/ITA.2012.6181824},
  ISSN={},
  month={Feb},}
@INPROCEEDINGS{6188190,
  author={Li, Peizheng and Cao, Yizhen},
  booktitle={2012 International Conference on Computer Science and Electronics Engineering}, 
  title={Research and Implementation of Jacobi Algorithm Based on MPI with Checkerboard Decomposition}, 
  year={2012},
  volume={3},
  number={},
  pages={166-169},
  abstract={In order to achieve parallel algorithm ported from serial algorithm, this paper proposes a simplified model based on MPI checkerboard decomposition. The process of analysis, design and implementation of parallel program will be speed up, by emphasizing data and calculation decomposition. Jacobi algorithm is used as an example to explain this simplified model. The example results show that simplified model is more suitable for implementation of parallel program than Foster's task/channel model, and checkerboard decomposition has better speedup than row/column decomposition. Furthermore, this simplified model applies to design not only Jacobi algorithm but also other parallel algorithms based on checkerboard decomposition.},
  keywords={},
  doi={10.1109/ICCSEE.2012.312},
  ISSN={},
  month={March},}
@INPROCEEDINGS{6189871,
  author={Andalon-Garcia, Irma R. and Chavoya, Arturo},
  booktitle={CONIELECOMP 2012, 22nd International Conference on Electrical Communications and Computers}, 
  title={Performance comparison of three topologies of the island model of a parallel genetic algorithm implementation on a cluster platform}, 
  year={2012},
  volume={},
  number={},
  pages={1-6},
  abstract={Parallel genetic algorithms (PGAs) have been used to improve the potential of genetic algorithms, which are efficient search techniques that have been employed in producing satisfactory solutions to optimization problems in which the application of standard techniques is not feasible or recommended. We implemented three communication topologies of the island model of a PGA, with the aim of analyzing the performance of the migration models applied. The topologies implemented were the star, the unidirectional ring and the bidirectional ring topologies. The implementation was developed on a cluster platform through the use of the standard Message Passing Interface (MPI) library. In order to test the performance of the algorithm with its variants, well-known benchmark functions were used.},
  keywords={},
  doi={10.1109/CONIELECOMP.2012.6189871},
  ISSN={},
  month={Feb},}
@ARTICLE{6195029,
  author={Ueng, Yeong-Luh and Wang, Yu-Luen and Kan, Li-Sheng and Yang, Chung-Jay and Su, Yung-Hsiang},
  journal={IEEE Transactions on Signal Processing}, 
  title={Jointly Designed Architecture-Aware LDPC Convolutional Codes and Memory-Based Shuffled Decoder Architecture}, 
  year={2012},
  volume={60},
  number={8},
  pages={4387-4402},
  abstract={In this paper, we jointly design architecture-aware (AA) low-density parity-check convolutional codes (LDPC-CCs) and the associated memory-based decoder architecture based on shuffled message-passing decoding (MPD). We propose a method for constructing AA-LDPC-CCs that can facilitate the design of a memory-based shuffled decoder using parallelization in both iteration and node dimensions. Through the use of shuffled MPD, the number of base processors and, hence, the decoder area is significantly reduced, since a fewer number of iterations is required in order to achieve a desired error performance. In addition, the use of memory instead of registers minimizes the implementation cost of each base processor. In the memory-based decoder, collisions in memory access can be avoided and the difficulty in exchanging information between iterations (processors) is overcome by using simple permutation networks. To demonstrate the feasibility of the proposed techniques, we constructed a time-varying (479, 3, 6) AA-LDPC-CC and implemented its associated shuffled decoder using a 90-nm CMOS process. This decoder comprises 11 processors, occupies an area of 5.36 , and achieves an information throughput of 1.025 Gbps at a clock frequency of 256.4 MHz based on post-layout results.},
  keywords={},
  doi={10.1109/TSP.2012.2197749},
  ISSN={1941-0476},
  month={Aug},}
@INPROCEEDINGS{6205497,
  author={Sait, Sadiq M. and Al-Shaikh, Raed},
  booktitle={2012 UKSim 14th International Conference on Computer Modelling and Simulation}, 
  title={Evaluating Qlogic's Dispersive Routing on High Performance Clusters}, 
  year={2012},
  volume={},
  number={},
  pages={499-504},
  abstract={As high performance clusters (HPC) expand in terms of nodes count and processing cores, internet work congestion and bottlenecks at the host and network levels become one of the main concerns in clustered computing. Considerably, the Infiniband Architecture (IBA) Specification provides six different routing algorithms to better optimize the HPC internet work traffic. In this paper, we present these algorithms and then evaluate QLogic's dispersive routing using a large-scale Infiniband cluster, equipped with Intel's latest Westmere processor. The paper presents the cluster configuration and evaluates its performance using High Performance LINPACK (HPL) and Intel MPI (IMB) benchmarks. Our results show that whilst the default Min Hop algorithm suits most of the serial and point-to-point benchmarks, the dispersive routing algorithm exhibits improved performance when running specific computational and parallel transfer routines.},
  keywords={},
  doi={10.1109/UKSim.2012.75},
  ISSN={},
  month={March},}
@INPROCEEDINGS{6217432,
  author={Jin, Hui and Ke, Tao and Chen, Yong and Sun, Xian-He},
  booktitle={2012 12th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing (ccgrid 2012)}, 
  title={Checkpointing Orchestration: Toward a Scalable HPC Fault-Tolerant Environment}, 
  year={2012},
  volume={},
  number={},
  pages={276-283},
  abstract={Check pointing is widely used in technical computing. However, the overhead of check pointing is a subject of increasing in concern in recent years, especially for large-scale parallel computer systems. In these systems, check pointing generates a huge number of concurrent I/O writes. The burst of writes plus the worsening I/O-wall problem often leads to network and I/O congestion, and makes the overall system performance painfully slow. Recognizing contention as a dominant performance factor, in this paper we propose a systematic approach named check pointing orchestration to reduce write contention, which combines the marshaling of concurrent checkpoint requests and the adopting of vertical data access in coordination. A prototype of the proposed check pointing orchestration approach has been implemented at the system-level under Open MPI over the PVFS2 file system. Extensive experiments based on NPB benchmarks have been conducted to verify the design and implementation. Experimental results show that check pointing orchestration reduced the check pointing cost at a degree of more than 30%. Check pointing cost was halved for 4 out of 5 the C class NPB benchmarks.},
  keywords={},
  doi={10.1109/CCGrid.2012.61},
  ISSN={},
  month={May},}
@INPROCEEDINGS{6217423,
  author={Ge, Rong and Feng, Xizhou and Sun, Xian-He},
  booktitle={2012 12th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing (ccgrid 2012)}, 
  title={SERA-IO: Integrating Energy Consciousness into Parallel I/O Middleware}, 
  year={2012},
  volume={},
  number={},
  pages={204-211},
  abstract={Improving energy efficiency is a primary concern in high performance computing system design. Because I/O accesses account for a large portion of the execution time for data intensive applications, energy-aware parallel I/O subsystems are critical for addressing challenges related to HPC energy efficiency. In this paper, we present an energy-conscious parallel I/O middleware approach that combines runtime I/O access interception and Dynamic Voltage and Frequency Scaling capability available on modern processors to intelligently schedule the system's power-performance mode for energy savings. We implement this approach into SERA-IO, an MPI-IO based middleware to enable energy consciousness for I/O intensive applications. Experimental evaluations conducted on real systems using multiple parallel I/O benchmarks show that SERA-IO can reduce system energy by 9% to 28% without decreasing application performance. With the emerging of large-scale data intensive applications and ever larger and more complex parallel computing systems, intelligent, energy conscious software and runtime systems such as SERA-IO are critical for the success of future high-end computing.},
  keywords={},
  doi={10.1109/CCGrid.2012.39},
  ISSN={},
  month={May},}
@INPROCEEDINGS{6217445,
  author={Bao, Bin and Ding, Chen and Gao, Yaoqing and Archambault, Roch},
  booktitle={2012 12th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing (ccgrid 2012)}, 
  title={Delta Send-Recv for Dynamic Pipelining in MPI Programs}, 
  year={2012},
  volume={},
  number={},
  pages={384-392},
  abstract={Pipelining is necessary for efficient do-across parallelism but the use is difficult to automate because it requires send-receive analysis and loop blocking in both sender and receiver code. The blocking factor is statically chosen. This paper presents a new interface called delta send-recv. Through compiler and run-time support, it enables dynamic pipelining. In program code, the interface is used to mark the related computation and communication. There is no need to restructure the computation code or compose multiple messages. At run time, the message size is dynamically determined, and multiple pipelines are chained among all tasks that participate in the delta communication. The new system is tested on kernel and reduced NAS benchmarks to show that it simplifies message-passing programming and improves program performance.},
  keywords={},
  doi={10.1109/CCGrid.2012.113},
  ISSN={},
  month={May},}
@INPROCEEDINGS{6217505,
  author={Bland, Wesley},
  booktitle={2012 12th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing (ccgrid 2012)}, 
  title={Enabling Application Resilience with and without the MPI Standard}, 
  year={2012},
  volume={},
  number={},
  pages={746-751},
  abstract={As recent research has demonstrated, it is becoming a necessity for large scale applications to have the ability to tolerate process failure during an execution. As the number of processes increases, checkpoint/restart fault tolerance approaches requiring large concurrent state check pointing become untenable and radically new methods to address fault tolerance are needed. This work addresses these challenges by proposing a novel approach to a minimalistic fault discovery and management model. Such a model allows application to run to completion despite fail-stop failures. As a proof of concept, in addition to the proposed fault tolerance model, an implementation in the context of the Open MPI library is provided, evaluated and analyzed.},
  keywords={},
  doi={10.1109/CCGrid.2012.25},
  ISSN={},
  month={May},}
@INPROCEEDINGS{6217490,
  author={Kulkarni, Kedar and Gadre, Geetanjali},
  booktitle={2012 12th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing (ccgrid 2012)}, 
  title={Analyzing Effect of Network Processor's Cache Dependent Parameter on MPI Broadcast Performance}, 
  year={2012},
  volume={},
  number={},
  pages={697-698},
  abstract={For cluster based parallel computing, optimization at every layer of Network Protocol to improve the performance is an ongoing process. Use of dedicated Network Processor has become good choice to cope up with continuous and rapid growth of network link speed. GPP or RISC can be used for packet processing, because of their higher processing speed and flexibility. To improve overall performance, it is necessary to program Network Processor by making efficient use of its resources. In our experiment, we have formed Hot Connection pool that is heavily dependent on Network Processor cache. Our experimental result shows performance improvement when pool value is chosen proportionate to cache size of Network Processor.},
  keywords={},
  doi={10.1109/CCGrid.2012.97},
  ISSN={},
  month={May},}
@INPROCEEDINGS{6217783,
  author={Shayovitz, Shachar and Raphaeli, Dan},
  booktitle={2012 5th International Symposium on Communications, Control and Signal Processing}, 
  title={Improved message passing algorithm for phase noise channels using optimal approximation of Tikhonov mixtures}, 
  year={2012},
  volume={},
  number={},
  pages={1-4},
  abstract={In this paper we propose an improved message passing algorithm for the phase noise channel. We assume LDPC or Turbo coding and utilize their soft decisions to perform joint detection and estimation of the phase noise. We use the directional statistics framework to approximate the messages of the Sum & Product Algorithm to a Tikhonov distribution. Finally, we show simulation results of the proposed algorithm and show its superiority over some of the current state of the art algorithms.},
  keywords={},
  doi={10.1109/ISCCSP.2012.6217783},
  ISSN={},
  month={May},}
@INPROCEEDINGS{6221766,
  author={Wu, Peng and Li, Fangmin},
  booktitle={2012 IEEE International Conference on Information Science and Technology}, 
  title={The pyroelectric sensor based system: Human tracking and self-calibration scheme}, 
  year={2012},
  volume={},
  number={},
  pages={839-846},
  abstract={The paper presents a distributed human tracking system based on pyroelectric sensors. The developing process of the system mainly includes two aspects: distributed tracking algorithm and self-calibration scheme. In the tracking algorithm, a distributed information filter is constructed with joint probabilistic data association (JPDA) and consensus method. The self-calibration utilizes Kullback-Leibler divergences to construct objective function and information projection to realize calibration process. A distributed message passing scheme is developed among neighboring sensor nodes to get distributed calibration. The simulation and experimental results verified the validity of tracking algorithm and improved tracking performance after using the proposed distributed self-calibration.},
  keywords={},
  doi={10.1109/ICIST.2012.6221766},
  ISSN={2164-4357},
  month={March},}
@INPROCEEDINGS{6223159,
  author={Zhang, Guoyi and Fang, Minghui and Li, Chuan and Ruan, Xiangwei},
  booktitle={2012 International Conference on Systems and Informatics (ICSAI2012)}, 
  title={Parallel SAR imaging on the KD-50 heterogeneous computer system}, 
  year={2012},
  volume={},
  number={},
  pages={927-931},
  abstract={With the increased requirements on the precision of image products, the parallel imaging of high resolution SAR data has been receiving much more concerns nowadays. However, many existed parallel algorithms haven't given adequate attentions to both the architecture of a certain parallel computer and the computational features (e.g. matrix transposition) of a SAR imaging algorithm, which couldn't reach higher parallel efficiency. In this paper, strategies for parallel SAR imaging on the KD-50 heterogeneous computer system were discussed, and a CSA based parallel SAR imaging algorithm to harness the features of KD-50 hardware architecture was presented. The algorithm was implemented in a message passing interface (MPI) plus OpenMP specifications based hybrid programming environment, and tested by a block size of 65536 × 32768 simulative SAR data. Both the theoretical analysis and test result show that the algorithm had a good performance, which can cut down the time-consuming from 7080(s) to nearly 536(s).},
  keywords={},
  doi={10.1109/ICSAI.2012.6223159},
  ISSN={},
  month={May},}
@INPROCEEDINGS{6236592,
  author={Sweilam, N. H. and Moharram, H. M. and Ahmed, Sameh},
  booktitle={2012 8th International Conference on Informatics and Systems (INFOS)}, 
  title={On the parallel iterative finite difference algorithm for 2-D Poisson's equation with MPI cluster}, 
  year={2012},
  volume={},
  number={},
  pages={MM-78-MM-85},
  abstract={In this paper, a parallel iterative finite difference method (PIFD) for solving 2D Poisson's equation on a distributed system using Message Passing Interface (MPI) is investigated. This method is based on the domain decomposition method, where the 2D domain is divided into multiple sub-domains using horizontal and/or vertical axis depending on the available number of computer nodes. For interior points Poisson's equation is solved implicitly by four iterative schemes in combining with the boundary conditions. At the interface points of interior subdomains, Poisson's equation is solved by explicit iterative schemes. The proposed approach fulfills the suitability for the implementation on Linux PC cluster through the minimization of inter-process communication by restricting the exchange of data to the interface between the sub-domains. To examine the efficiency and accuracy of the iterative algorithm, several numerical experiments using different number of nodes of the Linux PC cluster are tested. The performance metrics clearly show the benefit of using the proposed approach on the Linux PC cluster in terms of execution time reduction and speedup with respect to the sequential running in a single PC.},
  keywords={},
  doi={},
  ISSN={},
  month={May},}
@INPROCEEDINGS{6240667,
  author={Chitsaz, Behzad and Razzazi, Mohammadreza},
  booktitle={2012 Proceedings of the 35th International Convention MIPRO}, 
  title={Non-blocking roll-forward recovery for message passing systems}, 
  year={2012},
  volume={},
  number={},
  pages={339-344},
  abstract={Due to the message transmission between processes in a distributed system, an error in a process might be propagated to another via faulty messages, which causes a global failure. In the absence of built-in fault detection methods, rollback recovery approach is not useful. To avoid error propagation and rollback overhead, roll-forward recovery schemes based on redundancy techniques such as N-Version Programming techniques have been presented. The disadvantage of using these schemes is that they need to block the receiver process until each received message is confirmed by the other version of the process, which results in high time overhead. In the case of variant response latencies, consisting of processing time and message transmission delay, these techniques would not be efficient. In this paper, a non-blocking roll-forward recovery approach with some changes to duplex system is proposed. This approach does not avoid fault propagation. But it performs an additional test using a copy of a failed module version to discover faulty process and replace its state with the fault-free process and mask the faults which are propagated to other processes; so it does not need to block processing or message transmission in any phases of the process. This scheme has lower execution time than existing roll-forward techniques.},
  keywords={},
  doi={},
  ISSN={},
  month={May},}
@INPROCEEDINGS{6240668,
  author={Chitsaz, Behzad and Razzazi, Mohammadreza},
  booktitle={2012 Proceedings of the 35th International Convention MIPRO}, 
  title={Non-blocking N-version programming for message passing systems}, 
  year={2012},
  volume={},
  number={},
  pages={345-348},
  abstract={N-version programming (NVP) employs masking redundancy: N equivalent modules (called versions) are implemented independently and run concurrently. The results of their execution are adjudicated by a special component that defines the correct majority result and eliminates the results of the versions in which design faults have been triggered. The disadvantage of using these schemes is that they need to block the receiver process until each received message is confirmed by the other version, which results in high time overhead. In the case of variant response latencies, consisting of processing time and message transmission delay, these techniques would not be efficient. In this paper a new non-blocking NVP approach based on capturing the causality between requests and response is proposed. This approach does not need to block the versions to confirm the output. The simulations result show that for acceptable values for probability of failure per demand (pfd) and simultaneous active requests, our approach has lower execution time.},
  keywords={},
  doi={},
  ISSN={},
  month={May},}
@INPROCEEDINGS{6240670,
  author={Környei, L.},
  booktitle={2012 Proceedings of the 35th International Convention MIPRO}, 
  title={Parallel implementation of a combustion chamber simulation with MPI-OpenMP hybrid techniques}, 
  year={2012},
  volume={},
  number={},
  pages={356-361},
  abstract={The parallelization techniques utilized in a study of gas flow in a combustion chamber are described and discussed in this paper. Models of compressible fluid dynamics are solved with the finite volume method, and an additional algorithm, called “snapper” that handles piston and valve movement. In order to achieve an acceptable scaling on a CPU cluster with 240 cores, a two-stage parallelization with MPI in conjecture with OpenMP is implemented. For some types of physical investigations, the actual spatial region of interest is somehow changing, deforming, or moving in time in a predefined fashion. Handling gas dynamics with piston motion, even with the simplest models requires precaution. Apart from numerical and physical corrections, there are challenges, where multiple types of unstructured, and specially generated deforming grids are handled in a computer system with distributed memory. In the present work the results of the first implementations and benchmarks are presented, which prove to be well scaling for this modest-sized cluster.},
  keywords={},
  doi={},
  ISSN={},
  month={May},}
@INPROCEEDINGS{6240677,
  author={Tomić, Draško and Ogrizović, Dario},
  booktitle={2012 Proceedings of the 35th International Convention MIPRO}, 
  title={Running High Performance Linpack on CPUGPU clusters}, 
  year={2012},
  volume={},
  number={},
  pages={400-404},
  abstract={A trend is developing in High-Performance Computing with cluster nodes built of general purpose CPUs and GPU accelerators. The common name of these systems is CPUGPU clusters. High Performance Linpack (HPL) benchmarking of High Performance Clusters consisting of nodes with both CPUs and GPUs is still a challenging task and deserves a high attention. In order to make HPL on such clusters more efficient, a multi-layered programming model consisting of at least Message Passing Interface (MPI), Multiprocessing (MP) and Streams Programming (Streams) needs to be utilized. Besides multi-layered programming model, it is crucial to deploy a right load-balancing scheme if someone wants to run HPL efficiently on CPUGPU systems. That means, besides the highest possible utilization rate, both fast and slow processors needs to receive appropriate portion of load, in order to avoid faster resources waiting on slower to finish their jobs. Moreover, in HPC clusters on Cloud, one has to take into account not only computing nodes of different processing power, but also a communication links of different speed between nodes as well. For this reasons we propose a load balancing method based on a semidefinite optimization. We hope that this method, coupled with a multi-layered programming, can perform a HPL benchmark on CPUGPU clusters and HPC Cloud systems more efficiently than methods used today.},
  keywords={},
  doi={},
  ISSN={},
  month={May},}
@INPROCEEDINGS{6245639,
  author={Barone, G.B. and Boccia, V. and Bottalico, D. and Carracciuolo, L. and Doria, A. and Laccetti, G.},
  booktitle={2012 Sixth International Conference on Complex, Intelligent, and Software Intensive Systems}, 
  title={Modelling the Behaviour of an Adaptive Scheduling Controller}, 
  year={2012},
  volume={},
  number={},
  pages={438-442},
  abstract={The deployment, management and total cost of ownership of large computing environments always involve huge investments. These systems, once in production, have to meet the needs of users belonging to large and heterogeneous communities: only an efficient and effective use of these systems can repay the investment made. The heterogeneity of user communities implies that computational resources are used for different type of applications, traditional (sequential) or HPC (MPI and Open MP based), whose demands are often conflicting. In this document we report experiences in designing, implementing and validating an adaptive scheduling controller (ASC) that, by using an "adaptive" approach in scheduling policy, allows a balanced, effective and efficient use of computational resources.},
  keywords={},
  doi={10.1109/CISIS.2012.26},
  ISSN={},
  month={July},}
@INPROCEEDINGS{6249270,
  author={Corradi, Antonio and Foschini, Luca and Povedano-Molina, Javier and Lopez-Soler, Juan M.},
  booktitle={2012 IEEE Symposium on Computers and Communications (ISCC)}, 
  title={DDS-enabled Cloud management support for fast task offloading}, 
  year={2012},
  volume={},
  number={},
  pages={000067-000074},
  abstract={Cloud computing has become an essential technology not only for web provisioning, but also in mobile scenarios. Mobile devices are usually resource constrained due to processing and power limitations, so typical applications are not easy portable. Battery draining and application performance (resource shortage) have a big impact on the experienced quality, so shifting applications and services to the Cloud may improve mobile user's satisfaction. However, available Cloud solutions are mostly focused on scenarios with slowly changing provisioning, which are unable to support and promptly react to short-term provisioning requests. To address the new scenario, this paper proposes a novel Cloud monitoring and management architecture based on the data-centric publish-subscribe Data Distribution Service (DDS) standard. We present not only an architecture proposal, but also a real prototype that we have deployed in our experimental testbed. The experimental results show that our architecture is able to support the scheduling of highly dynamic tasks in the Cloud while maintaining low overheads.},
  keywords={},
  doi={10.1109/ISCC.2012.6249270},
  ISSN={1530-1346},
  month={July},}
@INPROCEEDINGS{6253455,
  author={Vogler, Walter and Stahl, Christian and Müller, Richard},
  booktitle={2012 12th International Conference on Application of Concurrency to System Design}, 
  title={A Trace-Based Semantics for Responsiveness}, 
  year={2012},
  volume={},
  number={},
  pages={42-51},
  abstract={In the context of asynchronously communicating services, responsiveness guarantees that a service and its environment have always the possibility to communicate. The responsiveness preorder describes when one service can be replaced by another such that responsiveness is preserved. We study responsiveness for possibly unbounded services with and without final states, and present for both preorder variants a semantical characterization based on traces. Surprisingly, the preorders turn out not to be precongruences, and for both we characterize the coarsest precongruence which is contained in the respective preorder.},
  keywords={},
  doi={10.1109/ACSD.2012.10},
  ISSN={1550-4808},
  month={June},}
@INPROCEEDINGS{6253466,
  author={Bezdeka, Martin and Bouda, Ondrej and Korenciak, Lubo and Madzin, Matú and Reh'k, Vojtech},
  booktitle={2012 12th International Conference on Application of Concurrency to System Design}, 
  title={Sequence Chart Studio}, 
  year={2012},
  volume={},
  number={},
  pages={148-153},
  abstract={The Sequence Chart Studio (SCStudio) is a user friendly drawing and verification tool for Message Sequence Charts (MSC). SCStudio supports several checkers that are able to verify properties such as realizability, time consistency, equivalence' checking between two MSC diagrams, etc. Some of them are well known, while others are new or nontrivial extensions of existing ones. The graphical front-end is implemented as a Microsoft Visio add-on, whereas the checkers are platform independent. SCStudio is an open source project that provides an open interface for additional modules.},
  keywords={},
  doi={10.1109/ACSD.2012.25},
  ISSN={1550-4808},
  month={June},}
@INPROCEEDINGS{6253521,
  author={Fan, Pei and Chen, Zhenbang and Wang, Ji and Zheng, Zibin and Lyu, Michael R.},
  booktitle={2012 IEEE Fifth International Conference on Cloud Computing}, 
  title={Topology-Aware Deployment of Scientific Applications in Cloud Computing}, 
  year={2012},
  volume={},
  number={},
  pages={319-326},
  abstract={Nowadays, more and more scientific applications are moving to cloud computing. The optimal deployment of scientific applications is critical for providing good services to users. Scientific applications are usually topology-aware applications. Therefore, considering the topology of a scientific application during the development will benefit the performance of the application. However, it is challenging to automatically discover and make use of the communication pattern of a scientific application while deploying the application on cloud. To attack this challenge, in this paper, we propose a framework to discover the communication topology of a scientific application by pre-execution and multi-scale graph clustering, based on which the deployment can be optimized. Comprehensive experiments are conducted by employing a well-known MPI benchmark and comparing the performance of our method with those of other methods. The experimental results show the effectiveness of our topology-aware deployment method.},
  keywords={},
  doi={10.1109/CLOUD.2012.70},
  ISSN={2159-6190},
  month={June},}
@INPROCEEDINGS{6261240,
  author={Silva, Rodolfo Adamshuk and de Souza, Simone do Rocio Senger and de Souza, Paulo Sergio Lopes},
  booktitle={2012 13th Latin American Test Workshop (LATW)}, 
  title={Mutation operators for concurrent programs in MPI}, 
  year={2012},
  volume={},
  number={},
  pages={1-6},
  abstract={Concurrent Programming became an essential paradigm to reduce the computational time in many application domains. Mutation testing is an important criterion which uses mistakes made by software developers to derive test requirements. To apply this criterion in context of concurrent programs it is necessary to consider the implicit features of these programs, such as: communication, synchronization and non-determinism. Due to the non-determinism, special attention must be given during the mutant behavior analysis. This paper presents a set of mutation operators for concurrent programs in MPI (Message Passing Interface). This mutation operators set was defined based on typical errors of concurrent programs, extracted from literature. An example is presented to illustrate the application of the mutation operators to reveal faults in MPI programs.},
  keywords={},
  doi={10.1109/LATW.2012.6261240},
  ISSN={2373-0862},
  month={April},}
@INPROCEEDINGS{6258000,
  author={Arévalo, Sergio and Anta, Antonio Fern'ndez and Imbs, Damien and Jiménez, Ernesto and Raynal, Michel},
  booktitle={2012 IEEE 32nd International Conference on Distributed Computing Systems}, 
  title={Failure Detectors in Homonymous Distributed Systems (with an Application to Consensus)}, 
  year={2012},
  volume={},
  number={},
  pages={275-284},
  abstract={This paper is on homonymous distributed systems where processes are prone to crash failures and have no initial knowledge of the system membership (``homonymous'' means that several processes may have the same identifier). New classes of failure detectors suited to these systems are first defined. Among them, the classes $\HO$ and $\HS$ are introduced that are the homonymous counterparts of the classes $\Omega$ and $\Sigma$, respectively. (Recall that the pair $\langle \Omega, \Sigma\rangle$ defines the weakest failure detector to solve consensus.) Then, the paper shows how $\HO$ and $\HS$ can be implemented in homonymous systems without membership knowledge (under different synchrony requirements). Finally, two algorithms are presented that use these failure detectors to solve consensus in homonymous asynchronous systems where there is no initial knowledge of the membership. One algorithm solves consensus with $\langle \HO, \HS\rangle$, while the other uses only $\HO$, but needs a majority of correct processes. Observe that the systems with unique identifiers and anonymous systems are extreme cases of homonymous systems from which follows that all these results also apply to these systems. Interestingly, the new failure detector class $\HO$ can be implemented with partial synchrony, while the analogous class $\AO$ defined for anonymous systems can not be implemented (even in synchronous systems). Hence, the paper provides us with the first proof showing that consensus can be solved in anonymous systems with only partial synchrony (and a majority of correct processes).},
  keywords={},
  doi={10.1109/ICDCS.2012.13},
  ISSN={1063-6927},
  month={June},}
@INPROCEEDINGS{6258487,
  author={Huimin Lin},
  booktitle={2012 IEEE Sixth International Conference on Software Security and Reliability Companion}, 
  title={Keynote Speech III}, 
  year={2012},
  volume={},
  number={},
  pages={xx-xx},
  abstract={Summary form only given. As network and multi-core systems are becoming pervasive, software systems also go concurrent. In a concurrent setting, in order to accomplish its computation task a program must cooperate with other programs by exchanging messages between them. These result in non-determinism and sophisticated interaction behavior, making it very difficult to ensure that concurrent software systems will run safely and reliably In this talk I will present an approach to checking safety properties of concurrent programs. In this approach, concurrent programs are represented as symbolic transition graphs which can be regarded as a generalization of flow chart diagrams to allow nondeterminism and communication. Safety properties are expressed as formulas in alteration-free first-order mu-calculus. An efficient algorithm exists to check whether a symbolic transition graph satisfies the desired properties. Various abstraction techniques can be incorporated to reduce the size of reachable state space.},
  keywords={},
  doi={10.1109/SERE-C.2012.52},
  ISSN={},
  month={June},}

@INPROCEEDINGS{6263557,
  author={Eichhorn, Mike and Woithe, Hans Christian and Kremer, Ulrich},
  booktitle={2012 Oceans - Yeosu}, 
  title={Parallelization of path planning algorithms for AUVs concepts, opportunities, and program-technical implementation}, 
  year={2012},
  volume={},
  number={},
  pages={1-8},
  abstract={Modern autonomous underwater vehicles (AUVs) have advanced sensing capabilities including sonar, cameras, acoustic communication, and diverse bio-sensors. Instead of just sensing its environment and storing the data for post-mission inspection, an AUV could use the collected information to gain an understanding of its environment, and based on this understanding autonomously adapt its behavior to enhance the overall effectiveness of its mission. Many such tasks are highly computation intensive. This paper presents the results of a case study that illustrates the effectiveness of an energy-aware, many-core computing architecture to perform on-board path planning within a battery-operated AUV. A previously published path planning algorithm was ported onto the SCC, an experimental 48 core single-chip system developed by Intel. The performance, power, and energy consumption of the application were measured for different numbers of cores and other system parameters. This case study shows that computation intensive tasks can be executed within an AUV that relies mainly on battery power. Future plans include the deployment and testing of an SCC system within a Teledyne Webb Research Slocum glider.},
  keywords={},
  doi={10.1109/OCEANS-Yeosu.2012.6263557},
  ISSN={},
  month={May},}
@INPROCEEDINGS{6263683,
  author={Karamshuk, Dmytro and Boldrini, Chiara and Conti, Marco and Passarella, Andrea},
  booktitle={2012 IEEE International Symposium on a World of Wireless, Mobile and Multimedia Networks (WoWMoM)}, 
  title={An arrival-based framework for human mobility modeling}, 
  year={2012},
  volume={},
  number={},
  pages={1-9},
  abstract={Modeling human mobility is crucial in the performance analysis and simulation of mobile ad hoc networks, where contacts are exploited as opportunities for peer-to-peer message forwarding. The current approach to human mobility modeling has been based on continuously modifying models, trying to embed in them the newest features of mobility properties (e.g., visiting patterns to locations or inter-contact times) as they came up from trace analysis. As a consequence, typically these models are neither flexible (i.e., features of mobility cannot be changed without changing the model) nor controllable (i.e., the exact shape of mobility properties cannot be controlled directly). In order to take into account the above requirements, in this paper we propose a mobility framework whose goal is, starting from the stochastic process describing the arrival patterns of users to locations, to generate pairwise inter-contact times and aggregate inter-contact times featuring a predictable probability distribution. We validate the proposed framework by means of simulations. In addition, assuming that the arrival process of users to locations can be described by a Bernoulli process, we mathematically derive a closed form for the pairwise and aggregate inter-contact times, proving the controllability of the proposed approach in this case.},
  keywords={},
  doi={10.1109/WoWMoM.2012.6263683},
  ISSN={},
  month={June},}
@INPROCEEDINGS{6263716,
  author={Deb, Budhaditya and Hartman, Michael J.},
  booktitle={2012 IEEE International Symposium on a World of Wireless, Mobile and Multimedia Networks (WoWMoM)}, 
  title={Distributed optimization of Contention Windows in 802.11e MAC to provide QoS differentiation and maximize channel utilization}, 
  year={2012},
  volume={},
  number={},
  pages={1-7},
  abstract={We propose a distributed algorithm for optimizing the Contention Windows in IEEE 802.11e based WLANs with the dual intention of providing fine-grained QoS and maximizing the channel utilization. The underlying concept behind the algorithm is modeling the network state as a function of MAC parameters and solving this analytical model constrained by the QoS requirements of multiple nodes. The main contribution of this paper is the completely distributed realization of this concept. The problem appears as a system of non-linear equations which is solved by an iterative gradient-based method. Distributed solution is achieved by first decoupling the equations and second by implicit message passing through local measurements. This allows local computation of partial differentials and residuals of the iterative process. Local measurements serve as inputs for the next iterative step and as natural feedback mechanism to handle dynamic channel conditions. Convergence of iterations is ensured through progressive target setting of QoS requirements. Extensive simulation results and a proof of concept with a test bed show that the algorithm achieves fine-grained QoS differentiation while minimizing delays, collisions and packet losses. As a result, when the network scales, the algorithm is shown to maximize the channel utilization and maintain a near optimal total throughput of the system. Finally, sub-minute convergence time makes the algorithm suitable for real-time flows.},
  keywords={},
  doi={10.1109/WoWMoM.2012.6263716},
  ISSN={},
  month={June},}
@INPROCEEDINGS{6264677,
  author={Zheng, Gengbin and Xiang Ni and Kalé, Laxmikant V.},
  booktitle={IEEE/IFIP International Conference on Dependable Systems and Networks Workshops (DSN 2012)}, 
  title={A scalable double in-memory checkpoint and restart scheme towards exascale}, 
  year={2012},
  volume={},
  number={},
  pages={1-6},
  abstract={As the size of supercomputers increases, the probability of system failure grows substantially, posing an increasingly significant challenge for scalability. It is important to provide resilience for long running applications. Checkpoint-based fault tolerance methods are effective approaches at dealing with faults. With these methods, the state of the entire parallel application is checkpointed to reliable storage. When a failure occurs, the application is restarted from a recent checkpoint. In previous work, we have demonstrated an efficient double in-memory checkpoint and restart fault tolerance scheme, which leverages Charm++'s parallel objects for checkpointing. In this paper, we further optimize the scheme by eliminating several bottlenecks caused by serialized communication. We extend the in-memory checkpointing scheme to work on MPI communication layer, and demonstrate the performance on very large scale supercomputers. For example, when running a one million atom molecular dynamics simulation on up to 64K cores of a BlueGene/P machine, the checkpoint time was in milliseconds. The restart time was measured to be less than 0.15 seconds on 64K cores.},
  keywords={},
  doi={10.1109/DSNW.2012.6264677},
  ISSN={2325-6664},
  month={June},}
@INPROCEEDINGS{6266942,
  author={Grünewald, Daniel},
  booktitle={2012 International Conference on High Performance Computing & Simulation (HPCS)}, 
  title={BQCD with GPI: A case study}, 
  year={2012},
  volume={},
  number={},
  pages={388-394},
  abstract={We compare the BQCD performance, a typical high performance computer application, using either the MPI or the Fraunhofer GPI communication library. In our analysis, we focus on the BQCD performance critical part covering 50 percent of the total program run-time. This is given by the computation of a four-dimensional nearest neighbor stencil operator in a domain decomposed simulation volume. Hence, BQCD is a typical representative for the broad class of stencil algorithms. In order to obtain optimal speedup, we overlap the communication with the computation and analyse the resulting run-times on two test systems. We introduce the overlap efficiency as a measure for the communication library's ability to overlap the communication with the computation. In the regime in which the raw communication latency is less than the raw computational time, the overlap efficiency should be equal to one. This regime depends on the problem size and on the number of used cores. Deviations from one show possible interferences of communication and computation induced by the communication library. Side effects which disturb the scalability in practice. As result, we find that GPI has overlap efficiency equal to one, i.e. it allows for perfect overlap and ideal scalability. The total runtime is equal to the time spent for the pure computation. For the same communication pattern, MPI has overlap efficiency less than one. It cannot hide the communication completely which results in a worse scalability in general. The GPI speedups in comparison with the equivalent MPI implementation are of the order of 20-30 percent.},
  keywords={},
  doi={10.1109/HPCSim.2012.6266942},
  ISSN={},
  month={July},}
@INPROCEEDINGS{6266974,
  author={Castro, Marcela and Rexachs, Dolores and Luque, Emilio},
  booktitle={2012 International Conference on High Performance Computing & Simulation (HPCS)}, 
  title={Transparent fault tolerance middleware at user level}, 
  year={2012},
  volume={},
  number={},
  pages={566-572},
  abstract={We present a design of a transparent fault tolerance middleware for message passing applications. The approach consists in transforming the interconnections used by the application in reliable ones and support log-based rollback recovery protocol. When one of the nodes of the cluster fails, the processes are recovered in a new one and the connections are reestablished. All this work is made automatically and in a transparent way for the application. This service can be optionally activated at runtime at user level. The models used for protection and recovering application and detection of failures are based on RADIC architecture. We have tested this middleware by executing a master-worker (M/W) and SPMD applications which follow different communication patterns.},
  keywords={},
  doi={10.1109/HPCSim.2012.6266974},
  ISSN={},
  month={July},}
@INPROCEEDINGS{6267849,
  author={Protze, Joachim and Hilbrich, Tobias and Knüpfer, Andreas and de Supinski, Bronis R. and Müller, Matthias S.},
  booktitle={2012 IEEE 26th International Parallel and Distributed Processing Symposium}, 
  title={Holistic Debugging of MPI Derived Datatypes}, 
  year={2012},
  volume={},
  number={},
  pages={354-365},
  abstract={The Message Passing Interface (MPI) specifies an API that allows programmers to create efficient and scalable parallel applications. The standard defines multiple constraints for each function parameter. For performance reasons, no MPI implementation checks all of these constraints at runtime. Derived data types are an important concept of MPI and allow users to describe an application's data structures for efficient and convenient communication. Using existing infrastructure we present scalable algorithms to detect usage errors of basic and derived MPI data types. We detect errors that include constraints for construction and usage of derived data types, matching their type signatures in communication, and detecting erroneous overlaps of communication buffers. We implement these checks in the MUST runtime error detection framework. We provide a novel representation of error locations to highlight usage errors. Further, approaches to buffer overlap checking can cause unacceptable overheads for non-contiguous data types. We present an algorithm that uses patterns in derived MPI data types to avoid these overheads without losing precision. Application results for the benchmark suites SPEC MPI2007 and NAS Parallel Benchmarks for up to 2048 cores show that our approach applies to a broad range of applications and that our extended overlap check improves performance by two orders of magnitude. Finally, we augment our runtime error detection component with a debugger extension to support in-depth analysis of the errors that we find as well as semantic errors. This extension to gdb provides information about MPI data type handles and enables gdb -- and other debuggers based on gdb -- to display the content of a buffer as used in MPI communications.},
  keywords={},
  doi={10.1109/IPDPS.2012.41},
  ISSN={1530-2075},
  month={May},}
@INPROCEEDINGS{6267848,
  author={Chen, Zhezhe and Li, Xinyu and Chen, Jau-Yuan and Zhong, Hua and Qin, Feng},
  booktitle={2012 IEEE 26th International Parallel and Distributed Processing Symposium}, 
  title={SyncChecker: Detecting Synchronization Errors between MPI Applications and Libraries}, 
  year={2012},
  volume={},
  number={},
  pages={342-353},
  abstract={While improving the performance, nonblocking communication is prone to synchronization errors between MPI applications and the underlying MPI libraries. Such synchronization error occurs in the following way. After initiating nonblocking communication and performing overlapped computation, the MPI application reuses the message buffer before the MPI library completes the use of the same buffer, which may lead to sending out corrupted message data or reading undefined message data. This paper presents a new method called Sync Checker to detect synchronization errors in MPI nonblocking communication. To examine whether the use of message buffers is well synchronized between the MPI application and the MPI library, Sync Checker first tracks relevant memory accesses in the MPI application and corresponding message send/receive operations in the MPI library. Then it checks whether the correct execution order between the MPI application and the MPI library is enforced by the MPI completion check routines. If not, Sync Checker reports the error with diagnostic information. To reduce runtime overhead, we propose three dynamic optimizations. We have implemented a prototype of Sync Checker on Linux and evaluated it with seven bug cases, i.e., five introduced by the original developers and two injected, in four different MPI applications. Our experiments show that Sync Checker detects all the evaluated synchronization errors and provides helpful diagnostic information. Moreover, our experiments with seven NAS Parallel Benchmarks demonstrate that Sync Checker incurs moderate runtime overhead, 1.3-9.5 times with an average of 5.2 times, making it suitable for software testing.},
  keywords={},
  doi={10.1109/IPDPS.2012.40},
  ISSN={1530-2075},
  month={May},}
@INPROCEEDINGS{6267924,
  author={Guermouche, Amina and Ropars, Thomas and Snir, Marc and Cappello, Franck},
  booktitle={2012 IEEE 26th International Parallel and Distributed Processing Symposium}, 
  title={HydEE: Failure Containment without Event Logging for Large Scale Send-Deterministic MPI Applications}, 
  year={2012},
  volume={},
  number={},
  pages={1216-1227},
  abstract={High performance computing will probably reach exascale in this decade. At this scale, mean time between failures is expected to be a few hours. Existing fault tolerant protocols for message passing applications will not be efficient anymore since they either require a global restart after a failure (check pointing protocols) or result in huge memory occupation (message logging). Hybrid fault tolerant protocols overcome these limits by dividing applications processes into clusters and applying a different protocol within and between clusters. Combining coordinated check pointing inside the clusters and message logging for the inter-cluster messages allows confining the consequences of a failure to a single cluster, while logging only a subset of the messages. However, in existing hybrid protocols, event logging is required for all application messages to ensure a correct execution after a failure. This can significantly impair failure free performance. In this paper, we propose HydEE, a hybrid rollback-recovery protocol for send-deterministic message passing applications, that provides failure containment without logging any event, and only a subset of the application messages. We prove that HydEE can handle multiple concurrent failures by relying on the send-deterministic execution model. Experimental evaluations of our implementation of HydEE in the MPICH2 library show that it introduces almost no overhead on failure free execution.},
  keywords={},
  doi={10.1109/IPDPS.2012.111},
  ISSN={1530-2075},
  month={May},}
@INPROCEEDINGS{6267926,
  author={Buntinas, Darius},
  booktitle={2012 IEEE 26th International Parallel and Distributed Processing Symposium}, 
  title={Scalable Distributed Consensus to Support MPI Fault Tolerance}, 
  year={2012},
  volume={},
  number={},
  pages={1240-1249},
  abstract={As system sizes increase, the amount of time in which an application can run without experiencing a failure decreases. Exascale applications will need to address fault tolerance. In order to support algorithm-based fault tolerance, communication libraries will need to provide fault-tolerance features to the application. One important fault-tolerance operation is distributed consensus. This is used, for example, to collectively decide on a set of failed processes. This paper describes a scalable, distributed consensus algorithm that is used to support new MPI fault-tolerance features proposed by the MPI 3 Forum's fault-tolerance working group. The algorithm was implemented and evaluated on a 4,096-core Blue Gene/P. The implementation was able to perform a full-scale distributed consensus in 222 μs and scaled logarithmically.},
  keywords={},
  doi={10.1109/IPDPS.2012.113},
  ISSN={1530-2075},
  month={May},}
@INPROCEEDINGS{6267927,
  author={Wu, Xing and Deshpande, Vivek and Mueller, Frank},
  booktitle={2012 IEEE 26th International Parallel and Distributed Processing Symposium}, 
  title={ScalaBenchGen: Auto-Generation of Communication Benchmarks Traces}, 
  year={2012},
  volume={},
  number={},
  pages={1250-1260},
  abstract={Benchmarks are essential for evaluating HPC hardware and software for petascale machines and beyond. But benchmark creation is a tedious manual process. As a result, benchmarks tend to lag behind the development of complex scientific codes. This work contributes an automated approach to the creation of communication benchmarks. Given an MPI application, we utilize Scala Trace, a loss less and scalable framework to trace communication operations and execution time while abstracting away the computations. A single trace file that reflects the behavior of all nodes is subsequently expanded to C source code by a novel code generator. This resulting benchmark code is compact, portable, human-readable, and accurately reflects the original application's communication characteristics and runtime characteristics. Experimental results demonstrate that generated source code of benchmarks preserves both the communication patterns and the wall clock-time behavior of the original application. Such automatically generated benchmarks not only shorten the transition from application development to benchmark extraction but also facilitate code obfuscation, which is essential for benchmark extraction from commercial and restricted applications.},
  keywords={},
  doi={10.1109/IPDPS.2012.114},
  ISSN={1530-2075},
  month={May},}
@INPROCEEDINGS{6267937,
  author={Hilbrich, Tobias and Müller, Matthias S. and de Supinski, Bronis R. and Schulz, Martin and Nagel, Wolfgang E.},
  booktitle={2012 IEEE 26th International Parallel and Distributed Processing Symposium}, 
  title={GTI: A Generic Tools Infrastructure for Event-Based Tools in Parallel Systems}, 
  year={2012},
  volume={},
  number={},
  pages={1364-1375},
  abstract={Runtime detection of semantic errors in MPI applications supports efficient and correct large-scale application development. However, current approaches scale to at most one thousand processes and design limitations prevent increased scalability. The need for global knowledge for analyses such as type matching, and deadlock detection presents a major challenge. We present a scalable tool infrastructure - the Generic Tool Infrastructure (GTI) - that we will use to implement MPI runtime error detection tools and that applies to other use cases. GTI supports simple offloading of tool processing onto extra processes or threads and provides a tree based overlay network (TBON) for creating scalable tools that analyze global knowledge. We present its abstractions and code generation facilities that ease many hurdles in tool development, including wrapper generation, tool communication, trace reductions, and filters. GTI ultimately allows tool developers to focus on implementing tool functionality instead of the surrounding infrastructure. Further, we demonstrate that GTI supports scalable tool development through a lost message detector and a phase profiler. The former provides a more scalable implementation of important base functionality for MPI correctness checking, while the latter tool demonstrates that GTI can serve as the basis of further types of tools. Experiments with up to 2048 cores show that GTI's scalability features apply to both tools.},
  keywords={},
  doi={10.1109/IPDPS.2012.123},
  ISSN={1530-2075},
  month={May},}
@INPROCEEDINGS{6269718,
  author={Calvagna, Andrea and Pappalardo, Giuseppe and Tramontana, Emiliano},
  booktitle={2012 IEEE 21st International Workshop on Enabling Technologies: Infrastructure for Collaborative Enterprises}, 
  title={A Novel Approach to Effective Parallel Computing of t-Wise Covering Arrays}, 
  year={2012},
  volume={},
  number={},
  pages={149-153},
  abstract={In this paper we present a novel parallel technique to compute t-wise covering arrays. The massive computational work, implied by the considered task when large configuration spaces are modeled, is distributed over a scalable set of parallel computing resources by means of an MPI-compliant algorithm. Due to NP-completeness of the covering array problem, existing research on combinatorial generation algorithms commonly assumes this computation task as strictly sequential. Conversely, basing on inherent combinatorial properties, we show that it is possible to scatter the overall workload into several and independent processing sub-tasks, and then collect all outcomes into a global solution whose size is still comparable to that of a sequentially computed solution. Reported results show that in this way significant speed-up is achieved on the computation times with respect to the sequential computation of the same task.},
  keywords={},
  doi={10.1109/WETICE.2012.106},
  ISSN={1524-4547},
  month={June},}
@INPROCEEDINGS{6269644,
  author={Burmeister, Rodger and Helke, Steffen},
  booktitle={2012 Sixth International Symposium on Theoretical Aspects of Software Engineering}, 
  title={The Observer Pattern Applied to Actor Systems: A TLA/TLC-based Implementation Analysis}, 
  year={2012},
  volume={},
  number={},
  pages={193-200},
  abstract={With the increasing impact of the actor-model in programming languages, there is also an increased demand for approved solutions for recurring implementation problems. Transferring established design pattern solutions from sequential contexts to concurrent ones requires a rigorous clarification of intentional requirements and concurrency issues. Existing approaches either do not verify concurrent pattern implementations rigorously or do not address the actor model. To solve these insufficiencies we (1) specify intentional requirements using LTL-expressions and an abstract outline, and (2) transfer and verify these for a concrete, actor-based TLA description using model checking techniques. The applicability of our approach is demonstrated for a concurrent version of the well known Observer Pattern. Our work enables software engineers to build up formal requirement catalogs for sequential and concurrent design pattern implementations and to rigorously verify them at a low effort.},
  keywords={},
  doi={10.1109/TASE.2012.15},
  ISSN={},
  month={July},}
@INPROCEEDINGS{6270274,
  author={Yafei Wang and Manchun Li and Shuai Zhang and Lihua Tong and Jinbiao Wei and Zhenjie Chen},
  booktitle={2012 20th International Conference on Geoinformatics}, 
  title={Research research on on parallel algorithm for polygon rasterization}, 
  year={2012},
  volume={},
  number={},
  pages={1-4},
  abstract={Vector to raster conversion has always been one of the foundational research topics in the field of Geographical Information System. With the development of processing for massive geospatial data, traditional serial algorithms can not satisfy the need of effective rastering of large amounts of vector data. This paper proposes a parallel algorithm of rasterization for vector polygon based on data parallel which is improved on the basis of scanline algorithm of polygon rasterization, and implements the parallel algorithm using the C++ programming language and the Message Passing Interface(MPI). We test the parallel algorithm by experiments and analyses the parallel efficiency. Results show that the parallel algorithm proposed in this paper achieves high parallel speedup and efficiency.},
  keywords={},
  doi={10.1109/Geoinformatics.2012.6270274},
  ISSN={2161-0258},
  month={June},}
@INPROCEEDINGS{6270768,
  author={Raikar, S. Pai and Subramoni, H. and Kandalla, K. and Vienne, J. and Panda, Dhabaleswar K.},
  booktitle={2012 IEEE 26th International Parallel and Distributed Processing Symposium Workshops & PhD Forum}, 
  title={Designing Network Failover and Recovery in MPI for Multi-Rail InfiniBand Clusters}, 
  year={2012},
  volume={},
  number={},
  pages={1160-1167},
  abstract={The emerging trends of designing commodity-based supercomputing systems have a severe detrimental impact on the Mean-Time-Between-Failures (MTBF). The MTBF for typical HEC installations is currently estimated to be between eight hours and fifteen days [1]. Failures in the interconnect fabric account for a fair share of the total failures occurring in such systems. This will continue to degrade as system sizes become larger. Thus, it is highly desirable that next generation system architectures and software environments provide sophisticated network level fault-tolerance and fault-resilient solutions. In the past few years, the number of cores on processors has increased dramatically. To make efficient use of these machines it is necessary to provide the required bandwidth to all the cores. To keep up with the multi-core trend, current generation supercomputers and clusters are designed with multiple network cards (rails) to provide enhanced data transfer capabilities. Besides providing enhanced performance, such multi-rail networks can also be leveraged to provide network level fault resilience. This paper presents a design for a failover mechanism in a multi-rail scenario, for handling network failures and their recovery without compromising on performance. In a general message passing scenario, whenever there is a network failure, the entire job aborts. Our design allows the job to continue even when a network failure occurs, by using the remaining rails for communication. Once the rail recovers from the failure, we also propose a protocol to re-establish connections on that rail and resume normal operations. We experimentally demonstrate that our implementation adds very little overhead and is able to deliver good performance which is comparable to that of the other rails running in isolation. We also show that the recovery is immediate and is associated with no additional overhead. We also depict sustenance and reliability of the design by running application benchmarks with permanent failures.},
  keywords={},
  doi={10.1109/IPDPSW.2012.142},
  ISSN={},
  month={May},}
@INPROCEEDINGS{6270754,
  author={Agarwal, Dinesh and Prasad, Sushil K.},
  booktitle={2012 IEEE 26th International Parallel and Distributed Processing Symposium Workshops & PhD Forum}, 
  title={AzureBench: Benchmarking the Storage Services of the Azure Cloud Platform}, 
  year={2012},
  volume={},
  number={},
  pages={1048-1057},
  abstract={Cloud computing is becoming mainstream for High Performance Computing (HPC) application development over the last few years. However, even though many vendors have rolled out their commercial cloud infrastructures, the service offerings are usually only best-effort based, without any performance guarantees. Cloud computing effectively saves the eScience developer the hassles of resource provisioning but utilization of these resources will be questionable if it can not meet the performance expectations of deployed applications. Furthermore, in order to make application design choices for a particular cloud offering, an eScience developer needs to understand the performance capabilities of the underlying cloud platform. Among all clouds, the emerging Azure cloud from Microsoft remains a challenge for HPC program development both due to lack of its support for traditional parallel programming support such as MPI and map-reduce and due to its evolving APIs. To aid the HPC developers, we present an open-source benchmark suite, Azure Bench, for Windows Azure cloud platform. We report comprehensive performance analysis of Azure cloud platform's storage services which are its primary artifacts for inter-processor coordination and communication. We also report on how much scalability Azure platform affords using up to 100 processors and point out various bottlenecks in parallel access of storage services. The paper also has pointers to overcome the steep learning curve for HPC application development over Azure. We also provide an open-source generic application framework that can be a starting point for application development for bag-of-task applications over Azure.},
  keywords={},
  doi={10.1109/IPDPSW.2012.128},
  ISSN={},
  month={May},}
@INPROCEEDINGS{6270788,
  author={Strazdins, Peter E.},
  booktitle={2012 IEEE 26th International Parallel and Distributed Processing Symposium Workshops & PhD Forum}, 
  title={Experiences in Teaching a Specialty Multicore Computing Course}, 
  year={2012},
  volume={},
  number={},
  pages={1283-1288},
  abstract={We detail the design and experiences in delivering a specialty multicore computing course whose materials are openly available. The course ambitiously covers three multicore programming paradigms: shared memory (OpenMP), device (CUDA) and message passing (RCCE), and involves significant practical work on their respective platforms: an UltraSPARC T2, Fermi GPU and the Intel Single-Chip Cloud Computer. Specialized multicore architecture topics include chip multiprocessing, virtualization support, on-chip accelerators and networks, transactional memory and speculative execution. The mode of delivery emphasizes the relationship between programming performance and the underlying computer architecture, necessitating the need to provide suitable infrastructure in the form of instrumented test programs and the use of performance evaluation tools. Further infrastructure had to be created to facilitate the safe, convenient and efficient use by students on the GPU and Single-Chip Cloud Computer. The programming assignments, based on the theme of the LINPACK benchmark, also required significant infrastructure for reliably determining correctness and assisting debugging. While the course assumed as background knowledge an introductory computer systems and concurrency course, we found that students could learn device programming in a short time, by building on their knowledge of shared memory programming. However, we found that more time is needed for learning message passing. We also found that, provided students had a suitably strong computer systems background, they could successfully meet the course's learning objectives, although the skill of correctly interpreting performance data remains difficult to learn when suitable performance analysis tools are not available.},
  keywords={},
  doi={10.1109/IPDPSW.2012.168},
  ISSN={},
  month={May},}
@INPROCEEDINGS{6270809,
  author={Strazdins, Peter E. and Cai, Jie and Atif, Muhammad and Antony, Joseph},
  booktitle={2012 IEEE 26th International Parallel and Distributed Processing Symposium Workshops & PhD Forum}, 
  title={Scientific Application Performance on HPC, Private and Public Cloud Resources: A Case Study Using Climate, Cardiac Model Codes and the NPB Benchmark Suite}, 
  year={2012},
  volume={},
  number={},
  pages={1416-1424},
  abstract={The ubiquity of on-demand cloud computing resources enables scientific researchers to dynamically provision and consume compute and storage resources in response to science needs. Whereas traditional HPC compute resources are often centrally managed with a priori CPU-time allocations and use policies. A long term goal of our work is to assess the efficacy of preserving the user environment (compilers, support libraries, runtimes and application codes) available at a traditional HPC facility for deployment into a VM environment, which can then be subsequently used in both private and public scientific clouds. This would afford greater flexibility to users in choosing hardware resources that suit their science needs better, as well as aiding them in transitioning onto private/public cloud resources. In this paper we present work in-progress performance results for a set of benchmark kernels and scientific applications running in a traditional HPC environment, a private VM cluster and an Amazon HPC EC2 cluster. These are the OSU MPI micro-benchmark, the NAS Parallel macro-benchmarks and two large scientific application codes (the UK Met Office's MetUM global climate model and the Chaste multi-scale computational biology code) respectively. We discuss parallel scalability and runtime information obtained using the IPM performance monitoring framework for MPI applications. We were also able to successfully build application codes in a traditional HPC environment and package these into VMs which ran on both private and public cloud resources.},
  keywords={},
  doi={10.1109/IPDPSW.2012.186},
  ISSN={},
  month={May},}
@INPROCEEDINGS{6270842,
  author={Gonzalez, Juan and Huck, Kevin and Gimenez, Judit and Labarta, Jesus},
  booktitle={2012 IEEE 26th International Parallel and Distributed Processing Symposium Workshops & PhD Forum}, 
  title={Automatic Refinement of Parallel Applications Structure Detection}, 
  year={2012},
  volume={},
  number={},
  pages={1680-1687},
  abstract={Analyzing parallel programs has become increasingly difficult due to the immense amount of information collected on large systems. In this scenario, cluster analysis has been proved to be a useful technique to reduce the amount of data to analyze. A good example is the use of the density-based cluster algorithm DBSCAN to identify similar single program multiple data (SPMD) computing phases in message-passing applications. This structure detection simplifies the analyst work as the whole information available is reduced to a small set of clusters. However, DBSCAN presents two major problems: it is very sensitive to its parametrization and is not capable of correctly detect clusters when the data set has different densities across the data space. In this paper, we introduce the Aggregative Cluster Refinement, an iterative algorithm that produces more accurate structure detections of SPMD phases than DBSCAN. In addition, it is able to detect clusters with different densities.},
  keywords={},
  doi={10.1109/IPDPSW.2012.209},
  ISSN={},
  month={May},}
@INPROCEEDINGS{6270866,
  author={Cheng, Pengqi and Gu, Yan},
  booktitle={2012 IEEE 26th International Parallel and Distributed Processing Symposium Workshops & PhD Forum}, 
  title={An Analysis of Multicore Specific Optimization in MPI Implementations}, 
  year={2012},
  volume={},
  number={},
  pages={1874-1878},
  abstract={We first introduced the multicore specific optimization modules of two common MPI implementations â" MPICH2 and Open MPI, and then tested their performance on one multicore computer. By enabling and disabling these modules, we provided their performance, including bandwidth and latency, under different circumstances. Finally, we analyzed the two MPI implementations and discussed the choice of MPI implementations and possible improvements.},
  keywords={},
  doi={10.1109/IPDPSW.2012.231},
  ISSN={},
  month={May},}
@ARTICLE{6275451,
  author={Marshall, Philip A. and Gaudet, Vincent C. and Elliott, Duncan G.},
  journal={IEEE Transactions on Circuits and Systems I: Regular Papers}, 
  title={Deeply Pipelined Digit-Serial LDPC Decoding}, 
  year={2012},
  volume={59},
  number={12},
  pages={2934-2944},
  abstract={Highly parallel VLSI implementations of low-density parity-check (LDPC) decoders have a large number of interconnections, which can result in designs with low logic density. Bit-serial architectures have been developed that reduce the number of wires needed, however, they do not fully realize the potential for deeply pipelined serial data processing. Digit- online arithmetic allows operations to be performed in a serial, digit-by-digit manner, making it ideal for use in implementing a digit-serial LDPC decoder. Digit-online circuits for the primitive operations required for an offset min-sum LDPC decoder are simple, and allow deep pipelining at the digit level. A new hardware architecture for LDPC decoding is demonstrated, using redundant number systems for the internal representation of values. We present post-layout decoder results for the (2048, 1723) 10GBASE-T LDPC code in a general-purpose 65 nm CMOS technology. The decoder requires a core area of 10.89 mm and operates at a clock frequency of 980 MHz. The decoder can simultaneously decode two 4-bit frames at 41.8 Gbit/s or one 10-bit frame at 20.9 Gbit/s.},
  keywords={},
  doi={10.1109/TCSI.2012.2206461},
  ISSN={1558-0806},
  month={Dec},}
@INPROCEEDINGS{6274170,
  author={Shi, Ruisheng and Zhang, Yang and Chen, Junliang and Cheng, Bo and Qiao, Xiuquan and Wu, Budan},
  booktitle={2012 IEEE Ninth International Conference on Services Computing}, 
  title={Summary Instance: Scalable Event Priority Determination Engine for Large Scale Distributed Event-Based System}, 
  year={2012},
  volume={},
  number={},
  pages={400-406},
  abstract={With the advent of ubiquitous sensor-rich environments and location-based services, distributed event-based systems based on the publish/subscribe communication paradigm are becoming very important and crucial. In many large-scale distributed mission critical areas, publish/subscribe systems must support a large number of geographically distributed publishers and subscribers and ensure real-time event data to be delivered timely. The concern is that a large number of low priority events may clog the channel thereby causing high priority events to get delayed. The challenge raised for the event-based middleware in large-scale distributed system is that event priority determination engine must be efficient and scalable in term of priority rule size and event throughputs. Checking every rule for priority on-the-fly is not friendly to the cache. This paper proposed an innovative approach based on Bloom filter technique. This approach is cache friendly and the online computation time of event priority determination is independent of the rule size. This approach is based on two ideas: make the online queries as simple as possible and exploit the power of cache on the broker. The rule instantiation engine (RIE) is made offline while online part is the priority determination engine (PDE). A Bloom filter data structure is used by RIE to store the rule instances and their priorities. The complex rule evaluation is reduced to set membership testing as queries on Bloom filters. The PDE makes the querying simplified by event discretization. Results are then cached in the broker caches. Finally, we have an analysis on the system complexity and some open issues. The further evaluation with prototype experiments are under development and the results may be found in our later publication.},
  keywords={},
  doi={10.1109/SCC.2012.44},
  ISSN={},
  month={June},}
@INPROCEEDINGS{6280381,
  author={Castro, Marcela and Rexachs, Dolores and Luque, Emilio},
  booktitle={2012 IEEE 10th International Symposium on Parallel and Distributed Processing with Applications}, 
  title={Transparent Fault Tolerance Solution at Socket Level Based on RADIC}, 
  year={2012},
  volume={},
  number={},
  pages={831-832},
  abstract={We present a transparent middleware for fault tolerance based on RADIC, Redundant Array of Distributed Independent Controllers, a transparent and scalable fault tolerant architecture for parallel applications. It is designed at socket level and makes a secure tunnel connection able to keep the tcp sessions established by the application in spite of node failures. It is located at user level and is independent of the message-passing communication library being used. The protection gets through uncoordinated checkpoints and log message and the recovery are done in a automatic way so in case of node failures there is no need of intervention of the administrator. We have tested our fault tolerance system by executing a master-worker (M/W) and SPMD applications that follow different communication patterns.},
  keywords={},
  doi={10.1109/ISPA.2012.121},
  ISSN={2158-9208},
  month={July},}
@INPROCEEDINGS{6283648,
  author={Ayday, Erman and Einolghozati, Arash and Fekri, Faramarz},
  booktitle={2012 IEEE International Symposium on Information Theory Proceedings}, 
  title={BPRS: Belief Propagation based iterative recommender system}, 
  year={2012},
  volume={},
  number={},
  pages={1992-1996},
  abstract={In this paper we introduce the first application of the Belief Propagation (BP) algorithm in the design of recommender systems. We formulate the recommendation problem as an inference problem and aim to compute the marginal probability distributions of the variables which represent the ratings to be predicted. However, computing these marginal probability functions is computationally prohibitive for large-scale systems. Therefore, we utilize the BP algorithm to efficiently compute these functions. Recommendations for each active user are then iteratively computed by probabilistic message passing. As opposed to the previous recommender algorithms, BPRS does not require solving the recommendation problem for all the users if it wishes to update the recommendations for only a single active. Further, BPRS computes the recommendations for each user with linear complexity and without requiring a training period. Via computer simulations (using the 100K MovieLens dataset), we verify that BPRS iteratively reduces the error in the predicted ratings of the users until it converges. Finally, we confirm that BPRS is comparable to the state of art methods such as Correlation-based neighborhood model (CorNgbr) and Singular Value Decomposition (SVD) in terms of rating and precision accuracy. Therefore, we believe that the BP-based recommendation algorithm is a new promising approach which offers a significant advantage on scalability while providing competitive accuracy for the recommender systems.},
  keywords={},
  doi={10.1109/ISIT.2012.6283648},
  ISSN={2157-8117},
  month={July},}
@INPROCEEDINGS{6288509,
  author={Cano, Alfonso and Giannakis, Georgios B.},
  booktitle={2012 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Distributed belief propagation using sensor networks with correlated observations}, 
  year={2012},
  volume={},
  number={},
  pages={2841-2844},
  abstract={A distributed belief propagation protocol is developed to carry inference and decoding tasks using wireless sensor networks with high-dimensional, correlated observations. Statistical dependencies are modeled using factor graphs. The overall a-posteriori probability is factored so that its factor graph representation can be mapped to the actual communication network. Sum-product message passing updates over the graphical model can thus be mapped to messages among sensors. As an application scenario, distributed spectrum sensing is considered. Simulated tests show that exploiting the correlation present among sensor observations can considerably improve sensing performance.},
  keywords={},
  doi={10.1109/ICASSP.2012.6288509},
  ISSN={2379-190X},
  month={March},}
@INPROCEEDINGS{6288590,
  author={Müller, Andreas and Sejdinovic, Dino and Piechocki, Robert},
  booktitle={2012 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Approximate message passing under finite alphabet constraints}, 
  year={2012},
  volume={},
  number={},
  pages={3177-3180},
  abstract={In this paper we consider Basis Pursuit De-Noising (BPDN) problems in which the sparse original signal is drawn from a finite alphabet. To solve this problem we propose an iterative message passing algorithm, which capitalises not only on the sparsity but by means of a prior distribution also on the discrete nature of the original signal. In our numerical experiments we test this algorithm in combination with a Rademacher measurement matrix and a measurement matrix derived from the random demodulator, which enables compressive sampling of analogue signals. Our results show in both cases significant performance gains over a linear programming based approach to the considered BPDN problem. We also compare the proposed algorithm to a similar message passing based algorithm without prior knowledge and observe an even larger performance improvement.},
  keywords={},
  doi={10.1109/ICASSP.2012.6288590},
  ISSN={2379-190X},
  month={March},}
@INPROCEEDINGS{6298166,
  author={Yoginath, Srikanth B. and Perumalla, Kalyan S. and Henz, Brian J.},
  booktitle={2012 IEEE 20th International Symposium on Modeling, Analysis and Simulation of Computer and Telecommunication Systems}, 
  title={Taming Wild Horses: The Need for Virtual Time-Based Scheduling of VMs in Network Simulations}, 
  year={2012},
  volume={},
  number={},
  pages={68-77},
  abstract={The next generation of scalable network simulators employ virtual machines (VMs) to act as high-fidelity models of traffic producer/consumer nodes in simulated networks. However, network simulations could be inaccurate if VMs are not scheduled according to virtual time, especially when many VMs are hosted per simulator core in a multi-core simulator environment. Since VMs are by default free-running, on the outset, it is not clear if, and to what extent, their untamed execution affects the results in simulated scenarios. Here, we provide the first quantitative basis for establishing the need for generalized virtual time scheduling of VMs in network simulators, based on an actual prototyped implementations. To exercise breadth, our system is tested with disparate applications: (a) a set of message passing parallel programs, (b) a computer worm propagation phenomenon, and (c) a mobile ad-hoc wireless network simulation. We define and use error metrics and benchmarks in scaled tests to empirically report the poor match of traditional, fairness-based VM scheduling to VM-based network simulation, and also clearly show the better performance of our simulation-specific scheduler, with up to 64 VMs hosted on a 12-core simulator node.},
  keywords={},
  doi={10.1109/MASCOTS.2012.18},
  ISSN={2375-0227},
  month={Aug},}
@INPROCEEDINGS{6298173,
  author={Pellegrini, Alessandro and Vitali, Roberto and Peluso, Sebastiano and Quaglia, Francesco},
  booktitle={2012 IEEE 20th International Symposium on Modeling, Analysis and Simulation of Computer and Telecommunication Systems}, 
  title={Transparent and Efficient Shared-State Management for Optimistic Simulations on Multi-core Machines}, 
  year={2012},
  volume={},
  number={},
  pages={134-141},
  abstract={Traditionally, Logical Processes (LPs) forming a simulation model store their execution information into disjoint simulations states, forcing events exchange to communicate data between each other. In this work we propose the design and implementation of an extension to the traditional Time Warp (optimistic) synchronization protocol for parallel/distributed simulation, targeted at shared-memory/multicore machines, allowing LPs to share parts of their simulation states by using global variables. In order to preserve optimism's intrinsic properties, global variables are transparently mapped to multi-version ones, so to avoid any form of safety predicate verification upon updates. Execution's consistency is ensured via the introduction of a new rollback scheme which is triggered upon the detection of an incorrect global variable's read. At the same time, efficiency in the execution is guaranteed by the exploitation of non-blocking algorithms in order to manage the multi-version variables' lists. Furthermore, our proposal is integrated with the simulation model's code through software instrumentation, in order to allow the application-level programmer to avoid using any specific API to mark or to inform the simulation kernel of updates to global variables. Thus we support full transparency. An assessment of our proposal, comparing it with a traditional message-passing implementation of variables' multi-version is provided as well.},
  keywords={},
  doi={10.1109/MASCOTS.2012.25},
  ISSN={2375-0227},
  month={Aug},}
@INPROCEEDINGS{6299100,
  author={Hughes, Danny and Thoelen, Klaas and Maerien, Jef and Matthys, Nelson and Horré, Wouter and Del Cid, Javier and Huygens, Christophe and Michiels, Sam and Joosen, Wouter},
  booktitle={2012 IEEE 11th International Symposium on Network Computing and Applications}, 
  title={LooCI: The Loosely-coupled Component Infrastructure}, 
  year={2012},
  volume={},
  number={},
  pages={236-243},
  abstract={Creating and managing applications for Wireless Sensor Networks (WSNs) is complicated by large scale, resource constraints and network dynamics. Reconfigurable component models minimize these complexities throughout the application lifecycle. However, contemporary component based middleware for WSNs is limited by its poor support for distribution. This paper introduces the Loosely-coupled Component Infrastructure (LooCI), a middleware for building distributed component-based WSN applications. LooCI advances the state-of-the-art by cleanly separating distributed concerns from component implementation, supporting application-level interoperability between heterogeneous WSN platforms and providing compatibility testing of bindings at runtime. Together, these features promote the safe and efficient composition and reconfiguration of distributed WSN applications. We evaluate the performance of LooCI on three classes of sensor nodes and demonstrate that these features can be provided with minimal overhead in terms of computation, memory and message passing.},
  keywords={},
  doi={10.1109/NCA.2012.30},
  ISSN={},
  month={Aug},}
@INPROCEEDINGS{6299125,
  author={Mostefaoui, Achour and Raynal, Michel and Stainer, Julien},
  booktitle={2012 IEEE 11th International Symposium on Network Computing and Applications}, 
  title={Chasing the Weakest Failure Detector for k-Set Agreement in Message-Passing Systems}, 
  year={2012},
  volume={},
  number={},
  pages={44-51},
  abstract={This paper continues our quest for the weakest failure detector which allows the k-set agreement problem to be solved in asynchronous message-passing systems prone to process failures. It has two main contributions which will be instrumental to complete this quest. The first contribution is a new failure detector (denoted PiSigma(x, y)) that has several noteworthy properties. (a) It is stronger than Sigma(k) which has been shown to be necessary. (b) It is equivalent to the pair (Sigma, Omega) when x=y=1 (optimal to solve consensus). (c) It is equivalent to the pair (Sigma(n-1), Omega(n-1)) when x=y=n-1 (optimal for (n-1)-set agreement). (d) It is strictly weaker than the pair (Sigma(x), anti-Omega(y)) (which has been investigated in previous works). (e) It is operational: the paper presents a PiSigma(x, y)-based algorithm that solves k-set agreement for k greater or equal to xy (intuitively, x refers to the maximum number of isolated groups of processes and y to the number of leaders in each of these groups). The second contribution of the paper is a proof that, for k strictly between 1 and n-1, the eventual leaders failure detector Omega(k) (which eventually provides each process with the same set of k process identities, this set including at least one correct process) is not necessary to solve k-set agreement problem.},
  keywords={},
  doi={10.1109/NCA.2012.19},
  ISSN={},
  month={Aug},}
@INPROCEEDINGS{6299071,
  author={Gutierrez, Samuel K. and Hjelm, Nathan T. and Venkata, Manjunath Gorentla and Graham, Richard L.},
  booktitle={2012 IEEE 20th Annual Symposium on High-Performance Interconnects}, 
  title={Performance Evaluation of Open MPI on Cray XE/XK Systems}, 
  year={2012},
  volume={},
  number={},
  pages={40-47},
  abstract={Open MPI is a widely used open-source implementation of the MPI-2 standard that supports a variety of platforms and interconnects. Current versions of Open MPI, however, lack support for the Cray XE6 and XK6 architectures -- both of which use the Gemini System Interconnect. In this paper, we present extensions to natively support these architectures within Open MPI, describe and propose solutions for performance and scalability bottlenecks, and provide an extensive evaluation of our implementation, which is the first completely open-source MPI implementation for the Cray XE/XK system families used at 49,152 processes. Application and micro-benchmark results show that the performance and scaling characteristics of our implementation are similar to the vendor-supplied MPI's. Micro-benchmark results show short-data 1-byte and 1,024-byte message latencies of 1.20 μs and 4.13 μs, which are 10.00% and 39.71% better than the vendor-supplied MPI's, respectively. Our implementation achieves a bandwidth of 5.32 GB/s at 8 MB, which is similar to the vendor-supplied MPI's bandwidth at the same message size. Two Sequoia benchmark applications, LAMMPS and AMG2006, were also chosen to evaluate our implementation at scales up to 49,152 cores -- where we exhibited similar performance and scaling characteristics when compared to the vendor-supplied MPI implementation. LAMMPS achieved a parallel efficiency of 88.20% at 49,152 cores using Open MPI, which is on par with the vendor-supplied MPI's achieved parallel efficiency.},
  keywords={},
  doi={10.1109/HOTI.2012.11},
  ISSN={2332-5569},
  month={Aug},}
@INPROCEEDINGS{6305905,
  author={Guo, Gang and Chen, Bin and Qiu, Xiao Gang and Li, Zhen},
  booktitle={2012 ACM/IEEE/SCS 26th Workshop on Principles of Advanced and Distributed Simulation}, 
  title={Parallel Simulation of Large-Scale Artificial Society on CPU/GPU Mixed Architecture}, 
  year={2012},
  volume={},
  number={},
  pages={174-177},
  abstract={Parallel simulations focus on conservative or optimistic algorithms to guarantee state consistency and causal order of messages between logical processes (LPs). It is usually hard for application domain users to develop complicated models for parallel simulations. For simplicity in large-scale artificial society, a modified DEVS component model is advocated in time-stepped parallel simulation with two-phase synchronization. A two-tier parallel simulation engine is designed on CPU/GPU mixed architecture with support of MPI and OpenCL. One-sided communication is selected for reflection of remote components and message passing between LPs. For cooperation between CPU and GPU, a size of 512 work items in each group is recommended. The parallel simulation engine is implemented in a micro kernel manner. An artificial society based on agent, container, grid and relation models are used to test the performance on an ordinary computer and a cluster with varied scales. The maximum speedup reaches 46 and 114 on the computer and the cluster respectively with about half a million agents.},
  keywords={},
  doi={10.1109/PADS.2012.31},
  ISSN={1087-4097},
  month={July},}
@INPROCEEDINGS{6305908,
  author={Chen, Bin and Guo, Gang},
  booktitle={2012 ACM/IEEE/SCS 26th Workshop on Principles of Advanced and Distributed Simulation}, 
  title={A Two-Tier Parallel Architecture for Artificial Society Simulation}, 
  year={2012},
  volume={},
  number={},
  pages={184-186},
  abstract={Artificial Society had been seemed as a new way to study emergence management. The traditional modeling and simulation could not satisfy the large population in Artificial Society. A Two-tier Parallel Architecture simulation is proposed to solve the large scale problem. Based on the analysis of parallelism degrees in Artificial Society, both MPI and GPU computation are used to construct the novel architecture. The experiments testify the high performance.},
  keywords={},
  doi={10.1109/PADS.2012.8},
  ISSN={1087-4097},
  month={July},}
@INPROCEEDINGS{6316440,
  author={Lotfi, Atieh and Safari, Saeed},
  booktitle={The 16th CSI International Symposium on Computer Architecture and Digital Systems (CADS 2012)}, 
  title={A genetic-based optimal checkpoint placement strategy for multicore processors}, 
  year={2012},
  volume={},
  number={},
  pages={172-177},
  abstract={Nowadays multicore processors are increasingly being deployed in high performance computing systems. As the complexity of systems increases, the probability of failure increases substantially. Therefore, the system requires techniques for supporting fault tolerance. Checkpointing technique is widely used to reduce the execution time of long-running programs in the presence of failures and to enhance the reliability of such systems. Optimizing the number of checkpoints in a parallel application running on a multicore processor is a complicated and challenging task. Infrequent checkpointing results in long reprocessing time, while too short checkpointing intervals lead to high checkpointing overhead. Since this is a multi-objective optimization problem, trapping in local optimums is very plausible. On the other hand, bio-inspired algorithms are powerful function optimizers that are successfully used to solve problems in many different areas. In this paper, by applying genetic algorithm, which is a well-known bio-inspired computing algorithm, finding optimal checkpoint placement in parallel applications is exercised. Under certain fault conditions, this new checkpoint placement strategy outperforms the existing ones with a significant reduction in the total wasted times. Our experimental results show that our method, which is implementable on any message-passing multicore system, can optimally find the suitable points in which checkpoints should be taken.},
  keywords={},
  doi={10.1109/CADS.2012.6316440},
  ISSN={2325-937X},
  month={May},}
@INPROCEEDINGS{6325224,
  author={Lechner, Gottfried and Johnson, Sarah J.},
  booktitle={2012 7th International Symposium on Turbo Codes and Iterative Information Processing (ISTC)}, 
  title={Absorbing sets and cycles}, 
  year={2012},
  volume={},
  number={},
  pages={185-189},
  abstract={Absorbing sets have been identified as structures in the graph of a low-density parity-check code that cause error floors - in particular in combination with binary message passing decoding algorithms. In this paper it is shown that absorbing sets involving only variable nodes up to degree 3 are equivalent to cycles and a sufficient and necessary condition on the degree distribution to avoid these absorbing sets is derived. The results are extended to irregular graphs and simulation results demonstrate the improvement in the error floor region.},
  keywords={},
  doi={10.1109/ISTC.2012.6325224},
  ISSN={2165-4719},
  month={Aug},}
@INPROCEEDINGS{6332282,
  author={Haeri, Sina and Shrimpton, John S.},
  booktitle={2012 IEEE 14th International Conference on High Performance Computing and Communication & 2012 IEEE 9th International Conference on Embedded Software and Systems}, 
  title={CFDComm: An Optimized Library for Scalable Point-to-Point Communication for General CFD Applications}, 
  year={2012},
  volume={},
  number={},
  pages={1001-1006},
  abstract={Domain decomposition is the most widely used technique to achieve parallelism in CFD applications. For complicated geometries usually graph partitioning programs are used to decompose the domain into smaller computational blocks such that the computation load is balanced and communication cost is minimized. In this paper an algorithm is provided and tested which avoids deadlocks in complicated communications patterns inherited from the graph decomposition process. The basic algorithm is implemented using FORTRAN 95 and MPI and then several optimization techniques are used to increase the scalability of the library which include addition of topologies, overlap of communication and computation to mask the message passing latency and non-blocking communication. The library is tested for up to 512 cores on the Iridis-3 cluster which incorporates 1008 compute nodes each composed of 2, 2.4 GHz 6-core Westmere processors. IO and inter-node communication is via a fast Infiniband network which is composed of groups of 32 nodes connected by DDR links to a 48 port QDR leaf-switch. The leaf switches then have 4 trunked QDR connections to 4 QDR 48-port core switches.},
  keywords={},
  doi={10.1109/HPCC.2012.146},
  ISSN={},
  month={June},}
@INPROCEEDINGS{6332318,
  author={Blocho, Miroslaw and Czech, Zbigniew J.},
  booktitle={2012 IEEE 14th International Conference on High Performance Computing and Communication & 2012 IEEE 9th International Conference on Embedded Software and Systems}, 
  title={A Parallel EAX-based Algorithm for Minimizing the Number of Routes in the Vehicle Routing Problem with Time Windows}, 
  year={2012},
  volume={},
  number={},
  pages={1239-1246},
  abstract={A parallel EAX-based algorithm for minimizing the number of routes in the vehicle routing problem with time windows is presented. The main contribution is a novel approach concerning the usage of the edge assembly crossover (EAX) operator during exchanging the best solutions between the processes. The objective of the work is to analyze the speedup, achieved accuracy of solutions and scalability of the MPI implementation. For comparisons the selected Gehring and Homberger's (GH) tests are used. The results of the extensive computational experiments indicate that the new algorithm based on the EAX approach is not only very fast but also very effective. The eight new best-known solutions for the GH benchmarking tests were found by making use of the algorithm.},
  keywords={},
  doi={10.1109/HPCC.2012.182},
  ISSN={},
  month={June},}
@INPROCEEDINGS{6334896,
  author={Kroeker, Anthony and Dimopoulos, Nikitas J. and Khunjush, Farshad},
  booktitle={2012 25th IEEE Canadian Conference on Electrical and Computer Engineering (CCECE)}, 
  title={Using indirection to minimize message delivery latency on cache-less many-core architectures}, 
  year={2012},
  volume={},
  number={},
  pages={1-6},
  abstract={The focus of this work is on techniques that promise to reduce the message delivery latency in message passing interface (MPI) environments for cache-less systems (e.g. the Cell BE processor). Significant contributors to message-delivery latency are the message copying operations during receive. To avoid this copying overhead, we introduce architectural extensions comprising an Indirection Cache and instructions to manage the operations of this extension. This method allows the late binding of the received message by redirecting its effective address. An Indirection Buffer stores the last Receive Variable effective address and uses it predictively for subsequent accesses.},
  keywords={},
  doi={10.1109/CCECE.2012.6334896},
  ISSN={0840-7789},
  month={April},}
@INPROCEEDINGS{6337272,
  author={Wang, Lei and Wombacher, Andreas and Pires, Luís Ferreira and van Sinderen, Marten J. and Chi, Chihung},
  booktitle={2012 IEEE 16th International Enterprise Distributed Object Computing Conference}, 
  title={A State Synchronization Mechanism for Orchestrated Processes}, 
  year={2012},
  volume={},
  number={},
  pages={51-60},
  abstract={Two orchestrated processes interacting with each other have to maintain their own states. Messages are used to synchronize states between orchestrated processes. Server crash and network failure may result in loss of messages and therefore result in a state change performed by only one party. Thus, the states of the parties are no longer synchronized, resulting in state inconsistencies and in worst case deadlocks. In this paper, we propose a mechanism for guaranteed state synchronization of orchestrated processes with system and network failures. Our mechanism is based on interaction patterns and process transformations. The basic idea is to redesign the original processes into their state synchronization-enabled counterparts via process transformations that can be automated. The transformation mechanism is formalized based on Colored Petri Nets. We present the formal proof of the correctness of our mechanism and give the overhead analysis to illustrate its practicability.},
  keywords={},
  doi={10.1109/EDOC.2012.16},
  ISSN={1541-7719},
  month={Sep.},}
@INPROCEEDINGS{6337565,
  author={Morozov, Vitali and Meng, Jiayuan and Vishwanath, Venkatram and Hammond, Jeff R. and Kumaran, Kalyan and Papka, Michael E.},
  booktitle={2012 41st International Conference on Parallel Processing Workshops}, 
  title={ALCF MPI Benchmarks: Understanding Machine-Specific Communication Behavior}, 
  year={2012},
  volume={},
  number={},
  pages={19-28},
  abstract={As systems grow larger and computation is further spread across nodes, efficient data communication is becoming increasingly important to achieve high throughput and low power consumption for high performance computing systems. However, communication efficacy not only depends on application-specific communication patterns, but also on machine-specific communication subsystems, node architectures, and even the runtime communication libraries. In fact, different hardware systems lead to different tradeoffs with respect to communication mechanisms, which can impact the choice of application implementations. We present a set of MPI-based benchmarks to better understand the communication behavior of the hardware systems and guide the performance tuning of scientific applications. We further apply these benchmarks to three clusters and present several interesting lessons from our experience.},
  keywords={},
  doi={10.1109/ICPPW.2012.7},
  ISSN={2332-5690},
  month={Sep.},}
@INPROCEEDINGS{6337512,
  author={Lorenz, Daniel and Philippen, Peter and Schmidl, Dirk and Wolf, Felix},
  booktitle={2012 41st International Conference on Parallel Processing Workshops}, 
  title={Profiling of OpenMP Tasks with Score-P}, 
  year={2012},
  volume={},
  number={},
  pages={444-453},
  abstract={With the task construct, the OpenMP 3.0 specification introduces an additional level of parallelism that challenges established schemes of performance profiling. First, a thread may execute a sequence of interleaved task fragments the profiling system must properly distinguish to enable correct performance analyses. Furthermore, the additional parallelization dimension requires new visualization methods for presenting analysis results. Finally, as a new programming paradigm, tasking implicitly introduces paradigm-specific performance issues and creates a need for corresponding optimization strategies. This paper presents solutions to overcome the challenges of profiling applications based on OpenMP tasks. Second, the paper describes metrics that may help uncover performance problems related to tasking. We present an implementation of our solution within the Score-P performance measurement system, which we evaluate using the Barcelona OpenMP Task Suite.},
  keywords={},
  doi={10.1109/ICPPW.2012.62},
  ISSN={2332-5690},
  month={Sep.},}
@INPROCEEDINGS{6337584,
  author={Kamal, Humaira and Wagner, Alan},
  booktitle={2012 41st International Conference on Parallel Processing}, 
  title={Added Concurrency to Improve MPI Performance on Multicore}, 
  year={2012},
  volume={},
  number={},
  pages={229-238},
  abstract={MPI implementations typically equate an MPI process with an OS-process, resulting in a coarse-grain programming model where MPI processes are bound to the physical cores. Fine-Grain (FG-MPI) extends the MPICH2 implementation of MPI and implements an integrated runtime system to allow multiple MPI processes to execute concurrently inside an OS-process. FG-MPI's integrated approach makes it possible to add more concurrency than available parallelism, while minimizing the overheads related to context switches, scheduling and synchronization. In this paper we evaluate the benefits of added concurrency for cache awareness and message size and show that performance gains are possible by using FG-MPI to adjust the grain-size of a program to better fit the cache and potential advantages in passing smaller versus larger messages. We evaluate the use of FG-MPI on the complete set of the NAS parallel benchmarks over large problem sizes, where we show significant performance improvement (20%-30%) for three of the eight benchmarks. We discuss the characteristics of the benchmarks with regards to trade-offs between the added costs and benefits.},
  keywords={},
  doi={10.1109/ICPP.2012.15},
  ISSN={2332-5690},
  month={Sep.},}
@INPROCEEDINGS{6337583,
  author={Jose, Jithin and Kandalla, Krishna and Luo, Miao and Panda, Dhabaleswar K.},
  booktitle={2012 41st International Conference on Parallel Processing}, 
  title={Supporting Hybrid MPI and OpenSHMEM over InfiniBand: Design and Performance Evaluation}, 
  year={2012},
  volume={},
  number={},
  pages={219-228},
  abstract={Message Passing Interface (MPI) has been the defacto programming model for scientific parallel applications. However, data driven applications with irregular communication patterns are harder to implement using MPI. The Partitioned Global Address Space (PGAS) programming models present an alternative approach to improve programmability. Open SHMEM is a library-based implementation of the PGAS model and it aims to standardize the SHMEM model to achieve performance, programmability and portability. However, Open SHMEM is an emerging standard and it is unlikely that entire an application will be re-written with it. Instead, it is more likely that applications will continue to be written with MPI as the primary model, but parts of them will be re-designed with newer models. This requires the underlying communication libraries to be designed with support for multiple programming models. In this paper, we propose a high performance, scalable unified communication library that supports both MPI and Open SHMEM for InfiniBand clusters. To the best of our knowledge, this is the first effort in unifying MPI and Open SHMEM communication libraries. Our proposed designs take advantage of InfiniBand's advanced features to significantly improve the communication performance of various atomic and collective operations defined in Open SHMEM specification. Hybrid (MPI+Open SHMEM) parallel applications can benefit from our proposed library to achieve better efficiency and scalability. Our studies show that our proposed designs can improve the performance of OpenSHMEM's atomic operations and collective operations by up to 41%. We observe that our designs improve the performance of the 2D-Heat Modeling benchmark (pure Open-SHMEM) by up to 45%. We also observe that our unified communication library can improve the performance of the hybrid (MPI+Open SHMEM) version of Graph500 benchmark by up to 35%. Moreover, our studies also indicate that our proposed designs lead to lower memory consumption due to efficient utilization of the network resources.},
  keywords={},
  doi={10.1109/ICPP.2012.55},
  ISSN={2332-5690},
  month={Sep.},}
@INPROCEEDINGS{6337574,
  author={Gahvari, Hormozd and Gropp, William and Jordan, Kirk E. and Schulz, Martin and Yang, Ulrike Meier},
  booktitle={2012 41st International Conference on Parallel Processing}, 
  title={Modeling the Performance of an Algebraic Multigrid Cycle Using Hybrid MPI/OpenMP}, 
  year={2012},
  volume={},
  number={},
  pages={128-137},
  abstract={The rise of multicore cluster architectures has led to intense interest in using a combination of MPI and OpenMP to more effectively program these machines. We present a performance model for hybrid implementation of the solve cycle of algebraic multigrid (AMG), a popular iterative solver for large sparse linear systems and a key component of many scientific simulations. We validate the model on two leading parallel platforms, and discuss implications for applications programmed in a hybrid model on future machines.},
  keywords={},
  doi={10.1109/ICPP.2012.41},
  ISSN={2332-5690},
  month={Sep.},}
@INPROCEEDINGS{6337813,
  author={Pellegrini, Simone and Hoefler, Torsten and Fahringer, Thomas},
  booktitle={2012 IEEE International Conference on Cluster Computing}, 
  title={On the Effects of CPU Caches on MPI Point-to-Point Communications}, 
  year={2012},
  volume={},
  number={},
  pages={495-503},
  abstract={Several researchers investigated the placing of communication calls in message-passing parallel codes. The current rule of thumb it to maximize communication/computation overlap with early binding. In this work, we demonstrate that this is not the only design constraint because CPU caches can have a significant impact on communications. We conduct an empirical study of the interaction between CPU caching and communications for several different communication scenarios. We use the gained insight to formulate a set of intuitive rules for communication call placement and show how our rules can be applied to practical codes. Our optimized codes show an improvement of up to 40% for a simple stencil code. Our work is a first step towards communication optimizations by moving communication calls. We expect that future communication-aware compilers will use our insights as a standard technique to move communication calls in order to optimize performance.},
  keywords={},
  doi={10.1109/CLUSTER.2012.22},
  ISSN={2168-9253},
  month={Sep.},}
@INPROCEEDINGS{6355868,
  author={Kandalla, K. and Buluç, A. and Subramoni, H. and Tomko, K. and Vienne, J. and Oliker, L. and Panda, D.K.},
  booktitle={2012 IEEE International Conference on Cluster Computing Workshops}, 
  title={Can Network-Offload Based Non-blocking Neighborhood MPI Collectives Improve Communication Overheads of Irregular Graph Algorithms?}, 
  year={2012},
  volume={},
  number={},
  pages={222-230},
  abstract={Graph-based computations are commonly used across various data intensive computing domains ranging from social networks to biological systems. On distributed memory systems, graph algorithms involve explicit communication between processes and often exhibit sparse, irregular behavior. Minimizing these communication overheads is critical to cater to the graph-theoretic analyses demands of emerging âbigdataâ applications. In this paper, we explore the challenges associated with reducing the communication overheads of a popular 2D Breadth First Search (BFS) implementation in the CombBLAS library. This BFS algorithm relies on two common MPI collectives, MPI Alltoallv and MPI Allgathervto exchange data between processes and they account for more than 20% of the overall run time. Re-designing parallel applications to take advantage of MPI-3 non-blocking collectives to achieve latency hiding is an active area of research. However, the 2D BFS algorithm in CombBLAS is not directly amenable for such a re-design through common overlap techniques such as, double-buffering. In this paper, we propose to re-design the BFS algorithm to leverage MPI-3 no blocking, neighborhood collective communication operations to achieve fine-grained computation/communication overlap. We also leverage the CORE-Direct network offload feature in theConnectX-2 InfiniBand adapter from Mellanox to design highly efficient and scalable non-blocking, neighborhood Alltoallv and Allgatherv collective operations. Our experimental evaluations show that we can improve the communication overheads of the2D BFS algorithm by up to 70%, with 1,936 processes.},
  keywords={},
  doi={10.1109/ClusterW.2012.40},
  ISSN={},
  month={Sep.},}
@INPROCEEDINGS{6356923,
  author={Sun, Ning and Wu, Jingxian and Lin, Hai},
  booktitle={2012 1st IEEE International Conference on Communications in China (ICCC)}, 
  title={Distributed joint source and channel code with correlated information sources}, 
  year={2012},
  volume={},
  number={},
  pages={443-447},
  abstract={In this paper, a new distributed joint source-channel code (DJSCC) is proposed for a communication network with multiple correlated information sources. The DJSCC is performed by puncturing the information bits of a linear block code but leaving the parity bits intact, given the fact that the correlation among the parity bits is usually much lower compared to the corresponding information bits. In recognition of the different roles of the information and parity bits in the DJSCC scheme, we propose to allocate unequal amounts of energy per bit to these two different types of bits. The unequal energy allocation leads to significant performance gains over conventional equal energy transmissions. At the receiver, the sources are jointly decoded with the iterative message passing algorithm. Simulation results demonstrate that the proposed scheme can achieve considerable performance gains over conventional schemes.},
  keywords={},
  doi={10.1109/ICCChina.2012.6356923},
  ISSN={2377-8644},
  month={Aug},}
@INPROCEEDINGS{6358373,
  author={Zhao, Xian-yong and Chen, Xiao-fang and Gui, Wei-hua},
  booktitle={Proceedings of the 10th World Congress on Intelligent Control and Automation}, 
  title={EBE-based parallel finite element analysis of electric field in aluminum reduction cell}, 
  year={2012},
  volume={},
  number={},
  pages={2939-2943},
  abstract={Finite element analysis for large-scale complicated structure such as aluminum reduction cell makes higher demand on memory capacity and calculation speed, which often results in failure or inefficiency of traditional serial computation for such large-scale problems. Finite element EBE-PCG algorithm is proposed on the basis of EBE(Element-By-Element) idea and Jacobi preconditioned conjugate gradient(PCG) method. The main difficulties in parallel implementation of this algorithm are discussed and solved, such as data organization of grid model, mixed elements processing and data communication. Subsequently, parallel program of finite element analysis based on EBE-PCG is developed using C language and MPI standard library, and then applied to numeric simulation of electric field distribution in aluminum reduction cell. The computational accuracy of parallel program developed is verified through comparison with commercial finite element software ANSYS. Experiment results show that the method is of very high parallel efficiency and can greatly shorten the calculation time, which indicates the effectiveness of EBE's use in parallel computation of large-scale complicated structures.},
  keywords={},
  doi={10.1109/WCICA.2012.6358373},
  ISSN={},
  month={July},}
@INPROCEEDINGS{6363991,
  author={Kang, Soonyoung and Moon, Jaekyun},
  booktitle={2012 IEEE International Conference on Communications (ICC)}, 
  title={Parallel LDPC decoder implementation on GPU based on unbalanced memory coalescing}, 
  year={2012},
  volume={},
  number={},
  pages={3692-3697},
  abstract={We consider flexible decoder implementation of low density parity check (LDPC) codes via compute-unified-device-architecture (CUDA) programming on graphics processing unit (GPU), a research subject of considerable recent interest. An important issue in LDPC decoder design based on CUDA-GPU is realizing coalesced memory access, a technique that reduces memory transaction time considerably. In previous works along this direction, it has not been possible to achieve coalesced memory access in both the read and write operations due to the asymmetric nature of the bipartite graph describing the LDPC code structure. In this paper, a new algorithm is proposed that enables coalesced memory access in both the read and write operations for one half of the decoding process - either the bit-to-check or the check-to-bit message passing. For the remaining half of the decoding step our scheme requires address transformation in both the read and write operations but one translating array is sufficient. We also describe the use of on-chip shared memory and texture cache. Overall, experimental results show that proposed GPU-based LDPC decoder achieves more than 234×-speedup compared to CPU-based LDPC decoders and also outperforms existing GPU-based decoders by a significant margin.},
  keywords={},
  doi={10.1109/ICC.2012.6363991},
  ISSN={1938-1883},
  month={June},}
@INPROCEEDINGS{6364014,
  author={Kesidis, G. and Kurve, A.},
  booktitle={2012 IEEE International Conference on Communications (ICC)}, 
  title={A study of unsupervised adaptive crowdsourcing}, 
  year={2012},
  volume={},
  number={},
  pages={1438-1442},
  abstract={We consider unsupervised crowdsourcing performance based on the model wherein the responses of end-users are essentially rated according to how their responses correlate with the majority of other responses to the same subtasks/questions. In one setting, we consider an independent sequence of identically distributed crowdsourcing assignments (meta-tasks), while in the other we consider a single assignment with a large number of component subtasks. Both problems yield intuitive results in which the overall reliability of the crowd is a factor.},
  keywords={},
  doi={10.1109/ICC.2012.6364014},
  ISSN={1938-1883},
  month={June},}
@INPROCEEDINGS{6364027,
  author={Gonçalves, João M. and Gomes, Diogo and Aguiar, Rui},
  booktitle={2012 IEEE International Conference on Communications (ICC)}, 
  title={Low-latency privacy-enabled Context Distribution Architecture}, 
  year={2012},
  volume={},
  number={},
  pages={1917-1922},
  abstract={As personal information and context sharing applications gain traction more attention is drawn to the associated privacy issues. These applications address privacy using an unsatisfactory “whitelist” approach, similar to social networks “friends”. Some of them also link location publishing with user interaction which is also a form of privacy control - the user has to explicitly say where he is. There are a few automatic location based-services (LBS) that track the user, but without more adequate privacy protection mechanisms they enable even bigger threats to the user. On previous work, an XMPP-based Context Distribution Architecture was defined, more suitable for the distribution of frequently changing context than other systems because it is based on the publish-subscribe pattern. In this paper the authors present an extension to this architecture that allows for the introduction of a complex degree of access control in context distribution. The devised changes enable the system to consider a number of interesting context privacy settings for context distribution control. Also, this control must be enforced in a way that it doesn't interfere with the real-time nature of the distribution process. After describing the enhancements to the architecture, a prototype of the system is presented. Finally, the delivery latency and additional processing introduced by the access control components is estimated by testing it against the existing system.},
  keywords={},
  doi={10.1109/ICC.2012.6364027},
  ISSN={1938-1883},
  month={June},}
@INPROCEEDINGS{6362987,
  author={Garcés, Nathalia and Sotelo, German A. and Villamizar, Mario and Castro, Harold},
  booktitle={2012 Seventh International Conference on P2P, Parallel, Grid, Cloud and Internet Computing}, 
  title={Running MPI Applications over Opportunistic Cloud Infrastructures}, 
  year={2012},
  volume={},
  number={},
  pages={309-314},
  abstract={This paper analyzes in detail the difficulties and issues that must be faced when running MPI (Message Passing Interface) applications over non-dedicated infrastructures. Alternatives to overcome these issues on a specific opportunistic infrastructure, called UnaCloud, are presented. We designed and implemented a UnaCloud extension to allow automatic recovery of the execution of MPI applications. This extension will provide new opportunities for research groups, allowing researchers to run MPI applications with a minimum overhead and at a low cost. We tested our implementation running a large application for several hours: Gromacs MPI, a molecular dynamic application that uses MPI to predict and redefine the tertiary structure of a particular protein. Our results show that running such an application is indeed possible, even if the underlying infrastructure exhibits high volatility. This provides a setting to introduce UnaCloud as an opportunistic platform that can be used to run Bag of Tasks (BoT) and MPI applications.},
  keywords={},
  doi={10.1109/3PGCIC.2012.61},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{6365102,
  author={Cicirelli, Franco and Furfaro, Angelo and Nigro, Libero and Pupo, Francesco},
  booktitle={2012 IEEE/ACM 16th International Symposium on Distributed Simulation and Real Time Applications}, 
  title={Development of a Schedulability Analysis Framework Based on pTPN and UPPAAL with Stopwatches}, 
  year={2012},
  volume={},
  number={},
  pages={57-64},
  abstract={This paper proposes an original schedulability framework which is based on preemptive Time Petri Nets (pTPNs) and UPPAAL with stopwatches (UPPAALSW). The realization enables a real-time tasking set, along with precedence constraints in the form of data control, message passing etc., to be uniformly formalized using pTPNs and then analyzed through model checking using UPPAALSW in the presence of a reusable library of template processes modelling transitions of the source pTPNs specification and the scheduler algorithm which can be based on fixed priority or earliest deadline first. The paper first introduces and motivates the proposed approach by relating it to similar work described in literature, then summarizes the pTPNs formalism through a modelling example. After that the prototyped library in UPPAALSW is presented and put to work for model checking the chosen real-time tasking set. Analysis of models which depend e.g. on non deterministic execution times and sporadic arrival times of tasks, is conditioned by the use of an over approximation in the generation of the model state graph.},
  keywords={},
  doi={10.1109/DS-RT.2012.16},
  ISSN={1550-6525},
  month={Oct},}
@INPROCEEDINGS{6375071,
  author={Zhang, Kefei and Zheng, Xiuhong},
  booktitle={2012 Fourth International Conference on Computational Intelligence and Communication Networks}, 
  title={A Network Parallel Computing System Based on Ethernet}, 
  year={2012},
  volume={},
  number={},
  pages={65-68},
  abstract={Network parallel computing is a problem solving procedure that using diversified computing resources simultaneously. It is an effective ways to large calculation at present. In order to carry out network parallel computing, two basic conditions are required: network parallel computing system and MPI. The former provides the hardware platform and MPI is uniform programming environments for parallel program design. This paper elaborated the building process of a network parallel computing system from the following aspects: hardware , network setting, the configuration and using of MPI. An example is given to test the performance of the whole system. The results show that it is a better solving way to small-scale task.},
  keywords={},
  doi={10.1109/CICN.2012.20},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{6385380,
  author={Leduc-Primeau, François and Raymond, Alexandre J. and Giard, Pascal and Cushon, Kevin and Thibeault, Claude and Gross, Warren J.},
  booktitle={Proceedings of the 2012 Conference on Design and Architectures for Signal and Image Processing}, 
  title={High-throughput LDPC decoding using the RHS algorithm}, 
  year={2012},
  volume={},
  number={},
  pages={1-6},
  abstract={The relaxed half-stochastic (RHS) algorithm is a recently proposed binary message-passing decoding algorithm for low-density parity check codes that can reach the same error rate performance as belief propagation algorithms that exchange LLR messages. Because of its low-complexity interleaver, the RHS algorithm makes it possible to achieve a fully-parallel implementation that can converge to a codeword in only a few clock cycles on average, enabling high throughput and power efficiency. To demonstrate the practicality of the RHS algorithm, we implement a decoder for the popular IEEE 802.3an 10GBASE-T standard. The paper presents details of the hardware implementation, as well as post-layout results for an ASIC implementation in 65nm CMOS technology, which indicate that the decoder can operate at 448 MHz and occupies an area of 4.41 mm2. The results obtained from bit-accurate software simulations show that the decoder meets the latency requirement prescribed by the standard and provides an average throughput of 160 Gbps.},
  keywords={},
  doi={},
  ISSN={},
  month={Oct},}
@INPROCEEDINGS{6384986,
  author={Dheeraj, D. and Nitish, B. and Ramesh, Shruti},
  booktitle={2012 International Conference on Cyber-Enabled Distributed Computing and Knowledge Discovery}, 
  title={Optimization of Automatic Conversion of Serial C to Parallel OpenMP}, 
  year={2012},
  volume={},
  number={},
  pages={309-314},
  abstract={This paper implements a technique that enhances parallel execution of auto-generated OpenMP programs by considering architecture of on chip cache memory. It avoids false-sharing in 'for-loops' by generating OpenMP code for dynamically scheduling chunks by placing each core's data cache line size apart. An open-source parallelization tool called Par4All has been analyzed and its power has been unleashed to achieve maximum hardware utilization. Some of the computationally intensive programs from Poly Bench have been tested on different architectures, with different data sets and the results obtained reveal that the OpenMP codes generated by the enhanced technique have resulted in considerable speedup.},
  keywords={},
  doi={10.1109/CyberC.2012.59},
  ISSN={},
  month={Oct},}
@INPROCEEDINGS{6385253,
  author={Guo, Yucheng and Hu, Dongxu and Wu, Peng},
  booktitle={2012 11th International Symposium on Distributed Computing and Applications to Business, Engineering & Science}, 
  title={MPI-Based Heterogeneous Cluster Construction Technology}, 
  year={2012},
  volume={},
  number={},
  pages={120-124},
  abstract={Nowadays, the applications of MPI-based clusters are used widely, such as the damage prediction of nuclear explosion and gene decryption. However, the usages of MPIbased heterogeneous cluster are nearly reported in contrast to the MPI-based homogeneous clusters due to the immature technology. This paper focuses on building a MPI based heterogeneous cluster with the MPICH2, which is released last year and has not supported the heterogeneous cluster yet. Beside, we give the reasons and test results in the paper to illustrate the benefits of using the MPI-based heterogeneous cluster without virtualization.},
  keywords={},
  doi={10.1109/DCABES.2012.116},
  ISSN={},
  month={Oct},}
@INPROCEEDINGS{6391169,
  author={Cao, Wei and Yang, Bo and Chen, Cailian and Guan, Xinping},
  booktitle={Proceedings of the 31st Chinese Control Conference}, 
  title={Event-triggered algorithm of demand response in power grid based on social welfare maximization}, 
  year={2012},
  volume={},
  number={},
  pages={6974-6979},
  abstract={Demand response is a method to increase efficiency of power grid which should be utilized in the next generation of power grid. In this paper, we propose a generalized model of users' electrical power consumption and a distributed demand management scheme in which we could achieve the maximization of total users' utility in power grid. Considering the limited communication situation in power grid, we present an event-triggered demand response scheme to reduce the message transmission between energy provider and energy consumption side. The efficiency of the proposed scheme is verified via simulations.},
  keywords={},
  doi={},
  ISSN={2161-2927},
  month={July},}
@INPROCEEDINGS{6391892,
  author={Cheng, Guo and Chen, Luo and Wu, Qiuyun and Jing, Ning},
  booktitle={2012 IEEE 12th International Conference on Computer and Information Technology}, 
  title={Parallelization Methods for Edge Extraction Applied to Chip Multiprocessor Clusters}, 
  year={2012},
  volume={},
  number={},
  pages={156-162},
  abstract={As the parallel computing technologies become mature, many computationally intensive and/or data intensive algorithms could be improved with parallelization methods. In this paper, we improve the performance of the edge extraction algorithmic program by parallelizing the sequential algorithm. We altogether propose three parallelization methods based on chip multiprocessor (CMP) clusters. The OpenMP-based method is investigated for the shared memory model and thus it is applied to single CMP node, while the three MPI-based methods are investigated for the message passing model and thus they are applied to CMP-clusters. Massive experiments verify that the parallelization methods proposed in this paper are all effective and efficient.},
  keywords={},
  doi={10.1109/CIT.2012.53},
  ISSN={},
  month={Oct},}
@INPROCEEDINGS{6393448,
  author={Hwang, Eun Hye and Cho, Seong Jin and Kim, Kil Jae and Kim, Yeong Jun and Yoon, Seung Hyun and Jeon, Jae Wook},
  booktitle={2012 12th International Conference on Control, Automation and Systems}, 
  title={A recovery algorithm for PE files in a multi-core system}, 
  year={2012},
  volume={},
  number={},
  pages={289-293},
  abstract={Several tools are available for reverse engineering Windows portable executable (PE) files. The first step of reverse engineering is to disassemble the PE file. However, files sometimes do not load or open correctly due an incorrect PE file format. We therefore developed an algorithm that restores the PE file structure of an incorrectly formatted PE file. The program that uses this algorithm loads the file to memory, reconstructs the file format automatically, and then saves the new file. However, processing of many large files can result in performance degradation. We therefore adopted a parallel programming technique that uses open multi-processing (OpenMP) to simultaneously process large files. For parallel programming, we used thread level parallelism and data decomposition. We compared the performance of a sequential implementation of our algorithm and two parallel implementations of the algorithm by evaluating execution time, CPU usage, and concurrency for three different files using Visual Studio's Profiler and Intel Parallel Studio 2011. Parallel processing reduced execution time by about 75% compared to sequential processing.},
  keywords={},
  doi={},
  ISSN={},
  month={Oct},}
@INPROCEEDINGS{6398133,
  author={Prakash, Geetha and Kulkarni, Muralidhar and Sripati, U and Kalyanpur, Mahesh Nayak},
  booktitle={2012 International Conference on Communication, Information & Computing Technology (ICCICT)}, 
  title={Performance analysis of Free Space Optical links encoded using Luby Transform codes}, 
  year={2012},
  volume={},
  number={},
  pages={1-6},
  abstract={Free Space Optical (FSO) communication is an emerging transmission technique to transmit high data rates without using cables. This technology is expected to revolutionize the present communication system architectures both in the terrestrial and the in -space architecture. Atmospheric effects can significantly degrade the performance of FSO systems. This reduces the SNR and leads to impaired performance. FSO channels can be modeled using Gamma-Gamma, Weibull, Log-Normal, K distribution functions. Error control codes can help to mitigate atmospheric turbulence induced signal fading in free space optical communication links. Luby Transform codes belong to a class of error control codes called Fountain codes and are meant for erasure channels. In this paper, we propose encoding FSO links with Luby Transform (LT) codes for error channels. Decoding is done using belief propagation with Log Likelihood Ratio and results are obtained for different modulation schemes under different channel distributions.},
  keywords={},
  doi={10.1109/ICCICT.2012.6398133},
  ISSN={},
  month={Oct},}
@INPROCEEDINGS{6404487,
  author={Takano, Ryousei and Nakada, Hidemoto and Hirofuchi, Takahiro and Tanaka, Yoshio and Kudoh, Tomohiro},
  booktitle={2012 IEEE 8th International Conference on E-Science}, 
  title={Cooperative VM migration for a virtualized HPC cluster with VMM-bypass I/O devices}, 
  year={2012},
  volume={},
  number={},
  pages={1-8},
  abstract={An HPC cloud, a flexible and robust cloud computing service specially dedicated to high performance computing, is a promising future e-Science platform. In cloud computing, virtualization is widely used to achieve flexibility and security. Virtualization makes migration or checkpoint/restart of computing elements (virtual machines) easy, and such features are useful for realizing fault tolerance and server consolidations. However, in widely used virtualization schemes, I/O devices are also virtualized, and thus I/O performance is severely degraded. To cope with this problem, VMM-bypass I/O technologies, including PCI passthrough and SR-IOV, in which the I/O overhead can be significantly reduced, have been introduced. However, such VMM-bypass I/O technologies make it impossible to migrate or checkpoint/restart virtual machines, since virtual machines are directly attached to hardware devices. This paper proposes a novel and practical mechanism, called Symbiotic Virtualization (SymVirt), for enabling migration and checkpoint/restart on a virtualized cluster with VMM-bypass I/O devices, without the virtualization overhead during normal operations. SymVirt allows a VMM to cooperate with a message passing layer on the guest OS, then it realizes VM-level migration and checkpoint/restart by using a combination of a PCI hotplug and coordination of distributed VMMs. We have implemented the proposed mechanism on top of QEMU/KVM and the Open MPI system. All PCI devices, including Infiniband and Myrinet, are supported without implementing specific para-virtualized drivers; and it is not necessary to modify either of the MPI runtime and applications. Using the proposed mechanism, we demonstrate reactive and proactive FT mechanisms on a virtualized Infiniband cluster. We have confirmed the effectiveness using both a memory intensive micro benchmark and the NAS parallel benchmark. Moreover, we also show that postcopy live migration enables us to reduce the down time of an application as the memory footprint increases.},
  keywords={},
  doi={10.1109/eScience.2012.6404487},
  ISSN={},
  month={Oct},}
@INPROCEEDINGS{6407112,
  author={Ueng, Yeong-Luh and Cheng, Chung-Chao},
  booktitle={2012 International SoC Design Conference (ISOCC)}, 
  title={A study into high-throughput decoder architectures for high-rate LDPC codes}, 
  year={2012},
  volume={},
  number={},
  pages={347-350},
  abstract={This study investigates a variety of high-throughput decoder architectures designed for high-rate low-density parity-check (LDPC) codes. To implement a high-throughput decoder, a fully-parallel architecture can be adopted, but with complex interconnections. In order to reduce the routing complexity, a Split-Row Threshold decoder can be adopted. However, the high check-node degree of a high-rate LDPC code leads to a long critical path when using the Split-Row Threshold decoder. The long critical path can be shortened by using partially-parallel architectures combined with vertical scheduling. Two-phase message passing and shuffled message passing can be adopted in the vertical scheduling. The features of these state-of-the-art high-throughput decoder architectures and the associated comparison are presented in this paper.},
  keywords={},
  doi={10.1109/ISOCC.2012.6407112},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{6407438,
  author={Wolterink, W. Klein and Heijenk, G. and van den Berg, J.L.},
  booktitle={2012 IEEE Vehicular Networking Conference (VNC)}, 
  title={An analytical model for the performance of geographical multi-hop broadcast}, 
  year={2012},
  volume={},
  number={},
  pages={242-249},
  abstract={In this paper we present an analytical model accurately describing the behaviour of a multi-hop broadcast protocol. Our model covers the scenario in which a message is forwarded over a straight road and inter-node distances are distributed exponentially. Intermediate forwarders draw a small random delay before forwarding a message such as is done in flooding protocols to avoid the broadcast storm problem. For a given node density and single-hop packet reception probability, the model is able to capture the probability distribution of (i) the delay of each hop, (ii) the length of each hop, (iii) the position of each forwarder, (iv) the required number of hops to cover the dissemination distance, and (v) the end-to-end delay to cover the dissemination distance. The model provides these quantities in terms of insightful, fast-to-evaluate closed-form expressions. The model has been validated by extensive simulations: modelling results stayed within typically 10%, depending on the source-to-sink distance and the node density.},
  keywords={},
  doi={10.1109/VNC.2012.6407438},
  ISSN={2157-9865},
  month={Nov},}
@INPROCEEDINGS{6413632,
  author={Wu, Zhimin and Wang, Rui and Xu, Weizhi and Chen, Mingyu and Yao, Erlin},
  booktitle={2012 IEEE 18th International Conference on Parallel and Distributed Systems}, 
  title={Supporting User-directed Fault Tolerance over Standard MPI}, 
  year={2012},
  volume={},
  number={},
  pages={696-697},
  abstract={User-directed means the process of carrying out fault tolerance is dynamic and the fault tolerance mode is chosen by users based on application requirements. In this paper, we introduce a general scheme based on standard MPI to provide the user directed support for application level algorithmic fault tolerance. The user-directed fault tolerance plays the role as a connection between applications and algorithmic fault tolerance. As a case study, our scheme has been incorporated to HPL combined with a non-blocking ABFT technique. We have tested the functional availability of our scheme for fault tolerance in real circumstance. We also evaluated that when there is no failure occurring, our support only brings 2.5 percent overhead. When failure occurs, with our scheme, the scalability of algorithmic fault tolerance maintains well.},
  keywords={},
  doi={10.1109/ICPADS.2012.100},
  ISSN={1521-9097},
  month={Dec},}
@INPROCEEDINGS{6413672,
  author={Guay, Wei Lin and Reinemo, Sven-Arne and Johnsen, Bjørn Dag and Skeie, Tor and Torudbakken, Ola},
  booktitle={2012 IEEE 18th International Conference on Parallel and Distributed Systems}, 
  title={A Scalable Signalling Mechanism for VM Migration with SR-IOV over Infiniband}, 
  year={2012},
  volume={},
  number={},
  pages={384-391},
  abstract={Single Root I/O Virtualization (SR-IOV) is a promising I/O virtualization approach for achieving high performance in the virtualization over InfiniBand (IB) network. One challenge is related to the hardware address assignment for each virtual IB device. There are two schemes for the hardware address assignment, static assignment and dynamic assignment. Static assignment always preserves the hardware address of a virtual IB device that is attached to a VM, but the dynamic assignment does not. A drawback, however, using static assignment is that its communication will be disconnected after VM migration. In this paper, we point out the problem related to SR-IOV over IB that breaks the network connections after VM migration when the static assignment is deployed. Then, we propose a signalling mechanism that can maintain the network connectivity after VM migration. The performance evaluation using an experimental test bed shows that the proposed signalling mechanism does not increase the service downtime during hot migration. We also optimize the signalling method, where the same event can only be forwarded to a physical server once regardless of the hosted VMs, to reduce the management message overhead from O(n*m) to O(n).},
  keywords={},
  doi={10.1109/ICPADS.2012.60},
  ISSN={1521-9097},
  month={Dec},}
@INPROCEEDINGS{6413677,
  author={Preud'Homme, Thomas and Sopena, Julien and Thomas, Gaël and Folliot, Bertil},
  booktitle={2012 IEEE 18th International Conference on Parallel and Distributed Systems}, 
  title={An Improvement of OpenMP Pipeline Parallelism with the BatchQueue Algorithm}, 
  year={2012},
  volume={},
  number={},
  pages={348-355},
  abstract={In the context of multicore programming, pipeline parallelism is a solution to easily transform a sequential program into a parallel one without requiring a whole rewriting of the code. The OpenMP stream-computing extension presented by Pop and Cohen proposes an extension of OpenMP to handle pipeline parallelism. However, their communication algorithm relies on Multiple-producer-Multiple-Consumer queues, while pipelined applications mostly deal with linear chains of communication, i.e., with only a single producer and a single consumer. To improve the performance of the OpenMP stream-extension, we propose to add a more specialized Single-Producer-Single-Consumer communication algorithm called Batch Queue and to select it for one-to-one communication. Our evaluation shows that Batch Queue is then able to improve the throughput up to a factor 2 on an 8-core machine both for example application and real applications. Our study shows therefore that using specialized and efficient communication algorithms can have a significant impact on the overall performance of pipelined applications.},
  keywords={},
  doi={10.1109/ICPADS.2012.55},
  ISSN={1521-9097},
  month={Dec},}
@INPROCEEDINGS{6419482,
  author={Jakimovska, Danijela and Jakimovski, Goran and Tentov, Aristotel and Bojchev, Dimitar},
  booktitle={2012 20th Telecommunications Forum (TELFOR)}, 
  title={Performance estimation of parallel processing techniques on various platforms}, 
  year={2012},
  volume={},
  number={},
  pages={1409-1412},
  abstract={As information society changes, the digital world is making more use of larger bulks of data and complex operations that need to be executed. This trend has caused overcoming the processor speed limit issues, by introducing multiple processor systems. In spite of hardware-level parallelism, the software has evolved with various techniques for achieving parallel programs execution. Executing a program in parallel can be efficiently done only if the program code follows certain rules. There are many techniques, which tend to provide variant processing speeds. The aim of this paper is to test the Matlab, OpenMPI and Pthreads methods on a single-processor, multi-processor, GRID and cluster systems and suggest optimal method for that particular system.},
  keywords={},
  doi={10.1109/TELFOR.2012.6419482},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{6424850,
  author={Vavala, Bruno and Neves, Nuno},
  booktitle={2012 IEEE 31st Symposium on Reliable Distributed Systems}, 
  title={Robust and Speculative Byzantine Randomized Consensus with Constant Time Complexity in Normal Conditions}, 
  year={2012},
  volume={},
  number={},
  pages={161-170},
  abstract={Randomized Byzantine Consensus can be an interesting building block in the implementation of asynchronous distributed systems. Despite its exponential worst-case complexity, which would make it less appealing in practice, a few experimental works have argued quite the opposite. To bridge the gap between theory and practice, we analyze a well-known state-of-the-art algorithm in normal system conditions, in which crash failures may occur but no malicious attacks, proving that it is fast on average. We then leverage our analysis to improve its best-case complexity from three to two phases, by reducing the communication operations through speculative executions. Our findings are confirmed through an experimental validation.},
  keywords={},
  doi={10.1109/SRDS.2012.62},
  ISSN={1060-9857},
  month={Oct},}
@INPROCEEDINGS{6449893,
  author={Yang, Rui and Thomas, Johnson},
  booktitle={2012 2nd IEEE International Conference on Parallel, Distributed and Grid Computing}, 
  title={Processing dependent tasks on a Heterogeneous GPU resource architecture}, 
  year={2012},
  volume={},
  number={},
  pages={627-632},
  abstract={The development of General Purpose GPUs (GPGPU) provides multiple cores of computing power and high memory bandwidth that can meet the high performance requirements of researchers in diverse areas such as weather forecasting, bioinformatics, and even nuclear simulation. In this work we present a Heterogeneous GPU computing system (HG) which can utilize GPUs with different capabilities. Firstly, the HG quantifies the capability of each GPU, and then assigns an acceptable workload to each GPU. The HG is different from other distributed GPU systems because HG can process dependent tasks which indicates the tasks in HG can communicate with each other. Using this architecture HG can deal with more complex task dependent applications. To validate our approach, in the first set of experiments we show that multiple GPU performs better in complex computing applications. Next we use 2D heat equation application to compare HG with a MPI program running on CPUs. With increasing work set size, computing power of HG results in a much better performance than the CPUs system.},
  keywords={},
  doi={10.1109/PDGC.2012.6449893},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{6363176,
  author={Marshall, Philip A. and Gaudet, Vincent C. and Elliott, Duncan G.},
  booktitle={2012 IEEE Workshop on Signal Processing Systems}, 
  title={Effects of Varying Message Precision in Digit-Online LDPC Decoders}, 
  year={2012},
  volume={},
  number={},
  pages={7-12},
  abstract={Increasing the pipeline depth of bit-parallel message-passing low-density parity-check (LDPC) decoders can be done by increasing the number of simultaneously decoded frames, or by decreasing the amount of parallelism in the decoder. In digit-serial decoders, the pipeline depth can also be increased by increasing message precision. Digit-online decoders are a class of digit-serial decoders that use redundant notation to allow for most-significant-digit-first processing of LLR messages. This paper examines the effect of changing the precision of LLRs on the throughput, area and energy efficiency of digit-online decoders for the irregular WiMAX rate 3/4A length 1056 block code. Both single-frame and frame-interlaced decoding are considered. Digit-online decoders have a throughput that is largely independent of message precision. Frame-interlaced decoding has a higher throughput than single-frame, but has an increased energy/bit cost.},
  keywords={},
  doi={10.1109/SiPS.2012.32},
  ISSN={2162-3570},
  month={Oct},}
@INPROCEEDINGS{6459679,
  author={Yue Jia and Bodanese, Eliane and Bigham, John},
  booktitle={2012 IV International Congress on Ultra Modern Telecommunications and Control Systems}, 
  title={Checking the robustness of a Message Oriented Middleware based system}, 
  year={2012},
  volume={},
  number={},
  pages={280-285},
  abstract={The publish/subscribe paradigm is used to support a many-to-many model that allows an efficient dissemination of messages across a distributed system. Message Oriented Middleware (MOM) is a middleware that provides an asynchronous method of passing information between networked applications. MOMs can be based on a publish/subscribe model, which offers a robust paradigm for message delivery. This paper is concerned with this specific type of MOM. Recently, systems using MOMs have been used to integrate enterprise systems over geographically distributed areas, like the ones used in financial services, telecommunication applications, transportation and health-care systems. However, the reliability of a MOM system must be verified as well as the guarantees of delivery and reachability to all intended destinations. This paper provides a suitable way of checking the configuration of a publish/subscribe MOM system by building a model and using Linear-time Temporal Logic and Computation Tree Logic rules to verify certain constraints. In addition a code generator and a sub-paths detector are implemented to make the system checking more user-friendly and efficient.},
  keywords={},
  doi={10.1109/ICUMT.2012.6459679},
  ISSN={2157-023X},
  month={Oct},}
@INPROCEEDINGS{6463002,
  author={Dong-Hyuk Lee and Hyungpil Moon and Ja Choon Koo and Hyouk Ryeol Choi},
  booktitle={2012 9th International Conference on Ubiquitous Robots and Ambient Intelligence (URAI)}, 
  title={MATRIX: A message passing interface for MPMD (Multiple Program Multiple Data) applications on heterogeneous distributed network}, 
  year={2012},
  volume={},
  number={},
  pages={310-315},
  abstract={This paper presents a message passing interface called MATRIX for the MPMD (Multiple Program Multiple Data) type parallel application running on a distributed network. The proposed interface provides network abstraction and peer-to-peer message transfer method to the application layer. The interface is designed to have scalability for a large-scale application. The concurrent application established on the proposed interface can be applied to a heterogeneous distributed network composed of multi-architectures and multi-OS machines. This paper describes the concepts, protocols and implementations of the message passing interface. Additionally, we present the remote file transfer and execution protocol called FTXP for large-scale applications on the message passing interface. For the verification of the proposed methods, we present an example of parallel application applied to a surveillance robot system composed of multi-architecture and multi-OS.},
  keywords={},
  doi={10.1109/URAI.2012.6463002},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{6462909,
  author={El-Sayed, Gamal A. and Hossny, Khadra A.},
  booktitle={2012 2nd International Conference on Advances in Computational Tools for Engineering Applications (ACTEA)}, 
  title={A distributed counter-based non-blocking coordinated checkpoint algorithm for grid computing applications}, 
  year={2012},
  volume={},
  number={},
  pages={80-85},
  abstract={In distributed systems, there are many opportunities for failure. Any component in any compute node could fail. This includes, but is not limited to, the processor, disk, memory, or network interface on the node. Any of these failures will cause the processes running on the affected nodes to crash or produce incorrect results. The common method of ensuring the progress of these processes is to take a checkpoint, this issue is complicated if the processes are inter-communication processes. This paper presents a distributed non-blocking coordinated checkpointing algorithm that ensures producing global consistent checkpoints images. These consistent checkpoint images can be used to migrate application processes to different computing nodes when a failure takes place.},
  keywords={},
  doi={10.1109/ICTEA.2012.6462909},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{6466622,
  author={Sibel, Jean-Christophe and Reynal, Sylvain},
  booktitle={2012 International Conference on Control, Automation and Information Sciences (ICCAIS)}, 
  title={On the Generalized Belief Propagation and its dynamics}, 
  year={2012},
  volume={},
  number={},
  pages={375-380},
  abstract={Numerous inference problems in statistical physics, computer vision or error-correcting coding theory consist in approximating the marginal probability distributions on Markov Random Fields (MRF). The Belief Propagation (BP) is an accurate solution that is optimal if the MRF is loop free and suboptimal otherwise. In the context of error-correcting coding theory, any Low-Density Parity-Check (LDPC) code has a graphical representation, the Tanner graph, which is a particular MRF. It is used as a media for the BP algorithm to correct the bits, damaged by a noisy channel, by estimating their probability distributions. Though loops and combination thereof in the Tanner graph prevent the BP from being optimal, especially harmful topological structures called the trapping-sets. The BP has been extended to the Generalized Belief Propagation (GBP). This message-passing algorithm runs on a non unique mapping of the Tanner graph, namely the regiongraph, such that its nodes are gatherings of the Tanner graph nodes. Then it appears the possibility to decrease the loops effect, making the GBP more accurate than the BP. In this article, we expose a novel region graph construction suited to the Tanner code, an LDPC code whose Tanner graph is entirely covered by trapping-sets. Furthermore, we investigate the dynamic behavior of the GBP compared with that of the BP to understand its evolution in terms of the Signal-to-Noise Ratio (SNR). To this end we make use of classical estimators and we introduce a new one called the hyperspheres method.},
  keywords={},
  doi={10.1109/ICCAIS.2012.6466622},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{6468512,
  author={Schindewolf, Martin and Biliari, Barna and Gyllenhaal, John and Schulz, Martin and Wang, Amy and Karl, Wolfgang},
  booktitle={SC '12: Proceedings of the International Conference on High Performance Computing, Networking, Storage and Analysis}, 
  title={What scientific applications can benefit from hardware transactional memory?}, 
  year={2012},
  volume={},
  number={},
  pages={1-11},
  abstract={Achieving efficient and correct synchronization of multiple threads is a difficult and error-prone task at small scale and, as we march towards extreme scale computing, will be even more challenging when the resulting application is supposed to utilize millions of cores efficiently. Transactional Memory (TM) is a promising technique to ease the burden on the programmer, but only recently has become available on commercial hardware in the new Blue Gene/Q system and hence the real benefit for realistic applications has not been studied yet. This paper presents the first performance results of TM embedded into OpenMP on a prototype system of BG/Q and characterizes code properties that will likely lead to benefits when augmented with TM primitives. We first study the influence of thread count, environment variables and memory layout on TM performance and identify code properties that will yield performance gains with TM. Second, we evaluate the combination of OpenMP with multiple synchronization primitives on top of MPI to determine suitable task to thread ratios per node. Finally, we condense our findings into a set of best practices. These are applied to a Monte Carlo Benchmark and a Smoothed Particle Hydrodynamics method. In both cases an optimized TM version, executed with 64 threads on one node, outperforms a simple TM implementation. MCB with optimized TM yields a speedup of 27.45 over baseline.},
  keywords={},
  doi={10.1109/SC.2012.113},
  ISSN={2167-4337},
  month={Nov},}
@INPROCEEDINGS{6468522,
  author={Speck, R. and Ruprecht, D. and Krause, R. and Emmett, M. and Minion, M. and Winkel, M. and Gibbon, P.},
  booktitle={SC '12: Proceedings of the International Conference on High Performance Computing, Networking, Storage and Analysis}, 
  title={A massively space-time parallel N-body solver}, 
  year={2012},
  volume={},
  number={},
  pages={1-11},
  abstract={We present a novel space-time parallel version of the Barnes-Hut tree code PEPC using PFASST, the Parallel Full Approximation Scheme in Space and Time. The naive use of increasingly more processors for a fixed-size N-body problem is prone to saturate as soon as the number of unknowns per core becomes too small. To overcome this intrinsic strong-scaling limit, we introduce temporal parallelism on top of PEPC's existing hybrid MPI/PThreads spatial decomposition. Here, we use PFASST which is based on a combination of the iterations of the parallel-in-time algorithm parareal with the sweeps of spectral deferred correction (SDC) schemes. By combining these sweeps with multiple space-time discretization levels, PFASST relaxes the theoretical bound on parallel efficiency in parareal. We present results from runs on up to 262,144 cores on the IBM Blue Gene/P installation JUGENE, demonstrating that the spacetime parallel code provides speedup beyond the saturation of the purely space-parallel approach.},
  keywords={},
  doi={10.1109/SC.2012.6},
  ISSN={2167-4337},
  month={Nov},}
@INPROCEEDINGS{6468533,
  author={Van der Wijngaart, Rob F. and Sridharan, Srinivas and Lee, Victor W.},
  booktitle={SC '12: Proceedings of the International Conference on High Performance Computing, Networking, Storage and Analysis}, 
  title={Extending the BT NAS Parallel Benchmark to exascale computing}, 
  year={2012},
  volume={},
  number={},
  pages={1-9},
  abstract={The NAS Parallel Benchmarks (NPB) are a well-known suite of benchmarks that proxy scientific computing applications. They specify several problem sizes that represent how such applications may run on different sizes of HPC systems. However, even the largest problem (class F) is still far too small to exercise properly a petascale supercomputer. Our work shows how one may scale the Block Tridiagonal (BT) NPB from today's published size to petascale and exascale computing systems. In this paper we discuss the pros and cons of various ways of scaling. We discuss how scaling BT would impact computation, memory access, and communications, and highlight the expected bottleneck, which turns out to be not memory or communication bandwidth, but network latency. Two complementary ways are presented to overcome latency obstacles. We also describe a practical method to gather approximate performance data for BT at exascale on actual hardware, without requiring an exascale system.},
  keywords={},
  doi={10.1109/SC.2012.55},
  ISSN={2167-4337},
  month={Nov},}
@INPROCEEDINGS{6468449,
  author={Hilbrich, Tobias and Protze, Joachim and Schulz, Martin and de Supinski, Bronis R. and Muller, Matthias S.},
  booktitle={SC '12: Proceedings of the International Conference on High Performance Computing, Networking, Storage and Analysis}, 
  title={MPI runtime error detection with MUST: Advances in deadlock detection}, 
  year={2012},
  volume={},
  number={},
  pages={1-10},
  abstract={The widely used Message Passing Interface (MPI) is complex and rich. As a result, application developers require automated tools to avoid and to detect MPI programming errors. We present the Marmot Umpire Scalable Tool (MUST) that detects such errors with significantly increased scalability. We present improvements to our graph-based deadlock detection approach for MPI, which cover future MPI extensions. Our enhancements also check complex MPI constructs that no previous graph-based detection approach handled correctly. Finally, we present optimizations for the processing of MPI operations that reduce runtime deadlock detection overheads. Existing approaches often require O(p) analysis time per MPI operation, for p processes. We empirically observe that our improvements lead to sub-linear or better analysis time per operation for a wide range of real world applications.},
  keywords={},
  doi={10.1109/SC.2012.79},
  ISSN={2167-4337},
  month={Nov},}
@INPROCEEDINGS{6468543,
  author={Rietmann, Max and Messmer, Peter and Nissen-Meyer, Tarje and Peter, Daniel and Basini, Piero and Komatitsch, Dimitri and Schenk, Olaf and Tromp, Jeroen and Boschi, Lapo and Giardini, Domenico},
  booktitle={SC '12: Proceedings of the International Conference on High Performance Computing, Networking, Storage and Analysis}, 
  title={Forward and adjoint simulations of seismic wave propagation on emerging large-scale GPU architectures}, 
  year={2012},
  volume={},
  number={},
  pages={1-11},
  abstract={Computational seismology is an area of wide sociological and economic impact, ranging from earthquake risk assessment to subsurface imaging and oil and gas exploration. At the core of these simulations is the modeling of wave propagation in a complex medium. Here we report on the extension of the high-order finite-element seismic wave simulation package SPECFEM3D to support the largest scale hybrid and homogeneous supercomputers. Starting from an existing highly tuned MPI code, we migrated to a CUDA version. In order to be of immediate impact to the science mission of computational seismologists, we had to port the entire production package, rather than just individual kernels. One of the challenges in parallelizing finite element codes is the potential for race conditions during the assembly phase. We therefore investigated different methods such as mesh coloring or atomic updates on the GPU. In order to achieve strong scaling, we needed to ensure good overlap of data motion at all levels, including internode and host-accelerator transfers. Finally we carefully tuned the GPU implementation. The new MPI/CUDA solver exhibits excellent scalability and achieves speedup on a node-to-node basis over the carefully tuned equivalent multi-core MPI solver. To demonstrate the performance of both the forward and adjoint functionality, we present two case studies run on the Cray XE6 CPU and Cray XK6 GPU architectures up to 896 nodes: (1) focusing on most commonly used forward simulations, we simulate seismic wave propagation generated by earthquakes in Turkey, and (2) testing the most complex seismic inversion type of the package, we use ambient seismic noise to image 3-D crust and mantle structure beneath western Europe.},
  keywords={},
  doi={10.1109/SC.2012.59},
  ISSN={2167-4337},
  month={Nov},}
@INPROCEEDINGS{6478490,
  author={Fan, Wen},
  booktitle={2012 8th International Conference on Wireless Communications, Networking and Mobile Computing}, 
  title={Designing of Parallel Platform H.264 Real-Time Coding Optimization Based on the MPI}, 
  year={2012},
  volume={},
  number={},
  pages={1-4},
  abstract={This essay applies the designing of parallel algorithm to analyse and prove that H.264 can realize parallel computing task unit selection through the research of H.264 video coding; realizes the transplantation of X264 source code based on the MPI parallel environment using the sheet (slice) class H.264 parallel coding calculation method; realizes the real-time coding of standard-definition video, and brings forward the optimal parallel computing allocation scheme subjected to a small cluster platform of laboratory through testing.},
  keywords={},
  doi={10.1109/WiCOM.2012.6478490},
  ISSN={2161-9654},
  month={Sep.},}
@INPROCEEDINGS{6481070,
  author={Sima, Ana Claudia and Slusanschi, Emil},
  booktitle={2012 14th International Symposium on Symbolic and Numeric Algorithms for Scientific Computing}, 
  title={Optimizing Parallel CFD Simulations of 2D Compressible Flows}, 
  year={2012},
  volume={},
  number={},
  pages={487-494},
  abstract={The present work gives a contribution to the investigation of optimization strategies for a parallel CFD solver for compressible flows. The focus of this study is the analysis and improved performance of an existing scientific application for CFD simulations by means of reducing MPI communication time. This is achieved by redesigning domain decomposition and communication patterns. Tests were carried out on multiple hardware configurations with various problem sizes. Results are illustrated by comparison with the original application, showing good improvement in performance when suitable optimization strategies for specific simulations are applied. The study concludes with a methodology for choosing the appropriate optimization strategy depending on the available hardware and the problem size.},
  keywords={},
  doi={10.1109/SYNASC.2012.46},
  ISSN={},
  month={Sep.},}
@INPROCEEDINGS{6483407,
  author={Ruozzi, Nicholas},
  booktitle={2012 50th Annual Allerton Conference on Communication, Control, and Computing (Allerton)}, 
  title={Convergent message-passing algorithms in the presence of erasures}, 
  year={2012},
  volume={},
  number={},
  pages={1566-1571},
  abstract={We examine how to design convergent and correct message-passing schemes, similar to the min-sum algorithm, for maximum a posteriori (MAP) estimation in the case that the messages passed between two nodes of the network may never be delivered. The proposed solution creates a new, but equivalent, graphical model over which the convergence of a specific message-passing algorithm is guaranteed. We then show that the messages passed on this new model can be reduced to message passing over the original model if we allow some additional state at each node of the network.},
  keywords={},
  doi={10.1109/Allerton.2012.6483407},
  ISSN={},
  month={Oct},}
@INPROCEEDINGS{6483287,
  author={Ayday, Erman and Zou, Jun and Einolghozati, Arash and Fekri, Faramarz},
  booktitle={2012 50th Annual Allerton Conference on Communication, Control, and Computing (Allerton)}, 
  title={A recommender system based on Belief Propagation over Pairwise Markov Random Fields}, 
  year={2012},
  volume={},
  number={},
  pages={703-707},
  abstract={Recommender systems enable service providers to predict and address the individual needs of their customers so as to deliver personalized experiences. In this paper, we formulate the recommendation problem as an inference problem on a Pairwise Markov Random Field (PMRF), where nodes representing items are connected with each other to exploit item-based similarity. However, direct prediction of ratings has exponential time complexity, as it requires to compute marginal probabilities. Thus, we utilize the Belief Propagation (BP) algorithm to solve the problem with a complexity that grows linearly with the number of items in the system. The BP algorithm computes marginal probabilities by performing iterative probabilistic message-passing between item nodes on the PMRF. One desirable feature of the proposed scheme is that it does not require to solve the problem for all users if it wishes to update the recommendations for only a single active user. Moreover, its complexity remains linear per active user. Via computer simulations using 100K MovieLens dataset, we verify that the proposed algorithm outperforms the MovieAvg and Pearson Correlation Coefficient (PCC) algorithms in terms of both Root Mean Squared Error (RMSE) and Mean Absolute Error (MAE).},
  keywords={},
  doi={10.1109/Allerton.2012.6483287},
  ISSN={},
  month={Oct},}
@INPROCEEDINGS{6489224,
  author={Amiri, Behzad and Srinivasa, Shayan Garani and Dolecek, Lara},
  booktitle={2012 Conference Record of the Forty Sixth Asilomar Conference on Signals, Systems and Computers (ASILOMAR)}, 
  title={Quantization, absorbing regions and practical message passing decoders}, 
  year={2012},
  volume={},
  number={},
  pages={1255-1259},
  abstract={Low-density parity-check (LDPC) codes and accompanying message passing decoding algorithms are a popular choice for data encoding and decoding in modern communications and storage systems. To reduce implementation complexity, the messages in a practical message passing decoder are necessarily quantized. It is well known that the performance of practical, quantized message passing decoders in the high-reliability regime is governed by non-codeword decoding errors, typically described via trapping/absorbing sets. Absorbing regions act as “decoding regions” around absorbing sets. In this work, we take a closer look at the interplay between quantization and absorbing regions. We provide a study of a range of quantization choices, describe the impact of quantization on the candidate absorbing regions, and derive guidelines for practical finite-precision decoders. In particular, we show that, depending on the choice of the quantization allocation, different absorbing sets emerge as dominant: even though the overall performance of two quantization schemes can be similar, the distribution of decoding errors across possible absorbing sets can be substantially different. We take the advantage of disjointness of error profiles of two carefully chosen quantized decoders to design a decoder that is a series of these two decoders. The result is a performance improvement of at least an order magnitude relative to constituent decoders without increase in complexity.},
  keywords={},
  doi={10.1109/ACSSC.2012.6489224},
  ISSN={1058-6393},
  month={Nov},}
@INPROCEEDINGS{6495838,
  author={Mubarak, Misbah and Carothers, Christopher D. and Ross, Robert and Carns, Philip},
  booktitle={2012 SC Companion: High Performance Computing, Networking Storage and Analysis}, 
  title={Modeling a Million-Node Dragonfly Network Using Massively Parallel Discrete-Event Simulation}, 
  year={2012},
  volume={},
  number={},
  pages={366-376},
  abstract={A low-latency and low-diameter interconnection network will be an important component of future exascale architectures. The dragonfly network topology, a two-level directly connected network, is a candidate for exascale architectures because of its low diameter and reduced latency. To date, small-scale simulations with a few thousand nodes have been carried out to examine the dragonfly topology. However, future exascale machines will have millions of cores and up to 1 million nodes. In this paper, we focus on the modeling and simulation of large-scale dragonfly networks using the Rensselaer Optimistic Simulation System (ROSS). We validate the results of our model against the cycle-accurate simulator “booksim”. We also compare the performance of booksim and ROSS for the dragonfly network model at modest scales. We demonstrate the performance of ROSS on both the Blue Gene/P and Blue Gene/Q systems on a dragonfly model with up to 50 million nodes, showing a peak event rate of 1.33 billion events/second and a total of 872 billion committed events. The dragonfly network model for million-node configurations strongly scales when going from 1,024 to 65,536 MPI tasks on IBM Blue Gene/P and IBM Blue Gene/Q systems. We also explore a variety of ROSS tuning parameters to get optimal results with the dragonfly network model.},
  keywords={},
  doi={10.1109/SC.Companion.2012.56},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{6495955,
  author={Dong, Tingxing and Kolev, Tzanio and Rieben, Robert and Dobrev, Veselin},
  booktitle={2012 SC Companion: High Performance Computing, Networking Storage and Analysis}, 
  title={Poster: Acceleration of the BLAST Hydro Code on GPU}, 
  year={2012},
  volume={},
  number={},
  pages={1337-1337},
  abstract={The BLAST code implements a high-order numerical algorithm that solves the equations of compressible hydrodynamics using the Finite Element Method in a moving Lagrangian frame. BLAST is coded in C++ and parallelized by MPI. We accelerate the most computationally intensive parts (80%-95%) of BLAST on an NVIDIA GPU with the CUDA programming model. Several 2D and 3D problems were tested and a maximum speedup of 4.3x was delivered. Our results demonstrate the validity and capability of GPU computing.},
  keywords={},
  doi={10.1109/SC.Companion.2012.172},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{6507503,
  author={Kutlu, Mucahid and Agrawal, Gagan and Kurt, Oguz},
  booktitle={2012 19th International Conference on High Performance Computing}, 
  title={Fault tolerant parallel data-intensive algorithms}, 
  year={2012},
  volume={},
  number={},
  pages={1-10},
  abstract={Fault-tolerance is rapidly becoming a crucial issue in high-end and distributed computing, as increasing number of cores are decreasing the mean-time to failure of the systems. While checkpointing, including checkpointing of parallel programs like MPI applications, provides a general solution, the overhead of this approach is becoming increasingly unacceptable. Thus, algorithm-based fault-tolerance provides a nice practical alternative, though it is less general. Although this approach has been studied for many applications, there is no existing work for algorithm-based fault-tolerance for the growing class of data-intensive parallel applications. In this paper, we present an algorithm-based fault tolerance solution that handles fail-stop failures for a class of data intensive algorithms. We divide the dataset into smaller data blocks and in replication step, we distribute the replicated blocks with the aim of keeping the maximum data intersection between any two processors minimum. This allows us to have minimum data loss when multiple failures occur. In addition, our approach enables better load balance after failure, and decreases the amount of re-processing of the lost data. We have evaluated our approach by using two popular parallel data mining algorithms, which are k-means and apriori. We show that our approach has negligible overhead when there are no failures, and allows us to gracefully handle different number of failures, and failures at different points of processing. We also provide the comparison of our approach with the MapReduce based solution for fault tolerance, and show that we outperform Hadoop both in absence and presence of failures.},
  keywords={},
  doi={10.1109/HiPC.2012.6507503},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{6507505,
  author={Apostal, David and Foerster, Kyle and Chatterjee, Amrita and Desell, Travis},
  booktitle={2012 19th International Conference on High Performance Computing}, 
  title={Password recovery using MPI and CUDA}, 
  year={2012},
  volume={},
  number={},
  pages={1-9},
  abstract={Using passwords to verify a user's identity is the most widely deployed method for electronic authentication. When system administrators need to recover lost passwords or test accounts for easily guessable passwords, it can require millions of hash function and string comparison operations. These operations can be computationally expensive but are easily parallelizable because each password can be tested independently. Therefore, using high performance computing (HPC) can greatly reduce the time required to perform password recovery. Due to the high level of fine-grained parallelism of this type of problem, GPU computing using Compute Unified Device Architecture (CUDA) can be used to further improve performance. The scale of HPC can be further increased through the use of multiple GPUs, but this requires communication between the GPU devices and can reduce the overall performance due to increased communications latency. In this work a well established HPC framework, Message Passing Interface (MPI), was used to minimize the amount of latency and handle the communication between the devices. This allowed for a course-grained division of the problem using MPI where each device applies a fine-grained division of the problem using CUDA to perform the actual calculations. This paper describes three dictionary-based password recovery algorithms that use both MPI and CUDA. In this approach the hashed values of known words are computed and compared with hash values of unknown user passwords. The algorithms differed in GPU memory utilization and how the data was divided and distributed among the MPI nodes and GPU devices. A divided dictionary algorithm split the dictionary of potential passwords over the G PUs and copied the password database to each GPU. A divided password database algorithm split the password database and copied the potential passwords. A minimal memory algorithm split the password database and sequentially processed individual passwords on the GPUs. The divided dictionary and the divided password database algorithms performed well, resulting in a speedup of 57x and 40x over a single processor using 8 GPUs across 4 compute nodes, respectively. Illustrating the cost of communication latency between MPI nodes and GPUs, the minimal memory algorithm performed significantly slower than a single CPU. The algorithms are shown to scale well to multiple GPUs, so this password recovery system could be used for much larger systems for larger databases. In addition to recovering lost passwords, this work could be used to help improve the security of computer systems by identifying accounts with weak or common passwords. The framework described may also be useful for other research that needs to process large amounts of data with similar characteristics using MPI and CUDA.},
  keywords={},
  doi={10.1109/HiPC.2012.6507505},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{6508639,
  author={Yang Yu and Liu, Dong and Lu, Yiming and Jianwei Gu},
  booktitle={2012 China International Conference on Electricity Distribution}, 
  title={The validation of message specifications based on Iec 61968 standards}, 
  year={2012},
  volume={},
  number={},
  pages={1-6},
  abstract={As the information standardization of smart grid gradually develops, the electric utilities are devoted to constructing the enterprise information integrated architecture based on the enterprise service bus according to IEC 61968 standards. However, in the implementation process, the consistency of message specification has not been well applied. In order to solve the problems or mismatches that appear in the information interaction, this paper proposes a practical validation mechanism for information interaction based on IEC 61968 standards, and describes the method for message validation based on XML Schema. The paper also includes a description of the M2VT (Model and Message Validation Tool) software tool, which establishes the consistency rules of the data model through analyzing the mapping relationship between XML and XML schema (XSD), to realize the checking function on the validity of the message (described in XML). The online testing in the integration bus of Hangzhou DMS system with this tool proves its feasibility and practicability.},
  keywords={},
  doi={10.1109/CICED.2012.6508639},
  ISSN={2161-749X},
  month={Sep.},}
@INPROCEEDINGS{6528245,
  author={Buimaga-Iarinca, Luiza and Calborean, Adrian},
  booktitle={2012 5th Romania Tier 2 Federation Grid, Cloud & High Performance Computing Science (RQLCG)}, 
  title={The scalling of computational time as a function of number of processors for Quantum Monte Carlo study of CO molecule}, 
  year={2012},
  volume={},
  number={},
  pages={57-58},
  abstract={We tested the efficiency of the MPI cluster in NIRDIMT by using a Quantum Monte Carlo algorithm (QMC). While the algorithm is highly efficient we show that a decrease of the computing efficiency occurs if the processor number is larger than eight.},
  keywords={},
  doi={},
  ISSN={},
  month={Oct},}
@INPROCEEDINGS{6674233,
  author={Meng, Qingyu and Humphrey, Alan and Berzins, Martin},
  booktitle={2012 SC Companion: High Performance Computing, Networking Storage and Analysis}, 
  title={The uintah framework: a unified heterogeneous task scheduling and runtime system}, 
  year={2012},
  volume={},
  number={},
  pages={2441-2448},
  abstract={The development of a new unified, multi-threaded runtime system for the execution of asynchronous tasks on heterogeneous systems is described in this work. These asynchronous tasks arise from the Uintah framework, which was developed to provide an environment for solving a broad class of fluid-structure interaction problems on structured adaptive grids. Uintah has a clear separation between its MPI-free user-coded tasks and its runtime system that ensures these tasks execute efficiently. This separation also allows for complete isolation of the application developer from the complexities involved with the parallelism Uintah provides. While we have designed scalable runtime systems for large CPU core counts, the emergence of heterogeneous systems, with additional on-node accelerators and co-processors presents additional design challenges in terms of effectively utilizing all computational resources on-node and managing multiple levels of parallelism. Our work addresses these challenges for Uintah by the development of new hybrid runtime system and Unified multi-threaded MPI task scheduler, enabling Uintah to fully exploit current and emerging architectures with support for asynchronous, out-of-order scheduling of both CPU and GPU computational tasks. This design coupled with an approach that uses MPI to communicate between nodes, a shared memory model on-node and the use of novel lock-free data structures, has made it possible for Uintah to achieve excellent scalability for challenging fluid-structure problems using adaptive mesh refinement on as many as 256K cores on the DoE Jaguar XK6 system. This design has also demonstrated an ability to run capability jobs on the heterogeneous systems, Keeneland and TitanDev. In this work, the evolution of Uintah and its runtime system is examined in the context of our new Unified multi-threaded scheduler design. The performance of the Unified scheduler is also tested against previous Uintah scheduler and runtime designs over a range of processor core and GPU counts.},
  keywords={},
  doi={10.1109/SCC.2012.6674233},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{6740467,
  author={Mawlood, Mahmood Khalid},
  booktitle={2012 First National Conference for Engineering Sciences (FNCES 2012)}, 
  title={A two-dimensional Navier-Stokes code on parallel PCs}, 
  year={2012},
  volume={},
  number={},
  pages={1-7},
  abstract={A parallel computer code is developed for solving the incompressible two-dimensional Navier-Stokes and energy equations. The solution algorithm is based on a second-order finite volume space discretization and a fourth-order explicit Runge-Kutta method for time advancement. The projection method is used for computing the pressure gradient in each time step. A one-direction domain decomposition scheme and message passing are used for code parallelization. The code is run on two parallel computing platforms. One parallel platform is built from two workstations and the other is a four-processor PC. The accuracy and performance characteristics of the code are tested, rated and demonstrated.},
  keywords={},
  doi={10.1109/NCES.2012.6740467},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{7842934,
  author={Laguna, Ignacio and Ahn, Dong H. and de Supinski, Bronis R. and Bagchi, Saurabh and Gamblin, Todd},
  booktitle={2012 21st International Conference on Parallel Architectures and Compilation Techniques (PACT)}, 
  title={Probabilistic diagnosis of performance faults in large-scale parallel applications}, 
  year={2012},
  volume={},
  number={},
  pages={213-222},
  abstract={Debugging large-scale parallel applications is challenging. Most existing techniques provide mechanisms for process control but little information about the causes of failures. Most debuggers also scale poorly despite continued growth in supercomputer core counts. Our novel, highly scalable tool helps developers to understand and to fix performance failures and correctness problems at scale. Our tool probabilistically infers the least progressed task in MPI programs using Markov models of execution history and dependence analysis. This analysis guides program slicing to find code that may have caused a failure. In a blind study, we demonstrate that our tool can isolate the root cause of a particularly perplexing bug encountered at scale in a molecular dynamics simulation. Further, we perform fault injections into two benchmark codes and measure the scalability of the tool. Our results show that it accurately detects the least progressed task in most cases and can perform the diagnosis in a fraction of a second with thousands of tasks.},
  keywords={},
  doi={},
  ISSN={},
  month={Sep.},}
@ARTICLE{6138858,
  author={Parsaeefard, Saeedeh and Sharafat, Ahmad R.},
  journal={IEEE Transactions on Mobile Computing}, 
  title={Robust Distributed Power Control in Cognitive Radio Networks}, 
  year={2013},
  volume={12},
  number={4},
  pages={609-620},
  abstract={We propose a robust distributed uplink power allocation algorithm for underlay cognitive radio networks (CRNs) with a view to maximizing the social utility of secondary users (SUs) when channel gains from SUs to primary base stations, and interference caused by primary users (PUs) to the SUs' base station are uncertain. In doing so, we utilize the worst case robust optimization to keep the interference caused by SUs to each primary base station below a given threshold, and satisfy each SU's quality of service in terms of its required SINR for all realizations of uncertain parameters. We model each uncertain parameter by a bounded distance between its estimated and exact values, and formulate the robust power allocation problem via protection values for constraints. We demonstrate that the convexity of our problem is preserved, and converts into a geometric programming problem, which we solve via a distributed algorithm by using Lagrange dual decomposition. To reduce the cost of robustness, defined as the reduction in the social utility of SUs and the increase in message passing, we utilize the D-norm approach to trade off between robustness and optimality, and propose a distributed power allocation algorithm with infrequent message passing. Simulation results validate the effectiveness of our proposed approach.},
  keywords={},
  doi={10.1109/TMC.2012.28},
  ISSN={1558-0660},
  month={April},}
@ARTICLE{6197182,
  author={Tsai, Jichiang},
  journal={IEEE Transactions on Parallel and Distributed Systems}, 
  title={Flexible Symmetrical Global-Snapshot Algorithms for Large-Scale Distributed Systems}, 
  year={2013},
  volume={24},
  number={3},
  pages={493-505},
  abstract={Most existing global-snapshot algorithms in distributed systems use control messages to coordinate the construction of a global snapshot among all processes. Since these algorithms typically assume the underlying logical overlay topology is fully connected, the number of control messages exchanged among the whole processes is proportional to the square of number of processes, resulting in higher possibility of network congestion. Hence, such algorithms are neither efficient nor scalable for a large-scale distributed system composed of a huge number of processes. Recently, some efforts have been presented to significantly reduce the number of control messages, but doing so incurs higher response time instead. In this paper, we propose an efficient global-snapshot algorithm able to let every process finish its local snapshot in a given number of rounds. Particularly, such an algorithm allows a tradeoff between the response time and the message complexity. Moreover, our global-snapshot algorithm is symmetrical in the sense that identical steps are executed by every process. This means that our algorithm is able to achieve better workload balance and less network congestion. Most importantly, based on our framework, we demonstrate that the minimum number of control messages required by a symmetrical global-snapshot algorithm is Ω(N log N), where N is the number of processes. Finally, we also assume non-FIFO channels.},
  keywords={},
  doi={10.1109/TPDS.2012.139},
  ISSN={1558-2183},
  month={March},}
@ARTICLE{6319390,
  author={Joven, Jaume and Bagdia, Akash and Angiolini, Federico and Strid, Per and Castells-Rufas, David and Fernandez-Alonso, Eduard and Carrabina, Jordi and De Micheli, Giovanni},
  journal={IEEE Transactions on Industrial Informatics}, 
  title={QoS-Driven Reconfigurable Parallel Computing for NoC-Based Clustered MPSoCs}, 
  year={2013},
  volume={9},
  number={3},
  pages={1613-1624},
  abstract={Reconfigurable parallel computing is required to provide high-performance embedded computing, hide hardware complexity, boost software development, and manage multiple workloads when multiple applications are running simultaneously on the emerging network-on-chip (NoC)-based multiprocessor systems-on-chip (MPSoCs) platforms. In these type of systems, the overall system performance may be affected due to congestion, and therefore parallel programming stacks must be assisted by quality-of-service (QoS) support to meet application requirements and to deal with application dynamism. In this paper, we present a hardware-software QoS-driven reconfigurable parallel computing framework, i.e., the NoC services, the runtime QoS middleware API and our ocMPI library and its tracing support which has been tailored for a distributed-shared memory ARM clustered NoC-based MPSoC platform. The experimental results show the efficiency of our software stack under a broad range of parallel kernels and benchmarks, in terms of low-latency interprocess communication, good application scalability, and most important, they demonstrate the ability to enable runtime reconfiguration to manage workloads in message-passing parallel applications.},
  keywords={},
  doi={10.1109/TII.2012.2222035},
  ISSN={1941-0050},
  month={Aug},}
@ARTICLE{6324392,
  author={He, Chenguang and Fan, Xiaomao and Li, Ye},
  journal={IEEE Transactions on Biomedical Engineering}, 
  title={Toward Ubiquitous Healthcare Services With a Novel Efficient Cloud Platform}, 
  year={2013},
  volume={60},
  number={1},
  pages={230-234},
  abstract={Ubiquitous healthcare services are becoming more and more popular, especially under the urgent demand of the global aging issue. Cloud computing owns the pervasive and on-demand service-oriented natures, which can fit the characteristics of healthcare services very well. However, the abilities in dealing with multimodal, heterogeneous, and nonstationary physiological signals to provide persistent personalized services, meanwhile keeping high concurrent online analysis for public, are challenges to the general cloud. In this paper, we proposed a private cloud platform architecture which includes six layers according to the specific requirements. This platform utilizes message queue as a cloud engine, and each layer thereby achieves relative independence by this loosely coupled means of communications with publish/subscribe mechanism. Furthermore, a plug-in algorithm framework is also presented, and massive semistructure or unstructured medical data are accessed adaptively by this cloud architecture. As the testing results showing, this proposed cloud platform, with robust, stable, and efficient features, can satisfy high concurrent requests from ubiquitous healthcare services.},
  keywords={},
  doi={10.1109/TBME.2012.2222404},
  ISSN={1558-2531},
  month={Jan},}
@ARTICLE{6365880,
  author={Narasimhan, T. Lakshmi and Chockalingam, A.},
  journal={IEEE Communications Letters}, 
  title={EXIT Chart Based Design of Irregular LDPC Codes for Large-MIMO Systems}, 
  year={2013},
  volume={17},
  number={1},
  pages={115-118},
  abstract={In this letter, we characterize the extrinsic information transfer (EXIT) behavior of a factor graph based message passing algorithm for detection in large multiple-input multiple-output (MIMO) systems with tens to hundreds of antennas. The EXIT curves of a joint detection-decoding receiver are obtained for low density parity check (LDPC) codes of given degree distributions. From the obtained EXIT curves, an optimization of the LDPC code degree profiles is carried out to design irregular LDPC codes matched to the large-MIMO channel and joint message passing receiver. With low complexity joint detection-decoding, these codes are shown to perform better than off-the-shelf irregular codes in the literature by about 1 to 1.5 dB at a coded BER of 10-5 in 16 × 16, 64 × 64 and 256 × 256 MIMO systems.},
  keywords={},
  doi={10.1109/LCOMM.2012.112812.122249},
  ISSN={1558-2558},
  month={January},}

@ARTICLE{6378362,
  author={Shen, Haiying and Liu, Guoxin},
  journal={IEEE Transactions on Parallel and Distributed Systems}, 
  title={A Geographically Aware Poll-Based Distributed File Consistency Maintenance Method for P2P Systems}, 
  year={2013},
  volume={24},
  number={11},
  pages={2148-2159},
  abstract={File consistency maintenance in P2P systems is a technique for maintaining consistency between files and their replicas. Most previous consistency maintenance methods depend on either message spreading or structure-based pushing. Message spreading generates high overhead due to a large amount of messages; structure-based pushing methods reduce this overhead. However, both approaches cannot guarantee that every replica node receives an update in churn, because replica nodes passively wait for updates. As opposed to push-based methods that are not effective in high-churn and low-resource P2P systems, polling is churn resilient and generates low overhead. However, it is faced with a number of challenges: 1) ensuring a limited inconsistency; 2) realizing polling in a distributed manner; 3) considering physical proximity in polling; and 4) leveraging polling to further reduce polling overhead. To handle these challenges, this paper introduces a poll-based distributed file consistency maintenance method called geographically aware wave (GeWave). GeWave further reduces update overhead, enhances the fidelity of file consistency, and takes proximity into account. Using adaptive polling in a dynamic structure, GeWave avoids redundant file updates and ensures that every node receives an update in a limited time period even in churn. Furthermore, it propagates updates between geographically close nodes in a distributed manner. Extensive experimental results from the PlanetLab real-world testbed demonstrate the efficiency and effectiveness of GeWave in comparison with other representative consistency maintenance schemes. It dramatically reduces the overhead and yields significant improvements on effectiveness, scalability, and churn resilience of previous file consistency maintenance methods.},
  keywords={},
  doi={10.1109/TPDS.2012.317},
  ISSN={1558-2183},
  month={Nov},}
@ARTICLE{6417011,
  author={Yao, Jun and Teh, Kah Chan and Li, Kwok Hung},
  journal={IEEE Transactions on Magnetics}, 
  title={Joint Message-Passing Decoding of LDPC Codes and 2-D ISI Channels}, 
  year={2013},
  volume={49},
  number={2},
  pages={675-681},
  abstract={Two-dimensional (2-D) intersymbol-interference (ISI) channels represent an important class of next-generation data-storage systems. In order to mitigate the 2-D ISI and improve system performance, a joint message-passing decoding algorithm is proposed in this paper. The proposed algorithm conducts an iterative decoding of low-density parity-check code and a 2-D ISI channel, which can be implemented in a fully parallel manner. An extrinsic information transfer chart is also introduced to analyze the performance and convergence behavior of the proposed message-passing decoding system. Simulation results show that the proposed joint message-passing decoding algorithm outperforms some existing joint decoding algorithms.},
  keywords={},
  doi={10.1109/TMAG.2012.2219299},
  ISSN={1941-0069},
  month={Feb},}
@ARTICLE{6416896,
  author={Chen, Zhezhe and Gao, Qi and Zhang, Wenbin and Qin, Feng},
  journal={IEEE Transactions on Parallel and Distributed Systems}, 
  title={Improving the Reliability of MPI Libraries via Message Flow Checking}, 
  year={2013},
  volume={24},
  number={3},
  pages={535-549},
  abstract={Despite the success of the Message Passing Interface (MPI), many MPI libraries have suffered from software bugs. These bugs severely impact the productivity of a large number of users, causing program failures or other errors. As a result, MPI application developers often have to spend days or weeks in vain debugging their own code. To address this daunting problem, this paper presents a new method called FlowChecker, which detects communication related bugs in MPI libraries. First, FlowChecker extracts program intentions of message passing (MP-intentions), which specify messages to be delivered from the sources to the destinations. Then FlowChecker tracks the message flows that actually occur in the underlying MPI libraries. Finally, FlowChecker checks whether the messages are correctly delivered from the sources to the destinations by comparing the message flows against the MP-intentions. If a mismatch is found, FlowChecker reports a bug and provides diagnostic information to help MPI library developers to understand and fix it. We have built a FlowChecker prototype on Linux and evaluated it with five real-world and two injected bug cases in three widely used MPI libraries, including Open MPI, MPICH2, and MVAPICH2. Our experimental results show that FlowChecker effectively detects all seven evaluated bug cases. Additionally, it provides useful diagnostic information for narrowing down or even pinpointing root causes of the bugs. Moreover, our experiments with High Performance Linpack and NAS Parallel Benchmarks show that FlowChecker induces low runtime overhead (0.9-5.6 percent on Open MPI, 0.9-8.1 percent on MPICH2, and 1.6-9.7 percent on MVAPICH2).},
  keywords={},
  doi={10.1109/TPDS.2012.127},
  ISSN={1558-2183},
  month={March},}
@ARTICLE{6468990,
  author={Leduc-Primeau, Francois and Hemati, Saied and Mannor, Shie and Gross, Warren J.},
  journal={IEEE Transactions on Communications}, 
  title={Relaxed Half-Stochastic Belief Propagation}, 
  year={2013},
  volume={61},
  number={5},
  pages={1648-1659},
  abstract={Low-density parity-check codes are attractive for high throughput applications because of their low decoding complexity per bit, but also because all the codeword bits can be decoded in parallel. However, achieving this in a circuit implementation is complicated by the number of wires required to exchange messages between processing nodes. Decoding algorithms that exchange binary messages are interesting for fully-parallel implementations because they can reduce the number and the length of the wires, and increase logic density. This paper introduces the Relaxed Half-Stochastic (RHS) decoding algorithm, a binary message belief propagation (BP) algorithm that achieves a coding gain comparable to the best known BP algorithms that use real-valued messages. We derive the RHS algorithm by starting from the well-known Sum-Product algorithm, and then derive a low-complexity version suitable for circuit implementation. We present extensive simulation results on two standardized codes having different rates and constructions, including low bit error rate results. These simulations show that RHS can converge faster on average than existing state-of-the-art decoding algorithms, leading to improvements in throughput and energy efficiency.},
  keywords={},
  doi={10.1109/TCOMM.2013.021913.120149},
  ISSN={1558-0857},
  month={May},}
@ARTICLE{6479251,
  author={Blair, Steven M. and Coffele, Federico and Booth, Campbell D. and Burt, Graeme M.},
  journal={IEEE Transactions on Power Delivery}, 
  title={An Open Platform for Rapid-Prototyping Protection and Control Schemes With IEC 61850}, 
  year={2013},
  volume={28},
  number={2},
  pages={1103-1110},
  abstract={Communications is becoming increasingly important to the operation of protection and control schemes. Although offering many benefits, using standards-based communications, particularly IEC 61850, in the course of the research and development of novel schemes can be complex. This paper describes an open-source platform which enables the rapid prototyping of communications-enhanced schemes. The platform automatically generates the data model and communications code required for an intelligent electronic device to implement a publisher-subscriber generic object-oriented substation event and sampled-value messaging. The generated code is tailored to a particular system configuration description (SCD) file, and is therefore extremely efficient at runtime. It is shown here how a model-centric tool, such as the open-source Eclipse Modeling Framework, can be used to manage the complexity of the IEC 61850 standard, by providing a framework for validating SCD files and by automating parts of the code generation process. The flexibility and convenience of the platform are demonstrated through a prototype of a real-time, fast-acting load-shedding scheme for a low-voltage microgrid network. The platform is the first open-source implementation of IEC 61850 which is suitable for real-time applications, such as protection, and is therefore readily available for research and education.},
  keywords={},
  doi={10.1109/TPWRD.2012.2231099},
  ISSN={1937-4208},
  month={April},}
@INPROCEEDINGS{6498252,
  author={Jung, Seung-Hyun and Na, Jong-Hwa and Choi, Chi-Hwan and Nazareno, Franco and Jung, In-Sun and Cho, Wan-Sup and Tang, Min-Hyunk and Jun, Sung-Hyun},
  booktitle={2013 4th International Conference on Intelligent Systems, Modelling and Simulation}, 
  title={A Private Cloud System for Web-based High-Performance Multiple Sequence Alignment Services}, 
  year={2013},
  volume={},
  number={},
  pages={143-147},
  abstract={We proposed a LanLinux-based cloud system for ClustalW-MPI, a parallel implementation of Clustal-W based on MPI, where researchers can submit their sequence data online for multiple sequence alignment. ClustalW is one of the most widely used programs for multiple sequence alignment (MSA) in bioinformatics. However, current in-silico environmental conditions for MSAs are facing computing power problems. The proposed system uses the MPICH2 (a standard message-passing interface for distributed-memory applications used in parallel computing) for handling all the tasks associated with the multiple sequence alignment on the Web. It provides sufficient computing power for aligning large number of sequences at a time, with real-time monitoring capabilities to ensure correctness, efficiency and effectiveness.},
  keywords={},
  doi={10.1109/ISMS.2013.141},
  ISSN={2166-0670},
  month={Jan},}
@ARTICLE{6502290,
  author={Dall'Anese, Emiliano and Zhu, Hao and Giannakis, Georgios B.},
  journal={IEEE Transactions on Smart Grid}, 
  title={Distributed Optimal Power Flow for Smart Microgrids}, 
  year={2013},
  volume={4},
  number={3},
  pages={1464-1475},
  abstract={Optimal power flow (OPF) is considered for microgrids, with the objective of minimizing either the power distribution losses, or, the cost of power drawn from the substation and supplied by distributed generation (DG) units, while effecting voltage regulation. The microgrid is unbalanced, due to unequal loads in each phase and non-equilateral conductor spacings on the distribution lines. Similar to OPF formulations for balanced systems, the considered OPF problem is nonconvex. Nevertheless, a semidefinite programming (SDP) relaxation technique is advocated to obtain a convex problem solvable in polynomial-time complexity. Enticingly, numerical tests demonstrate the ability of the proposed method to attain the globally optimal solution of the original nonconvex OPF. To ensure scalability with respect to the number of nodes, robustness to isolated communication outages, and data privacy and integrity, the proposed SDP is solved in a distributed fashion by resorting to the alternating direction method of multipliers. The resulting algorithm entails iterative message-passing among groups of consumers and guarantees faster convergence compared to competing alternatives.},
  keywords={},
  doi={10.1109/TSG.2013.2248175},
  ISSN={1949-3061},
  month={Sep.},}
@ARTICLE{6507327,
  author={Ruozzi, Nicholas and Tatikonda, Sekhar},
  journal={IEEE Transactions on Information Theory}, 
  title={Message-Passing Algorithms: Reparameterizations and Splittings}, 
  year={2013},
  volume={59},
  number={9},
  pages={5860-5881},
  abstract={The max-product algorithm, a local message-passing scheme that attempts to compute the most probable assignment (MAP) of a given probability distribution, has been successfully employed as a method of approximate inference for applications arising in coding theory, computer vision, and machine learning. However, the max-product algorithm is not guaranteed to converge, and if it does, it is not guaranteed to recover the MAP assignment. Alternative convergent message-passing schemes have been proposed to overcome these difficulties. This paper provides a systematic study of such message-passing algorithms that extends the known results by exhibiting new sufficient conditions for convergence to local and/or global optima, providing a combinatorial characterization of these optima based on graph covers, and describing a new convergent and correct message-passing algorithm whose derivation unifies many of the known convergent message-passing algorithms. While convergent and correct message-passing algorithms represent a step forward in the analysis of max-product style message-passing algorithms, the conditions needed to guarantee convergence to a global optimum can be too restrictive in both theory and practice. This limitation of convergent and correct message-passing schemes is characterized by graph covers and illustrated by example.},
  keywords={},
  doi={10.1109/TIT.2013.2259576},
  ISSN={1557-9654},
  month={Sep.},}
@ARTICLE{6516166,
  author={Li, Erbao and Declercq, David and Gunnam, Kiran},
  journal={IEEE Transactions on Communications}, 
  title={Trellis-Based Extended Min-Sum Algorithm for Non-Binary LDPC Codes and its Hardware Structure}, 
  year={2013},
  volume={61},
  number={7},
  pages={2600-2611},
  abstract={In this paper, we present an improvement and a new implementation of a simplified decoding algorithm for non-binary low density parity-check codes (NB-LDPC) in Galois fields GF(q). The base algorithm that we use is the Extended Min-Sum (EMS) algorithm, which has been widely studied in the recent literature, and has been shown to approach the performance of the belief propagation (BP) algorithm, with limited complexity. In our work, we propose a new way to compute modified configuration sets, using a trellis representation of incoming messages to check nodes. We call our modification of the EMS algorithm trellis-EMS (T-EMS). In the T-EMS, the algorithm operates directly on the deviation space by considering a trellis built from differential messages, which serves as a new reliability measure to sort the configurations. We show that this new trellis representation reduces the computational complexity, without any performance degradation. In addition, we show that our modifications of the algorithm allows to greatly reduce the decoding latency, by using a larger degree of hardware parallelization.},
  keywords={},
  doi={10.1109/TCOMM.2013.050813.120489},
  ISSN={1558-0857},
  month={July},}
@ARTICLE{6517349,
  author={Huang, Chao-Cheng and Wu, Chi-Jen and Chen, Chao-Yu and Chao, Chi-chao},
  journal={IEEE Communications Letters}, 
  title={Parallel Symbol-Flipping Decoding for Non-Binary LDPC Codes}, 
  year={2013},
  volume={17},
  number={6},
  pages={1228-1231},
  abstract={A new low-complexity parallel symbol-flipping decoding algorithm for non-binary low-density parity-check (NB-LDPC) codes is proposed. The algorithm outperforms quite a number of existing reliability-based message-passing algorithms, and its computation complexity is smaller than that of almost all the previously proposed iterative decoding algorithms for NB-LDPC codes. It is suitable for decoding NB-LDPC codes whose parity-check matrices have large column weights.},
  keywords={},
  doi={10.1109/LCOMM.2013.051313.130303},
  ISSN={1558-2558},
  month={June},}
@ARTICLE{6518129,
  author={Boufaied, Amine},
  journal={IEEE Transactions on Intelligent Transportation Systems}, 
  title={A Diagnostic Approach for Advanced Tracking of Commercial Vehicles With Time Window Constraints}, 
  year={2013},
  volume={14},
  number={3},
  pages={1470-1479},
  abstract={In this paper, we introduce a fleet supervision system used to monitor on-road evolutions of commercial transport vehicles. This monitoring is accomplished by the automatic dispatch, during crossing of a tracking location, of information issued from the localization system on the vehicle. This information can be sent to a server through a direct Transmission Control Protocol/Internet Protocol connection in a general packet radio service network (GPRS) or through a satellite network. The information is provided by the system to some allowed users via an Internet website. The fleet supervision system also enables analyzing messages sent by vehicles to identify differences between real data and planned data. We are more particularly interested in the diagnostics of delays, which can take place during deliveries. In fact, while crossing already fixed tracking locations, these delays are detected as early as possible, and their consequences are predicted so that corrective or preventive actions are undertaken as soon as possible.},
  keywords={},
  doi={10.1109/TITS.2013.2262635},
  ISSN={1558-0016},
  month={Sep.},}
@INPROCEEDINGS{6523666,
  author={Lee, Richard and Abdel-Khalek, Karim and Abdi, Samar and Risacher, Frederic},
  booktitle={International Symposium on Quality Electronic Design (ISQED)}, 
  title={Early system level modeling of real-time applications on embedded platforms}, 
  year={2013},
  volume={},
  number={},
  pages={558-565},
  abstract={This paper describes a methodology for developing abstract and executable system-level model in SystemC of real-time embedded software, targeted to an RTOS. We design a RTOS emulation layer, called RESC, on top of the SystemC kernel. The application software is linked against the emulation layer to create an executable model of the software. The model can be integrated into system level HW-SW models which can be used for fast, accurate and early system validation. We first identify key real-time software constructs such as task-level concurrency, priorities, timers, pulses, and message-passing communication. We, then, define equivalent abstractions of the constructs in RESC on top of the SystemC library. We validated our models using industrial-size examples such as MP3 decoder and Vocoder. The experimental results show that our models are very accurate (<; 1% error) and significantly faster (up to 11X) than real-time software execution on target platform.},
  keywords={},
  doi={10.1109/ISQED.2013.6523666},
  ISSN={1948-3287},
  month={March},}
@INPROCEEDINGS{6529020,
  author={Sampath, S and Sagar, Bharat Bhushan and Nanjesh, B R},
  booktitle={2013 International Conference on Circuits, Power and Computing Technologies (ICCPCT)}, 
  title={Performance evaluation and comparison of MPI and PVM using a cluster based parallel computing architecture}, 
  year={2013},
  volume={},
  number={},
  pages={1253-1258},
  abstract={Parallel computing operates on the principle that large problems can often be divided into smaller ones, which are then solved concurrently to save time (wall clock time) by taking advantage of non-local resources and overcoming memory constraints. The main aim is to form a common cluster based parallel computing architecture for both MPI and PVM, which demonstrates the performance gain and losses achieved through parallel processing using MPI and PVM as separate cases. This can be realized by implementing the parallel applications like solving matrix multiplication problem, using MPI and PVM separately. The common architecture for MPI and PVM is based on the Master-Slave computing paradigm. The master will monitor the progress and be able to report the time taken to solve the problem, taking into account the time spent in breaking the problem into sub-tasks and combining the results along with the communication delays. The slaves are capable of accepting sub problems from the master and finding the solution and sending back to the master. We aim to evaluate and compare these statistics of both the cases to decide which among MPI and PVM gives faster performance and also compare with the time taken to solve the same problem in serial execution to demonstrate communication overhead involved in parallel computation. The results with runs on different number of nodes are compared to evaluate the efficiency of both MPI and PVM. We also show the performance dependency of parallel and serial computation, on RAM.},
  keywords={},
  doi={10.1109/ICCPCT.2013.6529020},
  ISSN={},
  month={March},}
@INPROCEEDINGS{6530923,
  author={Mego, Roman and Fryza, Tomas},
  booktitle={2013 23rd International Conference Radioelektronika (RADIOELEKTRONIKA)}, 
  title={Performance of parallel algorithms using OpenMP}, 
  year={2013},
  volume={},
  number={},
  pages={236-239},
  abstract={This paper describes tests performed by parallel signal processing algorithms on Texas Instruments 8-core digital signal processor and Intel Core i7. Tests reveal how the change of number of threads and size of input data influences the performance compared with sequential code. The result of the test is that the relative speedup is highly dependent on type of the algorithm and the amount of processed data.},
  keywords={},
  doi={10.1109/RadioElek.2013.6530923},
  ISSN={},
  month={April},}
@INPROCEEDINGS{6546071,
  author={Hoshino, Tetsuya and Maruyama, Naoya and Matsuoka, Satoshi and Takaki, Ryoji},
  booktitle={2013 13th IEEE/ACM International Symposium on Cluster, Cloud, and Grid Computing}, 
  title={CUDA vs OpenACC: Performance Case Studies with Kernel Benchmarks and a Memory-Bound CFD Application}, 
  year={2013},
  volume={},
  number={},
  pages={136-143},
  abstract={OpenACC is a new accelerator programming interface that provides a set of OpenMP-like loop directives for the programming of accelerators in an implicit and portable way. It allows the programmer to express the offloading of data and computations to accelerators, such that the porting process for legacy CPU-based applications can be significantly simplified. This paper focuses on the performance aspects of OpenACC using two micro benchmarks and one real-world computational fluid dynamics application. Both evaluations show that in general OpenACC performance is approximately 50\% lower than CUDA. However, for some applications it can reach up to 98\% with careful manual optimizations. The results also indicate several limitations of the OpenACC specification that hamper full use of the GPU hardware resources, resulting in a significant performance gap when compared to a fully tuned CUDA code. The lack of a programming interface for the shared memory in particular results in as much as three times lower performance.},
  keywords={},
  doi={10.1109/CCGrid.2013.12},
  ISSN={},
  month={May},}
@INPROCEEDINGS{6546065,
  author={Zhao, Xin and Buntinas, Darius and Zounmevo, Judicael and Dinan, James and Goodell, David and Balaji, Pavan and Thakur, Rajeev and Afsahi, Ahmad and Gropp, William},
  booktitle={2013 13th IEEE/ACM International Symposium on Cluster, Cloud, and Grid Computing}, 
  title={Toward Asynchronous and MPI-Interoperable Active Messages}, 
  year={2013},
  volume={},
  number={},
  pages={87-94},
  abstract={Many new large-scale applications have emerged recently and become important in areas such as bioinformatics and social networks. These applications are often data-intensive and involve irregular communication patterns and complex operations on remote processes. Active messages have proven effective for parallelizing such nontraditional applications. However, most current active messages frameworks are low-level and system specific, do not efficiently support asynchronous progress, and are not interoperable with two-sided and collective communications. In this paper, we present the design and implementation of an active messages framework inside MPI to provide portability and programmability, and we explore challenges when asynchronously handling active messages and other messages from the network as well as from shared memory. We test our implementation with a set of comprehensive benchmarks. Evaluation results show that our framework has the advantages of overlapping and interoperability, while introducing only a modest overhead.},
  keywords={},
  doi={10.1109/CCGrid.2013.84},
  ISSN={},
  month={May},}
@INPROCEEDINGS{6546084,
  author={Miwa, Masahiro and Nakashima, Kohta and Naruse, Akira},
  booktitle={2013 13th IEEE/ACM International Symposium on Cluster, Cloud, and Grid Computing}, 
  title={Interference-aware Incoming Message Detection for MPI Threaded Progression}, 
  year={2013},
  volume={},
  number={},
  pages={184-185},
  abstract={To enable overlap of computation and communication with non-blocking collective communication, it is required to progress asynchronously a sequence of communications. One of the naive implementation is to use a separate thread for communitation and run it in back of computation thread. However if the total number of threads is greater than the number of physical cores, context switches cause performance degradation of the computation thread. Simultaneous MultiThread (SMT) can be used to avoid this problem. However, commonly-used busy polling for incoming message detection also causes performance degradation of the computation thread. In this paper, we propose incoming message detection method using MONITOR/MWAIT instructions to reduce the performance degradation. Experiment results show that the performance of computation thread is improved largely compared to the busy polling method while latency is suppressed by a small increase.},
  keywords={},
  doi={10.1109/CCGrid.2013.61},
  ISSN={},
  month={May},}
@INPROCEEDINGS{6546093,
  author={Portegies Zwart, Simon},
  booktitle={2013 13th IEEE/ACM International Symposium on Cluster, Cloud, and Grid Computing}, 
  title={The Astronomical Multipurpose Software Environment and the Ecology of Star Clusters}, 
  year={2013},
  volume={},
  number={},
  pages={202-202},
  abstract={Star cluster ecology is the field of research where stellar evolution, gravitational dynamics, hydrodynamcs and the background potential dynamics of the parent galaxy interact to a complex non-­-linear evolution of self gravitating stellar systems. I will review the processes related to the ecology of stellar clusters, discuss the numerical hurdles and the physical principles. In addition, I will introduce the AMUSE framework with which we are performing simulations of the ecology of stellar clusters. AMUSE is a general purpose framework for interconnecting existing scientific software with a homogeneous and unified interface. Since the framework is based on the standard message passing interface, any production ready code that is written in a language that supports its native bindings can be incorporated; in addition, our framework is intrinsically parallel and it conveniently separates all the numerical solvers in memory. The strict separation also enables the possibility to realize unit conversion between the different modules and to recover from fatalities in a unified and structured way. The time spent in the framework is relatively small, and for production simulations we measured an overhead of at most 10%, which in our case is acceptable. Due to the unified structure of the interface, incorporating new modules which address the same physics is relatively straightforward. The time stepping between the codes can be simply consecutive or realized via a mixed variable symplectic method in which the Hamiltonian of the problem is solved in separate steps and combined via a Verlet-­-leapfrog integration scheme. In our experience with an implementation for multiphysics simulations in astrophysics, we encounter relatively few problems with the strict separation in methods, and the results of our test simulations are consistent with earlier results that use a monolithic framework.},
  keywords={},
  doi={10.1109/CCGrid.2013.113},
  ISSN={},
  month={May},}
@INPROCEEDINGS{6546114,
  author={Xu, Cong and Venkata, Manjunath Gorentla and Graham, Richard L. and Wang, Yandong and Liu, Zhuo and Yu, Weikuan},
  booktitle={2013 13th IEEE/ACM International Symposium on Cluster, Cloud, and Grid Computing}, 
  title={SLOAVx: Scalable LOgarithmic AlltoallV Algorithm for Hierarchical Multicore Systems}, 
  year={2013},
  volume={},
  number={},
  pages={369-376},
  abstract={Scientific applications use collective communication operations in Message Passing Interface (MPI) for global synchronization and data exchanges. Alltoall and AlltoallV are two important collective operations. They are used by MPI jobs to exchange messages among all of MPI processes. AlltoallV is a generalization of Alltoall, supporting messages of varying sizes. However, the existing MPI AlltoallV implementation has linear complexity, i.e., each process has to send messages to all other processes in the job. Such linear complexity can result in sub optimal scalability of MPI applications when they are deployed on millions of cores. To address above challenge, in this paper, we introduce a new Scalable LOgarithmic AlltoallV algorithm, named SLOAV, for MPI AlltoallV collective operation. SLOAV aims to achieve global exchange of small messages of different sizes in a logarithmic number of rounds. Furthermore, given the prevalence of multicore systems with shared memory, we design a hierarchical AlltoallV algorithm based on SLOAV by leveraging the advantages of shared memory, which is referred to as SLOAVx. Compared to SLOAV, SLOAVx significantly reduces the inter-node communication, thus improving the entire system performance and mitigating the impact of message latency. We have implemented and embedded both algorithms in Open MPI. Our evaluation on large-scale computer systems shows that for the 8-byte and 1024-process MPI Alltoallv operation, the SLOAV can reduce the latency by as much as 86.4%, when compared to the state-of-the-art, and SLOAVx can further optimize the SLOAV by up to 83.1% in terms of message latency on multicore systems. In addition, experiments with NAS Parallel Benchmark (NPB) demonstrate that our algorithms are very effective for real-world applications.},
  keywords={},
  doi={10.1109/CCGrid.2013.22},
  ISSN={},
  month={May},}
@INPROCEEDINGS{6546121,
  author={Wu, Jiadong and Hong, Bo},
  booktitle={2013 13th IEEE/ACM International Symposium on Cluster, Cloud, and Grid Computing}, 
  title={Collocating CPU-only Jobs with GPU-assisted Jobs on GPU-assisted HPC}, 
  year={2013},
  volume={},
  number={},
  pages={418-425},
  abstract={In recent years, GPU has evolved rapidly and exhibited great potential in accelerating scientific applications. Massive GPU-assisted HPC systems have been deployed. However, as a heterogeneous system, GPU-assisted HPC is harder to be programmed and utilized than conventional CPU-only system. Statistics of the Keene land system indicate that the effective utilization rate of computational resources is only about 40% when the system runs in normal condition with enough jobs in its queue. Our theoretical model shows that the lack of overlap between CPU/GPU computation is a major obstacle in the efficient utilization of heterogeneous system. In this paper, we evaluate the possibility of collocating CPU-only job with GPU-assisted job on the same node to increase overlap between CPU/GPU computation, thus achieving better utilization. Several performance compromising factors, such as resource isolation, CPU load, and GPU memory demands, are studied based on workload from popular MPI/CUDA benchmarks. The results indicate that, when those factors are managed properly, the collocated CPU-only job can efficiently scavenge the underutilized CPU resource without affecting the performance of both collocated jobs. Based on this insight, an experimental system with collocation-aware job scheduler and resource manager is proposed. With our experiment workload pool of mixed CPU and GPU jobs, the system demonstrates 15% gain in throughput and 10% gain in both CPU and GPU utilization.},
  keywords={},
  doi={10.1109/CCGrid.2013.19},
  ISSN={},
  month={May},}
@INPROCEEDINGS{6550577,
  author={Morales Dominguez, Augusto and Alcarria, Ramon and Cedeno, Edwin and Robles, Tomas},
  booktitle={2013 27th International Conference on Advanced Information Networking and Applications Workshops}, 
  title={An Extended Topic-Based Pub/Sub Broker for Cooperative Mobile Services}, 
  year={2013},
  volume={},
  number={},
  pages={1313-1318},
  abstract={The convergence between the network and service levels in mobile distributed systems allows content distribution in the Internet of Things. Distributed executing tasks exchange control and data events for enabling service cooperation. Event correlation addresses the correct identification of received events and the message delivery to the accurate task. However, it still remains as a major issue in these systems. We propose an extended-topic based model that targets Cooperative Mobile Services through the publish/subscribe primitives. It contributes to solve the event correlation challenge in distributed event-based systems. Finally, we evaluate our model by implementing a topic-based broker with multi-topic intersection support.},
  keywords={},
  doi={10.1109/WAINA.2013.119},
  ISSN={},
  month={March},}
@INPROCEEDINGS{6550594,
  author={Cheptsov, Alexey},
  booktitle={2013 27th International Conference on Advanced Information Networking and Applications Workshops}, 
  title={Promoting Data-Centric Supercomputing to the WWW World: Open MPI's Java Bindings}, 
  year={2013},
  volume={},
  number={},
  pages={1417-1422},
  abstract={In view of the explosive data growth along with excessive QoS requirements on scalability and processing time constraints, the Web is expected to dominate the data-centric computing already in the next decade. On the other hand, most of the current high performance computing infrastructures, both academic and industrial, do not support parallel Web applications, which are prevalently developed in the Java language. As a reaction to novel challenges of promoting data centric supercomputing to the Web, we present a solution that introduces Java bindings for the Message Passing Interface (MPI), seamlessly integrated in one of the famous MPI native implementations - Open MPI. Our implementation allows Java-based Semantic Web applications to be successfully ported to the most of modern high performance computing systems. We discuss the design features of Open MPI and introduce basic benchmark evaluations for Web applications.},
  keywords={},
  doi={10.1109/WAINA.2013.118},
  ISSN={},
  month={March},}
@INPROCEEDINGS{6552316,
  author={Fernández, José M. and Regalia, Phillip A.},
  booktitle={2013 47th Annual Conference on Information Sciences and Systems (CISS)}, 
  title={A modified bethe free energy approximation for codeword quantization}, 
  year={2013},
  volume={},
  number={},
  pages={1-5},
  abstract={A novel codeword quantization algorithm based on message-passing using a low density generator matrix formulation is proposed and analyzed. The scheme is a seemingly subtle variant on a recently proposed “truthiness” propagation algorithm, but one which affords a more explicit connection to a modified Bethe free energy function. Applications to distributed coding in sensor networks are also included in the simulation examples, where the algorithm is observed to outperform conventional LDPC belief propagation decoding using side information, in a practical setting when the reliability of the side information diminishes.},
  keywords={},
  doi={10.1109/CISS.2013.6552316},
  ISSN={},
  month={March},}
@INPROCEEDINGS{6557167,
  author={Matienzo, John and Jerger, Natalie Enright},
  booktitle={2013 IEEE International Symposium on Performance Analysis of Systems and Software (ISPASS)}, 
  title={Performance analysis of broadcasting algorithms on the Intel Single-Chip Cloud Computer}, 
  year={2013},
  volume={},
  number={},
  pages={163-172},
  abstract={Efficient broadcasting is essential for good performance on distributed or multiprocessor systems. Broadcasts are commonly used to implement message passing synchronization primitives, such as barriers, and also appear frequently in the set up stage of scientific applications. The Intel Single-Chip Cloud Computer (SCC), an experimental processor, uses synchronous message passing to facilitate communication between its 48 cores. RCCE, the SCC's message passing library, implements broadcasting in a traditional way: sending n-1 unicast messages, where n is the number of cores participating in the broadcast. This implementation can hinder performance as the number of cores participating in the broadcast increases and if the data being sent to each core is large. Also in the RCCE implementation, the broadcasting core is blocked from doing any useful work until all cores receive the broadcast. This paper explores several broadcasting schemes that take advantage of the resources of the SCC and the RCCE library. For example, we explore a scheme that propagates a broadcast to multiple cores in parallel and a scheme that parallelizes off-chip memory accesses which would otherwise need to be done sequentially. Our best broadcast scheme achieves a 35× speedup over the RCCE implementation. We also demonstrate that our improved broadcasting substantially reduces the time spent on communication in some benchmarks. While the broadcast schemes presented in this paper are implemented specifically for the SCC, they provide insight into the more general problem of broadcast communication and could be adapted to other types of distributed and multiprocessor systems.},
  keywords={},
  doi={10.1109/ISPASS.2013.6557167},
  ISSN={},
  month={April},}
@INPROCEEDINGS{6554042,
  author={Feng Wang and Canqun Yang and Juncheng Bai},
  booktitle={2013 8th International Conference on Computer Science & Education}, 
  title={Hybrid MPI/OpenMP optimization in Linpack benchmark on multi-core platforms}, 
  year={2013},
  volume={},
  number={},
  pages={917-920},
  abstract={With the increasing of the number of CPU cores, thousands of cores are used in the current supercomputers. The MPIJOpenMP hybrid programming model is popular in multicore systems. Some serial codes in the pure MPI programs turn to bottleneck and are easy to be neglected when these codes are ported to the MPIJOpenMP hybrid model. In the Linpack benchmark, we focus on the local swap algorithm and present an OpenMP optimization method to speedup the performance using multi-thread. On a cluster system with 36 multi-core CPUs, experiment results show that this method can decrease the time of lacal swap from 271.11 seconds to 202.53 seconds with the problem size 240, 000 and improve 5.23% of the whole Linpack program from 5.01 TeraFLOPS to 5.28 TeraFLOPS.},
  keywords={},
  doi={10.1109/ICCSE.2013.6554042},
  ISSN={},
  month={April},}
@INPROCEEDINGS{6559572,
  author={Ranokphanuwat, Ratthaslip and Kittitornkun, Surin and Tongsima, Sissades},
  booktitle={2013 10th International Conference on Electrical Engineering/Electronics, Computer, Telecommunications and Information Technology}, 
  title={Performance analysis & improvement of SNPHAP on Multi-core CPUs}, 
  year={2013},
  volume={},
  number={},
  pages={1-6},
  abstract={In this paper, we attempt to analyse this highly computational problem by parallelizing a haplotype inference algorithm, called SNPHAP. The analysis is based on both the orignal (sequential) algorithm and its corresponding run time complexity in Big-O notations. Then, we improve its performance using OpenMP 3.0 and test on a 4-core Intel Core i7-2600 (Hyper-Threading), an 8-core Intel XeonE5405, an 8-core Intel Xeon E5520 (Hyper-Threading) and a 32-core AMD Opteron 8356 Linux machines. The achievements in terms of maximum speedups are 260%, 316%, 410% and 488%, respectively. The factors that affect the speedup of SNPHAP are the specific parallelized code fraction, the suitable OpenMP constructs, the number of physical cores, the sizes of cache memories within/among CPU cores, the clock frequency and finally the memory technology.},
  keywords={},
  doi={10.1109/ECTICon.2013.6559572},
  ISSN={},
  month={May},}
@INPROCEEDINGS{6569827,
  author={Zhang, Xuechen and Liu, Ke and Davis, Kei and Jiang, Song},
  booktitle={2013 IEEE 27th International Symposium on Parallel and Distributed Processing}, 
  title={iBridge: Improving Unaligned Parallel File Access with Solid-State Drives}, 
  year={2013},
  volume={},
  number={},
  pages={381-392},
  abstract={When files are striped in a parallel I/O system, requests to the files are decomposed into a number of sub-requests that are distributed over multiple servers. If a request is not aligned with the striping pattern such decomposition can make the first and last sub-requests much smaller than the striping unit. Because hard-disk-based servers can be much less efficient in serving small requests than large ones, the system exhibits heterogeneity in serving sub-requests of different sizes, and the net throughput of the entire system can be severely degraded by the inefficiency of serving the smaller requests, or fragments. Because a request is not considered complete until its slowest sub-request is, the penalty is yet greater for synchronous requests. To make the situation even worse, the larger the request, or the more data servers the requested data is striped over, the larger the detrimental performance effect of serving fragments can be. This effect can become the Achilles' heel of a parallel I/O system performance seeking scalability with large sequential accesses. In this paper we propose iBridge, a scheme that uses solid-state drives to serve request fragments and thereby bridge the performance gap between serving fragments and serving large sub-requests. We have implemented iBridge in the PVFS file system. Our experimental results with representative MPI-IO benchmarks show that iBridge can significantly improve the I/O throughput of storage systems, especially for large requests with fragments.},
  keywords={},
  doi={10.1109/IPDPS.2013.21},
  ISSN={1530-2075},
  month={May},}
@INPROCEEDINGS{6569826,
  author={Ahn, Dong H. and Brim, Michael J. and de Supinski, Bronis R. and Gamblin, Todd and Lee, Gregory L. and Legendre, Matthew P. and Miller, Barton P. and Moody, Adam and Schulz, Martin},
  booktitle={2013 IEEE 27th International Symposium on Parallel and Distributed Processing}, 
  title={Efficient and Scalable Retrieval Techniques for Global File Properties}, 
  year={2013},
  volume={},
  number={},
  pages={369-380},
  abstract={Large-scale systems typically mount many different file systems with distinct performance characteristics and capacity. Applications must efficiently use this storage in order to realize their full performance potential. Users must take into account potential file replication throughout the storage hierarchy as well as contention in lower levels of the I/O system, and must consider communicating the results of file I/O between application processes to reduce file system accesses. Addressing these issues and optimizing file accesses requires detailed runtime knowledge of file system performance characteristics and the location(s) of files on them. In this paper, we propose Fast Global File Status (FGFS), a scalable mechanism to retrieve file information, such as its degree of distribution or replication and consistency. We use a novel node-local technique that turns expensive, non-scalable file system calls into simple string comparison operations. FGFS raises the namespace of a locally-defined file path to a global namespace with little or no file system calls to obtain global file properties efficiently. Our evaluation on a large multi-physics application shows that most FGFS file status queries on its executable and 848 shared library files complete in 272 milliseconds or faster at 32,768 MPI processes. Even the most expensive operation, which checks global file consistency, completes in under 7 seconds at this scale, an improvement of several orders of magnitude over the traditional checksum technique.},
  keywords={},
  doi={10.1109/IPDPS.2013.49},
  ISSN={1530-2075},
  month={May},}
@INPROCEEDINGS{6569860,
  author={Rao, Weixiong and Chen, Chao and Hui, Pan and Tarkoma, Sasu},
  booktitle={2013 IEEE 27th International Symposium on Parallel and Distributed Processing}, 
  title={Replication-Based Load Balancing in Distributed Content-Based Publish/Subscribe}, 
  year={2013},
  volume={},
  number={},
  pages={765-774},
  abstract={In recent years, content-based publish/subscribe (pub/sub) has become a popular paradigm to decouple content producers and consumers for Internet-scale content services. Many real applications show that the content workloads frequently exhibit very skewed distribution, and incur unbalanced workloads. To balance the workloads, the literature of content-based pub/sub adopted a migration scheme (Mis) to move (a subset of) subscription filters from overloaded brokers to underloaded brokers. In this way, the publications that successfully match the moved filters are then overloaded, leading to balanced workloads. Unfortunately, the scheme cannot reduce the overall matching workloads. In the worst case, suppose that all brokers suffer from heavy workloads. cannot find available brokers to offload the heavy workloads of those overloaded brokers, and fails to balance the workloads. To overcome the issue, the contribution of this paper is to develop a set of novel load balancing algorithms, namely a similarity-based replication scheme (Sir). The novelty of is that it not only balances the workloads of brokers but also reduces the overall workloads. Based on both simulation and emulation results, the extensive experiments verify that can achieve much better performance than, in terms of 43.10% higher entropy value (i.e., more balanced workloads) and 46.39% lower workloads.},
  keywords={},
  doi={10.1109/IPDPS.2013.38},
  ISSN={1530-2075},
  month={May},}
@INPROCEEDINGS{6569896,
  author={Stamatakis, Alexandros and Aberer, Andre J.},
  booktitle={2013 IEEE 27th International Symposium on Parallel and Distributed Processing}, 
  title={Novel Parallelization Schemes for Large-Scale Likelihood-based Phylogenetic Inference}, 
  year={2013},
  volume={},
  number={},
  pages={1195-1204},
  abstract={The molecular data avalanche generated by novel wet-lab sequencing technologies allows for reconstructing phylogenies (evolutionary trees) using hundreds of complete genomes as input data. Therefore, scalable codes are required to infer trees on these data under likelihood-based models of molecular evolution. We recently introduced a checkpointable and scalable MPI-based code for this purpose called RAxML-Light and are currently using it for several real-world data analysis projects. It turned out that the scalability of RAxML-Light is nonetheless still limited because of the fork-join parallelization approach that is deployed. To this end, we introduce a novel, generally applicable, approach to computing the phylogenetic likelihood in parallel on whole-genome datasets and implement it in ExaML (Exascale Maximum Likelihood). ExaML executes up to 3.2 times faster than RAxML-Light because of the more efficient parallelization and communication scheme, while implementing exactly the same tree search algorithm. Moreover, the new parallelization approach exhibits lower code complexity and a more appropriate structure for implementing fault tolerance with respect to hardware failures.},
  keywords={},
  doi={10.1109/IPDPS.2013.70},
  ISSN={1530-2075},
  month={May},}
@INPROCEEDINGS{6571603,
  author={Zhu, Huiquan and Dong, Jin Song and Wadhwa, Bimlesh and Lin, Shang-Wei},
  booktitle={2013 IEEE Sixth International Conference on Software Testing, Verification and Validation Workshops}, 
  title={Generating C# Programs from CSP# Models}, 
  year={2013},
  volume={},
  number={},
  pages={21-26},
  abstract={Due to the inherent complexity of the concurrent behavior, it is difficult to ensure the program satisfies the concurrent properties. CSP#, as a formal language, is used to model the program and the properties can be verified on the CSP# model. It is desirable to have a transformation technique from the CSP# model to the implementation. We implement the CSP# operators in a C# library “PAT.Runtime”. Based on it, a code generation tool is developed in PAT framework to transform CSP# models to multi-threaded C# programs. We prove that the generated C# program and original CSP# model are equivalent on the traces semantics. The validated properties of the CSP# model preserve in the generated program.},
  keywords={},
  doi={10.1109/ICSTW.2013.10},
  ISSN={},
  month={March},}
@INPROCEEDINGS{6576421,
  author={Sidi, Habib B.A. and Chahin, Wissam and El-Azouzi, Rachid and De Pellegrini, Francesco},
  booktitle={2013 11th International Symposium and Workshops on Modeling and Optimization in Mobile, Ad Hoc and Wireless Networks (WiOpt)}, 
  title={Coordination minority games in delay tolerant networks}, 
  year={2013},
  volume={},
  number={},
  pages={667-674},
  abstract={In this paper we introduce a novel framework for the distributed control of DTNs. The mechanism that we propose tackles a crucial aspect of such systems: in order to support message replication the devices acting as relays need to sacrifice part of their batteries. The aim is thus to provide a reward mechanism able to induce activation of relays in a coordinated fashion. The proposed scheme functions in non-cooperative fashion, and requires minimal message exchange to operate. In particular, relays choose among two strategies: either to participate to message relaying, or not to participate in order to save energy. The base for our mechanism design is to define the relays' utility function according to a minority game; in fact, relays compete to be in the population minority with respect to activation. By tuning the activation level, the system can hence control and optimize the DTN operating point in a distributed manner. To this respect, we characterize extensively the possible equilibria of this game. Finally, a stochastic learning algorithm is proposed which can provably drive the system to the equilibrium solution without requiring perfect state information at relay nodes. We provide extensive numerical results to validate the proposed scheme.},
  keywords={},
  doi={},
  ISSN={},
  month={May},}
@INPROCEEDINGS{6579368,
  author={Han, S. and Choi, Hyoung G.},
  booktitle={2013 International Conference on Information Science and Applications (ICISA)}, 
  title={Q2P1 SPLITTiNG Finite Element Method for Large Eddy Simulation}, 
  year={2013},
  volume={},
  number={},
  pages={1-2},
  abstract={In A finite element code based on P2P1 tetra element has been developed for the large eddy simulation (LES) of turbulent flows around a complex geometry. Fractional 4-step algorithm is employed to obtain time accurate solution since it is less expensive than the integrated formulation, in which the velocity and pressure fields are solved at the same time. Crank-Nicolson method is used for second order temporal discretization and Galerkin method is adopted for spatial discretization. For very high Reynolds number flows which would require a formidable number of nodes to resolve the flow field, SUPG (Streamline Upwind Petrov Galerkin) method is applied to the quadratic interpolation function for velocity variables. Noting that the calculation of intrinsic time scale is very complicated when using SUPG for quadratic tetra element of velocity variables, the present study uses a unique intrinsic time scale proposed by Codina et al.[6] since it makes the present three-dimensional unstructured code much simpler in terms of implementing SUPG. In order to see the effect of numerical diffusion caused by using an upwind scheme (SUPG), those obtained from P2P1 Galerkin method and P2P1 Petrov-Galerkin approach are compared for the flow around a sphere at some Reynolds numbers. Both Smagorinsky model and dynamic model are adopted as subgrid scale models in the context of P2P1 finite element method. With the parallelization of the present code in mind, diagonal preconditioning is used for the momentum equation and ILU preconditioner is used for the pressure equation. As a bench mark problem for code validation, turbulent flow around a sphere has been studied at various Reynolds numbers. Drag coefficient has been obtained and compared with existing experimental. It is shown that the drag coefficient for the sphere agrees well with the existing experimental data when the Reynolds number is less than the critical value (~4x105). We also observe that the drag coefficient decreases as the Reynolds number goes beyond the transition value. Turbulent flow around MIRA model with wheels has been calculated at Re=2 x 106 using a relatively coarse grid for LES since the up-to-date serial computer can not afford to use a fine enough mesh to resolve very high Reynolds number flows around complex geometries. The computed drag coefficient is compared with the data from wind tunnel test. In order to study the mesh resolution effect on LES solution, the parallel version of the present code based on the domain decomposition and MPI (Message Passing Interface) is being developed and will be discussed.},
  keywords={},
  doi={10.1109/ICISA.2013.6579368},
  ISSN={2162-9048},
  month={June},}
@INPROCEEDINGS{6582779,
  author={Razavi, Razieh and Imran, Muhammad Ali and Xiao, Pei and Tafazolli, Rahim},
  booktitle={European Wireless 2013; 19th European Wireless Conference}, 
  title={Effect of Forward Error Correction Codes on the Performance of LDS-OFDM}, 
  year={2013},
  volume={},
  number={},
  pages={1-6},
  abstract={In this paper, selection criteria of Forward Error Correction (FEC) codes, in particular, the convolutional codes are evaluated for a novel air interface scheme, called Low Density Signature Orthogonal Frequency Division Multiple Access (LDS-OFDM). In this regard, the mutual information transfer characteristics of turbo Multiuser Detector (MUD) are investigated using Extrinsic Information Transfer (EXIT) charts. LDS-OFDM uses Low Density Signature structure for spreading the data symbols in frequency domain. This technique benefits from frequency diversity in addition to its ability of supporting parallel data streams more than the number of subcarriers (overloaded condition). The turbo MUD couples the data symbols' detector of LDS scheme with users' FEC decoders through the message passing principle.},
  keywords={},
  doi={},
  ISSN={},
  month={April},}
@INPROCEEDINGS{6583791,
  author={Huang, Huawei and Zeng, Deze and Guo, Song and Yao, Hong and Miyazaki, Toshiaki},
  booktitle={2013 9th International Wireless Communications and Mobile Computing Conference (IWCMC)}, 
  title={Stochastic analysis on epidemic dissemination of lifetime-controlled messages in DTNs}, 
  year={2013},
  volume={},
  number={},
  pages={1578-1583},
  abstract={To understand the delivery performance of message dissemination in Disruption Tolerant Networks (DTNs), various methods have been proposed in the literature. However, existing work shares a common simplification that the pairwise meeting rate between any two mobile nodes is exponentially distributed. In this paper, instead of relying on such assumption, we jointly consider the transmission range and Random Direction Mobility (RDM) model to stochastically analyze delivery performance of epidemic routing in terms of percolation ratio and delivery delay. Furthermore, we study a controlled epidemic routing, in which any message stays at a mobile node longer than a predefined lifetime should be removed from the node. It can be considered as an age-structure process described by the Susceptible-Infectious-Recovered (SIR) model. To the best of our knowledge, we are the first to characterize the message propagation process by applying the Delay Differential Equations (DDEs) in DTNs. The correctness of our analysis is validated by extensive simulations.},
  keywords={},
  doi={10.1109/IWCMC.2013.6583791},
  ISSN={2376-6506},
  month={July},}
@INPROCEEDINGS{6588794,
  author={Cai, Jing and Gao, Shenfa},
  booktitle={2013 5th International Conference on Computer Science and Information Technology}, 
  title={Message rearrange theory in message recovery protocol}, 
  year={2013},
  volume={},
  number={},
  pages={293-297},
  abstract={In optimistic message protocols, the receiving order of not logged messages and their payloads may be lost because of process failures. To address the lost order of received but not logged messages, our paper proposes a message rearranging theory with improved logic clock. With improved logic clock, our protocol rearranges lost messages as an equivalent message receiving sequence on the assumption of PWD. Once process failures occur, our recovery protocol first determines the lost messages with message number check theory and then restores them by logging files. Then the recovery protocol rearranges those lost messages, forms an equivalent message sequence and replaces the original one during failure-free process execution. There are two main advantages of our protocol: first only failed processes rollback and not failed processes can ongoing; second our protocol can deal with more than one failure.},
  keywords={},
  doi={10.1109/CSIT.2013.6588794},
  ISSN={},
  month={March},}
@ARTICLE{6595057,
  author={Barman, Siddharth and Liu, Xishuo and Draper, Stark C. and Recht, Benjamin},
  journal={IEEE Transactions on Information Theory}, 
  title={Decomposition Methods for Large Scale LP Decoding}, 
  year={2013},
  volume={59},
  number={12},
  pages={7870-7886},
  abstract={When binary linear error-correcting codes are used over symmetric channels, a relaxed version of the maximum likelihood decoding problem can be stated as a linear program (LP). This LP decoder can be used to decode error-correcting codes at bit-error-rates comparable to state-of-the-art belief propagation (BP) decoders, but with significantly stronger theoretical guarantees. However, LP decoding when implemented with standard LP solvers does not easily scale to the block lengths of modern error correcting codes. In this paper, we draw on decomposition methods from optimization theory, specifically the alternating direction method of multipliers (ADMM), to develop efficient distributed algorithms for LP decoding. The key enabling technical result is a “two-slice” characterization of the parity polytope, the polytope formed by taking the convex hull of all codewords of the single parity check code. This new characterization simplifies the representation of points in the polytope. Using this simplification, we develop an efficient algorithm for Euclidean norm projection onto the parity polytope. This projection is required by the ADMM decoder and its solution allows us to use LP decoding, with all its theoretical guarantees, to decode large-scale error correcting codes efficiently. We present numerical results for LDPC codes of lengths more than 1000. The waterfall region of LP decoding is seen to initiate at a slightly higher SNR than for sum-product BP, however an error floor is not observed for LP decoding, which is not the case for BP. Our implementation of LP decoding using the ADMM executes as fast as our baseline sum-product BP decoder, is fully parallelizable, and can be seen to implement a type of message-passing with a particularly simple schedule.},
  keywords={},
  doi={10.1109/TIT.2013.2281372},
  ISSN={1557-9654},
  month={Dec},}
@INPROCEEDINGS{6599689,
  author={Amirsoleimani, Amirali and Soleimani, H. and Ahmadi, A. and Bavandpour, M. and Zwolinski, M.},
  booktitle={2013 21st Iranian Conference on Electrical Engineering (ICEE)}, 
  title={Modeling the effect of process variations on the delay and power of the digital circuit using fast simulators}, 
  year={2013},
  volume={},
  number={},
  pages={1-6},
  abstract={Process variation has an increasingly dramatic effect on delay and power as process geometries shrink. Even if the amount of variation remains the same as in previous generations, it accounts for a greater percentage of process geometries as they get smaller. So an accurate prediction of path delay and power variability for real digital circuits in the current technologies is very important; however, its main drawback is the high runtime cost. In this paper, we present a new fast EDA tool which accelerates Monte Carlo based statistical static timing analysis (SSTA) for complex digital circuit. Parallel platforms like Message Passing Interface and POSIX® Threads and also the GPU-based CUDA platform suggests a natural fit for this analysis. So using these platforms, Monte Carlo based SSTA for complex digital circuits at 32, 45 and 65 nm has been performed. and of the pin-to-output delay and power distributions for all basic gates are extracted using a memory lookup from Hspice and then the results are extended to the complex digital circuit in a hierarchal manner on the parallel platforms. Results show that the GPU-based platform has the highest performance (speedup of 19×). The correctness of the Monte Carlo based SSTA implemented on a GPU has been verified by comparing its results with a CPU based implementation.},
  keywords={},
  doi={10.1109/IranianCEE.2013.6599689},
  ISSN={2164-7054},
  month={May},}
@INPROCEEDINGS{6598348,
  author={Jezequel, Loïg and Fabre, Eric and Khomenko, Victor},
  booktitle={2013 13th International Conference on Application of Concurrency to System Design}, 
  title={Factored Planning: From Automata to Petri Nets}, 
  year={2013},
  volume={},
  number={},
  pages={130-139},
  abstract={Factored planning mitigates the state space explosion problem by avoiding the construction of the state space of the whole system and instead working with the system's components. Traditionally, finite automata have been used to represent the components, with the overall system being represented as their product. In this paper we change the representation of components to safe Petri nets. This allows one to use cheap structural operations like transition contractions to reduce the size of the Petri net, before its state space is generated, which often leads to substantial savings compared with automata. The proposed approach has been implemented and proven efficient on several factored planning benchmarks.},
  keywords={},
  doi={10.1109/ACSD.2013.16},
  ISSN={1550-4808},
  month={July},}
@INPROCEEDINGS{6598481,
  author={Wu, Xingfu and Taylor, Valerie},
  booktitle={2013 14th ACIS International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing}, 
  title={Performance Characteristics of Hybrid MPI/OpenMP Scientific Applications on a Large-Scale Multithreaded BlueGene/Q Supercomputer}, 
  year={2013},
  volume={},
  number={},
  pages={303-309},
  abstract={In this paper, we investigate the performance characteristics of five hybrid MPI/OpenMP scientific applications (two NAS Parallel benchmarks Multi-Zone SP-MZ and BT-MZ, an earthquake simulation PEQdyna, an aerospace application PMLB and a 3D particle-in-cell application GTC) on a large-scale multithreaded Blue Gene/Q supercomputer at Argonne National laboratory, and quantify the performance gap resulting from using different number of threads per node. We use performance tools and MPI profile and trace libraries available on the supercomputer to analyze and compare the performance of these hybrid scientific applications with increasing the number OpenMP threads per node, and find that increasing the number of threads to some extent saturates or worsens performance of these hybrid applications. For the strong-scaling hybrid scientific applications such as SP-MZ, BT-MZ, PEQdyna and PLMB, using 32 threads per node results in much better application efficiency than using 64 threads per node, and as increasing the number of threads per node, the FPU (Floating Point Unit) percentage decreases, and the MPI percentage (except PMLB) and IPC (Instructions per cycle) per core (except BT-MZ) increase. For the weak-scaling hybrid scientific application such as GTC, the performance trend (relative speedup) is very similar with increasing number of threads per node no matter how many nodes (32, 128, 512) are used.},
  keywords={},
  doi={10.1109/SNPD.2013.81},
  ISSN={},
  month={July},}
@INPROCEEDINGS{6601454,
  author={Kalegari, Diego H. and Lopes, Heitor S.},
  booktitle={2013 IEEE Symposium on Differential Evolution (SDE)}, 
  title={An improved parallel differential evolution approach for protein structure prediction using both 2D and 3D off-lattice models}, 
  year={2013},
  volume={},
  number={},
  pages={143-150},
  abstract={Protein structure prediction (PSP) is a well-known problem in bioinformatics. Identifying protein native conformations makes it possible to predict its function within the organism. Knowing this also helps the development of new drugs and the comprehension of some biological mechanisms. During years some techniques have been developed for this purpose but, due to their high cost, it is necessary to use simplified models of protein structures. However, even the simplest models, with low biological plausibility, are excessively complex from the computational point of view. This paper reports the application of Differential Evolution (DE) to solve the PSP problem using a Toy Model (also known as the AB Model) in both 2D and 3D to represent the protein structure. This work presents two different versions of the DE algorithm (basic and adaptive) using a parallel architecture (master-slave) based on Message Passing Interface in a cluster. Some special operators for DE were developed: explosion and mirror mutation. All tests executed in this work used four benchmark sequences, ranging from 13 to 55 amino acids. The results for both parallel DE algorithms using both 2D and 3D models were compared with other works in the literature. The DE algorithm achieved excellent results. Overall results encourage further research towards the use of knowledge-based operators to improve further the performance of DE.},
  keywords={},
  doi={10.1109/SDE.2013.6601454},
  ISSN={},
  month={April},}
@INPROCEEDINGS{6602056,
  author={Taylor, Ian and Sharp, Julia L. and White, David L. and Hallstrom, Jason O. and Eidson, Gene and von Oehsen, J. Barr and Duffy, Edward B. and Privette, Charles V. and Cook, Charles T. and Sampath, Aravindh and Radhakrishnan, Gyanas},
  booktitle={2013 Fourth International Conference on Computing for Geospatial Research and Application}, 
  title={Monitoring Sensor Measurement Anomalies of Streaming Environmental Data Using a Local Correlation Score}, 
  year={2013},
  volume={},
  number={},
  pages={136-137},
  abstract={Real-time quality control (QC) of streaming natural resource data is needed to support the delivery of high quality data to system users. QC processes need to enable the identification of aberrations, as well as trends that may indicate degradation or component failures. These QC processes form a framework to support the goal of verified data delivered in a timely manner. In this paper, we investigate a method of computing Local Correlation Score (LCS) to detect anomalous patterns among sensor platforms in a concurrent manner. We use the R programming language and OpenMPI. Using empirical tests, we determine the benefits of computing the LCS in parallel, and on various sizes of clusters. We also analyze its use for real time mapping of Intelligent River data. Our results show that the LCS computed concurrently is an effective means for prompt quality assurance of natural resource data.},
  keywords={},
  doi={10.1109/COMGEO.2013.25},
  ISSN={},
  month={July},}
@INPROCEEDINGS{6620033,
  author={Khayami, S. R. and Alinezhad, A. and Jafari, H.},
  booktitle={The 5th Conference on Information and Knowledge Technology}, 
  title={Implementation of a parallel method for the graph coloring problem using MPI and verification of the number of processors on it}, 
  year={2013},
  volume={},
  number={},
  pages={30-34},
  abstract={In this paper, a parallel version based on a pipeline of innovative methods for graph coloring in a sequential mode is presented. The results of the execution time for parallel implementation in the C++ language using the Message Passing Interface (MPI) on a multi-processor machine is presented and discussed. This problem also has been implemented in a fully sequential and recursive mode, in the same environment, and the results of comparing them to parallel implementation have been reported.},
  keywords={},
  doi={10.1109/IKT.2013.6620033},
  ISSN={},
  month={May},}
@INPROCEEDINGS{6620477,
  author={Zhang, Xiaojie and Siegel, Paul H.},
  booktitle={2013 IEEE International Symposium on Information Theory}, 
  title={Efficient iterative LP decoding of LDPC codes with alternating direction method of multipliers}, 
  year={2013},
  volume={},
  number={},
  pages={1501-1505},
  abstract={In this paper, we propose an efficient message-passing algorithm to solve the LP decoding problem. This algorithm is based on the alternating direction method of multipliers (ADMM), a classic technique in convex optimization theory that is designed for parallel implementation. The computational complexity of ADMM-based LP decoding is largely determined by the method used to project a vector of real values to the parity polytope of a given parity check. The key contribution of this paper is a novel, efficient projection algorithm that can substantially improve the decoding speed of the ADMM-based LP decoder.},
  keywords={},
  doi={10.1109/ISIT.2013.6620477},
  ISSN={2157-8117},
  month={July},}
@INPROCEEDINGS{6624254,
  author={Brown, D. Richard and Ni, Min and Madhow, Upamanyu and Bidigare, Patrick},
  booktitle={2013 47th Annual Conference on Information Sciences and Systems (CISS)}, 
  title={Distributed reception with coarsely-quantized observation exchanges}, 
  year={2013},
  volume={},
  number={},
  pages={1-6},
  abstract={This paper considers the problem of jointly decoding binary phase shift keyed (BPSK) messages from a single distant transmitter to a cooperative receive cluster connected by a local area network (LAN). A distributed reception technique is proposed based on the exchange of coarsely-quantized observations among some or all of the nodes in the receive cluster. By taking into account the differences in channel quality across the receive cluster, the quantized information from other nodes in the receive cluster can be appropriately combined with locally unquantized information to form aggregate posterior likelihoods for the received bits. The LAN throughput requirements of this technique are derived as a function of the number of participating nodes in the receive cluster, the forward link code rate, and the quantization parameters. Using information theoretic analysis and simulations of an LDPC coded system in fading channels, numerical results show that the performance penalty (in terms of outage probability and block error rate with respect to ideal receive beamforming) due to coarse quantization is small in the low SNR regimes enabled by cooperative distributed reception.},
  keywords={},
  doi={10.1109/CISS.2013.6624254},
  ISSN={},
  month={March},}
@INPROCEEDINGS{6624252,
  author={Brown, D. Richard and Klein, Andrew G.},
  booktitle={2013 47th Annual Conference on Information Sciences and Systems (CISS)}, 
  title={Precise timestamp-free network synchronization}, 
  year={2013},
  volume={},
  number={},
  pages={1-6},
  abstract={This paper describes an approach to master/slave network synchronization based on bidirectional message exchanges without the use of timestamps. Rather than the usual approach of exchanging digital timestamps through a dedicated synchronization protocol, an approach is described in which synchronization information is conveyed implicitly at the physical layer through the timing of the master node¿s responses to the slave nodes. This approach can reduce overhead and allow the embedding of synchronization functions in existing network traffic. A timestamp-free synchronization protocol is described and its performance is quantified in the presence of delay estimation error and stochastic local oscillator dynamics. A filtering framework is also developed to allow each slave node to accurately infer and correct local clock drifts from multiple noisy clock offset estimates. Based on fundamental delay estimation bounds for narrowband signals, numerical results show that synchronization among the slave nodes can be achieved quickly and that the resulting steady-state accuracy can be sufficient to support distributed transmission techniques requiring carrier phase alignment, e.g. distributed beamforming.},
  keywords={},
  doi={10.1109/CISS.2013.6624252},
  ISSN={},
  month={March},}
@INPROCEEDINGS{6624621,
  author={Jingyan Mo and Liang Shen and Bing Wei and Weidong Fang and Ying Yan},
  booktitle={IET International Radar Conference 2013}, 
  title={RCS computation of engine by parallel higher-order MoM with out-of- core technique}, 
  year={2013},
  volume={},
  number={},
  pages={1-3},
  abstract={In this paper, a Method of Moments with Higher-Order basis functions (HOBMoM), parallel implementation based on Message Passing Interface (MPI) and Out-of-Core technology (OOC) has been proposed to compute the Radar Cross Section (RCS) of an aircraft's engine. The block-partitioned parallel scheme for the large dense MoM matrix is designed to achieve excellent load balancing and high parallel efficiency. Because of the bottleneck of the RAM limitation, the out-of-core technology is employed. Some numerical results demonstrate that the Higher-Order basis used in this paper is superior to the conventional RWG basis and is capable of solving various electrically large problems such as the computation of RCS.},
  keywords={},
  doi={10.1049/cp.2013.0457},
  ISSN={},
  month={April},}
@INPROCEEDINGS{6624650,
  author={Shugang Jiang and Zhaofeng Lv and Yu Zhang and Bing Wei and Xunwang Zhao},
  booktitle={IET International Radar Conference 2013}, 
  title={Analysis of parallel performance of MPI based parallel FDTD on supercomputer}, 
  year={2013},
  volume={},
  number={},
  pages={1-4},
  abstract={With the development of multi-core processors, computer clusters and the application of parallel MPI technique, the study of electromagnetic fields numerical arithmetic can improve the capacity of solving large problems. In this paper, based on the platform from National Supercomputing Center in Tianjin (NSCC-TJ: Ranked first in the world in 2010.11), some tests about the parallel efficiency of the parallel FDTD code are made to provide a general rule for a best performance of FDTD on multi-core computers. The results show that following this rule, we can achieve the highest computational efficiency on a more advanced platform.},
  keywords={},
  doi={10.1049/cp.2013.0486},
  ISSN={},
  month={April},}
@INPROCEEDINGS{6630626,
  author={Wong, Stanton and Walter, Jennifer},
  booktitle={2013 IEEE International Conference on Robotics and Automation}, 
  title={Deterministic distributed algorithm for self-reconfiguration of modular robots from arbitrary to straight chain configurations}, 
  year={2013},
  volume={},
  number={},
  pages={537-543},
  abstract={The problem addressed is the reconfiguration of a system of hexagonal metamorphic robots from an initial arbitrary shape configuration I, to a straight chain goal configuration, G. This is the first time a fully distributed deterministic algorithm has been written to achieve the parallel reconfiguration of a system of homogeneous modules from an initial arbitrary shape to a straight chain goal configuration. The contribution of this paper is an algorithm that uses no pre-processing or message passing to accomplish reconfiguration. The algorithm eliminates the possibility of module collision by assuming modules have the capability to detect another module at a distance of one cell away on each of their six sides. The algorithm is successful as long as: the system starts in an initial configuration that satisfies admissibility requirements, the goal cells are known to all modules, and if every module is equipped with sensors to determine if the cell adjacent to and in the same direction as a neighboring empty cell is occupied. A discrete-event simulator tests the algorithm.},
  keywords={},
  doi={10.1109/ICRA.2013.6630626},
  ISSN={1050-4729},
  month={May},}
@INPROCEEDINGS{6641412,
  author={Perks, O. and Beckingsale, D. A. and Dawes, A. S. and Herdman, J. A. and Mazauric, C. and Jarvis, S. A.},
  booktitle={2013 International Conference on High Performance Computing & Simulation (HPCS)}, 
  title={Analysing the influence of InfiniBand choice on OpenMPI memory consumption}, 
  year={2013},
  volume={},
  number={},
  pages={186-193},
  abstract={The ever increasing scale of modern high performance computing platforms poses challenges for system architects and code developers alike. The increase in core count densities and associated cost of components is having a dramatic effect on the viability of high memory-per-core ratios. Whilst the available memory per core is decreasing, the increased scale of parallel jobs is testing the efficiency of MPI implementations with respect to memory overhead. Scalability issues have always plagued both hardware manufacturers and software developers, and the combined effects can be disabling. In this paper we address the issue of MPI memory consumption with regard to InfiniBand network communications. We reaffirm some widely held beliefs regarding the existence of scalability problems under certain conditions. Additionally, we present results testing memory-optimised runtime configurations and vendor provided optimisation libraries. Using Orthrus, a linear solver benchmark developed by AWE, we demonstrate these memory-centric optimisations and their performance implications. We show the growth of OpenMPI memory consumption (demonstrating poor scalability) on both Mellanox and QLogic InfiniBand platforms. We demonstrate a 616× increase in MPI memory consumption for a 64× increase in core count, with a default OpenMPI configuration on Mellanox. Through the use of the Mellanox MXM and QLogic PSM optimisation libraries we are able to observe a 117× and 115× reduction in MPI memory at application memory high water mark. This significantly improves the potential scalability of the code.},
  keywords={},
  doi={10.1109/HPCSim.2013.6641412},
  ISSN={},
  month={July},}
@INPROCEEDINGS{6641414,
  author={Kanur, Sudeep and Georgakarakos, Georgios and Simlä, Antti and Lagravière, Jérémie and Nybom, Kristian and Lafond, Sébastien and Lilius, Johan},
  booktitle={2013 International Conference on High Performance Computing & Simulation (HPCS)}, 
  title={Parallel decoder for low density parity check codes: A MPSoC study}, 
  year={2013},
  volume={},
  number={},
  pages={202-206},
  abstract={The near channel performance of Low Density Parity Check Codes (LDPC) has motivated its wide applications. Iterative decoding of LDPC codes provides significant implementation challenges as the complexity grows with the code size. Recent trends in integrating Multiprocessor System on Chip (MPSoC) with Network on Chip (NoC) gives a modular platform for parallel implementation. This paper presents an implementation platform for decoding LDPC codes based on HeMPS, an open source MPSoC framework based on NoC communication fabric. Reduced minimum sum algorithm is used for decoding LDPC codes and simulations are performed using HeMPS tool. The data rate and speedup factor measured for decoding a rate 1/2 LDPC code characterised by 252 × 504 parity matrix is presented.},
  keywords={},
  doi={10.1109/HPCSim.2013.6641414},
  ISSN={},
  month={July},}
@INPROCEEDINGS{6642574,
  author={Moon, Todd K. and Gunther, Jacob H.},
  booktitle={2013 IEEE Digital Signal Processing and Signal Processing Education Meeting (DSP/SPE)}, 
  title={Message passing soft decoding of linear block codes over arbitrary finite fields}, 
  year={2013},
  volume={},
  number={},
  pages={107-111},
  abstract={In this paper, soft-input/soft-output decoding of an arbitrary linear block error correction code over any finite field is performed by transforming an algebraic description of the decoding problem to a binary message passing decoding problem, such as used for a binary LDPC decoder. Field symbols are represented using a Hadamard-like transform of the probability distribution over the field, and field operations in this setting are represented by real multiplication and permutations. This gives rise to a “soft key equation,” an overdetermined nonlinear equation. Here, a solution to the soft-key equation is obtained by enforcing a parity consistency, which converts the decoding problem into a message-passing problem which is able to exploit the sparse structure of the problem representation. Simulated performance results indicate that decoding is strongest for highest rate codes, motivating the investigation of improved performance.},
  keywords={},
  doi={10.1109/DSP-SPE.2013.6642574},
  ISSN={},
  month={Aug},}
@INPROCEEDINGS{6650896,
  author={Gamom Ngounou Ewo, Roland Christian and Kiegaing, Emmanuel and Mbouenda, Martin and Fotsin, Hilaire Bertrand and Granado, Bertrand},
  booktitle={2013 IEEE International Symposium on Parallel & Distributed Processing, Workshops and Phd Forum}, 
  title={Hardware MPI-2 Functions for Multi-Processing Reconfigurable System on Chip}, 
  year={2013},
  volume={},
  number={},
  pages={273-280},
  abstract={In this paper we describe a hardware implementation, of the MPI-2 RMA communication library primitive, devoted to a distributed Multi Processing Reconfigurable System on Chip (MP-RSoC). We designed a platform able to process communications over a custom heterogeneous MP-RSoC using our hardware MPI-2 RMA communication primitives. To implement these primitives, we have conceived a scalable Network on Chip based on a crossbar. MPI-2 RMA primitives are directly usable in hardware tasks in the MP-RSoC to transfer data between all resources, either hardware or software. We also show that using message passing for parallel programming can have benefits in term of scalability and heterogeneity. Our hardware primitives have been implemented and tested on Xilinx FPGA spartan6 board.},
  keywords={},
  doi={10.1109/IPDPSW.2013.147},
  ISSN={},
  month={May},}
@INPROCEEDINGS{6650939,
  author={Du, Jun and Yu, Ce and Sun, Jizhou and Sun, Chao and Tang, Shanjiang and Yin, Yanlong},
  booktitle={2013 IEEE International Symposium on Parallel & Distributed Processing, Workshops and Phd Forum}, 
  title={EasyHPS: A Multilevel Hybrid Parallel System for Dynamic Programming}, 
  year={2013},
  volume={},
  number={},
  pages={630-639},
  abstract={Dynamic programming approach solves complex problems efficiently by breaking them down into simpler sub-problems, and is widely utilized in scientific computing. With the increasing data volume of scientific applications and development of multi-core/multi-processor hardware technologies, it is necessary to develop efficient techniques for parallelizing dynamic programming algorithms, particularly in multilevel computing environment. The intrinsically strong data dependency of dynamic programming also makes it difficult and error-prone for the programmer to write a correct and efficient parallel program. In order to make the parallel programming easier and more efficient, we have developed a multilevel hybrid parallel runtime system for dynamic programming named EasyHPS based on the Directed Acyclic Graph(DAG) Data Driven Model in this paper. The EasyHPS system encapsulates details of parallelization implementation, such as task scheduling and message passing, and provides easy API for users to reduce the complexity of parallel programming parallelization. In the DAG Data Driven Model, the entire application is initially partitioned by data partitioning into sub-tasks that each sub-task processing a data block. Then all sub-tasks are modeled as a DAG, in which each vertex represents a sub-task and each edge indicates the communication dependency between the two sub-tasks. In task scheduling, a dynamic approach is proposed based on DAG Data Driven Model to achieve load balancing. Data partitioning and task scheduling are both done on processor-level and thread-level in the multilevel computing environment. In addition, experimental results demonstrate that the proposed dynamic scheduling approach in EasyHPS is more efficient in comparison with those static ones such as block-cyclic based wave front.},
  keywords={},
  doi={10.1109/IPDPSW.2013.93},
  ISSN={},
  month={May},}
@INPROCEEDINGS{6650969,
  author={Porterfield, Allan K. and Olivier, Stephen L. and Bhalachandra, Sridutt and Prins, Jan F.},
  booktitle={2013 IEEE International Symposium on Parallel & Distributed Processing, Workshops and Phd Forum}, 
  title={Power Measurement and Concurrency Throttling for Energy Reduction in OpenMP Programs}, 
  year={2013},
  volume={},
  number={},
  pages={884-891},
  abstract={Understanding on-node application power and performance characteristics is critical to the push toward exascale computing. In this paper, we present an analysis of factors that impact both performance and energy usage of OpenMP applications. Using hardware performance counters in the Intel Sandy bridge X86-64 architecture, we measure energy usage and power draw for a variety of OpenMP programs: simple micro-benchmarks, a task parallel benchmark suite, and a hydrodynamics mini-app of a few thousand lines. The evaluation reveals substantial variations in energy usage depending on the algorithm, the compiler, the optimization level, the number of threads, and even the temperature of the chip. Variations of 20% were common and in the extreme were over 2X. In most cases, performance increases and energy usage decreases as more threads are used. However, for programs with sub-linear speedup, minimal energy usage often occurs at a lower thread count than peak performance. Our findings informed the design and implementation of an adaptive run time system that automatically throttles concurrency using data measured on-line from hardware performance counters. Without source code changes or user intervention, the thread scheduler accurately decides when energy can be conserved by limiting the number of active threads. For the target programs, dynamic runtime throttling consistently reduces power and overall energy usage by up to 3%.},
  keywords={},
  doi={10.1109/IPDPSW.2013.15},
  ISSN={},
  month={May},}
@INPROCEEDINGS{6651025,
  author={Kunaseth, Manaschai and Kalia, Rajiv K. and Nakano, Aiichiro and Vashishta, Priya and Richards, David F. and Glosli, James N.},
  booktitle={2013 IEEE International Symposium on Parallel & Distributed Processing, Workshops and Phd Forum}, 
  title={Performance Characteristics of Hardware Transactional Memory for Molecular Dynamics Application on BlueGene/Q: Toward Efficient Multithreading Strategies for Large-Scale Scientific Applications}, 
  year={2013},
  volume={},
  number={},
  pages={1326-1335},
  abstract={We have investigated the performance characteristics of hardware transactional memory (HTM) on the Blue Gene/Q computer in comparison with conventional concurrency control mechanisms, using a molecular dynamics application as an example. Benchmark tests, along with overhead-cost and scalability analysis, quantify relative performance advantages of HTM over other mechanisms. We found that the bookkeeping cost of HTM is high but that the rollback cost is low. We propose transaction fusion and spatially-compact scheduling techniques to reduce the overhead of HTM with minimal programming. A strong scalability benchmark shows that the fused HTM has the shortest runtime among various concurrency control mechanisms without extra memory. Based on the performance characterization, we derive a decision tree in the concurrency-control design space for multithreading application.},
  keywords={},
  doi={10.1109/IPDPSW.2013.29},
  ISSN={},
  month={May},}
@INPROCEEDINGS{6651112,
  author={Meng, Chen and Wang, Long and Cao, Zongyan and Ye, Xianfeng and Feng, Long-Long},
  booktitle={2013 IEEE International Symposium on Parallel & Distributed Processing, Workshops and Phd Forum}, 
  title={Acceleration of a High Order Finite-Difference WENO Scheme for Large-Scale Cosmological Simulations on GPU}, 
  year={2013},
  volume={},
  number={},
  pages={2071-2078},
  abstract={In this work, we present our implementation of a three-dimensional 5th order finite-difference weighted essentially non-oscillatory (WENO) scheme in double precision on CPU/GPU clusters, which targets on large-scale cosmological hydrodynamic flow simulations involving both shocks and complicated smooth solution structures. In the level of MPI parallelization, we subdivided the domain along each of three axial directions. Then on each process, we ported the WENO computation to GPU. This method is memory-bound derived from the calculations of the weights and it becomes a greater challenge for a 3D high order problem in double precision. To make full use of impressive computing power of GPU and avoid its memory limitation, we performed a series of optimizations that are focused on memory accessing mode at all levels. We subjected this code to a number of typical tests for the evaluation of effectiveness and efficiency. Our tests indicate that, in a mono-thread Fortran code reference, the GPU version achieves a 12~19 speed-up and about 19~36 in the computation part. We analyzed the results on both Fermi and Kepler GPUs. We also outlined what is needed to further increase the speed by reducing the time spent on the communications part and other future work.},
  keywords={},
  doi={10.1109/IPDPSW.2013.169},
  ISSN={},
  month={May},}
@INPROCEEDINGS{6644206,
  author={Szomiński, Szymon and Gądek, Konrad and Konarski, Michal and Błaszczyk, Bogna and Anielski, Piotr and Turek, Wojciech},
  booktitle={2013 Federated Conference on Computer Science and Information Systems}, 
  title={Development of a cyber-physical system for mobile robot control using Erlang}, 
  year={2013},
  volume={},
  number={},
  pages={1441-1448},
  abstract={Design of mobile robot control systems is a huge challenge, which require solving issues related to concurrent hardware access and providing high availability. Existing solutions in the domain are based on technologies using low level languages and shared memory concurrency model, which seems unsuitable for the task. In this paper a different approach to the problem of building a cyber-physical system for mobile robots control is presented. It is based on Erlang language and technology, which support lightweight processes, fault tolerance mechanisms and uses message passing concurrency model with built-in inter-process communication. Created system used a new, open-source robotic platform, which had been designed for scientific and educational purposes. Integrated system has been tested in several scenarios, proving flexibility, durability and high performance.},
  keywords={},
  doi={},
  ISSN={},
  month={Sep.},}
@INPROCEEDINGS{6644215,
  author={Böhm, Stanislav and Běhálek, Marek and Meca, Ondřej and Šurkovský, Martin},
  booktitle={2013 Federated Conference on Computer Science and Information Systems}, 
  title={Visual programming of MPI applications: Debugging and performance analysis}, 
  year={2013},
  volume={},
  number={},
  pages={1495-1502},
  abstract={Our research is focused on the simplification of parallel programming for distributed memory systems. Our overall goal is to build a unifying framework for creating, debugging, profiling and verifying parallel applications. The key aspect is a visual model inspired by Colored Petri Nets. In this paper, we will present how to use the visual model for debugging and profiling as well. The presented ideas are integrated into our open source tool Kaira.},
  keywords={},
  doi={},
  ISSN={},
  month={Sep.},}
@INPROCEEDINGS{6656269,
  author={Saissi, Habib and Bokor, Péter and Muftuoglu, Can Arda and Suri, Neeraj and Serafini, Marco},
  booktitle={2013 IEEE 32nd International Symposium on Reliable Distributed Systems}, 
  title={Efficient Verification of Distributed Protocols Using Stateful Model Checking}, 
  year={2013},
  volume={},
  number={},
  pages={133-142},
  abstract={This paper presents efficient model checking of distributed software. Key to the achieved efficiency is a novel stateful model checking strategy that is based on the decomposition of states into a relevant and an auxiliary part. We formally show this strategy to be sound, complete, and terminating for general finite-state systems. As a case study, we implement the proposed strategy within Basset/MP-Basset, a model checker for message-passing Java programs. Our evaluation with actual deployed fault-tolerant message-passing protocols shows that the proposed stateful optimization is able to reduce model checking time and memory by up to 69% compared to the naive stateful search, and 39% compared to partial-order reduction.},
  keywords={},
  doi={10.1109/SRDS.2013.22},
  ISSN={1060-9857},
  month={Sep.},}
@INPROCEEDINGS{6666874,
  author={Weng, Yang and Fardanesh, Bruce and Ilić, Marija D. and Negi, Rohit},
  booktitle={2013 North American Power Symposium (NAPS)}, 
  title={Novel approaches using semidefinite programming method for power systems state estimation}, 
  year={2013},
  volume={},
  number={},
  pages={1-6},
  abstract={This paper is motivated by the open questions concerning effective nonlinear state estimation (SE) approaches. The basic difficulty comes from the highly nonlinear functions relating measurements and voltages defined by the AC power flow models. Today's AC power flow SE approach is, therefore, a highly non-convex problem and, as such, it is prone to convergence problems and sub-optimal solutions. We describe how two recently proposed methods overcome this problem by following a common idea of mapping the voltage space into higher dimensional space in which the problem can be posed as a convex optimization problem because the measurements can be expressed as linear functions in a higher-dimensional space. It is intriguing that the semi-definite programming (SDP)-based SE approach and the direct non-iterative method-based SE approach both employ a similar mapping of voltages into higher dimensional matrix W of voltage products at neighboring buses as new states. These recently discovered similarities are described in some detail by posing both approaches without loss of generality on a three bus system. The two methods differ significantly in their approaches to re-computing actual voltages once the voltage products are estimated. The SDP-based SE approach utilizes the structure of the mapping and states a sufficient rank one condition for matrix W to ensure the unique reconstruction of the actual bus voltages. Both methods are computationally demanding. To overcome this inherent problem, an approximate distributed SDP-based SE algorithm is proposed by performing: 1) a decomposition of the large power grid networks into much smaller clusters where extensive information exchange is not needed; and 2) by performing a Lagrangian dual decomposition-based computation and message-passing within each cluster. The accuracy of the SDP-based distributed algorithm is illustrated by comparing the results to those obtained using the SDP-based SE estimator. Advantages of the SDP-based methods when compared to today's AC power flow based SE are illustrated by showing numerical problems experienced when using the IEEE test systems.},
  keywords={},
  doi={10.1109/NAPS.2013.6666874},
  ISSN={},
  month={Sep.},}
@INPROCEEDINGS{6674477,
  author={Beermann, Moritz and Monró, Enrique and Schmalen, Laurent and Vary, Peter},
  booktitle={SiPS 2013 Proceedings}, 
  title={High speed decoding of non-binary irregular LDPC codes using GPUs}, 
  year={2013},
  volume={},
  number={},
  pages={36-41},
  abstract={Low-Density Parity-Check (LDPC) codes are very powerful channel coding schemes with a broad range of applications. The existence of low complexity (i.e., linear time) iterative message passing decoders with close to optimum error correction performance is one of the main strengths of LDPC codes. It has been shown that the performance of these decoders can be further enhanced if the LDPC codes are extended to higher order Galois fields, yielding so called non-binary LDPC codes. However, this performance gain comes at the cost of rapidly increasing decoding complexity. To deal with this increased complexity, we present an efficient implementation of a signed-log domain FFT decoder for non-binary irregular LDPC codes that exploits the inherent massive parallelization capabilities of message passing decoders. We employ Nvidia's Compute Unified Device Architecture (CUDA) to incorporate the available processing power of state-of-the-art Graphics Processing Units (GPU s).},
  keywords={},
  doi={10.1109/SiPS.2013.6674477},
  ISSN={2162-3570},
  month={Oct},}
@INPROCEEDINGS{6680828,
  author={Boudguiga, Aymen and Olivereau, Alexis and Oualha, Nouha},
  booktitle={2013 12th IEEE International Conference on Trust, Security and Privacy in Computing and Communications}, 
  title={Server Assisted Key Establishment for WSN: A MIKEY-Ticket Approach}, 
  year={2013},
  volume={},
  number={},
  pages={94-101},
  abstract={MIKEY-Ticket specifies new modes for the Multimedia Internet KEYing (MIKEY) protocol. It answers situations where the network contains a trusted third party (one or many trusted key management servers). Two of MIKEY-Ticket modes correspond to Kerberos and Otway--Rees key distribution protocols. Meanwhile, the general MIKEY--Ticket mode is a new key distribution scheme relying on six messages which are exchanged between the node initiating the protocol (Initiator), the Key Management Server (KMS) and the responding node (Responder). This general mode suffers from a risk of a Denial of Service (DoS) inherited from the protocol design. In this work, we first propose a new MIKEY--Ticket mode that solves the risk of DoS during the key establishment between the Initiator and the Responder. The security of our solution is evaluated with ProVerif, a protocol verification tool. Then, in the second part of the paper, we describe the application of our protocol to sensors in a Wireless Sensor Network (WSN).},
  keywords={},
  doi={10.1109/TrustCom.2013.16},
  ISSN={2324-9013},
  month={July},}
@INPROCEEDINGS{6681279,
  author={Herrera, Juan F.R. and Casado, Leocadio G. and Hendrix, Eligius M.T. and Paulavicius, Remigijus and Žilinskas, Julius},
  booktitle={2013 Eighth International Conference on P2P, Parallel, Grid, Cloud and Internet Computing}, 
  title={Dynamic and hierarchical load-balancing techniques applied to parallel branch-and-bound methods}, 
  year={2013},
  volume={},
  number={},
  pages={497-502},
  abstract={Most Lipschitzian Global Optimization algorithms perform an exhaustive search using a branch-and-bound (B&B) scheme. The question is how to run multi-dimensional Lipschitz Global Optimization in parallel, such that the implementation depending on the used platform is efficient. Previous work shows a parallel version developed for multicore nodes with two levels of parallelism: intra-node and inter-node. On intra-node level, one can perform dynamic load balancing by generating threads dynamically. Threads end when they complete their assigned work. The inter-node level carries out a static load balancing using MPI. In general, algorithm design depends on the characteristics of problems to be solved. There are several ways to improve performance of general parallel B&B algorithms. Specifically, we are interested in how to apply them to parallel Lipschitz Global Optimization algorithms. Operations like selecting the next subproblem to be evaluated become critical in parallel B&B schemes. We study Depth and Hybrid (Best-Depth) options as selection criterion. Previous work, using only MPI or OpenMP, discard not only the broadcasting of the best found upper bound of the solution due to its high average cost/performance but also the use of dynamic load balancing. Here we check how broadcasting the upper bound affects the developed MPI-Pthreads algorithm. Additionally, we study how to perform dynamic load balancing at inter-node level. Experimental results show which designs perform better on which type of instances for the used computational architecture.},
  keywords={},
  doi={10.1109/3PGCIC.2013.85},
  ISSN={},
  month={Oct},}
@INPROCEEDINGS{6681311,
  author={Stoja, Sebasijan and Vukmirovic, Srdan and Jelacic, Bojan},
  booktitle={2013 Eighth International Conference on P2P, Parallel, Grid, Cloud and Internet Computing}, 
  title={Publisher/Subscriber Implementation in Cloud Environment}, 
  year={2013},
  volume={},
  number={},
  pages={677-682},
  abstract={In modern-day systems there is a need for a system which allows indirect asynchronous communication during message exchange between clients and servers. This is known as Publisher/Subscriber system. Such system is important for transmitting data in distributed systems. This paper describes Publisher/Subscriber implementation in Microsoft Windows Azure environment for working services in distributed systems. This is useful for the large scale and big data processing because Microsoft Windows Azure is motivated by it. Pub/Sub system is implemented in every service/client in real-time distributed systems, tested with different distributed networks and the results of this type of implementation are shown in this paper.},
  keywords={},
  doi={10.1109/3PGCIC.2013.116},
  ISSN={},
  month={Oct},}
@INPROCEEDINGS{6685310,
  author={Martinez, Martin A. and Yarleque, Manuel A.},
  booktitle={2013 IEEE International Conference on Microwaves, Communications, Antennas and Electronic Systems (COMCAS 2013)}, 
  title={Gossip-based transmission algorithms performance in wireless sensor networks (WSN)}, 
  year={2013},
  volume={},
  number={},
  pages={1-5},
  abstract={Up-to-date, research in WSN has found a stalemate due to issues, such as energy consumption, scalability and terrain adaptation. This has motivated recent studies about algorithms and protocols that can help solving them in a way that consumption is reduced and the device's life span is maximized, as well as a reduction of data loss caused by collisions. To overcome these obstacles, gossip-based transmission techniques have shown some advantages in routing and data distribution. This paper presents simulation results and implementation regarding the efficiency in message transmission for different gossip-based algorithms (flooding, RGA, DRG, RGAM) and how the results in different topologies shows the DRG algorithm supremacy over the rest, since this can reduce up to half the amount of messages transmitted in different networks to complete a certain task. Likewise, an implementation of a short-scale WSN has been made to verify the previous results and see the capabilities that these algorithms exhibit in WSN.},
  keywords={},
  doi={10.1109/COMCAS.2013.6685310},
  ISSN={},
  month={Oct},}
@INPROCEEDINGS{6687443,
  author={Hilbrich, Tobias and Protze, Joachim and Supinski, Bronis R. de and Schulz, Martin and Müller, Matthias S. and Nagel, Wolfgang E.},
  booktitle={2013 42nd International Conference on Parallel Processing}, 
  title={Intralayer Communication for Tree-Based Overlay Networks}, 
  year={2013},
  volume={},
  number={},
  pages={995-1003},
  abstract={While various HPC tools use Tree-Based Overlay Networks (TBONs) to increase their scalability, some use cases do not map well to a tree-based hierarchy. We provide the concept of intralayer communication to improve this situation, where nodes in a specific hierarchy layer may exchange messages directly with each other. This concept targets data preprocessing that allows tool developers to avoid load imbalances in higher hierarchy levels. We implement intralayer communication within the Generic Tools Infrastructure (GTI) that provides TBON services, as well as a high-level abstraction to ease the creation of scalable runtime tools. An extension of GTI's abstractions allows simple and efficient use of intralayer communication. We demonstrate this capability with a runtime message matching tool for MPI's point-to-point communication, which we evaluate in an application study with up to 16,384 processes. Low overheads for two benchmark suites show the applicability of our approach, while a stress test demonstrates close to constant overheads across scales. The stress test measurements demonstrate that intralayer communication reduces application slowdown by two orders of magnitude at 2,048 processes, compared to a previous TBON-based implementation.},
  keywords={},
  doi={10.1109/ICPP.2013.118},
  ISSN={2332-5690},
  month={Oct},}
@INPROCEEDINGS{6687439,
  author={Engelmann, Christian and Naughton, Thomas},
  booktitle={2013 42nd International Conference on Parallel Processing}, 
  title={Toward a Performance/Resilience Tool for Hardware/Software Co-design of High-Performance Computing Systems}, 
  year={2013},
  volume={},
  number={},
  pages={960-969},
  abstract={xSim is a simulation-based performance investigation toolkit that permits running high-performance computing (HPC) applications in a controlled environment with millions of concurrent execution threads, while observing application performance in a simulated extreme-scale system for hardware/software co-design. The presented work details newly developed features for xSim that permit the injection of MPI process failures, the propagation/detection/notification of such failures within the simulation, and their handling using application-level checkpoint/restart. These new capabilities enable the observation of application behavior and performance under failure within a simulated future-generation HPC system using the most common fault handling technique.},
  keywords={},
  doi={10.1109/ICPP.2013.114},
  ISSN={2332-5690},
  month={Oct},}
@INPROCEEDINGS{6687401,
  author={Haque, Md. Ziaul and Yi, Qing and Dinan, James and Balaji, Pavan},
  booktitle={2013 42nd International Conference on Parallel Processing}, 
  title={Enhancing Performance Portability of MPI Applications through Annotation-Based Transformations}, 
  year={2013},
  volume={},
  number={},
  pages={631-640},
  abstract={MPI is the de facto standard for portable parallel programming on high-end systems. However, while the MPI standard provides functional portability, it does not provide sufficient performance portability across platforms. We present a framework that enables users to provide hints about communication patterns used within MPI applications. These annotations are then used by an automated program transformation system to leverage different MPI operations that better match each system's capabilities. Our framework currently supports three automated transformations: coalescing of operations in MPI one-sided communications, transformation of blocking communications to nonblocking, which enables communication-computation overlap, and selection of the appropriate communication operators based on the cache-coherence support of the underlying platform. We use our annotation-based approach to optimize several benchmark kernels, and we demonstrate that the framework is effective at automatically improving performance portability for MPI applications.},
  keywords={},
  doi={10.1109/ICPP.2013.77},
  ISSN={2332-5690},
  month={Oct},}
@INPROCEEDINGS{6691616,
  author={Weidner, Martin and Dees, Jonathan and Sanders, Peter},
  booktitle={2013 IEEE International Conference on Big Data}, 
  title={Fast OLAP query execution in main memory on large data in a cluster}, 
  year={2013},
  volume={},
  number={},
  pages={518-524},
  abstract={Main memory column-stores have proven to be efficient for processing analytical queries. Still, there has been little work in the context of clusters. Using only a single machine poses several restrictions: Processing power and data volume are bounded to the number of cores and main memory fitting on one tightly coupled system. To enable the processing of larger data sets, switching to a cluster becomes necessary. In this work, we explore techniques for efficient execution of analytical SQL queries on large amounts of data in a parallel database cluster while making maximal use of the available hardware. This includes precompiled query plans for efficient CPU utilization, full parallelization on single nodes and across the cluster, and efficient inter-node communication. We implement all features in a prototype for running a subset of TPC-H benchmark queries. We evaluate our implementation in a 128 node cluster running TPC-H queries with 30000 gigabyte of uncompressed data. Currently, there are no official cluster results for more than 10000 gigabyte of data, where we achieve up to one to two orders of magnitudes better performance than the current record holder.},
  keywords={},
  doi={10.1109/BigData.2013.6691616},
  ISSN={},
  month={Oct},}
@INPROCEEDINGS{6691614,
  author={Yin, Jiangling and Foran, Andrew and Wang, Jun},
  booktitle={2013 IEEE International Conference on Big Data}, 
  title={DL-MPI: Enabling data locality computation for MPI-based data-intensive applications}, 
  year={2013},
  volume={},
  number={},
  pages={506-511},
  abstract={Currently, most scientific applications based on MPI adopt a compute-centric architecture. Needed data is accessed by MPI processes running on different nodes through a shared file system. Unfortunately, the explosive growth of scientific data undermines the high performance of MPI-based applications, especially in the execution environment of commodity clusters. In this paper, we present a novel approach to enable data locality computation for MPI-based data-intensive applications and refer to it as DL-MPI. DL-MPI allows MPI-based programs to obtain data distribution information for compute nodes through a novel data locality API. In addition, the problem of allocating data processing tasks to parallel processes is formulated as an integer optimization problem with the objectives of achieving data locality computation and optimal parallel execution time. For heterogeneous runtime environments, we propose a scheduling algorithm based on probability to dynamically schedule tasks to processes by evaluating the unprocessed local data and the computing ability of each compute node. We demonstrate the functionality of our methods through the implementation of scientific data processing programs as well as the incorporation of DL-MPI with existing HPC applications.},
  keywords={},
  doi={10.1109/BigData.2013.6691614},
  ISSN={},
  month={Oct},}
@INPROCEEDINGS{6691566,
  author={Araki, Takuya and Narita, Kazuyo and Tamano, Hiroshi},
  booktitle={2013 IEEE International Conference on Big Data}, 
  title={Feliss: Flexible distributed computing framework with light-weight checkpointing}, 
  year={2013},
  volume={},
  number={},
  pages={143-149},
  abstract={Current distributed computing frameworks, such as MapReduce and Spark, allow programmers to use only limited operations defined by the framework. Because of this restriction, algorithms that do not fit with the framework cannot be efficiently expressed. This restriction arose from the need of fault-tolerance. That is, these frameworks recover lost data by re-computing them from available data when a fault occurs. To ensure this mechanism works correctly, only operations provided by the system can be used. On the other hand, there is another fault-tolerance method called checkpointing. Since it achieves fault-tolerance by saving memory contents, there is no such limitation to operations. However, the cost of saving a memory image is high. To overcome this trade-off, we propose a light-weight checkpointing method called continuation-based checkpointing, which enables low overhead fault-tolerance without any restriction. It saves only the information that is necessary for restarting, which significantly reduces the cost of checkpointing. We implemented a distributed computing framework called Feliss by using our continuation-based checkpointing method, which includes an improved MapReduce without the above restriction and a message passing interface (MPI) subset. We evaluated Feliss with various applications and showed that order-of-magnitude speedup can be attained with applications that cannot be expressed efficiently with current frameworks.},
  keywords={},
  doi={10.1109/BigData.2013.6691566},
  ISSN={},
  month={Oct},}
@INPROCEEDINGS{6691237,
  author={El-Khatib, Rafah and Macris, Nicolas and Urbanke, Ruediger},
  booktitle={2013 IEEE Information Theory Workshop (ITW)}, 
  title={Displacement convexity — A useful framework for the study of spatially coupled codes}, 
  year={2013},
  volume={},
  number={},
  pages={1-5},
  abstract={Spatial coupling has recently emerged as a powerful paradigm to construct graphical models that work well under low-complexity message-passing algorithms. Although much progress has been made on the analysis of spatially coupled models under message passing, there is still room for improvement, both in terms of simplifying existing proofs as well as in terms of proving additional properties. We introduce one further tool for the analysis, namely the concept of displacement convexity. This concept plays a crucial role in the theory of optimal transport and it is also well suited for the analysis of spatially coupled systems. In cases where the concept applies, displacement convexity allows functionals of distributions which are not convex to be represented in an alternative form, so that they are convex with respect to the new parametrization. The alternative convex structure can then often be used to prove the uniqueness of the minimizer of this functional. As a proof of concept we consider spatially coupled (l, r)-regular Gallager ensembles when transmission takes place over the binary erasure channel. In particular, we first show the existence of an optimal profile which minimizes the potential functional governing this system. This profile characterizes the “decoding wave” of the spatially coupled system. We then show that the potential function of the coupled system is displacement convex. Due to some translational degrees of freedom the convexity by itself falls short of establishing the uniqueness of the minimizing profile. But as we will discuss it is an important step in this direction.},
  keywords={},
  doi={10.1109/ITW.2013.6691237},
  ISSN={},
  month={Sep.},}
@INPROCEEDINGS{6697093,
  author={Williams, Ryan K. and Gasparri, Andrea and Priolo, Attilio and Sukhatme, Gaurav S.},
  booktitle={2013 IEEE/RSJ International Conference on Intelligent Robots and Systems}, 
  title={Decentralized generic rigidity evaluation in interconnected systems}, 
  year={2013},
  volume={},
  number={},
  pages={5093-5099},
  abstract={In this paper, we consider the problem of evaluating the generic rigidity of an interconnected system in the plane, without a priori knowledge of the network's topological properties. We propose the decentralization of the pebble game algorithm of Jacobs et. al., an O(n2) method that determines the generic rigidity of a planar network. Our decentralization is based on asynchronous inter-agent message-passing and a distributed memory architecture, coupled with consensus-based auctions for electing leaders in the system. We provide analysis of the asynchronous messaging structure and its interaction with leader election, and Monte Carlo simulations demonstrating complexity and correctness. Finally, a novel rigidity evaluation and control scenario in the accompanying media illustrates the applicability of our proposed algorithm.},
  keywords={},
  doi={10.1109/IROS.2013.6697093},
  ISSN={2153-0866},
  month={Nov},}
@INPROCEEDINGS{6693072,
  author={Tasharofi, Samira and Pradel, Michael and Lin, Yu and Johnson, Ralph},
  booktitle={2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)}, 
  title={Bita: Coverage-guided, automatic testing of actor programs}, 
  year={2013},
  volume={},
  number={},
  pages={114-124},
  abstract={Actor programs are concurrent programs where concurrent entities communicate asynchronously by exchanging messages. Testing actor programs is challenging because the order of message receives depends on the non-deterministic scheduler and because exploring all schedules does not scale to large programs. This paper presents Bita, a scalable, automatic approach for testing non-deterministic behavior of actor programs. The key idea is to generate and explore schedules that are likely to reveal concurrency bugs because these schedules increase the schedule coverage. We present three schedule coverage criteria for actor programs, an algorithm to generate feasible schedules that increase coverage, and a technique to force a program to comply with a schedule. Applying Bita to real-world actor programs implemented in Scala reveals eight previously unknown concurrency bugs, of which six have already been fixed by the developers. Furthermore, we show our approach to find bugs 122× faster than random scheduling, on average.},
  keywords={},
  doi={10.1109/ASE.2013.6693072},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{6702586,
  author={Lima, João V.F. and Broquedis, François and Gautier, Thierry and Raffin, Bruno},
  booktitle={2013 25th International Symposium on Computer Architecture and High Performance Computing}, 
  title={Preliminary Experiments with XKaapi on Intel Xeon Phi Coprocessor}, 
  year={2013},
  volume={},
  number={},
  pages={105-112},
  abstract={This paper presents preliminary performance comparisons of parallel applications developed natively for the Intel Xeon Phi accelerator using three different parallel programming environments and their associated runtime systems. We compare Intel OpenMP, Intel CilkPlus and XKaapi together on the same benchmark suite and we provide comparisons between an Intel Xeon Phi coprocessor and a Sandy Bridge Xeon-based machine. Our benchmark suite is composed of three computing kernels: a Fibonacci computation that allows to study the overhead and the scalability of the runtime system, a NQueens application generating irregular and dynamic tasks and a Cholesky factorization algorithm. We also compare the Cholesky factorization with the parallel algorithm provided by the Intel MKL library for Intel Xeon Phi. Performance evaluation shows our XKaapi data-flow parallel programming environment exposes the lowest overhead of all and is highly competitive with native OpenMP and CilkPlus environments on Xeon Phi. Moreover, the efficient handling of data-flow dependencies between tasks makes our XKaapi environment exhibit more parallelism for some applications such as the Cholesky factorization. In that case, we observe substantial gains with up to 180 hardware threads over the state of the art MKL, with a 47% performance increase for 60 hardware threads.},
  keywords={},
  doi={10.1109/SBAC-PAD.2013.28},
  ISSN={1550-6533},
  month={Oct},}
@INPROCEEDINGS{6702597,
  author={Sena, Alexandre C. and Ribeiro, Felipe S. and Rebello, Vinod E.F. and Nascimento, Aline P. and Boeres, Cristina},
  booktitle={2013 25th International Symposium on Computer Architecture and High Performance Computing}, 
  title={Autonomic Malleability in Iterative MPI Applications}, 
  year={2013},
  volume={},
  number={},
  pages={192-199},
  abstract={During their execution, a significant number of applications often sub utilize the capacity of the resources to which they are allocated or require more. Furthermore, with the current scale up trend in server design, effective utilization can only be achieved by applications sharing such resources. Cluster management systems already support static resource partitioning at job submission time and given that application utilization more than often varies during the execution, it will become increasingly more important to permit applications to harness all available spare capacity. This paper investigates the feasibility of malleable evolving versions of applications to improve performance and system efficiency. Extending a previous classification, we show that improvements can be achieved for a real astrophysics application.},
  keywords={},
  doi={10.1109/SBAC-PAD.2013.4},
  ISSN={1550-6533},
  month={Oct},}
@INPROCEEDINGS{6712721,
  author={Arashloo, Shervin Rahimzadeh and Kittler, Josef},
  booktitle={2013 IEEE Sixth International Conference on Biometrics: Theory, Applications and Systems (BTAS)}, 
  title={Efficient processing of MRFs for unconstrained-pose face recognition}, 
  year={2013},
  volume={},
  number={},
  pages={1-8},
  abstract={The paper addresses the problem of pose-invariant recognition of faces via an MRF matching model. Unlike previous costly matching approaches, the proposed algorithm employs effective techniques to reduce the MRF inference time. To this end, processing is done in a parallel fashion on a GPU employing a dual decomposition framework. The optimisation is further accelerated taking a multi-resolution approach based on the Renormalisation Group Theory (RGT) along with efficient methods for message passing and the incremental subgradient approach. For the graph construction, Daisy features are used as node attributes exhibiting high cross-pose invariance, while high discriminatory capability in the classification stage is obtained via multi-scale LBP histograms. The experimental evaluation of the method is performed via extensive tests on the databases of XM2VTS, FERET and LFW in verification, identification and the unseen pair-matching paradigms. The proposed approach achieves state-of-the-art performance in pose-invariant recognition of faces and performs as well or better than the existing methods in the unconstrained settings of the challenging LFW database using a single feature for classification.},
  keywords={},
  doi={10.1109/BTAS.2013.6712721},
  ISSN={},
  month={Sep.},}
@INPROCEEDINGS{6714010,
  author={Meng, Zhaoshi and Wei, Dennis and Hero, Alfred O. and Wiesel, Ami},
  booktitle={2013 5th IEEE International Workshop on Computational Advances in Multi-Sensor Adaptive Processing (CAMSAP)}, 
  title={Marginal likelihoods for distributed estimation of graphical model parameters}, 
  year={2013},
  volume={},
  number={},
  pages={73-76},
  abstract={This paper considers the estimation of graphical model parameters with distributed data collection and computation. We first discuss the use and limitations of well-known distributed methods for marginal inference in the context of parameter estimation. We then describe an alternative framework for distributed parameter estimation based on maximizing marginal likelihoods. Each node independently estimates local parameters through solving a low-dimensional convex optimization with data collected from its local neighborhood. The local estimates are then combined into a global estimate without iterative message-passing. We provide an asymptotic analysis of the proposed estimator, deriving in particular its rate of convergence. Numerical experiments validate the rate of convergence and demonstrate performance equivalent to the centralized maximum likelihood estimator.},
  keywords={},
  doi={10.1109/CAMSAP.2013.6714010},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{6717598,
  author={Yan, Ying and Zhao, Xunwang and Zhang, Yu and Liang, Changhong and Mo, Jingyan and Ma, Zhewang},
  booktitle={2013 Proceedings of the International Symposium on Antennas & Propagation}, 
  title={Parallel computation of complex antennas around the coated object using hybrid higher-order MoM and PO technique}, 
  year={2013},
  volume={02},
  number={},
  pages={791-794},
  abstract={This paper presents a novel hybrid technique for analyzing complex antennas around the coated object, which is termed the iterative vector fields with Physical Optics (PO). A closed box is used to enclose the antenna and then the complex field vector components on the box' surfaces can be obtained using Huygens principle. The equivalent electromagnetic currents on Huygens surface are computed by Higher-order Method of Moments (HOB-MoM) and the fields scattered from the coated platform are calculated by PO method. Moreover, the parallel technique based on Message Passing Interface (MPI) and Scalable Linear Algebra Package (ScaLAPACK) is employed to accelerate the computation, and good load balance and parallel efficiency are obtained under the proposed parallel scheme. Finally, some numerical examples are presented to validate and to show the effectiveness of the proposed method on solving the practical engineering problems.},
  keywords={},
  doi={},
  ISSN={},
  month={Oct},}
@INPROCEEDINGS{6723120,
  author={Luo, Xueping and Bai, Jinping and Chen, Yunping and Tong, Ling},
  booktitle={2013 IEEE International Geoscience and Remote Sensing Symposium - IGARSS}, 
  title={Parallel implementation of MPI-based SAR image soil moisture inversion}, 
  year={2013},
  volume={},
  number={},
  pages={1692-1695},
  abstract={Radar image has now becoming more and more widely used in the ecological environment monitoring. The soil moisture inversion for SAR(Synthetic Aperture Radar) image has important significance in the field of agriculture and environment. However, as the SAR image data is large scale and the algorithm of soil moisture inversion is complicated, it's a time-consuming work for SAR image processing, so how to get fast processing for SAR images has now become an important problem. Therefore, the this paper use MPI(Message Passing Interface) cluster system accelerate the processing speed of algorithm, thus speeding up the SAR image processing and improving the efficiency of the use of computers. This paper designed and implemented two cluster computing modes that are master-slave mode and peer-to-peer mode. At last, we takes an experimental testing, results show that relative to master-slave mode, peer-to-peer mode can get a better acceleration effect, greatly improves the processing speed.},
  keywords={},
  doi={10.1109/IGARSS.2013.6723120},
  ISSN={2153-7003},
  month={July},}
@INPROCEEDINGS{6730754,
  author={Huang, Dachuan and Zhang, Xuechen and Shi, Wei and Zheng, Mai and Jiang, Song and Qin, Feng},
  booktitle={2013 IEEE 21st International Symposium on Modelling, Analysis and Simulation of Computer and Telecommunication Systems}, 
  title={LiU: Hiding Disk Access Latency for HPC Applications with a New SSD-Enabled Data Layout}, 
  year={2013},
  volume={},
  number={},
  pages={111-120},
  abstract={Unlike in the consumer electronics and personal computing areas, in the HPC environment hard disks can hardly be replaced by SSDs. The reasons include hard disk's large capacity, very low price, and decent peak throughput. However, when latency dominates the I/O performance (e.g., when accessing random data), the hard disk's performance can be compromised. If the issue of high latency could be effectively solved, the HPC community would enjoy a large, affordable and fast storage without having to replace disks completely with expensive SSDs. In this paper, we propose an almost latency-free hard-disk dominated storage system called LiU for HPC. The key technique is leveraging limited amount of SSD storage for its low-latency access, and changing data layout in a hybrid storage hierarchy with low-latency SSD at the top and high-latency hard disk at the bottom. If a segment of data would be randomly accessed, we lift its top part (the head) up in the hierarchy to the SSD and leave the remaining part (the body) untouched on the disk. As a result, the latency of accessing this whole segment can be removed because access latency of the body can be hidden by the access time of the head on the SSD. Combined with the effect of prefetching a large segment, LiU (Lift it Up) can effectively remove disk access latency so disk's high peak throughput can now be fully exploited for data-intensive HPC applications. We have implemented a prototype of LiU in the PVFS parallel file system and evaluated it with representative MPI-IO micro benchmarks, including mpi-io-test, mpi-tile-io, and ior-mpi-io, and one macro-benchmark BTIO. Our experimental results show that LiU can effectively improve the I/O performance for HPC applications, with the throughput improvement ratio up to 5.8. Furthermore, LiU can bring much more benefits to sequential-I/O MPI applications when the applications are interfered by other workloads. For example, LiU improves the I/O throughput of mpi-io-test, which is under interference, by 1.1-3.4 times, while improving the same workload without interference by 15%.},
  keywords={},
  doi={10.1109/MASCOTS.2013.19},
  ISSN={2375-0227},
  month={Aug},}
@INPROCEEDINGS{6746356,
  author={Wang, Zhurong and Yu, Changqing and Hei, Xinhong and Zhang, Bin},
  booktitle={2013 Ninth International Conference on Computational Intelligence and Security}, 
  title={A Parallel Genetic Algorithm for Solving the Probabilistic Minimum Spanning Tree Problem}, 
  year={2013},
  volume={},
  number={},
  pages={61-65},
  abstract={The probabilistic minimum spanning tree (PMST) problem is NP-complete and is hard to solve. However, it has important theoretical significance and wide application prospect. A parallel genetic algorithm based on coarse-grained model is proposed to solve PMST problem in this paper. Firstly, we discuss several problems of determinant factorization encoding, and develop repairing method for illegal individuals. Secondly, a coarse-grained parallel genetic algorithm, which combines message passing interface (MPI) and genetic algorithm, is designed to solve probabilistic minimum spanning tree problems. Finally, the proposed algorithm is used to test several probabilistic minimum spanning tree problems which are generated by the method introduced in the literature. The statistical data of the test results show that the expectation best solution and average best solution obtained by the proposed algorithm are better than those provided in the literature.},
  keywords={},
  doi={10.1109/CIS.2013.20},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{6751250,
  author={Müller, Oliver and Yang, Michael Ying and Rosenhahn, Bodo},
  booktitle={2013 IEEE International Conference on Computer Vision}, 
  title={Slice Sampling Particle Belief Propagation}, 
  year={2013},
  volume={},
  number={},
  pages={1129-1136},
  abstract={Inference in continuous label Markov random fields is a challenging task. We use particle belief propagation (PBP) for solving the inference problem in continuous label space. Sampling particles from the belief distribution is typically done by using Metropolis-Hastings (MH) Markov chain Monte Carlo (MCMC) methods which involves sampling from a proposal distribution. This proposal distribution has to be carefully designed depending on the particular model and input data to achieve fast convergence. We propose to avoid dependence on a proposal distribution by introducing a slice sampling based PBP algorithm. The proposed approach shows superior convergence performance on an image denoising toy example. Our findings are validated on a challenging relational 2D feature tracking application.},
  keywords={},
  doi={10.1109/ICCV.2013.144},
  ISSN={2380-7504},
  month={Dec},}
@INPROCEEDINGS{6765500,
  author={Tian, Yuan and Lai, Junjie and Yang, Lei and Qi, Ji and Zhou, Qingguo},
  booktitle={2013 International Joint Conference on Awareness Science and Technology & Ubi-Media Computing (iCAST 2013 & UMEDIA 2013)}, 
  title={A heterogeneous CPU-GPU implementation for discrete elements simulation with multiple GPUs}, 
  year={2013},
  volume={},
  number={},
  pages={547-552},
  abstract={To calculate the large number of particles in discrete elements simulation, a heterogeneous CPU-GPU implementation with multiple GPUs is developed. The implementation is achieved by combining two different parallel programming languages so that it can be assigned to a CPU-GPU cluster. The communication between nodes uses Massage Passing Interface (MPI) implementation for dynamic domain decomposition, particles re-mapping and data copying of overlapping areas. Other works are assigned to GPUs to obtain a high computational speed. The results of strong and weak scalability tests are analyzed for different number of GPUs. Last, the LAMMPS is used as CPU platform to compare with multi-GPU application for reflecting the superiority of using heterogeneous implementation.},
  keywords={},
  doi={10.1109/ICAwST.2013.6765500},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{6786802,
  author={French, Tim and McCabe-Dansted, John and Reynolds, Mark},
  booktitle={2013 20th International Symposium on Temporal Representation and Reasoning}, 
  title={Complexity of Model Checking over General Linear Time}, 
  year={2013},
  volume={},
  number={},
  pages={107-114},
  abstract={Temporal logics over general linear time allow us to capture continuous properties in applications such as distributed systems, natural language, message passing and A.I. modelling of human reasoning. Linear time structures, however, can exhibit a wide range of behaviours that are hard to reason with, or even describe finitely. Recently, a formal language of Model Expressions has been proposed to allow the convenient finite description of an adequately representative range of these generally infinite structures. Given a model described in this Model Expression language and a temporal logic formula, a model checking algorithm decides whether the formula is satisfied at some time in the model. Tools based on such algorithms would support a wide variety of tasks such as verification and counter-example investigation. A previous paper gave an exponential space algorithm for the problem of model checking Until/Since temporal formulas over linear time Model Expressions. Here we prove that the problem is actually PSPACE-complete. We present a new PSPACE algorithm and we show PSPACE-hardness by a reduction from quantified boolean formulas.},
  keywords={},
  doi={10.1109/TIME.2013.21},
  ISSN={2332-6468},
  month={Sep.},}
@INPROCEEDINGS{6808176,
  author={Buettner, David and Acquaviva, Jean-Thomas and Weidendorfer, Josef},
  booktitle={2013 International Conference on Parallel and Distributed Systems}, 
  title={Real Asynchronous MPI Communication in Hybrid Codes through OpenMP Communication Tasks}, 
  year={2013},
  volume={},
  number={},
  pages={208-215},
  abstract={With the number of cores growing faster than memory per node, hybrid programming models (mixing message passing with shared memory paradigms) become a requirement for efficient use of HPC systems. For this scenario, achieving efficient communication is challenging. This is true even when using asynchronous communication, as most MPI implementations can only advance communication inside library calls. In this paper we propose to move communication into a new type of OpenMP task, which gets scheduled as part of the regular OpenMP work-pool. We show for compute intensive iterative stencil algorithms, that this provides real asynchronous communication. Without complicating the programming interface, our results show an excellent performance independent of the communication to computation ratio.},
  keywords={},
  doi={10.1109/ICPADS.2013.39},
  ISSN={1521-9097},
  month={Dec},}
@INPROCEEDINGS{6808175,
  author={Zhao, Xin and Balaji, Pavan and Gropp, William and Thakur, Rajeev},
  booktitle={2013 International Conference on Parallel and Distributed Systems}, 
  title={MPI-Interoperable Generalized Active Messages}, 
  year={2013},
  volume={},
  number={},
  pages={200-207},
  abstract={Data-intensive applications have become increasingly important in recent years, yet traditional data movement approaches for scientific computation are not well suited for such applications. The Active Message (AM) model is an alternative communication paradigm that is better suited for such applications by allowing computation to be dynamically moved closer to data. Given the wide usage of MPI in scientific computing, enabling an MPI-interoperable AM paradigm would allow traditional applications to incrementally start utilizing AMs in portions of their applications, thus eliminating the programming effort of rewriting entire applications. In our previous work, we extended the MPI ACCUMULATE and MPI GET ACCUMULATE operations in the MPI standard to support AMs. However, the semantics of accumulate-style AMs are fundamentally restricted by the semantics of MPI ACCUMULATE and MPI GET ACCUMULATE, which were not designed to support the AM model. In this paper, we present a new generalized framework for MPI-interoperable AMs that can alleviate those restrictions, thus providing a richer semantics to accommodate a wide variety of application computational patterns. Together with a new API, we present a detailed description of the correctness semantics of this functionality and a reference implementation that demonstrates how various API choices affect the flexibility provided to the MPI implementation and consequently its performance.},
  keywords={},
  doi={10.1109/ICPADS.2013.38},
  ISSN={1521-9097},
  month={Dec},}
@INPROCEEDINGS{6808174,
  author={Suo, Guang and Lu, Yutong and Liao, Xiangke and Xie, Min and Cao, Hongjia},
  booktitle={2013 International Conference on Parallel and Distributed Systems}, 
  title={NR-MPI: A Non-stop and Fault Resilient MPI}, 
  year={2013},
  volume={},
  number={},
  pages={190-199},
  abstract={Fault resilience has became a major issue for HPC systems, in particular in the perspective of future E-scale systems, which will consist of millions of CPU cores and other components. Fault tolerant MPI was proposed to offer support of software level fault tolerance approaches. However, the widely used MPI implementations, such as MPICH and Mvapich2, provide limited support for fault tolerance. This paper proposes NR-MPI, a Non-stop and Fault Resilient MPI. NR-MPI implements the semantics of FT-MPI based on MPICH. Specifically, this paper focuses on failure detection in MPI library, online failure recovery of communicators for multiple failures, friendly programming interface extending for NR-MPI. Furthermore, to support failure recovery of applications, NR-MPI implements data backup and restore interfaces based on double in-memory checkpoint/restart. We conduct experiments with NPB benchmarks on TH-1A supercomputer. Experimental results show that NR-MPI based fault tolerant programs can recover from failures online without restarting, and the overhead is small even for applications with tens of thousands of cores.},
  keywords={},
  doi={10.1109/ICPADS.2013.37},
  ISSN={1521-9097},
  month={Dec},}
@INPROCEEDINGS{6810665,
  author={Nieman, Karl F. and Nassar, Marcel and Lin, Jing and Evans, Brian L.},
  booktitle={2013 Asilomar Conference on Signals, Systems and Computers}, 
  title={FPGA implementation of a message-passing OFDM receiver for impulsive noise channels}, 
  year={2013},
  volume={},
  number={},
  pages={2041-2045},
  abstract={Conventional orthogonal frequency division multiplexing (OFDM) communication systems are typically designed assuming additive white Gaussian noise and interference statistics. However, in many applications, such as Wi-Fi and powerline communications (PLC), impulsive statistics are often observed. Impulsive noise can degrade the signal-to-noise ratio (SNR) of all subcarriers and impair communication performance. In this work, we design and implement a real-time OFDM receiver with approximate message passing (AMP) to estimate and mitigate impulsive noise. The goal is to meet throughput and latency requirements while guaranteeing improved communication performance in impulsive noise. Our contributions include (i) modeling functional parallelism in an AMP OFDM receiver in synchronous dataflow, (ii) converting an AMP OFDM PLC receiver to using only fixed-point data and arithmetic, and (iii) mapping the receiver in fixed-point onto a Field Programmable Gate Array (FPGA) target using a high-level graphical synthesis tool. Our FPGA OFDM transceiver testbed achieves full streaming throughput at G3-PLC rates and recovers up to 8 dB SNR of impulsive noise over a wide SNR range.},
  keywords={},
  doi={10.1109/ACSSC.2013.6810665},
  ISSN={1058-6393},
  month={Nov},}
@INPROCEEDINGS{6811839,
  author={FangFa Fu and Liang Wang and Yu Lu and Jinxiang Wang},
  booktitle={2013 IEEE 10th International Conference on ASIC}, 
  title={Low overhead task migration mechanism in NoC-based MPSoC}, 
  year={2013},
  volume={},
  number={},
  pages={1-4},
  abstract={Task migration, an effective resource management approach, contributes to an increase of on-chip communication overhead. We propose an MMPI-based task migration mechanism to lower task migration overhead in NoC-based MPSoC. This task migration mechanism depends on MPSoC message passing interface (MMPI), which defines a parallel programming pattern that program is dependent of task mapping. In the migration mechanism, task state information is transferred to another PE. The migration overhead is lowered since the task migration is based on MMPI and task code is not transferred. Furthermore, the task migration mechanism does not require checkpoints to detect migration request. Experimental results show that the migration delay decreases around 28% without transferring task code.},
  keywords={},
  doi={10.1109/ASICON.2013.6811839},
  ISSN={2162-755X},
  month={Oct},}
@INPROCEEDINGS{6818263,
  author={Cui, Shulin and Zhang, Shuqing},
  booktitle={2013 Ninth International Conference on Natural Computation (ICNC)}, 
  title={Parallel processing of topological operations by using a hybrid MPI/OpenMP approach}, 
  year={2013},
  volume={},
  number={},
  pages={1738-1742},
  abstract={The topological analysis of spatial objects is computationally very expensive, and therefore the applicability of existing codes is still limited to small datasets. Parallel computation provides an opportunity to reduce run times. This paper discusses a hybrid MPI/OpenMP approach to exploit two levels of parallelisms in software and hardware to reduce computing time on a PC cluster. The overall task is divided based on record size and then assigned to individual cluster nodes, where the calculation of spatial relations is parallelized using OpenMP. The parallel code is specifically tested with two case studies: Within and Overlap. Significant performance increases are seen in all applications, demonstrating the advantage of the present parallel scheme.},
  keywords={},
  doi={10.1109/ICNC.2013.6818263},
  ISSN={2157-9563},
  month={July},}
@INPROCEEDINGS{6821187,
  author={Jackson, Adrian and Campobasso, M. Sergio},
  booktitle={2013 15th International Symposium on Symbolic and Numeric Algorithms for Scientific Computing}, 
  title={Optimised Hybrid Parallelisation of a CFD Code on Many Core Architectures}, 
  year={2013},
  volume={},
  number={},
  pages={488-495},
  abstract={Reliable aerodynamic and aeroelastic design of wind turbines, aircraft wings and turbomachinery blades increasingly relies on the use of high-fidelity Navier-Stokes Computational Fluid Dynamics codes to predict the strongly nonlinear periodic flows associated with structural vibrations and periodically vary- ing farfield boundary conditions. On a single computer core, the harmonic balance solution of the Navier-Stokes equations has been shown to significantly reduce the analysis runtime with respect to the conventional time-domain approach. The problem size of realistic simulations, however, requires high- performance computing. The Computational Fluid Dynamics COSA code features a novel harmonic balance Navier-Stokes solver which has been previously parallelised using both a pure MPI implementation and a hybrid MPI/OpenMP implementation. This paper presents the recently completed optimisation of both parallelisations. The achieved performance improvements of both parallelisations highlight the effectiveness of the adopted parallel optimisation strategies. Moreover, a comparative analysis of the optimal performance of these two architectures in terms of runtime and power consumption using some of the current common HPC architectures highlights the reduction of both aspects achievable by using the hybrid parallelisation with emerging many-core architectures.},
  keywords={},
  doi={10.1109/SYNASC.2013.70},
  ISSN={},
  month={Sep.},}
@INPROCEEDINGS{6821188,
  author={Jackson, Adrian and Strand, Pär},
  booktitle={2013 15th International Symposium on Symbolic and Numeric Algorithms for Scientific Computing}, 
  title={MDMP: Managed Data Message Passing}, 
  year={2013},
  volume={},
  number={},
  pages={496-502},
  abstract={MDMP is a parallel programming approach designed to provide users with an easy way to add parallelism to programs, optimise scientific simulation algorithms, and providing optimised communications to MPI-based programs without requiring them to be re-written from scratch. MDMP uses directives to allow users to specify what communications should take place in the code, and then implements those communications in an optimal manner using both the information provided by the user and data collected from instrumenting the code and gathering information on the data to be communicated at runtime. In this paper we outline the basic concepts and functionality of MDMP and discuss the performance that can be achieved using our prototype implementation of MDMP a range of benchmark cases.},
  keywords={},
  doi={10.1109/SYNASC.2013.71},
  ISSN={},
  month={Sep.},}
@INPROCEEDINGS{6825336,
  author={Freitas, Allan Edgard Silva and Macêdo, Raimundo José de Araújo},
  booktitle={2013 III Brazilian Symposium on Computing Systems Engineering}, 
  title={Performance Evaluation in Hybrid and Dynamic Distributed Systems}, 
  year={2013},
  volume={},
  number={},
  pages={17-22},
  abstract={Distributed systems can be characterized by processes that communicate with each other by message passing, through communication channels, and may be located at several computers spread over a communication network. These processes and communication channels are usually characterized by synchronous or asynchronous timeliness behavior, according to the characteristics of underlying system (operating system and communication sub-system). Unlike conventional systems, the timeliness characteristics of dynamic and hybrid distributed systems may vary over time, according to the availability of resources and occurrence of failures. Such systems are becoming common today because of the increasing diversity and heterogeneity of computer networks and associated devices. Due their high complexity, these systems are difficult to test or verify. In this paper, we introduce a simulation tool for such environments, where distinct fault models and timeliness properties can be dynamically assigned to processes and communication channels. Such a tool is meant not only for protocol evaluation but also for prototyping, allowing code reuse in real applications. Besides presenting the simulation tool, we show a few experiments that validate the simulator behavior.},
  keywords={},
  doi={10.1109/SBESC.2013.20},
  ISSN={2324-7894},
  month={Dec},}
@INPROCEEDINGS{6831345,
  author={ul Hassan, Najeeb and Pusane, Ali E. and Lentmaier, Michael and Fettweis, Gerhard P. and Costello, Daniel J.},
  booktitle={2013 IEEE Global Communications Conference (GLOBECOM)}, 
  title={Non-uniform windowed decoding schedules for spatially coupled codes}, 
  year={2013},
  volume={},
  number={},
  pages={1862-1867},
  abstract={Low-density parity-check convolutional (LDPCC) codes, also known as spatially coupled LDPC codes, can be decoded using a message passing algorithm. In order to limit decoding latency and complexity, windowed decoding can be applied. Updates within the window can be performed either in parallel or serially. However, simulation results show that uniform updating schedules do not provide the expected reduction in complexity when applied within the window. Hence we propose non-uniform schedules for updating the nodes based on measured improvements in the bit error rate. Nodes within the window that stop showing any improvement are excluded from the update list for the next iteration. This results in a reduction of up to 50% in complexity compared to uniform window schedules.},
  keywords={},
  doi={10.1109/GLOCOM.2013.6831345},
  ISSN={1930-529X},
  month={Dec},}
@INPROCEEDINGS{6831999,
  author={Cha, Kwangho},
  booktitle={2013 IEEE 10th International Conference on High Performance Computing and Communications & 2013 IEEE International Conference on Embedded and Ubiquitous Computing}, 
  title={Performance Evaluation of LAMMPS on Multi-core Systems}, 
  year={2013},
  volume={},
  number={},
  pages={812-819},
  abstract={With the widespread use of multi-core processors, specialized applications requiring parallel processing can be run on general desktops. In this study, we measure and analyze the parallel performance of LAMMPS, a classical well-known molecular dynamics code, on single multi-core systems. In order to check the parallel efficiency on single machines, the various types of simulations with LAMMPS were performed with MPI and OpenMP. Although LAMMPS was run on a single machine, MPI based LAMMPS showed higher performance, because LAMMPS has been designed based on MPI and only some part of LAMMPS was parallelized with OpenMP. The preliminary experiments also showed that the memory sub-system affects the performance of LAMMPS.},
  keywords={},
  doi={10.1109/HPCC.and.EUC.2013.117},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{6832132,
  author={Hamid, Nor Asilah Wati Abdul and Serres, Olivier and Anbar, Ahmad and Hassan, Sazlinah},
  booktitle={2013 IEEE 10th International Conference on High Performance Computing and Communications & 2013 IEEE International Conference on Embedded and Ubiquitous Computing}, 
  title={Performance Pattern of Unified Parallel C on Multi-core Clusters}, 
  year={2013},
  volume={},
  number={},
  pages={1751-1757},
  abstract={The Partitioned Global Address Space (PGAS) model has been widely used in multi-core clusters as an alternative to MPI. Among the widespread use is Unified Parallel C (UPC). Previous research has shown that UPC performance is comparable with MPI, however in certain cases UPC require hand-tuning techniques such as prefetching and privatized pointers-to-shared to improve the performance. In this paper we reviews, evaluate and analyze the performance pattern between UPC Naïve, UPC optimize and MPI on two different multi-core clusters architecture. We focus our study using matrix multiplication as the benchmark and perform our experimental on two distributed memory machine, Cray XE6 with Gemini interconnects and Sun Cluster with Infiniband interconnects. We provide analysis on each core execution time to understand the pattern of communication for both machines. We also demonstrate the gaps between naïve and optimized are depends on the compiler with its associate distributed memory machine. We also observed unnecessary optimization for certain programs related to HPC architecture and compiler.},
  keywords={},
  doi={10.1109/HPCC.and.EUC.2013.250},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{6832099,
  author={Lai, Chenggang and Huang, Miaoqing and Shi, Xuan and You, Haihang},
  booktitle={2013 IEEE 10th International Conference on High Performance Computing and Communications & 2013 IEEE International Conference on Embedded and Ubiquitous Computing}, 
  title={Accelerating Geospatial Applications on Hybrid Architectures}, 
  year={2013},
  volume={},
  number={},
  pages={1545-1552},
  abstract={Accelerators have become critical in the process to develop supercomputers with exascale computing capability. In this work, we examine the potential of two latest acceleration technologies, Nvidia K20 Kepler GPU and Intel Many Integrated Core (MIC) Architecture, for accelerating geospatial applications. We first apply a set of benchmarks under 3 different configurations, i.e, MPI+CPU, MPI+GPU, and MPI+MIC. This set of benchmarks include embarrassingly parallel application, loosely communicating application, and intensely communicating application. It is found that the straightforward MPI implementation on MIC cores can achieve the same amount of performance speedup as hybrid MPI+GPU implementation when the same number of processors are used. Further, we demonstrate the potentials of hardware accelerators for advancing the scientific research using an urban sprawl simulation application. The parallel implementation of the urban sprawl simulation using 16 Tesla M2090 GPUs can realize a 155× speedup compared with the single-node implementation, while achieving a good strong scalability.},
  keywords={},
  doi={10.1109/HPCC.and.EUC.2013.217},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{6877527,
  author={Saini, Subhash and Jin, Haoqiang and Jespersen, Dennis and Feng, Huiyu and Djomehri, Jahed and Arasin, William and Hood, Robert and Mehrotra, Piyush and Biswas, Rupak},
  booktitle={SC '13: Proceedings of the International Conference on High Performance Computing, Networking, Storage and Analysis}, 
  title={An early performance evaluation of many integrated core architecture based sgi rackable computing system}, 
  year={2013},
  volume={},
  number={},
  pages={1-12},
  abstract={Intel recently introduced the Xeon Phi coprocessor based on the Many Integrated Core architecture featuring 60 cores with a peak performance of 1.0 Tflop/s. NASA has deployed a 128-node SGI Rackable system where each node has two Intel Xeon E2670 8-core Sandy Bridge processors along with two Xeon Phi 5110P coprocessors. We have conducted an early performance evaluation of the Xeon Phi. We used microbenchmarks to measure the latency and bandwidth of memory and interconnect, I/O rates, and the performance of OpenMP directives and MPI functions. We also used OpenMP and MPI versions of the NAS Parallel Benchmarks along with two production CFD applications to test four programming modes: offload, processor native, coprocessor native and symmetric (processor plus coprocessor). In this paper we present preliminary results based on our performance evaluation of various aspects of a Phi-based system.},
  keywords={},
  doi={10.1145/2503210.2503272},
  ISSN={2167-4337},
  month={Nov},}

@INPROCEEDINGS{6877449,
  author={Hilbrich, Tobias and de Supinski, Bronis R. and Nagel, Wolfgang E. and Protze, Joachim and Baier, Christel and Müller, Matthias S.},
  booktitle={SC '13: Proceedings of the International Conference on High Performance Computing, Networking, Storage and Analysis}, 
  title={Distributed wait state tracking for runtime MPI deadlock detection}, 
  year={2013},
  volume={},
  number={},
  pages={1-12},
  abstract={The widely used Message Passing Interface (MPI) with its multitude of communication functions is prone to usage errors. Runtime error detection tools aid in the removal of these errors. We develop MUST as one such tool that provides a wide variety of automatic correctness checks. Its correctness checks can be run in a distributed mode, except for its deadlock detection. This limitation applies to a wide range of tools that either use centralized detection algorithms or a timeout approach. In order to provide scalable and distributed deadlock detection with detailed insight into deadlock situations, we propose a model for MPI blocking conditions that we use to formulate a distributed algorithm. This algorithm implements scalable MPI deadlock detection in MUST. Stress tests at up to 4,096 processes demonstrate the scalability of our approach. Finally, overhead results for a complex benchmark suite demonstrate an average runtime increase of 34% at 2,048 processes.},
  keywords={},
  doi={10.1145/2503210.2503237},
  ISSN={2167-4337},
  month={Nov},}
@INPROCEEDINGS{6877441,
  author={Ropars, Thomas and Martsinkevich, Tatiana V. and Guermouche, Amina and Schiper, André and Cappello, Franck},
  booktitle={SC '13: Proceedings of the International Conference on High Performance Computing, Networking, Storage and Analysis}, 
  title={SPBC: Leveraging the characteristics of MPI HPC applications for scalable checkpointing}, 
  year={2013},
  volume={},
  number={},
  pages={1-12},
  abstract={The high failure rate expected for future supercomputers requires the design of new fault tolerant solutions. Most checkpointing protocols are designed to work with any message-passing application but sudder from scalability issues at extreme scale. We take a different approach: We identify a property common to many HPC applications, namely channel-determinism, and introduce a new partial order relation, called always-happens-before relation, between events of such applications. Leveraging these two concepts, we design a protocol that combines an unprecedented set of features. Our protocol called SPBC combines in a hierarchical way coordinated checkpointing and message logging. It is the first protocol that provides failure containment without logging any information reliably apart from process checkpoints, and this, without penalizing recovery performance. Experiments run with a representative set of HPC workloads demonstrate a good performance of our protocol during both, failure-free execution and recovery.},
  keywords={},
  doi={10.1145/2503210.2503271},
  ISSN={2167-4337},
  month={Nov},}
@INPROCEEDINGS{6919874,
  author={Xu, Menglu and Lv, Pin and Wang, Haibo},
  booktitle={2013 Fourth International Conference on Networking and Distributed Computing}, 
  title={Predicate Priority Based Event Matching Algorithm in Publish/Subscribe System}, 
  year={2013},
  volume={},
  number={},
  pages={146-150},
  abstract={The large distributed interactive simulation system which based on the publish/subscribe model has considerable data, it needs to disseminate accurate data to the interested users quickly, so improving the match efficient is a very important method to solve this problem. Based on the study and comparison of current matching algorithm, we have proposed a predicate priority based event matching algorithm(hereinafter referred to as PPEM). Performance analysis and detailed experimentations are carried out to verify the effectiveness of PPEM. When the number of subscriptions is 10000, the average time of matching one event is only 22.6ms and when we change the type of data distribution or increase the number of event attribute, the average matching time of PPEM is almost unchangeable comparing with bucket and multi-dimension algorithms. All the results show that PPEM achieves high matching efficiency and also has good scalability and robustness.},
  keywords={},
  doi={10.1109/ICNDC.2013.38},
  ISSN={2165-5006},
  month={Dec},}
@INPROCEEDINGS{6919876,
  author={Liu, Ronghua and Wei, Jiahua and Zhu, Dejun},
  booktitle={2013 Fourth International Conference on Networking and Distributed Computing}, 
  title={A Parallel JPWSPC Algorithm for Hydrodynamic Simulation of River Network}, 
  year={2013},
  volume={},
  number={},
  pages={155-158},
  abstract={To diminish the hydrodynamic simulation time of complex river network, a parallel computation algorithm based on JPWSPC (joint point water stage prediction and correction) is proposed. In the iteration of solving procedure of PJPWSPC algorithm, computation of each reach can be performed in slave process, and water level prediction and correction of joint point is executed in the master process with the MPI API employed in the communication between master process and slave process. This parallel framework for river network hydrodynamic simulation can be harnessed in the loop network as well as the tributary network. The relation between speed-up ratio and average segment count of river network calculated in single process is Preliminary analyzed and the grouping method of branches for task scheduling is constructed by analyzing the computing process of each reach and communication between master process and slave process. Two hydrodynamic scheme simulation of natural river network is carried out. The estimation method can be employed in the grouping of branched in the hydrodynamic simulation of river network and the multiobjective computing resources allocation in the massive river network hydrodynamic simulation in the cloud computing based framework (HydroMP).},
  keywords={},
  doi={10.1109/ICNDC.2013.31},
  ISSN={2165-5006},
  month={Dec},}
@INPROCEEDINGS{6959949,
  author={Valmiki, Manjunatha and Kurkure, Nisha and Das, Shweta and Dinde, Prashant and Deepu, C.V. and Misra, Goldi and Sinha, Pradeep},
  booktitle={2013 1st International Conference on Artificial Intelligence, Modelling and Simulation}, 
  title={Behavior of MDynaMix on Intel Xeon Phi Coprocessor}, 
  year={2013},
  volume={},
  number={},
  pages={387-392},
  abstract={Over the years, computational science has witnessed exceptional growth, but still lagging in efficient programming to effectively undertake research activities. Today, developments in almost all areas of Science & Technology heavily rely on computational capabilities. The latest TOP500 supercomputing list shows the relevance of computational simulation & modeling using accelerator technologies. Porting, optimization, scaling and tuning of existing High Performance Computing (HPC) Applications on such hybrid architectures is the norm for reaping the benefits of extreme scale computing. This paper gauges the performance of MDynaMix application from Molecular Dynamic domain on Intel Xeon Processor along with Intel Xeon Phi coprocessor. Different test cases were carried out to explore the performance of Intel Xeon Phi cards within the node as well as across the nodes.},
  keywords={},
  doi={10.1109/AIMS.2013.71},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{7005005,
  author={Antonova, Galina M.},
  booktitle={2013 8th EUROSIM Congress on Modelling and Simulation}, 
  title={Simulation of Information Flow on Transport Layer of Open System Interconnection-Model}, 
  year={2013},
  volume={},
  number={},
  pages={567-572},
  abstract={Network protocols on transport layer of Open System Interconnection (OSI) model of data transmission solve very difficult problems for delivery all messages in necessary places at designated time. There are no accurate mathematical methods for searching of solution for different problems of optimization for dynamical network characteristics. Some problems may be successfully solved by means of modeling, simulation optimization and other methods of modern cybernetics. The dynamical character of network causes problem of sufficient traffic capacity of data transmission system and admissible time delay because of variable volume of information flow or variable channel load. Sometimes the quantity of users may be so large, that network operation system may give a refuse and a set of messages may be lost. It is very important task to test network for stability work in case of different kinds of noise both amplitude and a distribution density. The main goal of the paper is consideration of one of the numerous ways for preliminary testing of network work with taking into account its dynamical features.},
  keywords={},
  doi={10.1109/EUROSIM.2013.100},
  ISSN={},
  month={Sep.},}
@ARTICLE{8140854,
  author={Wright, S.A. and Hammond, S.D. and Pennycook, S.J. and Bird, R.F. and Herdman, J.A. and Miller, I. and Vadgama, A. and Bhalerao, A. and Jarvis, S.A.},
  journal={The Computer Journal}, 
  title={Parallel File System Analysis Through Application I/O Tracing}, 
  year={2013},
  volume={56},
  number={2},
  pages={141-155},
  abstract={Input/Output (I/O) operations can represent a significant proportion of the run-time of parallel scientific computing applications. Although there have been several advances in file format libraries, file system design and I/O hardware, a growing divergence exists between the performance of parallel file systems and the compute clusters that they support. In this paper, we document the design and application of the RIOT I/O toolkit (RIOT) being developed at the University of Warwick with our industrial partners at the Atomic Weapons Establishment and Sandia National Laboratories. We use the toolkit to assess the performance of three industry-standard I/O benchmarks on three contrasting supercomputers, ranging from a mid-sized commodity cluster to a large-scale proprietary IBM BlueGene/P system. RIOT provides a powerful framework in which to analyse I/O and parallel file system behaviour—we demonstrate, for example, the large file locking overhead of IBM's General Parallel File System, which can consume nearly 30% of the total write time in the FLASH-IO benchmark. Through I/O trace analysis, we also assess the performance of HDF-5 in its default configuration, identifying a bottleneck created by the use of suboptimal Message Passing Interface hints. Furthermore, we investigate the performance gains attributed to the Parallel Log-structured File System (PLFS) being developed by EMC Corporation and the Los Alamos National Laboratory. Our evaluation of PLFS involves two high-performance computing systems with contrasting I/O backplanes and illustrates the varied improvements to I/O that result from the deployment of PLFS (ranging from up to 25× speed-up in I/O performance on a large I/O installation to 2× speed-up on the much smaller installation at the University of Warwick).},
  keywords={},
  doi={10.1093/comjnl/bxs044},
  ISSN={1460-2067},
  month={Feb},}
@ARTICLE{6470609,
  author={Zhao, Yaxiong and Wu, Jie},
  journal={IEEE Transactions on Parallel and Distributed Systems}, 
  title={The Design and Evaluation of An Information Sharing System for Human Networks}, 
  year={2014},
  volume={25},
  number={3},
  pages={796-805},
  abstract={With fast-growing consumer demands and rapidly-developing mobile technologies, portable mobile devices are becoming a necessity of our daily lives. However, existing mobile devices rely on the wireless infrastructure to access Internet services provided by central application providers. This architecture is inefficient in many situations and also does not utilize abundant interdevice communication opportunities in many scenarios. This paper proposes the human network (HUNET), a network architecture that enables information sharing between mobile devices through direct interdevice communication. We design B-SUB, an interest-driven information sharing system for HUNETs. In B-SUB, content and user interests are described by tags, which are human-readable strings that are designated by users. An experiment is performed to demonstrate the effectiveness of this tag-based content description method. To facilitate efficient data dissemination, we invent the Temporal Counting Bloom filter (TCBF) to encode tags, which also reduces the overhead of content routing. Comprehensive theoretical analyses on the parameter tuning of B-SUB are presented and verify B-SUB's ability to work efficiently under various network conditions. We then extend B-SUB's routing scheme to provide a stronger privacy guarantee. Extensive real-world trace-driven simulations are performed to evaluate the performance of B-SUB, and the results demonstrate its efficiency and usefulness.},
  keywords={},
  doi={10.1109/TPDS.2013.54},
  ISSN={1558-2183},
  month={March},}
@ARTICLE{6600683,
  author={Hendrickx, Julien M.},
  journal={IEEE Transactions on Parallel and Distributed Systems}, 
  title={Views in a Graph: To Which Depth Must Equality Be Checked?}, 
  year={2014},
  volume={25},
  number={7},
  pages={1907-1912},
  abstract={The view of depth k of a node is a tree containing all the walks of length k leaving that node. Views contain all the information that nodes could obtain by exchanging messages with their neighbors. In particular, a value can be computed by a node on a network using a distributed deterministic algorithm if and only if that value only depends on the node's view of the network. Norris has proved that if two nodes have the same view of depth n - 1, they have the same views for all depths. Taking the diameter d into account, we prove a new bound in O(d + d log(n/d)) instead of n - 1 for bidirectional graphs with port numbering, which are natural models in distributed computation. This automatically improves various results relying on Norris's bound. We also provide a bound that is stronger for certain colored graphs and extend our results to graphs containing directed edges.},
  keywords={},
  doi={10.1109/TPDS.2013.232},
  ISSN={1558-2183},
  month={July},}
@ARTICLE{6613989,
  author={Ibrahim, Khaled Z. and Hofmeyr, Steven and Iancu, Costin},
  journal={IEEE Transactions on Parallel and Distributed Systems}, 
  title={The Case for Partitioning Virtual Machines on Multicore Architectures}, 
  year={2014},
  volume={25},
  number={10},
  pages={2683-2696},
  abstract={In this paper we argue that partitioning is required for attaining the best performance of scientific applications when running on virtual machines. Current memory management and I/O handling techniques introduce high overhead when running scientific applications. Using KVM, we quantify this impact on applications written in multiple paradigms: message passing, shared memory and partitioned global address spaces. Our analysis shows that on NUMA systems, current memory translation schemes cannot preserve the locality of access and introduce up to 82 percent slowdown. We discuss the interaction between contemporary OS and VM architectures and argue that partitioning is the best solution to enforce memory locality. Current I/O solutions using one assistant task cannot provide the level of I/O parallelism required by scientific applications and we observe an average 7.2 × application slowdown on a cluster with 16 cores per node. More specialized solutions that implement shared memory by-pass within the communication stack also do not scale well with cores and we observe an average 2.4 × application slowdown. Overall, our results indicate that using partitioning and direct inter-VM shared memory support is enough to provide close to native performance in multicore clusters.},
  keywords={},
  doi={10.1109/TPDS.2013.242},
  ISSN={1558-2183},
  month={Oct},}
@ARTICLE{6675862,
  author={Cushon, Kevin and Hemati, Saied and Leroux, Camille and Mannor, Shie and Gross, Warren J.},
  journal={IEEE Transactions on Signal Processing}, 
  title={High-Throughput Energy-Efficient LDPC Decoders Using Differential Binary Message Passing}, 
  year={2014},
  volume={62},
  number={3},
  pages={619-631},
  abstract={In this paper, we present energy-efficient architectures for decoders of low-density parity check (LDPC) codes using the differential decoding with binary message passing (DD-BMP) algorithm and its modified variant (MDD-BMP). We also propose an improved differential binary (IDB) decoding algorithm. These algorithms offer significant intrinsic advantages in the energy domain: simple computations, low interconnect complexity, and very high throughput, while achieving error correction performance up to within 0.25 dB of the offset min-sum algorithm. We report on fully parallel decoder implementations of (273, 191), (1023, 781), and (4095, 3367) finite geometry-based LDPC codes in 65 nm CMOS. Using the MDD-BMP algorithm, these decoders achieve respective areas of 0.28 mm2, 1.38 mm2, and 15.37 mm2, average throughputs of 37 Gbps, 75 Gbps, and 141 Gbps, and energy efficiencies of 4.9 pJ/bit, 13.2 pJ/bit, and 37.9 pJ/bit with a 1.0 V supply voltage in post-layout simulations. At a reduced supply voltage of 0.8 V, these decoders achieve respective throughputs of 26 Gbps, 54 Gbps, and 94 Gbps, and energy efficiencies of 3.1 pJ/bit, 8.2 pJ/bit, and 23.5 pJ/bit. We also report on a fully parallel implementation of IDB for the (2048, 1723) LDPC code specified in the IEEE 802.3an (10GBASE-T) standard. This decoder achieves an area of 1.44 mm2, average throughput of 172 Gbps, and an energy efficiency of 2.8 pJ/bit with a 1.0 V supply voltage; at 0.8 V, it achieves throughput of 116 Gbps and energy efficiency of 1.7 pJ/bit.},
  keywords={},
  doi={10.1109/TSP.2013.2293116},
  ISSN={1941-0476},
  month={Feb},}
@ARTICLE{6749528,
  author={Brito Llamosas Gomes, Elizabeth and Roberto, Marisa and Sampaio Amarante, Gesil and Tomas Valero Orellana, Esbel},
  journal={IEEE Latin America Transactions}, 
  title={Parallelization of XPDP1 Code for Technology Applications of Plasmas}, 
  year={2014},
  volume={12},
  number={2},
  pages={122-128},
  abstract={This work presents the main steps towards a parallel version of the PIC (Particle In Cell) code XPDP1 (X Plasma Device Planar 1-Dimensional), which uses a Monte Carlo procedure to treat collisions among the particles of different species of neutral and ionized pure gases such as argon, oxygen and others. The graphical interface of XPDP1 has been removed and it was parallelized by means of a hybrid approach, with message-passing for distributed memory (using MPI) and shared memory (using OpenMP). The tests for the efficiency and speedup were carried out on a hybrid homogeneous cluster and the results obtained show speedups of approximately ten for 32 cores on 4 servers, which allows the use of this code on problems which are infeasible with the serial version.},
  keywords={},
  doi={10.1109/TLA.2014.6749528},
  ISSN={1548-0992},
  month={March},}
@ARTICLE{6775335,
  author={Kamilov, Ulugbek S. and Rangan, Sundeep and Fletcher, Alyson K. and Unser, Michael},
  journal={IEEE Transactions on Information Theory}, 
  title={Approximate Message Passing With Consistent Parameter Estimation and Applications to Sparse Learning}, 
  year={2014},
  volume={60},
  number={5},
  pages={2969-2985},
  abstract={We consider the estimation of an independent and identically distributed (i.i.d.) (possibly non-Gaussian) vector x ∈ Rn from measurements y ∈ Rm obtained by a general cascade model consisting of a known linear transform followed by a probabilistic componentwise (possibly nonlinear) measurement channel. A novel method, called adaptive generalized approximate message passing (adaptive GAMP) is presented. It enables the joint learning of the statistics of the prior and measurement channel along with estimation of the unknown vector x. We prove that, for large i.i.d. Gaussian transform matrices, the asymptotic componentwise behavior of the adaptive GAMP is predicted by a simple set of scalar state evolution equations. In addition, we show that the adaptive GAMP yields asymptotically consistent parameter estimates, when a certain maximum-likelihood estimation can be performed in each step. This implies that the algorithm achieves a reconstruction quality equivalent to the oracle algorithm that knows the correct parameter values. Remarkably, this result applies to essentially arbitrary parametrizations of the unknown distributions, including nonlinear and non-Gaussian ones. The adaptive GAMP methodology thus provides a systematic, general and computationally efficient method applicable to a large range of linear-nonlinear models with provable guarantees.},
  keywords={},
  doi={10.1109/TIT.2014.2309005},
  ISSN={1557-9654},
  month={May},}
@ARTICLE{6781619,
  author={Narasimhan, T. Lakshmi and Chockalingam, Ananthanaryanan},
  journal={IEEE Journal of Selected Topics in Signal Processing}, 
  title={Channel Hardening-Exploiting Message Passing (CHEMP) Receiver in Large-Scale MIMO Systems}, 
  year={2014},
  volume={8},
  number={5},
  pages={847-860},
  abstract={In this paper, we propose a multiple-input multiple-output (MIMO) receiver algorithm that exploits channel hardening that occurs in large MIMO channels. Channel hardening refers to the phenomenon where the off-diagonal terms of the HHH matrix become increasingly weaker compared to the diagonal terms as the size of the channel gain matrix H increases. Specifically, we propose a message passing detection (MPD) algorithm which works with the real-valued matched filtered received vector (whose signal term becomes HTHx, where x is the transmitted vector), and uses a Gaussian approximation on the off-diagonal terms of the HTH matrix. We also propose a simple estimation scheme which directly obtains an estimate of HTH (instead of an estimate of H), which is used as an effective channel estimate in the MPD algorithm. We refer to this receiver as the channel hardening-exploiting message passing (CHEMP) receiver. The proposed CHEMP receiver achieves very good performance in large-scale MIMO systems (e.g., in systems with 16 to 128 uplink users and 128 base station antennas). For the considered large MIMO settings, the complexity of the proposed MPD algorithm is almost the same as or less than that of the minimum mean square error (MMSE) detection. This is because the MPD algorithm does not need a matrix inversion. It also achieves a significantly better performance compared to MMSE and other message passing detection algorithms using MMSE estimate of H. Further, we design optimized irregular low density parity check (LDPC) codes specific to the considered large MIMO channel and the CHEMP receiver through EXIT chart matching. The LDPC codes thus obtained achieve improved coded bit error rate performance compared to off-the-shelf irregular LDPC codes.},
  keywords={},
  doi={10.1109/JSTSP.2014.2314213},
  ISSN={1941-0484},
  month={Oct},}
@ARTICLE{6783978,
  author={Cheng, Chung-Chao and Yang, Jeng-Da and Lee, Huang-Chang and Yang, Chia-Hsiang and Ueng, Yeong-Luh},
  journal={IEEE Transactions on Circuits and Systems I: Regular Papers}, 
  title={A Fully Parallel LDPC Decoder Architecture Using Probabilistic Min-Sum Algorithm for High-Throughput Applications}, 
  year={2014},
  volume={61},
  number={9},
  pages={2738-2746},
  abstract={This paper presents a normalized probabilistic min-sum algorithm for low-density parity-check (LDPC) codes, where a probabilistic second minimum value, instead of the true second minimum value, is used to facilitate fully parallel decoder realization. The comparators in each check-node unit (CNU) are connected through an interconnect network based on a mix of tree and butterfly networks such that the routing and message passing between the variable-node units (VNUs) and CNUs can be efficiently realized. In order to further reduce the hardware complexity, the normalization operation is realized in the VNU rather than in the CNU. An early termination scheme is proposed in order to prevent unnecessary energy dissipation for both low and high signal-to-noise-ratio regions. The proposed techniques are demonstrated by implementing a (2048, 1723) LDPC decoder using a 90 nm CMOS process. Post-layout simulation results show that the decoder supports a throughput of 45.42 Gbps at 199.6 MHz , achieving the highest throughput and throughput-to-area ratio among comparable works based on a similar or better error performance.},
  keywords={},
  doi={10.1109/TCSI.2014.2312479},
  ISSN={1558-0806},
  month={Sep.},}
@INPROCEEDINGS{6787279,
  author={Tsujita, Yuichi and Yoshinaga, Kazumi and Hori, Atsushi and Sato, Mikiko and Namiki, Mitaro and Ishikawa, Yutaka},
  booktitle={2014 22nd Euromicro International Conference on Parallel, Distributed, and Network-Based Processing}, 
  title={Multithreaded Two-Phase I/O: Improving Collective MPI-IO Performance on a Lustre File System}, 
  year={2014},
  volume={},
  number={},
  pages={232-235},
  abstract={ROMIO, a representative MPI-IO implementation, has been widely used in recent large-scale parallel computations. The two-phase I/O optimization scheme of ROMIO improves I/O performance for non-contiguous access patterns, however, this scheme still has room to improve performance to make it suitable for recent data-intensive computing. We propose overlapping data exchange operations with file I/O operations by using a multithreaded scheme to achieve further I/O throughput improvement. We show up to 60% improvement by the multithreaded two-phase I/O relative to the original two-phase I/O in performance evaluation of collective write operations on a Lustre file system of a Linux PC cluster.},
  keywords={},
  doi={10.1109/PDP.2014.46},
  ISSN={2377-5750},
  month={Feb},}
@INPROCEEDINGS{6787248,
  author={Davtyan, Seda and Prisco, Roberto De and Georgiou, Chryssis and Shvartsman, Alexander A.},
  booktitle={2014 22nd Euromicro International Conference on Parallel, Distributed, and Network-Based Processing}, 
  title={Coordinated Cooperative Work Using Undependable Processors with Unreliable Broadcast}, 
  year={2014},
  volume={},
  number={},
  pages={17-26},
  abstract={With the end of Moore's Law in sight, parallelism became the main means for speeding up computationally intensive applications, especially in the cases where large collections of tasks need to be performed. Network supercomputing -- taking advantage of very large numbers of computers in a distributed environment is an effective approach to massive parallelism that harnesses the processing power inherent in large networked settings. In such settings, processor failures are no longer an exception, but the norm. Any algorithm designed for realistic settings must be able to deal with failures. This paper presents a new message-passing algorithm for distributed cooperative work in synchronous settings where processors may crash, and where any broadcasts performed by crashing processors are unreliable. We specify the algorithm, prove that it is correct, and perform extensive simulations that show that its performance is close to similar algorithms that use reliable broadcast, and that its work compares favorably to the relevant lower bounds.},
  keywords={},
  doi={10.1109/PDP.2014.11},
  ISSN={2377-5750},
  month={Feb},}
@INPROCEEDINGS{6787313,
  author={Baudisch, Daniel and Bai, Yu and Schneider, Klaus},
  booktitle={2014 22nd Euromicro International Conference on Parallel, Distributed, and Network-Based Processing}, 
  title={Reducing the Communication of Message-Passing Systems Synthesized from Synchronous Programs}, 
  year={2014},
  volume={},
  number={},
  pages={444-451},
  abstract={This paper presents a method to translate a given synchronous system to a multithreaded system where process nodes communicate via channels with each other. It is well-known that the reduction of communication has been identified to be a crucial key for efficient utilization of multiprocessor systems. For this reason, we first use synchronous elastic design methods to generate a distributed/multithreaded system from a synchronous system, and then, reduce communication overhead between the obtained process nodes. Our benchmarks show that we can save up to 67.5% of communication costs using our method and can achieve an average speed-up of up to 1.09.},
  keywords={},
  doi={10.1109/PDP.2014.98},
  ISSN={2377-5750},
  month={Feb},}
@INPROCEEDINGS{6787350,
  author={Ng, Nicholas and Yoshida, Nobuko},
  booktitle={2014 22nd Euromicro International Conference on Parallel, Distributed, and Network-Based Processing}, 
  title={Pabble: Parameterised Scribble for Parallel Programming}, 
  year={2014},
  volume={},
  number={},
  pages={707-714},
  abstract={Many parallel and distributed message-passing programs are written in a parametric way over available resources, in particular the number of nodes and their topologies, so that a single parallel program can scale over different environments. This paper presents a parameterised protocol description language, Pabble, which can guarantee safety and progress in a large class of practical, complex parameterised message-passing programs through static checking. Pabble can describe an overall interaction topology, using a concise and expressive notation, designed for a variable number of participants arranged in multiple dimensions. These parameterised protocols in turn automatically generate local protocols for type checking parameterised MPI programs for communication safety and deadlock freedom. In spite of undecidability of endpoint projection and type checking in the underlying parameterised session type theory, our method guarantees the termination of endpoint projection and type checking.},
  keywords={},
  doi={10.1109/PDP.2014.20},
  ISSN={2377-5750},
  month={Feb},}
@INPROCEEDINGS{6838311,
  author={Jia, Yue and Bodanese, Eliane and Phillips, Chris and Bigham, John and Tao, Ran},
  booktitle={2014 IEEE Network Operations and Management Symposium (NOMS)}, 
  title={Improved reliability of large scale publish/subscribe based MOMs using model checking}, 
  year={2014},
  volume={},
  number={},
  pages={1-8},
  abstract={Many software systems operate across different geographically distributed hardware platforms, operating systems and programming languages. Publish/subscribe based Message Oriented Middleware (MOM) provides loose coupling and an efficient, asynchronous and scalable way of communication. However, as the complexity of such systems increase, manual verification of reconfiguration policies becomes unrealistic. The task calls for automated means of proof-checking configuration information in order to improve the reliability of large-scale MOM systems. This paper proposes a new model checking approach with temporal logic specifications to design and verify a system configuration. Model checking is a powerful technique, however the creation of appropriate finite state models for the systems being checked are complex and difficult to use in practice by non-formalists. The research presented in this paper finds suitable abstractions that reduce the system to a finite state model. The tools we developed for the generation of such models can be easily used by non-formalists. The systems models created using our techniques manages state explosion thanks to the choices of our abstractions. An example of the use of our tools and techniques is presented for a 50 node MOM, where the reachability of all topics and the presence of loops are proof-checked.},
  keywords={},
  doi={10.1109/NOMS.2014.6838311},
  ISSN={2374-9709},
  month={May},}
@INPROCEEDINGS{6844467,
  author={Fu, Yaosheng and Wentzlaff, David},
  booktitle={2014 IEEE International Symposium on Performance Analysis of Systems and Software (ISPASS)}, 
  title={PriME: A parallel and distributed simulator for thousand-core chips}, 
  year={2014},
  volume={},
  number={},
  pages={116-125},
  abstract={Modern processors are integrating an increasing number of cores, which brings new design challenges. However, mainstream architectural simulators primarily focus on unicore or multicore systems with small core counts. In order to simulate emerging manycore architectures, more simulators designed for thousand-core systems are needed. In this paper, we introduce the Princeton Manycore Executor (PriME), a parallelized, MPI-based, x86 manycore simulator. The primary goal of PriME is to provide high performance simulation for manycore architectures, allowing fast exploration of architectural ideas including cache hierarchies, coherence protocols and NoCs in thousand-core systems. PriME supports multi-threaded workloads as well as multi-programmed workloads. Furthermore, it parallelizes the simulation of multi-threaded workloads inside of a host machine and parallelizes the simulation of multi-programmed workloads across multiple host machines by utilizing MPI to communicate between different simulator modules. By using two levels of parallelization (within a host machine and across host machines), PriME can improve simulation performance which is especially useful when simulating thousands of cores. Prime is especially adept at executing simulations which have large memory requirements as previous simulators which use multiple machines are unable to simulate more memory than is available in any single host machine. We demonstrate PriME simulating 2000+ core machines and show near-linear scaling on up to 108 host processors split across 9 machines. Finally we validate PriME against a real-world 40-core machine and show the average error to be 12%.},
  keywords={},
  doi={10.1109/ISPASS.2014.6844467},
  ISSN={},
  month={March},}
@INPROCEEDINGS{6844686,
  author={Yokoyama, Roberto S. and Kimura, Bruno Y.L. and Jaimes, Luz M.S. and Moreira, Edson D.S.},
  booktitle={2014 28th International Conference on Advanced Information Networking and Applications Workshops}, 
  title={A Beaconing-Based Opportunistic Service Discovery Protocol for Vehicular Networks}, 
  year={2014},
  volume={},
  number={},
  pages={498-503},
  abstract={In the future, wireless access in vehicular environments (WAVE) will provide the foundation for a broad range of intelligent applications in transport, related to safety, comfort and, traffic management, to mention a few. Opportunities to instantaneously advertise and disseminate services arise with the technological advances of the vehicular networks. Points of interest (POI) to drivers and passengers, e.g., shops and gas stations, will broadcast advertisements with local services and facilities to the nearby vehicles by exploiting the road-side unit (RSU) infrastructure and comfort applications. However, RSU access coverage limitation or packet losses can prevent users (drivers or passengers) who are genuinely interested in services from finding them, even with a short distance from the POI. To improve the service discovery, we propose OSDP (opportunistic service discovery protocol), a protocol based on opportunistic vehicle contact and a store-and-forward technique to discover and advertise services in vehicular networks. OSDP is a lightweight and alternative protocol intended for location-aware applications. It supports distributed services fully independent from Internet access. In this paper we describe the key design concepts of OSDP and demonstrate its feasibility by a concept proof test bed. We perform two experiments evaluating the success rate of: i) capturing and storing service messages and ii) searching for a service of interest and receiving reply messages containing it. OSPD feasibility was demonstrated for different vehicle densities and for very short time connections. Results indicate that a vehicle can capture 100% of messages under the coverage of seven POI sending advertisement messages every second, with a contact time of 1.2s. Moreover, a user can find a service with 95% of success rate by querying one neighbour vehicle.},
  keywords={},
  doi={10.1109/WAINA.2014.82},
  ISSN={},
  month={May},}
@INPROCEEDINGS{6848205,
  author={Setty, Vinay and Kreitz, Gunnar and Urdaneta, Guido and Vitenberg, Roman and van Steen, Maarten},
  booktitle={IEEE INFOCOM 2014 - IEEE Conference on Computer Communications}, 
  title={Maximizing the number of satisfied subscribers in pub/sub systems under capacity constraints}, 
  year={2014},
  volume={},
  number={},
  pages={2580-2588},
  abstract={Publish/subscribe (pub/sub) is a popular communication paradigm in the design of large-scale distributed systems. A provider of a pub/sub service (whether centralized, peer-assisted, or based on a federated organization of cooperatively managed servers) commonly faces a fundamental challenge: given limited resources, how to maximize the satisfaction of subscribers? We provide, to the best of our knowledge, the first formal treatment of this problem by introducing two metrics that capture subscriber satisfaction in the presence of limited resources. This allows us to formulate matters as two new flavors of maximum coverage optimization problems. Unfortunately, both variants of the problem prove to be NP-hard. By subsequently providing formal approximation bounds and heuristics, we show, however, that efficient approximations can be attained. We validate our approach using real-world traces from Spotify and show that our solutions can be executed periodically in real-time in order to adapt to workload variations.},
  keywords={},
  doi={10.1109/INFOCOM.2014.6848205},
  ISSN={0743-166X},
  month={April},}
@INPROCEEDINGS{6848147,
  author={Qian, Shiyou and Cao, Jian and Zhu, Yanmin and Li, Minglu},
  booktitle={IEEE INFOCOM 2014 - IEEE Conference on Computer Communications}, 
  title={REIN: A fast event matching approach for content-based publish/subscribe systems}, 
  year={2014},
  volume={},
  number={},
  pages={2058-2066},
  abstract={Event matching is the process of checking high volumes of events against large numbers of subscriptions and is a fundamental issue for the overall performance of a large-scale distributed publish/subscribe system. Most existing algorithms are based on counting satisfied component constraints in each subscription. As the scale of a system grows, these algorithms inevitably suffer from performance degradation. We present REIN (REctangle INtersection), a fast event matching approach for large-scale content-based publish/subscribe systems. The idea behind REIN is to quickly filter out unlikely matched subscriptions. In REIN, the event matching problem is first transformed into the rectangle intersection problem. Then, an efficient index structure is designed to address the problem by using bit operations. Experimental results show that REIN has a better matching performance than its counterparts. In particular, the event matching speed is faster by an order of magnitude when the selectivity of subscriptions is high and the number of subscriptions is large.},
  keywords={},
  doi={10.1109/INFOCOM.2014.6848147},
  ISSN={0743-166X},
  month={April},}
@INPROCEEDINGS{6846464,
  author={Wang, Zhixiang and Shi, Xuanhua and Jin, Hai and Wu, Song and Chen, Yong},
  booktitle={2014 14th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing}, 
  title={Iteration Based Collective I/O Strategy for Parallel I/O Systems}, 
  year={2014},
  volume={},
  number={},
  pages={287-294},
  abstract={MPI collective I/O is a widely used I/O method that helps data-intensive scientific applications gain better I/O performance. However, it has been observed that existing collective I/O strategies do not perform well due to the access contention problem. Existing collective I/O optimization strategies mainly focus on the I/O phase efficiency and ignore the shuffle cost that may limit the potential of their performance improvement. We observe that as the size of I/O becomes larger, one I/O operation from the upper application would be separated into several iterations to complete. So, I/O requests in each file domain do not necessarily issue to the parallel file system simultaneously unless they are carried out within the same iteration step. Based on that observation, this paper proposes a new collective I/O strategy that reorganizes I/O requests within each file domain instead of coordinating requests across file domains, such that we can eliminate access contentions without introducing extra shuffle cost between aggregators and computing processes. Using benchmark workloads IOR, we evaluate our new strategy and compare with the conventional one. The proposed strategy achieves up to 47%-63% I/O bandwidth improvement compared to the existing ROMIO collective I/O strategy.},
  keywords={},
  doi={10.1109/CCGrid.2014.61},
  ISSN={},
  month={May},}
@INPROCEEDINGS{6846551,
  author={de Lacerda Ruivo, Tiago Pais Pitta and Altayo, Gerard Bernabeu and Garzoglio, Gabriele and Timm, Steven and Kim, Hyun Woo and Noh, Seo-Young and Raicu, Ioan},
  booktitle={2014 14th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing}, 
  title={Exploring Infiniband Hardware Virtualization in OpenNebula towards Efficient High-Performance Computing}, 
  year={2014},
  volume={},
  number={},
  pages={943-948},
  abstract={It has been widely accepted that software virtualization has a big negative impact on high-performance computing (HPC) application performance. This work explores the potential use of Infiniband hardware virtualization in an Open Nebula cloud towards the efficient support of MPI-based workloads. We have implemented, deployed, and tested an Infiniband network on the Fermi Cloud private Infrastructure-as-a-Service (IaaS) cloud. To avoid software virtualization towards minimizing the virtualization overhead, we employed a technique called Single Root Input/Output Virtualization (SRIOV). Our solution spanned modifications to the Linux's Hypervisor as well as the Open Nebula manager. We evaluated the performance of the hardware virtualization on up to 56 virtual machines connected by up to 8 DDR Infiniband network links, with micro-benchmarks (latency and bandwidth) as well as with a MPI-intensive application (the HPL Linpack benchmark).},
  keywords={},
  doi={10.1109/CCGrid.2014.90},
  ISSN={},
  month={May},}
@INPROCEEDINGS{6865149,
  author={Lu, Yichao and Tian, Guifen and Goto, Satoshi},
  booktitle={2014 IEEE International Symposium on Circuits and Systems (ISCAS)}, 
  title={An efficient decoder architecture for cyclic non-binary LDPC codes}, 
  year={2014},
  volume={},
  number={},
  pages={397-400},
  abstract={This paper proposes a hybrid message-passing decoding algorithm which consumes very low computational complexity, while achieving competitive error performance compared with conventional min-max algorithm. Simulation result on a (255,175) cyclic code shows that this algorithm obtains at least 0.5dB coding gain over other state-of-the-art low-complexity non-binary LDPC (NB-LDPC) decoding algorithms. Based on this algorithm, a partial-parallel decoder architecture is implemented for cyclic NB-LDPC codes, where the variable node units are redesigned and the routing network is optimized for the proposed algorithm. Synthesis results demonstrate that about 24.3% gates and 12% memories can be saved over previous works.},
  keywords={},
  doi={10.1109/ISCAS.2014.6865149},
  ISSN={2158-1525},
  month={June},}
@INPROCEEDINGS{6868640,
  author={Xiao, Hao and Isshiki, Tsuyoshi and Li, Dongju and Kunieda, Hiroaki and Zhu, Guanyu},
  booktitle={2014 IEEE 25th International Conference on Application-Specific Systems, Architectures and Processors}, 
  title={Distributed synchronization for message-passing based embedded multiprocessors}, 
  year={2014},
  volume={},
  number={},
  pages={82-83},
  abstract={This paper presents a distributed synchronization architecture for message-passing based embedded multiprocessors. The proposed solution effectively realizes the lock and barrier protocols in a completely decentralized manner without traffic contention. We implement the proposed mechanism using application-specific instruction-set processor (ASIP) techniques to speed up the message passing and handling. Experimental results show the proposed synchronization achieves ultra-low latency and almost ideal scalability when the number of processors increases.},
  keywords={},
  doi={10.1109/ASAP.2014.6868640},
  ISSN={2160-052X},
  month={June},}
@INPROCEEDINGS{6868348,
  author={Senior, Alexander and Şekercioğlu, Y. Ahmet and Khan, Asad I.},
  booktitle={2014 International Conference on Computer and Information Sciences (ICCOINS)}, 
  title={A polymorphic recogniser for distributed intelligence in wireless sensor networks}, 
  year={2014},
  volume={},
  number={},
  pages={1-5},
  abstract={We present an innovative scheme for performing pattern recognition in wireless sensor networks. It is based on the concept of a distributed computer that can alter itself to adjust to the user's needs. By emulating the distributed nature of biological computational devices and evenly spreading the computational and communication workload throughout the network, we will reduce energy consumption and enhance the reliability of the recognition process of sensing applications utilising this approach. We introduce the basic concepts of the scheme as a computer that operates via message passing (and not arithmetic operations), and show a theoretical validation of its operation.},
  keywords={},
  doi={10.1109/ICCOINS.2014.6868348},
  ISSN={},
  month={June},}
@INPROCEEDINGS{6869142,
  author={Hartanto, Ronny and Eich, Markus},
  booktitle={2014 IEEE International Conference on Technologies for Practical Robot Applications (TePRA)}, 
  title={Reliable, cloud-based communication for multi-robot systems}, 
  year={2014},
  volume={},
  number={},
  pages={1-8},
  abstract={In contrast to single robotic agent, multi-robot systems are highly dependent on reliable communication. Robots have to synchronize tasks or to share poses and sensor readings with other agents, especially for co-operative mapping task where local sensor readings are incorporated into a global map. The drawback of existing communication frameworks is that most are based on a central component which has to be constantly within reach. Additionally, they do not prevent data loss between robots if a failure occurs in the communication link. During a distributed mapping task, loss of data is critical because it will corrupt the global map. In this work, we propose a cloud-based publish/subscribe mechanism which enables reliable communication between agents during a cooperative mission using the Data Distribution Service (DDS) as a transport layer. The usability of our approach is verified by several experiments taking into account complete temporary communication loss.},
  keywords={},
  doi={10.1109/TePRA.2014.6869142},
  ISSN={2325-0534},
  month={April},}
@ARTICLE{6872556,
  author={Su, Qinliang and Wu, Yik-Chung},
  journal={IEEE Transactions on Signal Processing}, 
  title={Convergence Analysis of the Variance in Gaussian Belief Propagation}, 
  year={2014},
  volume={62},
  number={19},
  pages={5119-5131},
  abstract={It is known that Gaussian belief propagation (BP) is a low-complexity algorithm for (approximately) computing the marginal distribution of a high dimensional Gaussian distribution. However, in loopy factor graph, it is important to determine whether Gaussian BP converges. In general, the convergence conditions for Gaussian BP variances and means are not necessarily the same, and this paper focuses on the convergence condition of Gaussian BP variances. In particular, by describing the message-passing process of Gaussian BP as a set of updating functions, the necessary and sufficient convergence conditions of Gaussian BP variances are derived under both synchronous and asynchronous schedulings, with the converged variances proved to be independent of the initialization as long as it is chosen from the proposed set. The necessary and sufficient convergence condition is further expressed in the form of a semi-definite programming (SDP) optimization problem, thus can be verified more efficiently compared to the existing convergence condition based on computation tree. The relationship between the proposed convergence condition and the existing one based on computation tree is also established analytically. Numerical examples are presented to corroborate the established theories.},
  keywords={},
  doi={10.1109/TSP.2014.2345635},
  ISSN={1941-0476},
  month={Oct},}
@INPROCEEDINGS{6875307,
  author={Su, Qinliang and Wu, Yik-Chung},
  booktitle={2014 IEEE International Symposium on Information Theory}, 
  title={Determining the convergence of variance in Gaussian belief propagation via semi-definite programming}, 
  year={2014},
  volume={},
  number={},
  pages={2614-2618},
  abstract={In order to compute the marginal distribution from a high dimensional distribution with loopy Gaussian belief propagation (BP), it is important to determine whether Gaussian BP would converge. In general, the convergence condition for Gaussian BP variance and mean are not necessarily the same, and this paper focuses on the convergence condition of Gaussian BP variance. In particular, by describing the message-passing process of Gaussian BP as a set of updating functions, the necessary and sufficient convergence condition of Gaussian BP variance is derived, with the converged variance proved to be independent of the initialization as long as it is greater or equal to zero. It is further proved that the convergence condition can be verified efficiently by solving a semi-definite programming (SDP) optimization problem. Numerical examples are presented to corroborate the established theories.},
  keywords={},
  doi={10.1109/ISIT.2014.6875307},
  ISSN={2157-8117},
  month={June},}
@INPROCEEDINGS{6876769,
  author={Akele, Gebere and Redwan, Hassen and Kim, Ki-Hyung},
  booktitle={2014 Sixth International Conference on Ubiquitous and Future Networks (ICUFN)}, 
  title={Virtual group leader election algorithm in distributed WSN}, 
  year={2014},
  volume={},
  number={},
  pages={143-148},
  abstract={A distributed system is a collection of nodes interconnected by a communication network in which each node can work together and has its own local memory and other peripherals. The communications between the nodes are held by message passing over the communication network. An important challenge confronted in distributed wireless sensor network (WSN) is the adoption of suitable and efficient algorithms for leader election. The goal of a leader election in distributed WSN of autonomous nodes is to select one of the currently alive nodes as a leader so as to manage the coordination activities of the other nodes in the system. To the best of our knowledge most existing leader election algorithm have limitation either fault tolerance, message passing overhead or if the leader fails an election process could be initiated by communicating all the nodes in the distributed WSN. So, these types of algorithms have a great impact on the performance and the energy efficiency of the WSN because of communication overhead. To mitigate these type leader election limitations, in this paper, we propose a virtual group leader election algorithm by combining a group of nodes (including a master leader and multiple backups) on the WSN into a leader group. Our proposed algorithm improves the energy efficiency and the performance in message passing and less time complexity that results in electing a new leader node faster. The proposed algorithm analysed and validated through extensive mathematical results. And also the simulation result shows that the proposed algorithm can minimize a lot of energy when the number of nodes increases.},
  keywords={},
  doi={10.1109/ICUFN.2014.6876769},
  ISSN={2165-8536},
  month={July},}
@INPROCEEDINGS{6876832,
  author={Lin, Baihong and Li, Qi and Pei, Yukui and Yin, Liuguo and Lu, Jianhua},
  booktitle={2014 Sixth International Conference on Ubiquitous and Future Networks (ICUFN)}, 
  title={High speed LDPC decoder design based on general overlapped message-passing architecture}, 
  year={2014},
  volume={},
  number={},
  pages={454-459},
  abstract={The design of high speed decoders with traditional partly parallel architecture for non-quasi-cycle (NQC) LDPC codes is a challenging problem due to its high memory-block consumption and the low hardware utilization efficiency. In this paper, a general overlapped message passing (GOMP) decoding algorithm is proposed to improve the hardware utilization efficiency (HUE), which overcomes the limitation of overlapped message passing (OMP) decoders proposed before. On the basis of the given codes, this algorithm nearly doubles the throughput without sacrificing double memory or causing loss in performance compared to BP algorithm. Furthermore, we present a technique called cycle bus to reduce the number of block RAMs in the multi-core decoder. Moreover, an example of a rate-2/3, length-15360 irregular LDPC code with 8.43 dB coding gain for BPSK in AWGN channel is given, whose decoders features nearly double throughput, 22.22% increase in memory 8.35% reduction in logic registers cost and more reasonable distribution in block RAMs cost.},
  keywords={},
  doi={10.1109/ICUFN.2014.6876832},
  ISSN={2165-8536},
  month={July},}
@INPROCEEDINGS{6877346,
  author={Di, Sheng and Bouguerra, Mohamed Slim and Bautista-Gomez, Leonardo and Cappello, Franck},
  booktitle={2014 IEEE 28th International Parallel and Distributed Processing Symposium}, 
  title={Optimization of Multi-level Checkpoint Model for Large Scale HPC Applications}, 
  year={2014},
  volume={},
  number={},
  pages={1181-1190},
  abstract={HPC community projects that future extreme scale systems will be much less stable than current Petascale systems, thus requiring sophisticated fault tolerance to guarantee the completion of large scale numerical computations. Execution failures may occur due to multiple factors with different scales, from transient uncorrectable memory errors localized in processes to massive system outages. Multi-level checkpoint/restart is a promising model that provides an elastic response to tolerate different types of failures. It stores checkpoints at different levels: e.g., local memory, remote memory, using a software RAID, local SSD, remote file system. In this paper, we respond to two open questions: 1) how to optimize the selection of checkpoint levels based on failure distributions observed in a system, 2) how to compute the optimal checkpoint intervals for each of these levels. The contribution is three-fold. (1) We build a mathematical model to fit the multi-level checkpoint/restart mechanism with large scale applications regarding various types of failures. (2) We theoretically optimize the entire execution performance for each parallel application by selecting the best checkpoint level combination and corresponding checkpoint intervals. (3) We characterize checkpoint overheads on different checkpoint levels in a real cluster environment, and evaluate our optimal solutions using both simulation with millions of cores and real environment with real-world MPI programs running on hundreds of cores. Experiments show that optimized selections of levels associated with optimal checkpoint intervals at each level outperforms other state-of-the-art solutions by 5-50 percent.},
  keywords={},
  doi={10.1109/IPDPS.2014.122},
  ISSN={1530-2075},
  month={May},}
@INPROCEEDINGS{6877256,
  author={Parsons, Benjamin S. and Pai, Vijay S.},
  booktitle={2014 IEEE 28th International Parallel and Distributed Processing Symposium}, 
  title={Accelerating MPI Collective Communications through Hierarchical Algorithms Without Sacrificing Inter-Node Communication Flexibility}, 
  year={2014},
  volume={},
  number={},
  pages={208-218},
  abstract={This paper presents and evaluates a universal algorithm to improve the performance of MPI collective communication operations on hierarchical clusters with many-core nodes. This algorithm exploits shared-memory buffers for efficient intra-node communication while still allowing the use of unmodified, hierarchy-unaware traditional collectives for inter-node communication (including collectives like Alltoallv). This algorithm improves on past works that convert a specific collective algorithm into a hierarchical version and are generally restricted to fan-in, fan-out, and All gather algorithms. Experimental results show impressive performance improvements utilizing a variety of collectives from MPICH as well as the closed-source Cray MPT for the inter-node communication. The experimental evaluation tests the new algorithms with as many as 65536 cores and sees speedups over the baseline averaging 14.2x for Alltoallv, 26x for All gather, and 32.7x for Reduce-Scatter. The paper further improves inter-node communication by utilizing multiple senders from the same shared memory buffer, achieving additional speedups averaging 2.5x. The discussion also evaluates special-purpose extensions to improve intra-node communication by returning shared memory or copy-on-write protected buffers from the collective.},
  keywords={},
  doi={10.1109/IPDPS.2014.32},
  ISSN={1530-2075},
  month={May},}
@INPROCEEDINGS{6877350,
  author={Sato, Kento and Moody, Adam and Mohror, Kathryn and Gamblin, Todd and Supinski, Bronis R. de and Maruyama, Naoya and Matsuoka, Satoshi},
  booktitle={2014 IEEE 28th International Parallel and Distributed Processing Symposium}, 
  title={FMI: Fault Tolerant Messaging Interface for Fast and Transparent Recovery}, 
  year={2014},
  volume={},
  number={},
  pages={1225-1234},
  abstract={Future supercomputers built with more components will enable larger, higher-fidelity simulations, but at the cost of higher failure rates. Traditional approaches to mitigating failures, such as checkpoint/restart (C/R) to a parallel file system incur large overheads. On future, extreme-scale systems, it is unlikely that traditional C/R will recover a failed application before the next failure occurs. To address this problem, we present the Fault Tolerant Messaging Interface (FMI), which enables extremely low-latency recovery. FMI accomplishes this using a survivable communication runtime coupled with fast, in-memory C/R, and dynamic node allocation. FMI provides message-passing semantics similar to MPI, but applications written using FMI can run through failures. The FMI runtime software handles fault tolerance, including check pointing application state, restarting failed processes, and allocating additional nodes when needed. Our tests show that FMI runs with similar failure-free performance as MPI, but FMI incurs only a 28% overhead with a very high mean time between failures of 1 minute.},
  keywords={},
  doi={10.1109/IPDPS.2014.126},
  ISSN={1530-2075},
  month={May},}
@INPROCEEDINGS{6879997,
  author={Perumalla, Kalyan S. and Park, Alfred J.},
  booktitle={International Symposium on Performance Evaluation of Computer and Telecommunication Systems (SPECTS 2014)}, 
  title={Simulating billion-task parallel programs}, 
  year={2014},
  volume={},
  number={},
  pages={585-592},
  abstract={In simulating large parallel systems, bottom-up approaches exercise detailed hardware models with effects from simplified software models or traces, whereas top-down approaches evaluate the timing and functionality of detailed software models over coarse hardware models. Here, we focus on the top-down approach and significantly advance the scale of the simulated parallel programs. Via the direct execution technique combined with parallel discrete event simulation, we stretch the limits of the top-down approach by simulating parallel programs with hundreds of millions of tasks. Although the scaling issues and solutions presented here are generally applicable, we focus on message passing interface (MPI) programs. Using a timing-validated benchmark application, a proof-of-concept scaling level is achieved to over 0.22 billion virtual MPI processes on 216,000 cores of a Cray XTS supercomputer, representing one of the largest direct execution simulations to date, combined with a multiplexing ratio of 1024 simulated tasks per real task.},
  keywords={},
  doi={10.1109/SPECTS.2014.6879997},
  ISSN={},
  month={July},}
@INPROCEEDINGS{6882331,
  author={Etzlinger, Bernhard and Meyer, Florian and Wymeersch, Henk and Hlawatsch, Franz and Müller, Gerhard and Springer, Andreas},
  booktitle={2014 IEEE 8th Sensor Array and Multichannel Signal Processing Workshop (SAM)}, 
  title={Cooperative simultaneous localization and synchronization: Toward a low-cost hardware implementation}, 
  year={2014},
  volume={},
  number={},
  pages={33-36},
  abstract={Cooperative sensor self-localization (CSL) in wireless networks usually requires the nodes to be equipped with specific ranging hardware including ultra-wideband or ultrasonic distance sensors. Such designs are not suitable for application in low-cost, low-power sensor networks. Here, we demonstrate how low-cost, low-power, asynchronous sensor nodes can be used to perform CSL (and, simultaneously, distributed synchronization) by means of time-stamped communication without additional ranging hardware. Our method combines a belief propagation message passing algorithm for cooperative simultaneous localization and synchronization (CoSLAS) with a MAC-layer time stamping scheme.We validate the models underlying the CoSLAS algorithm by means of measurements, and we demonstrate that the localization accuracy achieved by our hardware implementation is far better than that corresponding to the time resolution and measurement errors of the hardware.},
  keywords={},
  doi={10.1109/SAM.2014.6882331},
  ISSN={2151-870X},
  month={June},}
@ARTICLE{6896568,
  author={Húdik, Martin and Hodoñ, Michal},
  journal={Journal of Communications and Networks}, 
  title={Performance optimization of parallel algorithms}, 
  year={2014},
  volume={16},
  number={4},
  pages={436-446},
  abstract={The high intensity of research and modeling in fields of mathematics, physics, biology and chemistry requires new computing resources. For the big computational complexity of such tasks computing time is large and costly. The most efficient way to increase efficiency is to adopt parallel principles. Purpose of this paper is to present the issue of parallel computing with emphasis on the analysis of parallel systems, the impact of communication delays on their efficiency and on overall execution time. Paper focuses is on finite algorithms for solving systems of linear equations, namely the matrix manipulation (Gauss elimination method, GEM). Algorithms are designed for architectures with shared memory (open multiprocessing, openMP), distributed-memory (message passing interface, MPI) and for their combination (MPI + openMP). The properties of the algorithms were analytically determined and they were experimentally verified. The conclusions are drawn for theory and practice.},
  keywords={},
  doi={10.1109/JCN.2014.000074},
  ISSN={1976-5541},
  month={Aug},}
@INPROCEEDINGS{6899132,
  author={Khoury, Joud and Lauer, Gregory and Pal, Partha and Thapa, Bishal and Loyall, Joseph},
  booktitle={2014 IEEE 17th International Symposium on Object/Component/Service-Oriented Real-Time Distributed Computing}, 
  title={Efficient Private Publish-Subscribe Systems}, 
  year={2014},
  volume={},
  number={},
  pages={64-71},
  abstract={We address the problem of privacy in publish-subscribe(pub-sub) systems that typically expose some form of published content and subscriber interest, at least to the infrastructure responsible for subscription matching and content delivery. In our recent work, we proposed P3S, a pub-sub middleware designed to protect the privacy of subscriber interest and confidentiality of published content. P3S combined Cipher text Policy Attribute Based Encryption(CP-ABE) with Predicate Based Encryption (PBE) in its novel system architecture to achieve the desired level of content (payload and metadata) confidentiality, and subscription privacy. In this work, we build upon P3S to achieve the strongest possible subscription privacy where clear text subscription is visible only to the subscriber. Furthermore, we add support for subscription policy enforcement, improve the expressiveness of predicates by allowing disjunctions of conjunction, and improve the efficiency of the underlying cryptography through enhanced cryptographic construction and optimized implementation of cryptographic primitives. To the best of our knowledge, this paper presents the first comprehensive and practical implementation of a real-time privacy preserving pub-sub system, demonstrated on a large-scale test bed featuring up to 90 subscribers with robust, scalable and efficient performance. Our code and test bed specifications are freely available for research and experimentation purposes.},
  keywords={},
  doi={10.1109/ISORC.2014.10},
  ISSN={2375-5261},
  month={June},}
@INPROCEEDINGS{6903631,
  author={Fang, Bo and Pattabiraman, Karthik and Ripeanu, Matei and Gurumurthi, Sudhanva},
  booktitle={2014 44th Annual IEEE/IFIP International Conference on Dependable Systems and Networks}, 
  title={Evaluating the Error Resilience of Parallel Programs}, 
  year={2014},
  volume={},
  number={},
  pages={720-725},
  abstract={As a consequence of increasing hardware fault rates, HPC systems face significant challenges in terms of reliability. Evaluating the error resilience of HPC applications is an essential step for building efficient fault-tolerant mechanisms for these applications. In this paper, we propose a methodology to characterize the resilience of OpenMP programs using fault-injection experiments. We find that the error resilience of OpenMP applications depends on the program structure and thread model, hence, these need to be taken into account while characterizing error resilience. We also report preliminary results about the correlation between the application's error resilience and the algorithm(s) used in the application.},
  keywords={},
  doi={10.1109/DSN.2014.73},
  ISSN={2158-3927},
  month={June},}
@INPROCEEDINGS{6903630,
  author={Jitsumoto, Hideyuki and Todoroki, Yuki and Ishikawa, Yutaka and Sato, Mitsuhisa},
  booktitle={2014 44th Annual IEEE/IFIP International Conference on Dependable Systems and Networks}, 
  title={Grid-Oriented Process Clustering System for Partial Message Logging}, 
  year={2014},
  volume={},
  number={},
  pages={714-719},
  abstract={In a computer cluster composed of many nodes, the mean time between failures becomes shorter as the number of nodes increases. This may mean that lengthy tasks cannot be performed, because they will be interrupted by failure. Therefore, fault tolerance has become an essential part of high-performance computing. Partial message logging forms clusters of processes, and coordinates a series of checkpoints to log messages between groups. Our study proposes a system of two features to improve the efficiency of partial message logging: 1) the communication log used in the clustering is recorded at runtime, and 2) a graph partitioning algorithm reduces the complexity of the system by geometrically partitioning a grid graph. The proposed system is evaluated by executing a scientific application. The results of process clustering are compared to existing methods in terms of the clustering performance and quality.},
  keywords={},
  doi={10.1109/DSN.2014.72},
  ISSN={2158-3927},
  month={June},}
@INPROCEEDINGS{6908538,
  author={Mohammad Taheri, Y. and Ahmad, M. Omair and Swamy, M. N. S.},
  booktitle={2014 IEEE 57th International Midwest Symposium on Circuits and Systems (MWSCAS)}, 
  title={Joint noise distribution parameter estimation and LDPC decoding using variational Bayes}, 
  year={2014},
  volume={},
  number={},
  pages={809-812},
  abstract={In this work, we investigate the problem of estimating time-varying noise distribution parameter on a factor graph. A new message passing scheme is proposed by incorporating the variational Bayes (VB) into the belief propagation algorithm for estimating of time-varying noise distribution parameter in a low-density parity-check decoder. The scheme can also be used for the estimation of the correlation noise model parameter in distributed video coding. A Bayesian estimator is used to estimate this parameter by obtaining its posterior distribution given the channel output. The VB algorithm is employed to approximate the complex form of the posterior distribution with a simple distribution. Finally, this distribution is used to derive a closed-form expression for the messages on the augmented factor graph for online parameter estimation and decoding process at the same time.},
  keywords={},
  doi={10.1109/MWSCAS.2014.6908538},
  ISSN={1558-3899},
  month={Aug},}
@INPROCEEDINGS{6912632,
  author={Húdik, Martin and Hodoň, Michal},
  booktitle={2014 IEEE Symposium on Computers and Communications (ISCC)}, 
  title={Modeling, optimization and performance prediction of parallel algorithms}, 
  year={2014},
  volume={Workshops},
  number={},
  pages={1-7},
  abstract={The high intensity of research and modeling in fields of mathematics, physics, biology and chemistry requires new computing resources. For the big computational complexity of such tasks computing time is large and costly. The most efficient way to increase efficiency is to adopt parallel principles. Purpose of this paper is to present the issue of parallel computing with emphasis on the analysis of parallel systems, the impact of communication delays on their efficiency and on overall execution time. Paper focuses is on finite algorithms for solving systems of linear equations, namely the matrix manipulation (Gauss elimination method GEM). Algorithms are designed for architectures with shared memory (openMP), distributed-memory (MPI) and for their combination (MPI+openMP). The properties of the algorithms were analytically determined and they were experimentally verified. The conclusions are drawn for theory and practice.},
  keywords={},
  doi={10.1109/ISCC.2014.6912632},
  ISSN={1530-1346},
  month={June},}
@INPROCEEDINGS{6915555,
  author={Caragnano, G. and Goga, K. and Ruiu, P. and Mossucca, L. and Terzo, O. and Kashani, G. Ghafour Zadeh},
  booktitle={2014 Eighth International Conference on Complex, Intelligent and Software Intensive Systems}, 
  title={Scalability of a Parallel Application in Hybrid Cloud}, 
  year={2014},
  volume={},
  number={},
  pages={451-456},
  abstract={Cloud computing is a convenient, on demand, model which relies on shared pool of computing resources that can be rapidly provisioned and needs minimal management effort. As cloud computing obtains popularity nowadays, customers are looking for cloud solutions to adapt their organization's requirements. The more changes occur, customers are trying to decide what kind of cloud they are going to choose. Beside that, users are concerned about security, privacy, vendor lock-in and cost issues. A hybrid cloud is a mix of one private cloud and at least one public cloud, customers could benefit interoperability and flexibility. There are many elements that should be considered in hybrid cloud architecture. This paper represents a set of mpi benchmarking test executed on a private and public cloud environment in order to evaluate the QoS when real application is running.},
  keywords={},
  doi={10.1109/CISIS.2014.64},
  ISSN={},
  month={July},}
@INPROCEEDINGS{6916686,
  author={Singhaudom, Wicharn and Supnithi, Pornchai},
  booktitle={2014 IEEE Fifth International Conference on Communications and Electronics (ICCE)}, 
  title={Symbol-based parallel message-passing decoding on partial-response channels}, 
  year={2014},
  volume={},
  number={},
  pages={94-98},
  abstract={Idea of parallel message passing (PMP) between detector and decoder has been studied. The PMP aims to achieve very-high speed decoder. This view point is extremely important in magnetic recording systems where data rate must be high but decoding delay should be low. Recently, the result of symbol based (SB) PMP decoding compared with SB-TE (SB-BCJR combined with q-ary LDPC) on PR channels is presented. However, the bit error rate cannot be equivalent to the SB-BCJR. Motivated by this issue, we introduced cycle-free SB-PMP detector combined with usage of optimal schedule in exchanging information between detector and decoder. Our proposed system could achieve both high speed decoding and identical performance to SB-TE. Additional, alternative method to construct a trellis for SB-PMP detector was presented.},
  keywords={},
  doi={10.1109/CCE.2014.6916686},
  ISSN={},
  month={July},}
@INPROCEEDINGS{6926584,
  author={Mingliang Xu and Qianmin Su},
  booktitle={2014 9th International Conference on Computer Science & Education}, 
  title={The realization of small cluster parallel computing environment for college education}, 
  year={2014},
  volume={},
  number={},
  pages={861-863},
  abstract={Parallel computing is widely used in various fields and Linux cluster system plays an important role in parallel computing. In this paper, the message passing interface (MPI) is taken to build a small cluster of Linux-based systems with the number of ordinary PC and establish a parallel development environment with lower investment. Meanwhile it is verified and proves to be reliable. System takes the advantages of low-cost hardware to provide a practical parallel programming environment on clusters for general research institutes and research schools.},
  keywords={},
  doi={10.1109/ICCSE.2014.6926584},
  ISSN={},
  month={Aug},}
@INPROCEEDINGS{6923182,
  author={Liang, Fan and Feng, Chen and Lu, Xiaoyi and Xu, Zhiwei},
  booktitle={2014 9th IEEE International Conference on Networking, Architecture, and Storage}, 
  title={Performance Characterization of Hadoop and Data MPI Based on Amdahl's Second Law}, 
  year={2014},
  volume={},
  number={},
  pages={207-215},
  abstract={Amdahl's second law has been seen as a useful guideline for designing and evaluating balanced computer systems for decades. This law has been mainly used for hardware systems and peak capacities. This paper utilizes Amdahl's second law from a new angle, i.e., Evaluating the influence on systems performance and balance of the application framework software, a key component of big data systems. We compare two big data application framework software systems, Apache Hadoop and Data MPI, with three representative application benchmarks and various data sizes. System monitors and hardware performance counters are used to record the resource utilization, characteristics of instructions execution, memory accesses, and I/O rates. These numbers are used to reveal the three runtime metrics of Amdahl's second law: CPU speed (GIPS), memory capacity (GB), and I/O rate (Gbps). The experiment and evaluation results show that a Data MPI-based big data system has better performance and is more balanced than a Hadoop-based system.},
  keywords={},
  doi={10.1109/NAS.2014.39},
  ISSN={},
  month={Aug},}
@INPROCEEDINGS{6923183,
  author={Lu, Tao and Stuart, Morgan and Tang, Kun and He, Xubin},
  booktitle={2014 9th IEEE International Conference on Networking, Architecture, and Storage}, 
  title={Clique Migration: Affinity Grouping of Virtual Machines for Inter-cloud Live Migration}, 
  year={2014},
  volume={},
  number={},
  pages={216-225},
  abstract={Affinity is common among Virtual Machines (VMs) in cloud environments. If VMs collaborating on a job are split in geographically distributed clouds, the low bandwidth and high latency inter-cloud communication via a wide area network (WAN) will dramatically degrade the system performance. A potential solution is migrating all of the VMs collaborating on a job in parallel, so as to avoid wide area communication. However, if the job is too large, it becomes impractical to migrate all of the VMs simultaneously due to limited WAN bandwidth and high block dirty rate. We propose a migration optimization mechanism called Clique Migration to partition a large group of VMs into subgroups based on the traffic affinities among VMs. Then, subgroups are migrated one at a time. Based on Clique Migration, we propose and implement two algorithms called R-Min-Cut and Kmeans-SF. Analysis of the traffic trace of 68 VMs in an IBM production cluster shows that our algorithms can reduce inter-cloud traffic by 25% to 60%, when the degree of parallel migration is from 2 to 32. Tests of MPI multi-Ping Ping benchmark running on simulated inter-cloud environments, show that our algorithms can significantly shorten the period during which applications undergo performance degradation. Tests of MPI Reduce scatter benchmark show that R-Min-Cut can keep the performance during migration at 26% to 75% of the non-migration scenario.},
  keywords={},
  doi={10.1109/NAS.2014.40},
  ISSN={},
  month={Aug},}
@INPROCEEDINGS{6924429,
  author={Li, Leisheng and Wang, Yingrui and Ma, Zhitao and Tian, Rong},
  booktitle={2014 IEEE International Symposium on Parallel and Distributed Processing with Applications}, 
  title={petaPar: A Scalable Petascale Framework for Meshfree/Particle Simulation}, 
  year={2014},
  volume={},
  number={},
  pages={50-57},
  abstract={Since high performance computing sustained petaflops in 2008, numerical simulation entered a new era to use 10K to 100K processor cores in one single run of parallel computing. In pursuit of petascale computing, the challenges of scalability must be addressed. Petapar is a highly scalable simulation framework which implements two popular meshfree/particle methods, the smoothed particle hydrodynamics (SPH) and the material point method (MPM). The parallelization starts from the regular-grid-based domain decomposition. The scalability of the code is assured by fully overlapping of communication and computation, and a dynamic load balancing strategy. Petapar supports both flat MPI and MPI+Pthreads hybrid parallelization. The code is tested on Titan, which ranked first on the Top500 supercomputer list when our research work has been done in November 2012. Experiment results show that petaPar linearly scales up to 260K CPU cores with an excellent parallel efficiency of 100% and 96% for the SPH and MPM, respectively.},
  keywords={},
  doi={10.1109/ISPA.2014.16},
  ISSN={2158-9208},
  month={Aug},}
@INPROCEEDINGS{6924451,
  author={Charr, Jean Claude and Couturier, Raphaël and Fanfakh, Ahmed and Giersch, Arnaud},
  booktitle={2014 IEEE International Symposium on Parallel and Distributed Processing with Applications}, 
  title={Dynamic Frequency Scaling for Energy Consumption Reduction in Synchronous Distributed Applications}, 
  year={2014},
  volume={},
  number={},
  pages={225-230},
  abstract={Dynamic Voltage Frequency Scaling (DVFS) can be applied to modern CPUs. This technique is usually used to reduce the energy consumed by a CPU while computing. Thus, decreasing the frequency reduces the power consumed by the CPU. However, it can also significantly affect the performance of the executed program if it is compute bound and if a low CPU frequency is selected. Therefore, the chosen scaling factor must give the best possible trade-off between energy reduction and performance. In this paper we present an algorithm that predicts the energy consumed with each frequency gear and selects the one that gives the best ratio between energy consumption reduction and performance. This algorithm works online without training or profiling and has a very small overhead. It also takes into account synchronous communications between the nodes that are executing the distributed algorithm. The algorithm has been evaluated over the SimGrid simulator while being applied to the NAS parallel benchmark programs. The results of the experiments show that it outperforms other existing scaling factor selection algorithms.},
  keywords={},
  doi={10.1109/ISPA.2014.38},
  ISSN={2158-9208},
  month={Aug},}
@INPROCEEDINGS{6924230,
  author={Mohamedin, Mohamed and Palmieri, Roberto and Ravindran, Binoy},
  booktitle={2014 IEEE 13th International Symposium on Network Computing and Applications}, 
  title={On Making Transactional Applications Resilient to Data Corruption Faults}, 
  year={2014},
  volume={},
  number={},
  pages={213-220},
  abstract={Multicore architectures are becoming increasingly prone to transient faults and data corruption. Relying on a multicore architecture is the common solution for increasing performance and scalability of core applications including transactional applications. In this paper we present SoftX, a low-invasive protocol for supporting execution of transactional applications relying on speculative processing and dedicated committer threads. Upon starting a transaction, SoftX forks a number of threads running the same transaction independently. The commit phase is handled by dedicated threads for optimizing synchronization's overhead. We conduct an evaluation study showing the performance obtained with the implementation of SoftX on a 48 cores AMD machine, running List, Bank and TPC-C benchmarks. Results reveal better performance than classical replication-based fault-tolerant systems and limited overhead with respect to non fault-tolerant protocols. We ported SoftX to a message-passing architecture, Tilera TILE-Gx. Hardware message-passing is an important emerging trend in multicore architectures. Our experiments on Tilera show that SoftX is still more efficient than replication.},
  keywords={},
  doi={10.1109/NCA.2014.39},
  ISSN={},
  month={Aug},}
@INPROCEEDINGS{6927046,
  author={Savvas, Ilias K. and Sofianidou, Georgia N.},
  booktitle={2014 IEEE 23rd International WETICE Conference}, 
  title={Parallelizing K-Means Algorithm for 1-D Data Using MPI}, 
  year={2014},
  volume={},
  number={},
  pages={179-184},
  abstract={Nowadays, colossal amount of information is produced by computational systems and electronic instruments such as telescopes, medical devices and so on. To explore these petabytes of data, new fast algorithms must be discovered or old ones may be redesigned. One of the most popular and useful techniques in order to discover and extract information from data pools is clustering, and k-means is an algorithm which clusters data according its characteristics. Its main disadvantage is its computational complexity which makes the technique very difficult to apply on big data sets. Although k-means is a very well studied technique, a fully parallel version of it has not been explored yet. In this work, a parallel version of the k-means is presented for 1-d objects. The experimental results obtained are inline with the theoretical outcome and prove both the correctness and the effectiveness of the technique.},
  keywords={},
  doi={10.1109/WETICE.2014.13},
  ISSN={1524-4547},
  month={June},}
@INPROCEEDINGS{6927506,
  author={Wenlai Zhao and Haohuan Fu and Guangwen Yang and Luk, Wayne},
  booktitle={2014 24th International Conference on Field Programmable Logic and Applications (FPL)}, 
  title={Patra: Parallel tree-reweighted message passing architecture}, 
  year={2014},
  volume={},
  number={},
  pages={1-6},
  abstract={Maximum a posteriori probability inference algorithms for Markov Random Field are widely used in many applications, such as computer vision and machine learning. Sequential tree-reweighted message passing (TRW-S) is an inference algorithm which shows good quality in finding optimal solutions. However, the performance of TRW-S in software cannot meet the requirements of many real-time applications, due to the sequential scheme and the high memory, bandwidth and computational costs. This paper proposes Patra, a novel parallel tree-reweighted message passing architecture, which involves a fully pipelined design targeting FPGA technology. We build a hybrid CPU/FPGA system to test the performance of Patra for stereo matching. Experimental results show that Patra provides about 100 times faster than a software implementation of TRW-S, and 12 times faster than a GPU-based message passing algorithm. Compared with an existing design in four FPGAs, we can achieve 2 times speedup in a single FPGA. Moreover, Patra can work at video rate in many cases, such as a rate of 167 frame/sec for a standard stereo matching test case, which makes it promising for many real-time applications.},
  keywords={},
  doi={10.1109/FPL.2014.6927506},
  ISSN={1946-1488},
  month={Sep.},}
@INPROCEEDINGS{6949803,
  author={Jesy, P. and Deepthi, P. P.},
  booktitle={2014 International Conference on Communication and Signal Processing}, 
  title={Joint source channel network coding using QC LDPC codes}, 
  year={2014},
  volume={},
  number={},
  pages={081-085},
  abstract={Motivated to develop a scheme that compresses, gives high throughput and adds robustness against channel noise, a new joint source channel network coding (JSCNC) using Quasi Cyclic Low Density Parity Check (QCLDPC) code is proposed for a sensor network with two source nodes communicating correlated information to multiple destination nodes. The source coding is performed by transmitting only half of the information bits of QCLDPC code and transmitting the parity bits as such, since the parity bits are usually uncorrelated compared to the corresponding information bits. The correlations in sensor network data are used effectively at the relay node to reconstruct the original information bits transmitted by the source nodes. Relay scheme used in our proposed work is a decode and forward relaying in which masking of information bits are done before network coding at the relay. This helps in low-error decoding at the destination.},
  keywords={},
  doi={10.1109/ICCSP.2014.6949803},
  ISSN={},
  month={April},}
@INPROCEEDINGS{6953106,
  author={Balamurugan, B. and Krishna, P. Venkata and Rajya Lakshmi, G. V. and Kumar, N. Saravana},
  booktitle={2014 International Conference on Embedded Systems (ICES)}, 
  title={Cloud cluster communication for critical applications accessing C-MPICH}, 
  year={2014},
  volume={},
  number={},
  pages={145-150},
  abstract={Cloud computing is a paradigm shift works with the combination of clients, storage servers, internet and provides security to the data stored with the aid of Access control techniques, encryption/ decryption and digital signature. MPI (Message Passing Interface) framework is used in cluster computing for achieving security of the data transferred between clusters. The concept of MPI had never been tried for cloud cluster computing in terms of high performance, high availability and high throughput. In proposed work, it has a specific explanation with a modified yet enhanced MPI framework for Cloud Cluster communication with the validation of security in terms of authentication, confidentiality, portability, data integrity and availability had overcome on MPI for cloud with results are found out to be reasonable. During communication it overheads the huge data request in a queue by providing the state of a complete security with the help of parallel computing.},
  keywords={},
  doi={10.1109/EmbeddedSys.2014.6953106},
  ISSN={},
  month={July},}
@INPROCEEDINGS{6955083,
  author={Devarakonda, Murthy V. R. S.},
  booktitle={2014 8th International Symposium on Turbo Codes and Iterative Information Processing (ISTC)}, 
  title={Variational message passing without initialization using a free energy constraint}, 
  year={2014},
  volume={},
  number={},
  pages={47-51},
  abstract={In iterative algorithms with graphical models, it is common to initialize messages. But this approach is not suitable in certain applications. In this paper, it is conjectured that if some messages are confined to a ball around their initialized values, then initialization can be avoided. Towards this goal, for networks specified with a bipartite graph, a variant of the sum-product algorithm is derived by adding an inequality constraint on the variable free energy in the underlying Bethe optimization problem. In the binary case, this leads to an upper bound that restricts the ℓ1 norm of the extrinsic message (vector) to a ball around its (otherwise) initial value. Results are reported for binary LDPC decoders through simulations which confirm that initialization between decoding attempts can be eliminated and show that the algorithm tends to outperform the standard sum-product. A few more observations and comments on this approach, relation with other variational methods, and applications to analog processing and inference over distributed networks are outlined in the end.},
  keywords={},
  doi={10.1109/ISTC.2014.6955083},
  ISSN={2165-4719},
  month={Aug},}
@INPROCEEDINGS{6956563,
  author={Kremer, Steve and Künnemann, Robert},
  booktitle={2014 IEEE Symposium on Security and Privacy}, 
  title={Automated Analysis of Security Protocols with Global State}, 
  year={2014},
  volume={},
  number={},
  pages={163-178},
  abstract={Security APIs, key servers and protocols that need to keep the status of transactions, require to maintain a global, non-monotonic state, e.g., in the form of a database or register. However, existing automated verification tools do not support the analysis of such stateful security protocols - sometimes because of fundamental reasons, such as the encoding of the protocol as Horn clauses, which are inherently monotonic. An exception is the recent tamarin prover which allows specifying protocols as multiset rewrite (MSR) rules, a formalism expressive enough to encode state. As multiset rewriting is a "low-level" specification language with no direct support for concurrent message passing, encoding protocols correctly is a difficult and error-prone process. We propose a process calculus which is a variant of the applied pi calculus with constructs for manipulation of a global state by processes running in parallel. We show that this language can be translated to MSR rules whilst preserving all security properties expressible in a dedicated first-order logic for security properties. The translation has been implemented in a prototype tool which useqs the tamarin prover as a backend. We apply the tool to several case studies among which a simplified fragment of PKCS#11, the Yubikey security token, and an optimistic contract signing protocol.},
  keywords={},
  doi={10.1109/SP.2014.18},
  ISSN={2375-1207},
  month={May},}
@INPROCEEDINGS{6957193,
  author={Engelmann, Christian and Naughton, Thomas},
  booktitle={2014 IEEE/ACM 18th International Symposium on Distributed Simulation and Real Time Applications}, 
  title={Improving the Performance of the Extreme-Scale Simulator}, 
  year={2014},
  volume={},
  number={},
  pages={198-207},
  abstract={Investigating the performance of parallel applications at scale on future high-performance computing (HPC) architectures and the performance impact of different architecture choices is an important component of HPC hardware/software co-design. The Extreme-scale Simulator (xSim) is a simulation-based toolkit for investigating the performance of parallel applications at scale. xSim scales to millions of simulated Message Passing Interface (MPI) processes. The overhead introduced by a simulation tool is an important performance and productivity aspect. This paper documents two improvements to xSim: (1) a new deadlock resolution protocol to reduce the parallel discrete event simulation management overhead and (2) a new simulated MPI message matching algorithm to reduce the oversubscription management overhead. The results clearly show a significant performance improvement, such as by reducing the simulation overhead for running the NAS Parallel Benchmark suite inside the simulator from 1,020% to 238% for the conjugate gradient (CG) benchmark and from 102% to 0% for the embarrassingly parallel (EP) and benchmark, as well as, from 37,511% to 13,808% for CG and from 3,332% to 204% for EP with accurate process failure simulation.},
  keywords={},
  doi={10.1109/DS-RT.2014.32},
  ISSN={1550-6525},
  month={Oct},}
@INPROCEEDINGS{6957230,
  author={Wesolowski, Lukasz and Venkataraman, Ramprasad and Gupta, Abhishek and Yeom, Jae-Seung and Bisset, Keith and Sun, Yanhua and Jetley, Pritish and Quinn, Thomas R. and Kale, Laxmikant V.},
  booktitle={2014 43rd International Conference on Parallel Processing}, 
  title={TRAM: Optimizing Fine-Grained Communication with Topological Routing and Aggregation of Messages}, 
  year={2014},
  volume={},
  number={},
  pages={211-220},
  abstract={Fine-grained communication in supercomputing applications often limits performance through high communication overhead and poor utilization of network bandwidth. This paper presents Topological Routing and Aggregation Module (TRAM), a library that optimizes fine-grained communication performance by routing and dynamically combining short messages. TRAM collects units of fine-grained communication from the application and combines them into aggregated messages with a common intermediate destination. It routes these messages along a virtual mesh topology mapped onto the physical topology of the network. TRAM improves network bandwidth utilization and reduces communication overhead. It is particularly effective in optimizing patterns with global communication and large message counts, such as all-to-all and many-to-many, as well as sparse, irregular, dynamic or data dependent patterns. We demonstrate how TRAM improves performance through theoretical analysis and experimental verification using benchmarks and scientific applications. We present speedups on petascale systems of 6x for communication benchmarks and up to 4x for applications.},
  keywords={},
  doi={10.1109/ICPP.2014.30},
  ISSN={2332-5690},
  month={Sep.},}
@INPROCEEDINGS{6899089,
  author={He, Qing and Au, William and Korobkov, Alexander and Venkateswaran, Subramanian},
  booktitle={2014 IEEE International Symposium on Electromagnetic Compatibility (EMC)}, 
  title={Parallel power grid analysis using distributed direct linear solver}, 
  year={2014},
  volume={},
  number={},
  pages={866-871},
  abstract={Accurate and efficient power grid analysis has become increasingly important in semiconductors chip design and verification. It is one of the most computationally challenging tasks in high performance processor design analysis. Due to the extremely large memory required to store and manipulate the design data, it is no longer possible to accommodate the analysis using one or more serial processes on a single computer. The proposed method of large scale power grid analysis with sparse linear solver effectively distributes the computing tasks across multiple processes running on different computers within the network. It provides a stable, accurate, and scalable solution for the future process technology and design generations. The implementation incorporates advanced packages for matrix ordering, matrix factorization and solution, and message passing interface (MPI) integrated into the software tool capable of simulating extremely large scale design with billions of devices. The method can be applied to the power grid of arbitrary size and configuration, and produces results with SPICE-like accuracy. The benchmark analysis runs applied to the largest blocks of the latest Sparc processor design using 16 distributed processes demonstrate more than 6X memory utilization improvement and 9X performance improvement over a state-of-the-art serial solution currently employed in semiconductor industry.},
  keywords={},
  doi={10.1109/ISEMC.2014.6899089},
  ISSN={2158-1118},
  month={Aug},}
@INPROCEEDINGS{6968739,
  author={Lifflander, Jonathan and Meneses, Esteban and Menon, Harshitha and Miller, Phil and Krishnamoorthy, Sriram and Kalé, Laxmikant V.},
  booktitle={2014 IEEE International Conference on Cluster Computing (CLUSTER)}, 
  title={Scalable replay with partial-order dependencies for message-logging fault tolerance}, 
  year={2014},
  volume={},
  number={},
  pages={19-28},
  abstract={Deterministic replay of a parallel application is commonly used for discovering bugs or to recover from a hard fault with message-logging fault tolerance. For message passing programs, a major source of overhead during forward execution is recording the order in which messages are sent and received. During replay, this ordering must be used to deterministically reproduce the execution. Previous work in replay algorithms often makes minimal assumptions about the programming model and application to maintain generality. However, in many applications, only a partial order must be recorded due to determinism intrinsic in the program, ordering constraints imposed by the execution model, and events that are commutative (their relative execution order during replay does not need to be reproduced exactly). In this paper, we present a novel algebraic framework for reasoning about the minimum dependencies required to represent the partial order for different orderings and interleavings. By exploiting this framework, we improve on an existing scalable message-logging fault tolerance scheme that uses a total order. The improved scheme scales to 131,072 cores on an IBM BlueGene/P with up to 2× lower overhead.},
  keywords={},
  doi={10.1109/CLUSTER.2014.6968739},
  ISSN={2168-9253},
  month={Sep.},}
@INPROCEEDINGS{6968752,
  author={Denis, Alexandre},
  booktitle={2014 IEEE International Conference on Cluster Computing (CLUSTER)}, 
  title={POSTER: a generic framework for asynchronous progression and multithreaded communications}, 
  year={2014},
  volume={},
  number={},
  pages={276-277},
  abstract={Recent cluster architectures include dozens of cores per node, with all cores sharing the network resources. To program such architectures, hybrid models mixing MPI+threads, and in particular MPI+OpenMP are gaining popularity. This imposes new requirements on communication libraries, such as the need for MPI_THREAD_MULTIPLE level of multi-threading support. Moreover, the high number of cores brings new opportunities to parallelize communication libraries, so as to have proper background progression of communication and communication/computation overlap. In this paper, we present pioman, a generic framework to be used by MPI implementations, that brings seamless asynchronous progression of communication by opportunistically using available cores. It uses system threads and thus is composable with any runtime system used for multithreading. Through various benchmarks, we demonstrate that our pioman-based MPI implementation exhibits very good properties regarding overlap, progression, and multithreading, and outperforms state-of-art MPI implementations.},
  keywords={},
  doi={10.1109/CLUSTER.2014.6968752},
  ISSN={2168-9253},
  month={Sep.},}
@INPROCEEDINGS{6968776,
  author={Panadero, Javier and Wong, Alvaro and Rexachs, Dolores and Luque, Emilio},
  booktitle={2014 IEEE International Conference on Cluster Computing (CLUSTER)}, 
  title={POSTER: “Analysis of scalability: A parallel application model approach”}, 
  year={2014},
  volume={},
  number={},
  pages={294-295},
  abstract={In this paper we propose a methodology that allows us to predict the application scalability behavior in a specific system, providing information to select the most appropriate resources to run the application. We explain the general methodology, focusing on the presentation of a novel method to model the logical application trace for a large number of processes. This method is based on the projection of a set of executions of the application signature for a small number of processes. The generated traces are validated by comparing them with the real traces obtained with PAS2P tool. We present the experimental validation for the BT Nas Parallel Benchmark. The signatures for 16, 36, 64, 81 and 100 processes were executed and used to model and project the logical trace for 1024 processes. The results obtained show the accuracy of the method. The communication pattern was predicted without error, while the predicted error is less than 10% for the communication volume and less than 5% for the number of instructions.},
  keywords={},
  doi={10.1109/CLUSTER.2014.6968776},
  ISSN={2168-9253},
  month={Sep.},}
@INPROCEEDINGS{6968755,
  author={Li, Mingzhe and Lu, Xiaoyi and Potluri, Sreeram and Hamidouche, Khaled and Jose, Jithin and Tomko, Karen and Panda, Dhabaleswar K.},
  booktitle={2014 IEEE International Conference on Cluster Computing (CLUSTER)}, 
  title={Scalable Graph500 design with MPI-3 RMA}, 
  year={2014},
  volume={},
  number={},
  pages={230-238},
  abstract={The MPI two-sided programming model has been widely used for scientific applications. However, the benefits of MPI one-sided communication are still not well exploited. Recently, MPI-3 Remote Memory Access (RMA) was introduced with several advanced features which provide better performance, programmability, and flexibility over MPI-2 RMA. However, few studies have shown the benefits of using MPI-3 RMA for scientific applications. In this paper, we take advantage of the new features from MPI-3 RMA to re-design a scalable Graph500 benchmark. Our design achieves much better overlap of communication and computation than the default two sided based implementation. The results show that the proposed design can achieve up to 2X improvement compared with the best MPI based implementation running with 4,096 cores. To the best of our knowledge, this is the first paper to re-design a high performance and scalable Graph500 with MPI-3 RMA.},
  keywords={},
  doi={10.1109/CLUSTER.2014.6968755},
  ISSN={2168-9253},
  month={Sep.},}
@INPROCEEDINGS{6969369,
  author={Malik, Tania and Rychkov, Vladimir and Lastovetsky, Alexey and Quintin, Jean-Noël},
  booktitle={2014 IEEE International Parallel & Distributed Processing Symposium Workshops}, 
  title={Topology-Aware Optimization of Communications for Parallel Matrix Multiplication on Hierarchical Heterogeneous HPC Platform}, 
  year={2014},
  volume={},
  number={},
  pages={39-47},
  abstract={Communications on hierarchical heterogeneous HPC platforms can be optimized based on topology information. For MPI, as a major programming tool for such platforms, a number of topology-aware implementations of collective operations have been proposed for optimal scheduling of messages. This approach improves communication performance and does not require to modify application source code. However, it is applicable to collective operations only and does not affect the parts of the application that are based on point-to-point exchanges. In this paper, we address the problem of efficient execution of data-parallel applications on interconnected clusters and present a topology-aware optimization that improves data partition by taking into account the entire communication flow of the application. This approach is also non-intrusive to the source code but application-specific. For illustration, we use parallel matrix multiplication, where the matrices are partitioned into irregular 2D rectangles assigned to different processors and arranged in columns, and the processors communicate over this partitioning vertically and horizontally. By rearranging the rectangles, we can minimize communications between different levels of the network hierarchy. Finding the optimal arrangement is NP-complete, therefore, we propose a heuristic based on evaluation of the communication flow on the given topology. We demonstrate the correctness and efficiency of the proposed approach by experimental results on multicore nodes and interconnected heterogeneous clusters.},
  keywords={},
  doi={10.1109/IPDPSW.2014.10},
  ISSN={},
  month={May},}
@INPROCEEDINGS{6969514,
  author={Ali, Md Mohsin and Southern, James and Strazdins, Peter and Harding, Brendan},
  booktitle={2014 IEEE International Parallel & Distributed Processing Symposium Workshops}, 
  title={Application Level Fault Recovery: Using Fault-Tolerant Open MPI in a PDE Solver}, 
  year={2014},
  volume={},
  number={},
  pages={1169-1178},
  abstract={A fault-tolerant version of Open Message Passing Interface (Open MPI), based on the draft User Level Failure Mitigation (ULFM) proposal of the MPI Forum's Fault Tolerance Working Group, is used to create fault-tolerant applications. This allows applications and libraries to design their own recovery methods and control them at the user level. However, only a limited amount of research work on user level failure recovery (including the implementation and performance evaluation of this prototype) has been carried out. This paper contributes a fault-tolerant implementation of an application solving 2D partial differential equations (PDEs) by means of a sparse grid combination technique which is capable of surviving multiple process failures caused by the faults. Our fault recovery involves reconstructing the faulty communicators without shrinking the global size by re-spawning failed MPI processes on the same physical processors where they were before the failure (for load balancing). It also involves restoring lost data from either exact check pointed data on disk, approximated data in memory (via an alternate sparse grid combination technique) or a near-exact copy of replicated data in memory. The experimental results show that the faulty communicator reconstruction time is currently large in the draft ULFM, especially for multiple process failures. They also show that the alternate combination technique has the lowest data recovery overhead, except on a system with very low disk write latency for which checkpointing has the lowest overhead. Furthermore, the errors due to the recovery of approximated data are within a factor of 10 in all cases, with the surprising result that the alternate combination technique being more accurate than the near-exact replication method. The contributed implementation details, including the analysis of the experimental results, of this paper will help application developers to resolve different issues of design and implementation of fault-tolerant applications by means of the Open MPI ULFM standard.},
  keywords={},
  doi={10.1109/IPDPSW.2014.132},
  ISSN={},
  month={May},}
@INPROCEEDINGS{6969479,
  author={Schmitt, Felix and Dietrich, Robert and Juckeland, Guido},
  booktitle={2014 IEEE International Parallel & Distributed Processing Symposium Workshops}, 
  title={Scalable Critical Path Analysis for Hybrid MPI-CUDA Applications}, 
  year={2014},
  volume={},
  number={},
  pages={908-915},
  abstract={Utilizing accelerators in heterogeneous systems is an established approach for designing peta-scale applications. Today, CUDA offers a rich programming interface for GPU accelerators but requires developers to incorporate several layers of parallelism on both CPU and GPU. From this increasing program complexity emerges the need for sophisticated performance tools. This work contributes by analyzing hybrid MPI-CUDA programs for their critical path, a property proven to effectively identify application bottlenecks. We developed a tool which constructs a dependency graph based on an execution trace and the inherent dependencies of the programming models CUDA and MPI. Thereafter, it detects wait-states and attributes blame to responsible activities. Together with the property of being on the critical path we can identify activities that are most viable for optimization. The developed approach has been demonstrated with suitable examples to be both scalable and correct. Furthermore, we establish a new categorization of CUDA inefficiency patterns ensuing from the dependencies between CUDA activities.},
  keywords={},
  doi={10.1109/IPDPSW.2014.103},
  ISSN={},
  month={May},}
@INPROCEEDINGS{6969521,
  author={Putigny, Bertrand and Ruelle, Benoit and Goglin, Brice},
  booktitle={2014 IEEE International Parallel & Distributed Processing Symposium Workshops}, 
  title={Analysis of MPI Shared-Memory Communication Performance from a Cache Coherence Perspective}, 
  year={2014},
  volume={},
  number={},
  pages={1238-1247},
  abstract={Shared memory MPI communication is an important part of the overall performance of parallel applications. However understanding the behavior of these data transfers is difficult because of the combined complexity of modern memory architectures with multiple levels of caches and complex cache coherence protocols, of MPI implementations, and of application needs. We analyze shared memory MPI communication from a cache coherence perspective through a new memory model. It captures the memory architecture characteristics with micro-benchmarks that exhibit the limitations of the memory accesses involved in the data transfer. We model the performance of intra-node communication without requiring complex analytical models. The advantage of the approach consists in not requiring deep knowledge of rarely documented hardware features such as caching policies or prefetchers that make modeling modern memory subsystems hardly feasible. Our qualitative analysis based on this result leads to a better understanding of shared memory communication performance for scientific computing. We then discuss some possible optimizations such as buffer reuse order, cache flushing, and non-temporal instructions that could be used by MPI implementers.},
  keywords={},
  doi={10.1109/IPDPSW.2014.139},
  ISSN={},
  month={May},}
@INPROCEEDINGS{6969411,
  author={Jose, Jithin and Hamidouche, Khaled and Zhang, Jie and Venkatesh, Akshay and Panda, Dhabaleswar K.},
  booktitle={2014 IEEE International Parallel & Distributed Processing Symposium Workshops}, 
  title={Optimizing Collective Communication in UPC}, 
  year={2014},
  volume={},
  number={},
  pages={361-370},
  abstract={Message Passing Interface (MPI) has been the defacto programming model for scientific parallel applications. However, data driven applications with irregular communication patterns are harder to implement using MPI. The Partitioned Global Address Space (PGAS) programming models present an alternative approach to improve programmability. PGAS languages like UPC are growing in popularity because of their ability to provide shared-memory programming model over distributed memory machines. However, since UPC is an emerging standard, it is unlikely that entire applications will be re-written with it. Instead, unified communication runtimes have paved the way for a new class of hybrid applications that can leverage the benefits of both MPI and PGAS models. Such unified runtimes need to be designed in a high performance, scalable manner to improve the performance of emerging hybrid applications. Collective communication primitives offer a flexible, portable way to implement group communication operations and are supported in both MPI and PGAS programming models. Owing to their advantages, they are also widely used across various scientific parallel applications. Over the years, MPI libraries have relied upon aggressive software- /hardware-based and kernel-assisted optimizations to deliver low communication latency for various collective operations. However, there is much room for improvement for collective operations in state-of-the-art, open-source implementations of UPC. In this paper, we address the challenges associated with improving the performance of collective primitives in UPC. Further, we also explore design alternatives to enable collective primitives in UPC to directly leverage the designs available in the MVAPICH2 MPI library. Our experimental evaluations show that our designs improve the performance of the UPC broadcast and all-gather operations, by 25X and 18X respectively for 128KB message at 2,048 processes. Our designs improve the performance of the UPC 2D-Heat kernel by up to 2X times at 2,048 processes, and NAS-FT benchmark by 12% at 256 processes.},
  keywords={},
  doi={10.1109/IPDPSW.2014.49},
  ISSN={},
  month={May},}
@INPROCEEDINGS{6970644,
  author={Rodríguez, Mónica and Cores, Iván and González, Patricia and Martín, María J.},
  booktitle={2014 IEEE 26th International Symposium on Computer Architecture and High Performance Computing}, 
  title={Improving an MPI Application-Level Migration Approach through Checkpoint File Splitting}, 
  year={2014},
  volume={},
  number={},
  pages={33-40},
  abstract={Traditionally used for load balancing, process migration has been gaining popularity in the fault tolerance context. Recently, checkpoint-based migration has been proposed to implement failure avoidance in MPI applications through the proactive migration of processes when impending failures are notified. However, the main drawback of checkpoint-based migration in these scenarios is its high I/0 cost, which may be unfeasible if the migration operation is not completed before the failure arises. To overcome this issue, this work proposes to split the checkpoint files of an application-level migration approach into multiple smaller files to overlap the different phase of the migration operation: checkpoint file writing in the terminating process, with data transferring through the network, and state file read and restart operations in the new spawned processes. The proposal has been tested using the MPI NAS Parallel Benchmarks. The experimental results show a significant reduction in the migration time.},
  keywords={},
  doi={10.1109/SBAC-PAD.2014.25},
  ISSN={1550-6533},
  month={Oct},}
@INPROCEEDINGS{6976562,
  author={Lei, Jinjiang and Qiu, Zongyan and Shao, Zhong},
  booktitle={2014 Theoretical Aspects of Software Engineering Conference}, 
  title={Trace-Based Temporal Verification for Message-Passing Programs}, 
  year={2014},
  volume={},
  number={},
  pages={10-17},
  abstract={Verification of concurrent systems is difficult because of their inherent nondeterminism. Modern verification requires clean specifications of inter-thread interferences and modular reasoning over separated components. But for message-passing models, a general reasoning system, which meets these standards, is still in demand. Here we propose a new logic for verifying distributed programs modularly. We concretize the concept of event traces to represent interactions among distributed agents, and constrain the environmental interferences by logical invariants. The verification is compositional w.r.t. agents as long as some inter-agent constraints are satisfied. Using this logic we successfully verified two classic message-passing algorithms: leader election and merging network.},
  keywords={},
  doi={10.1109/TASE.2014.14},
  ISSN={},
  month={Sep.},}
@INPROCEEDINGS{6984296,
  author={Hassani, Rashid and Chavan, Ganesh and Luksch, Peter},
  booktitle={2014 International Conference on Cyber-Enabled Distributed Computing and Knowledge Discovery}, 
  title={Optimization of Communication in MPI-Based Clusters}, 
  year={2014},
  volume={},
  number={},
  pages={143-149},
  abstract={Many parallel applications in high performance computing have to communicate via wide area network, e.g., in a grid or Cloud environment that spans multiple sites. Communication of links across wide area network slows down the application due to high latency and low bandwidth. Much of this overhead is due to the current implementations of the message passing interface standard. Efficient operation of such a distributed system requires that the characteristics of communication and synchronization across wide area network connections be addressed appropriately. This paper proposes a new approach to refine Open MPI communication scheme by using an optimized algorithm to improve the communication performance of high performance computing applications within the message passing interface protocol stack in wide area network environment. Our technique reduces unnecessary communications and synchronizations between processors with optimized communication-computation overlap. Our results emphasize the validity and effectiveness of our technique in which significant improvement over traditional Open MPI has been achieved.},
  keywords={},
  doi={10.1109/CyberC.2014.33},
  ISSN={},
  month={Oct},}
@INPROCEEDINGS{6986270,
  author={He, Weiwei and Wu, Jing and Zeng, Yaoyuan},
  booktitle={2014 IEEE International Conference on Signal Processing, Communications and Computing (ICSPCC)}, 
  title={Reserch on parallel computing of infrared small target detection}, 
  year={2014},
  volume={},
  number={},
  pages={632-635},
  abstract={Moving infrared small target detection is widely used in areas such as target surveillance, precise guidance, etc. It has a high demand for the real-time and the probability of detection. Multiband simultaneous detection can get a high detection probability, but it leads to substantial growth in computing time, which cannot meet the real-time requirement in practical applications. To solve this problem, this paper presents a parallel hierarchical approach based on MPI(Message Passing Interface) and OpenMP, which makes full use of the advantages of both message-passing model and shared storage model. It is based on the cluster system of multiprocessor nodes for testing. Experimental results show that, this parallel method can achieve a speedup of 7.8 compared with the serial method in the condition of the same detection probability. And its computational performance is also superior to the methods of pure OpenMP parallel and pure MPI parallel. This method has strong scalability.},
  keywords={},
  doi={10.1109/ICSPCC.2014.6986270},
  ISSN={},
  month={Aug},}
@INPROCEEDINGS{6986902,
  author={Mytsko, Evgeniy and Malchukov, Andrey},
  booktitle={2014 International Conference on Mechanical Engineering, Automation and Control Systems (MEACS)}, 
  title={Application of parallel computing technology OpenMP to search for the generator polynomials}, 
  year={2014},
  volume={},
  number={},
  pages={1-5},
  abstract={The paper deals with the application of parallel computing technology OpenMP to search for the generator polynomials. Forming the task of finding polynomials to create polynomial block codes is quite laborious. For example for generator polynomial, on which basis the fail-safe code (m = 32, t = 3), you need two weeks of continuous work program on the processor Intel XEON 5150 with a core clock of 2.66 GHz and RAM 1 GB. The article describes the search algorithm forming polynomials, which are constructed on the basis of codes more efficient than Bose-Chaudhuri-Hocquenghem codes. The article describes the ability to form the polynomials and analyzed in terms of the possibility of using parallel computing technology OpenMP. Computer experiment was delivered to compare the performance of software implementations with and without the OpenMP. Results supplied by the computer experiment to study the performance of sequential and parallelized implementations of the search algorithm polynomials showed that the usage of OpenMP technology allows under certain input parameters (m = 9, t = 2) to increase the speed of 20–24 times. On average, using of OpenMP algorithm enhances performance up to 3 times.},
  keywords={},
  doi={10.1109/MEACS.2014.6986902},
  ISSN={},
  month={Oct},}
@INPROCEEDINGS{6991059,
  author={Mytsko, Evgeniy and Malchukov, Andrey},
  booktitle={2014 9th International Forum on Strategic Technology (IFOST)}, 
  title={Adaptation of technology MPI and OpenMP to search for the generators polynomials}, 
  year={2014},
  volume={},
  number={},
  pages={5-8},
  abstract={The paper describes the usage of technologies of parallel and distributed computing OpenMP and MPI to find generator polynomials which is quite a tedious task. The description of the generator polynomials search algorithm which are constructed on the basis of codes more efficient than codes Bose-Chaudhuri — Hocquenghem. The algorithm of generator polynomials search was considered and analyzed in terms of the possibility of using technologies of parallel and distributed computing. The computer program of the generator polynomials search with the technology of parallel and distributed computing OpenMP and MPI was described. As input parameters, the values of : m — length of the information block of messages and t — the multiplicity of correctable errors. Computer experiment was delivered to compare the performance of software implementations with and without the application of the above technologies. Results supplied by the computer experiment to study the performance of sequential and parallelized implementations of the generator polynomials search algorithm showed that the use of technology in conjunction with MPI and OpenMP greatly accelerates generator polynomials search. Thus, using 20 cores of Intel XEON 5150 processor for averaging the acceleration input parameters studied (m from 8 to 24, and t = 4) was 2231 %.},
  keywords={},
  doi={10.1109/IFOST.2014.6991059},
  ISSN={},
  month={Oct},}
@INPROCEEDINGS{6991661,
  author={Zhou Zhifeng and Albert Dong and Yuan Qincheng and Huang Hongyuan},
  booktitle={2014 China International Conference on Electricity Distribution (CICED)}, 
  title={Communication research based on of Distributed intelligent Feeder Automation System of the distribution network}, 
  year={2014},
  volume={},
  number={},
  pages={1-4},
  abstract={In basic research on the self-healing control technology of Domestic and international distribution network, Proposed several solutions of distribution network self-healing technology, and pointed out the advantages and problems of the various solutions at present. With economic development. Reliability requirements of distribution network have become increasingly demanding. Using intelligent distributed Feeder Automation System by peer to peer communications between the intelligent terminal, and distributed intelligent control decisions, to achieve rapid fault isolation in distribution line. In the environment that Smart Grid is rapidly building, communication network of Distribution network gradually improved. Establish an efficient strong real-time communication system provide favorable conditions of Rapid Self-healing. This paper presents three communication program. based on reliable communication of connection-oriented TCP/IP based on the multicast communication of UDP and publish/subscribe communication of GOOSE protocol and gives a comparative for the three communication program. Systematically describe implementation of the three communication scheme used in intelligent distribution automation system, elaborated system modeling communication scheme and design ideas of GOOSE communication, and provides a solution of GOOSE to implement a typical fault isolation process. We test and verify the three communicate programs on power PC hardware platforms, build on a network test environment in a lab environment, provides real-time and reliability communication test result. Based on the above analysis and verification, GOOSE protocol-based communications solutions has certain advantages in communication efficiency, timeliness and versatility.},
  keywords={},
  doi={10.1109/CICED.2014.6991661},
  ISSN={2161-749X},
  month={Sep.},}
@INPROCEEDINGS{6999067,
  author={Zhu, Lin and Guo, Yucheng},
  booktitle={2014 13th International Symposium on Distributed Computing and Applications to Business, Engineering and Science}, 
  title={A Database Middleware Architecture for MPI-based Cloud Platform}, 
  year={2014},
  volume={},
  number={},
  pages={107-110},
  abstract={To solve the poor performance of existing cloud platforms in high-performance computing, our research team developed a high-performance cloud computing platform based on MPI. As a cloud platform, massive data storage is a key technology. In the research, we mainly studied how to build a MPI cloud platform that supports massive data storage, and implement a distributed cluster constructed by MySQL. This paper introduces the feature of MPI cloud platform, how to build the cloud platform database and the implementation of related SQL operations on the database. Based on this, we test the related operations in the database, and elaborate the shortcomings and challenges of the distributed database in this cloud computing platform.},
  keywords={},
  doi={10.1109/DCABES.2014.25},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{7013064,
  author={Park, Jongsoo and Smelyanskiy, Mikhail and Vaidyanathan, Karthikeyan and Heinecke, Alexander and Kalamkar, Dhiraj D. and Liu, Xing and Patwary, Md. Mosotofa Ali and Lu, Yutong and Dubey, Pradeep},
  booktitle={SC '14: Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis}, 
  title={Efficient Shared-Memory Implementation of High-Performance Conjugate Gradient Benchmark and its Application to Unstructured Matrices}, 
  year={2014},
  volume={},
  number={},
  pages={945-955},
  abstract={A new sparse high performance conjugate gradient benchmark (HPCG) has been recently released to address challenges in the design of sparse linear solvers for the next generation extreme-scale computing systems. Key computation, data access, and communication pattern in HPCG represent building blocks commonly found in today's HPC applications. While it is a well known challenge to efficiently parallelize Gauss-Seidel smoother, the most time-consuming kernel in HPCG, our algorithmic and architecture-aware optimizations deliver 95% and 68% of the achievable bandwidth on Xeon and Xeon Phi, respectively. Based on available parallelism, our Xeon Phi shared-memory implementation of Gauss-Seidel smoother selectively applies block multi-color reordering. Combined with MPI parallelization, our implementation balances parallelism, data access locality, CG convergence rate, and communication overhead. Our implementation achieved 580 TFLOPS (82% parallelization efficiency) on Tianhe-2 system, ranking first on the most recent HPCG list in July 2014. In addition, we demonstrate that our optimizations not only benefit HPCG original dataset, which is based on structured 3D grid, but also a wide range of unstructured matrices.},
  keywords={},
  doi={10.1109/SC.2014.82},
  ISSN={2167-4337},
  month={Nov},}
@INPROCEEDINGS{7013006,
  author={McLay, Robert and James, Doug and Liu, Si and Cazes, John and Barth, William},
  booktitle={SC '14: Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis}, 
  title={A User-Friendly Approach for Tuning Parallel File Operations}, 
  year={2014},
  volume={},
  number={},
  pages={229-236},
  abstract={The Lustre file system provides high aggregated I/O bandwidth and is in widespread use throughout the HPC community. Here we report on work (1) developing a model for understanding collective parallel MPI write operations on Lustre, and (2) producing a library that optimizes parallel write performance in a user-friendly way. We note that a system's default stripe count is rarely a good choice for parallel I/O, and that performance depends on a delicate balance between the number of stripes and the actual (not requested) number of collective writers. Unfortunate combinations of these parameters may degrade performance considerably. For the programmer, however, it's all about the stripe count: an informed choice of this single parameter allows MPI to assign writers in a way that achieves near-optimal performance. We offer recommendations for those who wish to tune performance manually and describe the easy-to-use T3PIO library that manages the tuning automatically.},
  keywords={},
  doi={10.1109/SC.2014.24},
  ISSN={2167-4337},
  month={Nov},}
@INPROCEEDINGS{7013028,
  author={Chen, Zhezhe and Dinan, James and Tang, Zhen and Balaji, Pavan and Zhong, Hua and Wei, Jun and Huang, Tao and Qin, Feng},
  booktitle={SC '14: Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis}, 
  title={MC-Checker: Detecting Memory Consistency Errors in MPI One-Sided Applications}, 
  year={2014},
  volume={},
  number={},
  pages={499-510},
  abstract={One-sided communication decouples data movement and synchronization by providing support for asynchronous reads and updates of distributed shared data. While such interfaces can be extremely efficient, they also impose challenges in properly performing asynchronous accesses to shared data. This paper presents MC-Checker, a new tool that detects memory consistency errors in MPI one-sided applications. MCChecker first performs online instrumentation and captures relevant dynamic events, such as one-sided communications and load/store operations. MC-Checker then performs analysis to detect memory consistency errors. When found, errors are reported along with useful diagnostic information. Experiments indicate that MC-Checker is effective at detecting and diagnosing memory consistency bugs in MPI one-sided applications, with low overhead, ranging from 24.6% to 71.1%, with an average of 45.2%.},
  keywords={},
  doi={10.1109/SC.2014.46},
  ISSN={2167-4337},
  month={Nov},}
@INPROCEEDINGS{7016383,
  author={Gioiosa, Roberto and Kerbyson, Darren J. and Hoisie, Adolfy},
  booktitle={2014 Energy Efficient Supercomputing Workshop}, 
  title={Evaluating Performance and Power Efficiency of Scientific Applications on Multi-threaded Systems}, 
  year={2014},
  volume={},
  number={},
  pages={11-20},
  abstract={The power and energy walls are changing the way users utilize supercomputers: Time-to-completion is not the only important goal but other metrics, such as the energy required to solve a problem or the power efficiency, are becoming as important as performance. This shift towards power- and energy-aware computing is expected to continue in the exascale era, thus, understanding the performance, power and energy implications of different hardware configurations is of paramount importance. In this paper we analyze the performance, power efficiency and energy consumption of scientific applications programmed in MPI, OpenMP and MPI+OpenMP on two different architectures that have take different approaches to limit power consumption, IBM POWER7+ and AMD Interlagos. We compare the scalability, power efficiency and energy consumption of distributed and shared memory versions of each applications and analyze performance and bottlenecks of different combinations of MPI tasks/OpenMP threads. Our results show that, although shared memory programming models usually provide lower synchronization cost, achieving the highest performance/efficiency requires a combination for MPI tasks/OpenMP threads that is dependent on the underlying architecture and takes into consideration how hardware resources are distributed among the computing elements. More importantly, our results show that the "best configuration" strongly depends on the particular target metric.},
  keywords={},
  doi={10.1109/E2SC.2014.15},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{7016351,
  author={Gardner, William B. and Carter, John D.},
  booktitle={2014 Workshop on Education for High Performance Computing}, 
  title={Using the Pilot Library to Teach Message-Passing Programming}, 
  year={2014},
  volume={},
  number={},
  pages={1-8},
  abstract={Message-passing is the staple of HPC codes, and MPI has long occupied the place of HPC's default programming paradigm, thus it would seem to be the natural choice for instructing undergraduates. Nonetheless, MPI is a low-level API, complex and tricky to use, with many pitfalls awaiting the inexperienced. The Pilot library was invented as an alternative HPC programming model for C and Fortran. Pilot-based codes, using a process/channel application architecture borrowed from Communicating Sequential Processes (CSP), can avoid some categories of errors, and the Pilot library with its integrated deadlock detector provides extensive checking and diagnosis of usage problems, which is especially important for students running cluster programs in their typical low-visibility environment with limited debugging tools. This paper gives an overview of programming in Pilot, with its compact API of point-to-point and collective operations. It explains reasons for preferring it as an introductory message-passing technique, describes free resources available to the instructor, and relates experiences of using Pilot with undergraduates over five years, including student reactions. Pilot is now available as free and open source.},
  keywords={},
  doi={10.1109/EduHPC.2014.14},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{7016355,
  author={Burkhart, Helmar and Guerrera, Danilo and Maffia, Antonio},
  booktitle={2014 Workshop on Education for High Performance Computing}, 
  title={Trusted High-Performance Computing in the Classroom}, 
  year={2014},
  volume={},
  number={},
  pages={27-33},
  abstract={A well-designed high-performance computing (HPC) course not only presents theoretical parallelism concepts but also includes practical work on parallel systems. Today's machine models are diverse and as a consequence multiple programming models exist. The challenge for HPC course lecturers is to decide what to include and what to exclude, respectively. We have experience in teaching HPC in a multi-paradigm style. The practical course parts include message-passing programming using MPI, directive-based shared memory programming using OpenMP, partitioned global address space based programming using Chapel, and domain-specific programming using a high-level framework. If these models are taught in an isolated mode, students would have problems in assessing the strengths and weaknessesof the approaches presented. We propose a projectbased approach which introduces a specific problem to be solved (in our case a stencil computation) and asks for solutions using the programming approaches introduced. Our course has been successfully taught several times but a major problem has always been checking the individual student solutions, especially to decide which performance results reported one can trust. In order to overcome these deficiencies, we have built a pedagogical tool which enhances the trust in students' work. In the paper we present the infrastructure and tools that make student experiments easily reproducible by lecturers. We introduce a taxonomy for general benchmark experiments, describe the distributed architecture of our development and analysis environment, and, as a case study, discuss performance experiments when solving a stencil problem in multiple programming models.},
  keywords={},
  doi={10.1109/EduHPC.2014.13},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{7020144,
  author={Inostrosa-Psijas, Alonso and Wainer, Gabriel and Gil-Costa, Veronica and Marin, Mauricio},
  booktitle={Proceedings of the Winter Simulation Conference 2014}, 
  title={DEVS modeling of large scale Web Search Engines}, 
  year={2014},
  volume={},
  number={},
  pages={3060-3071},
  abstract={Modeling large scale Web Search Engines (WSEs) is a complex task. It involves many issues such as representing user's behavior, query traffic, several strategies and heuristics to improve query response time, etc. Typically, WSEs are composed of several services deployed in data centers, which must interact to get the best document results to user queries. Additionally, hardware specification like multithreading and network communications have to be taken into account. In this paper, we propose to model a servicebased WSE using the Discrete Event System Specification (DEVS) formalism, which is one of the most powerful methodologies for discrete event systems. We validate our proposed model against an actual MPI implementation of the WSE and a process oriented simulation. We evaluate the accuracy of the proposed model by evaluating metrics such as query throughput and we show that there is no relevant differences, just small fluctuations of less than 4%.},
  keywords={},
  doi={10.1109/WSC.2014.7020144},
  ISSN={1558-4305},
  month={Dec},}
@INPROCEEDINGS{7020148,
  author={Mubarak, Misbah and Carothers, Christopher D. and Ross, Robert B. and Carns, Philip},
  booktitle={Proceedings of the Winter Simulation Conference 2014}, 
  title={Using massively parallel simulation for mpi collective communication modeling in extreme-scale networks}, 
  year={2014},
  volume={},
  number={},
  pages={3107-3118},
  abstract={MPI collective operations are a critical and frequently used part of most MPI-based large-scale scientific applications. In previous work, we have enabled the Rensselaer Optimistic Simulation System (ROSS) to predict the performance of MPI point-to-point messaging on high-fidelity million-node network simulations of torus and dragonfly interconnects. The main contribution of this work is an extension of these torus and dragonfly network models to support MPI collective communication operations using the optimistic event scheduling capability of ROSS. We demonstrate that both small- and large-scale ROSS collective communication models can execute efficiency on massively parallel architectures. We validate the results of our collective communication model against the measurements from IBM Blue Gene/Q and Cray XC30 platforms using a data-driven approach on our network simulations. We also perform experiments to explore the impact of tree degree on the performance of collective communication operations in large-scale network models.},
  keywords={},
  doi={10.1109/WSC.2014.7020148},
  ISSN={1558-4305},
  month={Dec},}
@INPROCEEDINGS{7018164,
  author={Bland, Wesley and Raffenetti, Kenneth and Balaji, Pavan},
  booktitle={2014 Workshop on Exascale MPI at Supercomputing Conference}, 
  title={Simplifying the Recovery Model of User-Level Failure Mitigation}, 
  year={2014},
  volume={},
  number={},
  pages={20-25},
  abstract={As resilience research in high-performance computing has matured, so too have the tools, libraries, and languages that result from it. The Message Passing Interface (MPI) Forum is considering the addition of fault tolerance to a future version of the MPI standard, and a new chapter called User-Level Failure Mitigation (ULFM) has been proposed to fill this need. However, as ULFM usage has become more widespread, many potential users are concerned about its complexity and the need to rewrite existing codes. In this paper, we present a usage model that is similar to the usage already common in existing codes but that does not require the user to restart the application (thereby incurring the costs of re-entering the batch queue, startup costs, etc.). We use a new implementation of ULFM in MPICH, a popular open source MPI implementation, and demonstrate the ULFM usage using the Monte Carlo Communication Kernel, a proxy-app developed by the Center for Exascale Simulation of Advanced Reactors. Results show that the approach used incurs a level of intrusiveness into the code similar to that of existing checkpoint/restart models, but with less overhead.},
  keywords={},
  doi={10.1109/ExaMPI.2014.4},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{7018162,
  author={Hammond, Jeff R. and Schäfer, Andreas and Latham, Rob},
  booktitle={2014 Workshop on Exascale MPI at Supercomputing Conference}, 
  title={To INT_MAX... and Beyond! Exploring Large-Count Support in MPI}, 
  year={2014},
  volume={},
  number={},
  pages={1-8},
  abstract={In order to describe a structured region of memory, the routines in the MPI standard use a (count, datatype) pair. The C specification for this convention uses an int type for the count. Since C int types are nearly always 32 bits large and signed, counting more than 231 elements poses a challenge. Instead of changing the existing MPI routines, and all consumers of those routines, the MPI Forum asserts that users can build up large datatypes from smaller types. To evaluate this hypothesis and to provide a user-friendly solution to the large-count issue, we have developed BigMPI, a library on top of MPI that maps large-count MPI-like functions to MPI-3 standard features. BigMPI demonstrates a way to perform such a construction, reveals shortcomings of the MPI standard, and uncovers bugs in MPI implementations.},
  keywords={},
  doi={10.1109/ExaMPI.2014.5},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{7023858,
  author={Shimosaka, Takenori and Murai, Hitoshi and Sato, Mitsuhisa},
  booktitle={2014 IEEE 17th International Conference on Computational Science and Engineering}, 
  title={A Design of a Communication Library between Multiple Sets of MPI Processes for MPMD}, 
  year={2014},
  volume={},
  number={},
  pages={1886-1893},
  abstract={An MPMD programming model is widely used as a master-worker program or a coupling program for multiple physical models. To utilize recent high-end parallel computers having more than several thousand nodes, we propose the communication library MPMPI between different multiple sets of MPI processes in the MPMD model. In particular, we present MPMPI interfaces that include interfaces for a PGAS language and the basic performance of MPMPI functions. As benchmark programs of the MPMPI library, we evaluated the performance of a master-worker program and a weak coupling program. As a result, we found that Pack/Unpack has a large influence on the performance of MPMPI functions, the interface of MPMPI functions can easily be used in these benchmark programs written in Xcalable MP PGAS language, and the performances of the master-worker and weak coupling benchmark programs using the basic MPMPI functions are practical under the conditions of this paper.},
  keywords={},
  doi={10.1109/CSE.2014.346},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{7030721,
  author={Panigrahi, Pinak and Kanchiraju, Sriram and Srinivasan, Ashok and Baruah, Pallav Kumar and Sudheer, C D},
  booktitle={2014 International Conference on Parallel, Distributed and Grid Computing}, 
  title={Optimizing MPI collectives on intel MIC through effective use of cache}, 
  year={2014},
  volume={},
  number={},
  pages={88-93},
  abstract={The Intel MIC architecture, implemented in the Xeon Phi coprocessor, is targeted at highly parallel applications. In order to exploit it, one needs to make full use of simultaneous multi-threading, which permits four simultaneous threads per core. Our results also show that distributed tag directories can be a greater bottleneck than the ring for small messages when multiple threads access the same cache line. Careful design of algorithms and implementations based on these results can yield substantial performance improvement. We demonstrate these ideas by optimizing MPI collective calls. We obtain a speedup of 9x on barrier and a speed-up of 10x on broadcast, when compared with Intel's MPI implementation. We also show the usefulness of our collectives in two realistic codes: particle transport and the load balancing phase in QMC. Another important contribution of our work lies in showing that optimization techniques - such as double buffering - used with programmer controlled caches are also useful on MIC. These results can help optimize other communication intensive codes running on MIC.},
  keywords={},
  doi={10.1109/PDGC.2014.7030721},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{7034379,
  author={Omerasevic, Damir and Behlilovic, Narcis and Mrdovic, Sasa},
  booktitle={2014 22nd Telecommunications Forum Telfor (TELFOR)}, 
  title={Secure message exchange protocol for Smart Grids}, 
  year={2014},
  volume={},
  number={},
  pages={158-161},
  abstract={Smart Grid (SG) communication become very hot topic for smart, intelligent and distributed transmission systems for electric power. However, security issues are still open and this is one of main concerns to the deployment of SG. In order to cope with this challenging concern, we propose secure message exchange protocol in this paper, for secure communication in SG system. Particularly, in the proposed protocol, we pay attention to robustness and resistance of exchanged messages to external noise, with a certain level of self-correction. Robustness and resistance to external noise is due to Quick Response (QR) code properties.},
  keywords={},
  doi={10.1109/TELFOR.2014.7034379},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{7036677,
  author={Azeem, Basma Abdel and Helal, Manal},
  booktitle={2014 9th International Conference on Informatics and Systems}, 
  title={Performance evaluation of checkpoint/restart techniques: For MPI applications on Amazon cloud}, 
  year={2014},
  volume={},
  number={},
  pages={PDC-49-PDC-57},
  abstract={Distributed applications running on a large cluster environment, such as the cloud instances will have shorter execution time. However, the application might suffer from sudden termination due to unpredicted computing node failures, thus loosing the whole computation. Checkpoint/restart is a fault tolerance technique used to solve this problem. In this work we evaluated the performance of two of the most commonly used checkpoint/restart techniques (Distributed Multithreaded Checkpointing (DMTCP) and Berkeley Lab Checkpoint/Restart library (BLCR) integrated into the OpenMPI framework). We aimed to test their validity and evaluate their performance in both local and Amazon Elastic Compute Cloud (EC2) environments. The experiments were conducted on Amazon EC2 as a well-known proprietary cloud computing service provider. Results obtained were reported and compared to evaluate checkpoint and restart time values, data scalability and compute processes scalability. The findings proved that DMTCP performs better than BLCR for checkpoint and restart speed, data scalability and compute processes scalability experiments.},
  keywords={},
  doi={10.1109/INFOS.2014.7036677},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{7040973,
  author={Wickramaarachchi, Charith and Frincu, Marc and Small, Patrick and Prasanna, Viktor K.},
  booktitle={2014 IEEE High Performance Extreme Computing Conference (HPEC)}, 
  title={Fast parallel algorithm for unfolding of communities in large graphs}, 
  year={2014},
  volume={},
  number={},
  pages={1-6},
  abstract={Detecting community structures in graphs is a well studied problem in graph data analytics. Unprecedented growth in graph structured data due to the development of the world wide web and social networks in the past decade emphasizes the need for fast graph data analytics techniques. In this paper we present a simple yet efficient approach to detect communities in large scale graphs by modifying the sequential Louvain algorithm for community detection. The proposed distributed memory parallel algorithm targets the costly first iteration of the initial method by parallelizing it. Experimental results on a MPI setup with 128 parallel processes shows that up to ≈5× performance improvement is achieved as compared to the sequential version while not compromising the correctness of the final result.},
  keywords={},
  doi={10.1109/HPEC.2014.7040973},
  ISSN={},
  month={Sep.},}
@INPROCEEDINGS{7039642,
  author={Ntakou, Elli and Caramanis, Michael},
  booktitle={53rd IEEE Conference on Decision and Control}, 
  title={Distribution network electricity market clearing: Parallelized PMP algorithms with minimal coordination}, 
  year={2014},
  volume={},
  number={},
  pages={1687-1694},
  abstract={The socially optimal power market clearing problem with diverse, complex-utility-structure participants at the distribution level, poses computational challenges that are exacerbated by the associated non-convex load flow constraints. We investigate variations and extensions of Proximal Message Passing algorithms proposed in the literature and implemented on similar, though simpler, social welfare function instantiations. Numerical results demonstrate that (i) in comparison to solving a computationally demanding, yet exact, centralized market clearing problem, significant computational improvements are possible with the proposed PMP algorithm extensions, (ii) comparison to the benchmark results obtained by solving the centralized formulation reveals that excellent accuracy is attainable by the PMP algorithms and (iii) in comparison to the PMP algorithms existing in the literature, the proposed extension reduces significantly the communication requirements for sub-problem coordination and convergence verification and enables faster converging asynchronous sub-problem iterations.},
  keywords={},
  doi={10.1109/CDC.2014.7039642},
  ISSN={0191-2216},
  month={Dec},}
@INPROCEEDINGS{7037698,
  author={Chakthranont, Nuttapong and Khunphet, Phonlawat and Takano, Ryousei and Ikegami, Tsutomu},
  booktitle={2014 IEEE 6th International Conference on Cloud Computing Technology and Science}, 
  title={Exploring the Performance Impact of Virtualization on an HPC Cloud}, 
  year={2014},
  volume={},
  number={},
  pages={426-432},
  abstract={The feasibility of the cloud computing paradigm is examined from the High Performance Computing (HPC) viewpoint. The impact of virtualization is evaluated on our latest private cloud, the AIST Super Green Cloud, which provides elastic virtual clusters interconnected by Infini Band. Performance is measured by using typical HPC benchmark programs, both on physical and virtual cluster computing clusters. The results of the micro benchmarks indicate that the virtual clusters suffer from the scalability issue on almost all MPI collective functions. The relative performance gradually becomes worse as the number of nodes increases. On the other hand, the benchmarks based on actual applications, including LINPACK, OpenMX, and Graph 500, show that the virtualization overhead is about 5% even when the number of nodes increase to 128. This observation leads to our optimistic conclusions on the feasibility of the HPC Cloud.},
  keywords={},
  doi={10.1109/CloudCom.2014.71},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{7046154,
  author={Schömig, Milan and Neuhäuser, David and Seidler, Ralf and Bücker, H. Martin},
  booktitle={2014 International Conference on Mathematics and Computers in Sciences and in Industry}, 
  title={Benchmarking Different MapReduce Implementations for Computer-Aided Hardware Development}, 
  year={2014},
  volume={},
  number={},
  pages={15-21},
  abstract={In the design of fast arithmetic circuits, the two's complement number representation can be alternatively replaced by a signed digit number representation. Compared to standard full adders used in two's complement arithmetic, signed digit adder cells offer the potential for improved performance. Designing an efficient signed digit adder cell leads to the problem of analyzing 2 to the power of 44 truth tables originating from different signed digit encodings. Since different digit encodings can produce identical truth tables, it is favorable to reduce this large number of truth tables by identifying identical ones. We introduce a novel approach for the solution of this problem using the MapReduce programming model. We take a step towards solving this problem using three different implementations of MapReduce (Hadoop, Disco, and MR-MPI) and compare their performance on an Opteron-based cluster using up to 64 physical cores.},
  keywords={},
  doi={10.1109/MCSI.2014.57},
  ISSN={},
  month={Sep.},}
@INPROCEEDINGS{7054382,
  author={Dijia, Xu and Hongxia, Bie and Jian, Zheng and Chunyang, Lei},
  booktitle={9th International Conference on Communications and Networking in China}, 
  title={Poster: FPGA based implementation of overlapped QC-LDPC decoder with limited resources}, 
  year={2014},
  volume={},
  number={},
  pages={652-653},
  abstract={In this paper, we propose a simplified architecture based on overlapped message passing (OMP) for QC-LDPC decoders with Normalized Minimum Sum (NMS) algorithm, aiming to reduce decoding latency with as less additional resources as possible. According to the OMP architecture, the two stages of NMS, namely check node process and variable node process, could be overlapped. Hence, overall decoding latency is reduced and hardware utilization efficiency (HUE) is improved. Based on the proposed OMP architecture, two irregular QC-LDPC decoders are implemented in serial and partly-parallel styles in FPGA respectively. Experimental results show that, achieving the same decoding performance, the serial QC-LDPC decoder with proposed OMP architecture can reduce latency by 39.1% compared with that of the decoder with TPMP(Two Stages Message Passing) architecture, and the latency reduction of partly-parallel decoder varies with degrees of parallelism.},
  keywords={},
  doi={10.1109/CHINACOM.2014.7054382},
  ISSN={},
  month={Aug},}
@INPROCEEDINGS{7056590,
  author={Serres, Olivier and Kayi, Abdullah and Anbar, Ahmad and El Ghazawi, Tarek},
  booktitle={2014 IEEE Intl Conf on High Performance Computing and Communications, 2014 IEEE 6th Intl Symp on Cyberspace Safety and Security, 2014 IEEE 11th Intl Conf on Embedded Software and Syst (HPCC,CSS,ICESS)}, 
  title={Enabling PGAS Productivity with Hardware Support for Shared Address Mapping: A UPC Case Study}, 
  year={2014},
  volume={},
  number={},
  pages={1-10},
  abstract={The Partitioned Global Address Space (PGAS) programming model strikes a balance between the locality-aware, but explicit, message-passing model (e.g. MPI) and the easy-to-use, but locality-agnostic, shared memory model (e.g. OpenMP). However, the PGAS rich memory model comes at a performance cost which can hinder its potential for scalability and performance. To contain this overhead and achieve full performance, compiler optimizations may not be sufficient and manual optimizations are typically added. This, however, can severely limit the productivity advantage. Such optimizations are usually targeted at reducing address translation overheads for shared data structures. This paper proposes a hardware architectural support for PGAS, which allows the processor to efficiently handle shared addresses. This eliminates the need for such hand-tuning, while maintaining the performance and productivity of PGAS languages. We propose to avail this hardware support to compilers by introducing new instructions to efficiently access and traverse the PGAS memory space. A prototype compiler is realized by extending the Berkeley Unified Parallel C (UPC) compiler. It allows unmodified code to use the new instructions without the user intervention, thereby creating a real productive programming environment. Two different implementations of the system are realized: the first is implemented using the full system simulator Gem5, which allows the evaluation of the performance gain. The second is implemented using a soft core processor Leon3 on an FPGA to verify the implement ability and to parameterize the cost of the new hardware and its instructions. The new instructions show promising results for the NAS Parallel Benchmarks implemented in UPC. A speedup of up to 5.5x is demonstrated for unmodified codes. Unmodified code performance using this hardware was shown to also surpass the performance of manually optimized code by up to 10%.},
  keywords={},
  doi={10.1109/HPCC.2014.8},
  ISSN={},
  month={Aug},}
@INPROCEEDINGS{7056852,
  author={Li, Ce and Chen, Wenbo and Zhang, Yang and Bai, Qifeng},
  booktitle={2014 IEEE Intl Conf on High Performance Computing and Communications, 2014 IEEE 6th Intl Symp on Cyberspace Safety and Security, 2014 IEEE 11th Intl Conf on Embedded Software and Syst (HPCC,CSS,ICESS)}, 
  title={Analyses on Performance of Gromacs in Hybrid MPI+OpenMP+CUDA Cluster}, 
  year={2014},
  volume={},
  number={},
  pages={904-911},
  abstract={The Tri-Level parallel programming pattern of MPI+OpenMP+CUDA, which enables better speedup for applications on popular multi-core architecture cluster, is increasingly admired by research institutions and companies. The interaction of particles of molecular dynamics simulation needs extensive calculation, which will also increases with the extension of system. Therefore higher performance for the computing capability and storage ability of current high performance computer is required. As one of main softwares of molecular dynamics simulation, GROMACS can be used for the simulation of hundreds of or even millions of atoms. Based on this kind of hybrid parallel programming pattern, the latest version of GROMACS has higher operation efficiency and shorter simulation time. In this paper, we take advantage of two different sizes of protein simulation system as the data of GROMACS for the molecular simulation of different parallel granularity on mixed cluster which is based on Intel Xeon5650 and NVIDIA C2050. By the result of experiment, we have obtained the best mechanism of hybird CPU-GPU cluster and analyzed the advantage of MPI+OpenMP+CUDA hybrid parallel programming pattern. In the end, we compared GROMACS4.6 with GROMACS4.5. The results of the test also provide a reference for scientists who work on building large-scale molecular dynamics simulation platform and observe the molecular dynamics simulation.},
  keywords={},
  doi={10.1109/HPCC.2014.157},
  ISSN={},
  month={Aug},}

@INPROCEEDINGS{7073450,
  author={Liu, Hao and Yan, Yuehao and Wang, Junhai},
  booktitle={2014 11th International Computer Conference on Wavelet Actiev Media Technology and Information Processing(ICCWAMTIP)}, 
  title={A fast algorithm of compressed sensing}, 
  year={2014},
  volume={},
  number={},
  pages={463-467},
  abstract={After studying the compressed sensing theory and its main reconstruction algorithm-Matching Pursuit (MP) algorithm, this paper proposes a new approach to improve the speed of MP algorithm, and it describes how to build a Beowulf parallel computing system with 8 PCs. Its parallel computations is implemented by Message-Passing-Interface(MPI), and a 100Mb/s high speed Ethernet network interconnects all PCs. Test is made using parallel computing program to measure the parallel efficiency of the system, results show that this approach can reduce the MP algorithm computing time-cost form 78 minutes with a PC to 11 minutes with 8 PCs.},
  keywords={},
  doi={10.1109/ICCWAMTIP.2014.7073450},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{7091301,
  author={Fu, Xianjin and Chen, Zhenbang and Huang, Chun and Dong, Wei and Wang, Ji},
  booktitle={2014 21st Asia-Pacific Software Engineering Conference}, 
  title={Synchronization Error Detection of MPI Programs by Symbolic Execution}, 
  year={2014},
  volume={1},
  number={},
  pages={127-134},
  abstract={Asynchrony based overlapping of computation and communication is commonly used in MPI applications. However, this overlapping introduces synchronization errors frequently in asynchronous MPI programming. In this paper, we propose a symbolic execution based method for detecting input-related synchronization errors. The path space of an MPI program is systematically explored, and the related operations of the synchronization errors in the program are checked specifically. In addition, two optimizations are proposed to improve the efficiency. We have implemented our method as a prototype tool based on the symbolic executor Cloud9. The results of the extensive experiments indicate the effectiveness of our method.},
  keywords={},
  doi={10.1109/APSEC.2014.28},
  ISSN={1530-1362},
  month={Dec},}
@INPROCEEDINGS{7097360,
  author={Changjian Wang and Yuxing Peng and Pengfei You and Mingxing Tang and Minghao Hu and Dongsheng Li and Youguo Li},
  booktitle={17th IEEE International Multi Topic Conference 2014}, 
  title={MEX: A distributed computing framework for executable programs}, 
  year={2014},
  volume={},
  number={},
  pages={326-332},
  abstract={Parallel computing can improve the data-processing efficiency significantly. However, the traditional approaches, such as MPI and MapReduce, need to program in the special environment. In this paper, a new distributed computing framework named MEX is proposed. Users just provides the input files and the name of an executable program to MEX. Then MEX will automatically process these files on a cluster of machines with the executable program. The MEX platform has been designed and implemented based on MapReduce and some key problems are addressed. An improved map function are designed for the start-up of the executable program. To support the improved map function, a data-conversion mechanism is added into MEX which generates the command texts as the parameter of the map function. A process-feedback mechanism is proposed for the fault-tolerance of the executable program. The mechanism also supports the synchronous execution between the map task and the executable program, which can avoid too many processes to be started on the same worknode. Comprehensive experiments are performed to verify the effectiveness of the MEX framework. According to the results, more computing worknodes can result in less job runtime in MEX. When 100 virtual machines are used for an OCR job with 1000 images in 400 dpi, the runtime is reduced 88.6% compared to a single machine.},
  keywords={},
  doi={10.1109/INMIC.2014.7097360},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{7097447,
  author={Kazarov, Andrei and Caprini, Mihai and Kolos, Serguei and Miotto, Giovanna Lehmann and Soloviev, Igor},
  booktitle={2014 19th IEEE-NPSS Real Time Conference}, 
  title={A scalable and reliable message transport service for the ATLAS Trigger and Data Acquisition system}, 
  year={2014},
  volume={},
  number={},
  pages={1-4},
  abstract={The ATLAS Trigger and Data Acquisition (TDAQ) is a large distributed computing system composed of several thousands of interconnected computers and tens of thousands applications. During a run, TDAQ applications produce a lot of control and information messages with variable rates, addressed to TDAQ operators or to other applications. Reliable, fast and accurate delivery of the messages is important for the functioning of the whole TDAQ system. The Message Transport Service (MTS) provides facilities for the reliable transport, the filtering and the routing of the messages, based on the publish-subscribe-notify communication pattern with content-based message filtering.During the ongoing LHC shutdown, MTS was re-implemented, taking into account important requirements like reliability, scalability and performance, handling of slow subscribers case and also simplicity of the design and the implementation. MTS uses CORBA middleware, a common layer for TDAQ infrastructure, and provides sending/subscribing APIs in the Java and C++ programming languages. The paper presents the design and the implementation details of MTS, as well as the results of performance and scalability tests executed on a computing farm with an amount of workers and working conditions which reproduced a realistic TDAQ environment during ATLAS operations.},
  keywords={},
  doi={10.1109/RTC.2014.7097447},
  ISSN={},
  month={May},}
@INPROCEEDINGS{7103455,
  author={Protze, Joachim and Hilbrich, Tobias and Schulz, Martin and de Supinski, Bronis R. and Nagel, Wolfgang E. and Mueller, Matthias S.},
  booktitle={2014 43rd International Conference on Parallel Processing Workshops}, 
  title={MPI Runtime Error Detection with MUST: A Scalable and Crash-Safe Approach}, 
  year={2014},
  volume={},
  number={},
  pages={206-215},
  abstract={The Message Passing Interface (MPI) is a widely used paradigm for distributed memory programming. Implementations of this interface are designed for good performance rather than on usability extensions that enforce their correct use. Runtime MPI usage error detection tools aid application developers in the correct use of this interface. Since usage errors can cause failures that lead to an application crash, it is crucial that runtime error detection tools employ techniques that allow them to finish all of their correctness checks. This includes situations in which the application is interrupted by the MPI library, due to an incorrect function call, and operating system signals after fatal errors like division by zero or faulty memory accesses. We present an approach that uses an alternative tool communication means along with signal and error handling capabilities. A study of the assumptions that enable this approach details its applicability for different use cases and compares it to less efficient schemes that rely on synchronous processing and/or communication. Additionally, we enable bandwidth efficient communication with a scalable propagation technique that raises the awareness of an application crash within the tool. An application study with the SPEC MPI2007 benchmark suite demonstrates the applicability of our approach for up to 2,048 processes. Overhead measurements underline that our application crash handling increases the runtime of our runtime error detection tool by only 4% in average.},
  keywords={},
  doi={10.1109/ICPPW.2014.37},
  ISSN={2332-5690},
  month={Sep.},}
@INPROCEEDINGS{7116892,
  author={Sajjapongse, Kittisak and Agarwal, Tejaswi and Becchi, Michela},
  booktitle={2014 21st International Conference on High Performance Computing (HiPC)}, 
  title={A flexible scheduling framework for heterogeneous CPU-GPU clusters}, 
  year={2014},
  volume={},
  number={},
  pages={1-11},
  abstract={In the last few years, thanks to their computational power and progressively increased programmability, GPUs have become part of HPC clusters. As a result, widely used open-source cluster resource managers (e.g. TORQUE and SLURM) have recently been extended with GPU support capabilities. These systems, however, treat GPUs as dedicated resources and provide scheduling mechanisms that often result in resource underutilization and, thereby, in suboptimal performance. We propose a cluster-level scheduler and integrate it with our previously proposed node-level GPU virtualization runtime [1, 2], thus providing a hierarchical cluster resource management framework that allows the efficient use of heterogeneous CPU-GPU clusters. The scheduling policy used by our system is configurable, and our scheduler provides administrators with a high-level API that allows easily defining custom scheduling policies. We provide two application- and hardware-heterogeneity-aware cluster-level scheduling schemes for hybrid MPI-CUDA applications: co-location- and latency-reduction-based scheduling, and use them in combination with a preemption-based GPU sharing policy implemented at the node-level. We validate our framework on two heterogeneous clusters: one consisting of commodity workstations and the other of high-end nodes with various hardware configurations, and on a mix of communication- and compute-intensive applications. Our experiments show that, by better utilizing the available resources, our scheduling framework outperforms existing batch-schedulers both in terms of throughput and application latency.},
  keywords={},
  doi={10.1109/HiPC.2014.7116892},
  ISSN={1094-7256},
  month={Dec},}
@INPROCEEDINGS{7116873,
  author={Shi, Rong and Potluri, Sreeram and Hamidouche, Khaled and Perkins, Jonathan and Li, Mingzhe and Rossetti, Davide and Panda, Dhabaleswar K. D K},
  booktitle={2014 21st International Conference on High Performance Computing (HiPC)}, 
  title={Designing efficient small message transfer mechanism for inter-node MPI communication on InfiniBand GPU clusters}, 
  year={2014},
  volume={},
  number={},
  pages={1-10},
  abstract={Increasing number of MPI applications are being ported to take advantage of the compute power offered by GPUs. Data movement on GPU clusters continues to be the major bottleneck that keeps scientific applications from fully harnessing the potential of GPUs. Earlier, GPU-GPU inter-node communication has to move data from GPU memory to host memory before sending it over the network. MPI libraries like MVAPICH2 have provided solutions to alleviate this bottleneck using host-based pipelining techniques. Besides that, the newly introduced GPU Direct RDMA (GDR) is a promising solution to further solve this data movement bottleneck. However, existing design in MPI libraries applies the rendezvous protocol for all message sizes, which incurs considerable overhead for small message communications due to extra synchronization message exchange. In this paper, we propose new techniques to optimize internode GPU-to-GPU communications for small message sizes. Our designs to support the eager protocol include efficient support at both sender and receiver sides. Furthermore, we propose a new data path to provide fast copies between host and GPU memories. To the best of our knowledge, this is the first study to propose efficient designs for GPU communication for small message sizes, using eager protocol. Our experimental results demonstrate up to 59% and 63% reduction in latency for GPU-to-GPU and CPU-to-GPU point-to-point communications, respectively. These designs boost the uni-directional bandwidth by 7.3x and 1.7x, respectively. We also evaluate our proposed design with two end-applications: GPULBM and HOOMD-blue. Performance numbers on Kepler GPUs shows that, compared to the best existing GDR design, our proposed designs achieve up to 23.4% latency reduction for GPULBM and 58% increase in average TPS for HOOMD-blue, respectively.},
  keywords={},
  doi={10.1109/HiPC.2014.7116873},
  ISSN={1094-7256},
  month={Dec},}
@INPROCEEDINGS{7231907,
  author={Zhang, Bo and Lv, Qixing},
  booktitle={2014 International Conference on Mechatronics and Control (ICMC)}, 
  title={The research of network message communication mechanism based on mobile distributed agent}, 
  year={2014},
  volume={},
  number={},
  pages={1966-1968},
  abstract={This article proposes an efficient and reliable communication mechanism of mobile Agent based on the current communication mechanism of mobile Agent to combine mobile Agent name resolution mechanism with message transfer mechanism. The communication component of the domain server and mobile Agent system are combined to realize the mobile Agent communication. The message processing uses the message storage and transfer mechanism based on the e-mail and the buffer pool processing, message transfer status and offline transfer in mobile Agent. In the Agent message and email migration we need check whether the message is timeout or not and its priority status. When deleting overtime message, give priority to the implementation of high priority message. This mechanism improves the communication efficiency of mobile Agent, solves the communication failure of mobile Agent problems, ensure the stability of the system and realize a distributed communication mechanism.},
  keywords={},
  doi={10.1109/ICMC.2014.7231907},
  ISSN={},
  month={July},}
@INPROCEEDINGS{7855941,
  author={Agarwal, Tejaswi and Becchi, Michela},
  booktitle={2014 23rd International Conference on Parallel Architecture and Compilation Techniques (PACT)}, 
  title={Design of a hybrid MPI-CUDA benchmark suite for CPU-GPU clusters}, 
  year={2014},
  volume={},
  number={},
  pages={505-506},
  abstract={In the last few years, GPUs have become an integral part of HPC clusters. To test these heterogeneous CPU-GPU systems, we designed a hybrid CUDA-MPI benchmark suite that consists of three communication- and compute-intensive applications: Matrix Multiplication (MM), Needleman-Wunsch (NW) and the ADFA compression algorithm [1]. The main goal of this work is to characterize these workloads on CPU-GPU clusters. Our benchmark applications are designed to allow cluster administrators to identify bottlenecks in the cluster, to decide if scaling applications to multiple nodes would improve or decrease overall throughput and to design effective scheduling policies. Our experiments show that inter-node communication can significantly degrade the throughput of communication-intensive applications. We conclude that the scalability of the applications depends primarily on two factors: the cluster configuration and the applications characteristics.},
  keywords={},
  doi={10.1145/2628071.2671423},
  ISSN={},
  month={Aug},}
@ARTICLE{8130908,
  author={Yang, Xu and Guo, Deyuan and He, Hu and Tang, Haijing and Zhang, Yanjun},
  journal={The Computer Journal}, 
  title={An Implementation of Message-Passing Interface over VxWorks for Real-Time Embedded Multi-Core Systems}, 
  year={2014},
  volume={57},
  number={11},
  pages={1756-1764},
  abstract={Message-passing interface (MPI) has proved to be very successful in the high performance computing domain. However, suitability of MPI for embedded real-time system design is still under investigation. In this work, we have provided our methods and experiences of implementing MPI parallel environment for a real-time embedded multi-core system. Our main contributions were to: (1) enable hyper transport bus communication mechanism to establish MPI parallel environment; (2) support VxWorks operating system for establishing MPI parallel environment and (3) enhance the real-time property of MPI mechanism. The digital signal processor (DSP)-MPI presented in this work can also be used on other platforms supporting VxWorks operating system. The results indicate that the real-time property of DSP-MPI has been improved significantly compared with MPICH2. The test on realistic applications also shows that DSP-MPI can fulfill the requirement of our target multi-core platform.},
  keywords={},
  doi={10.1093/comjnl/bxt152},
  ISSN={1460-2067},
  month={Nov},}
@ARTICLE{8131337,
  author={Cores, Iván and Rodríguez, Gabriel and González, Patricia and Martín, María J.},
  journal={The Computer Journal}, 
  title={Failure Avoidance in MPI Applications Using an Application-Level Approach}, 
  year={2014},
  volume={57},
  number={1},
  pages={100-114},
  abstract={Execution times of large-scale computational science and engineering parallel applications are usually longer than the mean-time-between-failures. For this reason, hardware failures must be tolerated by the applications to ensure that not all computation done is lost on machine failures. Checkpointing and rollback recovery is one of the most popular techniques to provide fault tolerance support to parallel applications. However, when a failure occurs, most checkpointing mechanisms require a complete restart of the parallel application from the last checkpoint. New advances in the prediction of hardware failures have led to the development of proactive process migration approaches, where tasks are migrated in a preventive way when node failures are anticipated, avoiding the restart of the whole application. The work presented in this paper extends an application-level checkpointing framework to proactively migrate message passing interface (MPI) processes when impending failures are notified, without having to restart the entire application. The main features of the proposed solution are: low overhead in failure-free executions, avoiding the checkpoint dumping associated to rolling back strategies; low overhead at migration time, by means of the design of a light and asynchronous protocol to achieve a consistent global state; transparency for the user, thanks to the use of a compiler tool and a runtime library and portability, as it is not locked into a particular architecture, operating system or MPI implementation.},
  keywords={},
  doi={10.1093/comjnl/bxs158},
  ISSN={1460-2067},
  month={Jan},}
@INBOOK{9004615,
  author={Dichev, Kiril and Lastovetsky, Alexey},
  booktitle={High-Performance Computing on Complex Environments}, 
  title={Optimization of Collective Communication for Heterogeneous HPC Platforms}, 
  year={2014},
  volume={},
  number={},
  pages={95-114},
  abstract={This chapter overviews the existing research in collective communication area. Observes both message passing interface (MPI) collectives as well as alternatives from the distributed computing domain. It reviews the main generic optimization techniques for collective communication. Most optimizations of collective operations on homogeneous clusters focus on finding an efficient algorithm on top of point‐to‐point primitives. With increasingly heterogeneous networks, empirical approaches to optimizing communication become unfeasible because of the exponential growth of the already huge test space. Therefore, it needs some sort of network model. Such a network model based on topology or performance. Topology‐aware collectives are a relatively straightforward and popular approach to optimization. The minimal spanning trees based on the per‐link Hockney model provide efficient broadcast for small messages. For very large messages, receiver‐initiated multicasts are gaining popularity in the high‐performance computing (HPC) domain. The adaptive nature of these algorithms makes them suitable even for very complex networks.},
  keywords={},
  doi={10.1002/9781118711897.ch6},
  ISSN={},
  publisher={IEEE},
  isbn={},
  url={https://ieeexplore.ieee.org/document/9004615},}
@ARTICLE{6782663,
  author={Banerjee, Tania and Sahni, Sartaj},
  journal={IEEE Transactions on Computers}, 
  title={Pubsub: An Efficient Publish/Subscribe System}, 
  year={2015},
  volume={64},
  number={4},
  pages={1119-1132},
  abstract={Pubsub is a versatile, efficient, and scalable content-based publish/subscribe system. This paper describes the architecture of Pubsub together with some of its current capabilities. A version of Pubsub optimized for event processing was benchmarked against the publish/subscribe systems BE-Tree and Siena, which also are optimized for event processing. Although the run time performance of both BE-Tree and Pubsub is orders of magnitude better than that of Siena, BE-Tree is able to handle only a restricted class of predicates while Pubsub can handle most predicate types handled by Siena. On our tests, the speedup of the fastest version of Pubsub relative to Siena ranged from a low of 18 to a high of 1,703 and averaged 185. The speedup range relative to BE-Tree was up to 9.81 and averaged 2.37. Siena’s memory requirements are about a fourth of those of BE-Tree and Pubsub. The memory required by the most memory efficient of Pubsub ’s data structures was between 4 and 16 percent less that required by BE-Tree. With respect to data structure initialization, the three systems took a comparable amount of time on some data sets while on some Pubsub could be initialized in 1/7th time required to initialize Siena and 1/14th that to initialize BE-Tree. Pubsub achieves its high performance from the use of very efficient data structures and event matching algorithms.},
  keywords={},
  doi={10.1109/TC.2014.2315636},
  ISSN={1557-9956},
  month={April},}
@ARTICLE{6803050,
  author={Laguna, Ignacio and Ahn, Dong H. and Supinski, Bronis R. de and Bagchi, Saurabh and Gamblin, Todd},
  journal={IEEE Transactions on Parallel and Distributed Systems}, 
  title={Diagnosis of Performance Faults in LargeScale MPI Applications via Probabilistic Progress-Dependence Inference}, 
  year={2015},
  volume={26},
  number={5},
  pages={1280-1289},
  abstract={Debugging large-scale parallel applications is challenging. Most existing techniques provide little information about failure root causes. Further, most debuggers significantly slow down program execution, and run sluggishly with massively parallel applications. This paper presents a novel technique that scalably infers the tasks in a parallel program on which a failure occurred, as well as the code in which it originated. Our technique combines scalable runtime analysis with static analysis to determine the least-progressed task(s) and to identify the code lines at which the failure arose. We present a novel algorithm that infers probabilistically progress dependence among MPI tasks using a globally constructed Markov model that represents tasks' control-flow behavior. In comparison to previous work, our algorithm infers more precisely the least-progressed task. We combine this technique with static backward slicing analysis, further isolating the code responsible for the current state. A blind study demonstrates that our technique isolates the root cause of a concurrency bug in a molecular dynamics simulation, which only manifests itself at 7,996 tasks or more. We extensively evaluate fault coverage of our technique via fault injections in 10 HPC benchmarks and show that our analysis takes less than a few seconds on thousands of parallel tasks.},
  keywords={},
  doi={10.1109/TPDS.2014.2314100},
  ISSN={1558-2183},
  month={May},}
@ARTICLE{6827943,
  author={Wong, Alvaro and Rexachs, Dolores and Luque, Emilio},
  journal={IEEE Transactions on Parallel and Distributed Systems}, 
  title={Parallel Application Signature for Performance Analysis and Prediction}, 
  year={2015},
  volume={26},
  number={7},
  pages={2009-2019},
  abstract={Predicting the performance of parallel scientific applications is becoming increasingly complex. Our goal was to characterize the behavior of message-passing applications on different target machines. To achieve this goal, we developed a method called parallel application signature for performance prediction (PAS2P), which strives to describe an application based on its behavior. Based on the application's message-passing activity, we identified and extracted representative phases, with which we created a parallel application signature that enabled us to predict the application's performance. We experimented with using different scientific applications on different clusters. We were able to predict execution times with an average accuracy greater than 97 percent.},
  keywords={},
  doi={10.1109/TPDS.2014.2329688},
  ISSN={1558-2183},
  month={July},}
@ARTICLE{6846313,
  author={Jo, Gangwon and Nah, Jeongho and Lee, Jun and Kim, Jungwon and Lee, Jaejin},
  journal={IEEE Transactions on Parallel and Distributed Systems}, 
  title={Accelerating LINPACK with MPI-OpenCL on Clusters of Multi-GPU Nodes}, 
  year={2015},
  volume={26},
  number={7},
  pages={1814-1825},
  abstract={OpenCL is an open standard to write parallel applications for heterogeneous computing systems. Since its usage is restricted to a single operating system instance, programmers need to use a mix of OpenCL and MPI to program a heterogeneous cluster. In this paper, we introduce an MPI-OpenCL implementation of the LINPACK benchmark for a cluster with multi-GPU nodes. The LINPACK benchmark is one of the most widely used benchmark applications for evaluating high performance computing systems. Our implementation is based on High Performance LINPACK (HPL) and uses the blocked LU decomposition algorithm. We address that optimizations aimed at reducing the overhead of CPUs are necessary to overcome the performance gap between the CPUs and the multiple GPUs. Our LINPACK implementation achieves 93.69 Tflops (46 percent of the theoretical peak) on the target cluster with 49 nodes, each node containing two eight-core CPUs and four GPUs.},
  keywords={},
  doi={10.1109/TPDS.2014.2321742},
  ISSN={1558-2183},
  month={July},}
@ARTICLE{6855347,
  author={Simon, Balazs and Goldschmidt, Balazs and Kondorosi, Karoly},
  journal={IEEE Transactions on Services Computing}, 
  title={A Performance Model for the Web Service Protocol Stacks}, 
  year={2015},
  volume={8},
  number={5},
  pages={644-657},
  abstract={Web services are built on XML. They use XML for describing the service interface, they use XML for message exchange and the WS-* protocols that provide addressing, security and reliable messaging also use XML. This burdens the communication with a large response time overhead compared to binary distributed communications like CORBA or RMI. Therefore, it is important to know how to design the interface of a web service so we can minimize the communication overhead. In this paper we propose a performance model with which the response time overhead of web services with arbitrary interfaces can be predicted if the coefficients of the model are calculated from some simple measurements for the given set of test cases. The paper shows the measurement results for two web service frameworks and also gives a detailed description of the performance model.},
  keywords={},
  doi={10.1109/TSC.2014.2338866},
  ISSN={1939-1374},
  month={Sep.},}
@ARTICLE{6867296,
  author={Ma, Xingkong and Wang, Yijie and Pei, Xiaoqiang},
  journal={IEEE Transactions on Cloud Computing}, 
  title={A Scalable and Reliable Matching Service for Content-Based Publish/Subscribe Systems}, 
  year={2015},
  volume={3},
  number={1},
  pages={1-13},
  abstract={Characterized by the increasing arrival rate of live content, the emergency applications pose a great challenge: how to disseminate large-scale live content to interested users in a scalable and reliable manner. The publish/subscribe (pub/sub) model is widely used for data dissemination because of its capacity of seamlessly expanding the system to massive size. However, most event matching services of existing pub/sub systems either lead to low matching throughput when matching a large number of skewed subscriptions, or interrupt dissemination when a large number of servers fail. The cloud computing provides great opportunities for the requirements of complex computing and reliable communication. In this paper, we propose SREM, a scalable and reliable event matching service for content-based pub/sub systems in cloud computing environment. To achieve low routing latency and reliable links among servers, we propose a distributed overlay SkipCloud to organize servers of SREM. Through a hybrid space partitioning technique HPartition, large-scale skewed subscriptions are mapped into multiple subspaces, which ensures high matching throughput and provides multiple candidate servers for each event. Moreover, a series of dynamics maintenance mechanisms are extensively studied. To evaluate the performance of SREM, 64 servers are deployed and millions of live content items are tested in a CloudStack testbed. Under various parameter settings, the experimental results demonstrate that the traffic overhead of routing events in SkipCloud is at least 60 percent smaller than in Chord overlay, the matching rate in SREM is at least 3.7 times and at most 40.4 times larger than the single-dimensional partitioning technique of BlueDove. Besides, SREM enables the event loss rate to drop back to 0 in tens of seconds even if a large number of servers fail simultaneously.},
  keywords={},
  doi={10.1109/TCC.2014.2338327},
  ISSN={2168-7161},
  month={Jan},}
@ARTICLE{6876150,
  author={Wang, Yijie and Ma, Xingkong},
  journal={IEEE Transactions on Parallel and Distributed Systems}, 
  title={A General Scalable and Elastic Content-Based Publish/Subscribe Service}, 
  year={2015},
  volume={26},
  number={8},
  pages={2100-2113},
  abstract={The big data era is characterized by the emergence of live content with increasing complexities of data dimensionality and data sizes, which poses a new challenge to emergency applications: how to timely disseminate large-scale live content to users who are interested in. The publish/subscribe (pub/sub) model is widely used to disseminate data because of its possibility of expanding the system to Internet-scale size. However, existing pub/sub systems are inadequate to meet the requirement of disseminating live content in the big data era, since their multi-hop routing techniques and coarse-grained partitioning techniques lead to a low matching throughput, and their upload capacities do not scale well. In this paper, we propose a general scalable and elastic pub/sub service based on the cloud computing environment, called GSEC. For generality, we propose a two-layer pub/sub framework to support the dissemination with diverse data sizes and data dimensionality. For scalability, a hybrid space partitioningtechnique is proposed to achieve high matching throughput, which divides subscriptions into multiple clusters in a hierarchical manner. Moreover, a helper-based content distribution technique is proposed to achieve high upload bandwidth, where servers act as both providers and coordinators to fully explore the upload capacity of the system. For elasticity, we propose a performance-aware provisioningtechnique to adjust the scale of servers to adapt to the churn workloads. To evaluate the performance of GSEC, about 1,000 servers are deployed and hundreds of thousands of live content items are tested in our CloudStack-based testbed. Extensive experiments confirm that GSEC can linearly increase the capacities of event matching and content distribution with the growth of servers, adaptively adjust these capacities in tens of seconds according to the churn workloads, and significantly outperforms the state-of-the-art approaches under various parameter settings.},
  keywords={},
  doi={10.1109/TPDS.2014.2346759},
  ISSN={1558-2183},
  month={Aug},}
@ARTICLE{6881677,
  author={Lacruz, Jesús O. and García-Herrero, Francisco and Declercq, David and Valls, Javier},
  journal={IEEE Transactions on Very Large Scale Integration (VLSI) Systems}, 
  title={Simplified Trellis Min–Max Decoder Architecture for Nonbinary Low-Density Parity-Check Codes}, 
  year={2015},
  volume={23},
  number={9},
  pages={1783-1792},
  abstract={Nonbinary low-density parity-check (NB-LDPC) codes have become an efficient alternative to their binary counterparts in different scenarios, such as moderate codeword lengths, high-order modulations, and burst error correction. Unfortunately, the complexity of NB-LDPC decoders is still too high for practical applications, especially for the check node (CN) processing, which limits the maximum achievable throughput. Although a great effort has been made in the recent literature to overcome this disadvantage, the proposed decoders are still not ready for high-speed implementations for high-order fields. In this paper, a simplified trellis min-max algorithm is proposed, where the CN messages are computed in a parallel way using only the most reliable information. The proposed CN algorithm is implemented using a horizontal layered schedule. The overall decoder architecture has been implemented in a 90-nm CMOS process for a (N = 837 and K = 726) NB-LDPC code over GF(32), achieving a throughput of 660 Mb/s at nine iterations based on postlayout results. This decoder increases hardware efficiency compared with the existing recent solutions for the same code.},
  keywords={},
  doi={10.1109/TVLSI.2014.2344113},
  ISSN={1557-9999},
  month={Sep.},}
@ARTICLE{6910215,
  author={Jia, Chungang and Guo, Lixin and Yang, Pengju},
  journal={IEEE Antennas and Wireless Propagation Letters}, 
  title={EM Scattering From a Target Above a 1-D Randomly Rough Sea Surface Using GPU-Based Parallel FDTD}, 
  year={2015},
  volume={14},
  number={},
  pages={217-220},
  abstract={This letter presents the graphics processing unit (GPU)-based finite-difference time-domain (FDTD) algorithm to investigate the electromagnetic (EM) scattering from a target above a rough sea surface. The proposed method is validated by comparing the numerical results to those obtained through sequential FDTD execution on a central processing unit (CPU), as well as through method of moments (MOM). The comparison results show a significant improvement in computation efficiency for GPU-based FDTD versus the message passing interface (MPI)-based FDTD. Furthermore, our parallel implementation is employed to study the influences of wind speed and the tilt angle of the target on composite scattering from the target above a sea surface.},
  keywords={},
  doi={10.1109/LAWP.2014.2360415},
  ISSN={1548-5757},
  month={},}
@ARTICLE{6911991,
  author={George, Cijo and Vadhiyar, Sathish},
  journal={IEEE Transactions on Computers}, 
  title={Fault Tolerance on Large Scale Systems using Adaptive Process Replication}, 
  year={2015},
  volume={64},
  number={8},
  pages={2213-2225},
  abstract={Exascale systems of the future are predicted to have mean time between failures (MTBF) of less than one hour. At such low MTBFs, employing periodic checkpointing alone will result in low efficiency because of the high number of application failures resulting in large amount of lost work due to rollbacks. In such scenarios, it is highly necessary to have proactive fault tolerance mechanisms that can help avoid significant number of failures. In this work, we have developed a mechanism for proactive fault tolerance using partial replication of a set of application processes. Our fault tolerance framework adaptively changes the set of replicated processes periodically based on failure predictions to avoid failures. We have developed an MPI prototype implementation, PAREP-MPI that allows changing the replica set. We have shown that our strategy involving adaptive process replication significantly outperforms existing mechanisms providing up to 20 percent improvement in application efficiency even for exascale systems.},
  keywords={},
  doi={10.1109/TC.2014.2360536},
  ISSN={1557-9956},
  month={Aug},}
@ARTICLE{6914533,
  author={Shokri-Ghadikolaei, Hossein and Fischione, Carlo},
  journal={IEEE Journal on Selected Areas in Communications}, 
  title={Analysis and Optimization of Random Sensing Order in Cognitive Radio Networks}, 
  year={2015},
  volume={33},
  number={5},
  pages={803-819},
  abstract={Developing an efficient spectrum access policy enables cognitive radios to dramatically increase spectrum utilization while ensuring the predetermined quality of service levels for primary users (PUs). In this paper, the modeling, performance analysis, and optimization of a distributed secondary network with a random sensing order policy are studied. Specifically, secondary users (SUs) create a random order of available channels upon PUs' return, and then, they find optimal transmission and handoff opportunities in a distributed manner. By a Markov chain analysis, the average throughputs of the SUs and the average interference level among the SUs and the PUs are investigated. A maximization of the secondary network performance in terms of the throughput while keeping under control the average interference is proposed. It is shown that, despite traditional views, a nonzero false alarm in the channel sensing can increase channel utilization, particularly in a dense secondary network where the contention is too high. Then, two simple and practical adaptive algorithms are established to optimize the network. The second algorithm follows the variations of the wireless channels in nonstationary conditions and outperforms even static brute force optimization while demanding few computations. The convergence of the distributed algorithms is theoretically investigated based on the analytical performance indicators established by the Markov chain analysis. Finally, numerical results validate the analytical derivations and demonstrate the efficiency of the proposed schemes. It is concluded that fully distributed sensing order algorithms can lead to substantial performance improvements in cognitive radio networks without the need for centralized management or message passing among the users.},
  keywords={},
  doi={10.1109/JSAC.2014.2361077},
  ISSN={1558-0008},
  month={May},}
@ARTICLE{6920049,
  author={Zhao, Ming and Zhang, Xiaolin and Zhao, Ling and Lee, Chen},
  journal={IEEE Transactions on Circuits and Systems II: Express Briefs}, 
  title={Design of a High-Throughput QC-LDPC Decoder With TDMP Scheduling}, 
  year={2015},
  volume={62},
  number={1},
  pages={56-60},
  abstract={Low-density parity-check (LDPC) codes with turbodecoding message-passing (TDMP) scheduling can obtain good performance and high convergence rates. In addition, the min- sum (MS) algorithm can reduce the complexity. The hybrid normalized MS algorithm with TDMP scheduling is presented to achieve good performance and to lower the complexity. For a quasi-cyclic LDPC (QC-LDPC) code with a long code length, parallel degree optimization and an offset iterative sequence rule are proposed. With the proposed techniques, the data correlation problem and memory access conflicts during TDMP scheduling can be resolved so that the iteration can smoothly proceed through the reasonable division of each block row. Fabricated in the 90-nm 1-Poly 9-Metal (1P9M) CMOS process, a multimode 96000-bit irregular QC-LDPC decoder is implemented. It attains throughputs of 1.7-3.0 Gb/s and dissipates an average power of 502 mW at an operation frequency of 100 MHz and at 10 iterations. The decoder chip area is 13.32 mm2, with a core area of 9.73 mm2.},
  keywords={},
  doi={10.1109/TCSII.2014.2362661},
  ISSN={1558-3791},
  month={Jan},}
@ARTICLE{6926846,
  author={Kolmogorov, Vladimir},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={A New Look at Reweighted Message Passing}, 
  year={2015},
  volume={37},
  number={5},
  pages={919-930},
  abstract={We propose a new family of message passing techniques for MAP estimation in graphical models which we call Sequential Reweighted Message Passing (SRMP). Special cases include well-known techniques such as Min-Sum Diffusion (MSD) and a faster Sequential Tree-Reweighted Message Passing (TRW-S). Importantly, our derivation is simpler than the original derivation of TRW-S, and does not involve a decomposition into trees. This allows easy generalizations. The new family of algorithms can be viewed as a generalization of TRW-S from pairwise to higher-order graphical models. We test SRMP on several real-world problems with promising results.},
  keywords={},
  doi={10.1109/TPAMI.2014.2363465},
  ISSN={1939-3539},
  month={May},}
@ARTICLE{6994826,
  author={Lee, Sang Hyun and Sohn, Illsoo},
  journal={IEEE Communications Letters}, 
  title={Distributed Relay Pairing for Bandwidth Exchange Based Cooperative Forwarding}, 
  year={2015},
  volume={19},
  number={3},
  pages={459-462},
  abstract={This letter develops a distributed algorithm for relay pairing in bandwidth exchange (BE) based cooperative forwarding scenarios, where each node can delegate a fraction of its allocated resources to a neighboring node as an incentive for relaying. Determining the relay pairs that maximize the overall network utility yields a non-bipartite matching problem, which incurs a considerable computational load when implemented in a centralized way. To resolve this challenge, we use a message-passing framework to develop an efficient distributed solution. Simulation results verify that the proposed algorithm outperforms existing approaches.},
  keywords={},
  doi={10.1109/LCOMM.2014.2385064},
  ISSN={1558-2558},
  month={March},}
@ARTICLE{6998058,
  author={Jamali, Vahid and Karimian, Yasser and Huber, Johannes and Attari, Mahmoud Ahmadian},
  journal={IEEE Transactions on Communications}, 
  title={On the Design of Fast Convergent LDPC Codes for the BEC: An Optimization Approach}, 
  year={2015},
  volume={63},
  number={2},
  pages={351-363},
  abstract={The complexity-performance trade-off is a fundamental aspect of the design of low-density parity-check (LDPC) codes. In this paper, we consider LDPC codes for the binary erasure channel (BEC), use code rate for performance metric, and number of decoding iterations to achieve a certain residual erasure probability for complexity metric. We first propose a quite accurate approximation of the number of iterations for the BEC. Moreover, a simple but efficient utility function corresponding to the number of iterations is developed. Using the aforementioned approximation and the utility function, two optimization problems w.r.t. complexity are formulated to find the code degree distributions. We show that both optimization problems are convex. In particular, the problem with the proposed approximation belongs to the class of semi-infinite problems which are computationally challenging to be solved. However, the problem with the proposed utility function falls into the class of semi-definite programming (SDP) and thus, the global solution can be found efficiently using available SDP solvers. Numerical results reveal the superiority of the proposed code design compared to existing code designs from literature.},
  keywords={},
  doi={10.1109/TCOMM.2014.2385858},
  ISSN={1558-0857},
  month={Feb},}
@INPROCEEDINGS{7027430,
  author={Fu, Xianjin and Chen, Zhenbang and Zhang, Yufeng and Huang, Chun and Dong, Wei and Wang, Ji},
  booktitle={2015 IEEE 16th International Symposium on High Assurance Systems Engineering}, 
  title={MPISE: Symbolic Execution of MPI Programs}, 
  year={2015},
  volume={},
  number={},
  pages={181-188},
  abstract={Message Passing Interfaces (MPI) plays an important role in parallel computing. Many parallel applications are implemented as MPI programs. The existing methods of bug detection for MPI programs have the shortage of providing both input and non-determinism coverage, leading to missed bugs. In this paper, we employ symbolic execution to ensure the input coverage, and propose an on-the-fly schedule algorithm to reduce the interleaving explorations for non-determinism coverage, while ensuring the soundness and completeness. We have implemented our approach as a tool, called MPISE, which can automatically detect the deadlock and runtime bugs in MPI programs. The results of the experiments on benchmark programs and real world MPI programs indicate that MPISE finds bugs effectively and efficiently. In addition, our tool also provides diagnostic information and replay mechanism to help understand bugs.},
  keywords={},
  doi={10.1109/HASE.2015.35},
  ISSN={1530-2059},
  month={Jan},}
@ARTICLE{7035105,
  author={Cherukuri, Ashish and Cortés, Jorge},
  journal={IEEE Transactions on Control of Network Systems}, 
  title={Distributed Generator Coordination for Initialization and Anytime Optimization in Economic Dispatch}, 
  year={2015},
  volume={2},
  number={3},
  pages={226-237},
  abstract={This paper considers the economic dispatch problem for a group of generator units communicating over an arbitrary weight-balanced digraph. The objective of the individual units is to collectively generate power to satisfy a certain load while minimizing the total generation cost, which corresponds to the sum of individual arbitrary convex functions. We propose a class of distributed Laplacian-gradient dynamics that are guaranteed to asymptotically find the solution to the economic dispatch problem with and without generator constraints. The proposed coordination algorithms are anytime, meaning that its trajectories are feasible solutions at any time before convergence, and they become better solutions as time elapses. In addition, we design the provably correct determine feasible allocation strategy that handles generator initialization and the addition and deletion of units via a message passing routine over a spanning tree of the network. Our technical approach combines notions and tools from algebraic graph theory, distributed algorithms, nonsmooth analysis, set-valued dynamical systems, and penalty functions. Simulations illustrate our results.},
  keywords={},
  doi={10.1109/TCNS.2015.2399191},
  ISSN={2325-5870},
  month={Sep.},}
@INPROCEEDINGS{7063064,
  author={Chen, Chia-Hsiang and Tang, Wei and Zhang, Zhengya},
  booktitle={2015 IEEE International Solid-State Circuits Conference - (ISSCC) Digest of Technical Papers}, 
  title={18.7 A 2.4mm2 130mW MMSE-nonbinary-LDPC iterative detector-decoder for 4×4 256-QAM MIMO in 65nm CMOS}, 
  year={2015},
  volume={},
  number={},
  pages={1-3},
  abstract={In this work, the authors demonstrate an MMSE-NBLDPC iterative detector-decoder for a 4×4 256-QAM MIMO system to achieve an excellent error rate that improves with iterations, as shown in Fig. 18.7.1. To minimize latency over the iterative loop and improve throughput, the MMSE detector is divided into 4 task-based coarse pipeline stages so that all stages can operate in parallel. Both the number of stages and the stage latency of the detector are minimized, and the long critical paths are interleaved and placed in a slow clock domain to support a high data rate in a cost-effective way. The resulting MMSE detector achieves an 82% higher throughput compared, and almost 3.5× the throughput of the latest SD detector. The NBLDPC decoder is implemented using 78 processing nodes to enable fully parallel message passing. Serial Galois field (GF) processing is pipelined using a data forwarding technique to cut the decoding latency by 30% over the latest design. The detector and decoder exchange symbol log-likelihood ratios (LLR) that are efficiently computed based on the L1 distance to the nearest neighbors in the QAM constellation. To lower the power consumption, automatic clock gating is applied to stage boundary and buffer registers to save 53% of the detector power and 61% of the decoder power. The results are demonstrated in a 65nm MMSE-NBLDPC iterative detector-decoder test chip that achieves 1.38Gb/s detection and 1.02Gb/s decoding (5 iterations), consuming 26.5mW and 103mW, respectively.},
  keywords={},
  doi={10.1109/ISSCC.2015.7063064},
  ISSN={2376-8606},
  month={Feb},}
@INPROCEEDINGS{7079156,
  author={Kapoor, Vijaya and Kumar, Parveen},
  booktitle={2015 Fifth International Conference on Advanced Computing & Communication Technologies}, 
  title={Review of State Based Approach Recovery Schemes in Mobile Distributed Environments}, 
  year={2015},
  volume={},
  number={},
  pages={621-626},
  abstract={Fault tolerance techniques enable a system to perform tasks in the existence of faults. In a distributed system, hardware and software components are located at network computers and communication and coordination of their action is done by only passing messages. Mobile computing is progression of wireless network technology and portable information appliances such as laptops, handheld devices, PDAs etc. In the state based approach for recovery, known as snapshot, the entire state of a process is saved. When a recovery point is established, recovering a process involves reinstating its saved state and resuming the execution of the process from the state. Exhaustive research work has been carried out on designing efficient state based schemes for fault tolerance. In mobile distributed computing, due to mobility of MHs and limitations of wireless networks, there are new issues like mobility, catastrophic failure, limited battery life, low bandwidth, disconnections etc. That complicate the design of the snapshot algorithms. Recently, more attention has been given to providing state based approach of recovery for mobile systems. This paper surveys the algorithms reported in literature for introducing fault tolerance in mobile distributed systems and extension of it.},
  keywords={},
  doi={10.1109/ACCT.2015.19},
  ISSN={2327-0659},
  month={Feb},}
@ARTICLE{7084675,
  author={Lee, Sang Hyun and Sohn, Illsoo},
  journal={IEEE Transactions on Wireless Communications}, 
  title={Affinity Propagation for Energy-Efficient BS Operations in Green Cellular Networks}, 
  year={2015},
  volume={14},
  number={8},
  pages={4534-4545},
  abstract={This paper develops a distributed strategy to identify an energy-efficient base station (BS) network configuration for green cellular networks. During off-peak periods where traffic demands are only a fraction of the peak-time traffic demands, a subset of BSs is switched off to minimize operational energy consumption without affecting service to any of network users. To this end, we formulate a combinatorial optimization of jointly determining BS switching and user association. This formulation, however, requires a computationally demanding task as the population of the network grows. To resolve these challenges, we introduce a graphical-model approach to the optimization formulation and derive a distributed algorithm based on affinity propagation, which is a message-passing algorithm developed for data clustering in data-mining techniques. The proposed algorithm operates via simple local information exchanges among users and BSs and provides a very efficient solution for energy-saving management with low computational costs. We also present a green protocol that transforms commercial cellular networks into green radio networks using the proposed algorithm. Simulation results verify that the developed solution significantly improves the energy savings and resource utilization in the network.},
  keywords={},
  doi={10.1109/TWC.2015.2422701},
  ISSN={1558-2248},
  month={Aug},}
@INPROCEEDINGS{7092715,
  author={Miwa, Masahiro and Nakashima, Kohta},
  booktitle={2015 23rd Euromicro International Conference on Parallel, Distributed, and Network-Based Processing}, 
  title={Progression of MPI Non-blocking Collective Operations Using Hyper-Threading}, 
  year={2015},
  volume={},
  number={},
  pages={163-171},
  abstract={MPI non-blocking collective operations offer a high level interface to MPI library users, and potentially allow communication to be overlapped with calculation. Progression, which controls communications running in the background of the calculation, is the key factor to achieve an efficient overlap. The most commonly used progression method is manual progression, in which a progression function is called in the main calculation. In manual progression, MPI library users have to estimate the communication timing to maximize the overlap effect and thus to manage the complex communication optimization. An alternative approach for progression is the use of separate communication threads. By using communication threads, communication calculation overlap can be achieved simply. However, context switches between the calculation thread and the communication thread cause lower performance in the frequent case where all cores are used for calculation. In this paper, we propose a novel threaded progression method using Hyper-Threading to maximize the overlap effect of non-blocking collective operations. We apply MONITOR/MWAIT instructions to the communication thread on Hyper-Threading so as not to degrade the calculation thread due to shared core resource conflict. Evaluation on 8-node Infini Band connected IA server clustered systems confirmed that the latency is suppressed to a small level and that our approach has an advantage over manual progression in terms of communication-calculation overlap. Using a real application of CG benchmark, our method achieved 32% reduction in execution time compared to using blocking collective operation, and that is nearly perfect overlap. Although manual progression also achieved perfect overlap, our method has the advantage that no communication timing tuning is required for each application.},
  keywords={},
  doi={10.1109/PDP.2015.68},
  ISSN={2377-5750},
  month={March},}
@INPROCEEDINGS{7092760,
  author={Guthmuller, Marion and Quinson, Martin and Corona, Gabriel},
  booktitle={2015 23rd Euromicro International Conference on Parallel, Distributed, and Network-Based Processing}, 
  title={System-Level State Equality Detection for the Formal Dynamic Verification of Legacy Distributed Applications}, 
  year={2015},
  volume={},
  number={},
  pages={451-458},
  abstract={The ever increasing complexity of distributed systems mandates to formally verify their design and implementation. Unfortunately, the common approaches and existing tools to formally establish the correctness of these systems remain hardly applicable to the kind of legacy applications that are commonly found in the HPC community. We present how system-level memory introspection can be achieved directly at runtime without relying on the source code analysis. We use this mechanism to detect the equality of the application's state at system level. As the storage of the system state may be memory expensive, we compact the memory by sharing unchanged memory pages between snapshots. This enables the automated verification of safety and liveness properties on legacy distributed applications written in Fortran or C/C++ using the MPI standard. We demonstrate the effectiveness of our approach on several programs from the MPICH3 test suite.},
  keywords={},
  doi={10.1109/PDP.2015.95},
  ISSN={2377-5750},
  month={March},}
@INPROCEEDINGS{7092698,
  author={Danilecki, Arkadiusz D.},
  booktitle={2015 23rd Euromicro International Conference on Parallel, Distributed, and Network-Based Processing}, 
  title={Marching Band: Fault-Tolerance with Replicable Message Delivery Order}, 
  year={2015},
  volume={},
  number={},
  pages={43-47},
  abstract={Marching Band ensures the same total ordering of message deliveries in each possible execution history, providing replicable execution for a subset of piecewise deterministic applications. With Marching Band any number of failures can be tolerated with a sender-based logging. The main idea behind the algorithm is to log and then broadcast each sent message, with a precomputed tag describing ordering of the message delivery.},
  keywords={},
  doi={10.1109/PDP.2015.52},
  ISSN={2377-5750},
  month={March},}
@INPROCEEDINGS{7092702,
  author={Trahay, François and Brunet, Élisabeth and Bouksiaa, Mohamed Mosli and Liao, Jianwei},
  booktitle={2015 23rd Euromicro International Conference on Parallel, Distributed, and Network-Based Processing}, 
  title={Selecting Points of Interest in Traces Using Patterns of Events}, 
  year={2015},
  volume={},
  number={},
  pages={70-77},
  abstract={Over the past few years, the architecture of supercomputing platforms has evolved towards more complexity: multicore processors attached to multiple memory banks are now combined with accelerators. Exploiting such architecture often requires to mix programming models (MPI + CUDA for instance). As a result, understanding the performance of an application has become tedious. The use of performance analysis tools, such as tracing tools, now becomes unavoidable to optimize a parallel application. However, analyzing a trace file composed of millions of events requires a tremendous amount of work in order to spot the cause of the poor performance of an application. In this paper, we propose mechanisms for assisting application developers in their exploration of trace files. We propose an algorithm for detecting repetitive patterns of events in trace files. Thanks to this algorithm, a trace can be viewed as loops and groups of events instead of the usual representation as a sequential list of events. We also propose a method to filter traces in order to eliminate duplicated information and to highlight points of interest. These mechanisms allow the performance analysis tool to pre-select the subsets of the trace that are more likely to contain useful information. We implemented the proposed mechanism in the EZTrace performance analysis framework and the experiments show that detecting patterns in various benchmarking applications is done in reasonable time, even when the trace contains millions of events. We also show that the filtering process can reduce the quantity of information in the trace that the user has to analyze by up to 99 %.},
  keywords={},
  doi={10.1109/PDP.2015.30},
  ISSN={2377-5750},
  month={March},}
@INPROCEEDINGS{7096063,
  author={Wolfer, James},
  booktitle={2015 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={A heterogeneous supercomputer model for high-performance parallel computing pedagogy}, 
  year={2015},
  volume={},
  number={},
  pages={799-805},
  abstract={To visually illustrate the impact of architecture and communication on parallel computing we created a model supercomputer in the spirit of other engineering models. Combining Raspberry Pi computers with an Nvidia TK1 the resulting machine is distinguished by it's instructional utility, asymmetric CPU and communication channel speed, and for incorporating current trends in heterogeneous supercomputing. Running Linux, the model supports major high-performance computing software environments, including OpenMP, MPI, and Nvidia's CUDA. The model architecture includes aspects of heterogeneous, supercomputers such as shared- and distributed-memory MIMD, and 192 CUDA core SIMD-like processors.},
  keywords={},
  doi={10.1109/EDUCON.2015.7096063},
  ISSN={2165-9567},
  month={March},}
@ARTICLE{7102989,
  author={Van Nguyen, Thang and Jeong, Youngmin and Shin, Hyundong and Win, Moe Z.},
  journal={IEEE Journal on Selected Areas in Communications}, 
  title={Machine Learning for Wideband Localization}, 
  year={2015},
  volume={33},
  number={7},
  pages={1357-1380},
  abstract={Wireless localization has a great importance in a variety of areas including commercial, service, and military positioning and tracking systems. In harsh indoor environments, it is hard to localize an agent with high accuracy due to non-line-of-sight (NLOS) radio blockage or insufficient information from anchors. Therefore, NLOS identification and mitigation are highlighted as an effective way to improve the localization accuracy. In this paper, we develop a robust and efficient algorithm to enhance the accuracy for (ultrawide bandwidth) time-of-arrival localization through identifying and mitigating NLOS signals with relevance vector machine (RVM) techniques. We also propose a new localization algorithm, called the two-step iterative (TSI) algorithm, which converges fast with a finite number of iterations. To enhance the localization accuracy as well as expand the coverage of a localizable area, we continue to exploit the benefits of RVM in both classification and regression for cooperative localization by extending the TSI algorithm to a centralized cooperation case. For self-localization setting, we then develop a distributed cooperative algorithm based on variational Bayesian inference to simplify message representations on factor graphs and reduce communication overheads between agents. In particular, we build a refined version of Gaussian variational message passing to reduce the computational complexity while maintaining the localization accuracy. Finally, we introduce the notion of a stochastic localization network to verify proposed cooperative localization algorithms.},
  keywords={},
  doi={10.1109/JSAC.2015.2430191},
  ISSN={1558-0008},
  month={July},}
@ARTICLE{7106508,
  author={Karimi, Babak and Namboodiri, Vinod and Jadliwala, Murtuza},
  journal={IEEE Transactions on Smart Grid}, 
  title={Scalable Meter Data Collection in Smart Grids Through Message Concatenation}, 
  year={2015},
  volume={6},
  number={4},
  pages={1697-1706},
  abstract={Advanced metering infrastructure (AMI) initiatives are a popular tool to incorporate changes for modernizing the electricity grid, reduce peak loads, and meet energy efficiency targets. There is the looming issue of how to communicate and handle consumer data collected by electric utilities and manage limited communication network resources. Several data relay points are required to collect data distributedly and send them through a communication backhaul. This paper studies the smart meter message concatenation (SMMC) problem of how to efficiently concatenate multiple small smart metering messages arriving at data concentrator units in order to reduce protocol overhead and thus network utilization. This problem needs to deal with the added constraint that each originating message from its source may have its own stated deadline that must be taken into account during the concatenation process. This paper provides hardness results for the SMMC problem, and proposes six heuristics and evaluates them to gain a better understanding of the best data volume reduction policies that can be applied at data concentrators of AMI infrastructures. These results are further tested for feasibility under practical settings based on aspects, such as network and processing delays, tightness of application deadlines, and lossy backhaul links.},
  keywords={},
  doi={10.1109/TSG.2015.2426020},
  ISSN={1949-3061},
  month={July},}
@ARTICLE{7118260,
  author={Cámpora Pérez, Daniel Hugo and Schwemmer, Rainer and Neufeld, Niko},
  journal={IEEE Transactions on Nuclear Science}, 
  title={Protocol-Independent Event Building Evaluator for the LHCb DAQ System}, 
  year={2015},
  volume={62},
  number={3},
  pages={1110-1114},
  abstract={The Data Acquisition (DAQ) system of LHCb is a complex real-time system. It will be upgraded to provide LHCb with an all-software, trigger-free readout starting from 2020. Consequently, more CPU power in the form of servers will be needed and the DAQ network will grow to a capacity of 40 Tbps. A PC-based readout system would receive data incoming from the detector, which would then be scattered across builder nodes, and further distributed to a computing farm for data filtering. The design bandwidth of such a DAQ system requires rates as high as 400 Gbps single-duplex per node. These builder nodes will be connected with cost-effective, high-bandwidth data-centre switches in order to minimize the system cost. The behaviour of such an Event Building network can of course be studied in simulation but experience tells us that it is crucial to test, in particular to find out limitations in the switches themselves and to which extent various Event Building protocols can mitigate these limitations. We present a protocol, topology and transport independent emulation software named DAQ Protocol-Independent Performance Evaluator (DAQPIPE). It allows us to test different communication architectures, such as push or pull, with regards to the initiator of the communication. Different topologies and transport protocols can also be tested. We present throughput and stress tests on an InfiniBand FDR multi-rail based LAN network setup, with a focus on the network performance. Large tests on the current system LHCb DAQ are shown to demonstrate the scalability of DAQPIPE itself and its capability to be deployed on any kind of large, tightly interconnected network to test its suitability for Event Building applications.},
  keywords={},
  doi={10.1109/TNS.2015.2428891},
  ISSN={1558-1578},
  month={June},}
@INPROCEEDINGS{7157854,
  author={Nasri, Maryam and Hossain, Md Rishad and Ginn, Herbert L. and Moallem, Mehrdad},
  booktitle={2015 IEEE Electric Ship Technologies Symposium (ESTS)}, 
  title={Agent-based real-time coordination of power converters in a DC shipboard power system}, 
  year={2015},
  volume={},
  number={},
  pages={8-13},
  abstract={The objective of this paper is to describe the implementation of an innovative agent based architecture of controllers for stand-alone shipboard DC microgrids. The controllers have to regulate voltage to the required level and balance load flow in all converters. In addition, they should maintain a deterministic time frame on the order of a few tens of milliseconds for a system with tens of converters with no limitation in the number of events which might happen concurrently. The paper proposes application of the publish-subscribe agent-based controllers for real-time coordination of power converters in the defined microgrid. To test the design, a sample DC shipboard microgrid including four converters is used as a case study. Results of implementing the agent based publish-subscribe system using JADE Platform are shown. The results indicate that publish-subscribe is the best option for developing an agent based API for microgrids. The implementation results of the agent platform show that the upper time limit for task management is consistent and independent of the number of converters.},
  keywords={},
  doi={10.1109/ESTS.2015.7157854},
  ISSN={},
  month={June},}
@INPROCEEDINGS{7161575,
  author={Bonomi, Silvia and Potop-Butucaru, Maria and Tixeuil, Sébastien},
  booktitle={2015 IEEE International Parallel and Distributed Processing Symposium}, 
  title={Stabilizing Byzantine-Fault Tolerant Storage}, 
  year={2015},
  volume={},
  number={},
  pages={894-903},
  abstract={Distributed storage service is one of the main abstractions provided to developers of distributed applications due to its ability to hide the complexity generated by the various messages exchanged between processes. Many protocols have been proposed to build Byzantine-fault-tolerant (BFT) storage services on top of a message-passing system but none of them considers the possibility that well-behaving processes (i.e. correct processes) may experience transient failures due to, say, isolated errors during computation or bit alteration during message transfer. This paper proposes a stabilizing Byzantine-tolerant algorithm for emulating a multi-writer multi-reader regular register abstraction on top of a message passing system with n > 5f servers, which we prove to be the minimal possible number of servers for stabilizing and tolerating f Byzantine servers. That is, each read operation returns the value written by the most recent write and write operations are totally ordered with respect to the happened before relation. Our algorithm is particularly appealing for cloud computing architectures where both processors and memory contents (including stale messages in transit) are prone to errors, faults and malicious behaviors. The proposed implementation extends previous BFT implementations in two ways. First, the algorithm works even when the local memory of processors and the content of the communication channels are initially corrupted in an arbitrary manner. Second, unlike previous solutions, our algorithm uses bounded logical timestamps, a feature difficult to achieve in the presence of transient errors.},
  keywords={},
  doi={10.1109/IPDPS.2015.89},
  ISSN={1530-2075},
  month={May},}
@INPROCEEDINGS{7161546,
  author={Moustafa, Salli and Faverge, Mathieu and Plagne, Laurent and Ramet, Pierre},
  booktitle={2015 IEEE International Parallel and Distributed Processing Symposium}, 
  title={3D Cartesian Transport Sweep for Massively Parallel Architectures with PaRSEC}, 
  year={2015},
  volume={},
  number={},
  pages={581-590},
  abstract={High-fidelity nuclear power plant core simulations require solving the Boltzmann transport equation. In discrete ordinates methods, the most computationally demanding operation of this equation is the sweep operation. Considering the evolution of computer architectures, we propose in this paper, as a first step toward heterogeneous distributed architectures, a hybrid parallel implementation of the sweep operation on top of the generic task-based runtime system: PaRSEC. Such an implementation targets three nested levels of parallelism: message passing, multi-threading, and vectorization. A theoretical performance model was designed to validate the approach and help the tuning of the multiple parameters involved in such an approach. The proposed parallel implementation of the Sweep achieves a sustained performance of 6.1 Tflop/s, corresponding to 33.9% of the peak performance of the targeted supercomputer. This implementation compares favourably with state-of-art solvers such as PartiSN, and it can therefore serve as a building block for a massively parallel version of the neutron transport solver DOMINO developed at EDF.},
  keywords={},
  doi={10.1109/IPDPS.2015.75},
  ISSN={1530-2075},
  month={May},}
@INPROCEEDINGS{7161554,
  author={Si, Min and Peña, Antonio J. and Hammond, Jeff and Balaji, Pavan and Takagi, Masamichi and Ishikawa, Yutaka},
  booktitle={2015 IEEE International Parallel and Distributed Processing Symposium}, 
  title={Casper: An Asynchronous Progress Model for MPI RMA on Many-Core Architectures}, 
  year={2015},
  volume={},
  number={},
  pages={665-676},
  abstract={In this paper we present "Casper," a process-based asynchronous progress solution for MPI one-sided communication on multi- and many-core architectures. Casper uses transparent MPI call redirection through PMPI and MPI-3 shared-memory windows to map memory from multiple user processes into the address space of one or more ghost processes, thus allowing for asynchronous progress where needed while allowing native hardware-based communication where available. Unlike traditional thread- and interrupt-based asynchronous progress models, Casper provides the capability to dedicate an arbitrary number of ghost processes for asynchronous progress, thus balancing application requirements with the capabilities of the underlying MPI implementation. We present a detailed design of the proposed architecture including several techniques for maintaining correctness per the MPI-3 standard as well as performance optimizations where possible. We also compare Casper with traditional thread- and interrupt-based asynchronous progress models and demonstrate its performance improvements with a variety of micro benchmarks and a production chemistry application.},
  keywords={},
  doi={10.1109/IPDPS.2015.35},
  ISSN={1530-2075},
  month={May},}
@INPROCEEDINGS{7161552,
  author={Ropars, Thomas and Lefray, Arnaud and Kim, Dohyun and Schiper, André},
  booktitle={2015 IEEE International Parallel and Distributed Processing Symposium}, 
  title={Efficient Process Replication for MPI Applications: Sharing Work between Replicas}, 
  year={2015},
  volume={},
  number={},
  pages={645-654},
  abstract={With the increased failure rate expected in future extreme scale supercomputers, process replication might become a viable alternative to check pointing. By default, the workload efficiency of replication is limited to 50% because of the additional resources that have to be used to execute the replicas of the application's processes. In this paper, we introduce intra-parallelization, a solution that avoids replicating all computation by introducing work-sharing between replicas. We show on a representative set of benchmarks that intra-parallelization allows achieving more than 50% efficiency without compromising fault tolerance.},
  keywords={},
  doi={10.1109/IPDPS.2015.29},
  ISSN={1530-2075},
  month={May},}
@INPROCEEDINGS{7164773,
  author={Singh, Natthan and Chandra, Manik and Yadav, Divakar},
  booktitle={2015 International Conference on Advances in Computer Engineering and Applications}, 
  title={Formal specification of asynchronous checkpointing using Event-B}, 
  year={2015},
  volume={},
  number={},
  pages={659-664},
  abstract={The major issue in distributed systems is the recovery from some short term failures. It is desired to have transparent scheme for recovery, from such failures, which is efficient as well. Checkpoint is the one of the scheme. Checkpoint-based protocols simply depend on checkpointing in order to get system state restoration. Generally, checkpointing may be categorised as synchronous, asynchronous or communication-induced. While, there is another mechanism, log-based, in which checkpointing also include logging of nondeterministic events. These events are encoded in tuples known as determinants. A formal reasoning is required to precisely understand the behaviour of such techniques and to understand how they achieve the objectives. Event-B is a formal technique which gives a framework for the distributed systems by mathematical models. We are presenting a formal development of asynchronous checkpointing using Event-B in this paper.},
  keywords={},
  doi={10.1109/ICACEA.2015.7164773},
  ISSN={},
  month={March},}
@INPROCEEDINGS{7164951,
  author={Chao, Lu and Li, Chundian and Liang, Fan and Lu, Xiaoyi and Xu, Zhiwei},
  booktitle={2015 IEEE 35th International Conference on Distributed Computing Systems}, 
  title={Accelerating Apache Hive with MPI for Data Warehouse Systems}, 
  year={2015},
  volume={},
  number={},
  pages={664-673},
  abstract={Data warehouse systems, like Apache Hive, have been widely used in the distributed computing field. However, current generation data warehouse systems have not fully embraced High Performance Computing (HPC) technologies even though the trend of converging Big Data and HPC is emerging. For example, in traditional HPC field, Message Passing Interface (MPI) libraries have been optimized for HPC applications during last decades to deliver ultra-high data movement performance. Recent studies, like DataMPI, are extending MPI for Big Data applications to bridge these two fields. This trend motivates us to explore whether MPI can benefit data warehouse systems, such as Apache Hive. In this paper, we propose a novel design to accelerate Apache Hive by utilizing DataMPI. We further optimize the DataMPI engine by introducing enhanced non-blocking communication and parallelism mechanisms for typical Hive workloads based on their communication characteristics. Our design can fully and transparently support Hive workloads like Intel HiBench and TPC-H with high productivity. Performance evaluation with Intel HiBench shows that with the help of light-weight DataMPI library design, efficient job start up and data movement mechanisms, Hive on DataMPI performs 30% faster than Hive on Hadoop averagely. And the experiments on TPC-H with ORCFile show that the performance of Hive on DataMPI can improve 32% averagely and 53% at most more than that of Hive on Hadoop. To the best of our knowledge, Hive on DataMPI is the first attempt to propose a general design for fully supporting and accelerating data warehouse systems with MPI.},
  keywords={},
  doi={10.1109/ICDCS.2015.73},
  ISSN={1063-6927},
  month={June},}
@INPROCEEDINGS{7168426,
  author={Soiman, Stefania-Iuliana and Rusu, Ionela and Pentiuc, Stefan-Gheorghe},
  booktitle={2015 20th International Conference on Control Systems and Computer Science}, 
  title={Multilevel Parallelized Forward Algorithm for Hidden Markov Models on IBM Roadrunner Clusters}, 
  year={2015},
  volume={},
  number={},
  pages={177-182},
  abstract={In this work we propose an efficient parallel algorithm to evaluate an observation sequence on Hidden Markov Model starting from the sequential Forward Algorithm (FA). The Cell Broadband Engine (Cell/B.E.) hybrid architecture, allows us to approach two levels of parallelization in developing our algorithms. Two strategies were implemented and tested in order to obtain a parallel version of the FA, using solely the Message Passing Interface (MPI) and, in the second case, using the MPI along with the Synergistic Processing Elements (SPEs) on the Cell/B.E. Processors. Performance tests were run for the two approached techniques on an IBM Roadrunner cluster with Power XCell8i processors. We found that our parallel versions of FA performed approximately 37 times faster on Cell/B.E. Processors without SPE cores, and 75 times faster with SPE cores the, compared to the serial algorithm.},
  keywords={},
  doi={10.1109/CSCS.2015.42},
  ISSN={2379-0482},
  month={May},}
@INPROCEEDINGS{7185066,
  author={Lekidis, Alexios and Stachtiari, Emmanouela and Katsaros, Panagiotis and Bozga, Marius and Georgiadis, Christos K.},
  booktitle={10th IEEE International Symposium on Industrial Embedded Systems (SIES)}, 
  title={Using BIP to reinforce correctness of resource-constrained IoT applications}, 
  year={2015},
  volume={},
  number={},
  pages={1-10},
  abstract={Internet of Things (IoT) systems process and respond to multiple (external) events, while performing computations for a Sense-Compute-Control (SCC) or a Sense-Only (SO) goal. Given the limitations of the interconnected resource-constrained devices, the execution environment can be based on an appropriate operating system for the IoT. The development effort can be reduced, when applications are built on top of RESTful web services, which can be shared and reused. However, the asynchronous communication between remote nodes is prone to event scheduling delays, which cannot be predicted and taken into account while programming the application. Long delays in message processing and communication, due to packet collisions, are avoided by carefully choosing the data transmission frequencies between the system's nodes. But even when specialized simulators are available, it is still a hard challenge to guarantee the functional and non-functional requirements at the application and system levels. In this article, we introduce a model-based rigorous analysis approach using the BIP component framework. We present a BIP model for IoT applications running on the Contiki OS. At the application level, we verify qualitative properties for service responsiveness requirements, whereas at the system level we can validate qualitative and quantitative properties using statistical model checking. We present results for an application scenario running on a distributed system infrastructure.},
  keywords={},
  doi={10.1109/SIES.2015.7185066},
  ISSN={2150-3117},
  month={June},}
@INPROCEEDINGS{7184879,
  author={Lin, Jian and Liang, Fan and Lu, Xiaoyi and Zha, Li and Xu, Zhiwei},
  booktitle={2015 IEEE First International Conference on Big Data Computing Service and Applications}, 
  title={Modeling and Designing Fault-Tolerance Mechanisms for MPI-Based MapReduce Data Computing Framework}, 
  year={2015},
  volume={},
  number={},
  pages={176-183},
  abstract={Fault-tolerance is a significant property for distributed and parallel computing systems. An emerging trend of Big Data computing is to combine MPI and MapReduce technologies in a single framework. The distinctive state model in this kind of frameworks brings challenges to designing an efficient and transparent fault-tolerance mechanism. In this paper, a state model analysis method is proposed for uniformly modeling independent MPI, MapReduce and MPI-based MapReduce data computing frameworks. Based on this analysis, a library-level fault-tolerance mechanism with global persistent state model is proposed, a data-staging and routine-sharing based checkpoint approach is designed within this mechanism. The proposed mechanism has been implemented in DataMPI, a communication library supporting MPI-based MapReduce data computing applications. The experiments show that it can transparently enable fault-tolerance for applications. Taking TeraSort as an example, it introduces only 6.8% time overhead and 11% space overhead. For a failure-resume execution, it has a 10%-32% performance advantage compared with the naive checkpoint solutions based on local or parallel storages. The proposed mechanism also provides superior performance and resource utilization compared with Hadoop for both fault-free and failure-resume executions.},
  keywords={},
  doi={10.1109/BigDataService.2015.33},
  ISSN={},
  month={March},}
@INPROCEEDINGS{7195588,
  author={Jia, Changjiang and Yang, Chunbai and Chan, W.K.},
  booktitle={2015 IEEE International Conference on Web Services}, 
  title={Architecturing Dynamic Data Race Detection as a Cloud-Based Service}, 
  year={2015},
  volume={},
  number={},
  pages={345-352},
  abstract={A web-based service consists of layers of programs (components) in the technology stack. Analyzing program executions of these components separately allows service vendors to acquire insights into specific program behaviors or problems in these components, thereby pinpointing areas of improvement in their offering services. Many existing approaches for testing as a service take an orchestration approach that splits components under test and the analysis services into a set of distributed modules communicating through message-based approaches. In this paper, we present the first work in providing dynamic analysis as a service using a virtual machine (VM)-based approach on dynamic data race detection. Such a detection needs to track a huge number of events performed by each thread of a program execution of a service component, making such an analysis unsuitable to use message passing to transit huge numbers of events individually. In our model, we instruct VMs to perform holistic dynamic race detections on service components and only transfer the detection results to our service selection component. With such result data as the guidance, the service selection component accordingly selects VM instances to fulfill subsequent analysis requests. The experimental results show that our model is feasible.},
  keywords={},
  doi={10.1109/ICWS.2015.54},
  ISSN={},
  month={June},}
@ARTICLE{7219476,
  author={Shirvanimoghaddam, Mahyar and Li, Yonghui and Vucetic, Branka and Yuan, Jinhong and Zhang, Philipp},
  journal={IEEE Transactions on Signal Processing}, 
  title={Binary Compressive Sensing Via Analog Fountain Coding}, 
  year={2015},
  volume={63},
  number={24},
  pages={6540-6552},
  abstract={In this paper, a compressive sensing (CS) approach is proposed for sparse binary signals' compression and reconstruction based on analog fountain codes (AFCs). In the proposed scheme, referred to as the analog fountain compressive sensing (AFCS), each measurement is generated from a linear combination of L randomly selected binary signal elements with real weight coefficients. The weight coefficients are chosen from a finite weight set and L, called measurement degree, is obtained based on a predefined degree distribution function. We propose a simple verification based reconstruction algorithm for the AFCS in the noiseless case. The proposed verification based decoder is analyzed through SUM-OR tree analytical approach and an optimization problem is formulated to find the optimum measurement degree to minimize the number of measurements required for the reconstruction of binary sparse signals. We show that in the AFCS, the number of required measurements is of O(-nlog(1-k/n)), where n is the signal length and L=k is the signal sparsity level. Simulation results show that the AFCS can perfectly recover all non-zero elements of the sparse binary signal with a significantly reduced number of measurements, compared to the conventional binary CS and l1-minimization approaches in a wide range of signal to noise ratios (SNRs) by using the standard message passing decoder. Finally, we show a practical application of the AFCS for the sparse event detection in wireless sensor networks (WSNs), where the sensors' readings can be treated as measurements from the CS point of view.},
  keywords={},
  doi={10.1109/TSP.2015.2472362},
  ISSN={1941-0476},
  month={Dec},}
@INPROCEEDINGS{7225952,
  author={Joshi, Ramesh and Parihar, Manoj and Jadav, H M and Kulkarni, S.V.},
  booktitle={2015 IEEE International Conference on Electrical, Computer and Communication Technologies (ICECCT)}, 
  title={Epics based prototype client for ICRH DAC}, 
  year={2015},
  volume={},
  number={},
  pages={1-5},
  abstract={The VME based Ion Cyclotron Resonance Heating (ICRH) Data Acquisition Control system (DAC) is integrated for auxiliary heating experiment on SST-1 Tokamak. VME processor board contains real-time operating system which works as server and Linux based host computer contains client user interface and additional support software. ICRH-DAC is distributed into two sections one at RF Lab and second at SST-1 hall which are 200 meter far away from each other. RF Lab DAC is installed to take care of RF power generation part. SST-1 hall DAC is installed to take care of diagnostics, matching networks and interface vacuum. Both DACs are running on master-slave mode when synchronized operation is needed. This synchronization of both DAC could be possible with EPICS (Experimental Physics and Industrial Control System) process variables, which broadcast and describe itself in Ethernet. The existing system uses the TCP/IP socket communication between both DAC clients. EPICS provides channel access protocol layers which broadcast required process variable on periodic time interval which are available on network for communication. Master DAC communicates with central control system using high speed trigger network and message passing interface on Ethernet network. During experiment shot details available using TCP/IP socket communication to master DAC only with hardware trigger event. Slave DAC acquires data using experimental shot details available on network which are broadcasted by master DAC using EPICS process variables. Same way the interface vacuum monitored at slave DAC will be available to master DAC for interlock. The prototype program is used for real-time parameters transmission, dynamic graphical user interface, modification of the existing system with synchronization. This paper will describe the prototype software design of EPICS based ICRH DAC software to achieve desired goal of experiment.},
  keywords={},
  doi={10.1109/ICECCT.2015.7225952},
  ISSN={},
  month={March},}
@INPROCEEDINGS{7227005,
  author={Vukobratovic, Dejan and Sejdinovic, Dino and Pizurica, Aleksandra},
  booktitle={2015 IEEE 16th International Workshop on Signal Processing Advances in Wireless Communications (SPAWC)}, 
  title={Compressed Sensing using sparse binary measurements: A rateless coding perspective}, 
  year={2015},
  volume={},
  number={},
  pages={86-90},
  abstract={Compressed Sensing (CS) methods using sparse binary measurement matrices and iterative message-passing recovery procedures have been recently investigated due to their low computational complexity and excellent performance. Drawing much of inspiration from sparse-graph codes such as Low-Density Parity-Check (LDPC) codes, these studies use analytical tools from modern coding theory to analyze CS solutions. In this paper, we consider and systematically analyze the CS setup inspired by a class of efficient, popular and flexible sparse-graph codes called rateless codes. The proposed rateless CS setup is asymptotically analyzed using tools such as Density Evolution and EXIT charts and fine-tuned using degree distribution optimization techniques.},
  keywords={},
  doi={10.1109/SPAWC.2015.7227005},
  ISSN={1948-3252},
  month={June},}
@INPROCEEDINGS{7237072,
  author={Utrera, Gladys and Gil, Marisa and Martorell, Xavier},
  booktitle={2015 International Conference on High Performance Computing & Simulation (HPCS)}, 
  title={In search of the best MPI-OpenMP distribution for optimum Intel-MIC cluster performance}, 
  year={2015},
  volume={},
  number={},
  pages={429-435},
  abstract={Applications for HPC platforms are mainly based on hybrid programming models: MPI for communication and OpenMP for task and fork-join parallelism to exploit shared memory communication inside a node. On the basis of this scheme, much research has been carried out to improve performance. Some examples are: the overlap of communication and computation, or the increase of speedup and bandwidth on new network fabrics (i.e. Infiniband and 10GB or 40GB ethernet). Henceforth, as far as computation and communication are concerned, the HPC platforms will be heterogeneous with high-speed networks. And, in this context, an important issue is to decide how to distribute the workload among all the nodes in order to balance the application execution as well as choosing the most appropriate programming model to exploit parallelism inside the node. In this paper we propose a mechanism to balance dynamically the work distribution among the heterogeneous components of an heterogeneous cluster based on their performance characteristics. For our evaluations we run the miniFE mini-application of the Mantevo suite benchmark, in a heterogeneous Intel MIC cluster. Experimental results show that making an effort to choose the appropriate number of threads can improve performance significantly over choosing the maximum available number of cores in the Intel MIC.},
  keywords={},
  doi={10.1109/HPCSim.2015.7237072},
  ISSN={},
  month={July},}
@INPROCEEDINGS{7282622,
  author={Shari, Shahrouz and Tanc, A. Korhan and Duman, Tolga M.},
  booktitle={2015 IEEE International Symposium on Information Theory (ISIT)}, 
  title={LDPC code design for binary-input binary-output Z interference channels}, 
  year={2015},
  volume={},
  number={},
  pages={1084-1088},
  abstract={In this paper, we explore code optimization for two-user discrete memoryless interference channels (DMICs) wherein the inputs and outputs of the channel are from a finite alphabet. For encoding, we employ irregular low-density parity-check (LDPC) codes combined with non-linear trellis codes (NLTCs) to satisfy the desired distribution of zeros and ones in the transmitted codewords. At the receiver sides, we adopt BCJR algorithm based decoders to compute the symbol-by-symbol log-likelihood ratios (LLRs) of LDPC coded bits to be fed to message passing decoders. As a specific example, we consider the binary-input binary-output Z interference channel (BIBO ZIC) for which the transmitted and received signals are binary and one of the receivers is interference free. For a specific example of a BIBO ZIC, we examine the Han-Kobayashi inner bound on the achievable rate pairs and show that with a simple scheme of sending the messages as private one can achieve the sum-capacity of the channel. We also perform code optimization and demonstrate that the jointly optimized codes outperform the optimal single user codes with time sharing.},
  keywords={},
  doi={10.1109/ISIT.2015.7282622},
  ISSN={2157-8117},
  month={June},}
@INPROCEEDINGS{7284349,
  author={Tang, Jian and Larrea, Mikel and Arévalo, Sergio and Jiménez, Ernesto},
  booktitle={2015 IEEE International Parallel and Distributed Processing Symposium Workshop}, 
  title={Implementing Uniform Reliable Broadcast in Anonymous Distributed Systems with Fair Lossy Channels}, 
  year={2015},
  volume={},
  number={},
  pages={500-508},
  abstract={Uniform Reliable Broadcast (URB) is an important abstraction in distributed systems, offering delivery guarantee when spreading messages among processes. Informally, URB guarantees that if a process (correct or not) delivers a message m, then all correct processes deliver m. This abstraction has been extensively investigated in distributed systems where all processes have different identifiers. Furthermore, the majority of papers in the literature usually assume that the communication channels of the system are reliable, which is not always the case in real systems. In this paper, the URB abstraction is investigated in anonymous asynchronous message passing systems with fair lossy communication channels. Firstly, a simple algorithm is given to solve URB in such system model assuming a majority of correct processes. Then a new failure detector class AT is proposed. With AT, URB can be implemented with any number of correct processes. Due to the message loss caused by fair lossy communication channels, every correct process in this first algorithm has to broadcast all URB delivered messages forever, which makes the algorithm to be non-quiescent. In order to get a quiescent URB algorithm in anonymous asynchronous systems, a perfect anonymous failure detector AP* is proposed. Finally, a quiescent URB algorithm using AT and AP* is given.},
  keywords={},
  doi={10.1109/IPDPSW.2015.23},
  ISSN={},
  month={May},}
@INPROCEEDINGS{7284408,
  author={Bhalachandra, Sridutt and Porterfield, Allan and Prins, Jan F.},
  booktitle={2015 IEEE International Parallel and Distributed Processing Symposium Workshop}, 
  title={Using Dynamic Duty Cycle Modulation to Improve Energy Efficiency in High Performance Computing}, 
  year={2015},
  volume={},
  number={},
  pages={911-918},
  abstract={Power is increasingly the limiting factor in High Performance Computing (HPC). Growing core counts in each generation increase power and energy demands. In the future, strict power and energy budgets will be used to control the operating costs of supercomputer centers. Every node needs to use energy wisely. Energy efficiency can either be improved by taking less time or running at lower power. In this paper, we use Dynamic Duty Cycle Modulation (DDCM) to improve energy efficiency by improving performance under a power bound. When the power is not capped, DDCM reduces processor power, saving energy and reducing processor temperature. DDCM allows the clock frequency to be controlled for each individual core with very low overhead. Any situation where the individual threads on a processor are exhibiting imbalance, a more balanced execution can be obtained by slowing the "fast" threads. We use time between MPI collectives and the waiting time at the collective to determine a thread's "near optimal" frequency. All changes are within the MPI library, introducing no user code changes or additional communication/synchronization. To test DDCM, a set of synthetic MPI programs with load imbalance were created. In addition, a couple of HPC MPI benchmarks with load imbalance were examined. In our experiments, DDCM saves up to 13.5% processor energy on one node and 20.8% on 16 nodes. By applying a power cap, DDCM effectively shifts power consumption between cores and improves overall performance. Performance improvements of 6.0% and 5.6% on one and 16 nodes, respectively, were observed.},
  keywords={},
  doi={10.1109/IPDPSW.2015.144},
  ISSN={},
  month={May},}
@INPROCEEDINGS{7284314,
  author={Lin, Jian and Hamidouche, Khaled and Lu, Xiaoyi and Li, Mingzhe and Panda, Dhabaleswar K.},
  booktitle={2015 IEEE International Parallel and Distributed Processing Symposium Workshop}, 
  title={High-Performance Coarray Fortran Support with MVAPICH2-X: Initial Experience and Evaluation}, 
  year={2015},
  volume={},
  number={},
  pages={225-234},
  abstract={Coarray Fortran (CAF) is a parallel programming paradigm that extends Fortran for the partitioned global address space (PGAS) programming model at the language level. The current runtime implementations of CAF are mainly using MPI or GASNet as underlying communication components. MVAPICH2-X is a hybrid MPI+PGAS programming library with a Unified Communication Runtime (UCR) design. In this paper, the classic implementation of CAF runtime in Open UH is redesigned and rebuilt on top of MVAPICH2-X. The proposed design does not only enable the support of MPI+CAF hybrid programming model, but also provides superior performance on most of the CAF one-sided operations and the newly proposed collective operations in Fortran 2015 specification. A comprehensive evaluation with different benchmarks and applications has been performed. Comparing with current GASNet-based solutions, the CAF runtime with MVAPICH2-X can improve the bandwidths of put and bidirectional operations up to 3.5X for inter-node communication, and improve the bandwidths of collective communication operations represented by broadcast up to 3.0X on 64 processes. It also reduces the execution time of NPB CAF benchmarks by up to 18% on 256 processes.},
  keywords={},
  doi={10.1109/IPDPSW.2015.115},
  ISSN={},
  month={May},}
@ARTICLE{7294666,
  author={Wang, Sheng and Rahnavard, Nazanin},
  journal={IEEE Transactions on Communications}, 
  title={A Framework for Compressive Sensing of Asymmetric Signals Using Normal and Skew-Normal Mixture Prior}, 
  year={2015},
  volume={63},
  number={12},
  pages={5062-5072},
  abstract={In this work, we are interested in the compressive sensing of sparse signals whose significant coefficients are distributed asymmetrically with respect to zero. To properly address this problem, we develop a framework utilizing a two-state normal and skew normal mixture density as the prior distribution of the signal. The significant and insignificant coefficients of the signal are represented by skew normal and normal distributions, respectively. A novel approximate message passing-based algorithm is developed to estimate the signal from its compressed measurements. A fast gradient-based estimator is designed to infer the density of each state. Experiment results on simulated data and two real-world tests, i.e., multi-input multi-output (MIMO) communication system and weather sensor network, confirm that our proposed technique is powerful in exploiting asymmetrical feature, and outperforms many sophisticated methods.},
  keywords={},
  doi={10.1109/TCOMM.2015.2488651},
  ISSN={1558-0857},
  month={Dec},}
@INPROCEEDINGS{7300241,
  author={Baua'a, Mustapha M. and Shareef, Jehan K. and Hamad, Aqeel M.},
  booktitle={2015 Fourth International Conference on Future Generation Communication Technology (FGCT)}, 
  title={Virtual and physical parallelism environments evaluation}, 
  year={2015},
  volume={},
  number={},
  pages={1-5},
  abstract={Parallelism is the concept that associates with executing a problem by multi-computer. This concept is used for increasing multitasks performance execution effectively. Many algorithms, techniques, architectures, frameworks, and environments are found to enhance this concept and finally enhance the performance. However, two basic environments already exist to be used by parallelism; these two environments are Virtual and Physical parallelism. Both of these two runtime environments have their features, advantages and disadvantages. The paper focuses on analyze, evaluate and clarify some differences between these two environments. Results in this proposal depend on real case study executed via JavaThread, OpenMP, MPI in virtual environment and an MPI in physical environment. Implementation of the case study and validation results are shown and they clearly clarify the advantages, disadvantages and limits of using any runtime of them.},
  keywords={},
  doi={10.1109/FGCT.2015.7300241},
  ISSN={2377-2638},
  month={July},}
@INPROCEEDINGS{7304277,
  author={Walsh, John and Dukes, Jonathan},
  booktitle={2015 IEEE 11th International Conference on e-Science}, 
  title={Application Support for Virtual GPGPUs in Grid Infrastructures}, 
  year={2015},
  volume={},
  number={},
  pages={67-77},
  abstract={Scientific computing on grid infrastructures has historically focused on processing vast workloads of independent single-core CPU jobs. Limitations of this approach, however, have motivated a shift towards parallel computing using message passing, multi-core CPUs and computational accelerators, including GPGPUs in particular. Application support for the use of GPGPUs in existing grid infrastructures is still lacking. A model is proposed for the orchestration of GPGPU-enabled applications based on commonly used frameworks such as CUDA and OpenCL. The model makes use of recent advances in remote GPGPU virtualisation, making it possible for an application to access GPGPUs installed on remote hosts. Each physical GPGPU is isolated, creating a pool of virtual GPGPUs that can be allocated independently to jobs. A proof-of-concept Grid supporting virtual GPGPUs has been implemented and tested. It will be shown that users can be provided with a simple yet flexible and powerful mechanism for specifying GPGPU requirements. Furthermore, vGPGPU provision can be fully integrated with existing grid middleware and services. Performance results suggest that improved resource utilisation can compensate for the overhead of remote GPGPU access.},
  keywords={},
  doi={10.1109/eScience.2015.45},
  ISSN={},
  month={Aug},}
@INPROCEEDINGS{7304285,
  author={Nguyen, Anthony and Matsunaga, Andréa and Tsugawa, Maurício and Date, Susumu and Ichikawa, Kohei and Haga, Jason H.},
  booktitle={2015 IEEE 11th International Conference on e-Science}, 
  title={Deployment of a Multi-site Cloud Environment for Molecular Virtual Screenings}, 
  year={2015},
  volume={},
  number={},
  pages={145-154},
  abstract={With the constant increase in the number and variety of small molecule chemical compounds, drug discovery is becoming a very resource intensive endeavor. Performing molecular simulations of ligand-protein binding by virtual screening has become an integral part of the discovery process. Cloud computing is an efficient choice to execute these large-scale screenings, given that large compute allocations are not accessible to many researchers. This research focused on developing a multi-site cloud environment that combines small allocations of virtual machines in multiple locations connected through a virtual networking system (ViNe), and compared two parallelization approaches: Message Passing Interface (MPI) and MapReduce using Hadoop. Virtual screenings were conducted using DOCK, a protein-ligand molecular interaction simulation program. Multiple DOCK test simulations through MPI and Hadoop were run to assess the performance and flexibility of the environment. These tests indicated that MPI and MapReduce offer comparable scalability performance, and that network latency has a significant influence on low accuracy simulations. Furthermore, differences in performance at individual cloud resource sites were reduced on average because of the larger combined pool of resources. This project prototyped and assessed a fully functional multi-site cloud environment for virtual screenings, which can be used to guide small laboratories in deploying their own cloud-based screenings.},
  keywords={},
  doi={10.1109/eScience.2015.49},
  ISSN={},
  month={Aug},}
@INPROCEEDINGS{7311827,
  author={Gîză-Belciug, Felicia and Pentiuc, Ştefan-Gheorghe},
  booktitle={2015 14th RoEduNet International Conference - Networking in Education and Research (RoEduNet NER)}, 
  title={Parallelization of similarity matrix calculus in ontology mapping systems}, 
  year={2015},
  volume={},
  number={},
  pages={50-55},
  abstract={Ontology mapping systems are used in different areas of applications, including the real time ones. In order to increase their performance various approaches have been proposed and a large number of mapping systems were developed, but their performance fails when it comes to large ontologies. In the ontotogy mapping process the similarity matrix calculus takes about 50% of the entire execution time. We focused on this calculus and we proposed a parallel algorithm for computing the linguistic similarity matrix of two ontologies. This algorithm has been tested in different configurations: one or more computing nodes, different number of running processes. Different specializations of running processes were taken into consideration: either all for computing, or one for distributing and managing the results of the tasks and the rest for computing. For implementation we took into account the Java MPI, the MPJExpress project was used as middleware for messaging communication in Java, and we evaluated the time of message passing. The resulted module for similarity matrix computing was inserted in Falcon-AO, one of the systems with the best execution time for medium size ontology, in order to improve its overall mapping performance.},
  keywords={},
  doi={10.1109/RoEduNet.2015.7311827},
  ISSN={2247-5443},
  month={Sep.},}
@INPROCEEDINGS{7307653,
  author={Martsinkevich, Tatiana and Subasi, Omer and Unsal, Osman and Cappello, Franck and Labarta, Jesus},
  booktitle={2015 IEEE International Conference on Cluster Computing}, 
  title={Fault-Tolerant Protocol for Hybrid Task-Parallel Message-Passing Applications}, 
  year={2015},
  volume={},
  number={},
  pages={563-570},
  abstract={We present a fault-tolerant protocol for task-parallel message-passing applications to mitigate transient errors. The protocol requires the restart only of the task that experienced the error and transparently handles any MPI calls inside the task. The protocol is implemented in Nanos -- a dataflow runtime for task-based OmpSs programming model -- and the PMPI profiling layer to fully support hybrid OmpSs+MPI applications. In our experiments we demonstrate that our fault-tolerant solution has a reasonable overhead, with a maximum observed overhead of 4.5%. We also show that fine-grained parallelization is important for hiding the overheads related to the protocol as well as the recovery of tasks.},
  keywords={},
  doi={10.1109/CLUSTER.2015.104},
  ISSN={2168-9253},
  month={Sep.},}
@INPROCEEDINGS{7307611,
  author={Gahvari, Hormozd and Schulz, Martin and Yang, Ulrike Meier},
  booktitle={2015 IEEE International Conference on Cluster Computing}, 
  title={An Approach to Selecting Thread + Process Mixes for Hybrid MPI + OpenMP Applications}, 
  year={2015},
  volume={},
  number={},
  pages={418-427},
  abstract={Hybrid MPI + OpenMP is a popular means of programming modern machines that feature substantial parallelism both off-node and on-node. Determining the right mix of the two programming models to use, however, is not as straightforward as simply using exclusively OpenMP on-node and limiting MPI to only inter-node communication. We present a step-by-step methodology to help make the decision of which mix of the two programming models to use. It starts with an estimate of the performance of a generic hybrid application on a given machine and incorporates additional available information about the specific application and the machine to provide guidance for selecting effective mixes of MPI processes and OpenMP threads to use when running that application on the machine in question. We validate our approach on four different applications on an IBM Blue Gene/Q, a Cray XK7, and a Cray XC30.},
  keywords={},
  doi={10.1109/CLUSTER.2015.64},
  ISSN={2168-9253},
  month={Sep.},}
@INPROCEEDINGS{7307578,
  author={Feng, Kun and Venkata, Manjunath Gorentla and Li, Dong and Sun, Xian-He},
  booktitle={2015 IEEE International Conference on Cluster Computing}, 
  title={Fast Fault Injection and Sensitivity Analysis for Collective Communications}, 
  year={2015},
  volume={},
  number={},
  pages={148-157},
  abstract={The collective communication operations, which are widely used in parallel applications for global communication and synchronization are critical for application's performance and scalability. However, how faulty collective communications impact the application and how errors propagate between the application processes is largely unexplored. One of the critical reasons for this situation is the lack of fast evaluation method to investigate the impacts of faulty collective operations. The traditional random fault injection methods relying on a large amount of fault injection tests to ensure statistical significance require a significant amount of resources and time. These methods result in prohibitive evaluation cost when applied to the collectives. In this paper, we introduce a novel tool named Fast Fault Injection and Sensitivity Analysis Tool (FastFIT) to conduct fast fault injection and characterize the application sensitivity to faulty collectives. The tool achieves fast exploration by reducing the exploration space and predicting the application sensitivity using Machine Learning (ML) techniques. A basis for these techniques are implicit correlations between MPI semantics, application context, critical application features, and application responses to faulty collective communications. The experimental results show that our approach reduces the fault injection points and tests by 97% for representative benchmarks (NAS Parallel Benchmarks (NPB)) and a realistic application (Large-scale Atomic/Molecular Massively Parallel Simulator (LAMMPS)) on a production supercomputer. Further, we statistically generalize the application sensitivity to faulty collective communications for these workloads, and present correlation between application features and the sensitivity.},
  keywords={},
  doi={10.1109/CLUSTER.2015.31},
  ISSN={2168-9253},
  month={Sep.},}
@INPROCEEDINGS{7307598,
  author={Rettenberger, Sebastian and Bader, Michael},
  booktitle={2015 IEEE International Conference on Cluster Computing}, 
  title={Optimizing I/O for Petascale Seismic Simulations on Unstructured Meshes}, 
  year={2015},
  volume={},
  number={},
  pages={314-317},
  abstract={SeisSol simulates earthquake dynamics by coupling seismic wave propagation and dynamic rupture simulations with high order accuracy on fully adaptive, unstructured meshes. In this paper we present an optimization of SeisSol's I/O implementations to establish a workflow that supports petascale simulations on large unstructured datasets. Our implementations can handle meshes with more than 1 billion cells and 660 billion degrees of reedom. The results show that SeisSol can initialize the mesh structure within 35 seconds on 2048 SuperMUC nodes from our new optimized mesh format. For the wave field output we implemented carefully tuned I/O routines based on HDF5 and MPI-IO. With an aggregation strategy we are able to increase the write bandwidth from 832 MiB/s to 6.7 GiB/s on 2048 SuperMUC nodes.},
  keywords={},
  doi={10.1109/CLUSTER.2015.51},
  ISSN={2168-9253},
  month={Sep.},}
@INPROCEEDINGS{7307680,
  author={Ivanov, Ilya and Gong, Jing and Akhmetova, Dana and Peng, Ivy Bo and Markidis, Stefano and Laure, Erwin and Machado, Rui and Rahn, Mirko and Bartsch, Valeria and Hart, Alistair and Fischer, Paul},
  booktitle={2015 IEEE International Conference on Cluster Computing}, 
  title={Evaluation of Parallel Communication Models in Nekbone, a Nek5000 Mini-Application}, 
  year={2015},
  volume={},
  number={},
  pages={760-767},
  abstract={Nekbone is a proxy application of Nek5000, a scalable Computational Fluid Dynamics (CFD) code used for modelling incompressible flows. The Nekbone mini-application is used by several international co-design centers to explore new concepts in computer science and to evaluate their performance. We present the design and implementation of a new communication kernel in the Nekbone mini-application with the goal of studying the performance of different parallel communication models. First, a new MPI blocking communication kernel has been developed to solve Nekbone problems in a three-dimensional Cartesian mesh and process topology. The new MPI implementation delivers a 13% performance improvement compared to the original implementation. The new MPI communication kernel consists of approximately 500 lines of code against the original 7,000 lines of code, allowing experimentation with new approaches in Nekbone parallel communication. Second, the MPI blocking communication in the new kernel was changed to the MPI non-blocking communication. Third, we developed a new Partitioned Global Address Space (PGAS) communication kernel, based on the GPI-2 library. This approach reduces the synchronization among neighbor processes and is on average 3% faster than the new MPI-based, non-blocking, approach. In our tests on 8,192 processes, the GPI-2 communication kernel is 3% faster than the new MPI non-blocking communication kernel. In addition, we have used the OpenMP in all the versions of the new communication kernel. Finally, we highlight the future steps for using the new communication kernel in the parent application Nek5000.},
  keywords={},
  doi={10.1109/CLUSTER.2015.131},
  ISSN={2168-9253},
  month={Sep.},}
@INPROCEEDINGS{7307583,
  author={Rezaei, Arash and Mueller, Frank},
  booktitle={2015 IEEE International Conference on Cluster Computing}, 
  title={DINO: Divergent Node Cloning for Sustained Redundancy in HPC}, 
  year={2015},
  volume={},
  number={},
  pages={180-183},
  abstract={Soft faults like silent data corruption and hard faults like hardware failures may cause a high performance computing (HPC) job of thousands of processes to nearly cease to make progress due to recovery overheads. Redundant computing has been proposed as a solution at extreme scale by allocating two or more processes to perform the same task. However, current redundant computing approaches do not repair failed replicas. Thus, SDC-free execution is not guaranteed after a replica failure and the job may finish with incorrect results. Replicas are logically equivalent, yet may have divergent runtime states during job execution, which complicates on-the-fly repairs for forward recovery. In this work, we present a redundant execution environment that quickly repairs hard failures via Divergent Node cloning (DINO) at the MPI task level. DINO contributes a novel task cloning service integrated into the MPI runtime system that solves the problem of consolidating divergent states among replicas on-the-fly. Experimental results indicate that DINO can recover from failures nearly instantaneously, thus retaining the redundancy level throughout job execution. The cloning overhead, depending on the process image size and its transfer rate, ranges from 5.60 to 90.48 seconds. To the best of our knowledge, the design and implementation for repairing failed replicas in redundant MPI computing is unprecedented.},
  keywords={},
  doi={10.1109/CLUSTER.2015.36},
  ISSN={2168-9253},
  month={Sep.},}
@INPROCEEDINGS{7307690,
  author={Andújar, Franisco J. and Villar, Juan A. and Sánchez, José L. and Alfaro, Francisco J. and Escudero-Sahuquillo, Jesus},
  booktitle={2015 IEEE International Conference on Cluster Computing}, 
  title={VEF Traces: A Framework for Modelling MPI Traffic in Interconnection Network Simulators}, 
  year={2015},
  volume={},
  number={},
  pages={841-848},
  abstract={Simulation is often used to evaluate the behaviour and measure the performance of computing systems. Specifically, in high-performance interconnection networks, the simulation has been extensively considered to verify the behaviour of the network itself and to evaluate its performance. In this context, network simulation must be fed with network traffic, also referred to as network workload, whose nature has been traditionally synthetic. These workloads can be used for the purpose of driving studies on network performance, but often such workloads are not accurate enough if a realistic evaluation is pursued. For this reason, other non-synthetic workloads have gained popularity over last decades since they are best to capture the realistic behaviour of existing applications. In this paper, we present the VEF traces framework, a self-related trace model, and all their associated tools. The main novelty of this framework is that, unlike existing ones, it does not provide a network simulation framework, but only offers an MPI task simulation framework, which allows one to use the MPI-based network traffic by any third-party network simulator, since this framework does not depend on any specific simulation platform.},
  keywords={},
  doi={10.1109/CLUSTER.2015.141},
  ISSN={2168-9253},
  month={Sep.},}
@INPROCEEDINGS{7307617,
  author={Ma, Hongyi and Wang, Liqiang and Krishnamoorthy, Krishanthan},
  booktitle={2015 IEEE International Conference on Cluster Computing}, 
  title={Detecting Thread-Safety Violations in Hybrid OpenMP/MPI Programs}, 
  year={2015},
  volume={},
  number={},
  pages={460-463},
  abstract={We propose an approach by integrating static and dynamic program analyses to detect thread-safety violations in hybrid MPI/OpenMP programs. We innovatively transform the thread-safety violation problems to race conditions problems. In our approach, the static analysis identifies a list of MPI calls related to thread-safety violations, then replaces them with our own MPI wrappers, which involve accesses to some specific shared variables. The static analysis avoids instrumenting unrelated code, which significantly reduces runtime overhead. In the dynamic analysis, both happen-before and lockset-based race detection algorithms are used to detect races on these aforementioned shared variables. By detecting races, we can identify thread-safety violations according to their specifications. Our experimental evaluation over real-world applications shows that our approach is both accurate and efficient.},
  keywords={},
  doi={10.1109/CLUSTER.2015.70},
  ISSN={2168-9253},
  month={Sep.},}
@INPROCEEDINGS{7307655,
  author={Shahzad, Faisal and Kreutzer, Moritz and Zeiser, Thomas and Machado, Rui and Pieper, Andreas and Hager, Georg and Wellein, Gerhard},
  booktitle={2015 IEEE International Conference on Cluster Computing}, 
  title={Building a Fault Tolerant Application Using the GASPI Communication Layer}, 
  year={2015},
  volume={},
  number={},
  pages={580-587},
  abstract={It is commonly agreed that highly parallel software on Exascale computers will suffer from many more runtime failures due to the decreasing trend in the mean time to failures (MTTF). Therefore, it is not surprising that a lot of research is going on in the area of fault tolerance and fault mitigation. Applications should survive a failure and/or be able to recover with minimal cost. MPI is not yet very mature in handling failures, the User-Level Failure Mitigation (ULFM) proposal being currently the most promising approach is still in its prototype phase. In our work we use GASPI, which is a relatively new communication library based on the PGAS model. It provides the missing features to allow the design of fault-tolerant applications. Instead of introducing algorithm-based fault tolerance in its true sense, we demonstrate how we can build on (existing) clever checkpointing and extend applications to allow integrate a low cost fault detection mechanism and, if necessary, recover the application on the fly. The aspects of process management, the restoration of groups and the recovery mechanism is presented in detail. We use a sparse matrix vector multiplication based application to perform the analysis of the overhead introduced by such modifications. Our fault detection mechanism causes no overhead in failure-free cases, whereas in case of failure(s), the failure detection and recovery cost is of reasonably acceptable order and shows good scalability.},
  keywords={},
  doi={10.1109/CLUSTER.2015.106},
  ISSN={2168-9253},
  month={Sep.},}
@INPROCEEDINGS{7307588,
  author={Li, Mingzhe and Subramoni, Hari and Hamidouche, Khaled and Lu, Xiaoyi and Panda, Dhabaleswar K.},
  booktitle={2015 IEEE International Conference on Cluster Computing}, 
  title={High Performance MPI Datatype Support with User-Mode Memory Registration: Challenges, Designs, and Benefits}, 
  year={2015},
  volume={},
  number={},
  pages={226-235},
  abstract={Noncontiguous data communication has been heavily adopted in scientific applications, especially for those written with MPI. Common strategies to handle noncontiguous data, like packing/unpacking, incur significant performance overhead during communication, which could become as a barrier of using MPI derived datatypes. Recently, a novel feature of Mellanox InfiniBand, called User-mode Memory Registration (UMR), has been introduced for noncontiguous data communication. UMR has the potential to support MPI derived datatype communication efficiently without the overhead of packing/unpacking. In this paper, we analyze the UMR feature and study its basic performance with InfiniBand verbs-level micro-benchmarks. With this knowledge, we propose UMR-based schemes to support zero-copy datatype communication at MPI level. We show that a naive integration of UMR with an MPI stack could not bring performance benefits over existing schemes. Thus we propose two schemes -- UMR Pool and UMR Cache -- to enable high performance MPI datatype communication with UMR. To the best of our knowledge, this is the first paper to study, analyze, and design MPI noncontiguous data communication using the UMR feature. We propose and implement UMR-based designs on top of MVAPICH2 library. The experimental results at the microbenchmark level show that the proposed UMR-based design is able to deliver 4X performance improvement in latency for large message vector benchmarks over the packing/unpacking scheme. At the application level, for a 3D stencil communication kernel with MPI derived datatype on 512 processes, the optimized UMR-based design outperforms the packing/unpacking scheme by 27% in execution time.},
  keywords={},
  doi={10.1109/CLUSTER.2015.41},
  ISSN={2168-9253},
  month={Sep.},}
@INPROCEEDINGS{7309603,
  author={Gregorek, Daniel and Garcia-Ortiz, Alberto},
  booktitle={2015 IEEE Computer Society Annual Symposium on VLSI}, 
  title={The DRACON Embedded Many-Core: Hardware-Enhanced Run-Time Management Using a Network of Dedicated Control Nodes}, 
  year={2015},
  volume={},
  number={},
  pages={416-421},
  abstract={Many-core systems provide abundant computing power for parallel applications. The run-time manager of an embedded system has to efficiently exploit the available resources while guaranteeing a high responsiveness. We propose a dedicated hardware infrastructure to improve the scalability and responsiveness of a run-time task manager. The hardware enhancements constitute a hierarchy of global and local control nodes which communicate by means of message passing. The global nodes facilitate a distributed task manager which performs the task scheduling and a flexible task synchronization scheme at run-time. A low-latency interface between the run-time system and the processing cores is provided by the local nodes. Based on simulations using a SystemC model, we demonstrate the advantages of our approach in terms of application performance. The design feasibility is substantiated by means of gate-level analysis. We compare our results against state-of-the-art software and hardware-based run-time management systems.},
  keywords={},
  doi={10.1109/ISVLSI.2015.90},
  ISSN={2159-3477},
  month={July},}
@INPROCEEDINGS{7313496,
  author={Heidenreich, Toni and Spehr, Jens and Stiller, Christoph},
  booktitle={2015 IEEE 18th International Conference on Intelligent Transportation Systems}, 
  title={LaneSLAM -- Simultaneous Pose and Lane Estimation Using Maps with Lane-Level Accuracy}, 
  year={2015},
  volume={},
  number={},
  pages={2512-2517},
  abstract={In this paper we provide a method for coarse map localisation using low-cost sensors (GPS and camera-based lane recognition) and maps with lane-level accuracy while simultaneously updating the perceived road network and the map. This is a conceptual improvement on previous works which either focussed on a subtask (localisation or lane update) or only worked with single lanes. The problem is solved by applying Loopy Belief Propagation on a tailored factor graph which models the dependencies between observed and hidden variables. Message passing within the graph relies on multimodal normal distributions for variable representation and quadratic noise models resulting in a fast and well-defined calculation framework. Simulations show that the localisation accuracy is insensitive to most types of measurement noise except constant offsets of global pose measurements which can still be reduced by a factor of 8. Real-world tests with an average localisation error of 1.71m in an urban scenario prove the applicability of the approach for automatic driving tasks as well as its run-time performance with an average execution time of 3ms.},
  keywords={},
  doi={10.1109/ITSC.2015.404},
  ISSN={2153-0017},
  month={Sep.},}
@INPROCEEDINGS{7322475,
  author={Glass, Kimberly and Quackenbush, John and Kepner, Jeremy},
  booktitle={2015 IEEE High Performance Extreme Computing Conference (HPEC)}, 
  title={High performance computing of gene regulatory networks using a message-passing model}, 
  year={2015},
  volume={},
  number={},
  pages={1-6},
  abstract={Gene regulatory network reconstruction is a fundamental problem in computational biology. We recently developed an algorithm, called PANDA (Passing Attributes Between Networks for Data Assimilation), that integrates multiple sources of omics data and estimates regulatory network models. This approach was initially implemented in the C++ programming language and has since been applied to a number of biological systems. In our current research we are beginning to expand the algorithm to incorporate larger and most diverse data-sets, to reconstruct networks that contain increasing numbers of elements, and to build not only single network models, but sets of networks. In order to accomplish these “Big Data” applications, it has become critical that we increase the computational efficiency of the PANDA implementation. In this paper we show how to recast PANDA's similarity equations as matrix operations. This allows us to implement a highly readable version of the algorithm using the MATLAB/Octave programming language. We find that the resulting M-code much shorter (103 compared to 1128 lines) and more easily modifiable for potential future applications. The new implementation also runs significantly faster, with increasing efficiency as the network models increase in size. Tests comparing the C-code and M-code versions of PANDA demonstrate that this speed-up is on the order of 20-80 times faster for networks of similar dimensions to those we find in current biological applications.},
  keywords={},
  doi={10.1109/HPEC.2015.7322475},
  ISSN={},
  month={Sep.},}
@INPROCEEDINGS{7330181,
  author={Wang, Qi and Cherkasova, Ludmila and Li, Jun and Volos, Haris},
  booktitle={2015 IEEE 23rd International Symposium on Modeling, Analysis, and Simulation of Computer and Telecommunication Systems}, 
  title={InterSense: Interconnect Performance Emulator for Future Scale-out Distributed Memory Applications}, 
  year={2015},
  volume={},
  number={},
  pages={122-125},
  abstract={A common approach for improving application performance is to process its working set from memory. For datasets that do not fit into DRAM of a single machine this leads to a design of scale-out applications, where the application dataset is partitioned and processed by a cluster of machines. Performance of distributed memory applications, implemented using MPI (Message Passing Interface), inherently depends on performance of communication layer, which is largely defined by performance characteristics of underlying interconnect. During last couple years, many Big Data applications, e.g., Hadoop, Spark, Memcached, were re-written to take advantage of Remote Direct Memory Access (RDMA) technology and RDMA-capable interconnects which provide fast and high-bandwidth communications. The application analysis of potential performance improvements due to faster and higher bandwidth interconnects is a challenging task. Does the existing application implementation take a full advantage of the underlying interconnect or not? Will the application performance get worse if the interconnect has X% increased latency or Y% lower bandwidth? In this work, we introduce a novel emulation framework, called InterSense, which is implemented on top of existing high-speed interconnect, such as InfiniBand, and which provides two performance knobs for changing the interconnect bandwidth and latency. This approach offers an easy-to-use framework for a sensitivity analysis of complex distributed applications to communication layer performance instead of creating customized and time-consuming application models to answer the same questions. We evaluate the emulator accuracy with popular OSU MPI benchmarks: InterSense emulates the specified bandwidth and latency values with less than 2% error between the expected and measured values. We apply InterSense for sensitivity analysis of two new benchmarks, such as GUPS and Graph 500 to demonstrate the emulator's ease of use in getting non-trivial insights.},
  keywords={},
  doi={10.1109/MASCOTS.2015.13},
  ISSN={1526-7539},
  month={Oct},}
@INPROCEEDINGS{7336323,
  author={Gunes, Volkan and Givargis, Tony},
  booktitle={2015 IEEE 17th International Conference on High Performance Computing and Communications, 2015 IEEE 7th International Symposium on Cyberspace Safety and Security, and 2015 IEEE 12th International Conference on Embedded Software and Systems}, 
  title={XGRID: A Scalable Many-Core Embedded Processor}, 
  year={2015},
  volume={},
  number={},
  pages={1143-1146},
  abstract={The demand for compute cycles needed by embedded systems is rapidly increasing. In this paper, we introduce the XGRID embedded many-core system-on-chip architecture. XGRID makes use of a novel, FPGA-like, programmable interconnect infrastructure, offering scalability and deterministic communication using hardware supported message passing among cores. Our experiments with XGRID are very encouraging. A number of parallel benchmarks are evaluated on the XGRID processor using the application mapping technique described in this work. We have validated our scalability claim by running our benchmarks on XGRID varying in core count. We have also validated our assertions on XGRID architecture by comparing XGRID against the Graphite many-core architecture and have shown that XGRID outperforms Graphite in performance.},
  keywords={},
  doi={10.1109/HPCC-CSS-ICESS.2015.99},
  ISSN={},
  month={Aug},}
@INPROCEEDINGS{7336217,
  author={Yuan, Shijin and Yan, Jinghao and Mu, Bin and Li, Hongyu},
  booktitle={2015 IEEE 17th International Conference on High Performance Computing and Communications, 2015 IEEE 7th International Symposium on Cyberspace Safety and Security, and 2015 IEEE 12th International Conference on Embedded Software and Systems}, 
  title={Parallel Dynamic Step Size Sphere-Gap Transferring Algorithm for Solving Conditional Nonlinear Optimal Perturbation}, 
  year={2015},
  volume={},
  number={},
  pages={559-565},
  abstract={Intelligent algorithms have been extensively applied in scientific computing. Recently, some researchers apply intelligent algorithms to solve conditional nonlinear optimal perturbation (CNOP) which is proposed to study the predictability of numerical weather and climate prediction. The difficulty of solving CNOP using the intelligent algorithm is the high dimensionality of complex numerical models. Therefore, previous researches either are just tested in ideal models or have low time efficiency in complex numerical models which limited the application of CNOP. In this paper, we proposed a parallel dynamic step size sphere-gap transferring algorithm (DSGT) to solve CNOP in complex numerical models. A dynamic step size factor is also designed to speed up convergence of sphere-gap transferring algorithm. Through the singular value decomposition, the original problem is reduced into a low-dimensional space to hunt the coordinate of the optimal CNOP with the DSGT algorithm. Moreover, in order to accelerate the computation speed, we parallelize the DSGT method with MPI technology. To demonstrate the validity, the proposed method has been studied in the Zebiak-Cane model to solve the CNOP. Experimental results prove that the proposed method can efficiently and stably obtain a satisfactory CNOP, and the parallel version can reach the speedup of 7.18 times with 10 cores.},
  keywords={},
  doi={10.1109/HPCC-CSS-ICESS.2015.261},
  ISSN={},
  month={Aug},}
@INPROCEEDINGS{7340463,
  author={Li, Wenchao and Gérard, Léonard and Shankar, Natarajan},
  booktitle={2015 ACM/IEEE International Conference on Formal Methods and Models for Codesign (MEMOCODE)}, 
  title={Design and verification of multi-rate distributed systems}, 
  year={2015},
  volume={},
  number={},
  pages={20-29},
  abstract={Multi-rate systems arise naturally in distributed settings where computing units execute periodically according to their local clocks and communicate among themselves via message passing. We present a systematic way of designing and verifying such systems with the assumption of bounded drift for local clocks and bounded communication latency. First, we capture the system model through an architecture definition language (called RADL) that has a precise model of computation and communication. The RADL paradigm is simple, compositional, and resilient against denial-of-service attacks. Our radler build tool takes the architecture definition and individual local functions as inputs and generate executables for the overall system as output. In addition, we present a modular encoding of multi-rate systems using calendar automata and describe how to verify real-time properties of these systems using SMT-based infinite-state bounded model checking. Lastly, we discuss our experiences in applying this methodology to building high-assurance cyber-physical systems.},
  keywords={},
  doi={10.1109/MEMCOD.2015.7340463},
  ISSN={},
  month={Sep.},}
@INPROCEEDINGS{7343279,
  author={King, Heather and Flanagan, Mark F.},
  booktitle={2015 IEEE 26th Annual International Symposium on Personal, Indoor, and Mobile Radio Communications (PIMRC)}, 
  title={Joint weighted bit-flipping decoder for use in diversity network coding}, 
  year={2015},
  volume={},
  number={},
  pages={116-120},
  abstract={A new joint message-passing decoder is presented for use in a two-user cooperative wireless network. This decoder is designed for use with the diversity network coding scheme of Xiao et al. , which uses nonbinary network codes together with channel coding to achieve high diversity gains. The proposed joint decoder, together with appropriate modifications to the cooperative protocol of Xiao and Skoglund (2010), significantly reduces the required implementation complexity both at the relay nodes and at the receiver. The destination's joint decoder structure consists of two parallel weighted bit flipping (PWBF) decoders which exchange extrinsic soft/hard information regarding the two users' packets. It is demonstrated through simulations that the proposed joint decoder achieves not only the same diversity gain as in the work of Xiao and Skoglund (2010), but also approximately 5dB of additional coding gain. It is also notable that a significant improvement in system performance can be achieved after only two joint decoding iterations.},
  keywords={},
  doi={10.1109/PIMRC.2015.7343279},
  ISSN={},
  month={Aug},}
@INPROCEEDINGS{7346834,
  author={Bocan Hu and Yan Zhang and Lazos, Loukas},
  booktitle={2015 IEEE Conference on Communications and Network Security (CNS)}, 
  title={PHYVOS: Physical layer voting for secure and fast cooperation}, 
  year={2015},
  volume={},
  number={},
  pages={245-253},
  abstract={Distributed wireless networks often employ voting to perform critical network functions such as fault-tolerant data fusion, cooperative sensing, and reaching consensus. Voting is implemented by exchanging messages with a fusion center or just between the participants. However, the communication and delay overheads of message-based voting can be prohibitive when voting is frequent. Additional overheads are incurred if voter authentication and vote integrity verification are required. In this paper, we propose a fast PHY-layer voting scheme called PHYVOS, which significantly reduces the voting overhead. In PHYVOS, wireless devices transmit their votes to a fusion center simultaneously, by exploiting the subcarrier orthogonality in OFDM and without explicit messaging. We show that PHYVOS is secure against attackers that attempt to manipulate the voting outcome. Security is achieved without employing cryptography-based authentication and message integrity schemes. We analytically evaluate the voting robustness as a function of PHY-layer parameters. We further discuss practical implementation challenges of PHYVOS related to multi-device frequency and time synchronization. Finally, we present a prototype implementation of PHYVOS on the USRP platform.},
  keywords={},
  doi={10.1109/CNS.2015.7346834},
  ISSN={},
  month={Sep.},}
@INPROCEEDINGS{7348074,
  author={Labasan, Stephanie and Larsen, Matthew and Childs, Hank},
  booktitle={2015 IEEE 5th Symposium on Large Data Analysis and Visualization (LDAV)}, 
  title={Exploring tradeoffs between power and performance for a scientific visualization algorithm}, 
  year={2015},
  volume={},
  number={},
  pages={73-80},
  abstract={Power is becoming a major design constraint in the world of high-performance computing (HPC). This constraint affects the hardware being considered for future architectures, the ways it will run software, and the design of the software itself. Within this context, we explore tradeoffs between power and performance. Visualization algorithms themselves merit special consideration, since they are more data-intensive in nature than traditional HPC programs like simulation codes. This data-intensive property enables different approaches for optimizing power usage. Our study focuses on the isosurfacing algorithm, and explores changes in power and performance as clock frequency changes, as power usage is highly dependent on clock frequency. We vary many of the factors seen in the HPC context - programming model (MPI vs. OpenMP), implementation (generalized vs. optimized), concurrency, architecture, and data set - and measure how these changes affect power-performance properties. The result is a study that informs the best approaches for optimizing energy usage for a representative visualization algorithm.},
  keywords={},
  doi={10.1109/LDAV.2015.7348074},
  ISSN={},
  month={Oct},}
@INPROCEEDINGS{7349596,
  author={Zhang, Mingxing and Wu, Yongwei and Chen, Kang and Zheng, Weimin},
  booktitle={2015 44th International Conference on Parallel Processing}, 
  title={What Is Wrong with the Transmission? A Comprehensive Study on Message Passing Related Bugs}, 
  year={2015},
  volume={},
  number={},
  pages={410-419},
  abstract={Along with the prevalence of distributed systems, more and more applications require the ability of reliably transferring messages across a network. However, passing messages in a convenient and dependable way is both difficult and error prone. Thus the existing messaging products usually suffer from numerous software bugs. And these bugs are particularly difficult to be diagnosed or avoided. Therefore, in order to improve the methods for handling them, we need a better understanding of their characteristics. This paper provides the first (to the best of our knowledge)comprehensive characteristic study on message passing related bugs (MP-bugs). We have carefully examined the pattern, manifestation, fixing and other characteristics of 349 randomly selected real world MP-bugs from 3 representative open-source applications (Open MPI, Zero MQ, and Active MQ). Surprisingly, we found that nearly 60% of the non-latent MP-bugs can be categorised into two simple patterns: the message level bugs and the connection level bugs, which implies a promising perspective of detecting/tolerating tools for MP-bugs. Apart from this finding, our study have also uncovered many new (and sometimes surprising)insights of the message passing systems' developing process. The results should be useful for the design of corresponding bug detecting, exposing and tolerating tools.},
  keywords={},
  doi={10.1109/ICPP.2015.50},
  ISSN={0190-3918},
  month={Sep.},}
@INPROCEEDINGS{7349625,
  author={Yan, Jie and Tan, Guangming and Sun, Ninghui},
  booktitle={2015 44th International Conference on Parallel Processing}, 
  title={Study on Partitioning Real-World Directed Graphs of Skewed Degree Distribution}, 
  year={2015},
  volume={},
  number={},
  pages={699-708},
  abstract={Distributed computation on directed graphs has been increasingly important in emerging big data analytics. However, partitioning the huge real-world graphs, such as social and web networks, is known challenging for their skewed (or power-law) degree distributions. In this paper, by investigating two representative k-way balanced edge-cut methods (LDG streaming heuristic and METIS) on 12 real social and web graphs, we empirically find that both LDG and METIS can partition page-level web graphs with extremely high quality, but fail to generate low-cut balanced partitions for social networks and host-level web graphs. Our deep analysis identifies that the global star-motif structures around high-degree vertices is the main obstacle to high-quality partitioning. Based on the empirical study, we further propose a new distributed graph model, namely Agent-Graph, and the Agent+ framework that partitions power-law graphs in the Agent-Graph model. Agent-Graph is a vertex cut variant in the context of message passing, where any high-degree vertex is factored into arbitrary computational agents in remote partitions for message combining and scattering. The Agent framework filters the high-degree vertices to form a residual graph which is then partitioned with high quality by existing edge-cut methods, and finally refills high-degree vertices as agents to construct an agent-graph. Experiments show that the Agent+ approach constantly generates high-quality partitions for all tested real-world skewed graphs. In particular, for 64-way partitioning on social networks and host-level web graphs, the Agent+ approach reduces edge cut equivalently by 27%~79% for LDG and 23%~82% for METIS.},
  keywords={},
  doi={10.1109/ICPP.2015.37},
  ISSN={0190-3918},
  month={Sep.},}
@INPROCEEDINGS{7349902,
  author={Zhou, Huan and Marjanovic, Vladimir and Niethammer, Christoph and Gracia, José},
  booktitle={2015 44th International Conference on Parallel Processing Workshops}, 
  title={A Bandwidth-Saving Optimization for MPI Broadcast Collective Operation}, 
  year={2015},
  volume={},
  number={},
  pages={111-118},
  abstract={The efficiency and scalability of MPI collective operations, in particular the broadcast operation, plays an integral part in high performance computing applications. MPICH, as one of the contemporary widely-used MPI software stacks, implements the broadcast operation based on point-to-point operation. Depending on the parameters, such as message size and process count, the library chooses to use different algorithms, as for instance binomial dissemination, recursive-doubling exchange or ring all-to-all broadcast (all-gather). However, the existing broadcast design in latest release of MPICH does not provide good performance for large messages (lmsg) or medium messages with non-power-of-two process counts (mmsg-npof2) due to the inner suboptimal ring allgather algorithm. In this paper, based on the native broadcast design in MPICH, we propose a tuned broadcast approach with bandwidth-saving in mind catering to the case of lmsg and mmsg-npof2. Several comparisons of the native and tuned broadcast designs are made for different data sizes and program sizes on Cray XC40 cluster. The results show that the performance of the tuned broadcast design can get improved by a range from 2% to 54% for lmsg and mmsg-npof2 in terms of user-level testing.},
  keywords={},
  doi={10.1109/ICPPW.2015.20},
  ISSN={1530-2016},
  month={Sep.},}
@INPROCEEDINGS{7349904,
  author={Liu, Jialin and Chen, Yong and Byna, Surendra},
  booktitle={2015 44th International Conference on Parallel Processing Workshops}, 
  title={Collective Computing for Scientific Big Data Analysis}, 
  year={2015},
  volume={},
  number={},
  pages={129-137},
  abstract={Big science discovery requires an efficient computing framework in the high performance computing architecture. Traditional scientific data analysis relies on Message Passing Interface (MPI) and MPI-IO to achieve fast computing and low I/O bottleneck. Among them, two-phase collective I/O is commonly used to reduce data movement by optimizing the non-contiguous I/O pattern. However, the inherent constraint of collective I/O prevents it from having a flexible combination with computing and lacks an efficient non-blocking I/O-Computing framework in current HPC. In this work, we propose Collective Computing, a framework that breaks the constraint of the two-phase collective I/O and provides an efficient non-blocking computing paradigm with runtime support. The fundamental idea is to move the analysis stage in advance and insert the computation into the two-phase I/O, such that the data in the first I/O phase can be computed in place and the second shuffle phase is minimized with a reduce operation. We motivate this idea by profiling the I/O and CPU usage. With both theoretical analysis and evaluation on real application and benchmarks, we show that the collective computing can achieve 2.5X speedup and is promising in big scientific data analysis.},
  keywords={},
  doi={10.1109/ICPPW.2015.22},
  ISSN={1530-2016},
  month={Sep.},}
@INPROCEEDINGS{7354637,
  author={Sohn, Illsoo and Lee, Sang Hyun},
  booktitle={2015 International Conference on Information and Communication Technology Convergence (ICTC)}, 
  title={Distributed scheduling for coexistence of IoT wireless devices}, 
  year={2015},
  volume={},
  number={},
  pages={680-682},
  abstract={In this paper, we propose a distributed scheduling scheme for internet-of-things (IoT) wireless devices. The scheduling determination that maximizes overall sum rate of the network is formulated as an optimization problem, which is very challenging because there exists no centralized coordinator in the typical IoT network. To resolve this, we introduce the-state-of-the-art message-passing framework and develop a distributed scheduling algorithm based on it. Our simulation results verify that the proposed distributed scheduling algorithm considerably outperforms previous distributed approaches.},
  keywords={},
  doi={10.1109/ICTC.2015.7354637},
  ISSN={},
  month={Oct},}
@INPROCEEDINGS{7359890,
  author={Biji C.L. and Nair, Achuthsankar S. and Arun P.R and George, Jojo},
  booktitle={2015 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)}, 
  title={NGS read data compression using parallel computing algorithm}, 
  year={2015},
  volume={},
  number={},
  pages={1456-1460},
  abstract={Analysing and storing the high-throughput sequencing data from next generation sequencing technologies is facing great bottlenecks, hampered by the big data emerging in Terabyte range from the Next Generation Sequencing (NGS) machine. The present trend demands more sophisticated parallel computing algorithms for managing the data explosion. We propose a parallel implementation of MFCompress algorithm using message passing interface model. In the NGS Read Compression using parallel computing algorithm, the input file is split into different number of parts based on the number of nodes and each processor uses the multiple finite-context models for compression. For testing the proposed approach, we have selected read dataset from the range 50MB to 10 GB. The algorithm reported a best compression of 0.33 bpb and a speedup ratio of 6 with an average of 23 times disk space reduction.},
  keywords={},
  doi={10.1109/BIBM.2015.7359890},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{7363823,
  author={Bahmani, Amir and Mueller, Frank},
  booktitle={2015 IEEE International Conference on Big Data (Big Data)}, 
  title={ACURDION: An adaptive clustering-based algorithm for tracing large-scale MPI applications}, 
  year={2015},
  volume={},
  number={},
  pages={785-792},
  abstract={Communication traces help developers of high-performance computing (HPC) applications understand and improve their codes. When run on large-scale HPC facilities, the scalability of tracing tools becomes a challenge. To address this problem, traces can be clustered into groups of processes that exhibit similar behavior. Instead of collecting traces information of each individual node, it then suffices to collect a trace of a small set of representative nodes, namely one per cluster. However, clustering algorithms themselves need to have low overhead, be scalable, and adapt to application characteristics. We devised an adaptive clustering algorithm for large-scale applications called ACURDION that traces the MPI communication of code with O(log P) time complexity where P is the number of processes. First, ACURDION identifies the parameters that differ across processes by using a logarithmic algorithm called Adaptive Signature Building. Second, it clusters the processes based on those parameters. Experiments show that collecting traces of just nine nodes/clusters suffices to capture the communication behavior of all nodes while retaining sufficient accuracy of trace events and parameters. In summary, ACURDION improves trace scalability and automation over prior approaches.},
  keywords={},
  doi={10.1109/BigData.2015.7363823},
  ISSN={},
  month={Oct},}
@INPROCEEDINGS{7363271,
  author={Tu, Jianguang and Cheng, Jianquan and Han, Liangxiu},
  booktitle={2015 IEEE International Conference on Computer and Information Technology; Ubiquitous Computing and Communications; Dependable, Autonomic and Secure Computing; Pervasive Intelligence and Computing}, 
  title={Big Data Computation for Workshop-Based Planning Support}, 
  year={2015},
  volume={},
  number={},
  pages={1510-1514},
  abstract={Involving stakeholders in decision-making at planning workshops requires a computer system to respond quickly to various scenarios proposed by participants. Due to the increasing complexity of urban systems, such planning support often faces the challenges of "big data" and poor computational performance. This paper proposes a new approach using parallel processing techniques (i.e. MPI Message Passing Interface) to support workshop participants in interactively building planning scenarios and visualizing outputs of job accessibility across the Greater Manchester. MPI-based parallel algorithms have been run on a cluster of computers for reducing computational time cost. The tested results and computational performances are critically evaluated and recommendations for future work provided. Particularly this paper also addresses several key research questions related to a theoretical framework of applying big data analytics for urban planning support.},
  keywords={},
  doi={10.1109/CIT/IUCC/DASC/PICOM.2015.226},
  ISSN={},
  month={Oct},}
@INPROCEEDINGS{7363399,
  author={Elhadef, Mourad},
  booktitle={2015 IEEE International Conference on Computer and Information Technology; Ubiquitous Computing and Communications; Dependable, Autonomic and Secure Computing; Pervasive Intelligence and Computing}, 
  title={An Adaptable inVANETs-Based Intersection Traffic Control Algorithm}, 
  year={2015},
  volume={},
  number={},
  pages={2387-2392},
  abstract={With the recent advances in intelligent vehicular ad-hoc networks (inVANETs), the traditional traffic control problem at intersections is being revisited to cope with the future intelligent transportation systems. The traditional traffic light scheduling, the recently developed artificial-intelligence-based traffic control approaches, or the trajectory maneuver remain all either inaccurate, inflexible, inefficient, or costly. In this paper, we improve the inVANETs-based intersection control algorithm, developed by Wu et al. in [1], by making it more adaptable to realistic traffic scenarios and traffic bottlenecks or accidents. The intersection control and the coordination among the vehicles are implemented via message passing using vehicle to vehicle (V2V) communications. The vehicles can rely on V2V or vehicle to infrastructure communications to compete for the privilege to cross the intersection providing hence a more flexible and adaptable approach. A proof of correctness is provided to show that the proposed solution satisfies the properties of safety, liveness, and fairness of the vehicle mutual exclusion for intersections (VMEI) problem.},
  keywords={},
  doi={10.1109/CIT/IUCC/DASC/PICOM.2015.352},
  ISSN={},
  month={Oct},}
@INPROCEEDINGS{7371618,
  author={Lu, Shuaibing and Pang, Jianmin and Pan, Yaomin and Tan, Jie and Dai, Tao},
  booktitle={2015 International Conference on Computer Science and Mechanical Automation (CSMA)}, 
  title={A MPI-Friendly Efficient Static Binary Translator Based on QEMU}, 
  year={2015},
  volume={},
  number={},
  pages={36-40},
  abstract={While high performance computing (HPC) is flourishing these years, the lack of HPC applications is increasingly serious. Conventional binary translation focused on desktop applications and embedded software, which could not be scaled up to HPC. This paper proposed a novel static binary translator MPI-QEMU aiming at MPI programs, the most commonly used on HPC platforms. Firstly, the efficient dynamic binary translator QEMU was altered to a static binary translator to translate the source binary to target platforms. Secondly, by analysing the symbol table and global offset table, the library function name and address were extracted and jacketed. Finally, the generated codes were linked with corresponding native library functions including MPI to generate the target executive binary. The experiments on NPB and IMB benchmarks show that MPI-QEMU translates the benchmarks successfully and gains dramatically speedup.},
  keywords={},
  doi={10.1109/CSMA.2015.14},
  ISSN={},
  month={Oct},}
@INPROCEEDINGS{7371720,
  author={Anceaume, Emmanuelle and Castella, François and Mostéfaoui, Achour and Sericola, Bruno},
  booktitle={2015 IEEE 14th International Symposium on Network Computing and Applications}, 
  title={A Message-Passing and Adaptive Implementation of the Randomized Test-and-Set Object}, 
  year={2015},
  volume={},
  number={},
  pages={167-175},
  abstract={This paper presents a solution to the well-known Test-and-Set operation in asynchronous systems prone to process crashes. Test-and-Set is a synchronization operation that, when invoked by a set of processes, returns "yes" to a unique process and returns "no" to all the others. Recently many advances in implementing Test and Set objects have been achieved, however all of them uniquely target the shared memory model. In this paper we propose an implementation of a Test-and-Set object for message passing distributed systems. This implementation can be invoked by any number p of processes. It has an expected step complexity in O(p) and an expected message complexity in O(np), where n is the total number of processes in the system. The proposed Test and Set object is built atop a new basic building block that allows to select a winning group among two groups of processes.},
  keywords={},
  doi={10.1109/NCA.2015.27},
  ISSN={},
  month={Sep.},}
@INPROCEEDINGS{7404439,
  author={Wen Long and Yang, Zhaoqing and Copping, Andrea and Jung, Ki Won and Deng, Z. Daniel},
  booktitle={OCEANS 2015 - MTS/IEEE Washington}, 
  title={The development of a finite volume method for modeling sound in coastal ocean environment}, 
  year={2015},
  volume={},
  number={},
  pages={1-6},
  abstract={The rapid growth of renewable energy from offshore sources has raised concerns that underwater noise from construction and operation of offshore devices may interfere with communication of marine animals. An underwater sound model was developed to simulate sound propagation from marine-hydrokinetic energy (MHK) devices or offshore wind (OSW) energy platforms. Finite volume and finite difference methods were developed to solve the 3D Helmholtz equation of sound propagation in the coastal environment. For the finite volume method, the grid system consists of triangular grids in the horizontal plane and sigma-layers in the vertical dimension. A 3D sparse matrix solver with complex coefficients was formed for solving the resulting acoustic pressure field. The Complex Shifted Laplacian Preconditioner (CSLP) method was applied to solve the matrix system iteratively with MPI parallelization using a high performance cluster. The sound model was then coupled with the Finite Volume Community Ocean Model (FVCOM) for simulating sound propagation generated by human activities in a range-dependent setting, such as offshore wind energy platform construction and tidal stream turbine operations. As a proof of concept, initial validation of the finite difference solver is presented for two coastal wedge problems.},
  keywords={},
  doi={10.23919/OCEANS.2015.7404439},
  ISSN={},
  month={Oct},}
@INPROCEEDINGS{7408388,
  author={EunJung Park and Eidenbenz, Stephan and Santhi, Nandakishore and Chapuis, Guillaume and Settlemyer, Bradley},
  booktitle={2015 Winter Simulation Conference (WSC)}, 
  title={Parameterized benchmarking of parallel discrete event simulation systems: Communication, computation, and memory}, 
  year={2015},
  volume={},
  number={},
  pages={2836-2847},
  abstract={We introduce La-pdes, a parameterized benchmark application for measuring parallel and serial discrete event simulation (PDES) performance. Applying a holistic view of PDES system performance, La-pdes tests the performance factors of (i) the (P)DES engine in terms of event queue efficiency, synchronization mechanism, and load-balancing schemes; (ii) available hardware in terms of handling computationally intensive loads, memory size, cache hierarchy, and clock speed; and (iii) interaction with communication middleware (often MPI) through message buffering. La-pdes consists of seven scenarios for individual performance factors and an agglomerative stress evaluation scenario. The scenarios are implemented through concrete values of input parameters to La-pdes, which include number of entities and events, endtime, inter-send time distributions, computational and event load distributions, memory use distributions, cachefriendliness, and event queue sizes. We demonstrate through instrumentation that La-pdes assumptions regarding distributions are realistic and we present results of the eight scenarios on the PDES engine Simian.},
  keywords={},
  doi={10.1109/WSC.2015.7408388},
  ISSN={1558-4305},
  month={Dec},}
@INPROCEEDINGS{7410613,
  author={Psota, Eric T. and Kowalczuk, Jedrzej and Mittek, Mateusz and Pérez, Lance C.},
  booktitle={2015 IEEE International Conference on Computer Vision (ICCV)}, 
  title={MAP Disparity Estimation Using Hidden Markov Trees}, 
  year={2015},
  volume={},
  number={},
  pages={2219-2227},
  abstract={A new method is introduced for stereo matching that operates on minimum spanning trees (MSTs) generated from the images. Disparity maps are represented as a collection of hidden states on MSTs, and each MST is modeled as a hidden Markov tree. An efficient recursive message-passing scheme designed to operate on hidden Markov trees, known as the upward-downward algorithm, is used to compute the maximum a posteriori (MAP) disparity estimate at each pixel. The messages processed by the upward-downward algorithm involve two types of probabilities: the probability of a pixel having a particular disparity given a set of per-pixel matching costs, and the probability of a disparity transition between a pair of connected pixels given their similarity. The distributions of these probabilities are modeled from a collection of images with ground truth disparities. Performance evaluation using the Middlebury stereo benchmark version 3 demonstrates that the proposed method ranks second and third in terms of overall accuracy when evaluated on the training and test image sets, respectively.},
  keywords={},
  doi={10.1109/ICCV.2015.256},
  ISSN={2380-7504},
  month={Dec},}
@INPROCEEDINGS{7415019,
  author={Zhang, Jianan and Ma, Kai and Feng, Feng and Zhao, Zhihao and Zhang, Wei and Zhang, Qijun},
  booktitle={2015 IEEE MTT-S International Conference on Numerical Electromagnetic and Multiphysics Modeling and Optimization (NEMO)}, 
  title={Distributed parallel computing technique for EM modeling}, 
  year={2015},
  volume={},
  number={},
  pages={1-3},
  abstract={This paper proposes a novel distributed parallel EM modeling technique to speed up the process of neural network modeling for EM structures. Existing techniques for EM modeling usually need to repeatedly change the parameters of microwave devices and drive the EM simulator to obtain sufficient training and testing samples. As the complexity in EM modeling problem increases, traditional techniques are computationally expensive on data generation and training due to the limited performance of a single computer. Our technique incorporates distributed parallel computing technique to neural network modeling. It generates data and trains neural network models in parallel using message passing interface (MPI). An example shows that our technique is much faster than traditional technique while maintaining good model accuracy.},
  keywords={},
  doi={10.1109/NEMO.2015.7415019},
  ISSN={},
  month={Aug},}
@INPROCEEDINGS{7424434,
  author={Qawasmeh, Ahmad and Malik, Abid M. and Chapman, Barbara M.},
  booktitle={2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)}, 
  title={Adaptive OpenMP Task Scheduling Using Runtime APIs and Machine Learning}, 
  year={2015},
  volume={},
  number={},
  pages={889-895},
  abstract={Task-based programming models adopt different scheduling strategies to exploit parallelism in irregular applications. These scheduling strategies differ in terms of exploiting data locality, maintaining load balance, and minimizing overhead. OpenMP tasks allow programmers to express unstructured parallelism at a high level of abstraction and make the runtime responsible about the burden of scheduling parallel execution. For irregular applications, the performance of task scheduling cannot often be predicted due to the nature of application, the used compiler, and the platform/architecture dependencies. In this work, we introduce an automatic, portable, and adaptive runtime feedback-driven framework (APARF) that combines standard low-level tasking runtime APIs, a developed profiling tool, and a hybrid machine learning model. We employ APARF to select the optimum task scheduling scheme of any given application using similarity analysis through the correlation between the captured runtime APIs with low profiling costs. Our hybrid model predicts the best scheduling strategy for a variety of unseen applications with an average accuracy of 93%, while maintaining a 100% training accuracy. An average performance enhancement of 25% was obtained compared with the default configuration, when APARF was applied on different unseen programs. APARF was examined against a real application (Molecular Dynamics), where we achieved up to 31% performance improvement. Compared to Intel, PGI and GNU compilers, our predicted scheme achieved better performance in most cases.},
  keywords={},
  doi={10.1109/ICMLA.2015.111},
  ISSN={},
  month={Dec},}

@INPROCEEDINGS{7424546,
  author={Mirto, Maria and Aloisio, Giovanni},
  booktitle={2015 10th International Conference on P2P, Parallel, Grid, Cloud and Internet Computing (3PGCIC)}, 
  title={A Parallel Algorithm for the Prediction of Protein Binding Sites}, 
  year={2015},
  volume={},
  number={},
  pages={85-91},
  abstract={The Pocket-Finder algorithm identifies the location of ligand binding sites in a protein and is a fundamental component for a range of applications including molecular docking, de novo drug design and structural identification and comparison of functional sites. In this paper, we propose a parallel version of the Pocket-Finder algorithm. The proposed parallel algorithm uses a geometrical approach to locate favorable binding sites and has been MPI-enabled for parallel execution. The proposed algorithm has been applied on a small test of 15 proteins and 2 proteins complexes. The algorithm gets very interesting results when applied to large proteins.},
  keywords={},
  doi={10.1109/3PGCIC.2015.123},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{7423176,
  author={Bez, Jean Luca and Schnorr, Lucas Mello and Navaux, Philippe O.A.},
  booktitle={2015 International Symposium on Computer Architecture and High Performance Computing Workshop (SBAC-PADW)}, 
  title={Characterizing Anomalies of a Multicore ARMv7 Cluster with Parallel N-Body Simulations}, 
  year={2015},
  volume={},
  number={},
  pages={25-30},
  abstract={ARM processors are beginning to gain attention from the HPC community due to its performance and energy efficiency characteristics. When developing HPC applications for such test beds developers assume that the computation resources available are homogeneous. However, we observed some anomalies when executing a relatively simple HPC application (an NBody simulation). One of the cores in all available nodes presented some variabilities in the computation time. This unexpected behavior was not observed on the second core of each node. In this paper, we aim at characterizing such anomalies, seen in a multicore ARMv7 8-node cluster. We also attempted to isolate and remove all possible interferences that could be contributing to this unexpected behavior, including compilation directives, dynamic processor frequency scaling and communication. Results show that such anomaly might be correlated with the architecture of the dual-core chip. We also analyze the effects of different deployments of MPI process in the total execution time and correlate them to the application and the test bed.},
  keywords={},
  doi={10.1109/SBAC-PADW.2015.18},
  ISSN={},
  month={Oct},}
@INPROCEEDINGS{7429307,
  author={Chatarasi, Prasanth and Shirako, Jun and Sarkar, Vivek},
  booktitle={2015 International Conference on Parallel Architecture and Compilation (PACT)}, 
  title={Polyhedral Optimizations of Explicitly Parallel Programs}, 
  year={2015},
  volume={},
  number={},
  pages={213-226},
  abstract={The polyhedral model is a powerful algebraic framework that has enabled significant advances to analysis and transformation of sequential affine (sub)programs, relative to traditional AST-based approaches. However, given the rapid growth of parallel software, there is a need for increased attention to using polyhedral frameworks to optimize explicitly parallel programs. An interesting side effect of supporting explicitly parallel programs is that doing so can also enable optimization of programs with unanalyzable data accesses within a polyhedral framework. In this paper, we address the problem of extending polyhedral frameworks to enable analysis and transformation of programs that contain both explicit parallelism and unanalyzable data accesses. As a first step, we focus on OpenMP loop parallelism and task parallelism, including task dependences from OpenMP 4.0. Our approach first enables conservative dependence analysis of a given region of code. Next, we identify happens-before relations from the explicitly parallel constructs, such as tasks and parallel loops, and intersect them with the conservative dependences. Finally, the resulting set of dependences is passed on to a polyhedral optimizer, such as PLuTo and PolyAST, to enable transformation of explicitly parallel programs with unanalyzable data accesses. We evaluate our approach using eleven OpenMP benchmark programs from the KASTORS and Rodinia benchmark suites. We show that 1) these benchmarks contain unanalyzable data accesses that prevent polyhedral frameworks from performing exact dependence analysis, 2) explicit parallelism can help mitigate the imprecision, and 3) polyhedral transformations with the resulting dependences can further improve the performance of the manually-parallelized OpenMP benchmarks. Our experimental results show geometric mean performance improvements of 1.62x and 2.75x on the Intel Westmere and IBM Power8 platforms respectively (relative to the original OpenMP versions).},
  keywords={},
  doi={10.1109/PACT.2015.44},
  ISSN={1089-795X},
  month={Oct},}
@INPROCEEDINGS{7440322,
  author={Debbabi, Imen and Le Gal, Bertrand and Khouja, Nadia and Tlili, Fethi and Jego, Christophe},
  booktitle={2015 IEEE International Conference on Electronics, Circuits, and Systems (ICECS)}, 
  title={Analysis of ADMM-LP algorithm for LDPC decoding, a first step to hardware implementation}, 
  year={2015},
  volume={},
  number={},
  pages={356-359},
  abstract={The recent interest in linear programming techniques for LDPC decoding showed that these methods are too complex for real applicability. Alternating direction method of multipliers is a classic technique in convex optimization theory. When applied to the linear programming decoding of LDPC codes, the ADMM algorithm acts as a message passing decoding method. In this work, we present a complexity analysis of the ADMM LDPC decoder compared with the sum product approach and we explain the parallelism levels that are explored in the ADMM algorithm. A software implementation by taking advantage of the architectural features of the multi-core processors parallelism is presented. The overall analysis provides a better understanding of the ADMM approach complexity which makes a start to possible hardware implementations.},
  keywords={},
  doi={10.1109/ICECS.2015.7440322},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{7437613,
  author={Nath, Amar and Niyogi, Rajdeep},
  booktitle={2015 International Conference on Information Technology (ICIT)}, 
  title={Validation and Verification of Joint-Actions in Multi-agent Planning}, 
  year={2015},
  volume={},
  number={},
  pages={187-192},
  abstract={In multi-agent planning problem, multiple agents are involved in doing some task to achieve a common goal. At present, major approaches to multi-agent planning are decomposition, heuristic improvement, and joint-action planning. Joint-action is a special case of concurrent actions where, two or more agents perform the same action simultaneously. Joint-action executes if preconditions hold true, but it contains so many dynamic elements with it that make it so complex to be true. The aim of the study is to make an attempt to formalize the precondition of joint-action so that it can be ensured that joint-action going to be executed would execute correctly. In joint-action, two or more agents must be ready to perform a single action. In the literature, it is assumed that two or more agents become available at the same place and then are ready to execute the action, but in the real world this is not true. Naturally, there are different situations i.e. 1: both of the agents are not at same location, 2: agents may or may not be obliged to do the task, 3: agents may be busy in doing some other task and deadlock may happen, so this process involves agent's synchronization, message passing and process synchronization. Because of this, the formalization of precondition becomes necessary and it ensure the correctness of action to be executed. This study made an attempt to formalize the precondition through BPMN and verifying it with a formal method i.e. Petri net. This work has a novelty as no one has made an attempt to formalize the precondition till today.},
  keywords={},
  doi={10.1109/ICIT.2015.11},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{7456606,
  author={Samantray, Bhabani Sankar and Kanhar, Debananda},
  booktitle={2015 International Conference on Man and Machine Interfacing (MAMI)}, 
  title={Empirical analysis of dense matrix multiplication on shared and distributed memory clusters}, 
  year={2015},
  volume={},
  number={},
  pages={1-7},
  abstract={In this paper we present two dense, square matrix multiplication algorithms, and give a comparative analysis and performance evolutions of the algorithms in distributed memory and shared memory architecture. In this paper, we explore the performance of Rocks cluster and Beowulf cluster. Beowulf cluster is the distributed memory parallel computers and rocks 5.4 (Maverick) is the CentOS based high performance Linux cluster having shared memory architecture. In this study, we first build a Beowulf cluster by connecting 16, Pentium 4 personal computers with 100 Mb Fast Ethernet. We evaluate the execution time, speedup and Efficiency of the simple block checkerboard partitioning algorithm and the most popular cannon's algorithm based on block checkerboard. The topology used for communication is 2D mesh. In these algorithms we used the message passing using MPI with C. We analyze the performance of the algorithms in our experimental platforms i.e Beowulf Cluster and Rocks Cluster.},
  keywords={},
  doi={10.1109/MAMI.2015.7456606},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{7458357,
  author={Makpaisit, Pisit and Ichikawa, Kohei and Uthayopas, Putchong and Date, Susumu and Takahashi, Keichi and Khureltulga, Dashdavaa},
  booktitle={2015 15th International Symposium on Communications and Information Technologies (ISCIT)}, 
  title={MPI_Reduce algorithm for OpenFlow-enabled network}, 
  year={2015},
  volume={},
  number={},
  pages={261-264},
  abstract={The MPI reduction operation such as MPI_Reduce and MPI_Allreduce are frequently used and time-consuming operations. The performance enhancement of these operations can substantially speed up large-scale parallel applications. In this paper, a greedy based MPI_Reduce algorithm called Greedy Shortest Binomial Tree (GSBT) is proposed. This proposed algorithm leverages SDN technology and OpenFlow network to speed up MPI reduction operations. This is accomplished using network topology information from the OpenFlow controller to reduce overall hops in message transmission. The implementation of the proposed algorithm by modifying MPI library and OpenFlow controller is presented. The proposed GSBT algorithm has been evaluated in a real test-bed to compare with the traditional approaches used in both MPICH and Open MPI. The result shows that GSBT algorithm is faster than standard algorithms 30.48–66.35% for Open MPI and faster 50.77–82.89% for MPICH when message size between 2 KB – 24 KB.},
  keywords={},
  doi={10.1109/ISCIT.2015.7458357},
  ISSN={},
  month={Oct},}
@INPROCEEDINGS{7459842,
  author={Liu, Lei and Yuen, Chau and Guan, Yong Liang and Li, Ying and Su, Yuping},
  booktitle={2015 10th International Conference on Information, Communications and Signal Processing (ICICS)}, 
  title={A low-complexity Gaussian message passing iterative detector for massive MU-MIMO systems}, 
  year={2015},
  volume={},
  number={},
  pages={1-5},
  abstract={This paper considers a low-complexity Gaussian Message Passing Iterative Detection (GMPID) method over a pairwise graph for a massive Multiuser Multiple-Input Multiple-Output (MU-MIMO) system, in which a base station with M antennas serves K Gaussian sources simultaneously. Both K and M are large numbers and we consider the cases that K < M in this paper. The GMPID is a message passing algorithm based on a fully connected loopy graph, which is well known that it is not convergent in some cases. In this paper, we first analyse the convergence of GMPID. Two sufficient conditions that the GMPID converges to the Minimum Mean Square Error (MMSE) detection are proposed. However, the GMPID may still not converge when K/M > (√2 − l)2. Therefore, a new convergent GMPID with equally low complexity called SA-GMPID is proposed, which converges to the MMSE detection for any K < M with a faster convergence speed. Finally, numerical results are provided to verify the validity and accuracy of the proposed theoretical results.},
  keywords={},
  doi={10.1109/ICICS.2015.7459842},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{7473375,
  author={Weidong, Gu and Jinqiao, Feng and Yazhou, Wang and Hongjun, Zhong and Jidong, Huo},
  booktitle={2015 8th International Conference on Intelligent Computation Technology and Automation (ICICTA)}, 
  title={Parallel Performance of an Ant Colony Optimization Algorithm for TSP}, 
  year={2015},
  volume={},
  number={},
  pages={625-629},
  abstract={MAX-MIN ant colony system (MMAS) has been one of the most effective ant colony optimization algorithm for the traveling salesman problem (TSP) up to the present. Despite the intrinsic parallelism, problems such as excessive memory occupation and overlong communication cost arise in the parallel process for large-scale numerical examples. In this paper, for parallel optimization of MMAS, some strategies are proposed: a) by comparing the current solution with the optimal solution, unnecessary ergodic paths and iterations are abandoned, which accelerates the searching process, b) for generating distance matrix and updating pheromone matrix, communications are replaced by calculations, which reduces memory occupation and communication cost enormously. MMAS with the above strategies is implemented on the Sunway Blue Light supercomputer based on MPI. As a result, high feasibility and effectiveness are verified.},
  keywords={},
  doi={10.1109/ICICTA.2015.159},
  ISSN={},
  month={June},}
@INPROCEEDINGS{7488425,
  author={Nair, Manjusha and Surya, Shan and Kumar, Revathy S and Nair, Bipin and Diwakar, Shyam},
  booktitle={2015 IEEE Recent Advances in Intelligent Computational Systems (RAICS)}, 
  title={Efficient simulations of spiking neurons on parallel and distributed platforms: Towards large-scale modeling in computational neuroscience}, 
  year={2015},
  volume={},
  number={},
  pages={262-267},
  abstract={Human brain communicates information by means of electro-chemical reactions and processes it in a parallel, distributed manner. Computational models of neurons at different levels of details are used in order to make predictions for physiological dysfunctions. Advances in the field of brain simulations and brain computer interfaces have increased the complexity of this modeling process. With a focus to build large-scale detailed networks, we used high performance computing techniques to model and simulate the granular layer of the cerebellum. Neuronal firing patterns of cerebellar granule neurons were modeled using two mathematical models Hodgkin-Huxley (HH) and Adaptive Exponential Leaky Integrate and Fire(AdEx). The performance efficiency of these modeled neurons was tested against a detailed multi-compartmental model of the granule cell. We compared different schemes suitable for large scale simulations of cerebellar networks. Large networks of neurons were constructed and simulated. Graphic Processing Units (GPU) was employed in the pleasantly parallel implementation while Message Passing Interface (MPI) was used in the distributed computing approach. This allowed to explore constraints of different parallel architectures and to efficiently load balance the tasks by maximally utilizing the available resources. For small scale networks, the observed absolute speedup was 6X in an MPI based approach with 32 processors while GPUs gave 10X performance gain compared to a single CPU implementation. In large networks, GPUs gave approximately 5X performance gain in processing time compared to the MPI implementation. The results enabled us to choose parallelization schemes suitable for large-scale simulations of cerebellar circuits. We are currently extending the network model based on large scale simulations evaluated in this paper and using a hybrid — heterogeneous MPI based multi-GPU architecture for incorporating millions of cerebellar neurons for assessing physiological disorders in such circuits.},
  keywords={},
  doi={10.1109/RAICS.2015.7488425},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{7507256,
  author={da Rosa Righi, Rodrigo and de Quadros Gomes, Roberto and Rodrigues, Vinicius Facco and da Costa, Cristiano André and Alberti, Antonio Marcos},
  booktitle={2015 IEEE/ACS 12th International Conference of Computer Systems and Applications (AICCSA)}, 
  title={MigBSP++: Improving process rescheduling on Bulk-Synchronous Parallel applications}, 
  year={2015},
  volume={},
  number={},
  pages={1-8},
  abstract={Process migration is a known technique to offer process rescheduling, being especially pertinent for Bulk Synchronous Parallel (BSP) programs. Such programs are organized in a set of supersteps, in which the slowest process always determines the synchronization time. This approach motivated us to develop a first model called MigBSP, which combines computation, communication, and migration costs metrics for process rescheduling decisions. In this paper, a new model named MigBSP++ enhances our previous work in three aspects: (i) a different algorithm for detecting imbalance situations, which considers the performance of all processes over each processor instead of their individual times; (ii) an improvement on the rescheduling reactivity through shortening the interval for the next migration call when imbalance situations arise; (iii) a new algorithm for self-organizing the migratable processes and their destinations. Particularly, this third item represents our main scientific contribution, not only in terms of the MigBSP context, but also in a broader one that covers the entire BSP landscape. We developed a MigBSP++ prototype with the Adaptive MPI (AMPI) library, which offers a standard framework for implementing migration-based load balancing policies. We tested this prototype against other built-in AMPI rescheduling policies with a fractal image compression application. The results revealed performance gains up to 41% and an overhead limited to 5% when migrations do not take place.},
  keywords={},
  doi={10.1109/AICCSA.2015.7507256},
  ISSN={2161-5330},
  month={Nov},}
@INPROCEEDINGS{7507167,
  author={Ktari, Mouna and Haddar, Mohamed Amine and Kacem, Ahmed Hadj and Mosbah, Mohamed},
  booktitle={2015 IEEE/ACS 12th International Conference of Computer Systems and Applications (AICCSA)}, 
  title={Proving distributed algorithms for mobile agents: Examples of spanning tree computation in dynamic networks}, 
  year={2015},
  volume={},
  number={},
  pages={1-7},
  abstract={In a dynamic network topological events can occur at any time, and no stable periods can be assumed. To make designing distributed algorithms easier, we model these latter with a local computation model. The implementation of a local computation model using message passing communication model has given rise to various problems. Among these we can mention the use of a great amount of communication and computation resources. In order to solve these problems, we propose another implementation of rewriting systems using mobile agents. We present then, using local computations, a framework for describing distributed algorithms for mobile agents in a dynamic network. We make use of the high level encoding of these algorithms as transition rules. The main advantage of this uniform and formal approach is the proof correctness of distributed algorithms. We illustrate this approach by giving an example of distributed computation of a hierarchical spanning tree by mobile agents in a dynamic network.},
  keywords={},
  doi={10.1109/AICCSA.2015.7507167},
  ISSN={2161-5330},
  month={Nov},}
@INPROCEEDINGS{7517004,
  author={Zhang, Wenchao and Chen, Song and Bai, Xuefei and Zhou, Dajiang},
  booktitle={2015 IEEE 11th International Conference on ASIC (ASICON)}, 
  title={A full layer parallel QC-LDPC decoder for WiMAX and Wi-Fi}, 
  year={2015},
  volume={},
  number={},
  pages={1-4},
  abstract={This paper presents a full layer parallel quasi-cyclic low density parity check (QC-LDPC) code decoder for IEEE 802.16e (WiMAX) and IEEE 802.11n (Wi-Fi). By adopting three techniques including reusable fully parallel check node unit (CNU) structure, path rerouting network (PRN) and reusable permutation network (PN), the proposed decoder gets Gbps level throughput and could support two standards and most code modes of them with low hardware cost. By using turbo-decoding message-passing normalized min-sum (TDMP-NMS) decoding strategy, the bit error rate (BER) of the proposed decoder is decreasing fast to 10−5 at 2.2 dB. It only takes 30∼40/30∼60 clock cycles in each decoding iteration for WiMAX/Wi-Fi. Using SMIC 40nm low leakage HS RVT CMOS process and 7-bit quantization, the proposed decoder attains 789∼2227/470∼1879 Mbps for WiMAX/Wi-Fi at 290 MHz, 10 iterations, and only occupies 2.26 mm2 area.},
  keywords={},
  doi={10.1109/ASICON.2015.7517004},
  ISSN={2162-755X},
  month={Nov},}
@INPROCEEDINGS{7542267,
  author={Talupur, Muralidhar and Ray, Sandip and Erickson, John},
  booktitle={2015 Formal Methods in Computer-Aided Design (FMCAD)}, 
  title={Transaction flows and executable models: formalization and analysis of message-passing protocols}, 
  year={2015},
  volume={},
  number={},
  pages={168-175},
  abstract={The lack of appropriate models is often the biggest hurdle in applying formal methods in the industry. Creating executable models of industrial designs is a challenging task, one that we believe has not been sufficiently addressed by existing research. We address this problem for distributed message passing protocols by showing how to synthesize executable models of such protocols from transaction message flows, which are readily available in architecture descriptions. We present industrial case studies showing that this approach to creating formal models is effective in practice. We also show that going the other way, i.e., extracting flows from executable models, is at least as hard as the model-checking problem. These results indicate that transaction flows may provide a superior approach to capture design intent than executable models.},
  keywords={},
  doi={10.1109/FMCAD.2015.7542267},
  ISSN={},
  month={Sep.},}
@INPROCEEDINGS{7745774,
  author={Guo, Chunli and Nelson, James D. B.},
  booktitle={2nd IET International Conference on Intelligent Signal Processing 2015 (ISP)}, 
  title={Direction of arrival estimation via approximate message passing}, 
  year={2015},
  volume={},
  number={},
  pages={1-6},
  abstract={In this paper, the conventional direction-of-arrival (DOA) problem is revisited by considering the recently proposed expectation maximization approximate message passing (EM-AMP) algorithm. The EM-AMP approximates the sparse DOA prior with the Bernoulli-Gaussian distribution to explore both the signal sparsity and the pdf information for the bearing estimation. Tests are performed on both synthetic and real acoustic experiment data with a partially oversampled discrete Fourier transform sensing matrix. Simulations with EM-AMP demonstrate practicable performance while circumventing the regularizor selection problem suffered by the Iι minimization approach, which makes it a useful tool for practical DOA estimation.},
  keywords={},
  doi={10.1049/cp.2015.1774},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{7832806,
  author={Gong, Yifan and He, Bingsheng and Zhou, Amelie Chi},
  booktitle={SC '15: Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis}, 
  title={Monetary cost optimizations for MPI-based HPC applications on Amazon clouds: checkpoints and replicated execution}, 
  year={2015},
  volume={},
  number={},
  pages={1-12},
  abstract={In this paper, we propose monetary cost optimizations for MPI-based applications with deadline constraints on Amazon EC2. Particularly, we consider to utilize two kinds of Amazon EC2 instances (on-demand and spot instances). As a spot instance can fail at any time due to out-of-bid events, fault tolerant executions are necessary. Through detailed studies, we have found that two common fault tolerant mechanisms, i.e., checkpoints and replicated executions, are complementary for cost-effective MPI executions on spot instances. We formulate the optimization problem and propose a novel cost model to minimize the expected monetary cost. The experimental results with NPB benchmarks on Amazon EC2 demonstrate that 1) it is feasible to run MPI applications with performance constraints on spot instances, 2) our proposal achieves significant monetary cost reduction compared to the state-of-the-art algorithm and 3) it is necessary to adaptively choose checkpoint and replication techniques for cost-effective and reliable MPI executions on Amazon EC2.},
  keywords={},
  doi={10.1145/2807591.2807612},
  ISSN={2167-4337},
  month={Nov},}
@INPROCEEDINGS{7832808,
  author={Guo, Yanfei and Bland, Wesley and Balaji, Pavan and Zhou, Xiaobo},
  booktitle={SC '15: Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis}, 
  title={Fault tolerant MapReduce-MPI for HPC clusters}, 
  year={2015},
  volume={},
  number={},
  pages={1-12},
  abstract={Building MapReduce applications using the Message-Passing Interface (MPI) enables us to exploit the performance of large HPC clusters for big data analytics. However, due to the lacking of native fault tolerance support in MPI and the incompatibility between the MapReduce fault tolerance model and HPC schedulers, it is very hard to provide a fault tolerant MapReduce runtime for HPC clusters. We propose and develop FT-MRMPI, the first fault tolerant MapReduce framework on MPI for HPC clusters. We discover a unique way to perform failure detection and recovery by exploiting the current MPI semantics and the new proposal of user-level failure mitigation. We design and develop the checkpoint/restart model for fault tolerant MapReduce in MPI. We further tailor the detect/resume model to conserve work for more efficient fault tolerance. The experimental results on a 256-node HPC cluster show that FT-MRMPI effectively masks failures and reduces the job completion time by 39%.},
  keywords={},
  doi={10.1145/2807591.2807617},
  ISSN={2167-4337},
  month={Nov},}
@INPROCEEDINGS{7832835,
  author={Siegel, Stephen F. and Zheng, Manchun and Luo, Ziqing and Zirkel, Timothy K. and Marianiello, Andre V. and Edenhofner, John G. and Dwyer, Matthew B. and Rogers, Michael S.},
  booktitle={SC '15: Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis}, 
  title={CIVL: the concurrency intermediate verification language}, 
  year={2015},
  volume={},
  number={},
  pages={1-12},
  abstract={There are many ways to express parallel programs: message-passing libraries (MPI) and multithreading/GPU language extensions such as OpenMP, Pthreads, and CUDA, are but a few. This multitude creates a serious challenge for developers of software verification tools: it takes enormous effort to develop such tools, but each development effort typically targets one small part of the concurrency landscape, with little sharing of techniques and code among efforts. To address this problem, we present CIVL: the Concurrency Intermediate Verification Language. CIVL provides a general concurrency model capable of representing programs in a variety of concurrency dialects, including those listed above. The CIVL framework currently includes front-ends for the four dialects, and a back-end verifier which uses model checking and symbolic execution to check a number of properties, including the absence of deadlocks, race conditions, assertion violations, illegal pointer dereferences and arithmetic, memory leaks, divisions by zero, and out-of-bound array indexing; it can also check that two programs are functionally equivalent.},
  keywords={},
  doi={10.1145/2807591.2807635},
  ISSN={2167-4337},
  month={Nov},}
@INPROCEEDINGS{7832851,
  author={Kaya, Oguz and Uçar, Bora},
  booktitle={SC '15: Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis}, 
  title={Scalable sparse tensor decompositions in distributed memory systems}, 
  year={2015},
  volume={},
  number={},
  pages={1-11},
  abstract={We investigate an efficient parallelization of the most common iterative sparse tensor decomposition algorithms on distributed memory systems. A key operation in each iteration of these algorithms is the matricized tensor times Khatri-Rao product (MTTKRP). This operation amounts to element-wise vector multiplication and reduction depending on the sparsity of the tensor. We investigate a fine and a coarse-grain task definition for this operation, and propose hypergraph partitioning-based methods for these task definitions to achieve the load balance as well as reduce the communication requirements. We also design a distributed memory sparse tensor library, HyperTensor, which implements a well-known algorithm for the CANDECOMP-/PARAFAC (CP) tensor decomposition using the task definitions and the associated partitioning methods. We use this library to test the proposed implementation of MTTKRP in CP decomposition context, and report scalability results up to 1024 MPI ranks. We observed up to 194 fold speedups using 512 MPI processes on a well-known real world data, and significantly better performance results with respect to a state of the art implementation.},
  keywords={},
  doi={10.1145/2807591.2807624},
  ISSN={2167-4337},
  month={Nov},}
@ARTICLE{8202992,
  author={Li, Xue-Bao and Liu, Zhong and Wang, Feng and Jin, Zhen-Yu and Xiang, Yong-Yuan and Zheng, Yan-Fang},
  journal={Publications of the Astronomical Society of Japan}, 
  title={High-performance parallel image reconstruction for the New Vacuum Solar Telescope}, 
  year={2015},
  volume={67},
  number={3},
  pages={47-47},
  abstract={Many technologies have been developed to help improve spatial resolution of observational images for ground-based solar telescopes, such as adaptive optics (AO) systems and post-processing reconstruction. As any AO system correction is only partial, it is indispensable to use post-processing reconstruction techniques. In the New Vacuum Solar Telescope (NVST), a speckle-masking method is used to achieve the diffraction-limited resolution of the telescope. Although the method is very promising, the computation is quite intensive, and the amount of data is tremendous, requiring several months to reconstruct observational data of one day on a high-end computer. To accelerate image reconstruction, we parallelize the program package on a high-performance cluster. We describe parallel implementation details for several reconstruction procedures. The code is written in the C language using the Message Passing Interface (MPI) and is optimized for parallel processing in a multiprocessor environment. We show the excellent performance of parallel implementation, and the whole data processing speed is about 71 times faster than before. Finally, we analyze the scalability of the code to find possible bottlenecks, and propose several ways to further improve the parallel performance. We conclude that the presented program is capable of executing reconstruction applications in real-time at NVST.},
  keywords={},
  doi={10.1093/pasj/psv018},
  ISSN={2053-051X},
  month={June},}
@ARTICLE{7060719,
  author={Xiao, Hao and Wu, Ning and Ge, Fen and Isshiki, Tsuyoshi and Kunieda, Hiroaki and Xu, Jun and Wang, Yuangang},
  journal={IEEE Transactions on Very Large Scale Integration (VLSI) Systems}, 
  title={Efficient Synchronization for Distributed Embedded Multiprocessors}, 
  year={2016},
  volume={24},
  number={2},
  pages={779-783},
  abstract={In multiprocessor systems, low-latency synchronization is extremely important to effectively exploit fine-grain data parallelism and improve overall performance. This brief presents an efficient synchronization for embedded distributed multiprocessors. The proposed solution works in a completely decentralized request-response manner via explicit message exchange among the processing elements. Scalable lock and barrier synchronization algorithms, which are derived from the inherent distributed characteristics of the underlying architecture, are proposed to enable fair, orderly, and contention-free synchronization. We implement the proposed synchronization model in a distributed 32-core architecture with a commercial cycle-accurate SystemC simulation platform. Experimental results that show our proposed approach achieves ultralow synchronization latency and almost ideal scalability when the core count scales.},
  keywords={},
  doi={10.1109/TVLSI.2015.2408345},
  ISSN={1557-9999},
  month={Feb},}
@ARTICLE{7078972,
  author={Guan, Zhangyu and Melodia, Tommaso and Scutari, Gesualdo},
  journal={IEEE/ACM Transactions on Networking}, 
  title={To Transmit or Not to Transmit? Distributed Queueing Games in Infrastructureless Wireless Networks}, 
  year={2016},
  volume={24},
  number={2},
  pages={1153-1166},
  abstract={We study distributed queueing games in interference-limited wireless networks. We formulate the throughput maximization problem via distributed selection of users' transmission thresholds as a Nash Equilibrium Problem (NEP). We first focus on the solution analysis of the NEP and derive sufficient conditions for the existence and uniqueness of a Nash Equilibrium (NE). Then, we develop a general best-response-based algorithmic framework wherein the users can explicitly choose the degree of desired cooperation and signaling, converging to different types of solutions, namely: 1) a NE of the NEP when there is no cooperation among users and 2) a stationary point of the Network Utility Maximization (NUM) problem associated with the NEP, when some cooperation among the users in the form of (pricing) message passing is allowed. Finally, as a benchmark, we design a globally optimal but centralized solution method for the nonconvex NUM problem. Our experiments show that in many scenarios the sum-throughput at the NE of the NEP is very close to the global optimum of the NUM problem, which validates our noncooperative and distributed approach. When the gap of the NE from the global optimality is non negligible (e.g., in the presence of “high” coupling among users), exploiting cooperation among the users in the form of pricing enhances the system performance.},
  keywords={},
  doi={10.1109/TNET.2015.2412116},
  ISSN={1558-2566},
  month={April},}
@ARTICLE{7097735,
  author={Mostéfaoui, Achour and Raynal, Michel},
  journal={IEEE Transactions on Parallel and Distributed Systems}, 
  title={Intrusion-Tolerant Broadcast and Agreement Abstractions in the Presence of Byzantine Processes}, 
  year={2016},
  volume={27},
  number={4},
  pages={1085-1098},
  abstract={A process commits a Byzantine failure when its behavior does not comply with the algorithm it is assumed to execute. Considering asynchronous message-passing systems, this paper presents distributed abstractions, and associated algorithms, that allow non-faulty processes to correctly cooperate, despite the uncertainty created by the net effect of asynchrony and Byzantine failures. These abstractions are broadcast abstractions (namely, no-duplicity broadcast, reliable broadcast, and validated broadcast), and agreement abstraction (namely, consensus). While no-duplicity broadcast and reliable broadcast are well-known one-to-all communication abstractions, validated broadcast is a new all-to-all communication abstraction designed to address agreement problems. After having introduced these abstractions, the paper presents an algorithm implementing validated broadcast on top of reliable broadcast. Then the paper presents two consensus algorithms, which are reductions of multivalued consensus to binary consensus. The first one is a generic algorithm, that can be instantiated with unreliable broadcast or no-duplicity broadcast, while the second is a consensus algorithm based on validated broadcast. Finally, a third algorithm is presented that solves the binary consensus problem. This algorithm is a randomized algorithm based on validated broadcast and a common coin. The presentation of all the abstractions and their algorithms is done incrementally.},
  keywords={},
  doi={10.1109/TPDS.2015.2427797},
  ISSN={1558-2183},
  month={April},}
@ARTICLE{7098397,
  author={Zhang, Weizhe and Cheng, Albert M. K. and Subhlok, Jaspal},
  journal={IEEE Transactions on Computers}, 
  title={DwarfCode: A Performance Prediction Tool for Parallel Applications}, 
  year={2016},
  volume={65},
  number={2},
  pages={495-507},
  abstract={We present DwarfCode, a performance prediction tool for MPI applications on diverse computing platforms. The goal is to accurately predict the running time of applications for task scheduling and job migration. First, DwarfCode collects the execution traces to record the computing and communication events. Then, it merges the traces from different processes into a single trace. After that, DwarfCode identifies and compresses the repeating patterns in the final trace to shrink the size of the events. Finally, a dwarf code is generated to mimic the original program behavior. This smaller running benchmark is replayed in the target platform to predict the performance of the original application. In order to generate such a benchmark, two major challenges are to reduce the time complexity of trace merging and repeat compression algorithms. We propose an O(mpn) trace merging algorithm to combine the traces generated by separate MPI processes, where m denotes the upper bound of tracing distance, p denotes the number of processes, and n denotes the maximum of event numbers of all the traces. More importantly, we put forward a novel repeat compression algorithm, whose time complexity is O(nlogn). Experimental results show that DwarfCode can accurately predict the running time of MPI applications. The error rate is below 10 percent for compute and communication intensive applications. This toolkit has been released for free download as a GNU General Public License v3 software.},
  keywords={},
  doi={10.1109/TC.2015.2417526},
  ISSN={1557-9956},
  month={Feb},}
@ARTICLE{7329979,
  author={Huang, Qin and Yuan, Shuai},
  journal={IEEE Transactions on Communications}, 
  title={Bit Reliability-Based Decoders for Non-Binary LDPC Codes}, 
  year={2016},
  volume={64},
  number={1},
  pages={38-48},
  abstract={Message-passing decoders typically perform well for nonbinary low-density parity-check (NB-LDPC) codes with large computational complexity. As another type of simplified decoders, symbol-reliability-based decoders further reduce the computational complexity. However, the previously proposed algorithms suffer severe error performance degradation for NB-LDPC codes with low column weights. In this paper, a weighted bit-reliability based (wBRB) decoder for NB-LDPC codes is developed and implemented with efficient layered partial-parallel structure. It not only balances the tradeoff between complexity and error performance, but also reduces the memory usage significantly. Furthermore, to enhance the performance of the wBRB decoder, a full bit-reliability-based (FBRB) decoder is proposed. The FBRB decoder is derived based on the binary matrix representation of the nonzero entries in the parity-check matrix. Since more bit-reliability values are passed through the edges of the Tanner graph, the FBRB decoder can achieve better error performance and faster convergence rate than the wBRB decoder. Both of the decoders are implemented on a Xilinx Virtex-5 XC5VLX155T FPGA device for a (403,226) code over GF(25). The results shows that they achieve 118.98 and 95.73 Mbps throughput with 15 iterations, respectively.},
  keywords={},
  doi={10.1109/TCOMM.2015.2501298},
  ISSN={1558-0857},
  month={Jan},}
@ARTICLE{7387784,
  author={Sohn, Illsoo and Lee, Sang Hyun},
  journal={IEEE Transactions on Vehicular Technology}, 
  title={Distributed Load Balancing via Message Passing for Heterogeneous Cellular Networks}, 
  year={2016},
  volume={65},
  number={11},
  pages={9287-9298},
  abstract={This paper presents a distributed load-balancing algorithm that maximizes the network-wide sum rate in heterogeneous cellular networks (HetNets). Unlike previous studies that have considered a logarithmic utility defined with respect to the sum rate, we maximize the sum rate directly to achieve the best user association for the HetNet. To capture realistic communication scenarios, we also consider a minimum rate constraint for individual users. The corresponding problem is formulated as a combinatorial optimization of which finding the solution becomes computationally demanding as the size of the network grows. Another challenge in HetNets is that the information exchange among base stations (BSs) is limited if each tier of BSs is deployed by different network vendors or users, and this brings about the need for distributed control. To resolve these challenges, we introduce a promising approach based on a message-passing framework and derive a distributed load-balancing algorithm. The proposed algorithm developed via message passing provides a very efficient solution for the load-balancing problem with reduced computational complexity. We compare the proposed algorithm with existing load-balancing strategies. Simulation results verify that the proposed algorithm significantly improves resource utilization and mitigates the congestion of macro BSs, thereby resulting in a multifold gain to the sum rate.},
  keywords={},
  doi={10.1109/TVT.2016.2519921},
  ISSN={1939-9359},
  month={Nov},}
@ARTICLE{7407632,
  author={Lee, Sang Hyun and Shin, Dong Ryul and Jeong, Hyun Woo and Kim, Yun Hee},
  journal={IEEE Transactions on Communications}, 
  title={Distributed Bargaining Strategy for Downlink Virtual MIMO With Device-to-Device Communication}, 
  year={2016},
  volume={64},
  number={4},
  pages={1503-1516},
  abstract={This letter considers the downlink of a cellular network with an asymmetric antenna configuration, where virtual multiple-input multiple-output (MIMO) is formed with receive cooperation over out-of-band or in-band overlay device-to-device (D2D) links. The objective of this work is to determine the best pairing and resource sharing configuration of the cooperative devices such that the overall network utility is optimized and the devices achieve their best available rate larger than that without D2D cooperation. A distributed algorithm is developed via an algorithmic-game-theoretic message-passing framework to obtain a solution at a low computational cost and without reporting the D2D link qualities to the base station. We show that the algorithm converges to an optimal point through analysis and its performance is validated by simulation. In addition, the virtual MIMO network enabled by the D2D receive cooperation is shown to provide a significant gain over the network without the D2D receive cooperation.},
  keywords={},
  doi={10.1109/TCOMM.2016.2530709},
  ISSN={1558-0857},
  month={April},}
@ARTICLE{7426807,
  author={Hunold, Sascha and Carpen-Amarie, Alexandra},
  journal={IEEE Transactions on Parallel and Distributed Systems}, 
  title={Reproducible MPI Benchmarking is Still Not as Easy as You Think}, 
  year={2016},
  volume={27},
  number={12},
  pages={3617-3630},
  abstract={The Message Passing Interface (MPI) is the prevalent programming model used on today's supercomputers. Therefore, MPI library developers are looking for the best possible performance (shortest run-time) of individual MPI functions across many different supercomputer architectures. Several MPI benchmark suites have been developed to assess the performance of MPI implementations. Unfortunately, the outcome of these benchmarks is often neither reproducible nor statistically sound. To overcome these issues, we show which experimental factors have an impact on the run-time of blocking collective MPI operations and how to measure their effect. Finally, we present a new experimental method that allows us to obtain reproducible and statistically sound measurements of MPI functions.},
  keywords={},
  doi={10.1109/TPDS.2016.2539167},
  ISSN={1558-2183},
  month={Dec},}
@INPROCEEDINGS{7427899,
  author={Gonçalves, Rogério and Amaris, Marcos and Okada, Thiago and Bruel, Pedro and Goldman, Alfredo},
  booktitle={2016 49th Hawaii International Conference on System Sciences (HICSS)}, 
  title={OpenMP is Not as Easy as It Appears}, 
  year={2016},
  volume={},
  number={},
  pages={5742-5751},
  abstract={This paper aims to show that knowing the core concepts related to a given parallel architecture is necessary to write correct code, regardless of the parallel programming paradigm used. Programmers unaware of architecture concepts, such as beginners and students, often write parallel code that is slower than their sequential versions. It is also easy to write code that produces incorrect answers under specific conditions, which are hard to detect and correct. The increasing popularization of multi-core architectures motivates the implementation of parallel programming frameworks and tools, such as OpenMP, that aim to lower the difficulty of parallel programming. OpenMP uses compilation directives, or pragmas, to reduce the number of lines that the programmer needs to write. However, the programmer still has to know when and how to use each of these directives. The documentation and available tutorials for OpenMP give the idea that using compilation directives for parallel programming is easy. In this paper we show that this is not always the case by analysing a set of corrections of OpenMP programs made by students of a graduate course in Parallel and Distributed Computing, at University of São Paulo. Several incorrect examples of OpenMP pragmas were found in tutorials and official documents available in the Internet. The idea that OpenMP is easy to use can lead to superficial efforts in teaching fundamental parallel programming concepts. This can in its turn lead to code that does not develop the full potential of OpenMP, and could also crash inexplicably due to very specific and hard-to-detect conditions. Our main contribution is showing how important it is to teach core architecture and parallel programming concepts properly, even when you have powerful tools such as OpenMP available.},
  keywords={},
  doi={10.1109/HICSS.2016.710},
  ISSN={1530-1605},
  month={Jan},}
@ARTICLE{7442589,
  author={Lai, Bo-Cheng Charles and Lee, Chia-Ying and Chiu, Tsou-Han and Kuo, Hsien-Kai and Chang, Chun-Kai},
  journal={IEEE Transactions on Computers}, 
  title={Unified Designs for High Performance LDPC Decoding on GPGPU}, 
  year={2016},
  volume={65},
  number={12},
  pages={3754-3765},
  abstract={Modern GPGPU's have enabled massively parallel computing with programmability that can exploit the highly parallel nature of LDPC decoding. Previous works customized the design on a GPGPU towards specific execution attributes of a particular LDPC decoding matrix. Supporting different LDPC decoding matrices requires either substantial rework on the current program, or a brand new parallel design. This paper proposes two unified designs that can achieve high performance for both regular and irregular LDPC decoding on a GPGPU. The first design introduces a node-based scheme with a versatile translation array mechanism that can efficiently handle the complex data access patterns of different LDPC decoding matrices. The second design proposes an edge-based parallel paradigm that uses more intuitive data layout. More edges than nodes in a Tanner graph also give the edge-based design higher computation parallelism when there are limited concurrent codewords. With the proposed unified designs, designers can be ignorant of the types of LDPC matrices and achieve high performance LDPC decoding. The experiments on a GTX 470 GPGPU have demonstrated up to 134.56x runtime improvement, when compared with designs on a high-end CPU. The maximum throughput can reach 80.25 Mbps. When compared with the previous customized designs, the proposed systematic designs can reach better performance while relieving the effort of customization.},
  keywords={},
  doi={10.1109/TC.2016.2547379},
  ISSN={1557-9956},
  month={Dec},}
@INPROCEEDINGS{7445337,
  author={Majd, Amin and Lotfi, Shahriar and Sahebi, Golnaz and Daneshtalab, Masoud and Plosila, Juha},
  booktitle={2016 24th Euromicro International Conference on Parallel, Distributed, and Network-Based Processing (PDP)}, 
  title={PICA: Multi-population Implementation of Parallel Imperialist Competitive Algorithms}, 
  year={2016},
  volume={},
  number={},
  pages={248-255},
  abstract={The importance of optimization and NP-problems solving cannot be over emphasized. The usefulness and popularity of evolutionary computing methods are also well established. There are various types of evolutionary methods that are mostly sequential, and some others have parallel implementation. We propose a method to parallelize Imperialist Competitive Algorithm (Multi-Population). The algorithm has been implemented with MPI on two platforms and have tested our algorithms on a shared-memory and message passing architecture. An outstanding performance is obtained, which indicates that the method is efficient concern to speed and accuracy. In the second step, the proposed algorithm is compared with a set of existing well known parallel algorithms and is indicated that it obtains more accurate solutions in a lower time.},
  keywords={},
  doi={10.1109/PDP.2016.93},
  ISSN={2377-5750},
  month={Feb},}
@INPROCEEDINGS{7445369,
  author={Utrera, Gladys and Gil, Marisa and Martorell, Xavier},
  booktitle={2016 24th Euromicro International Conference on Parallel, Distributed, and Network-Based Processing (PDP)}, 
  title={Analyzing Data-Error Propagation Effects in High-Performance Computing}, 
  year={2016},
  volume={},
  number={},
  pages={418-421},
  abstract={Algorithmic codes for scientific computing may exhibit diverse levels of tolerance to memory errors, depending on the program behavior when accessing data. For example, tolerance to errors may depend on the specific access patterns used while accessing memory, due to the application data structures and arrays. In this paper, we analyze the impact of the propagation of the errors originated from memory accesses on a solver running on a cluster. The application is written on top of the MPI programming model, and we evaluate the speed of the error propagation to other MPI processes. In addition, we propose a preliminary model to represent the most probable number of iterations needed to propagate the error from one process to any other process of the application. We implement and validate our model with the execution of miniFE miniapplication in a supercomputer platform. Our preliminary experimental results show that our model can make a quite accurate prediction of the memory error propagation within 14% of error.},
  keywords={},
  doi={10.1109/PDP.2016.42},
  ISSN={2377-5750},
  month={Feb},}
@INPROCEEDINGS{7445383,
  author={Taylor, Ramsay and Tuosto, Emilio and Walkinshaw, Neil and Derrick, John},
  booktitle={2016 24th Euromicro International Conference on Parallel, Distributed, and Network-Based Processing (PDP)}, 
  title={Choreography-Based Analysis of Distributed Message Passing Programs}, 
  year={2016},
  volume={},
  number={},
  pages={512-519},
  abstract={We report on the analysis of gen_server, a popular Erlang library to build client-server applications. Our analysis uses a tool based on choreographic models. We discuss how, once the library has been modelled in terms of communicating finite state machines, an automated analysis can be used to detect potential communication errors. The results of our analysis suggest how to properly use gen_server in order to guarantee the absence of communication errors.},
  keywords={},
  doi={10.1109/PDP.2016.72},
  ISSN={2377-5750},
  month={Feb},}
@INPROCEEDINGS{7459398,
  author={Mavroidis, Iakovos and Papaefstathiou, Ioannis and Lavagno, Luciano and Nikolopoulos, Dimitrios S. and Koch, Dirk and Goodacre, John and Sourdis, Ioannis and Papaefstathiou, Vassilis and Coppola, Marcello and Palomino, Manuel},
  booktitle={2016 Design, Automation & Test in Europe Conference & Exhibition (DATE)}, 
  title={ECOSCALE: Reconfigurable computing and runtime system for future exascale systems}, 
  year={2016},
  volume={},
  number={},
  pages={696-701},
  abstract={In order to reach exascale performance, current HPC systems need to be improved. Simple hardware scaling is not a feasible solution due to the increasing utility costs and power consumption limitations. Apart from improvements in implementation technology, what is needed is to refine the HPC application development flow as well as the system architecture of future HPC systems. ECOSCALE tackles these challenges by proposing a scalable programming environment and architecture, aiming to substantially reduce energy consumption as well as data traffic and latency. ECOSCALE introduces a novel heterogeneous energy-efficient hierarchical architecture, as well as a hybrid many-core+OpenCL programming environment and runtime system. The ECOSCALE approach is hierarchical and is expected to scale well by partitioning the physical system into multiple independent Workers (i.e. compute nodes). Workers are interconnected in a tree-like fashion and define a contiguous global address space that can be viewed either as a set of partitions in a Partitioned Global Address Space (PGAS), or as a set of nodes hierarchically interconnected via an MPI protocol. To further increase energy efficiency, as well as to provide resilience, the Workers employ reconfigurable accelerators mapped into the virtual address space utilizing a dual stage System Memory Management Unit with coherent memory access. The architecture supports shared partitioned reconfigurable resources accessed by any Worker in a PGAS partition, as well as automated hardware synthesis of these resources from an OpenCL-based programming model.},
  keywords={},
  doi={},
  ISSN={1558-1101},
  month={March},}
@INPROCEEDINGS{7471820,
  author={Debbabi, Imen and Khouja, Nadia and Tlili, Fethi and Le Gal, Bertrand and Jego, Christophe},
  booktitle={2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Multicore implementation of LDPC decoders based on ADMM algorithm}, 
  year={2016},
  volume={},
  number={},
  pages={971-975},
  abstract={Alternate direction method of multipliers (ADMM) technique has recently been proposed for LDPC decoding. Even though it improves the error rate performance compared with traditional message passing (MP) techniques, it shows a higher computation complexity. In this article, the ADMM decoding algorithm is first described. Then, its computation complexity is analyzed. Finally, an optimized version which benefits from the multi-core processors architecture as well as the ADMM algorithm s parallelism is presented. The optimized version of the ADMM decoder can achieve up to 30 Mbps for standardized LDPC codes on a laptop x86 processor. Therefore, it could guide an efficient GPU implementation for real-time and high-throughput decoding systems requiring correction performances beyond MP-Sum Product Algorithm (SPA) capabilities.},
  keywords={},
  doi={10.1109/ICASSP.2016.7471820},
  ISSN={2379-190X},
  month={March},}
@INPROCEEDINGS{7471246,
  author={Fontaine, Allyx and Mosbah, Mohamed and Tounsi, Mohamed and Zemmari, Akka},
  booktitle={2016 30th International Conference on Advanced Information Networking and Applications Workshops (WAINA)}, 
  title={A Fault-Tolerant Handshake Algorithm for Local Computations}, 
  year={2016},
  volume={},
  number={},
  pages={475-480},
  abstract={Distributed systems have been studied thoroughly. Many applications are based on huge systems and one of the main property an algorithm running on such systems should verified is fault-tolerance. This paper presents a new randomized algorithm to solve the handshake problem in a distributed system. This algorithm is designed for an asynchronous distributed network ofanonymous processes under the message passing communication protocol. In addition to its fault-tolerance, this algorithm is more effective than the existing ones thanks to its asynchronous aspect. To highlight its performance, we provide an experimental evaluation by comparing it to the most representative algorithm solving the handshake problem. The experimentation is done using Visidia, a tool for simulating and visualizing distributed algorithms.},
  keywords={},
  doi={10.1109/WAINA.2016.78},
  ISSN={},
  month={March},}
@INPROCEEDINGS{7482452,
  author={Nimara, Sergiu and Boncalo, Oana and Amaricai, Alexandru and Popa, Mircea},
  booktitle={2016 IEEE 19th International Symposium on Design and Diagnostics of Electronic Circuits & Systems (DDECS)}, 
  title={FPGA architecture of multi-codeword LDPC decoder with efficient BRAM utilization}, 
  year={2016},
  volume={},
  number={},
  pages={1-4},
  abstract={Implementation of Quasi-Cyclic (QC) Low Density Parity-Check (LDPC) decoder on FPGA devices has shown great interest in both wireless communication, as well as error correction for Flash memories. This paper presents an FPGA flooded LDPC decoder which uses multiple codeword processing for efficient memory utilization. It is based on a partially parallel implementation, which relies on memory blocks for message passing between the processing units. We obtain efficient memory utilization by packing multiple messages corresponding to multiple codewords into the same Block RAM word. The increase in throughput is linear with the number of processed codewords. The proposed LDPC decoder can process up to 9 codewords in parallel, for 4-bit message quantization, or up to 12 codewords, for 3-bit message quantization, without introducing significant memory overhead.},
  keywords={},
  doi={10.1109/DDECS.2016.7482452},
  ISSN={},
  month={April},}
@INPROCEEDINGS{7486275,
  author={Ranadive, Priti and Vaidya, Vinay G.},
  booktitle={2016 International Conference on Information Systems Engineering (ICISE)}, 
  title={Modeling Parallelization Overheads for Predicting Performance}, 
  year={2016},
  volume={},
  number={},
  pages={62-67},
  abstract={Legacy codes primarily exist on a single core processor. With the proliferation of multicore processors, end users often want to migrate to new platforms to improve performance or reduce execution time of the application. Migration from a single core processor to multicore is an expensive proposition. Thus, end users often want to get some idea about possible performance benefit prior to actual migration. Parallelizing a given application often leads to overheads due to the very constructs that enable parallelization. These overheads reduce performance of the application. In this paper, we analyze the overheads caused by OpenMP parallelization constructs. We further provide guidelines to programmers on how to reduce these overheads and maximize the performance benefits of parallelization. We start our analysis by using motivational examples, create a model and then validate our model with benchmark codes. Our experiments show that the following factors affect overheads: 1) type and scope of arrays, 2) array access w.r.t. the overall data flow, 3) number of iterations, and 4) the chunk sizes during execution. Based on our experiments we propose a mathematical model for predicting the number of cycles for these overheads. We use this model to predict overheads of four benchmark codes. Our results show that the error between the number of cycles predicted and observed is on an average 8.22%.},
  keywords={},
  doi={10.1109/ICISE.2016.19},
  ISSN={2160-1291},
  month={April},}
@INPROCEEDINGS{7497200,
  author={Thomas, Yannis and Xylomenos, George and Tsilopoulos, Christos and Polyzos, George C.},
  booktitle={2016 IFIP Networking Conference (IFIP Networking) and Workshops}, 
  title={Multi-flow congestion control with network assistance}, 
  year={2016},
  volume={},
  number={},
  pages={440-448},
  abstract={A well-known technique for enhancing the performance and stability of content distribution is the use of multiple dissemination flows. Multipath TCP (MPTCP), the most popular multiflow protocol on the Internet, allows receivers to exploit multiple paths towards a single sender. Nevertheless, MPTCP cannot fully exploit the potential gains of multipath connectivity, as it must fairly share resources with (single-flow) TCP, without a clear understanding of whether the available paths do share any bottleneck links. In this paper, we introduce a hybrid congestion control algorithm for multisource and multipath transport that enables higher bandwidth utilization compared to MPTCP, while remaining friendly to TCP-like flows. Our solution employs (i) an in-network module that offers essential topological information and (ii) Normalized Multiflow Congestion Control (NMCC), a novel end-to-end congestion control algorithm. While NMCC is architecture-independent and the in-network module can be adapted for Multi-Protocol Label Switching (MPLS) or Software Defined Networks (SDNs), our prototype was implemented on the Publish-Subscribe Internetworking (PSI) architecture, which offers centralized path formation and source routing. Using an actual protocol implementation deployed on our test-bed, we provide experimental results which validate the effectiveness of our design in terms of performance, adaptation to shifting network conditions and friendliness to other flows.},
  keywords={},
  doi={10.1109/IFIPNetworking.2016.7497200},
  ISSN={},
  month={May},}
@INPROCEEDINGS{7516003,
  author={Georganas, Evangelos and Van Der Wijngaart, Rob F. and Mattson, Timothy G.},
  booktitle={2016 IEEE International Parallel and Distributed Processing Symposium (IPDPS)}, 
  title={Design and Implementation of a Parallel Research Kernel for Assessing Dynamic Load-Balancing Capabilities}, 
  year={2016},
  volume={},
  number={},
  pages={73-82},
  abstract={The Parallel Research Kernels (PRK) are a tool to study parallel architectures and runtime systems from an application perspective. It provides paper and pencil specifications and reference implementations of elementary operations covering a broad range of parallel application patterns. The current PRK are trivially statically load-balanced. Future large-scale systems will require dynamic load balancing for unsteady workloads and for handling system/network fluctuations and non-uniformities. We present a new PRK that requires dynamic load balancing, and provides knobs for controlling workload behavior. It is inspired by Particle-In-Cell (PIC) applications and captures one of the computational patterns in such codes. We give a detailed specification of the new PRK, highlighting the challenges and corresponding design choices that make it compact, arbitrarily scalable and self-verifying. We also present implementations of the PIC PRK in MPI, with and without application-specific load balancing, and show an implementation with runtime-assisted load balancing provided by Adaptive MPI features. Our experimental results provide an illustrative example of how PIC can be used to assess the load-balancing capabilities of modern parallel runtimes.},
  keywords={},
  doi={10.1109/IPDPS.2016.65},
  ISSN={1530-2075},
  month={May},}
@INPROCEEDINGS{7516015,
  author={Jacquelin, Mathias and Lin, Lin and Wichmann, Nathan and Yang, Chao},
  booktitle={2016 IEEE International Parallel and Distributed Processing Symposium (IPDPS)}, 
  title={Enhancing Scalability and Load Balancing of Parallel Selected Inversion via Tree-Based Asynchronous Communication}, 
  year={2016},
  volume={},
  number={},
  pages={192-201},
  abstract={We develop a method for improving the parallel scalability of computations that involve asynchronous task execution. We apply this method to the recently developed parallel selected inversion algorithm [Jacquelin, Lin and Yang 2014], named PSelInv, on massively parallel distributed memory machines. In the PSelInv method, we compute selected elements of the inverse of a sparse matrix A that can be decomposed as A = LU, where L is lower triangular and U is upper triangular. Computing these selected elements of A-1 requires restricted collective communications among a subset of processors within each column or row communication group created by a block cyclic distribution of L and U. We describe how this type of restricted collective communication can be implemented using asynchronous point-to-point MPI communications combined with a binary tree based data propagation scheme. Because multiple restricted collective communications may take place at the same time, we need to use a heuristic to prevent processors participating in multiple collective communications from receiving too many messages. This heuristic allows us to reduce communication load imbalance and improve the overall scalability of the selected inversion algorithm. For instance, when 6, 400 processors are used, we observe that the use of this heuristic leads to over 5x speedup for a number of test matrices. It also mitigates the performance variability introduced by an inhomogeneous network topology.},
  keywords={},
  doi={10.1109/IPDPS.2016.38},
  ISSN={1530-2075},
  month={May},}
@INPROCEEDINGS{7516132,
  author={Marginean, Marcel-Titus and Lu, Chao},
  booktitle={2016 IEEE 14th International Conference on Software Engineering Research, Management and Applications (SERA)}, 
  title={Multi-threaded message dispatcher framework for Mission Critical Applications}, 
  year={2016},
  volume={},
  number={},
  pages={83-89},
  abstract={The usage of well-tried software design patterns and application frameworks is often encountered in Mission and Safety Critical Applications development due to the high stakes involved in the case of failures. To increase reliability, some frameworks attempt to separate the implementation of business logic and low level implementation details and move the latter inside of framework-implementation in order to allow the developers to focus as much as possible on the problem to be solved while providing the necessary infrastructure into easy to use API's. In this paper we present a framework for message processing which takes advantage of the newer C++11 features to enforce separation of concerns, perform dead-lock avoidance, and encourage unit testing.},
  keywords={},
  doi={10.1109/SERA.2016.7516132},
  ISSN={},
  month={June},}
@INPROCEEDINGS{7515685,
  author={El-Helw, Ismail and Hofman, Rutger and Bal, Henri E.},
  booktitle={2016 16th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing (CCGrid)}, 
  title={Towards Fast Overlapping Community Detection}, 
  year={2016},
  volume={},
  number={},
  pages={175-178},
  abstract={Accelerating sequential algorithms in order to achieve high performance is often a nontrivial task. However, there are certain properties that can exacerbate this process and make it particularly daunting. For example, building an efficient parallel solution for a data-intensive algorithm requires a deep analysis of the memory access patterns and data reuse potential. Attempting to scale out the computations on clusters of machines introduces further complications due to network speed limitations. In this context, the optimization landscape can be extremely complex owing to the large number of trade-off decisions. In this paper, we discuss our experience designing two parallel implementations of an existing data-intensive machine learning algorithm that detects overlapping communities in graphs. The first design uses a single GPU to accelerate the computations of small data sets. We employed a code generation strategy in order to test and identify the best performing combination of optimizations. The second design uses a cluster of machines to scale out the computations for larger problem sizes. We used a mixture of MPI, RDMA and pipelining in order to circumvent networking overhead. Both these efforts bring us closer to understanding the complex relationships hidden within networks of entities.},
  keywords={},
  doi={10.1109/CCGrid.2016.98},
  ISSN={},
  month={May},}
@INPROCEEDINGS{7515735,
  author={Dosanjh, Matthew G. F. and Groves, Taylor and Grant, Ryan E. and Brightwell, Ron and Bridges, Patrick G.},
  booktitle={2016 16th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing (CCGrid)}, 
  title={RMA-MT: A Benchmark Suite for Assessing MPI Multi-threaded RMA Performance}, 
  year={2016},
  volume={},
  number={},
  pages={550-559},
  abstract={Reaching Exascale will require leveraging massive parallelism while potentially leveraging asynchronous communication to help achieve scalability at such large levels of concurrency. MPI is a good candidate for providing the mechanisms to support communication at such large scales. Two existing MPI mechanisms are particularly relevant to Exascale: multi-threading, to support massive concurrency, and Remote Memory Access (RMA), to support asynchronous communication. Unfortunately, multi-threaded MPI RMA code has not been extensively studied. Part of the reason for this is that no public benchmarks or proxy applications exist to assess its performance. The contributions of this paper are the design and demonstration of the first available proxy applications and micro-benchmark suite for multi-threaded RMA in MPI, a study of multi-threaded RMA performance of different MPI implementations, and an evaluation of how these benchmarks can be used to test development for both performance and correctness.},
  keywords={},
  doi={10.1109/CCGrid.2016.84},
  ISSN={},
  month={May},}
@INPROCEEDINGS{7515761,
  author={García H., John A. and Hernandez B., Esteban and Montenegro, Carlos E. and Navaux, Philippe O. and Barrios H., Carlos J.},
  booktitle={2016 16th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing (CCGrid)}, 
  title={enerGyPU and enerGyPhi Monitor for Power Consumption and Performance Evaluation on Nvidia Tesla GPU and Intel Xeon Phi}, 
  year={2016},
  volume={},
  number={},
  pages={718-725},
  abstract={The evaluation of performance and power consumption is a key step in the design of applications for large computational systems as supercomputers and clusters (multicore and accelerator nodes, multicore and coprocessor nodes, manycore and accelerator nodes). In these systems the developers must design several experiments for workload characterization observing the architectural implications when using different combinations of computational resources such as number of GPU, number of cores for processing, number of cores for administration of GPU, number of MPI processes and thread affinity policy. It should also engage factors as the clock frequency and memory usage as well select the combination of computational resources that increases the performance and minimizes the power consumption. This research proposes an integrated energy-aware scheme called efficiently energetic acceleration (EEA) for large-scale scientific applications running on heterogeneous architectures. This paper shows the use of a monitoring tool with two components called enerGyPU and enerGyPhi to recording EEA control factors in runtime on two environments: one cluster with multicore and accelerator nodes (2-CPU/8-GPU) and one server with multiple cores and one coprocessor (2-CPU/1-MIC). These monitors allow to analyze multiple testing results under different parameter combinations to observe the EEA control factors that determine the energy efficiency.},
  keywords={},
  doi={10.1109/CCGrid.2016.100},
  ISSN={},
  month={May},}
@INPROCEEDINGS{7522812,
  author={Wu, Xia and Zhou, Yu},
  booktitle={2016 Asia-Pacific International Symposium on Electromagnetic Compatibility (APEMC)}, 
  title={Solution of 3-dimensional electromagnetics radiation problems by using time-domain finite element method with parallel solvers}, 
  year={2016},
  volume={01},
  number={},
  pages={61-63},
  abstract={In this paper, parallel fulfillment is developed for calculation of the electric field and radiation patterns of three-dimensional electromagnetic (EM) radiation problems by using time-domain finite element method (TDFEM). To speed up the calculation process, SuperLU of a Message Passing Interface (MPI) version called SuperLU_DIST is employed in this approach. Finally, a rectangular waveguide and a two-segment dielectric resonator antenna (TSDRA) are computed to validate the accuracy and stability of the scheme.},
  keywords={},
  doi={10.1109/APEMC.2016.7522812},
  ISSN={},
  month={May},}
@INPROCEEDINGS{7529947,
  author={Hao, Ning and Oghbaee, Amirreza and Rostami, Mohammad and Derbinsky, Nate and Bento, José},
  booktitle={2016 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)}, 
  title={Testing Fine-Grained Parallelism for the ADMM on a Factor-Graph}, 
  year={2016},
  volume={},
  number={},
  pages={835-844},
  abstract={There is an ongoing effort to develop tools that apply distributed computational resources to tackle large problems or reduce the time to solve them. In this context, the Alternating Direction Method of Multipliers (ADMM) arises as a method that can exploit distributed resources like the dual ascent method and has the robustness and improved convergence of the augmented Lagrangian method. Traditional approaches to accelerate the ADMM using multiple cores are problem-specific and often require multi-core programming. By contrast, we propose a problem-independent scheme of accelerating the ADMM that does not require the user to write any parallel code. We show that this scheme, an interpretation of the ADMM as a message-passing algorithm on a factor-graph, can automatically exploit fine-grained parallelism both in GPUs and shared-memory multi-core computers and achieves significant speedup in such diverse application domains as combinatorial optimization, machine learning, and optimal control. Specifically, we obtain 10-18x speedup using a GPU, and 5-9x using multiple CPU cores, over a serial, optimized C-version of the ADMM, which is similar to the typical speedup reported for existing GPU-accelerated libraries, including cuFFT (19x), cuBLAS (17x), and cuRAND (8x).},
  keywords={},
  doi={10.1109/IPDPSW.2016.162},
  ISSN={},
  month={May},}
@INPROCEEDINGS{7530005,
  author={Carpaye, Jean Marie Couteyen and Roman, Jean and Brenner, Pierre},
  booktitle={2016 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)}, 
  title={Towards an Efficient Task-Based Parallelization over a Runtime System of an Explicit Finite-Volume CFD Code with Adaptive Time Stepping}, 
  year={2016},
  volume={},
  number={},
  pages={1212-1221},
  abstract={FLUSEPA is an advanced simulation tool whichperforms a large panel of aerodynamic studies. It is the unstructured finite-volume solver developed by Airbus Defence & Spacecompany to calculate compressible, multidimensional, unsteady, viscous and reactive flows around bodies in relative motion. Thetime integration in FLUSEPA is done using an explicit temporaladaptive method. The current production version of the codeis based on MPI and OpenMP. This implementation leads toimportant synchronizations that must be reduced. To tackle thisproblem, we present a first study of a task-based parallelizationof the solver part of FLUSEPA using the runtime system StarPUand combining up to three levels of parallelism. We validate oursolution on the simulation of a take-off blast wave propagationfor Ariane 5 launcher.},
  keywords={},
  doi={10.1109/IPDPSW.2016.125},
  ISSN={},
  month={May},}
@INPROCEEDINGS{7530007,
  author={Strazdins, Peter E. and Ali, Md. Mohsin and Debusschere, Bert},
  booktitle={2016 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)}, 
  title={Application Fault Tolerance for Shrinking Resources via the Sparse Grid Combination Technique}, 
  year={2016},
  volume={},
  number={},
  pages={1232-1238},
  abstract={The need to make large-scale scientific simulations resilient to the shrinking and growing of compute resources arises from exascale computing and adverse operating conditions (fault tolerance). It can also arise from the cloudcomputing context where the cost of these resources can fluctuate. In this paper, we describe how the Sparse Grid Combination Technique can make such applications resilient to shrinking compute resources. The solution of the non-trivial issues of dealing with data redistribution and on-the-fly malleability of process grid information and ULFM MPI communicatorsare described. Results on a 2D advection solver indicate that process recovery time is significantly reduced from the alternate strategy where failed resources are replaced, overall execution time is actually improved from this case and for checkpointing and the execution error remains small, even when multiple failures occur.},
  keywords={},
  doi={10.1109/IPDPSW.2016.210},
  ISSN={},
  month={May},}
@INPROCEEDINGS{7529902,
  author={Sachdeva, Vipin and Aluru, Srinivas and Bader, David A.},
  booktitle={2016 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)}, 
  title={A Memory and Time Scalable Parallelization of the Reptile Error-Correction Code}, 
  year={2016},
  volume={},
  number={},
  pages={453-462},
  abstract={This paper details a distributed memory implementation of Reptile, a scalable and accurate spectrum based error-correction method. Reptile uses both k-mer and adjoining k-mers (called tiles) information along with the quality scores of bases to correct substitution-based errors from next generation sequencing machines. Previous approaches to parallelize Preptile have replicated the spectrums on each node which can be prohibitive in terms of memory needed for huge datasets. Our approach distributes both the k-mer and the tile spectrum amongst the processing ranks, relying on message passing for error correction. This allows hardware with any memory size per node to be employed for error-correction using Reptile's algorithm, irrespective of the size of the dataset. As part of our implementation, we have also implemented several heuristics which can be used to run the algorithm optimally based on the advantages of the hardware used. We present our results on IBM's BlueGene/Q architecture for the E.Coli, Drosophila and the human datasets showing excellent scalability with increasing number of nodes. Using 256 nodes of BlueGene/Q, we are able to error correct E.Coli and Drosphila datasets in less than 200 seconds and 600 seconds respectively. The human dataset consisting of 1.55 billion reads is corrected in a little more than two hours using 1024 nodes of BlueGene/Q. All three datasets are corrected with Reptile's memory intensive algorithm with less than 512 MB per process.},
  keywords={},
  doi={10.1109/IPDPSW.2016.59},
  ISSN={},
  month={May},}
@INPROCEEDINGS{7536435,
  author={Savvas, Ilias K. and Tselios, Dimitrios},
  booktitle={2016 IEEE 25th International Conference on Enabling Technologies: Infrastructure for Collaborative Enterprises (WETICE)}, 
  title={Parallelizing DBSCaN Algorithm Using MPI}, 
  year={2016},
  volume={},
  number={},
  pages={77-82},
  abstract={The last years, huge bundles of information are extracted by computational systems and electronic devices. To exploit the derived amount of data, new innovative algorithms must be employed or the established ones maybe changed. One of the most fascinating and productive techniques, in order to locate and extract information from data repositories is clustering, and DBSCAN is a successful density based algorithm which clusters data according its characteristics. However, its main disadvantage is its severe computational complexity which proves the technique very inadequate to apply on big datasets. Although DBSCAN is a very well studied technique, a fully operational parallel version of it, has not been accepted yet by the scientific community. In this work, a three phase parallel version of DBSCAN is presented. The obtained experimental results are very promising and prove the correctness, the scalability, and the effectiveness of the technique.},
  keywords={},
  doi={10.1109/WETICE.2016.26},
  ISSN={},
  month={June},}
@INPROCEEDINGS{7536391,
  author={Murray, Toby and Sison, Robert and Pierzchalski, Edward and Rizkallah, Christine},
  booktitle={2016 IEEE 29th Computer Security Foundations Symposium (CSF)}, 
  title={Compositional Verification and Refinement of Concurrent Value-Dependent Noninterference}, 
  year={2016},
  volume={},
  number={},
  pages={417-431},
  abstract={Value-dependent noninterference allows the classification of program variables to depend on the contents of other variables, and therefore is able to express a range of data-dependent security policies. However, so far its static enforcement mechanisms for software have been limited either to progress-and termination-insensitive noninterference for sequential languages, or to concurrent message-passing programs without shared memory. Additionally, there exists no methodology for preserving value-dependent noninterference for shared memory programs under compositional refinement. This paper presents a flow-sensitive dependent type system for enforcing timing-sensitive value-dependent noninterference for shared memory concurrent programs, comprising a collection of sequential components, as well as a compositional refinement theory for preserving this property under componentwise refinement. Our results are mechanised in Isabelle/HOL.},
  keywords={},
  doi={10.1109/CSF.2016.36},
  ISSN={2374-8303},
  month={June},}
@INPROCEEDINGS{7536565,
  author={Babay, Amy and Amir, Yair},
  booktitle={2016 IEEE 36th International Conference on Distributed Computing Systems (ICDCS)}, 
  title={Fast Total Ordering for Modern Data Centers}, 
  year={2016},
  volume={},
  number={},
  pages={669-679},
  abstract={The performance profile of local area networks has changed over the last decade, but many practical group communication and ordered messaging tools rely on core ideas invented over a decade ago. We present the Accelerated Ring protocol, a novel ordering protocol that improves on the performance of standard token-based protocols by allowing processes to pass the token before they have finished multicasting. This performance improvement is obtained while maintaining the correctness and other beneficial properties of token-based protocols. On 1-gigabit networks, a single-threaded daemon-based implementation of the protocol reaches network saturation, and can reduce latency by 45% compared to a standard token-based protocol while simultaneously increasing throughput by 30%. On 10-gigabit networks, the implementation reaches throughputs of 6 Gbps, and can reduce latency by 30-35% while simultaneously increasing throughput by 25-40%. A production implementation of the Accelerated Ring protocol has been adopted as the default ordering protocol for data center environments in Spread, a widely-used open-source group communication system.},
  keywords={},
  doi={10.1109/ICDCS.2016.20},
  ISSN={1063-6927},
  month={June},}
@INPROCEEDINGS{7541385,
  author={Zhu, Junan and Beirami, Ahmad and Baron, Dror},
  booktitle={2016 IEEE International Symposium on Information Theory (ISIT)}, 
  title={Performance trade-offs in multi-processor approximate message passing}, 
  year={2016},
  volume={},
  number={},
  pages={680-684},
  abstract={We consider large-scale linear inverse problems in Bayesian settings. Our general approach follows a recent line of work that applies the approximate message passing (AMP) framework in multi-processor (MP) computational systems by storing and processing a subset of rows of the measurement matrix along with corresponding measurements at each MP node. In each MP-AMP iteration, nodes of the MP system and its fusion center exchange lossily compressed messages pertaining to their estimates of the input. There is a trade-off between the physical costs of the reconstruction process including computation time, communication loads, and the reconstruction quality, and it is impossible to simultaneously minimize all the costs. We pose this minimization as a multi-objective optimization problem (MOP), and study the properties of the best trade-offs (Pareto optimality) in this MOP. We prove that the achievable region of this MOP is convex, and conjecture how the combined cost of computation and communication scales with the desired mean squared error. These properties are verified numerically.},
  keywords={},
  doi={10.1109/ISIT.2016.7541385},
  ISSN={2157-8117},
  month={July},}
@INPROCEEDINGS{7546612,
  author={Sudhakar, Chapram and Adhikari, Pankaj and Ramesh, T.},
  booktitle={2016 Second International Conference on Computational Intelligence & Communication Technology (CICT)}, 
  title={Process Assignment in Multi-core Clusters Using Job Assignment Algorithm}, 
  year={2016},
  volume={},
  number={},
  pages={259-264},
  abstract={Modern high performance cluster systems for parallel processing are employing multi-core processors and high speed interconnection networks. Efficient mapping of the processes of a parallel application onto cores of such a cluster system, plays a vital role in improving the performance of that application. Parallel application can be modelled as a weighted graph showing the communication among the processes of that application. Such a graph can be constructed with the help of profiling tools. Cluster hardware also can be modelled as a graph, by collecting hardware details using HWLOC tool. Maximum weight matching based approach can be used to embed the application graph into cluster hardware graph. The proposed approach is implemented under a cluster system and tested using benchmark MPI parallel application. The performance of the parallel application, which is mapped using the proposed approach is better than, that is mapped using the legacy packed and round robin approaches of MPI library.},
  keywords={},
  doi={10.1109/CICT.2016.58},
  ISSN={},
  month={Feb},}
@ARTICLE{7549005,
  author={Freniere, Cole and Pathak, Ashish and Raessi, Mehdi and Khanna, Gaurav},
  journal={Computing in Science & Engineering}, 
  title={The Feasibility of Amazon's Cloud Computing Platform for Parallel, GPU-Accelerated, Multiphase-Flow Simulations}, 
  year={2016},
  volume={18},
  number={5},
  pages={68-77},
  abstract={The feasibility of running MPI-parallel, GPU-accelerated, multiphase flow simulations on Amazon's Elastic Compute Cloud (EC2) service is evaluated as an alternative computational resource. A cloud cluster on Amazon EC2 is compared to a conventional local high-performance computing cluster in terms of performance and cost. The steps necessary to set up a cloud cluster and acquire the appropriate hardware and software stacks are outlined. The incompressible multiphase flow solver is benchmarked on both cloud and local clusters by performing strong and weak scaling analyses. Amazon's EC2 service is competitive with the local cluster in a certain range of simulations, but there are some performance limitations, particularly in its GPU card performance and cluster network connection, which negatively impact the parallel simulations presented herein. Finally, Amazon's EC2 service is studied from an economic perspective and compared with a conventional local cluster.},
  keywords={},
  doi={10.1109/MCSE.2016.94},
  ISSN={1558-366X},
  month={Sep.},}
@INPROCEEDINGS{7556136,
  author={Khaled, Heba and Faheem, H. M. and Fayez, Mahmoud and Katib, Iyad and Aljohani, Naif R.},
  booktitle={2016 SAI Computing Conference (SAI)}, 
  title={Performance improvement of the parallel smith waterman algorithm implementation using Hybrid MPI-OpenMP model}, 
  year={2016},
  volume={},
  number={},
  pages={1232-1234},
  abstract={This paper applies the hybrid parallel model that combines both shared and distributed memory architectures to improve the performance of the Smith waterman algorithm (SW). The hybrid model uses both MPI and OpenMp as programming techniques for different memory architectures. Our improved implementation executes a parallel version of SW algorithm with a row wise computation of the alignment matrix, which mainly optimizes the memory usage. We applied the parallel SW implementation and tested the system scalability on a homogenous cluster of up to eight nodes each of twenty four cores. We used the SWISS-PROT protein knowledgebase to test our implementation which achieved a tremendous reduction in the running time using the Hybrid MPI-OpenMP over the OpenMP and sequential implementations. The Hybrid MPI-OpenMP achieved a speed up of 14X and 50X over the OpenMP and sequential implementations respectively when tested against all the SWISS-PROT protein knowledgebase entries.},
  keywords={},
  doi={10.1109/SAI.2016.7556136},
  ISSN={},
  month={July},}
@INPROCEEDINGS{7560142,
  author={Peng, Long and Guan, Fei and Perneel, Luc and Fayyad-Kazan, Hasan and Timmerman, Martin},
  booktitle={2016 3rd International Conference on Advances in Computational Tools for Engineering Applications (ACTEA)}, 
  title={EmSBoT: A lightweight modular software framework for networked robotic systems}, 
  year={2016},
  volume={},
  number={},
  pages={216-221},
  abstract={Developing applications for modern complex networked robotic systems is more challenging due to the introduction of possibly sophisticated communication and coordination aspects. In this paper, we propose EmSBoT, a lightweight embedded component-based software framework targeting resource-constrained networked robotic systems. EmSBoT provides a unified Application Program Interface (API) that hides the heterogeneous distributed environment from applications. Its OS abstraction layer endows it with OS independence and portability. A port-based communication mechanism is adopted to exchange message between loosely coupled components, making the system with fault-tolerance capability. By isolating the communication channels as separate agents, the framework provides uniform and transparent message-passing for agents over node boundaries. We describe the architecture, programming model and core features of EmSBoT in this paper, together with the performance evaluation and behavior validation to demonstrate its efficiency and feasibility.},
  keywords={},
  doi={10.1109/ACTEA.2016.7560142},
  ISSN={},
  month={July},}
@INPROCEEDINGS{7561483,
  author={Ampha, Phongsuk and Ruengwaree, Amnoiy},
  booktitle={2016 13th International Conference on Electrical Engineering/Electronics, Computer, Telecommunications and Information Technology (ECTI-CON)}, 
  title={Parallel implementation of 3D-EFIT simulation using MPI library for elastic waves}, 
  year={2016},
  volume={},
  number={},
  pages={1-6},
  abstract={In present paper demonstrated the implementation of the three dimensional time-domain wavefield computation technique for a large and realistic modeling which called Elastodynamic Finite Integration Technique (EFIT). The disadvantage of the time-domain computation are time consumptions and memory requirements. In this work, we apply the portable message passing interface standard (MPI) for the domain decomposition and the communication between processes. For the outer boundary conditions, we have used convolutional perfectly matched layer (C-PML) as open boundaries to terminate the EFIT lattices. For the numerical simulation example, we performed 2 numerical models with size of 1000×1000×600 cells with 16 processors on cluster computer nodes. The MPI based 3D-EFIT code shows good performance on speed up, efficiency, and elapsed time.},
  keywords={},
  doi={10.1109/ECTICon.2016.7561483},
  ISSN={},
  month={June},}
@INPROCEEDINGS{7568353,
  author={Chandru, Vishwanathan and Mueller, Frank},
  booktitle={2016 International Conference on High Performance Computing & Simulation (HPCS)}, 
  title={Hybrid MPI/OpenMP programming on the Tilera manycore architecture}, 
  year={2016},
  volume={},
  number={},
  pages={326-333},
  abstract={This work assesses the viability of different programming models for large-scale manycores using an MPI-like abstraction, the vendor's OpenMP, and a combination (hybrid) of both. Experiments with Tilera's TilePro64 demonstrate that MPI and OpenMP both scale while the hybrid model performs inferior to the others. Further, network-on-chip contention significantly affects performance and its variance, especially if the number of utilized cores is high. These findings provide an early insight on trends for single die/chip solutions with large numbers of cores, which will become mainstream in HPC in the coming years. Prior work lacks such a study on large manycores with an efficient native on-chip message passing on shared memory on the same hardware platform.},
  keywords={},
  doi={10.1109/HPCSim.2016.7568353},
  ISSN={},
  month={July},}
@INPROCEEDINGS{7568441,
  author={Gankevich, Ivan and Tipikin, Yuri and Korkhov, Vladimir and Gaiduchok, Vladimir},
  booktitle={2016 International Conference on High Performance Computing & Simulation (HPCS)}, 
  title={Factory: Non-stop batch jobs without checkpointing}, 
  year={2016},
  volume={},
  number={},
  pages={979-984},
  abstract={Nowadays many job schedulers rely on checkpoint mechanisms to make long-running batch jobs resilient to node failures. At large scale stopping a job and creating its image consumes considerable amount of time. The aim of this study is to propose a method that eliminates this overhead. For this purpose we decompose a problem being solved into computational microkernels which have strict hierarchical dependence on each other. When a kernel abruptly stops its execution due to a node failure, it is responsibility of its principal to restart computation on a healthy node. In the course of experiments we successfully applied this method to make hydrodynamics HPC application run on constantly changing number of nodes. We believe, that this technique can be generalised to other types of scientific applications as well.},
  keywords={},
  doi={10.1109/HPCSim.2016.7568441},
  ISSN={},
  month={July},}
@INPROCEEDINGS{7568430,
  author={Pascolo, E. and Salon, S. and Canu, D. Melaku and Solidoro, C. and Cavazzoni, Carlo and Umgiesser, Georg},
  booktitle={2016 International Conference on High Performance Computing & Simulation (HPCS)}, 
  title={OpenMP tasks: Asynchronous programming made easy}, 
  year={2016},
  volume={},
  number={},
  pages={901-907},
  abstract={The task technology is one of most promising to exploit node parallelism for next generation of HPC architectures, like those under development within the CORAL initiative in the US. In general, single FPU performance is not going to increase any longer in contrast to single node performance. As a consequence, nodes architecture will feature more and more FPUs (proportional to the peak power of the node itself) and determine the need for an efficient technology able to take advantage of intra-node parallelism, reducing synchronization among threads and improving data locality to meet the memory hierarchy. In this paper we present a case study of node parallelization using SHYFEM code, a software for coastal area studies. To the best of our knowledge, this is one of the first work that shows how to fully parallelize a software with OpenMP task technology. We present the comparison between tasks and threads OpenMP programming paradigms, showing the advantages of using the hierarchical and asynchronous programming paradigm made available by OpenMP tasks.},
  keywords={},
  doi={10.1109/HPCSim.2016.7568430},
  ISSN={},
  month={July},}
@INPROCEEDINGS{7568413,
  author={Kutil, Rade},
  booktitle={2016 International Conference on High Performance Computing & Simulation (HPCS)}, 
  title={Towards an object oriented programming framework for parallel matrix algorithms}, 
  year={2016},
  volume={},
  number={},
  pages={776-783},
  abstract={A C++ programming framework (Slabber) is introduced which supports matrix algorithms on distributed and shared memory parallel architectures in an object oriented way. It has the following goals: First, the algorithm implementation should be as convenient as possible by making parallelization details transparent to the algorithm implementation. Second, the choice of architecture (MPI or threads) and the choice of data distribution must not require changing or adapting the algorithm. These goals are achieved by a new approach to decompose matrix operations such as the matrix multiplication into communication free sub-operators, and letting the framework take care of data redistributions between those sub-operators. As a usage example, an iterative algorithm for the non-negative matrix decomposition is implemented using the framework, serving as a usage tutorial and performance test. The results are promising and improve over a straight forward ScaLapack implementation while providing a much cleaner and easier algorithm formulation.},
  keywords={},
  doi={10.1109/HPCSim.2016.7568413},
  ISSN={},
  month={July},}
@INPROCEEDINGS{7568416,
  author={Lagravière, Jérémie and Langguth, Johannes and Sourouri, Mohammed and Ha, Phuong H. and Cai, Xing},
  booktitle={2016 International Conference on High Performance Computing & Simulation (HPCS)}, 
  title={On the performance and energy efficiency of the PGAS programming model on multicore architectures}, 
  year={2016},
  volume={},
  number={},
  pages={800-807},
  abstract={Using large-scale multicore systems to get the maximum performance and energy efficiency with manageable programmability is a major challenge. The partitioned global address space (PGAS) programming model enhances programmability by providing a global address space over large-scale computing systems. However, so far the performance and energy efficiency of the PGAS model on multicore-based parallel architectures have not been investigated thoroughly. In this paper we use a set of selected kernels from the well-known NAS Parallel Benchmarks to evaluate the performance and energy efficiency of the UPC programming language, which is a widely used implementation of the PGAS model. In addition, the MPI and OpenMP versions of the same parallel kernels are used for comparison with their UPC counterparts. The investigated hardware platforms are based on multicore CPUs, both within a single 16-core node and across multiple nodes involving up to 1024 physical cores. On the multi-node platform we used the hardware measurement solution called High definition Energy Efficiency Monitoring tool in order to measure energy. On the single-node system we used the hybrid measurement solution to make an effort into understanding the observed performance differences, we use the Intel Performance Counter Monitor to quantify in detail the communication time, cache hit/miss ratio and memory usage. Our experiments show that UPC is competitive with OpenMP and MPI on single and multiple nodes, with respect to both the performance and energy efficiency.},
  keywords={},
  doi={10.1109/HPCSim.2016.7568416},
  ISSN={},
  month={July},}
@INPROCEEDINGS{7568422,
  author={Khan, Malik M. and Elster, Anne C.},
  booktitle={2016 International Conference on High Performance Computing & Simulation (HPCS)}, 
  title={Characterizing numascale clusters with GPUs: MPI-based and GPU interconnect benchmarks}, 
  year={2016},
  volume={},
  number={},
  pages={840-847},
  abstract={Modern HPC clusters are increasingly heterogeneous both in processor types, topologies of computing, communication and storage resources. In this paper, we describe how to use benchmarking, to characterize the high-speed interconnect, NumaConnect, associated with a shared-memory Numascale cluster system with GPUs, constituting a novel testbed at NTNU. Numascale systems include a unique node controller, NumaConnect, based on the FPGA or ASIC-based NumaChip, depending on system vendor requirements. The system's interconnects uses AMD's HyperTransport protocol, and provide a cache-coherent shared-memory single image operating system. Our system has, in addition, a GPU added to each server blade. Our characterizations efforts target the NumaConnect which includes an RDMA-type Block Transfer Engine (BTE). The BTE is used by Byte Transfer Libraries such as the NumaConnect BTL (NC-BTL) for message passing (MPI) or BLACS. To characterize our Numascale system, we use several benchmark suites including: our own SimpleBench that includes ping-pong, MPI-Reduce and MPI-Barrier tests; two well-known MPI benchmark suites: the NAS Parallel Benchmarks (NPB)-MPI, the OSU microbenchmarks; as well as Nvidia's Bandwidth test for GPUs. Our results show that it is generally very beneficial to use MPI or other libraries that use the NC-BTL library. In fact, on selected OSU and NPB benchmarks, we achieve order-of-magnitude performance improvements on communication and synchronization costs on these benchmarks when using NC-BTL.},
  keywords={},
  doi={10.1109/HPCSim.2016.7568422},
  ISSN={},
  month={July},}
@ARTICLE{7570401,
  author={Makinen, Ville and Sarjakoski, Tapani and Oksanen, Juha and Westerholm, Jan},
  journal={IEEE Geoscience and Remote Sensing Magazine}, 
  title={A Multi-GPU Program for Uncertainty-Aware Drainage Basin Delineation: Scalability benchmarking with country-wide data sets}, 
  year={2016},
  volume={4},
  number={3},
  pages={59-68},
  abstract={Processing high-resolution digital elevation models (DEMs) can be tedious due to the large size of the data. In uncertainty-aware drainage basin delineation, we apply a Monte Carlo (MC) simulation that further increases the processing demand by two to three orders of magnitude. Utilizing graphics processing units (GPUs) can speed up the programs, but their on-chip random access memory (RAM) limits the size of the DEMs that can be processed efficiently on one GPU. Here, we present a parallel uncertainty-aware drainage basin delineation algorithm and a multinode GPU compute unified device architecture (CUDA) implementation along with scalability benchmarking. All of the computations are run on the GPUs, and the parallel processes communicate using a message-passing interface (MPI) via the host central processing units (CPUs). The implementation can utilize any number of nodes, with one or many GPUs per node. The performance and scalability of the program have been tested with a 10-m DEM covering 390,905 km2, i.e., the entire area of Finland. Performing the drainage basin delineation for the DEM with different numbers of GPUs shows a nearly linear strong scalability.},
  keywords={},
  doi={10.1109/MGRS.2016.2561405},
  ISSN={2168-6831},
  month={Sep.},}
@INPROCEEDINGS{7573826,
  author={Denis, Alexandre and Trahay, François},
  booktitle={2016 45th International Conference on Parallel Processing (ICPP)}, 
  title={MPI Overlap: Benchmark and Analysis}, 
  year={2016},
  volume={},
  number={},
  pages={258-267},
  abstract={In HPC applications, one of the major overhead compared to sequential code, is communication cost. Application programmers often amortize this cost by overlapping communications with computation. To do so, they post a non-blocking MPI request, perform computation, and wait for communication completion, assuming MPI communication will progress in background. In this paper, we propose to measure what really happens when trying to overlap non-blocking point-to-point communications with computation. We explain how background progression works, we describe relevant test cases, we identify challenges for a benchmark, then we propose a benchmark suite to measure how much overlap happen in various cases. We exhibit overlap benchmark results on a wide panel of MPI libraries and hardware platforms. Finally, we classify, analyze, and explain the results using low-level traces to reveal the internal behavior of the MPI library.},
  keywords={},
  doi={10.1109/ICPP.2016.37},
  ISSN={2332-5690},
  month={Aug},}
@INPROCEEDINGS{7576485,
  author={Gamell, Marc and Katz, Daniel S. and Teranishi, Keita and Heroux, Michael A. and Van der Wijngaart, Rob F. and Mattson, Timothy G. and Parashar, Manish},
  booktitle={2016 45th International Conference on Parallel Processing Workshops (ICPPW)}, 
  title={Evaluating Online Global Recovery with Fenix Using Application-Aware In-Memory Checkpointing Techniques}, 
  year={2016},
  volume={},
  number={},
  pages={346-355},
  abstract={Exascale systems promise the potential for computation atunprecedented scales and resolutions, but achieving exascale by theend of this decade presents significant challenges. A key challenge isdue to the very large number of cores and components and the resultingmean time between failures (MTBF) in the order of hours orminutes. Since the typical run times of target scientific applicationsare longer than this MTBF, fault tolerance techniques will beessential. An important class of failures that must be addressed isprocess or node failures. While checkpoint/restart (C/R) is currentlythe most widely accepted technique for addressing processor failures, coordinated, stable-storage-based global C/R might be unfeasible atexascale when the time to checkpoint exceeds the expected MTBF. This paper explores transparent recovery via implicitly coordinated, diskless, application-driven checkpointing as a way to tolerateprocess failures in MPI applications at exascale. The discussedapproach leverages User Level Failure Mitigation (ULFM), which isbeing proposed as an MPI extension to allow applications to createpolicies for tolerating process failures. Specifically, this paper demonstrates how different implementations ofapplication-driven in-memory checkpoint storage and recovery comparein terms of performance and scalability. We also experimentally evaluate the effectiveness and scalability ofthe Fenix online global recovery framework on a production system -- the Titan Cray XK7 at ORNL -- and demonstrate the ability of Fenix totolerate dynamically injected failures using the execution of fourbenchmarks and mini-applications with different behaviors.},
  keywords={},
  doi={10.1109/ICPPW.2016.56},
  ISSN={2332-5690},
  month={Aug},}
@INPROCEEDINGS{7576480,
  author={Cramer, Tim and Schwitanski, Simon and Münchhalfen, Felix and Terboven, Christian and Müller, Matthias S.},
  booktitle={2016 45th International Conference on Parallel Processing Workshops (ICPPW)}, 
  title={An OpenMP Epoch Model for Correctness Checking}, 
  year={2016},
  volume={},
  number={},
  pages={299-308},
  abstract={The range of OpenMP features increases continuously to address developments in parallel computer architectures and to improve expressiveness. As a consequence, also the complexity of OpenMP applications increases and thus applications tend to be more error-prone. While correctness checking tools for data race detections exist, tools for the validation of recent OpenMP features are rare. We will present a generic and formal OpenMP epoch model as a basis for correctness checking tools to determine the happens-before relations for different OpenMP constructs in order to detect a wide class of errors. This model is based on information directly delivered by an instrumented OpenMP runtime with low overhead. Thus, scalable tools based on our model can be developed, taking the OpenMP memory model into account.},
  keywords={},
  doi={10.1109/ICPPW.2016.51},
  ISSN={2332-5690},
  month={Aug},}
@INPROCEEDINGS{7576484,
  author={Macarenco, Konstantin and Frye, Kristina and Hamlin, Benjamin and Karavanic, Karen L.},
  booktitle={2016 45th International Conference on Parallel Processing Workshops (ICPPW)}, 
  title={The Effects of System Management Interrupts on Multithreaded, Hyper-threaded, and MPI Applications}, 
  year={2016},
  volume={},
  number={},
  pages={338-345},
  abstract={System Management Interrupts (SMIs) are a potential source of noise for parallel applications at all levels, and their use may be increasing. Building on a previous effort, we have conducted a study of SMI effects on parallel applications. In this paper we present initial results for NAS benchmarks, a multithreaded application, and the UnixBench benchmark. Findings reconfirm that performance degradation scales with the latency of the SMI. Additional results show that performance degradation increases when SMIs are enabled upon multiple communicating nodes, and may be amplified with HTT. This potential source of noise is of interest to tool developers both to detect its presence and also to accommodate the effect on measurement tools.},
  keywords={},
  doi={10.1109/ICPPW.2016.55},
  ISSN={2332-5690},
  month={Aug},}
@ARTICLE{7587490,
  author={Scardapane, Simone and Panella, Massimo and Comminiello, Danilo and Hussain, Amir and Uncini, Aurelio},
  journal={IEEE Computational Intelligence Magazine}, 
  title={Distributed Reservoir Computing with Sparse Readouts [Research Frontier]}, 
  year={2016},
  volume={11},
  number={4},
  pages={59-70},
  abstract={In a network of agents, a widespread problem is the need to estimate a common underlying function starting from locally distributed measurements. Real-world scenarios may not allow the presence of centralized fusion centers, requiring the development of distributed, message-passing implementations of the standard machine learning training algorithms. In this paper, we are concerned with the distributed training of a particular class of recurrent neural networks, namely echo state networks (ESNs). In the centralized case, ESNs have received considerable attention, due to the fact that they can be trained with standard linear regression routines. Based on this observation, in our previous work we have introduced a decentralized algorithm, framed in the distributed optimization field, in order to train an ESN. In this paper, we focus on an additional sparsity property of the output layer of ESNs, allowing for very efficient implementations of the resulting networks. In order to evaluate the proposed algorithm, we test it on two well-known prediction benchmarks, namely the Mackey-Glass chaotic time series and the 10th order nonlinear auto regressive moving average (NARMA) system.},
  keywords={},
  doi={10.1109/MCI.2016.2601759},
  ISSN={1556-6048},
  month={Nov},}
@INPROCEEDINGS{7588871,
  author={Esposito, Christian and Castiglione, Aniello and Palmieri, Francesco and Pop, Florin},
  booktitle={2016 IEEE 14th Intl Conf on Dependable, Autonomic and Secure Computing, 14th Intl Conf on Pervasive Intelligence and Computing, 2nd Intl Conf on Big Data Intelligence and Computing and Cyber Science and Technology Congress(DASC/PiCom/DataCom/CyberSciTech)}, 
  title={Distributed Strategic Learning for Building Network Embedded Coding to Achieve Reliable Event Notification}, 
  year={2016},
  volume={},
  number={},
  pages={360-367},
  abstract={Event-driven communications characterize several key industrial projects for realizing future federated architectures, and publish/subscribe services are considered as key building blocks in such projects. Most of these projects are also affected by strong requirements for the reliability and timely data sharing, since involved in providing decision support for critical activities. In the current literature, reliable multicast is always achieved at the expenses of violations of temporal constraints, since retransmissions are used to recover lost messages. In this paper, we present a solution to apply a proper coding scheme so as to jointly achieve reliability and timeliness when multicasting over the Internet. Such a solution employs game theory so as to select the best locations within the multicast tree where to perform coding operations. Our driving idea is to take a distributed strategic learning in order to determine such locations without a formal characterization of the payoff functions within the non-cooperative game. We prove the quality of this solution by using a series of simulations run on OMNET++.},
  keywords={},
  doi={10.1109/DASC-PICom-DataCom-CyberSciTec.2016.77},
  ISSN={},
  month={Aug},}
@ARTICLE{7600404,
  author={Rangan, Sundeep and Schniter, Philip and Riegler, Erwin and Fletcher, Alyson K. and Cevher, Volkan},
  journal={IEEE Transactions on Information Theory}, 
  title={Fixed Points of Generalized Approximate Message Passing With Arbitrary Matrices}, 
  year={2016},
  volume={62},
  number={12},
  pages={7464-7474},
  abstract={The estimation of a random vector with independent components passed through a linear transform followed by a componentwise (possibly nonlinear) output map arises in a range of applications. Approximate message passing (AMP) methods, based on Gaussian approximations of loopy belief propagation, have recently attracted considerable attention for such problems. For large random transforms, these methods exhibit fast convergence and admit precise analytic characterizations with testable conditions for optimality, even for certain non-convex problem instances. However, the behavior of AMP under general transforms is not fully understood. In this paper, we consider the generalized AMP (GAMP) algorithm and relate the method to more common optimization techniques. This analysis enables a precise characterization of the GAMP algorithm fixed points that applies to arbitrary transforms. In particular, we show that the fixed points of the so-called max-sum GAMP algorithm for MAP estimation are critical points of a constrained maximization of the posterior density. The fixed points of the sum-product GAMP algorithm for estimation of the posterior marginals can be interpreted as critical points of a certain free energy.},
  keywords={},
  doi={10.1109/TIT.2016.2619365},
  ISSN={1557-9654},
  month={Dec},}
@INPROCEEDINGS{7593120,
  author={Kasai, Kenta and Hirotomo, Masanori and Morii, Masakatu},
  booktitle={2016 9th International Symposium on Turbo Codes and Iterative Information Processing (ISTC)}, 
  title={LDPC codes and iterative decoding over symbol-tuple error channels}, 
  year={2016},
  volume={},
  number={},
  pages={276-279},
  abstract={This paper deals with symbol-pair error channels. First, we generalize the channels to symbol-tuple error channels whose read length is D. Then, we derive a message passing algorithm for decoding LDPC codes over the generalized channels. Furthermore, we investigate the Hamming distance distributions of LDPC codes in terms of D symbol-tuple metric.},
  keywords={},
  doi={10.1109/ISTC.2016.7593120},
  ISSN={2165-4719},
  month={Sep.},}
@INPROCEEDINGS{7636802,
  author={Yuan, Weijie and Wu, Nan and Ma, Chengqi and Wang, Hua and Kuang, Jingming},
  booktitle={2016 IEEE/CIC International Conference on Communications in China (ICCC)}, 
  title={Factor graph and damped expectation propagation based passive localization}, 
  year={2016},
  volume={},
  number={},
  pages={1-5},
  abstract={The location awareness of a “passive” target has drawn much attention in recent years. Several papers have investigated passive localization in different scenarios. In this paper, we build a factor graph framework and show that the factor graph can be modified easily for different passive localization problems. Then the beliefs of unknown variables are obtained via message passing algorithms. To reduce the huge complexity of nonparametric message passing, we propose a damped expectation propagation method which restricts the messages on factor graph to Gaussian distributions. Simulations results verify the feasibility of proposed algorithm.},
  keywords={},
  doi={10.1109/ICCChina.2016.7636802},
  ISSN={},
  month={July},}
@INPROCEEDINGS{7723748,
  author={Andersen, Andrew and Kim, Wooyoung and Fukuda, Munehiro},
  booktitle={2016 IEEE International Conferences on Big Data and Cloud Computing (BDCloud), Social Computing and Networking (SocialCom), Sustainable Computing and Communications (SustainCom) (BDCloud-SocialCom-SustainCom)}, 
  title={MASS-Based NemoProfile Construction for an Efficient Network Motif Search}, 
  year={2016},
  volume={},
  number={},
  pages={601-606},
  abstract={A network motif is a frequent and unique subgraph pattern defined in a network and it has been applied in various biological and medical problems. However, finding network motifs is computationally intensive task as it involves heavily resource-demanding tasks. We have suggested a couple of parallelization efforts to alleviate the computational intensity in the past including MASS(Multi-Agent Spatial Simulation)-based and MapReduce-based methods. MASS library allows software agent to crawl a distributed array over a cluster system to find network motifs. Although MASS library can serve as a promising tool to parallelize graph algorithms intuitively with moderate performance penalty, current output formats that fail to provide instances of network motifs, are restricting extensible applications for real-world problems. Therefore, this paper introduces a MASS-based parallelization strategy to construct a new network motif representation called, NemoProfile (Network Motif Profile). A sequential implementation has showed that NemoProfile is a compact representation that can be almost effortlessly generated during sequential version of motif-finding process. In this paper, we also show that its effectiveness in various parallel implementations including MASS-Agent, MASS-Place, and MPI-based methods, by providing various testing results.},
  keywords={},
  doi={10.1109/BDCloud-SocialCom-SustainCom.2016.94},
  ISSN={},
  month={Oct},}
@INPROCEEDINGS{7735371,
  author={Qi Liu and Haifeng Huang and Zhihua He and Zhiwei Huang and Feng He},
  booktitle={2016 Progress in Electromagnetic Research Symposium (PIERS)}, 
  title={Spaceborne AT-InSAR raw signal simulation of dynamic ocean scene}, 
  year={2016},
  volume={},
  number={},
  pages={3557-3563},
  abstract={The interpretation of Synthetic Aperture Radar (SAR) images of dynamic ocean scene is extremely complex, owing to the comprehensive mechanisms of ocean SAR imaging. Along-track Interferometric SAR (AT-InSAR) technique provides us a convenient tool to cope with these problems. But the lack of in-situ data of AT-InSAR is one of the most restricted factors for the further study of this technique. Simulation tools, if appropriately based on sound models, can provide extremely fruitful results to improve the comprehension of the physics and to interpret the SAR images. This paper outlines a spaceborne AT-InSAR raw signal simulator for dynamic ocean scene in time domain. Firstly, we adopt the fractal model to construct the large scale wave of the ocean scene, and then the scene is divided into facets (of approximately half the size of a resolution cell) and each facet is given a dynamic behaviour under certain constraint. Secondly, the RCS corresponding to each frame of the dynamic sea surface is calculated with Kirchhoff Approximation method. At last, the spaceborne AT-InSAR raw signal simulation flow, considering the actual procedure of real satellite moving in the obit, is established. In the dynamic ocean scene raw signal simulation flow, the scene of ocean surface and corresponding RCS was updated at each azimuth slow time. In this procedure, the raw signal can reflect the system error, and it will be quite helpful for the SAR system design. And the simulator is also validated by the accordance of the simulation results and the theoretical results. We adopted the MPI (Message Passing Interface) and parallel computing techniques to implement the fast simulation.},
  keywords={},
  doi={10.1109/PIERS.2016.7735371},
  ISSN={},
  month={Aug},}
@INPROCEEDINGS{7745715,
  author={Bi, Hui and Zhang, Bingchen and Zhu, Xiao Xiang and Hong, Wen and Wu, Yirong},
  booktitle={2016 4th International Workshop on Compressed Sensing Theory and its Applications to Radar, Sonar and Remote Sensing (CoSeRa)}, 
  title={CFAR detection for the complex approximated message passing reconstructed SAR image}, 
  year={2016},
  volume={},
  number={},
  pages={133-137},
  abstract={Complex approximated message passing (CAMP) is an iterative recovery algorithm for L1 regularization reconstruction which can achieve sparse and non-sparse estimations of original signal simultaneously. This paper demonstrates a CAMP-based synthetic aperture radar (SAR) image regularization reconstruction method along with a constant false alarm rate (CFAR) detection via the output non-sparse image of CAMP iterative algorithm. Compared with iterative thresholding algorithm (ITA) and orthogonal matching pursuit (OMP), the conventional L1 regularization reconstruction techniques, it not only can improve SAR image performance, but also its non-sparse estimation retains a similar background statistical distribution as conventional matched filtering (MF)-based techniques, which can be used for CFAR detection efficiently. Simulated and experimental results validate the effectiveness of the designed CFAR detector for the CAMP reconstructed SAR image.},
  keywords={},
  doi={10.1109/CoSeRa.2016.7745715},
  ISSN={},
  month={Sep.},}
@INPROCEEDINGS{7743904,
  author={Corrêa, Abel},
  booktitle={2016 IEEE Congress on Evolutionary Computation (CEC)}, 
  title={Binary max-sum for clustering-based task allocation in the RMASBench platform}, 
  year={2016},
  volume={},
  number={},
  pages={1046-1053},
  abstract={Multiagent systems has been extensively used in the context of urban disaster situations. In such situations, the agents have to perform tasks in order to mitigate the damage in a simulated city, dealing with uncertainty and conflicting information during the disaster management. This paper addresses the group formation in the RMASBench platform centred on clustering-based task allocation. The RMASBench provides an API for multiagent coordination based in the distributed constraint optimization problem. We present an objective function to minimize a distance metric based in the similarities between the features of the agents and the set of perceived tasks. To efficiently optimize our objective function, we use a message passing algorithm in a graphical model representation. Our approach is compared with the state-of-art approaches in the domain of the RMASBench platform and our results show that is possible to reduce the amount of exchanged messages and constraint checks, improving the performance of the agents in some situations.},
  keywords={},
  doi={10.1109/CEC.2016.7743904},
  ISSN={},
  month={July},}
@INPROCEEDINGS{7751684,
  author={Sun, Xuan and Gao, Xin and Li, Chen},
  booktitle={2016 16th International Symposium on Communications and Information Technologies (ISCIT)}, 
  title={A joint abnormal event detection scheme based on compressed sensing for Internet of Things}, 
  year={2016},
  volume={},
  number={},
  pages={509-513},
  abstract={In order to improve the efficiency of abnormal event detection for Internet of Things, this paper proposes an abnormal event detection scheme based on compressed sensing. Due to the low energy consumption target constraints, the cluster-head often has no ability to collect all the data of the terminal nodes. Therefore, a sparse model of terminal nodes is proposed, which is applied to the WSNs scenario. When the number of nodes to be collected is far beyond the ability to collect data, the sparse model is used to propose a distributed abnormal event detection scheme. Each cluster-head uses the compressed sensing method to collect the data. During the procedure, data collection rules are in accordance with the sparse parity check matrix of LDPC code. In the fusion center, the compressed sensing equations of these cluster-heads will be combined into a complete equation. Then the Message Passing algorithm based on Tanner Graph is used to reconstruct the abnormal event sensing results of the sensor nodes.},
  keywords={},
  doi={10.1109/ISCIT.2016.7751684},
  ISSN={},
  month={Sep.},}
@INPROCEEDINGS{7759844,
  author={Song, Yang and O'Kane, Jason M.},
  booktitle={2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, 
  title={Forming repeating patterns of mobile robots: A provably correct decentralized algorithm}, 
  year={2016},
  volume={},
  number={},
  pages={5737-5744},
  abstract={We describe a new decentralized algorithm for multi-robot systems to form arbitrary repeated lattice patterns. Prior work showed how to represent a desired pattern using a directed graph in which each edge is labeled with a rigid body transformation, and proposed an algorithm that accepts this graph as input and computes destinations for each robot using only local information. In this paper, we improve upon that result by describing a new algorithm, substantially different both in message passing procedure and in movement strategy, to resolve several limitations of the existing algorithm. We prove that, by executing this algorithm, the robots will form the desired lattice pattern in a bounded amount of time. We further show that, if the robots' communication graph is connected at the start of the algorithm, it will remain connected throughout the algorithm's execution. Using a simulation, we demonstrate that this algorithm works correctly for systems with dozens of autonomous robots to form various lattice patterns. Moreover, the experiments show a significant improvement in solution quality for our new algorithm compared to the previous approach.},
  keywords={},
  doi={10.1109/IROS.2016.7759844},
  ISSN={2153-0866},
  month={Oct},}
@INPROCEEDINGS{7762450,
  author={Si-Lu Huang and Hang Xu and Pan, Xiao-Min and Sheng, Xin-Qing},
  booktitle={2016 IEEE International Conference on Microwave and Millimeter Wave Technology (ICMMT)}, 
  title={Efficient MPI parallel interpolative decomposition}, 
  year={2016},
  volume={2},
  number={},
  pages={807-809},
  abstract={The interpolative decomposition (ID) has been employed to reduce the computational cost for low-rank approximation of matrices, such as the method of moments (MoM) system with many right-hand-sides. However, the memory requirement may be the bottleneck of the ID when the scale of the problem becomes very large. A parallel scheme of the ID is proposed to alleviate the difficulty. Numerical experiments have been conducted to validate efficiency of the proposed parallel scheme.},
  keywords={},
  doi={10.1109/ICMMT.2016.7762450},
  ISSN={},
  month={June},}
@INPROCEEDINGS{7761131,
  author={O'Donncha, Fearghal and Venugopal, Srikumar and James, Scott C. and Ragnoli, Emanuele},
  booktitle={OCEANS 2016 MTS/IEEE Monterey}, 
  title={Deploying and optimizing performance of a 3D hydrodynamic model on cloud}, 
  year={2016},
  volume={},
  number={},
  pages={1-7},
  abstract={Container-based cloud computing, as standardised and popularised by the open-source docker project has many potential opportunities for scientific application in highperformance computing. It promises highly flexible and available compute capabilities via cloud, without the resource overheads of traditional virtual machines. Further, productivity gains can be made by easy repackaging of images with additional developments, automated deployments, and version-control integrations. Nevertheless, the impact of container overhead and overlay network implementation and performance are areas that requires detailed study to allow for well-defined quality of service for typical HPC applications. This papers presents details on deploying the Environmental Fluid Dynamics Code (EFDC) on a container-based cloud environment. Results are compared to a bare metal deployment. Application-specific benchmarking tests are complemented by detailed network tests that evaluate isolated MPI communication protocols both at intra-node and inter-node level with varying degrees of self-contention. Cloud-based simulations report significant performance loss in mean run-times. A containerised environment increases simulation time by up to 50%. More detailed analysis demonstrates that much of this performance penalty is a result of large variance in MPI communciation times. This manifests as simulation runtime variance on container cloud that hinders both simulation run-time and collection of well-defined quality-of-service metrics.},
  keywords={},
  doi={10.1109/OCEANS.2016.7761131},
  ISSN={},
  month={Sep.},}
@INPROCEEDINGS{7774542,
  author={Ganesan, Dharmalingam and Lindvall, Mikael and Hafsteinsson, Stefan and Cleaveland, Rance and Strege, Susanne L. and Moleski, Walter},
  booktitle={2016 IEEE 27th International Symposium on Software Reliability Engineering (ISSRE)}, 
  title={Experience Report: Model-Based Test Automation of a Concurrent Flight Software Bus}, 
  year={2016},
  volume={},
  number={},
  pages={445-454},
  abstract={Many systems make use of concurrent tasks, however it is often difficult to test concurrent design. Therefore, many test cases are simplified and do not fully test all concurrency aspects of the system. We encountered this problem when analyzing test cases for concurrent flight software at NASA. To address this problem, we developed and evaluated a model based testing (MBT) technique for testing of concurrent systems. Using MBT, the tester creates a model, which is based on the requirements of the system under test (SUT), and lets the computer generate innumerable test cases automatically from the model. We evaluate the effectiveness of the technique using Microsoft's Spec Explorer MBT tool. We apply the technique on NASA's Core Flight Software (cFS) software bus module API, which is based on a concurrent publisher-subscriber architecture style and is a safety-critical system. We describe how we created a test automation architecture for testing concurrent inter-task communication as carried out by the software bus. We also investigate the type of issues the technique for testing of concurrent systems can find as well as what degree of code coverage it can achieve.},
  keywords={},
  doi={10.1109/ISSRE.2016.47},
  ISSN={2332-6549},
  month={Oct},}
@INPROCEEDINGS{7776479,
  author={Guo, Jichi and Yi, Qing and Meng, Jiayuan and Zhang, Junchao and Balaji, Pavan},
  booktitle={2016 IEEE International Conference on Cluster Computing (CLUSTER)}, 
  title={Compiler-Assisted Overlapping of Communication and Computation in MPI Applications}, 
  year={2016},
  volume={},
  number={},
  pages={60-69},
  abstract={The performance of distributed-memory applications, many of which are written in MPI, critically depends on how well the applications can ameliorate the long latency of data movement by overlapping them with ongoing computations, thereby minimizing wait time. This paper presents a study of the various optimization techniques to enable such overlapping in large MPI applications and presents a framework that uses an analytical performance model and an optimizing compiler to systematically enable a majority of such optimizations. In particular, we first generate an analytical performance model of the application execution flow to automatically identify potential communication hot spots that may induce long wait time. Next, for each communication hot spot, we search the execution flow graph to find surrounding loops that include sufficient local computation to overlap with the communication. Then, blocking MPI communications are decoupled into non-blocking operations when necessary, and their surrounding loop is transformed to hide the communication latencies behind local computations. We evaluated our framework using 7 MPI applications from the NAS benchmark suite. Our optimizations can attain 3% to 72% speedup over the original implementations.},
  keywords={},
  doi={10.1109/CLUSTER.2016.62},
  ISSN={2168-9253},
  month={Sep.},}
@INPROCEEDINGS{7776536,
  author={Arya, Kapil and Garg, Rohan and Polyakov, Artem Y. and Cooperman, Gene},
  booktitle={2016 IEEE International Conference on Cluster Computing (CLUSTER)}, 
  title={Design and Implementation for Checkpointing of Distributed Resources Using Process-Level Virtualization}, 
  year={2016},
  volume={},
  number={},
  pages={402-412},
  abstract={System-level checkpoint-restart is a critical technology for long-running jobs in high-performance computing. Yet, only two approaches to checkpointing MPI applications continue to survive in wide use today. One approach is to use the kernel module-based BLCR in combination with an MPI checkpoint-restart service particular to the MPI implementation in use. Unfortunately, this lacks support for some important Linux system services such as SysV IPC (e.g., shared memory objects). A second approach has been to use the original 2009 DMTCP implementation (herein referred to as DMTCP-09) for transparent, system-level checkpointing. Unfortunately, DMTCP-09 lacked support for checkpointing many of the necessary features found by MPI in a modern batch environment. These include: ssh, the InfiniBand network, process migration (restarting an MPI application on different cluster nodes), and modified file path prefixes on restart (typically due to a changing current directory, mount points, library paths, etc.). This work presents DMTCP-PV, a new user-space transparent checkpointing system based on the concept of process virtualization. This approach separately models the state of each local or distributed subsystem while decoupling it from the core checkpointing engine. By separating these concerns, a domain expert can extend checkpointing into a new domain without any knowledge of the core checkpointing engine. This allowed DMTCP-PV to address the deficiencies noted above and many others. It is shown that the runtime overhead of DMTCP-PV is generally less than 1%, and the checkpointing time is dominated by the time to write an image file to stable storage.},
  keywords={},
  doi={10.1109/CLUSTER.2016.55},
  ISSN={2168-9253},
  month={Sep.},}
@INPROCEEDINGS{7776535,
  author={Yang, Jin-Min},
  booktitle={2016 IEEE International Conference on Cluster Computing (CLUSTER)}, 
  title={A Lightweight Causal Message Logging Protocol to Lower Fault Tolerance Overhead}, 
  year={2016},
  volume={},
  number={},
  pages={392-401},
  abstract={Rollback recovery is a trustworthy and key approach to fault tolerance in high performance computing and to parallel program debugging. In various rollback recovery protocols, causal message logging shows some desirable characteristics, but its high piggybacking overhead obstructs its applications, especially in large-scale distributed systems. Its high overhead arises from its conservation in the assumption on program execution model. This paper identifies the influence of non-deterministic message delivery on the correct outcome of a process, and then gives a scheme to relax the constraints from the piecewise deterministic execution model. Subsequently, a lightweight implementation of causal message logging is proposed to decrease the overhead of piggybacking and rolling forward. The experimental results of 3 NAS NPB2.3 benchmarks show that the proposed scheme achieves a significant improvement in the overhead reduction.},
  keywords={},
  doi={10.1109/CLUSTER.2016.64},
  ISSN={2168-9253},
  month={Sep.},}
@INPROCEEDINGS{7783819,
  author={Chang, Siyuan and Liu, Jun and Liu, Fang and Yang, Jie},
  booktitle={2016 8th International Conference on Intelligent Human-Machine Systems and Cybernetics (IHMSC)}, 
  title={A Parallel Space Saving Algorithm and Performance Test}, 
  year={2016},
  volume={02},
  number={},
  pages={198-202},
  abstract={Finding k-majority elements in a data set is becoming increasingly critical in a lot of applications. These algorithms are generally classified as the counter-based and the sketch-based, and both types try to deliver high throughput with limited resources. Space Saving, which exhibits desirable efficiency and accuracy among counter-based algorithms, could meet our requirements in most cases. In this paper, we present an message-passing algorithm to solve the k-majority problem, which named parallel space saving algorithm. We not only present the basic theories of this algorithm and explain how the algorithm is parallelized, but also show the experimental results of it. Some suggestions are given to improve the performance and reduce the running time of this algorithm in a practical situation.},
  keywords={},
  doi={10.1109/IHMSC.2016.112},
  ISSN={},
  month={Aug},}
@INPROCEEDINGS{7789439,
  author={Nguyen, Cao Ngoc and Kim, Jik-Soo and Hwang, Soonwook},
  booktitle={2016 IEEE 1st International Workshops on Foundations and Applications of Self* Systems (FAS*W)}, 
  title={KOHA: Building a Kafka-Based Distributed Queue System on the Fly in a Hadoop Cluster}, 
  year={2016},
  volume={},
  number={},
  pages={48-53},
  abstract={Message queues take a crucial role in a distributed and scalable system by interconnecting loosely-coupled and autonomic computational units. Among the state of art distributed message queue systems, Apache Kafka has been able to achieve high throughput, low latency, and good load-balancing. Recently, we have worked on developing a new data processing framework that can efficiently handle a very large number of tasks on top of a Hadoop cluster by effectively leveraging Kafka as a job queue, which motivated us to explore more opportunities of utilizing Kafka in the Hadoop platform. The Apache Hadoop has already become the de facto big data processing infrastructure and with the help of YARN, it is now evolving into multi-use data platform that can harness various types of data processing workflows. Therefore, effectively utilizing Kafka for various purposes including message distribution, task processing, metadata management in a Hadoop cluster can potentially contribute to the expansion of current Hadoop ecosystem. In this paper, we design and implement a framework called KOHA (Kafka On HAdoop) that provides users with a simple, convenient and powerful way to develop a large-scale distributed Kafka-based application running on top of a Hadoop cluster. The framework automatically builds and starts Kafka brokers on the fly and allocates resources to launch producers and consumers. Users can use the framework to adopt Apache Kafka without any understanding of YARN programming model and efforts to deploy a Kafka cluster. In addition, we also present a use case of the framework to evaluate Kafka's performance with various test cases and working scenarios. The experimental results allow Kafka's potential users to perceive the influences of different settings on the queuing performance.},
  keywords={},
  doi={10.1109/FAS-W.2016.23},
  ISSN={},
  month={Sep.},}
@INPROCEEDINGS{7789782,
  author={Nakayama, Hiroki and Nakamura, Shigenari and Enokido, Tomoya and Takizawa, Makoto},
  booktitle={2016 19th International Conference on Network-Based Information Systems (NBiS)}, 
  title={Topic-Based Causally Ordered Delivery of Event Messages in a Peer-to-Peer (P2P) Model of Publish/Subscribe Systems}, 
  year={2016},
  volume={},
  number={},
  pages={348-354},
  abstract={An event-driven publish/subscribe (PS) model of a distributed system is used in various applications. In this paper, we discuss a peer-to-peer (P2P) model of a topic-based PS system (P2PPS model) where each peer process (peer) can both subscribe interesting topics and publish event messages with topics. In our previous studies, we propose the TBC (topicbased causally delivery) protocol an homogeneous networks where maximum delay time between every pair of peers is same. Here, a pair of event messages are checked if the event messages are related in the topic vector and are causally delivered by taking advantage of physical time and linear time. In this paper, we consider a system where peers are interconnected in heterogeneous networks. Here, maximum delay time between every pair of peers is not same. We propose a heterogeneous TBC (HTBC) protocol where event messages are TBC-causally delivered to target peers in heterogeneous network. We evaluate the HTBC protocol and show the number of pair of event messages unnecessarily ordered is reduced in the HTBC protocol.},
  keywords={},
  doi={10.1109/NBiS.2016.89},
  ISSN={2157-0426},
  month={Sep.},}
@INPROCEEDINGS{7794798,
  author={Gu, Qun and Teng, Yinglei and Song, Mei},
  booktitle={2016 IEEE 27th Annual International Symposium on Personal, Indoor, and Mobile Radio Communications (PIMRC)}, 
  title={Improved message passing algorithms for resource allocation in two-tier femtocell networks}, 
  year={2016},
  volume={},
  number={},
  pages={1-6},
  abstract={Deploying femtocells in macrocell network is an economical and reliable way to increase network coverage and efficiency. However, such deployment poses great challenges for the resource allocation of two tier femtocell networks due to the existence of inter-tier and intra-tier interference. We propose a uplink transmission resource allocation scheme with the goal of maximizing the total power efficiency. Nevertheless, the resource allocation optimization problem is NP-hard and non-convex, thereby, we adopt message passing (MP) method which approaches the optimality by iteratively passing the messages between each user equipments (UEs) and access points (APs). To reduce excessive number of iterations, we present two improved MP algorithms, i.e. best selection message passing (BSMP) algorithm as well as UE priority message passing (UPMP) algorithm. BSMP algorithm is optimal allocation algorithm which could avoid excessive number of iterations. Based on BSMP algorithm, UPMP algorithm take the UEs' priorities into consideration to ensure the fairness of resource allocation. Compared to existing schemes, simulation results show that improved MP algorithms have excellent convergences. Meanwhile, the vast improvements on power efficiency as well as weighted power efficiency have been demonstrated.},
  keywords={},
  doi={10.1109/PIMRC.2016.7794798},
  ISSN={2166-9589},
  month={Sep.},}
@INPROCEEDINGS{7794350,
  author={Amozarrain, Ugaitz and Larrea, Mikel},
  booktitle={2016 IEEE 35th Symposium on Reliable Distributed Systems (SRDS)}, 
  title={Reliable Event Dissemination in Dynamic Distributed Systems}, 
  year={2016},
  volume={},
  number={},
  pages={217-218},
  abstract={The proposed research addresses the problem of communicating events in a reliable and efficient manner between the producing and consuming devices. To do so, we will focus on the publish/subscribe paradigm. Commonly, this model has assumed a static topology of brokers that optimize event dissemination. The next step is to relax the conditions of the broker network in order to include fault tolerance and mobility in its elements, developing and validating new algorithms for highly dynamic publish/subscribe systems.},
  keywords={},
  doi={10.1109/SRDS.2016.038},
  ISSN={1060-9857},
  month={Sep.},}
@INPROCEEDINGS{7801433,
  author={Abdel-Gawad, Ahmed H. and Thottethodi, Mithuna},
  booktitle={2016 IEEE 24th Annual Symposium on High-Performance Interconnects (HOTI)}, 
  title={Scalable, Global, Optimal-bandwidth, Application-Specific Routing}, 
  year={2016},
  volume={},
  number={},
  pages={9-18},
  abstract={High performance computing platforms can benefit from additional bandwidth from the interconnection network because there are many applications with significant communication demands. Further, many HPC applications expressed as MPI programs have stable communication patterns across runs. Ideally, one would like to exploit the stable communication patterns by using global routing of communication paths to minimize network contention. Unfortunately, existing optimal-bandwidth, global routing techniques use mixed integer linear programs which fundamentally do not scale to the sizes that HPC workloads and platforms demand. Consequently, HPC platforms use simple distributed routing techniques, possibly with local adaptive routing, at best. Our design - Scalable Global Routing (SGR) - addresses this gap. Simulations reveal that in a 4096-node, 4D-torus network, SGR achieves global route computation with a speedup of nearly two orders of magnitude over prior global routing techniques. SGR outperforms simpler (non-global) routing techniques such as minimal adaptive routing by a 3.1X margin and non-minimal adaptive routing by a 37% margin.},
  keywords={},
  doi={10.1109/HOTI.2016.016},
  ISSN={2332-5569},
  month={Aug},}
@INPROCEEDINGS{7803697,
  author={da Silva, Hércules Cardoso and Pisani, Flávia and Borin, Edson},
  booktitle={2016 International Symposium on Computer Architecture and High Performance Computing Workshops (SBAC-PADW)}, 
  title={A Comparative Study of SYCL, OpenCL, and OpenMP}, 
  year={2016},
  volume={},
  number={},
  pages={61-66},
  abstract={Recent trends indicate that future computing systems will be composed by a group of heterogeneous computing devices, including CPUs, GPUs, and other hardware accelerators. These devices provide increased processing performance, however, creating efficient code for them may require that programmers manage memory assignments and use specialized APIs, compilers, or runtime systems, thus making their programs dependent on specific tools. In this scenario, SYCL is an emerging C++ programming model for OpenCL that allows developers to write code for heterogeneous computing devices that are compatible with standard C++ compilation frameworks. In this paper, we analyze the performance and programming characteristics of SYCL, OpenMP, and OpenCL using both a benchmark and a real-world application. Our performance results indicate that programs that rely on available SYCL runtimes are not on par with the ones based on OpenMP and OpenCL yet. Nonetheless, the gap is getting smaller if we consider the results reported by previous studies. In terms of programmability, SYCL presents itself as a competitive alternative to OpenCL, requiring fewer lines of code to implement kernels and also fewer calls to essential API functions and methods.},
  keywords={},
  doi={10.1109/SBAC-PADW.2016.19},
  ISSN={},
  month={Oct},}
@INPROCEEDINGS{7816128,
  author={Hosseinidoust, Zahra and Giannacopoulos, Dennis and Gross, Warren J.},
  booktitle={2016 IEEE Conference on Electromagnetic Field Computation (CEFC)}, 
  title={GPU optimization and implementation of Gaussian belief propagation algorithm}, 
  year={2016},
  volume={},
  number={},
  pages={1-5},
  abstract={We report the utilization of the parallel resources of the graphic processing unit (GPU) to solve sparse systems by optimizing and implementation of a variant of Gaussian belief propagation algorithm for sparse matrices on a Tesla 2070M GPU with the Fermi architecture. The implementation was verified with finite element method data and achieved up to 4× improvement in execution time compared to serial CPU implementation.},
  keywords={},
  doi={10.1109/CEFC.2016.7816128},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{7811473,
  author={Huda, Sheila Nurul},
  booktitle={2016 International Conference on Instrumentation, Control and Automation (ICA)}, 
  title={Semantic on PROMELA dynamic process creation in concurrent systems}, 
  year={2016},
  volume={},
  number={},
  pages={44-47},
  abstract={PROMELA is a high level modeling language for model checking purpose. PROMELA model can be checked using SPIN (Simple PROMELA Interpreter) model checker to ensure formally some specifications hold in the model. However, PROMELA does not have formal and clear semantics. It is interpreted under SPIN implementation only and thus is bounded into SPIN. With high-level language it has, PROMELA has gain fame in model checker world due to its easiness to capture process model using high level language. Describing PROMELA formal semantic is a good way to broaden PROMELA usage. One of PROMELA feature is the ability to model concurrent processes, in which the concurrent process may not start from the same time point. This feature, called dynamic process creation, is essential to be noticed, to ensure that state-transition of PROMELA model is correct. Dynamic process creation in PROMELA should be defined formally, we use Labeled Transition Systems (LTSs) to describe formal semantic of PROMELA dynamic process creation.},
  keywords={},
  doi={10.1109/ICA.2016.7811473},
  ISSN={},
  month={Aug},}
@INPROCEEDINGS{7814913,
  author={Muhyiddeen, Abdulfattah and Nor, Rizal Mohd and Rahman, M.M. Hafizur},
  booktitle={2016 6th International Conference on Information and Communication Technology for The Muslim World (ICT4M)}, 
  title={Analyzing Communication Overhead in Linearizing Peer to Peer System}, 
  year={2016},
  volume={},
  number={},
  pages={260-263},
  abstract={In a peer to peer self-stabilizing message passing system, every single node in the network operates independently with independent resources. In order to self-stabilize to a correct state, messages are passed as a distributed system collectively, messages are passed through out the network among each of the member of the network to inform other nodes about their own states which is later to be used to construct a complex distributed routing tables. Each of the members of the network should be able to communicate intelligently so that the topology can be constructed just by passing messages and take some actions upon receiving messages from other nodes. In this paper, we present the analysis of overhead of number of messages passed during the construction process of a self-stabilizing linearizing algorithm. This overhead really give some impact on the network, especially in the simulation environment where resources are physically shared by logical nodes.},
  keywords={},
  doi={10.1109/ICT4M.2016.060},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{7816900,
  author={Tran, Van Long and Renault, Eric and Ha, Viet Hai},
  booktitle={2016 Intl IEEE Conferences on Ubiquitous Intelligence & Computing, Advanced and Trusted Computing, Scalable Computing and Communications, Cloud and Big Data Computing, Internet of People, and Smart World Congress (UIC/ATC/ScalCom/CBDCom/IoP/SmartWorld)}, 
  title={Analysis and Evaluation of the Performance of CAPE}, 
  year={2016},
  volume={},
  number={},
  pages={620-627},
  abstract={MPI (Message Passing Interface), OpenMP are two tools broadly used to develop parallel programs. On the one hand, MPI has the advantage of high performance while being difficult to use. On the other hand, OpenMP is very easy to use but is restricted to shared-memory architectures. CAPE is an approach based on checkpoints to allow the execution of OpenMP programs on distributed-memory architectures. This paper aims at presenting both an in-depth analysis, an evaluation of the performance of CAPE by comparing the execution model of both CAPE, MPI. Some suggestions are also provided to improve the use of CAPE.},
  keywords={},
  doi={10.1109/UIC-ATC-ScalCom-CBDCom-IoP-SmartWorld.2016.0104},
  ISSN={},
  month={July},}
@INPROCEEDINGS{7816875,
  author={Biswas, Amit and Dutta, Animesh},
  booktitle={2016 Intl IEEE Conferences on Ubiquitous Intelligence & Computing, Advanced and Trusted Computing, Scalable Computing and Communications, Cloud and Big Data Computing, Internet of People, and Smart World Congress (UIC/ATC/ScalCom/CBDCom/IoP/SmartWorld)}, 
  title={A Timer Based Leader Election Algorithm}, 
  year={2016},
  volume={},
  number={},
  pages={432-439},
  abstract={This paper addresses a problem of Leader Election in a distributed system. Basically Leader Election Algorithms choose a process or node among the number of processes or nodes as a Coordinator to manage the use of shared resources in an optimal manner, construct the fault-tolerant distributed systems. A good leader election algorithm should take less time, less message passing to elect a leader or Coordinator. In this paper, we introduce a timer based new leader election algorithm which is somehow or order beneficial than the existing leader election algorithms. The higher efficiency, better performance of our proposed algorithm with respect to the existing algorithms is validated through the complexity Analysis of the algorithms.},
  keywords={},
  doi={10.1109/UIC-ATC-ScalCom-CBDCom-IoP-SmartWorld.2016.0079},
  ISSN={},
  month={July},}
@INPROCEEDINGS{7818769,
  author={Amaricai, Alexandru and Boncalo, Oana},
  booktitle={2016 24th Telecommunications Forum (TELFOR)}, 
  title={Cost effective FPGA implementation for hard decision LDPC decoders}, 
  year={2016},
  volume={},
  number={},
  pages={1-4},
  abstract={This paper proposes a QC-LDPC partial parallel architecture that implements a hard decision message passing algorithm based on Gallager-B decoding. The proposed architecture uses an optimized variable node unit, with adaptive threshold, suitable for irregular LDPC codes. We present implementation results for WiMAX rate 1/2 code for FPGA technology. These indicate a cost reduction of 2.5x in logic, and 25% in memory with respect to Min-Sum algorithm with 2 bits.},
  keywords={},
  doi={10.1109/TELFOR.2016.7818769},
  ISSN={},
  month={Nov},}

@INPROCEEDINGS{7818664,
  author={Hayashi, Yasuharu and Takizawa, Hiroyuki and Kobayashi, Hiroaki},
  booktitle={2016 Fourth International Symposium on Computing and Networking (CANDAR)}, 
  title={A User-Defined Code Transformation Approach to Overlapping MPI Communication with Computation}, 
  year={2016},
  volume={},
  number={},
  pages={508-514},
  abstract={The Xevolver framework has been developed to enable application programmers to define their own code translation rules outside of their codes so that they can express platform-specific optimizations separately from algorithm-level application codes. Due to the diversity of HPC node architectures, the Xevolver framework has so far mainly been used to separate node-level code optimizations from application codes. However, user-defined code transformation rules are also potentially useful for optimizing MPI applications without messing up their codes. Therefore, this paper shows a case study of using the Xevolver framework to optimize MPI applications through customizable code transformations without loss of high performance portability, and discusses the benefits of the framework.},
  keywords={},
  doi={10.1109/CANDAR.2016.0094},
  ISSN={2379-1896},
  month={Nov},}
@INPROCEEDINGS{7823817,
  author={Xiao, Wenhua and Bao, Weidong and Zhu, Xiaomin and Zhou, Wen and Luy, Peizhong},
  booktitle={2016 IEEE 22nd International Conference on Parallel and Distributed Systems (ICPADS)}, 
  title={Improving the Performance of Data Sharing in Dynamic Peer-to-Peer Mobile Cloud}, 
  year={2016},
  volume={},
  number={},
  pages={743-752},
  abstract={Mobile cloud computing has become an emerging computing paradigm to extend the capability of the mobile devices and it has gained increasing popularity in recent years. Existing studies mainly focus on how to leverage the computing capability of the individual device by employing the capability from remote cloud datacenters or local mobile cloud formed by nearby devices. Different from these studies, we investigate how to improve the performance of data sharing in the peer-to-peer mobile cloud, with the limited bandwidth and the presence of dynamic and unpredictable wireless channel state. Specifically, we first formulate the data transmission among devices as a utility maximization problem with the consideration of limited bandwidth, incentive participation and the QoE (Quality of Experience) heterogeneity, based on incorporating publish/subscribe component into the base station. Then, a dynamic online algorithm, which does not need the future context (e.g., channel state) of the mobile cloud, is developed to simultaneously make the decision of data transmission and communication interface selection. Rigorously theoretical analysis shows the optimality and the effectiveness of the proposed algorithm. Extensive experiments are conducted to verify the analysis results and the superiority of the proposed algorithm over existing strategies.},
  keywords={},
  doi={10.1109/ICPADS.2016.0102},
  ISSN={1521-9097},
  month={Dec},}
@INPROCEEDINGS{7823750,
  author={Yang, Jingli and Fan, Jing and Jiang, Shouda},
  booktitle={2016 IEEE 22nd International Conference on Parallel and Distributed Systems (ICPADS)}, 
  title={DOCO: An Efficient Event Matching Algorithm in Content-Based Publish/Subscribe Systems}, 
  year={2016},
  volume={},
  number={},
  pages={200-207},
  abstract={The content-based publish/subscribe systems are attracting more and more attention in Internet applications due to their intrinsic time, space, and synchronization decoupling properties. With the increase in system scale, the efficiency of event matching becomes more critical for system performance. However, most existing methods suffer significant performance degradation when the system has large volumes of subscriptions. This paper presents DOCO (DOuble COmbination event matching algorithm) to improve the efficiency of event matching in content-based publish/subscribe systems. Via assembling the attributes in the attribute space by pairs, a novel index structure is built up for classification of the subscriptions. On the arrival of an event, the event matching process is only carried out on some related units of the index structure, thus, the number of subscriptions that involved in the event matching process is reduced. A series of experiments are designed to verify the performance of the proposed algorithm, and a comparison with other event matching algorithms is also carried out. The experimental results show that DOCO can improve the efficiency of event matching in content-based publish/subscribe systems.},
  keywords={},
  doi={10.1109/ICPADS.2016.0035},
  ISSN={1521-9097},
  month={Dec},}
@INPROCEEDINGS{7823840,
  author={Cao, Jiajun and Arya, Kapil and Garg, Rohan and Matott, Shawn and Panda, Dhabaleswar K. and Subramoni, Hari and Vienne, Jérôme and Cooperman, Gene},
  booktitle={2016 IEEE 22nd International Conference on Parallel and Distributed Systems (ICPADS)}, 
  title={System-Level Scalable Checkpoint-Restart for Petascale Computing}, 
  year={2016},
  volume={},
  number={},
  pages={932-941},
  abstract={Fault tolerance for the upcoming exascale generation has long been an area of active research. One of the components of a fault tolerance strategy is checkpointing. Petascale-level checkpointing is demonstrated through a new mechanism for virtualization of the InfiniBand UD (unreliable datagram) mode, and for updating the remote address on each UD-based send, due to lack of a fixed peer. Note that InfiniBand UD is required to support modern MPI implementations. An extrapolation from the current results to future SSD-based storage systems provides evidence that the current approach will remain practical in the exascale generation. This transparent checkpointing approach is evaluated using a framework of the DMTCP checkpointing package. Results are shown for HPCG (linear algebra), NAMD (molecular dynamics), and the NAS NPB benchmarks. In tests up to 32,752 MPI processes on 32,752 CPU cores, checkpointing of a computation with a 38 TB memory footprint in 11 minutes is demonstrated. Runtime overhead is reduced to less than 1%. The approach is also evaluated across three widely used MPI implementations.},
  keywords={},
  doi={10.1109/ICPADS.2016.0125},
  ISSN={1521-9097},
  month={Dec},}
@INPROCEEDINGS{7823829,
  author={Langguth, Johannes and Lan, Qiang and Gaur, Namit and Cai, Xing and Wen, Mei and Zhang, Chun-Yuan},
  booktitle={2016 IEEE 22nd International Conference on Parallel and Distributed Systems (ICPADS)}, 
  title={Enabling Tissue-Scale Cardiac Simulations Using Heterogeneous Computing on Tianhe-2}, 
  year={2016},
  volume={},
  number={},
  pages={843-852},
  abstract={We develop a simulator for 3D tissue of the human cardiac ventricle with a physiologically realistic cell model and deploy it on the supercomputer Tianhe-2. In order to attain the full performance of the heterogeneous CPU-Xeon Phi design, we use carefully optimized codes for both devices and combine them to obtain suitable load balancing. Using a large number of nodes, we are able to perform tissue-scale simulations of the electrical activity and calcium handling in millions of cells, at a level of detail that tracks the states of trillions of ryanodine receptors. We can thus simulate arrythmogenic spiral waves and other complex arrhythmogenic patterns which arise from calcium handling deficiencies in human cardiac ventricle tissue. Due to extensive code tuning and parallelization via OpenMP, MPI, and SCIF/COI, large scale simulations of 10 heartbeats can be performed in a matter of hours. Test results indicate excellent scalability, thus paving the way for detailed whole-heart simulations in future generations of leadership class supercomputers.},
  keywords={},
  doi={10.1109/ICPADS.2016.0114},
  ISSN={1521-9097},
  month={Dec},}
@INPROCEEDINGS{7823749,
  author={Li, Lun and Hao, Zhiyu and Zhang, Yongzheng and Peng, Yaqiong and Deng, Xin and Sun, Zhenxi},
  booktitle={2016 IEEE 22nd International Conference on Parallel and Distributed Systems (ICPADS)}, 
  title={DMNS: A Framework to Dynamically Monitor Simulated Network}, 
  year={2016},
  volume={},
  number={},
  pages={192-199},
  abstract={With rapid development of network simulation technology, monitoring system has become an essential tool for the researching and testing of network space activities. However, the current monitoring technologies of simulated networks cannot satisfy the requirements in terms of flexibility and efficiency. This paper proposes a framework called DMNS to dynamically monitor simulated network. With DMNS, users are able to customize the monitored objects and monitoring actions to meet the requirements of flexibility. In addition, the administrators could dynamically change the monitoring rules for saving resources based on callback mechanism. DMNS also considers the requirements of large-scale distributed simulation. Specifically, it leverages message oriented middleware to achieve efficient monitoring message information transmission to guarantee the robustness of the monitoring system. We implement a prototype of DMNS in a network range system and demonstrate the effectiveness by a case study.},
  keywords={},
  doi={10.1109/ICPADS.2016.0034},
  ISSN={1521-9097},
  month={Dec},}
@INPROCEEDINGS{7828506,
  author={Hashmi, Jahanzeb Maqbool and Hamidouche, Khaled and Panda, Dhabaleswar K.},
  booktitle={2016 IEEE 18th International Conference on High Performance Computing and Communications; IEEE 14th International Conference on Smart City; IEEE 2nd International Conference on Data Science and Systems (HPCC/SmartCity/DSS)}, 
  title={Enabling Performance Efficient Runtime Support for Hybrid MPI+UPC++ Programming Models}, 
  year={2016},
  volume={},
  number={},
  pages={1180-1187},
  abstract={UPC++ is an emerging Partition Global Address Space (PGAS) library. The performance of UPC++ applications is highly dependent on the efficiency of the communication runtime. Current UPC++ runtime relies on MPI and native IB verbs based conduit implementations of GASNet communication middleware. Hybrid MPI+UPC++ programming model is seen as an attractive way to program next generation systems. However, current approach towards a hybrid model requires the use of the GASNet-MPI conduit which implements one model on top of the other, thereby significantly limiting the performance. In this paper, we propose a unified runtime based approach that natively unifies both MPI and UPC++ models to achieve better performance and deadlock free execution. We evaluated our design on a pure UPC++ based microbenchmark which we implemented on top of OSU Microbenchmark (OMB) suite. To evaluate application level performance, we implemented a Gauss-seidel based 2D-heat diffusion kernel in UPC++ and redesigned LULESH (3-D shock hydrodynamics simulation) using MPI-3 Non-blocking Collectives (NBC) for hybrid MPI+UPC++ models. At microbenchmark level, the proposed approach achieves up to 15X and 35X speedup over GASNet-MPI and GASNet-IBV conduits, respectively for dense collective operations on 128 cores. The application level evaluation of 2D-heat shows that our proposed approach achieves up to 30% improvement on 512 cores. Finally, we demonstrate the design benefits of NBC redesigned hybrid implementation of LULESH over pure MPI and pure UPC++ and show that our unified runtime based approach can achieve up to 6% improvement in total execution time on 216 (63) cores.},
  keywords={},
  doi={10.1109/HPCC-SmartCity-DSS.2016.0165},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{7828496,
  author={Farmer, Shane and Skjellum, Anthony and Grant, Ryan E. and Brightwell, Ron},
  booktitle={2016 IEEE 18th International Conference on High Performance Computing and Communications; IEEE 14th International Conference on Smart City; IEEE 2nd International Conference on Data Science and Systems (HPCC/SmartCity/DSS)}, 
  title={MPI Performance Characterization on InfiniBand with Fine-Grain Multithreaded Communication}, 
  year={2016},
  volume={},
  number={},
  pages={1102-1106},
  abstract={This paper describes work with end goal of quantifying the impact of threading on MPI performance models in order to enable justifications of model construction methods. To do so, it evaluates benchmarks on a specific, representative networked platform, and makes these contributions: 1) it evaluates the performance of point-to-point transmission between two multithreaded Message Passing Interface (MPI) processes over InfiniBand, 2) it elucidates strengths and weaknesses of Intel MPI under multiple multithreaded modes, 3) it provides indications as to where predictive modeling of such multithreaded performance would prove fruitful. Two established benchmarks are used to obtain performance information and they are compared and contrasted as needed to explain the results described here. In one case, we enhanced a benchmark to enable threading for study, justification for these changes are provided.},
  keywords={},
  doi={10.1109/HPCC-SmartCity-DSS.2016.0155},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{7838782,
  author={Dekkiche, Djamila and Vincke, Bastien and Merigot, Alain},
  booktitle={2016 14th International Conference on Control, Automation, Robotics and Vision (ICARCV)}, 
  title={Investigation and performance analysis of OpenVX optimizations on computer vision applications}, 
  year={2016},
  volume={},
  number={},
  pages={1-6},
  abstract={The development of Advanced Driver Assistance Systems (ADAS), such as pedestrian detection, requires real-time update rates at high image resolution. Hopefully, heterogeneous architectures with high computing performance have been developed for this purpose. To benefit from this hardware performance, different programming languages and acceleration frameworks have been developed. OpenVX framework provides a graph-based execution model to program image processing algorithms on heterogeneous platforms. In this work, we investigate OpenVX optimizations for computer vision applications. We examine how this framework responds to different data access patterns. We test three important optimizations of OpenVX: kernels merge, data tiling and parallelization via OpenMP. The contribution and the impact of each optimization on different data access pattern are explained.},
  keywords={},
  doi={10.1109/ICARCV.2016.7838782},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{7836600,
  author={Dávila, Diego and Alexandrov, Vassil and Esquivel-Flores, Oscar A.},
  booktitle={2016 7th Workshop on Latest Advances in Scalable Algorithms for Large-Scale Systems (ScalA)}, 
  title={On Monte Carlo Hybrid Methods for Linear Algebra}, 
  year={2016},
  volume={},
  number={},
  pages={81-88},
  abstract={This paper presents an enhanced hybrid (e.g. stochastic/deterministic) method for Linear Algebra based on bulding an efficient stochastic s and then solving the corresponding System of Linear Algebraic Equations (SLAE) by applying an iterative method. This is a Monte Carlo preconditioner based on Markov Chain Monte Carlo (MCMC) methods to compute a rough approximate matrix inverse first. The above Monte Carlo preconditioner is further used to solve systems of linear algebraic equations thus delivering hybrid stochastic/deterministic algorithms. The advantage of the proposed approach is that the sparse Monte Carlo matrix inversion has a computational complexity linear of the size of the matrix, it is inherently parallel and thus can be obtained very efficiently for large matrices and can be used also as an efficient preconditioner while solving systems of linear algebraic equations. Several improvements, as well as the mixed MPI/OpenMP implementation, are carried out that enhance the scalability of the method and the efficient use of computational resources. A set of different test matrices from several matrix market collections were used to show the consistency of these improvements.},
  keywords={},
  doi={10.1109/ScalA.2016.015},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{7836843,
  author={Smith, Ross},
  booktitle={2016 6th Workshop on Python for High-Performance and Scientific Computing (PyHPC)}, 
  title={Performance of MPI Codes Written in Python with NumPy and mpi4py}, 
  year={2016},
  volume={},
  number={},
  pages={45-51},
  abstract={Python is an interpreted language that has become more commonly used within HPC applications. Python benefits from the ability to write extension modules in C, which can further use optimized libraries that have been written in other compiled languages. For HPC users, two of the most common extensions are NumPy and mpi4py. It is possible to write a full computational kernel in a compiled language and then build that kernel into an extension module. However, this process requires not only the kernel be written in the compiled language, but also the interface between the kernel and Python be implemented. If possible, it would be preferable to achieve similar performance by writing the code directly in Python using readily available performant modules. In this work the performance differences between compiled codes and codes written using Python3 and commonly available modules, most notably NumPy and mpi4py, are investigated. Additionally, the performance of an open source Python stack is compared to the recently announced Intel Python3 distribution.},
  keywords={},
  doi={10.1109/PyHPC.2016.010},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{7836847,
  author={Lund, Jeffrey and Ashcraft, Chace and McNabb, Andrew and Seppi, Kevin},
  booktitle={2016 6th Workshop on Python for High-Performance and Scientific Computing (PyHPC)}, 
  title={Mrs: High Performance MapReduce for Iterative and Asynchronous Algorithms in Python}, 
  year={2016},
  volume={},
  number={},
  pages={76-85},
  abstract={Mrs [1] is a lightweight Python-based MapReduce implementation designed to make MapReduce programs easy to write and quick to run, particularly useful for research and academia. A common set of algorithms that would benefit from Mrs are iterative algorithms, like those frequently found in machine learning; however, iterative algorithms typically perform poorly in the MapReduce framework, meaning potentially poor performance in Mrs as well. Therefore, we propose four modifications to the original Mrs with the intent to improve its ability to perform iterative algorithms. First, we used direct task-to-task communication for most iterations and only occasionally write to a distributed file system to preserve fault tolerance. Second, we combine the reduce and map tasks which span successive iterations to eliminate unnecessary communication and scheduling latency. Third, we propose a generator-callback programming model to allow for greater flexibility in the scheduling of tasks. Finally, some iterative algorithms are naturally expressed in terms of asynchronous message passing, so we propose a fully asynchronous variant of MapReduce. We then demonstrate Mrs' enhanced performance in the context of two iterative applications: particle swarm optimization (PSO), and expectation maximization (EM).},
  keywords={},
  doi={10.1109/PyHPC.2016.014},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{7836382,
  author={Hamidouche, Khaled and Zhang, Jie and Panda, Dhabaleswar K. and Tomko, Karen},
  booktitle={2016 PGAS Applications Workshop (PAW)}, 
  title={OpenSHMEM Non-blocking Data Movement Operations with MVAPICH2-X: Early Experiences}, 
  year={2016},
  volume={},
  number={},
  pages={9-16},
  abstract={PGAS models with a lightweight synchronization and shared memory abstraction, are seen as a good alternative to the Message Passing model for irregular communication patterns. OpenSHMEM is a library based PGAS model. OpenSHMEM 1.3 introduced Non-Blocking data movement operations to provide better asynchronous progress and overlap. In this paper, we present our experiences in designing Non-Blocking Put and Get operations on InfiniBand systems. Using the MVAPICH2-X runtime, we present the alternative designs for intra-node and inter-node operations. We also present a set of new benchmarks to analyze the latency, message rate performance, and communication/computation overlap benefits. The performance evaluation shows 7X improvement in the message rate. Furthermore, using a 3D-Stencil based application kernel, we assess the benefits of OpenSHMEM Non-Blocking extensions. We show 50% and 28% improvement on 27 and 64 processes, respectively.},
  keywords={},
  doi={10.1109/PAW.2016.007},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{7837053,
  author={Jaiswal, Shashank and Reddy, Rajesh and Banerjee, Raja and Sato, Shingo and Komagata, Daisuke and Ando, Makoto and Okada, Jun},
  booktitle={2016 IEEE 23rd International Conference on High Performance Computing Workshops (HiPCW)}, 
  title={An Efficient GPU Parallelization for Arbitrary Collocated Polyhedral Finite Volume Grids and Its Application to Incompressible Fluid Flows}, 
  year={2016},
  volume={},
  number={},
  pages={81-89},
  abstract={This paper presents GPU parallelization for a computational fluid dynamics solver which works on a mesh consisting of polyhedral cells, where each cell has an arbitrary number of faces and each face has an arbitrary number of vertices. The parallelization is achieved using NVIDIAs compute unified device architecture (CUDA). The developed code specifically targets performance improvement on NVIDIA Tesla accelerator GPUs. The implementation has been carried out in a general purpose open-source CFD framework namely OpenFOAM which is capable of solving arbitrary flow problems involving complex geometries with polyhedral unstructured grids. The present work considers incompressible flow simulations, where solving pressure Poisson equation is the most computationally expensive step. The Poisson equation is solved using conjugate gradient method preconditioned by algebraic multigrid method. This part of the solver is outsourced by OpenFOAM to GPU. The GPU pressure Poisson solver acceleration is determined with respect to OpenFOAM serial version (single cpu core) and MPI parallelized version (8 cpu cores). The GPU solver acceleration was tested by simulating a standard benchmark test case called lid driven cavity flow for different grid sizes. The current GPU based solver has shown a speedup of approximately 16× when compared to single cpu core and 3.3 × when compared to OpenFOAM MPI version using 8 cpu cores, for a grid size of 5 million cells.},
  keywords={},
  doi={10.1109/HiPCW.2016.020},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{7839469,
  author={Shi, Justin and Celik, Yasin},
  booktitle={2016 Fourth International Workshop on Software Engineering for High Performance Computing in Computational Science and Engineering (SE-HPCCSE)}, 
  title={Single-Sided Statistic Multiplexed High Performance Computing}, 
  year={2016},
  volume={},
  number={},
  pages={35-40},
  abstract={For the last three decades, end-to-end computing has been the de facto paradigm for distributed and parallel computing. MPI (Message Passing Interface), RPC (Remote Procedure Call), OpenMP (share memory) and RMI (Remote Method Invocation) are all end-to-end protocols from the same computing paradigm. A myth persisted since 1990's that while the data communication community is well served by the end-to-end protocols, direct use of the end-to-end protocols in distributed computing was considered a fallacy.This paper explores the possibility of acquiring higher performance and better reliability at the same time when expanding the application processing infrastructure by avoiding the well-known fallacy. The key instrument is a single-sided statistic multiplexed computing (SMC) paradigm. It reports a computation performance study for two single-sided SMC prototypes: Synergy and AnkaCom against an MPI application in bare metal HPC environments. Computational experiments confirmed the investigation objectives by exposing the hidden deficiencies of end-to-end computing protocols. Reliability tests are also included.},
  keywords={},
  doi={10.1109/SE-HPCCSE.2016.009},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{7839465,
  author={Hovy, Christian and Kunkel, Julian},
  booktitle={2016 Fourth International Workshop on Software Engineering for High Performance Computing in Computational Science and Engineering (SE-HPCCSE)}, 
  title={Towards Automatic and Flexible Unit Test Generation for Legacy HPC Code}, 
  year={2016},
  volume={},
  number={},
  pages={1-8},
  abstract={Unit testing is an established practice in professional software development. However, in high-performance computing (HPC) with its scientific applications, it is not widely applied. Besides general problems regarding testing of scientific software, for many HPC applications the effort of creating small test cases with a consistent set of test data is high.We have created a tool called FortranTestGenerator, that significantly reduces the effort of creating unit tests for subroutines of an existing Fortran application. It is based on Capture & Replay (C&R), that is, it extracts data while running the original application and uses the extracted data as test input data. The tool automatically generates code for capturing the input data and a basic test driver which can be extended by the developer to an appropriate unit test. A static source code analysis is conducted, to reduce the number of captured variables. Code is generated based on flexibly customizable templates. Thus, both the capturing process and the unit tests can easily be integrated into an existing software ecosystem.Since most HPC applications use message passing for parallel processing, we also present an approach to extend our C&R model to MPI communication. This allows extraction of unit tests from massively parallel applications that can be run with a single process.},
  keywords={},
  doi={10.1109/SE-HPCCSE.2016.005},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{7841301,
  author={Abich, G. and Mandelli, M. G. and Rosa, F. R. and Moraes, F. and Ost, L. and Reis, R.},
  booktitle={2016 IEEE International Conference on Electronics, Circuits and Systems (ICECS)}, 
  title={Extending FreeRTOS to support dynamic and distributed mapping in multiprocessor systems}, 
  year={2016},
  volume={},
  number={},
  pages={712-715},
  abstract={With the ever-increasing complexity of both embedded application workloads and multiprocessor platforms grows the demand for efficient mapping heuristics able of allocating several application workloads at runtime. The majority of promoted mapping techniques are bespoke implementations that consider an in-house operating system, which is developed to a particular architecture, restricting its adoption in other platforms. This work proposes a FreeRTOS extension that supports distributed task mapping heuristics, which enables to balance application workloads in multiprocessor architectures at runtime. Promoted extension is validated through a trustworthy number of scenarios considering large scale Cortex-M-based multiprocessor systems executing up to 600 application tasks.},
  keywords={},
  doi={10.1109/ICECS.2016.7841301},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{7841216,
  author={Madalozzo, Guilherme and Duenha, Liana and Azevedo, Rodolfo and Moraes, Fernando G.},
  booktitle={2016 IEEE International Conference on Electronics, Circuits and Systems (ICECS)}, 
  title={Scalability evaluation in many-core systems due to the memory organization}, 
  year={2016},
  volume={},
  number={},
  pages={396-399},
  abstract={Many-core systems are a common place in the electronic consumer market. Thus, complex benchmark suites have been modeled for shared memory (SM) architectures since it is easier to develop applications (threads) for many-core. Shared memory presents a scalability limitation due to the number of memory accesses. One way to mitigate the SM limitations is to adopt distributed memory system (DSM) architectures. However, DSM presents the same scalability limitation, since the number of processors is clearly superior to the number of SMs in the system. The alternative is to adopt distributed memory organization (DM), which enables the direct communication among the tasks (message passing). The goal of this paper is to highlight the limitations of shared memory connected through a network-on-chip (NoC) in many-core systems, executing a similar workload with both memory organizations. Results evaluate communication volume into NoC and a total number of executed instructions. SM has a worst traffic distribution, with hotspots around the SM, and a much higher communication volume compared to DM. It is worth to highlight such effects since aging effects may appear earlier due to hotspots, reducing the system lifetime.},
  keywords={},
  doi={10.1109/ICECS.2016.7841216},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{7843313,
  author={Abdu-Aguye, Umar-Faruk and Ambroze, Marcel Adrian and Tomlinson, Martin},
  booktitle={2016 10th International Conference on Signal Processing and Communication Systems (ICSPCS)}, 
  title={An efficient algorithm for determining the girth and ACE distributions in LDPC code Tanner graphs}, 
  year={2016},
  volume={},
  number={},
  pages={1-7},
  abstract={We propose a simple and efficient algorithm for evaluating the girth and approximate cycle extrinsic message degree (ACE) of all short cycles through symbol nodes in short-to-medium length low-density parity-check (LDPC) code Tanner graphs. The algorithm uses single-edge tree-apex (SETA) subgraph expansions to find all the short cycles in a code graph in a direct manner, unlike existing algorithms which use message-passing algorithms or trellis representations of code graphs. The complexity of the algorithm, when applied to a parity-check matrix H of dimension m × n, is O(n m). Due to the fact that both girth and ACE are features of cycles, we adopt parameters similar to those used for girth descriptions for ACE descriptions. Accordingly, we define the `local ACE' at a symbol node or the `symbol node ACE', as the minimum ACE of the short cycles through the symbol node in the graph. This basic parameter enables the local ACE distribution, minimum and maximum local ACE, modal ACE, and the average ACE of an LDPC code graph to be determined using SETA subgraph expansions. The average ACE of an LDPC code graph is a concise single-valued measure of the overall connectivity of cycles in the graph. The proposed algorithm determines the local girth and ACE distributions in irregular short length LDPC codes in less time than existing algorithms. The algorithm is not intended for quasi-cyclic (QC) LDPC codes.},
  keywords={},
  doi={10.1109/ICSPCS.2016.7843313},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{7842501,
  author={Meca, Ondřej and Böhm, Stanislav and Behálek, Marek and Jančar, Petr},
  booktitle={2016 16th International Conference on Application of Concurrency to System Design (ACSD)}, 
  title={An Approach to Verification of MPI Applications Defined in a High-Level Model}, 
  year={2016},
  volume={},
  number={},
  pages={55-64},
  abstract={Kaira is a prototyping tool for developing MPI programs (Bohm et al., Petri Nets 2014). The user of Kaira suggests a parallelization of a given sequential C++ code by creating a visual Petri-net based model, the tool then automatically generates the corresponding stand-alone MPI application. One of the tool modules enables to verify that the suggested parallelization has not introduced unexpected behaviors caused by unintended orders of communications among processes. The verification uses a state-space exploration procedure. Here we report on a new substantial enhancement of this procedure, leading to a significant reduction of the explored state space. The enhancement is based on the well-known methods of stubborn sets and ample sets, and is tailored to the use in the above mentioned visual model. Our concrete method is particularly simple but the experiments show that it works very well for practical examples from the area of scientific computing in distributed environment. The experiments also confirm that the Kaira model together with this method outperforms other tools for verifying MPI programs (w.r.t. instance-size/time).},
  keywords={},
  doi={10.1109/ACSD.2016.17},
  ISSN={1550-4808},
  month={June},}
@INPROCEEDINGS{7858529,
  author={Chiu, Jih-Ching and Guo, Bao-Ren and Chao, Chih-Hsun},
  booktitle={2016 International Computer Symposium (ICS)}, 
  title={Massage-Passing Interface Cluster Bulid upon System Kernel Environment}, 
  year={2016},
  volume={},
  number={},
  pages={509-514},
  abstract={With the age of Big Data coming, the three defining characteristics of Big Data-Volume, variety and Velocity, make Cloud Computing facing new challenges. In response to the demand of Big Data analytics, using distributed computing cluster to process vast amounts of data is a megatrend. In this paper, we discuss the performance of distributed computing clusters provided by the current cloud computing platforms. Found that for the Message-Passing Interface (MPI) cluster, which is used in Scientific Computing, such as astronomical, atmosphere, physical spectrum... etc., cloud computing platforms provide less relevant integration services. Which made MPI cluster make inefficient use of cloud computing resources and unable to exert its high computing performance. To improve these, we propose MPI cluster architecture makes efficient use of cloud computing resources. To break the limitation of constructing traditional MPI cluster computing environment, the MPI cluster uses Socket Interface-TCP/IP Server & Client to build Communication System as the message-passing channel, and simplifies Operating System computing resources management mechanism by Group Manager. As the separated way described above, the MPI cluster can resiliently grasp Operating System computing resources, and work well on the cloud computing platform, that computing resources are virtualization and flexible. In order to make The MPI cluster flexible dispatch computing resources on the cloud computing platform more easily, we adopt Kernel Distributed Computing Management (KDCM), proposed by Chiu and Huang. By its ability to unify manage and allocate computing resources, provides the MPI cluster has a path to flexible dispatch computing resources. As the goal of the MPI cluster: Running in Linux kernel driver, and loading on KDCM, we name it MPI Kernel Cluster (MPIKC). As MPIKC and KDCM fit tightly, they can efficient dispatch computing resources, exert its high computing performance, and provide Operating System-based computing environment on cloud computing platform. At the end, we verify the correctness of running MPIKC on KDCM, and use MPIKC to do distributed computing of high computing load, each computing unit used, enhances a 0.5~1 times performance. We proved that MPIKC fits well with cloud computing platform, and exerts its high performance as the advantage of distributed computing cluster.},
  keywords={},
  doi={10.1109/ICS.2016.0107},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{7861161,
  author={Pupezescu, Valentin and Rădescu, Radu},
  booktitle={2016 8th International Conference on Electronics, Computers and Artificial Intelligence (ECAI)}, 
  title={The influence of data replication in the knowledge discovery in distributed databases process}, 
  year={2016},
  volume={},
  number={},
  pages={1-6},
  abstract={The process of knowledge discovery applied in distributed databases implies finding useful knowledge from mining data sets stored in real implementations of distributed databases. Distributed Databases represents a software system that allows a multitude of applications to access the data stored in local or remote databases. In this scenario, the data distribution is achieved through the process of replication. Nowadays many solutions for storing the data are available: relational distributed Database Management Systems (DBMS), NoSQL storing solutions, NewSQL storing solutions, graph oriented databases, object oriented databases, object-relational databases, etc. The present study analyzes the most commonly used storing solution: the relational model. The replication topology used in the related experiments was the classical publisher-subscriber topology. The distribution of data is made from the publisher system. The present work studies the interaction between the most suited distributed data mining architecture (Distributed Committee Machines) for mining distributed data and real relational distributed databases. The chosen Data Mining task is the classification one. Distributed Committee Machines are a group of neuronal networks working in a distributed procedure to obtain an improved classification performance compared to a single neural structure. In these experiments we used the classical multilayer perceptron trained with the backpropagation algorithm. The execution performance of the Distributed Committee Machine is analyzed, based on some of the most used types of replication in relational databases: snapshot replication, merge replication, transactional replication, and transactional with queued updating replication. For all these types of replications the execution performances (distributed speedup and distributed efficiency) of the entire system is also analyzed. These results are useful to numerous research fields: adaptive e-learning applications, medical diagnosis, artificial intelligence, business management, etc.},
  keywords={},
  doi={10.1109/ECAI.2016.7861161},
  ISSN={},
  month={June},}
@INPROCEEDINGS{7860073,
  author={Shitole, Shilpa and Gujar, A. D.},
  booktitle={2016 International Conference on Computing Communication Control and automation (ICCUBEA)}, 
  title={Securing broker-less publisher/subscriber systems using cryptographic technique}, 
  year={2016},
  volume={},
  number={},
  pages={1-6},
  abstract={A publisher-subscriber framework is generally develop on join network architecture. This framework allows authorized data distribution among subscribers through publishers. This is an open overlay network. It has some security issues including integrity and confidentiality, authorization, validation etc. Also there is another problem regarding this network, such as Events secrecy and subscriptions clashes with content based routing. Such security issues are very difficult to predict and resolve. To increase the confirmation and secrecy of broker, this paper introduced the concept of broker less content based publish/subscribe system and also developed a novel technique to improve the same. In this proposed system, subscribers are allowed to view and publish the information if and only if publishers want to share their information. Additionally, to make secure information sharing, only data in encrypted format are shared among subscriber and publishers. For this purpose a more secure encryption algorithm i.e. ECC algorithm is used. Therefore this proposed system is more secure and safe. As ECC utilizes small key size for encryption and decryption, this system takes less computation time and consumes less memory. Different from existing system which can only publish the articles, this proposed system also support for dynamic news or article update with publishing it. After this, to increase the performance of system, cloud services are used. Because of this the performance of system is improved in terms of efficiency, security, data availability and low cost. Also system detect the man in middle attack and replace attack which occurred at the time of data upload and download in the cloud and improve the performance.},
  keywords={},
  doi={10.1109/ICCUBEA.2016.7860073},
  ISSN={},
  month={Aug},}
@INPROCEEDINGS{7859981,
  author={Ghone, Atish Shankar and Umale, Jayant S. and Kulkarni, Kedar},
  booktitle={2016 International Conference on Computing Communication Control and automation (ICCUBEA)}, 
  title={Parallel communication library for TCP stack}, 
  year={2016},
  volume={},
  number={},
  pages={1-5},
  abstract={Message Passing Interface (MPI) has been the predominant standard for writing parallel applications. MPI allows programmerss to write a parallel application by handling the communication between a set of processes. The proprietary high performance network, along with the basic functionalities, may provide additional functionalities or may be able to handle some of the MPI functionalities. There is need to change or modify MPI library in order to validate additional functionalities that the network supports. We plan to implement parallel communication library (PCL) that can provide MPI like interface to the user and simultaneously make use of the additional features provided by the underlying network. The focus of our work is not to implement all the features that MPI provides for the application, but to implement minimal functionality of MPI and employ the additional features that the underlying network interconnect provides. Before targeting the proprietary network, we have developed parallel communication library for standard TCP stack as a part of the first stage of our project. We have implemented a few basic functions in parallel communication library. In this paper, we would like to share our work with the community. Also, we have evaluated the PCL for standard TCP stack using basic tests. We present the performance results of those basic tests.},
  keywords={},
  doi={10.1109/ICCUBEA.2016.7859981},
  ISSN={},
  month={Aug},}
@INPROCEEDINGS{7870915,
  author={Karlsson, Andreas and Olofsson, Niten and Laure, Erwin and Clements, Mark},
  booktitle={2016 IEEE 12th International Conference on e-Science (e-Science)}, 
  title={A parallel microsimulation package for modelling cancer screening policies}, 
  year={2016},
  volume={},
  number={},
  pages={323-330},
  abstract={Microsimulation with stochastic life histories is an important tool in the development of public policies. In this article, we use microsimulation to evaluate policies for prostate cancer testing. We implemented the microsimulations as an R package, with pre- and post-processing in R and with the simulations written in C++. Calibrating a microsimulation model with a large population can be computationally expensive. To address this issue, we investigated four forms of parallelism: (i) shared memory parallelism using R; (ii) shared memory parallelism using OpenMP at the C++ level; (iii) distributed memory parallelism using R; and (iv) a hybrid shared/distributed memory parallelism using OpenMP at the C++ level and MPI at the R level. The close coupling between R and C++ offered advantages for ease of software dissemination and the use of high-level R parallelisation methods. However, this combination brought challenges when trying to use shared memory parallelism at the C++ level: the performance gained by hybrid OpenMP/MPI came at the cost of significant re-factoring of the existing code. As a case study, we implemented a prostate cancer model in the microsimulation package. We used this model to investigate whether prostate cancer testing with specific re-testing protocols would reduce harms and maintain any mortality benefit from prostate-specific antigen testing. We showed that four-yearly testing would have a comparable effectiveness and a marked decrease in costs compared with two-yearly testing and current testing. In summary, we developed a microsimulation package in R and assessed the cost-effectiveness of prostate cancer testing. We were able to scale up the microsimulations using a combination of R and C++, however care was required when using shared memory parallelism at the C++ level.},
  keywords={},
  doi={10.1109/eScience.2016.7870915},
  ISSN={},
  month={Oct},}
@INPROCEEDINGS{7877117,
  author={Kong, Martin and Pouchet, Louis-Noël and Sadayappan, P. and Sarkar, Vivek},
  booktitle={SC '16: Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis}, 
  title={PIPES: A Language and Compiler for Task-Based Programming on Distributed-Memory Clusters}, 
  year={2016},
  volume={},
  number={},
  pages={456-467},
  abstract={Applications running on clusters of shared-memory computers are often implemented using OpenMP+MPI. Productivity can be vastly improved using task-based programming, a paradigm where the user expresses the data and control-flow relations between tasks, offering the runtime maximal freedom to place and schedule tasks. While productivity is increased, high-performance execution remains challenging: the implementation of parallel algorithms typically requires specific task placement and communication strategies to reduce internode communications and exploit data locality. In this work, we present a new macro-dataflow programming environment for distributed-memory clusters, based on the Intel Concurrent Collections (CnC) runtime. Our language extensions let the user define virtual topologies, task mappings, task-centric data placement, task and communication scheduling, etc. We introduce a compiler to automatically generate Intel CnC C++ run-time, with key automatic optimizations including task coarsening and coalescing. We experimentally validate our approach on a variety of scientific computations, demonstrating both productivity and performance.},
  keywords={},
  doi={10.1109/SC.2016.38},
  ISSN={2167-4337},
  month={Nov},}
@INPROCEEDINGS{7881407,
  author={De Doncker, Elise and Almulihi, Ahmed},
  booktitle={2016 International Conference on Computational Science and Computational Intelligence (CSCI)}, 
  title={Adaptive Task Partitioning for Bayesian Applications}, 
  year={2016},
  volume={},
  number={},
  pages={572-577},
  abstract={The numerical integration of the posterior in Bayesian analysis leads to a class of multivariate integration problems where the integrand has a dominant peak. As Monte-Carlo integration is inadequate, various techniques have been proposed in the literature, involving substantial reformulation with additional analysis, or transformations requiring additional problem parameters. We resort to a black-box approach provided by the ParInt multivariate integration package, which is layered over MPI to run on a distributed system, and utilizes adaptive task partitioning with load balancing to keep high-error subregions distributed over the processes. The performance of the algorithm is demonstrated by detailed test results for Bayesian integrals arising as posterior expectations in linear modeling and for cross-classifications in medical data.},
  keywords={},
  doi={10.1109/CSCI.2016.0114},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{7892575,
  author={Alwi, Erick Irawadi and Adji, Teguh Bharata and Sumaryono, Sujoko},
  booktitle={2016 International Conference on Computational Intelligence and Cybernetics}, 
  title={Implementation and performance analysis of MPI cluster system in distributed rendering}, 
  year={2016},
  volume={},
  number={},
  pages={103-108},
  abstract={Graphic image is compulsory in delivering information and communication in this information technology era. Graphic applications are used widely to manipulate images in advertising industries and in animation movie productions. In order to manipulate numerous and complex images, it is required long period of time and high-performance computers. However, computers with high-performance specification are still very expensive these days. This condition triggers the development of distributed processing technique using the implementation of computer cluster which does not require very advanced specifications. A computer cluster is a computer system that employs many computers (PCs) which are connected within a computer network and work simultaneously in parallel for solving given computational processes.},
  keywords={},
  doi={10.1109/CyberneticsCom.2016.7892575},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{7904270,
  author={Tang, Jing and Li, Bin and Chen, Jiangtao and Gong, Xiaoquan},
  booktitle={2016 15th International Symposium on Parallel and Distributed Computing (ISPDC)}, 
  title={Large Scale Parallel Computing for Fluid Dynamics on Unstructured Grid}, 
  year={2016},
  volume={},
  number={},
  pages={64-69},
  abstract={Massive parallel computational fluid dynamics is a vital tool for the modern aviation industry. The parallel aerodynamics numerical simulation software based on unstructured mixed grid and cell-centered finite volume method (FVM) was presented in this paper, which was developed for the complicated configurations of industrial grade. The algorithms for parallel implementation with message passing interface (MPI), including compact numerical discrete schemes, grid partition method for multi-processors and data transfer scheme, are discussed in detail. The validity of parallel computing is verified using a revolving model of relatively small grid. Then a large transport airplane configuration with hundred millions of grid elements is used for parallel testing, and the efficiency is preserved above 80% up to 18816 processors.},
  keywords={},
  doi={10.1109/ISPDC.2016.17},
  ISSN={},
  month={July},}
@INPROCEEDINGS{7904309,
  author={Do-Mai, Anh-Tu and Diep, Thanh-Dang and Thoai, Nam},
  booktitle={2016 15th International Symposium on Parallel and Distributed Computing (ISPDC)}, 
  title={Race Condition and Deadlock Detection for Large-Scale Applications}, 
  year={2016},
  volume={},
  number={},
  pages={319-326},
  abstract={Debugging large-scale parallel applications is a problematic issue. Characteristics of scalability bring about an exponential increase in errors and many impacts on performance. With suffering unacceptable overhead and debugging time, traditional techniques, such as checkpointing or record and replay, have become obsolete when applying to largescale parallel applications. The ex-scale trend is coming, which demands cutting-edge large-scale parallel application debugging techniques. Instead of prior works based on locating exact errors, we proposed an on-the-fly approach by detecting abnormal behaviors arising frequently in complicated message passing channels. In this paper, anomalies are race conditions causing concealing deadlocks which probably result in hangs and make programmers unable to inspect manually errors. The technique utilizes one state-of-the-art detection algorithm which is related to allocation and management tactics. The proposed algorithm is proved the precision and effectiveness by theoretical proofs and experimental results. With acceptable overhead, this technique shows the potential for applying to large-scale parallel applications, specially ones running as master/slave model.},
  keywords={},
  doi={10.1109/ISPDC.2016.53},
  ISSN={},
  month={July},}
@INPROCEEDINGS{7913195,
  author={Arivazhagan, G. B. and Bhattacharya, Amitabh and Sharma, Atul},
  booktitle={2016 Fourth International Conference on Parallel, Distributed and Grid Computing (PDGC)}, 
  title={Parallel performance study for simulation of multi-phase flows with phase change development, parallelization and analysis of in-house CFD codes}, 
  year={2016},
  volume={},
  number={},
  pages={605-610},
  abstract={MPI based parallelization strategy incurring minimum modification in the 3D in-house serial code and good parallel performance is the focus of this work. The objective of this work is to analyze the parallel performance of multi-phase problem with phase change using the standardized parallelization technique of domain decomposition that incurs minimum modification in the code. The computational domain is mapped over a distributed memory parallel architecture using uni-directional domain decomposition. The overlapping boundary control volumes communicate with each other using MPI. The parallel performance of this parallelization methodology is studied briefly on classical problem like - simple 3D lid-driven cavity problem which stands as the benchmark for flow solver. Further, parallel performance is studied on 3D single mode film boiling, a multi-phase flow problem involving phase change. Presently, the work doesn't attribute to deal with load balancing issue and concentrates on minimum modification of the serial code and the parallel performance associated with it.},
  keywords={},
  doi={10.1109/PDGC.2016.7913195},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{7915001,
  author={Rekhate, Vaibhav and Tale, Ankush and Sambhus, Nikhil and Joshi, Amit},
  booktitle={2016 International Conference on Computing, Analytics and Security Trends (CAST)}, 
  title={Secure and efficient message passing in distributed systems using One-Time Pad}, 
  year={2016},
  volume={},
  number={},
  pages={393-397},
  abstract={Distributed Computing system is a cluster of computers connected on a network which coordinate their actions via passing messages. Since the cluster can also be accessed publicly, the security of various messaging operations is of great concern. In this paper a highly efficient and secure implementation of message passing interface (MPI) in distributed environment has been proposed and implemented. This implementation, which is named as VAN-MPICH2, integrates security measures to ensure data confidentiality using One-Time Pad (OTP) encryption technique. Since the proposed encryption implementation decreases the security overhead substantially, VAN-MPICH2 manages to provide confidentiality with very insignificant decrease in performance.},
  keywords={},
  doi={10.1109/CAST.2016.7915001},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{7917187,
  author={Sun, Yichun and Yi, Xiaodong and Liu, Hengzhu},
  booktitle={2016 IEEE International Conference on Internet of Things (iThings) and IEEE Green Computing and Communications (GreenCom) and IEEE Cyber, Physical and Social Computing (CPSCom) and IEEE Smart Data (SmartData)}, 
  title={The Communication Analysis of Implementation in Breadth First Search Algorithm}, 
  year={2016},
  volume={},
  number={},
  pages={754-759},
  abstract={Breadth first search (BFS), specially deals with large graph involving millions of vertices and edges, is a key component in processing bio-informatics, social networks etc. Since the scale of data stored and queried increasing, the performance of BFS algorithm is not satisfied in large amounts of data processing. For efficiently utilizing the processing power of modern processors, researchers optimized the algorithm and proposed four major types of implementation: 1D top-down BFS, 1D bottom-up BFS, 2D top-down BFS, 2D bottom-up BFS. These four types of implementation apply in different parallel computing system according specific conditions. In this paper we construct a MPI communication delay model to analysis these four types of BFS algorithm implementation. Our MPI communication model is based on MPI primitives. We break the four types of BFS algorithm implementation into MPI group communications and non-blocking communications. We extrapolate the latency of non-blocking communication by function of discrete data fitting and applying with network calculus. We take the MPI non-blocking communication as a basic unit to derive MPI group communication latency by analysing MPI primitives. We adopt logic communication and physical communication to discuss the MPI primitives' latency. We seek to obtain the optimal communication buffer in these four types of BFS algorithm implementation. And we try to provide a quantitative solution to choose a suitable topology in communication. Finally we use our experimental platform (a cluster computing system) to validate the proposed model.algorithm implementation. And we try to provide a quantitative solution to choose a suitable topology in communication. Finally we use our experimental platform (a cluster computing system) to validate the proposed model.},
  keywords={},
  doi={10.1109/iThings-GreenCom-CPSCom-SmartData.2016.159},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{7924860,
  author={Shenbo Xu and Zhonghao Wu and Yujing Hong and Qian Xue and Suiyang Liao and Boyue Liu},
  booktitle={2016 2nd IEEE International Conference on Computer and Communications (ICCC)}, 
  title={Optimization of High Performance Computing Cluster based on Intel MIC}, 
  year={2016},
  volume={},
  number={},
  pages={1028-1033},
  abstract={This paper focuses on theoretical analysis, computational test and optimization of High Performance Computing Cluster (HPCC). Also known as Data Analytics Supercomputer (DAS), HPCC is built on Intel Many Integrated Core (MIC) for High Performance Linpack (HPL) test. Initially, a platform is configured by 5 nodes with an Intel® Xeon Phi™ Coprocessor 31S1P per node to analyze power consumption as well as parallel level of Intel MIC accelerator. Compiling with Message Passing Interface (MPI) library and Math Kernel Library (MKL), the “Make” file is modified and debugged by adjusting parameters in hpccinf.txt. According to multiple Infiniband nodes evaluation, the libhpl library of Intel is employed and value of NB is set to be 960 for a single node with one MIC while debugging. Moreover, this paper optimized the algorithm on Double Precision General Matrix Multiplication (DGEMM) test and PTRANS to acquire efficient, precise and truncated working time duration. From HPL and Gridding Program experimental results, it's clear that the theoretical analysis and experiments were performed successfully.},
  keywords={},
  doi={10.1109/CompComm.2016.7924860},
  ISSN={},
  month={Oct},}
@INPROCEEDINGS{7966806,
  author={Nath, Amar and Niyogi, Rajdeep},
  booktitle={2016 International Conference on Information Technology (ICIT)}, 
  title={A Team Formation with Unknown Size in Multi-agent Environment}, 
  year={2016},
  volume={},
  number={},
  pages={33-38},
  abstract={Usually, in the Multi-Agent System (MAS), a number of agents required to finish a job are known a priori. But, there are many situations in which it is not known prior that how many agents will exactly be required to finish the job, i.e., the rescue operation. The Multi-Agent Planning problems (MAP) contains collective (several agents are performing different actions at the same time such that the combined effect achieves a common goal) and joint actions (a kind of collective action where several agents are performing the same action at the same time such that the combined effect achieves a common goal) makes the planning a bit challenging. The execution of such actions demand team formation prior to their execution. The plan execution, involving team formation of the size that is not known a priori is very hard and challenging. The key contributions of the paper include: (1) identification of the domain where the number of agents required to finish a job is not known a prior, (2) proposing a distributed consensus algorithm based on asynchronous communication (messages passing) to form a team and (3) The design specification and validation of the proposed algorithm with Specification and Descriptive Language (SDL) and Message Sequence Charts (MSCs).},
  keywords={},
  doi={10.1109/ICIT.2016.020},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{8070192,
  author={Yu, Zhoujian and Yuan, Cangzhou and Wei, Xin and Gao, Yanhua and Wang, Lei},
  booktitle={2016 5th International Conference on Computer Science and Network Technology (ICCSNT)}, 
  title={Message-passing interprocess communication design in seL4}, 
  year={2016},
  volume={},
  number={},
  pages={418-422},
  abstract={seL4 is formally verified for its functional correctness and its kernel modules provide strong support to achieve interprocess communication mechanism. In recent years, some scholars designed Interprocess Communication Systems with library-based architecture. This design abandons Message-Passing technique that most of microkernels adhere to. The present research still insists on the Message-Passing design for interprocess communication in seL4. The IPC facilities we designed are compliant to POSIX standard, and provide distributed support for three separate subsystems: message queues, semaphores, and shared memory. The evaluation result shows that the IPC facilities can be enforced by our design.},
  keywords={},
  doi={10.1109/ICCSNT.2016.8070192},
  ISSN={},
  month={Dec},}
@ARTICLE{8213190,
  author={Zhao, Jie and Zhao, Rongcai and Xu, Jinchen},
  journal={The Computer Journal}, 
  title={Code Generation for Distributed-Memory Architectures}, 
  year={2016},
  volume={59},
  number={1},
  pages={119-132},
  abstract={Compiling for distributed-memory architectures comprise two main phases. The first phase is to determine computation and data composition. In the 1990s, a great deal of work addressed this problem. The second phase is code generation. However, there is still no effective solution to this problem. Existing methods try to generate codes on the basis of computation and data composition. To enhance the performance of generated codes, various communication optimizations are introduced since communication is one of the main factors degrading the performance. These approaches would bring redundant communication data, as they did not optimize communications jointly with code generation. In this paper, we propose a novel code generation technique for distributed-memory architectures. First, we determine the communication sender and receiver by traversing a loop-based tree structure. To support message aggregation, we find the most appropriate point to insert a message. Secondly, we construct the communication set by proposing some code generation rules, and prove their correctness and accuracy. Redundant communication is thus eliminated. Also, we have evaluated some programs ranging from micro-kernels to applications in NAS parallel benchmarks, and have compared the performance with their message passing interface (MPI), High Performance Fortran (HPF) and Unified Parallel C (UPC) versions. Compared with these versions, our compiler can generate fewer communication points. The generated codes of outperform the HPF and UPC versions and the state-of-the-art, and the average performance can reach 70% of the hand-coded MPI programs.},
  keywords={},
  doi={10.1093/comjnl/bxv077},
  ISSN={1460-2067},
  month={Jan},}
@ARTICLE{7134784,
  author={Barazzutti, Raphaël and Felber, Pascal and Mercier, Hugues and Onica, Emanuel and Rivière, Etienne},
  journal={IEEE Transactions on Dependable and Secure Computing}, 
  title={Efficient and Confidentiality-Preserving Content-Based Publish/Subscribe with Prefiltering}, 
  year={2017},
  volume={14},
  number={3},
  pages={308-325},
  abstract={Content-based publish/subscribe provides a loosely-coupled and expressive form of communication for large-scale distributed systems. Confidentiality is a major challenge for publish/subscribe middleware deployed over multiple administrative domains. Encrypted matching allows confidentiality-preserving content-based filtering but has high performance overheads. It may also prevent the use of classical optimizations based on subscriptions containment. We propose a support mechanism that reduces the cost of encrypted matching, in the form of a prefiltering operator using Bloom filters and simple randomization techniques. This operator greatly reduces the amount of encrypted subscriptions that must be matched against incoming encrypted publications. It leverages subscription containment information when available, but also ensures that containment confidentiality is preserved otherwise. We propose containment obfuscation techniques and provide a rigorous security analysis of the information leaked by Bloom filters in this case. We conduct a thorough experimental evaluation of prefiltering under a large variety of workloads. Our results indicate that prefiltering is successful at reducing the space of subscriptions to be tested in all cases. We show that while there is a tradeoff between prefiltering efficiency and information leakage when using containment obfuscation, it is practically possible to obtain good prefiltering performance while securing the technique against potential leakages.},
  keywords={},
  doi={10.1109/TDSC.2015.2449831},
  ISSN={1941-0018},
  month={May},}
@ARTICLE{7416217,
  author={Lu, Jiang and Zhang, Ting and Hu, Fei and Hao, Qi},
  journal={IEEE Transactions on Systems, Man, and Cybernetics: Systems}, 
  title={Preprocessing Design in Pyroelectric Infrared Sensor-Based Human-Tracking System: On Sensor Selection and Calibration}, 
  year={2017},
  volume={47},
  number={2},
  pages={263-275},
  abstract={This paper presents an information-gain-based sensor selection approach as well as a sensor sensing probability model-based calibration process for multihuman tracking in distributed binary pyroelectric infrared sensor networks. This research includes three contributions: 1) choose the subset of sensors that can maximize the mutual information between sensors and targets; 2) find the sensor sensing probability model to represent the sensing space for sensor calibration; and 3) provide a factor graph-based message passing scheme for distributed tracking. Our approach can find the solution for sensor selection to optimize the performance of tracking. The sensing probability model is efficiently optimized through the calibration process in order to update the parameters of sensor positions and rotations. An application for mobile calibration and tracking is developed. Simulation and experimental results are provided to validate the proposed framework.},
  keywords={},
  doi={10.1109/TSMC.2016.2523914},
  ISSN={2168-2232},
  month={Feb},}
@ARTICLE{7433468,
  author={Grosset, A. V. Pascal and Prasad, Manasa and Christensen, Cameron and Knoll, Aaron and Hansen, Charles},
  journal={IEEE Transactions on Visualization and Computer Graphics}, 
  title={TOD-Tree: Task-Overlapped Direct Send Tree Image Compositing for Hybrid MPI Parallelism and GPUs}, 
  year={2017},
  volume={23},
  number={6},
  pages={1677-1690},
  abstract={Modern supercomputers have thousands of nodes, each with CPUs and/or GPUs capable of several teraflops. However, the network connecting these nodes is relatively slow, on the order of gigabits per second. For time-critical workloads such as interactive visualization, the bottleneck is no longer computation but communication. In this paper, we present an image compositing algorithm that works on both CPU-only and GPU-accelerated supercomputers and focuses on communication avoidance and overlapping communication with computation at the expense of evenly balancing the workload. The algorithm has three stages: a parallel direct send stage, followed by a tree compositing stage and a gather stage. We compare our algorithm with radix-k and binary-swap from the IceT library in a hybrid OpenMP/MPI setting on the Stampede and Edison supercomputers, show strong scaling results and explain how we generally achieve better performance than these two algorithms. We developed a GPU-based image compositing algorithm where we use CUDA kernels for computation and GPU Direct RDMA for inter-node GPU communication. We tested the algorithm on the Piz Daint GPU-accelerated supercomputer and show that we achieve performance on par with CPUs. Last, we introduce a workflow in which both rendering and compositing are done on the GPU.},
  keywords={},
  doi={10.1109/TVCG.2016.2542069},
  ISSN={1941-0506},
  month={June},}
@ARTICLE{7463051,
  author={Valero, Valentín and Díaz, Gregorio and Cambronero, María-Emilia},
  journal={IEEE Transactions on Software Engineering}, 
  title={Timed Automata Modeling and Verification for Publish-Subscribe Structures Using Distributed Resources}, 
  year={2017},
  volume={43},
  number={1},
  pages={76-99},
  abstract={In this paper we present a Timed Automata model for the Publish/Subscribe paradigm in the context of Web Service Compositions with distributed resources, on the basis of an algebraic language inspired by the WSRF standard constructions. This framework allows a set of participants in a Web Service composition to interact with one another and also to manage a collection of distributed resources. The model includes operations for clients to publish, discover and subscribe to resources, so as to be notified when the resource property values fulfill certain conditions (topic-based subscription). Simulation and model-checking techniques can therefore be applied to the obtained network of timed automata, in order to check whether certain properties of interest are satisfied. A specific case study is finally presented to illustrate the model and the verification of the relevant properties on the obtained timed automata model.},
  keywords={},
  doi={10.1109/TSE.2016.2560842},
  ISSN={1939-3520},
  month={Jan},}
@ARTICLE{7478121,
  author={Tarable, Alberto and Nordio, Alessandro and Leonardi, Emilio and Marsan, Marco Ajmone},
  journal={IEEE Transactions on Parallel and Distributed Systems}, 
  title={The Importance of Worker Reputation Information in Microtask-Based Crowd Work Systems}, 
  year={2017},
  volume={28},
  number={2},
  pages={558-571},
  abstract={This paper presents the first systematic investigation of the potential performance gains for crowd work systems, deriving from available information at the requester about individual worker reputation. In particular, we first formalize the optimal task assignment problem when workers' reputation estimates are available, as the maximization of a monotone (submodular) function subject to Matroid constraints. Then, being the optimal problem NP-hard, we propose a simple but efficient greedy heuristic task allocation algorithm. We also propose a simple “maximum a-posteriori” decision rule and a decision algorithm based on message passing. Finally, we test and compare different solutions, showing that system performance can greatly benefit from information about workers' reputation. Our main findings are that: i) even largely inaccurate estimates of workers' reputation can be effectively exploited in the task assignment to greatly improve system performance; ii) the performance of the maximum a-posteriori decision rule quickly degrades as worker reputation estimates become inaccurate; iii) when workers' reputation estimates are significantly inaccurate, the best performance can be obtained by combining our proposed task assignment algorithm with the message-passing decision algorithm.},
  keywords={},
  doi={10.1109/TPDS.2016.2572078},
  ISSN={1558-2183},
  month={Feb},}
@ARTICLE{7736134,
  author={Chopra, Ribhu and Murthy, Chandra R. and Annavajjala, Ramesh},
  journal={IEEE Transactions on Signal Processing}, 
  title={Multistream Distributed Cophasing}, 
  year={2017},
  volume={65},
  number={4},
  pages={1042-1057},
  abstract={In this paper, we develop a distributed cophasing (DCP) technique for physical layer fusion of multiple data streams in a wireless sensor network with multiple destination nodes (DNs). The DNs can either be connected to a fusion center (referred to as centralized data processing; CDP) or process data independently and communicate with each other via a rate-limited link (referred to as distributed data processing; DDP). In the first stage of this two-stage cophasing scheme, sensors estimate the channel to the DNs using pilot symbols transmitted by the latter; following which they simultaneously transmit multiple streams of data symbols by prerotating them according to the estimated channel phases to the different DNs. The achievable rates for both CDP and DDP are derived to quantify the gains obtainable by the multistream DCP. In order to aid data detection at the receiver, we propose a least-squares-based iterative algorithm for blind channel estimation in CDP-DCP. Following this, we develop a message passing based blind channel estimation algorithm for DDP-DCP. It is found using Monte Carlo simulations that for the CDP system, the proposed blind channel estimation algorithm achieves a probability of error performance very close to that with perfect CSI at the DNs, while using only a moderate number of unknown data symbols for channel estimation. We also derive approximate expressions for the error probability performance of the proposed system for both CDP and DDP and validate their accuracy using Monte Carlo simulations.},
  keywords={},
  doi={10.1109/TSP.2016.2625263},
  ISSN={1941-0476},
  month={Feb},}
@ARTICLE{7747452,
  author={Leng, Jiewu and Jiang, Pingyu},
  journal={IEEE Transactions on Systems, Man, and Cybernetics: Systems}, 
  title={Mining and Matching Relationships From Interaction Contexts in a Social Manufacturing Paradigm}, 
  year={2017},
  volume={47},
  number={2},
  pages={276-288},
  abstract={There is an increasing use of social interaction contexts in the cross-enterprise manufacturing problem solving. To transform these massive and unstructured data into decision-support information for cross-enterprise manufacturing demand-capability matching, we present automated solutions to two phases: (1) extracting relationships based on a semi-supervised learning approach to derive formalized heterogeneous manufacturing network from the unstructured text-based context that contains high levels of noise and irrelevant information and (2) matching group-level relationships among the entities in the established manufacturing network. The extracting phase formulates network data using multiattributed graph that can encode various entities and relationships. The matching phase is based on probabilistic multiattributed graph matching, and implemented using distributed message passing algorithm. We developed a prototype system to verify the proposed model, which is also flexible to new domains of contexts and scale to large datasets. The ultimate goal of this paper is to facilitate knowledge transferring and sharing in the context of cross-enterprise social interaction, thereby supporting the integration of the resources and capabilities among different enterprise.},
  keywords={},
  doi={10.1109/TSMC.2016.2623630},
  ISSN={2168-2232},
  month={Feb},}
@ARTICLE{7762121,
  author={Ul Hassan, Najeeb and Pusane, Ali E. and Lentmaier, Michael and Fettweis, Gerhard P. and Costello, Daniel J.},
  journal={IEEE Transactions on Communications}, 
  title={Non-Uniform Window Decoding Schedules for Spatially Coupled LDPC Codes}, 
  year={2017},
  volume={65},
  number={2},
  pages={501-510},
  abstract={Spatially coupled low-density parity-check codes can be decoded using a graph-based message passing algorithm applied across the total length of the coupled graph. However, considering practical constraints on decoding latency and complexity, a sliding window decoding approach is normally preferred. In order to reduce decoding complexity compared with standard parallel decoding schedules, serial schedules can be applied within a decoding window. However, uniform serial schedules within a window do not provide the expected reduction in complexity. Hence, we propose non-uniform schedules (parallel and serial) based on measured improvements in the estimated bit error rate (BER). We show that these non-uniform schedules result in a significant reduction in complexity without any loss in performance. Furthermore, based on observations made using density evolution, we propose a non-uniform pragmatic decoding schedule (parallel and serial) that does not require any additional calculations (e.g., BER estimates) within the decoding process.},
  keywords={},
  doi={10.1109/TCOMM.2016.2633466},
  ISSN={1558-0857},
  month={Feb},}
@ARTICLE{7802563,
  author={Zhu, Junan and Baron, Dror and Krzakala, Florent},
  journal={IEEE Transactions on Signal Processing}, 
  title={Performance Limits for Noisy Multimeasurement Vector Problems}, 
  year={2017},
  volume={65},
  number={9},
  pages={2444-2454},
  abstract={Compressed sensing (CS) demonstrates that sparse signals can be estimated from underdetermined linear systems. Distributed CS (DCS) further reduces the number of measurements by considering joint sparsity within signal ensembles. DCS with jointly sparse signals has applications in multisensor acoustic sensing, magnetic resonance imaging with multiple coils, remote sensing, and array signal processing. Multimeasurement vector (MMV) problems consider the estimation of jointly sparse signals under the DCS framework. Two related MMV settings are studied. In the first setting, each signal vector is measured by a different independent and identically distributed (i.i.d.) measurement matrix, while in the second setting, all signal vectors are measured by the same i.i.d. matrix. Replica analysis is performed for these two MMV settings, and the minimum mean squared error (MMSE), which turns out to be identical for both settings, is obtained as a function of the noise variance and number of measurements. To showcase the application of MMV models, the MMSE's of complex CS problems with both real and complex measurement matrices are also analyzed. Multiple performance regions for MMV are identified where the MMSE behaves differently as a function of the noise variance and the number of measurements. Belief propagation (BP) is a CS signal estimation framework that often achieves the MMSE asymptotically. A phase transition for BP is identified. This phase transition, verified by numerical results, separates the regions where BP achieves the MMSE and where it is suboptimal. Numerical results also illustrate that more signal vectors in the jointly sparse signal ensemble lead to a better phase transition.},
  keywords={},
  doi={10.1109/TSP.2016.2646663},
  ISSN={1941-0476},
  month={May},}
@ARTICLE{7830899,
  author={Lin, Baihong and Pei, Yukui and Yin, Liuguo and Lu, Jianhua},
  journal={Tsinghua Science and Technology}, 
  title={Design and efficient hardware implementation schemes for non-Quasi-Cyclic LDPC codes}, 
  year={2017},
  volume={22},
  number={01},
  pages={92-103},
  abstract={The design of a high-speed decoder using traditional partly parallel architecture for Non-Quasi-Cyclic (NQC) Low-Density Parity-Check (LDPC) codes is a challenging problem due to its high memory-block cost and low hardware utilization efficiency. In this paper, we present efficient hardware implementation schemes for NQCLDPC codes. First, we propose an implementation-oriented construction scheme for NQC-LDPC codes to avoid memory-access conflict in the partly parallel decoder. Then, we propose a Modified Overlapped Message-Passing (MOMP) algorithm for the hardware implementation of NQC-LDPC codes. This algorithm doubles the hardware utilization efficiency and supports a higher degree of parallelism than that used in the Overlapped Message Passing (OMP) technique proposed in previous works. We also present single-core and multi-core decoder architectures in the proposed MOMP algorithm to reduce memory cost and improve circuit efficiency. Moreover, we introduce a technique called the cycle bus to further reduce the number of block RAMs in multi-core decoders. Using numerical examples, we show that, for a rate-2/3, length-15360 NQC-LDPC code with 8.43-dB coding gain for Binary PhaseShift Keying (BPSK) in an Additive White Gaussian Noise (AWGN) channel, the decoder with the proposed scheme achieves a 23.8%-52.6% reduction in logic utilization per Mbps and a 29.0%-90.0% reduction in message-memory bits per Mbps.},
  keywords={},
  doi={10.1109/TST.2017.7830899},
  ISSN={1007-0214},
  month={February},}
@ARTICLE{7840049,
  author={Condo, Carlo and Gross, Warren J.},
  journal={IEEE Transactions on Signal Processing}, 
  title={Implementation of Sparse Superposition Codes}, 
  year={2017},
  volume={65},
  number={9},
  pages={2421-2427},
  abstract={Sparse superposition codes (SSCs) are capacity achieving codes whose decoding process is a linear sensing problem. Decoding approaches thus exploit the approximate message passing algorithm, which has been proven to be effective in compressing sensing. Previous work from the authors has evaluated the error correction performance of SSCs under finite precision and finite code length. This paper proposes the first SSC encoder and decoder architectures in the literature. The architectures are parametrized and applicable to all SSCs: A set of wide-ranging case studies is then considered, and code-specific approximations, along with implementation results in 65 nm CMOS technology, are then provided. The encoding process can be carried out with low power consumption (≤2.103 mW), while the semi-parallel decoder architecture can reach a throughput of 1.3 Gb/s with a 768 × 6-bit SSC codeword and an area occupation of 2.43 mm2.},
  keywords={},
  doi={10.1109/TSP.2017.2664045},
  ISSN={1941-0476},
  month={May},}
@ARTICLE{7867084,
  author={Cao, Bin and Zhao, Jianwei and Lv, Zhihan and Liu, Xin},
  journal={IEEE Transactions on Industrial Informatics}, 
  title={A Distributed Parallel Cooperative Coevolutionary Multiobjective Evolutionary Algorithm for Large-Scale Optimization}, 
  year={2017},
  volume={13},
  number={4},
  pages={2030-2038},
  abstract={A considerable amount of research has been devoted to multiobjective optimization problems. However, few studies have aimed at multiobjective large-scale optimization problems (MOLSOPs). To address MOLSOPs, which may involve big data, this paper proposes a message passing interface MPI -based distributed parallel cooperative coevolutionary multiobjective evolutionary algorithm (DPCCMOEA). DPCCMOEA tackles MOLSOPs based on decomposition. First, based on a modified variable analysis method, we separate decision variables into several groups, each of which is optimized by a subpopulation (species). Then, the individuals in each subpopulation are further separated to several sets. DPCCMOEA is implemented with MPI distributed parallelism and a two-layer parallel structure is constructed. We examine the proposed algorithm using the multiobjective test suites Deb-Thiele-Laumanns-Zitzler and Walking-Fish-Group. In comparison with cooperative coevolutionary generalized differential evolution 3 and multiobjective evolutionary algorithm based on decision variable analyses, which are state-of-the-art cooperative coevolutionary multiobjective evolutionary algorithms, experimental results show that the novel algorithm has better performance in both optimization results and time consumption.},
  keywords={},
  doi={10.1109/TII.2017.2676000},
  ISSN={1941-0050},
  month={Aug},}
@ARTICLE{7865926,
  author={Jin, Shuangshuang and Huang, Zhenyu and Diao, Ruisheng and Wu, Di and Chen, Yousu},
  journal={IEEE Transactions on Smart Grid}, 
  title={Comparative Implementation of High Performance Computing for Power System Dynamic Simulations}, 
  year={2017},
  volume={8},
  number={3},
  pages={1387-1395},
  abstract={Dynamic simulation for transient stability assessment is one of the most important, but intensive, computational tasks for power system planning and operation. Several commercial software tools provide functionality for performing multiple dynamic simulations such as those in contingency analysis simultaneously on parallel computers. Nevertheless, a single dynamic simulation is still a time consuming process performed sequentially on one single computing core as the tools were originally designed. Modern high performance computing (HPC) holds the promise to accelerate a single dynamic simulation by parallelizing its kernel algorithms without compromising computational accuracy. Parallelizing a single dynamic simulation is a much more challenging problem than the contingency-type parallel computing. It requires a good match between simulation algorithms and computing hardware. This paper provides guidance for such a match so as to design and implement parallel dynamic simulation to maximize the utilization of computing hardware and the performance of the simulation. The guidance is derived through comparative implementation of four parallel dynamic simulation schemes in two state-of-the-art HPC environments: 1) message passing interface and 2) open multi-processing. The scalability and speedup performance of parallelized dynamic simulation are thoroughly studied to determine the impact of simulation algorithms and computing hardware configurations. Several testing cases are presented to illustrate the derived guidance.},
  keywords={},
  doi={10.1109/TSG.2016.2647220},
  ISSN={1949-3061},
  month={May},}
@ARTICLE{7875477,
  author={Bi, Hui and Zhang, Bingchen and Zhu, Xiao Xiang and Hong, Wen and Sun, Jinping and Wu, Yirong},
  journal={IEEE Transactions on Geoscience and Remote Sensing}, 
  title={$L_{1}$ -Regularization-Based SAR Imaging and CFAR Detection via Complex Approximated Message Passing}, 
  year={2017},
  volume={55},
  number={6},
  pages={3426-3440},
  abstract={Synthetic aperture radar (SAR) is a widely used active high-resolution microwave imaging technique that has alltime and all-weather reconnaissance ability. Compared with traditionally matched filtering (MF)-based methods, Lq(0 ≤ q ≤ 1) regularization technique can efficiently improve SAR imaging performance e.g., suppressing sidelobes and clutter. However, conventional Lq-regularization-based SAR imaging approach requires transferring the 2-D echo data into a vector and reconstructing the scene via 2-D matrix operations. This leads to significantly more computational complexity compared with MF, and makes it very difficult to apply in high-resolution and wide-swath imaging. Typical Lq regularization recovery algorithms, e.g., iterative thresholding algorithm, can improve imaging performance of bright targets, but not preserve the image background distribution well. Thus, image background statistical-property-based applications, such as constant false alarm rate (CFAR) detection, cannot be applied to regularization recovered SAR images. On the other hand, complex approximated message passing (CAMP), an iterative recovery algorithm for L1 regularization reconstruction, can achieve not only the sparse estimation of the original signal as typical regularization recovery algorithms but also a nonsparse solution simultaneously. In this paper, two novel CAMP-based SAR imaging algorithms are proposed for raw data and complex radar image data, respectively, along with CFAR detection via the CAMP recovered nonsparse result. The proposed method for raw data can not only improve SAR image performance as conventional L1 regularization technique but also reduce the computational cost efficiently. While only when we have MF recovered SAR complex image rather than raw data, the proposed method for complex image data can achieve a similar reconstructed image quality as the regularization-based SAR imaging approach using the full raw data. The most important contribution of this paper is that the proposed CAMP-based methods make CFAR detection based on the regularization reconstruction SAR image possible using their nonsparse scene estimations, which has a similar background statistical distribution as the MF recovered images. The experimental results validated the effectiveness of the proposed methods and the feasibility of the recovered nonsparse images being used for CFAR detection.},
  keywords={},
  doi={10.1109/TGRS.2017.2671519},
  ISSN={1558-0644},
  month={June},}
@ARTICLE{7888533,
  author={Bi, Hui and Zhang, Bingchen and Zhu, Xiao Xiang and Jiang, Chenglong and Hong, Wen},
  journal={IEEE Transactions on Geoscience and Remote Sensing}, 
  title={Extended Chirp Scaling-Baseband Azimuth Scaling-Based Azimuth–Range Decouple $L_{1}$ Regularization for TOPS SAR Imaging via CAMP}, 
  year={2017},
  volume={55},
  number={7},
  pages={3748-3763},
  abstract={This paper proposes a novel azimuth-range decouple-based L1 regularization imaging approach for the focusing in terrain observation by progressive scans (TOPS) synthetic aperture radar (SAR). Since conventional L1 regularization technique requires transferring the (2-D) echo data into a vector and reconstructing the scene via 2-D matrix operations leading to significantly more computational complexity, it is very difficult to apply in high-resolution and wide-swath SAR imaging, e.g., TOPS. The proposed method can achieve azimuth-range decouple by constructing an approximated observation operator to simulate the raw data, the inverse of matching filtering (MF) procedure, which makes large-scale sparse reconstruction, or called compressive sensing reconstruction of surveillance region with full- or downsampled raw data in TOPS SAR possible. Compared with MF algorithm, e.g., extended chirp scaling-baseband azimuth scaling, it shows huge potential in image performance improvement; while compared with conventional L1 regularization technique, it significantly reduces the computational cost, and provides similar image features. Furthermore, this novel approach can also obtain a nonsparse estimation of considered scene retaining a similar background statistical distribution as the MF-based image, which can be used to the further application of SAR images with precondition being preserving image statistical properties, e.g., constant false alarm rate detection. Experimental results along with a performance analysis validate the proposed method.},
  keywords={},
  doi={10.1109/TGRS.2017.2679129},
  ISSN={1558-0644},
  month={July},}
@ARTICLE{7891590,
  author={Xiong, Youzhi and Wei, Ning and Zhang, Zhongpei and Li, Binrui and Chen, Yang},
  journal={IEEE Access}, 
  title={Channel Estimation and IQ Imbalance Compensation for Uplink Massive MIMO Systems With Low-Resolution ADCs}, 
  year={2017},
  volume={5},
  number={},
  pages={6372-6388},
  abstract={In this paper, two techniques to compensate inphase/quadrature-phase imbalance (IQI) are investigated in the uplink-quantized massive multiple-input and multiple-output (MIMO) systems for different models of randomized IQI parameters. One is referred to as combined-signal-based channel estimation and compensation (CCEC) and the other is denoted by effective channel estimation and compensation (ECEC). First, an independent automatic gain control (AGC) scheme is proposed to calibrate the dynamic range of both the I branch and the Q branch. By doing that, different quantization steps are used for analog-to-digital converters following the AGCs in these two branches at each receive antenna. Second, considering the impacts of both quantization and IQI, we give the details of channel estimation and IQI compensation for both the CCEC and the ECEC using bilinear generalized approximate message passing (Bi-GAMP). Moreover, to exploit the Bi-GAMP for ECEC reasonably, we theoretically derive the probability density function PDF of the elements in the effective channel for the case where only RX IQI is considered. Furthermore, we extend the ECEC to the case where both RX IQI and TX IQI are incorporated into the systems and derive the similar pdf as well. Finally, we use the numerical results to testify the validity of our theoretical analysis and the fact that the analytic PDF can be approximated by a Gaussian distribution when the IQI parameters are relatively small. Compared with other classical methods, the proposed methods can obtain better performance based on the Monte Carlo simulation results.},
  keywords={},
  doi={10.1109/ACCESS.2017.2690439},
  ISSN={2169-3536},
  month={},}
@ARTICLE{7912593,
  author={Silva, J.O. and Orellana, E.T.V. and Torres, M.},
  journal={IEEE Latin America Transactions}, 
  title={Development of a Parallel Version of PhyML 3.0 Using Shared Memory}, 
  year={2017},
  volume={15},
  number={5},
  pages={959-967},
  abstract={This work presents the main steps towards a parallel version of the open source phylogenetic tree reconstruction software PhyML 3.0, which uses the method of maximum likelihood in phylogenetic reconstruction process. The PhyML was parallelized by a shared memory approach (using OpenMP) and at the same time using the version already consolidated in PhyML 3.0, the version passing messages with distributed memory (using MPI), was also constructed a version hybrid (MPI and OpenMP) of PhyML. The tests for the efficiency and speedup were carried out in a cluster of two ways, the first only by analyzing the performance version with OpenMP (DNA and proteins) and the second making a comparative analysis of the performance of three parallel versions (OpenMP, MPI and Hybrid) using DNA data only. The results obtained show speedup of approximately six to 8 cores on 1 server, which allows the use of this code problems that require a lot of time in the serial version, front the need or urgent of the fast processing of data.},
  keywords={},
  doi={10.1109/TLA.2017.7912593},
  ISSN={1548-0992},
  month={May},}
@INPROCEEDINGS{7912662,
  author={Grebe, Marco and Lacko, Tilman and Loogen, Rita},
  booktitle={2017 25th Euromicro International Conference on Parallel, Distributed and Network-based Processing (PDP)}, 
  title={Analysing Message Numbers in Actor Systems}, 
  year={2017},
  volume={},
  number={},
  pages={291-294},
  abstract={Constructing a fitting actor system to solve a problem is a task which needs experience. Deducing its properties and behaviour without a running instance and a set of test cases is even harder. In this paper, we show how methods from linear algebra allow us to make statements about the number of messages in a given system. This can be used to reason about reaction to bigger or changed inputs and to analyse how optimisations will change the behaviour of a system. Further different numbers of actors or other design alternatives can be compared.},
  keywords={},
  doi={10.1109/PDP.2017.86},
  ISSN={2377-5750},
  month={March},}
@INPROCEEDINGS{7912618,
  author={Nalepa, Jakub and Blocho, Miroslaw},
  booktitle={2017 25th Euromicro International Conference on Parallel, Distributed and Network-based Processing (PDP)}, 
  title={A Parallel Memetic Algorithm for the Pickup and Delivery Problem with Time Windows}, 
  year={2017},
  volume={},
  number={},
  pages={1-8},
  abstract={Solving the pickup and delivery problem with time windows (PDPTW) is a vital research topic due to its NP-hardness and its numerous practical applications. In this paper, we propose an island-model parallel memetic algorithm for minimizing the distance in the PDPTW. In this algorithm, the processes execute the same memetic algorithm and co-operate to guide the optimization efficiently. An extensive experimental study revealed that the MPI implementation of the proposed approach retrieves very high-quality routing schedules. The analysis is coupled with appropriate statistical tests.},
  keywords={},
  doi={10.1109/PDP.2017.75},
  ISSN={2377-5750},
  month={March},}
@INPROCEEDINGS{7923813,
  author={Azab, Abdulrahman},
  booktitle={2017 IEEE International Conference on Cloud Engineering (IC2E)}, 
  title={Enabling Docker Containers for High-Performance and Many-Task Computing}, 
  year={2017},
  volume={},
  number={},
  pages={279-285},
  abstract={Docker is the most popular and user friendly platform for running and managing Linux containers. This is proven by the fact that vast majority of containerized tools are packaged as Docker images. A demanding functionality is to enable running Docker containers inside HPC job scripts for researchers to make use of the flexibility offered by containers in their real-life computational and data intensive jobs. The main two questions before implementing such functionality are: how to securely run Docker containers within cluster jobs? and how to limit the resource usage of a Docker job to the borders defined by the HPC queuing system? This paper presents Socker, a secure wrapper for running Docker containers on Slurm and similar queuing systems. Socker enforces the execution of containers within Slurm jobs as the submitting user instead of root, as well as enforcing the inclusion of containers in the cgroups assigned by the queuing system to the parent jobs. Different from other Docker supported containers-for-hpc platform, socker uses the underlaying Docker engine instead of replacing it. To eveluate socker, it has been tested for running MPI Docker jobs on Slurm. It has been also tested for Many-task computing (MTC) on interconnected clusters. Socker has proven to be secure, as well as introducing no additional overhead to the one introduced already by the Docker engine.},
  keywords={},
  doi={10.1109/IC2E.2017.52},
  ISSN={},
  month={April},}
@INPROCEEDINGS{7925930,
  author={Kim, Nam I. and Cho, Dong-Ho},
  booktitle={2017 IEEE Wireless Communications and Networking Conference (WCNC)}, 
  title={Hybrid Multiple Access System Based on Non Orthogonality and Sparse Code}, 
  year={2017},
  volume={},
  number={},
  pages={1-6},
  abstract={In this paper, a hybrid access system based on non- orthogonality and sparse code is proposed. Non- orthogonal multiple access (NOMA) applied to a communications network can exploit higher spectral efficiency than conventional orthogonal multiple access (OMA) scheme by using channel gain difference. Sparse code multiple access (SCMA) scheme can give massive connectivity by using sparsely spread code and message passing algorithm (MPA). Therefore, we propose a hybrid access system to use the advantages of two schemes which are mentioned above. The hybrid system supports near and far users simultaneously by using NOMA scheme and data for near users is transmitted by SCMA scheme. We present the results of two kinds of simulations, i.e., bit error rate simulation and throughput simulation, to verify the superiority of the proposed system.},
  keywords={},
  doi={10.1109/WCNC.2017.7925930},
  ISSN={1558-2612},
  month={March},}
@INPROCEEDINGS{7925583,
  author={Feng, Jing and Gao, Hui and Wang, Taotao and Lv, Tiejun and Guo, Weibin},
  booktitle={2017 IEEE Wireless Communications and Networking Conference (WCNC)}, 
  title={A Noncoherent Differential Transmission Scheme for Multiuser Massive MIMO Systems}, 
  year={2017},
  volume={},
  number={},
  pages={1-6},
  abstract={A noncoherent multiuser transmission scheme is proposed for massive multiple-input multiple-output (M-MIMO) systems without explicit channel estimation. In particular, each user uses differential PSK modulation and the receiver employs differential detection. First, we propose a simple user selection scheme to optimize the distributions of power space profile (PSP) of individual users which alleviates the overlap of PSPs. Then, each output stream of the weighing filter is fed into a noncoherent successive interference cancellation (N-SIC) processor, and finally into a soft-input soft-output (SISO) multiple-symbol differential detector(MSDD). Employing the autocorrelation receiver (AcR) and the belief propagation(BP) message passing algorithm, the proposed SISO-MSDD framework can be easily integrated with advanced channel coding. The proposed scheme bears the potential to solve the high channel estimation overhead for conventional coherent M-MIMO systems. Simulation results show that the BER performance can be significantly improved within a few iterations of the proposed scheme.},
  keywords={},
  doi={10.1109/WCNC.2017.7925583},
  ISSN={1558-2612},
  month={March},}
@INPROCEEDINGS{7926084,
  author={Long Feng and Ruijun Ma and Dicker, Lee H.},
  booktitle={2017 51st Annual Conference on Information Sciences and Systems (CISS)}, 
  title={Nonparametric maximum likelihood approximate message passing}, 
  year={2017},
  volume={},
  number={},
  pages={1-6},
  abstract={Generalized approximate message passing (GAMP) is an effective algorithm for recovering signals from noisy linear measurements, assuming known a priori signal distributions. However, in practice, both the signal distribution and noise level are often unknown. The EM-GM-AMP algorithm integrates GAMP with the EM algorithm to simultaneously estimate the signal distribution and noise variance while recovering the signal. EM-GM-AMP is built on the assumption that the signal is drawn from a sparse Gaussian mixture. In this paper, we propose nonparametric maximum likelihood-AMP (NPML-AMP) for estimating an arbitrary signal distribution in this setting. In addition to providing more flexibility (and performance improvements), we argue that the nonparametric approach actually simplifies implementation and improves stability by leveraging approximate convexity, which is not available in the sparse Gaussian mixture formulation of EM-GM-AMP. We also propose a simplified noise variance estimator for use in conjunction with NPML-AMP (or EM-GM-AMP). A comprehensive numerical study validates the performance of NPML-AMP algorithm in reaching nearly minimum mean squared error (MMSE) under various signal distributions, noise levels, and undersampling ratios.},
  keywords={},
  doi={10.1109/CISS.2017.7926084},
  ISSN={},
  month={March},}
@INPROCEEDINGS{7926961,
  author={Siddhartha and Kapre, Nachiket},
  booktitle={Design, Automation & Test in Europe Conference & Exhibition (DATE), 2017}, 
  title={eBSP: Managing NoC traffic for BSP workloads on the 16-core Adapteva Epiphany-III processor}, 
  year={2017},
  volume={},
  number={},
  pages={73-78},
  abstract={We can deliver high performance and energy efficient operation on the multi-core NoC-based Adapteva Epiphany-III SoC for bulk-synchronous workloads using our proposed eBSP communication API. We characterize and automate performance tuning of spatial parallelism for supporting (1) random access load-store style traffic suitable for irregular sparse computations, as well as (2) variable, data-dependent traffic patterns in neural networks or PageRank-style workloads in a manner tailored for the Epiphany NoC. We aggressively optimize traffic by exposing spatial communication structure to the fabric through offline pre-computation of destination addresses, unrolling of message-passing loops, selective squelching of messages, and careful ordering of communication and compute. Using our approach, across a range of applications and datasets such as Sparse Matrix-Vector multiplication (Matrix Market datasets), PageRank (BerkStan SNAP dataset), and Izhikevich spiking neural evaluation, we deliver speedups of 6.5–10x while lowering power use by 2x over optimized ARM-based mappings. When compared to optimized OpenMP x86 mappings, we observe a 11–31x improvement in energy efficiency (GFLOP/s/W) for the Epiphany SoC. Epiphany is also able to beat state-of-the-art spatial FPGA (ZC706) and embedded GPU (Jetson TK1) mappings due to our communication optimizations. Our library is open-source and available at github.com/sidmontu/ebsp.git.},
  keywords={},
  doi={10.23919/DATE.2017.7926961},
  ISSN={1558-1101},
  month={March},}
@INPROCEEDINGS{7927281,
  author={Mohr, Manuel and Tradowsky, Carsten},
  booktitle={Design, Automation & Test in Europe Conference & Exhibition (DATE), 2017}, 
  title={Pegasus: Efficient data transfers for PGAS languages on non-cache-coherent many-cores}, 
  year={2017},
  volume={},
  number={},
  pages={1781-1786},
  abstract={To improve scalability, some many-core architectures abandon global cache coherence, but still provide a shared address space. Partitioning the shared memory and communicating via messages is a safe way of programming such machines. However, accessing pointered data structures from a foreign memory partition is expensive due to the required serialization. In this paper, we propose a novel data transfer technique that avoids serialization overhead for pointered data structures by managing cache coherence in software at object granularity. We show that for PGAS programming languages, the compiler and runtime system can completely handle the necessary cache management, thus requiring no changes to application code. Moreover, we explain how cache operations working on address ranges complement our data transfer technique. We propose a novel non-blocking implementation of range-based cache operations by offloading them to an enhanced cache controller. We evaluate our approach on a non-cache-coherent many-core architecture using a distributed-kernel benchmark suite and demonstrate a reduction of communication time of up to 39.8%.},
  keywords={},
  doi={10.23919/DATE.2017.7927281},
  ISSN={1558-1101},
  month={March},}
@ARTICLE{7945295,
  author={Wang, Shengchu and Zhang, Lin and Jing, Xiaojun},
  journal={IEEE Transactions on Wireless Communications}, 
  title={Phase Retrieval Motivated Nonlinear MIMO Communication With Magnitude Measurements}, 
  year={2017},
  volume={16},
  number={8},
  pages={5452-5466},
  abstract={This paper proposes a multiuser magnitude-only (MO-)MIMO, whose base station acquires quantized magnitudes of the complex baseband signals through envelop detectors and low-resolution ADCs. Consequently, MO-MIMO enjoys much lower circuit power and cost in comparison with the conventional MIMO. Because the phase information is unavailable, all the existing MIMO baseband algorithms cannot be applied into MO-MIMO. Therefore, two types of channel estimators and multiuser detectors are constructed by first categorizing the channel estimation and multiuser detection problems as a quantized phase retrieval (PR) problem, and then solving the latter by developing two methods under the framework of generalized approximate message passing (GAMP). The first method directly applies GAMP to solve the quantized PR problem by exploiting the probability relationships between the quantized magnitude measurements and unknown complex signals. The second method iterates between the missing phase estimation and signal recovery, where the latter calls for GAMP to handle a linear mixing problem with quantized observations. The developed estimators and detectors call for matrix-vector multiplications and nonlinear function calculations as the most complex operations, handle the nonlinear quantization loss specially, and exploit the signal prior probability distributions. Finally, their effectiveness is validated experimentally.},
  keywords={},
  doi={10.1109/TWC.2017.2711606},
  ISSN={1558-2248},
  month={Aug},}
@INPROCEEDINGS{7946808,
  author={Lescisin, Michael and Mahmoud, Qusay H.},
  booktitle={2017 IEEE 30th Canadian Conference on Electrical and Computer Engineering (CCECE)}, 
  title={DCM: A Python-based middleware for parallel processing applications on small scale devices}, 
  year={2017},
  volume={},
  number={},
  pages={1-5},
  abstract={Parallel programming has been an active area of research in computer science and software engineering for many years. Parallel programming should ideally provide a linear speedup to computational problems. In reality, this is rarely the case. While there are some algorithms that cannot be parallelized, many that can, still fail to provide the ideal linear speedup. For algorithms that can benefit from parallelization, it is often much more difficult to develop the parallel code than it is to write a sequential, single-threaded program. The existence of this gap between ideal parallel computing and parallel computing on real hardware and software has caused many developers to create new solutions in an attempt to move real parallel computing closer to its idealized model. While many of these solutions provide a great performance benefit on large-scale systems, they often lag behind when deployed on small-scale systems. In this paper, we introduce the design and implementation of DCM (Distributed Computing Middleware) - a Python-based middleware for writing parallel processing applications for execution on clusters of small-scale devices. Evaluation results show the feasibility of DCM. Our middleware and its test cases are publicly available on GitHub.},
  keywords={},
  doi={10.1109/CCECE.2017.7946808},
  ISSN={},
  month={April},}
@INPROCEEDINGS{7952843,
  author={Zheng, Naijun and He, Yuxuan and Bai, Baoming and So, Anthony Man-Cho and Yang, Kehu},
  booktitle={2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={LDPC code design for Gaussian multiple-access channels using dynamic EXIT chart analysis}, 
  year={2017},
  volume={},
  number={},
  pages={3679-3683},
  abstract={We consider the degree distribution design of the low-density parity-check (LDPC) code ensembles for symmetric Gaussian multiple-access channels (GMAC). To characterize the probability density function (PDF) of the message passing in the process of joint decoding, we propose a new scheme to construct the associated Gaussian mixture (GM) distribution, where each GM component is assigned according to the corresponding signal group transmitted by the users. By tracking the variation of the GM components in the iterative decoding process, more accurate mutual information can be obtained for the extrinsic information transfer (EXIT) chart analysis. Simulation results show that the performance of our proposed LDPC codes is better than that of the existing methods.},
  keywords={},
  doi={10.1109/ICASSP.2017.7952843},
  ISSN={2379-190X},
  month={March},}
@INPROCEEDINGS{7964877,
  author={Irannejad, Milad and Tchamgoue, Guy Martin and Fischmeister, Sebastian},
  booktitle={2017 IEEE 20th International Symposium on Real-Time Distributed Computing (ISORC)}, 
  title={A Reordering Framework for Testing Message-Passing Systems}, 
  year={2017},
  volume={},
  number={},
  pages={109-116},
  abstract={In a message-passing system (MPS), components communicate through messages. However, both the time and order in which messages are delivered depend on the execution environment. The resulting nondeterminism may lead to concurrency defects such as message races, making it difficult to thoroughly test and debug MPS. This paper presents a new framework for testing components of an MPS for faults that involve the violation of any implicit user-intended receiving order of messages. The framework purposefully assesses possible interleavings by reordering incoming messages before delivering them to the tested target component. We evaluate three methods to support the reordering process: the blocking method intercepts and blocks each message until all its dependencies have occurred, the buffering method buffers a message until either its dependencies are observed or a predefined timeout expires, and the adaptive buffering dynamically adjusts its flushing period. All three methods are implemented inside QNX Neutrino, a popular embedded real-time operating system. The evaluation shows a 4x speedup over random testing with minimal run time overhead and only a few kilobytes of memory overhead. These results confirms the effectiveness and capability of the framework to uncover faults in real-world applications.},
  keywords={},
  doi={10.1109/ISORC.2017.6},
  ISSN={2375-5261},
  month={May},}
@INPROCEEDINGS{7965064,
  author={Bao, Tianyi and Gardner, William B.},
  booktitle={2017 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)}, 
  title={Log Visualization Tool for Message-Passing Programming in Pilot}, 
  year={2017},
  volume={},
  number={},
  pages={331-338},
  abstract={The Pilot library is aimed at novice high-performance computing (HPC) programmers and has been used for years to teach message-passing programming to undergraduates. While built on top of standard Message Passing Interface (MPI), it offers a compact application programming interface (API) based upon simple abstractions from the process/channel model of Communicating Sequential Processes (CSP), extensive error-checking, and an integrated deadlock detector. This work enhances Pilot with a log visualization facility adapted from MPI Parallel Environment (MPE) and Jumpshot-4. This new feature is a pedagogical tool helping beginners to understand actual run-time message-passing between processes, and a debugging tool for diagnosing logic that impedes parallelism.},
  keywords={},
  doi={10.1109/IPDPSW.2017.52},
  ISSN={},
  month={May},}
@INPROCEEDINGS{7967119,
  author={Ramos, Sabela and Hoefler, Torsten},
  booktitle={2017 IEEE International Parallel and Distributed Processing Symposium (IPDPS)}, 
  title={Capability Models for Manycore Memory Systems: A Case-Study with Xeon Phi KNL}, 
  year={2017},
  volume={},
  number={},
  pages={297-306},
  abstract={Increasingly complex memory systems and onchip interconnects are developed to mitigate the data movement bottlenecks in manycore processors. One example of such a complex system is the Xeon Phi KNL CPU with three different types of memory, fifteen memory configuration options, and a complex on-chip mesh network connecting up to 72 cores. Users require a detailed understanding of the performance characteristics of the different options to utilize the system efficiently. Unfortunately, peak performance is rarely achievable and achievable performance is hardly documented. We address this with capability models of the memory subsystem, derived by systematic measurements, to guide users to navigate the complex optimization space. As a case study, we provide an extensive model of all memory configuration options for Xeon Phi KNL. We demonstrate how our capability model can be used to automatically derive new close-to-optimal algorithms for various communication functions yielding improvements 5x and 24x over Intel's tuned OpenMP and MPI implementations, respectively. Furthermore, we demonstrate how to use the models to assess how efficiently a bitonic sort application utilizes the memory resources. Interestingly, our capability models predict and explain that the high bandwidthMCDRAM does not improve the bitonic sort performance over DRAM.},
  keywords={},
  doi={10.1109/IPDPS.2017.30},
  ISSN={1530-2075},
  month={May},}
@INPROCEEDINGS{7975509,
  author={Shukla, Sankalp and Rajput, Dheeraj Singh and Ahirwar, Maniram},
  booktitle={2017 International Conference on Innovative Mechanisms for Industry Applications (ICIMIA)}, 
  title={Self-assessing processes in HPC applications: Alternate approach to Master/Slave Processes}, 
  year={2017},
  volume={},
  number={},
  pages={1-4},
  abstract={This paper proposes the use of a new approach, i.e., `Self Assessing Processes' approach in high performance computing (HPC) applications in which all processes identify the section of data to be computed using them. After the successful completion of these computations, each process employs a Message Passing Interface (MPI) I/O to write the results to a file in parallel. This eliminates idle time of processes, making efficient use of modern parallel file architecture systems. Contemporary high performance applications employ Master/Slave model to make use of modern multi-core architectures. The disadvantage of Master/Slave model is that master processes create communication overheads while distributing and gathering information. Also, master and slave processes remain idle for a considerable amount of time waiting for communication. The master-slave model application involves file I/O, consuming excessive amount of time due to sequential reading and writing by the master process. The performance of the proposed approach is verified by using Intel Trace Analyzer and Collector (ITAC).},
  keywords={},
  doi={10.1109/ICIMIA.2017.7975509},
  ISSN={},
  month={Feb},}
@INPROCEEDINGS{7973768,
  author={Rivas-Gomez, Sergio and Markidis, Stefano and Peng, Ivy Bo and Laure, Erwin and Kestor, Gokcen and Gioiosa, Roberto},
  booktitle={2017 17th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing (CCGRID)}, 
  title={Extending Message Passing Interface Windows to Storage}, 
  year={2017},
  volume={},
  number={},
  pages={727-730},
  abstract={This paper presents an extension to MPI supporting the one-sided communication model and window allocations in storage. Our design transparently integrates with the current MPI implementations, enabling applications to target MPI windows in storage, memory or both simultaneously, without major modifications. Initial performance results demonstrate that the presented MPI window extension could potentially be helpful for a wide-range of use-cases and with low-overhead.},
  keywords={},
  doi={10.1109/CCGRID.2017.44},
  ISSN={},
  month={May},}
@INPROCEEDINGS{7973750,
  author={Tabuchi, Akihiro and Nakao, Masahiro and Murai, Hitoshi and Boku, Taisuke and Sato, Mitsuhisa},
  booktitle={2017 17th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing (CCGRID)}, 
  title={Implementation and Evaluation of One-Sided PGAS Communication in XcalableACC for Accelerated Clusters}, 
  year={2017},
  volume={},
  number={},
  pages={625-634},
  abstract={Clusters equipped with accelerators such as graphics processing unit (GPU) and Many Integrated Core (MIC) are widely used. For such clusters, programmers write programs for their applications by combining MPI with one of the available accelerator programming models. In particular, OpenACC enables programmers to develop their applications easily, but with lower productivity owing to complex MPI programming. XcalableACC (XACC) is a new programming model, which is an "orthogonal" integration of a partitioned global address space (PGAS) language XcalableMP (XMP) and OpenACC. While XMP enables distributed-memory programming on both global-view and local-view models, OpenACC allows operations to be offloaded to a set of accelerators. In the local-view model, programmers can describe communication with the coarray features adopted from Fortran 2008, and we extend them to communication between accelerators. We have designed and implemented an XACC compiler for NVIDIA GPU and evaluated its performance and productivity by using two benchmarks, Himeno benchmark and NAS Parallel Benchmarks CG (NPB-CG). The performance of the XACC version with the Himeno benchmark and NPB-CG are over 85% and 97% in the local-view model against the MPI+OpenACC version, respectively. Moreover, using non-blocking communication makes the performance of local-view version over 89% with the Himeno benchmark. From the viewpoint of productivity, the local-view model provides an intuitive form of array assignment statement for communication.},
  keywords={},
  doi={10.1109/CCGRID.2017.81},
  ISSN={},
  month={May},}
@INPROCEEDINGS{7973717,
  author={Dang, Hoang-Vu and Seo, Sangmin and Amer, Abdelhalim and Balaji, Pavan},
  booktitle={2017 17th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing (CCGRID)}, 
  title={Advanced Thread Synchronization for Multithreaded MPI Implementations}, 
  year={2017},
  volume={},
  number={},
  pages={314-324},
  abstract={Concurrent multithreaded access to the Message Passing Interface (MPI) is gaining importance to support emerging hybrid MPI applications. The interoperability between threads and MPI, however, is complex and renders efficient implementations nontrivial. Prior studies showed that threads waiting for communication progress (waiting threads) often interfere with others (active threads) and degrade their progress. This situation occurs when both classes of threads compete for the same MPI resource and ownership passing to waiting threads does not guarantee communication to advance. The best-known practical solution prioritizes active threads and adapts first-in-first-out arbitration within each class. This approach, however, suffers from residual wasted resource acquisitions (waste) and ignores data locality, thus resulting in poor scalability. In this work, we propose thread synchronization improvements to eliminate waste while preserving data locality in a production MPI implementation. First, we leverage MPI knowledge and a fast synchronization method to eliminate waste and accelerate progress. Second, we rely on a cooperative progress model that dynamically elects and restricts a single waiting thread to drive a communication context for improved data locality. Third, we prioritize active threads and synchronize them with a locality-preserving lock that is hierarchical and exploits unbounded bias for high throughput. Results show significant improvement in synthetic microbenchmarks and two MPI+OpenMP applications.},
  keywords={},
  doi={10.1109/CCGRID.2017.65},
  ISSN={},
  month={May},}
@INPROCEEDINGS{7980227,
  author={Chapuis, Bertil and Garbinato, Benoît},
  booktitle={2017 IEEE 37th International Conference on Distributed Computing Systems (ICDCS)}, 
  title={Scaling and Load Testing Location-Based Publish and Subscribe}, 
  year={2017},
  volume={},
  number={},
  pages={2543-2546},
  abstract={The rise of the Internet of things (IoT) poses massive scalability issues for location-based services. More particularly, location-aware publish and subscribe services are struggling to scale out the computation of matches between publications and subscriptions that continuously update their location. In this demonstration paper, we propose a novel distributed and horizontally scalable architecture for location-aware publish and subscribe. Our middleware architecture relies on a multi-step routing mechanism based on consistent hashing and range partitioning. To demonstrate its scalability, we present a traffic data generator, which, in contrast to existing generators, can be used to perform real-time load tests. Finally, we show that our architecture can be deployed on a small 10-node cluster and can process up to 80,000 location updates per second producing 25,000 matches per seconds.},
  keywords={},
  doi={10.1109/ICDCS.2017.234},
  ISSN={1063-6927},
  month={June},}
@INPROCEEDINGS{7980147,
  author={Zhang, Kaiwen and Muthusamy, Vinod and Sadoghi, Mohammad and Jacobsen, Hans-Arno},
  booktitle={2017 IEEE 37th International Conference on Distributed Computing Systems (ICDCS)}, 
  title={Subscription Covering for Relevance-Based Filtering in Content-Based Publish/Subscribe Systems}, 
  year={2017},
  volume={},
  number={},
  pages={2039-2044},
  abstract={Large-scale applications require a scalable data dissemination service with advanced filtering capabilities. We propose the use of a content-based publish/subscribe system with support for top-k filtering in the context of such applications. We focus on the problem of top-k subscription filtering, where a publication is delivered only to the k highest scoring subscribers. The naive approach to perform filtering early at the publisher edge works only if complete knowledge of the subscriptions is available, which is not compatible with the well-established covering optimization in scalable content-based publish/subscribe systems. We propose an efficient rank-cover technique to reconcile top-k subscription filtering with covering. We extend the covering model to support top-k and describe a novel algorithm for forwarding subscriptions to publishers while maintaining correctness. Finally, we compare our solutions to a baseline covering system. In a typical setting, our optimized solution is scalable and provides over 81% of the covering benefit.},
  keywords={},
  doi={10.1109/ICDCS.2017.184},
  ISSN={1063-6927},
  month={June},}
@INPROCEEDINGS{7986521,
  author={Ben Abdessalem, Marwa and Zribi, Amin and Matsumoto, Tad and Bouallègue, Ammar},
  booktitle={2017 13th International Wireless Communications and Mobile Computing Conference (IWCMC)}, 
  title={Graph-based Joint Source Channel LDPC decoding for cooperative communication with error-corrupted relay observations}, 
  year={2017},
  volume={},
  number={},
  pages={1588-1593},
  abstract={In this paper, we design a unified framework decoder for relay systems with iterative decoding. In the proposed scheme, the source node needs to transmit a correlated content to a destination with the help of a relay. Then, a distributed Joint Source Channel (JSC) Low-Density-Parity-Check (LDPC) encoding is applied at the source and the relay. The destination receives simultaneously the source compressed data from the source node, and the source/channel encoded data from the relay node. The cooperative network is mapped into a factor graph on which message passing iterative decoding is applied to estimate the source information. The JSC decoder takes into account the source-relay correlation which involves remarkable improvements even if errors occur at the source-relay link. The Bit Error-Rate (BER) system performance are investigated for different scenario, according to the relay position, and it is shown that the performance of the proposed cooperative scheme is typically about 0.5–1.0 dB better than an equivalent rate point-to-point system.},
  keywords={},
  doi={10.1109/IWCMC.2017.7986521},
  ISSN={2376-6506},
  month={June},}
@INPROCEEDINGS{7987195,
  author={Liu, Weifeng and Gong, Bin and Guo, Meng},
  booktitle={2017 IEEE 4th International Conference on Cyber Security and Cloud Computing (CSCloud)}, 
  title={Improving the Energy Efficiency for Parallel Applications Running on Clusters}, 
  year={2017},
  volume={},
  number={},
  pages={177-186},
  abstract={Now cloud computing is rapidly growing as an alternative to traditional computing architecture. However, it is based on models like cluster computing in general. Thus, improving the energy consumption of the cluster system is the basis for the green cloud. In order to reach exascale computing, more and more efforts are made to improve the energy consumption and efficiency in high performance computing systems. As the de facto standard for designing parallel applications in cluster environment, the Message Passing Interface has been widely used in high performance computing. Therefore, getting the energy consumption information of MPI applications is critical for improving the energy efficiency of cluster systems. By creating a distributed measuring framework which can collect all nodes' energy consumption without the aid of power meters, it is possible to get the detailed energy information of an MPI application. In this work, we present MEMT, a software framework that eases the energy collection in cluster environment. Using this tool, it is viable to find out parameters that affect an MPI program's energy efficiency and to build the models for execution time and energy consumption. Based on the pre-built models, energy saving strategy can be designed. The use of this tool is tested in a cluster.},
  keywords={},
  doi={10.1109/CSCloud.2017.52},
  ISSN={},
  month={June},}
@INPROCEEDINGS{7995927,
  author={Koenig, Alexander and Rehder, Tobias and Hohmann, Soeren},
  booktitle={2017 IEEE Intelligent Vehicles Symposium (IV)}, 
  title={Exact inference and learning in hybrid Bayesian Networks for lane change intention classification}, 
  year={2017},
  volume={},
  number={},
  pages={1535-1540},
  abstract={Determining the current intentions of other drivers is essential for correctly predicting or simulating their future actions. Especially unpredicted lane changes can result in very uncomfortable or even dangerous braking maneuvers for succeeding vehicles. Bayesian Networks (BN) allow for a physically motivated probabilistic representation of features influencing driver intentions. While features often take continuous values, e.g. velocity and distance, maneuver intentions are discrete, which results in hybrid BN. For efficient and exact inference, we implement an approach for hybrid nets into the original Bayes Net Toolbox. Furthermore, we extend the approach with a learning component to train a BN with simulated traffic data. Finally, we compare the classification performance for lane changes with a Deep Neural Network (DNN) classifier.},
  keywords={},
  doi={10.1109/IVS.2017.7995927},
  ISSN={},
  month={June},}
@INPROCEEDINGS{8001961,
  author={Cantu, Melisa and Joon Kim and Zhang, Xiaowen},
  booktitle={2017 IEEE Long Island Systems, Applications and Technology Conference (LISAT)}, 
  title={Finding hash collisions using MPI on HPC clusters}, 
  year={2017},
  volume={},
  number={},
  pages={1-6},
  abstract={In cryptography, a hash function is a very important cryptographic primitive with a wide range of applications. There are three required properties for a good hash function, i.e., collision, pre-image, and second pre-image resistance. In this paper, we try to contest these properties on a popular and widely used hash function called MD5 - and its two simplified versions that we made. The birthday attack technique was used to test MD5's general collision resistance, while the brute force method was used in the search for pre-image and second pre-image collisions. We calculated the Hamming distance to monitor the progress in our search for a collision; the smaller the Hamming distance the better. Our input domain for the MD5 hash function consisted of hexadecimal bit-strings and strategically generated ASCII character strings. Since finding hash collisions demands much more computing power and storage, we wrote C parallel programs in conjunction with the Message Passing Interface (MPI) library that runs over multiple processors / cores in the heavily used CUNY HPC cluster called Penzias. Multiple search / sort / merge algorithms were tested, not only to reduce time and space complexities, but also to improve performance. Hash distributions, numerous arbitrary meaningless and a few meaningful collisions were found.},
  keywords={},
  doi={10.1109/LISAT.2017.8001961},
  ISSN={},
  month={May},}
@INPROCEEDINGS{8002911,
  author={Alali, Fatma and Mizero, Fabrice and Veeraraghavan, Malathi and Dennis, John M.},
  booktitle={2017 Network Traffic Measurement and Analysis Conference (TMA)}, 
  title={A measurement study of congestion in an InfiniBand network}, 
  year={2017},
  volume={},
  number={},
  pages={1-9},
  abstract={This paper presents a measurement study of congestion on a production, highly utilized, 72K-core InfiniBand cluster called Yellowstone. The measurement study consists of a 23-day data collection phase in which port counters of the Yellowstone switches were read multiple times every hour to check for stalls during which the port is unable to send data due to a lack of flow-control credits. A total of 30M data records were obtained and analyzed. Results showed that a significant number of the 100-ms intervals over which a port counter was observed, there were transmission stalls. For example, out of 6M observations of Top-of-Rack (ToR) switch uplink ports, we found that the port was forced to wait for credits in 60% of these 100-ms intervals. Such transmission stalls could increase application execution time, and also decrease cluster utilization. The latter will occur when Message Passing Interface (MPI) Barrier calls are issued for synchronization and communication delays cause one or more MPI ranks to be slower than others.},
  keywords={},
  doi={10.23919/TMA.2017.8002911},
  ISSN={},
  month={June},}
@INPROCEEDINGS{8003796,
  author={Savvas, Ilias K. and Tselios, Dimitrios},
  booktitle={2017 IEEE 26th International Conference on Enabling Technologies: Infrastructure for Collaborative Enterprises (WETICE)}, 
  title={Combining Distributed and Multi-core Programming Techniques to Increase the Performance of K-Means Algorithm}, 
  year={2017},
  volume={},
  number={},
  pages={95-100},
  abstract={The last years, huge masses of data are produced or extracted by computational systems and independent electronic devices. To exploit this resource, novel methods must be employed or the established ones may be altered in order to confront the issues that arise. One of the most fruitful techniques, in order to locate and use information from data sources is clustering, and k-means is a successful representative algorithm which clusters data according specific characteristics. However, its main disadvantage is the computational complexity which proves the techniques very unproductive to apply on big datasets. Although k-means is a very well studied technique, a fully operational distributed version combining the multi-core power of today machines, have not been accepted yet by the scientific community. In this work, a three phase distributed/multi-core version of k-means is presented. The obtained experimental results are very promising and prove the correctness, the scalability, and the effectiveness of the proposed technique.},
  keywords={},
  doi={10.1109/WETICE.2017.21},
  ISSN={},
  month={June},}
@INPROCEEDINGS{7965109,
  author={Pino, Sergio and Pollock, Lori and Chandrasekaran, Sunita},
  booktitle={2017 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)}, 
  title={Exploring translation of OpenMP to OpenACC 2.5: lessons learned}, 
  year={2017},
  volume={},
  number={},
  pages={673-682},
  abstract={Scientists who want to exploit the computing power of the latest parallel architectures are faced with a diverse set of architectures and a number of programming languages, models and approaches. Among several such programming techniques are directive-based programming models, OpenMP and OpenACC. This paper explores the similarities and the functionality gaps between both models and presents insights into the translation process of constructs from OpenMP to OpenACC. An empirical study of performance and portability across multicore platforms and GPU accelerators for varying workload sizes is also presented.},
  keywords={},
  doi={10.1109/IPDPSW.2017.84},
  ISSN={},
  month={May},}
@INPROCEEDINGS{7965119,
  author={Akhmetova, Dana and Iakymchuk, Roman and Ekeberg, Orjan and Laure, Erwin},
  booktitle={2017 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)}, 
  title={Performance Study of Multithreaded MPI and OpenMP Tasking in a Large Scientific Code}, 
  year={2017},
  volume={},
  number={},
  pages={756-765},
  abstract={With a large variety and complexity of existing HPC machines and uncertainty regarding exact future Exascale hardware, it is not clear whether existing parallel scientific codes will perform well on future Exascale systems: they can be largely modified or even completely rewritten from scratch. Therefore, now it is important to ensure that software is ready for Exascale computing and will utilize all Exascale resources well. Many parallel programming models try to take into account all possible hardware features and nuances. However, the HPC community does not yet have a precise answer whether, for Exascale computing, there should be a natural evolution of existing models interoperable with each other or it should be a disruptive approach. Here, we focus on the first option, particularly on a practical assessment of how some parallel programming models can coexist with each other. This work describes two API combination scenarios on the example of iPIC3D [26], an implicit Particle-in-Cell code for space weather applications written in C++ and MPI plus OpenMP. The first scenario is to enable multiple OpenMP threads call MPI functions simultaneously, with no restrictions, using an MPI THREAD MULTIPLE thread safety level. The second scenario is to utilize the OpenMP tasking model on top of the first scenario. The paper reports a step-by-step methodology and experience with these API combinations in iPIC3D; provides the scaling tests for these implementations with up to 2048 physical cores; discusses occurred interoperability issues; and provides suggestions to programmers and scientists who may adopt these API combinations in their own codes.},
  keywords={},
  doi={10.1109/IPDPSW.2017.128},
  ISSN={},
  month={May},}
@INPROCEEDINGS{8022750,
  author={Lavery, Paul and Watanabe, Takuo},
  booktitle={2017 18th IEEE/ACIS International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing (SNPD)}, 
  title={An actor-based runtime monitoring system for web and desktop applications}, 
  year={2017},
  volume={},
  number={},
  pages={385-390},
  abstract={In this paper, we introduce a runtime monitoring method for Actor-based programs and present a Scala module that realizes the proposed method. The primary characteristic of our method is that it supports asynchronous message-passing based on the Actor model. Besides, the module does not require specialized languages for describing application properties to be monitored. Once a developer incorporates the module in his/her application, it continuously checks whether the application satisfies certain properties described as Scala code and invokes mitigation code when it finds the violation of the properties. This paper also provides two non-trivial use cases to illustrate how the module can be seamlessly integrated into actual modern Scala applications. We also demonstrate the efficiency of the module using a set of benchmarks that resulted in only 8% of the experiments causing more than 5% runtime overhead.},
  keywords={},
  doi={10.1109/SNPD.2017.8022750},
  ISSN={},
  month={June},}
@INPROCEEDINGS{8025290,
  author={Chu, Ching-Hsiang and Lu, Xiaoyi and Awan, Ammar A. and Subramoni, Hari and Hashmi, Jahanzeb and Elton, Bracy and Panda, Dhabaleswar K.},
  booktitle={2017 46th International Conference on Parallel Processing (ICPP)}, 
  title={Efficient and Scalable Multi-Source Streaming Broadcast on GPU Clusters for Deep Learning}, 
  year={2017},
  volume={},
  number={},
  pages={161-170},
  abstract={Broadcast operations (e.g. MPI_Bcast) have been widely used in deep learning applications to exchange a large amount of data among multiple graphics processing units (GPUs). Recent studies have shown that leveraging the InfiniBand hardware-based multicast (IB-MCAST) protocol can enhance scalability of GPU-based broadcast operations. However, these initial designs with IB-MCAST are not optimized for multi-source broadcast operations with large messages, which is the common communication scenario for deep learning applications. In this paper, we first model existing broadcast schemes and analyze their performance bottlenecks on GPU clusters. Then, we propose a novel broadcast design based on message streaming to better exploit IB-MCAST and NVIDIA GPUDirect RDMA (GDR) technology for efficient large message transfer operation. The proposed design can provide high overlap among multi-source broadcast operations. Experimental results show up to 68% reduction of latency compared to state-of-the-art solutions in a benchmark-level evaluation. The proposed design also shows near-constant latency for a single broadcast operation as a system grows. Furthermore, it yields up to 24% performance improvement in the popular deep learning framework, Microsoft CNTK, which uses multi-source broadcast operations; notably, the performance gains are achieved without modifications to applications. Our model validation shows that the proposed analytical model and experimental results match within a 10% range. Our model also predicts that the proposed design outperforms existing schemes for multi-source broadcast scenarios with increasing numbers of broadcast sources in large-scale GPU clusters.},
  keywords={},
  doi={10.1109/ICPP.2017.25},
  ISSN={2332-5690},
  month={Aug},}
@INPROCEEDINGS{8026869,
  author={Liu, Wei and Wu, Kai and Liu, Jialin and Chen, Feng and Li, Dong},
  booktitle={2017 International Conference on Networking, Architecture, and Storage (NAS)}, 
  title={Performance Evaluation and Modeling of HPC I/O on Non-Volatile Memory}, 
  year={2017},
  volume={},
  number={},
  pages={1-10},
  abstract={HPC applications pose high demands on I/O performance and storage capability. The emerging non-volatile memory (NVM) techniques offer low- latency, high bandwidth, and persistence for HPC applications. However, the existing I/O stack are designed and optimized based on an assumption of disk-based storage. To effectively use NVM, we must re-examine the existing high performance computing (HPC) I/O sub-system to properly integrate NVM into it. Using NVM as a fast storage, the previous assumption on the inferior performance of storage (e.g., hard drive) is not valid any more. The performance problem caused by slow storage may be mitigated; the existing mechanisms to narrow the performance gap between storage and CPU may be unnecessary and result in large overhead. Thus fully understanding the impact of introducing NVM into the HPC software stack demands a thorough performance study. In this paper, we analyze and model the performance of I/O intensive HPC applications with NVM as a block device. We study the performance from three perspectives: (1) the impact of NVM on the performance of traditional page cache; (2) a performance comparison between MPI individual I/O and POSIX I/O; and (3) the impact of NVM on the performance of collective I/O. We reveal the diminishing effects of page cache, minor performance difference between MPI individual I/O and POSIX I/O, and performance disadvantage of collective I/O on NVM due to unnecessary data shuffling. We also model the performance of MPI collective I/O and study the complex interaction between data shuffling, storage performance, and I/O access patterns.},
  keywords={},
  doi={10.1109/NAS.2017.8026869},
  ISSN={},
  month={Aug},}
@INPROCEEDINGS{8035094,
  author={Singh, Krishna Kant and Marin, Dmitriy F. and Redon, Stephane},
  booktitle={2017 International Conference on High Performance Computing & Simulation (HPCS)}, 
  title={Parallel Adaptively Restrained Molecular Dynamics}, 
  year={2017},
  volume={},
  number={},
  pages={308-314},
  abstract={Force computations are one of the most time consuming part in performing Molecular Dynamics (MD) simulations. Adaptively Restrained Molecular Dynamics (ARMD) makes it possible to perform fewer force calculations by adaptively restraining particles positions. This paper introduces parallel algorithms for single-pass incremental force computations to take advantage of adaptive restraints using the Message Passage Interface (MPI) standard. The proposed algorithms are implemented and validated in LAMMPS, however, these algorithms can be applied to other MD simulators. We compared our algorithms with LAMMPS for performance and scalability measurements.},
  keywords={},
  doi={10.1109/HPCS.2017.55},
  ISSN={},
  month={July},}
@INPROCEEDINGS{8035124,
  author={Rangel, Carlos R. and Wong, Alvaro and Rexachs, Dolores and Luque, Emilio},
  booktitle={2017 International Conference on High Performance Computing & Simulation (HPCS)}, 
  title={Using the Application Signature to Detect Inefficiencies Generated by Mapping Policies in Parallel Applications}, 
  year={2017},
  volume={},
  number={},
  pages={534-540},
  abstract={The execution of HPC applications in multicore environments can occasionally use the resources in an inefficient way. There are idle times during the application execution that can be caused by synchronization or message passing collisions. We define this idle time as an application inefficiency and may be caused by the message passing collisions at different types of interconnections in the compute nodes. We propose a methodology to characterize the application's execution in order to analyze and detect these inefficiencies in a bounded time as well as to locate on which parallel segments of the application code (phases) these inefficiencies are generated. The parallel segments of code (phases) represent the most relevant application behavior and are obtained by the application's characterization using the PAS2P tool. The tool allows us to predict the execution time by the generation of the application signature, which is composed of phases. Taking advantage of the prediction quality and the time to obtain the prediction of application performance, we propose modeling the factors that potentially influence the application's execution time, especially characterizing the behavior during the execution time of these phases. We performed experimental validation using signatures of NAS Parallel benchmarks in order to detect and model the inefficiencies in the application phases.},
  keywords={},
  doi={10.1109/HPCS.2017.85},
  ISSN={},
  month={July},}
@INPROCEEDINGS{8035110,
  author={Montezanti, Diego and De Giusti, A. and Naiouf, M. and Villamayor, Jorge and Rexachs, Dolores and Luque, Emilio},
  booktitle={2017 International Conference on High Performance Computing & Simulation (HPCS)}, 
  title={A Methodology for Soft Errors Detection and Automatic Recovery}, 
  year={2017},
  volume={},
  number={},
  pages={434-441},
  abstract={Handling faults is a growing concern in HPC; higher error rates, larger detection intervals and silent faults are expected in the future. It is projected that, in exascale systems, errors will occur several times a day, and they will propagate to generate errors that will range from process crashes to corrupted results because of undetected errors. In this article, we propose a methodology that improves system reliability against transient faults, when running parallel message-passing applications. The proposed solution, based on process replication, has the goal of helping programmers and users of parallel scientific applications to achieve reliable executions with correct results. This work presents a characterization of the strategy, defining its behavior in the presence of faults and modeling the temporal costs of employing it. As a result, we show its efficacy and viability to tolerate transient faults in HPC systems.},
  keywords={},
  doi={10.1109/HPCS.2017.71},
  ISSN={},
  month={July},}
@INPROCEEDINGS{8035112,
  author={Villamayor, Jorge and Rexachs, Dolores and Luque, Emilio},
  booktitle={2017 International Conference on High Performance Computing & Simulation (HPCS)}, 
  title={A Fault Tolerance Manager with Distributed Coordinated Checkpoints for Automatic Recovery}, 
  year={2017},
  volume={},
  number={},
  pages={452-459},
  abstract={Components for High Performance Computing are continuously increasing to achieve more performance and satisfy scientific application users demands. To reduce the Mean Time To Repair in these systems and increment high availability, Fault Tolerance (FT) solutions are required. The checkpoint/restart approach is a widely used mechanism in FT solutions. One of the most used technique to take checkpoints in parallel applications implemented using Message Passing Interface is the coordinated checkpoints. In this paper a Fault Tolerance Manager (FTM) for coordinated checkpoint files is presented, to provide users automatic recovery from failures when losing computing nodes. This proposal makes the configuration of FT simpler and transparent for users without knowledge of their application implementation. Furthermore, system administrators are not required to install libraries in their cluster to support FTM. It takes advantage of node local storage to save checkpoints, and it distributes copies of them along all the computation nodes, avoiding the bottleneck of a central stable storage. This approach is particularly useful in IaaS cloud environments, where users have to pay for centralized stable storage services. This work is based on RADIC, a well- known architecture to provide fault tolerance in a distributed, flexible, automatic and scalable way. Experimental results shows the benefits of the presented approach in a private cluster and a well-known cloud computing environment, Amazon EC2.},
  keywords={},
  doi={10.1109/HPCS.2017.73},
  ISSN={},
  month={July},}
@INPROCEEDINGS{8035128,
  author={Rościszewski, Paweł and Kaliski, Jakub},
  booktitle={2017 International Conference on High Performance Computing & Simulation (HPCS)}, 
  title={Minimizing Distribution and Data Loading Overheads in Parallel Training of DNN Acoustic Models with Frequent Parameter Averaging}, 
  year={2017},
  volume={},
  number={},
  pages={560-565},
  abstract={In the paper we investigate the performance of parallel deep neural network training with parameter averaging for acoustic modeling in Kaldi, a popular automatic speech recognition toolkit. We describe experiments based on training a recurrent neural network with 4 layers of 800 LSTM hidden states on a 100-hour corpora of annotated Polish speech data. We propose a MPI-based modification of the training program which minimizes the overheads of both distributing training jobs and loading and preprocessing training data by using message passing and CPU/GPU computation overlapping. The impact of the proposed optimizations is greater for the more frequent neural network model averaging. To justify our efforts, we examine the influence of averaging frequency on the trained model efficiency. We plot learning curves based on the average log-probability per frame of correct paths for utterances in the validation set, as well as word error rates of test set decodings. Based on experiments with training on 2 workstations with 4 GPUs each we point that for the given network architecture, dataset and computing environment there is a certain range of averaging frequencies that are optimal for the model efficiency. For the selected averaging frequency of 600k frames per iteration the proposed optimizations reduce the training time by 54.9%.},
  keywords={},
  doi={10.1109/HPCS.2017.89},
  ISSN={},
  month={July},}
@INPROCEEDINGS{8048921,
  author={Heinrich, Franz Christian and Cornebize, Tom and Degomme, Augustin and Legrand, Arnaud and Carpen-Amarie, Alexandra and Hunold, Sascha and Orgerie, Anne-Cécile and Quinson, Martin},
  booktitle={2017 IEEE International Conference on Cluster Computing (CLUSTER)}, 
  title={Predicting the Energy-Consumption of MPI Applications at Scale Using Only a Single Node}, 
  year={2017},
  volume={},
  number={},
  pages={92-102},
  abstract={Monitoring and assessing the energy efficiency of supercomputers and data centers is crucial in order to limit and reduce their energy consumption. Applications from the domain of High Performance Computing (HPC), such as MPI applications, account for a significant fraction of the overall energy consumed by HPC centers. Simulation is a popular approach for studying the behavior of these applications in a variety of scenarios, and it is therefore advantageous to be able to study their energy consumption in a cost-efficient, controllable, and also reproducible simulation environment. Alas, simulators supporting HPC applications commonly lack the capability of predicting the energy consumption, particularly when target platforms consist of multi-core nodes. In this work, we aim to accurately predict the energy consumption of MPI applications via simulation. Firstly, we introduce the models required for meaningful simulations: The computation model, the communication model, and the energy model of the target platform. Secondly, we demonstrate that by carefully calibrating these models on a single node, the predicted energy consumption of HPC applications at a larger scale is very close (within a few percents) to real experiments. We further show how to integrate such models into the SimGrid simulation toolkit. In order to obtain good execution time predictions on multi-core architectures, we also establish that it is vital to correctly account for memory effects in simulation. The proposed simulator is validated through an extensive set of experiments with wellknown HPC benchmarks. Lastly, we show the simulator can be used to study applications at scale, which allows researchers to save both time and resources compared to real experiments.},
  keywords={},
  doi={10.1109/CLUSTER.2017.66},
  ISSN={2168-9253},
  month={Sep.},}
@INPROCEEDINGS{8048918,
  author={Tessier, François and Vishwanath, Venkatram and Jeannot, Emmanuel},
  booktitle={2017 IEEE International Conference on Cluster Computing (CLUSTER)}, 
  title={TAPIOCA: An I/O Library for Optimized Topology-Aware Data Aggregation on Large-Scale Supercomputers}, 
  year={2017},
  volume={},
  number={},
  pages={70-80},
  abstract={Reading and writing data efficiently from storage system is necessary for most scientific simulations to achieve good performance at scale. Many software solutions have been developed to decrease the I/O bottleneck. One well-known strategy, in the context of collective I/O operations, is the two-phase I/O scheme. This strategy consists of selecting a subset of processes to aggregate contiguous pieces of data before performing reads/writes. In this paper, we present TAPIOCA, an MPI-based library implementing an efficient topology-aware two-phase I/O algorithm. We show how TAPIOCA can take advantage of double-buffering and one-sided communication to reduce as much as possible the idle time during data aggregation. We also introduce our cost model leading to a topology-aware aggregator placement optimizing the movements of data. We validate our approach at large scale on two leadership-class supercomputers: Mira (IBM BG/Q) and Theta (Cray XC40). We present the results obtained with TAPIOCA on a micro-benchmark and the I/O kernel of a large-scale simulation. On both architectures, we show a substantial improvement of I/O performance compared with the default MPI I/O implementation. On BG/Q+GPFS, for instance, our algorithm leads to a performance improvement by a factor of twelve while on the Cray XC40 system associated with a Lustre filesystem, we achieve an improvement of four.},
  keywords={},
  doi={10.1109/CLUSTER.2017.80},
  ISSN={2168-9253},
  month={Sep.},}
@INPROCEEDINGS{8049000,
  author={Brown, Kevin and Matsuoka, Satoshi},
  booktitle={2017 IEEE International Conference on Cluster Computing (CLUSTER)}, 
  title={Co-locating Graph Analytics and HPC Applications}, 
  year={2017},
  volume={},
  number={},
  pages={659-660},
  abstract={We evaluate the on-node interference caused when co-locating traditional high-performance computing applications with a big-data application. Using kernel benchmarks from the NPB suite and a state-of-art graph analytics code, we explore different process placements and effects they have on application performance. Our results show that the most memory intensive HPC application (MG) experienced the highest performance variation during co-location.},
  keywords={},
  doi={10.1109/CLUSTER.2017.111},
  ISSN={2168-9253},
  month={Sep.},}
@INPROCEEDINGS{8048963,
  author={Dreher, Matthieu and Sasikumar, Kiran and Sankaranarayanan, Subramanian and Peterka, Tom},
  booktitle={2017 IEEE International Conference on Cluster Computing (CLUSTER)}, 
  title={Manala: A Flexible Flow Control Library for Asynchronous Task Communication}, 
  year={2017},
  volume={},
  number={},
  pages={509-519},
  abstract={Tasks coupled in an in situ workflow may not process data at the same speed, potentially causing overflows in the communication channel between them. To prevent this problem, software infrastructures for in situ workflows usually impose a strict FIFO policy that has the side-effect of slowing down faster tasks to the speed of the slower ones. This may not be the desired behavior; for example, a scientist may prefer to drop older data in the communication channel in order to visualize the latest snapshot of a simulation. In this paper, we present Manala, a flexible flow control library designed to manage the flow of messages between a producer and a consumer in an in situ workflow. Manala intercepts messages from the producer, stores them, and selects the message to forward to the consumer depending on the flow control policy. The library is designed to ease the creation of new flow control policies and buffering mechanisms. We demonstrate with three examples how changing the flow control policy between tasks can influence the performance and results of scientific workflows. The first example focuses on materials science with LAMMPS and a synthetic diffraction analysis code. The second example is an interactive visualization scenario with Gromacs as the producer and Damaris/Viz as consumer. Our third example studies different strategies to perform an asynchronous checkpoint with Gromacs.},
  keywords={},
  doi={10.1109/CLUSTER.2017.31},
  ISSN={2168-9253},
  month={Sep.},}
@INPROCEEDINGS{8048947,
  author={Subramoni, Hari and Lu, Xiaoyi and Panda, Dhabaleswar K.},
  booktitle={2017 IEEE International Conference on Cluster Computing (CLUSTER)}, 
  title={A Scalable Network-Based Performance Analysis Tool for MPI on Large-Scale HPC Systems}, 
  year={2017},
  volume={},
  number={},
  pages={354-358},
  abstract={Studying the interaction among applications, MPI runtimes, and the fabric they run on is critical to understanding application performance. There exists no high-performance and scalable tool that enables understanding this interplay on modern multi-petaflop systems. Designing such a tool is non-trivial and involves multiple components including 1) data profiling/collection from network/MPI library, 2) storing and, 3) rendering the data. Furthermore, achieving this with minimal overhead and scalability is a challenging task. We take up this challenge and propose a high-performance and scalable network-based performance analysis tool for MPI libraries operating on modern networks like InfiniBand and Omni-Path. Our designs facilitate caching and pre-rendering, allowing a cluster with 6,541 nodes, 764 switches and, 16,893 network links renders in just 30 seconds - a 44X speed up over non-prerendered solutions. The proposed lock-free and optimized memory-backed storage design enables the tool to handle over a quarter million inserts into the database every 45 seconds (data from 27,504 switch ports and 104,656 MPI processes). The tool has been successfully deployed and validated on HPC systems at OSC and on Comet at SDSC.},
  keywords={},
  doi={10.1109/CLUSTER.2017.78},
  ISSN={2168-9253},
  month={Sep.},}
@INPROCEEDINGS{8054288,
  author={Xiang, Yangxia and Chen, Caisen and Wang, Hongyan and Zhou, Zeyun},
  booktitle={2017 IEEE 2nd Advanced Information Technology, Electronic and Automation Control Conference (IAEAC)}, 
  title={An improved automatic MPI code generation algorithm for parallelizing compilation}, 
  year={2017},
  volume={},
  number={},
  pages={1623-1626},
  abstract={Open64 is an open source compiler with powerful analysis and widely used as a research and commercial development platform. However, it has not been designed and developed to realize MPI parallelization. There are many contributions in the paper. Firstly, the Open64 compiler infrastructure is showed. Secondly, the location of MPI code generation in the Open64 compiler architecture is analyzed. Thirdly, an Open64-based automatic generation algorithm for MPI code is presented. By the experiments of testing the NPB benchmarks, the results show that the approach not only has a high rate of parallel transformation, but also can produce correct MPI parallel programs.},
  keywords={},
  doi={10.1109/IAEAC.2017.8054288},
  ISSN={},
  month={March},}
@INPROCEEDINGS{8056199,
  author={Semba, Kazuki and Katagiri, Hirokatsu and Asanuma, Tatsuya and Miwa, Masahiko and Sano, Hiroyuki and Yamada, Takashi},
  booktitle={2017 20th International Conference on Electrical Machines and Systems (ICEMS)}, 
  title={Realistic and very fast simulation of electric machines and apparatus by using massively parallel processing}, 
  year={2017},
  volume={},
  number={},
  pages={1-5},
  abstract={In this paper, we present the performance of massively parallel processing in finite element electromagnetic field analyses with time periodic explicit error correction. The Domain decomposition technique is used for parallelization, and the Message Passing Interface (MPI) library is used for processing communications. Results show over a 64-fold speed increase compared with the sequential solver, and that it is very effective for designing electric machines and apparatuses in a brief amount of time.},
  keywords={},
  doi={10.1109/ICEMS.2017.8056199},
  ISSN={},
  month={Aug},}
@INPROCEEDINGS{8080064,
  author={Ashraf, M. Usman and Eassa, Fathy Alboraei and Albeshri, Aiiad Ahmad},
  booktitle={2017 8th International Conference on Information Technology (ICIT)}, 
  title={High performance 2-D Laplace equation solver through massive hybrid parallelism}, 
  year={2017},
  volume={},
  number={},
  pages={594-598},
  abstract={High Performance Computing (HPC) is a strategical resource that allows research communities and developers to fulfill the processing demand (1 ExaFlops/Sec) for future Exascale Computing system which is expected in the end of current decade. In order to provide an extensive level of performance, many powerful and energy efficient devices (MIC, GPU) and parallel programming models have been proposed. One solution deal HPC applications is optimized utilization of these parallel computing based devices and programming models. In this paper we have proposed a novel approach hybrid Tri-level parallel computing model. The objective of proposed model was to provide a platform that can render both fine-grain and course-grain parallelism for massive computation. For hybrid proposed model, three promising parallel computing models were considered including CUDA (parallelize GPU thread), OpenMP (parallelize CPU threads) and MPI (communicate among homogeneous / heterogeneous cores). Further to validate proposed model, we considered Gauss Jacobi iterative solver for 2-D Laplace equation and implemented in proposed hybrid model. Experiments performed at various mesh size on conventional CPU and proposed hybrid model. Consequently, hybrid model performed much faster as compared to serial and single GPU computation. Nevertheless, based on significant results, hybrid parallel model could be considered as initiative model to solve other HPC applications in linear / non-linear system.},
  keywords={},
  doi={10.1109/ICITECH.2017.8080064},
  ISSN={},
  month={May},}
@INPROCEEDINGS{8081422,
  author={Lu, Yang and Dai, Wei and Eldar, Yonina C.},
  booktitle={2017 25th European Signal Processing Conference (EUSIPCO)}, 
  title={Optimal number of measurements for compressed sensing with quadratically decreasing SNR}, 
  year={2017},
  volume={},
  number={},
  pages={1319-1323},
  abstract={In this paper, we consider a practical signal transmission application with fixed power budget such as radar/sonar. The system is modeled by a linear equation with the assumption that the signal energy per measurement decreases linearly and the noise energy per measurement increases approximately linearly with the increasing of the number of measurements. Thus the SNR decreases quadratically with the number of measurements. This model suggests an optimal operation point different from the common wisdom where more measurements always mean better performance. Our analysis shows that there is an optimal number of measurements, neither too few nor too many, to minimize the mean-squared error of the estimate. The analysis is based on a state evolution technique which is proposed for the approximate message passing algorithm. We consider the Gaussian, Bernoulli-Gaussian and least-favorite distributions in both real and complex domains. Numerical results justify the correctness of our analysis.},
  keywords={},
  doi={10.23919/EUSIPCO.2017.8081422},
  ISSN={2076-1465},
  month={Aug},}
@INPROCEEDINGS{8102193,
  author={Loussert, Arthur and Welterlen, Benoît and Carribault, Patrick and Jaeger, Julien and Pérache, Marc and Namyst, Raymond},
  booktitle={2017 29th International Symposium on Computer Architecture and High Performance Computing (SBAC-PAD)}, 
  title={Resource-Management Study in HPC Runtime-Stacking Context}, 
  year={2017},
  volume={},
  number={},
  pages={177-184},
  abstract={With the advent of multicore and manycore processors as building blocks of HPC supercomputers, many applications shift from relying solely on a distributed programming model (e.g., MPI) to mixing distributed and shared-memory models (e.g., MPI+OpenMP), to better exploit shared-memory communications and reduce the overall memory footprint. One side effect of this programming approach is runtime stacking: mixing multiple models involve various runtime libraries to be alive at the same time and to share the underlying computing resources. This paper explores different configurations where this stacking may appear and introduces algorithms to detect the misuse of compute resources when running a hybrid parallel application. We have implemented our algorithms inside a dynamic tool that monitors applications and outputs resource usage to the user. We validated this tool on applications from CORAL benchmarks. This leads to relevant information which can be used to improve runtime placement, and to an average overhead lower than 1% of total execution time.},
  keywords={},
  doi={10.1109/SBAC-PAD.2017.30},
  ISSN={},
  month={Oct},}

@INPROCEEDINGS{8109095,
  author={Ayub, Muhammad Sohaib and Rehman, Waqas Ur and Siddiqui, Junaid Haroon},
  booktitle={2017 IEEE 28th International Symposium on Software Reliability Engineering (ISSRE)}, 
  title={Experience Report: Verifying MPI Java Programs Using Software Model Checking}, 
  year={2017},
  volume={},
  number={},
  pages={294-304},
  abstract={Parallel and distributed computing have enabled development of much more scalable software. However, developing concurrent software requires the programmer to be aware of nondeterminism, data races, and deadlocks. MPI (message passing interface) is a popular standard for writing message-oriented distributed applications. Some messages in MPI systems can be processed by one of the many machines and in many possible orders. This non-determinism can affect the result of an MPI application. The alternate results may or may not be correct. To verify MPI applications, we need to check all these possible orderings and use an application specific oracle to decide if these orderings give correct output. MPJ Express is an open source Java implementation of the MPI standard. Model checking of MPI Java programs is a challenging task due to their parallel nature. We developed a Java based model of MPJ Express, where processes are modeled as threads, and which can run unmodified MPI Java programs on a single system. This model enabled us to adapt the Java PathFinder explicit state software model checker (JPF) using a custom listener to verify our model running real MPI Java programs. The evaluation of our approach shows that model checking reveals incorrect system behavior that results in very intricate message orderings.},
  keywords={},
  doi={10.1109/ISSRE.2017.15},
  ISSN={2332-6549},
  month={Oct},}
@INPROCEEDINGS{8124972,
  author={Kyriakakis, Eleftherios and Ngo, Kalle and Öberg, Johnny},
  booktitle={2017 IEEE Nordic Circuits and Systems Conference (NORCAS): NORCHIP and International Symposium of System-on-Chip (SoC)}, 
  title={Implementation of a fault-tolerant, globally-asynchronous-locally-synchronous, inter-chip NoC communication bridge on FPGAs}, 
  year={2017},
  volume={},
  number={},
  pages={1-6},
  abstract={Network-on-Chip (NoC) architectures were introduced to help mitigate the bottleneck and scalability issues faced by the traditional bus interconnect in Multi-Processor System-On Chip (MPSoC). Nowadays, many embedded systems host a significant number of micro-controllers and processors (i.e. vehicles, airplanes, satellites, etc.) and as this number continues to increase, traditional bus solutions will start to fail on those platforms as well. NoCs not only offer a scalable solution for MPSoC interconnects but they can also provide a uniform platform of communication to embedded systems with multiple off-chip, often heterogeneous, processors. This leads to the need for investigation on inter-chip communication bridges suitable for transmitting flits/packets across chips and possibly across clock domains. This paper investigates an inter-chip communication link, of an MPSoC NoC architecture which is extended with an off-chip, heterogeneous processor (node) and proposes a scalable, fault-tolerant, globally asynchronous locally synchronous bridge for inter-chip communication. The proposed bridge is implemented on a prototype board of the SEUD KTH experiment where it successfully enables the communication of a NoC distributed over two FPGAs. The inter-chip bridge is verified in-circuit achieving transfer speeds up to 24 MByte/s (≈ 1.5 Mflit/s) and its ability to correct single bit errors is demonstrated in simulation.},
  keywords={},
  doi={10.1109/NORCHIP.2017.8124972},
  ISSN={},
  month={Oct},}
@INPROCEEDINGS{8121622,
  author={Oana, Liviu and Frincu, Marc},
  booktitle={2017 16th International Symposium on Parallel and Distributed Computing (ISPDC)}, 
  title={Benchmarking the WRF Model on Bluegene/P, Cluster, and Cloud Platforms and Accelerating Model Setup Through Parallel Genetic Algorithms}, 
  year={2017},
  volume={},
  number={},
  pages={78-84},
  abstract={This paper investigates the scalability of WRF (Weather Research and Forecast) model on three different platforms: BlueGene/P, Intel Xeon Cluster and Microsoft Azure cloud at different resolutions and domain sizes. Contrary to prior work we benchmark the model on a cloud platform, analyze the behavior of various individual configurations, and test the scalability of our previously proposed parallel genetic algorithm for physical parametrization of WRF. While we obtain good results on all platforms, the speedup is particularly interesting on the cloud platform, peaking at 10x using OpenMP library with up to 20 processors. This is similar to that achieved on Bluegene/P on 1,024 cores. On the Bluegene/P and Xeon cluster we used the MPI library which provided speedups ranging between 2--10x. Overall, running on Azure or the Xeon cluster is more effective than running experiments on Bluegene/P especially at low resolutions and with few processors. Finally, we tested the scalability of a parallel GA implementation with the purpose of finding optimal physical parametrization settings for WRF and achieved speedups up to 6x which proved superior than those from a similar experiment done in a prior paper.},
  keywords={},
  doi={10.1109/ISPDC.2017.24},
  ISSN={},
  month={July},}
@INPROCEEDINGS{8121620,
  author={Negoita, Gianina Alina and Luecke, Glenn R. and Kraeva, Marina and Prabhu, Gurpur and Vary, James P.},
  booktitle={2017 16th International Symposium on Parallel and Distributed Computing (ISPDC)}, 
  title={The Performance and Scalability of the SHMEM and Corresponding MPI-3 Routines on a Cray XC30}, 
  year={2017},
  volume={},
  number={},
  pages={62-69},
  abstract={In this paper the authors compare the performance and scalability of the SHMEM and corresponding MPI-3 routines for five different benchmark tests using a Cray XC30. The performance of the MPI-3 get and put operations was evaluated using fence synchronization and also using lock-unlock synchronization. The five tests used communication patterns ranging from light to heavy data traffic: accessing distant messages, circular right shift, gather, broadcast and all-to-all. Each implementation was run using message sizes of 8 bytes, 10 Kbytes and 1 Mbyte and up to 768 processes. For nearly all tests, the SHMEM get and put implementations outperformed the MPI-3 get and put implementations. The authors noticed significant performance increase using MPI-3 instead of MPI-2 when compared with performance results from previous studies.},
  keywords={},
  doi={10.1109/ISPDC.2017.19},
  ISSN={},
  month={July},}
@INPROCEEDINGS{8171149,
  author={Hao, Yanming and Xiao, Kexin and Chen, Zhiyong and Xia, Bin},
  booktitle={2017 9th International Conference on Wireless Communications and Signal Processing (WCSP)}, 
  title={Density evolution analysis of LDPC-coded SCMA systems}, 
  year={2017},
  volume={},
  number={},
  pages={1-6},
  abstract={Sparse code multiple access (SCMA) is a promising non-orthogonal multiple access scheme to support massive connectivity. In this paper, we propose a novel scheme to analyze the performance of Low-density Parity-check (LDPC) codes in SCMA systems based on density evolution (DE) theory. In particular, we develop the combination method including channel adapter and log-likelihood ratio (LLR) convertor in conjunction with SCMA detection by leveraging the message passing (MPA) algorithm. For the density evolution analysis of regular and irregular LDPC codes, we design a novel multiuser DE algorithm in SCMA systems with the given principle of minimizing the maximum channel threshold of all users. As the simulation results demonstrate, proposed scheme and algorithm can obtain the channel thresholds close to the system capacity in case of regular LDPC and irregular LDPC codes, and also present the optimal degree distribution for irregular LDPC codes in the SCMA systems.},
  keywords={},
  doi={10.1109/WCSP.2017.8171149},
  ISSN={2472-7628},
  month={Oct},}
@INPROCEEDINGS{8171382,
  author={Amelchenko, Maxim and Dolev, Shlomi},
  booktitle={2017 IEEE 16th International Symposium on Network Computing and Applications (NCA)}, 
  title={Blockchain abbreviation: Implemented by message passing and shared memory (Extended abstract)}, 
  year={2017},
  volume={},
  number={},
  pages={1-7},
  abstract={Blockchain's ever increasing size has become a major problem. Bitcoin [7], for example, has grown to 115120 MB as of May 2017, which is roughly 115 GB. This uncontrollable growth of the Blockchain is bound to become an issue in the future, as hard disks may become too small to store the entire Blockchain history and traversing the transactions databases may become increasingly slow. Already, there are lightweight clients in various Blockchain platforms (Bitcoin included), who do not store the entire chain locally but rely on a third party to send them the blocks they need. There are many issues with these clients, mainly security problems, since they go back to trusting a central authority rather than gaining trust from several distributed peers. These clients' knowledge of the Blockchain is solely based on some third party that should be trusted, while the conceptual base for Blockchain is trust distributing. In this paper we present two Blockchain abbreviation schemes. The first one is based on the Ethereum [8] project and proposes replacing the full Blockchain with a new Genesis block, which summarizes everyone's account balances at a certain point in time. One possible benefit is to use less communication while still storing the prefix of the old Blockchain (or signature of the Blockchain that can validate a version archived by other participants) in a local archive. Here we trade loss of transaction history for efficiency. Our second contribution is a UNIX based architecture using the file system, for implementing Blockchain. We demonstrate a Blockchain abbreviation technique for this architecture too.},
  keywords={},
  doi={10.1109/NCA.2017.8171382},
  ISSN={},
  month={Oct},}
@INPROCEEDINGS{8203471,
  author={Cesarini, Daniele and Bartolini, Andrea and Benini, Luca},
  booktitle={2017 IFIP/IEEE International Conference on Very Large Scale Integration (VLSI-SoC)}, 
  title={Prediction horizon vs. efficiency of optimal dynamic thermal control policies in HPC nodes}, 
  year={2017},
  volume={},
  number={},
  pages={1-6},
  abstract={We are entering the era of thermally-bound computing: Advanced and costly cooling solutions are needed to sustain the high computing densities of high-performance computing equipment. To reduce cooling costs and cooling overprovisioning, dynamic thermal management (DTM) strategies aim at controlling the device temperature by modulating online the performance of processing elements. While operating systems allow the migration of threads between cores, in HPC systems the threads of parallel applications are pinned to the allocated cores at start-time to avoid job-migration overheads. In this scenario state-of-the-art DTM solutions, which use thermal models to map jobs to cores, are based on long-term predictions to map the most critical job to the coldest core. Instead, turbo-mode and DVFS controllers are based on short-term predictions to squeeze the thermal capacitance allowing for short period performance boosts which are thermally unsustainable. In this work we propose an integer-linear programming formulation and a fast solver for controlling, at the same time, the job mapping and cores frequency selections in HPC nodes, tested with real supercomputer workload. Our approach can be integrated with the MPI runtimes and OpenMP libraries and is capable of assigning high-performance cores to performance-critical threads. We show that by combining long and short term predictions with information of the programming model we can significantly improve the performance of final application w.r.t. state-of-the-art DTM solutions.},
  keywords={},
  doi={10.1109/VLSI-SoC.2017.8203471},
  ISSN={2324-8440},
  month={Oct},}
@INPROCEEDINGS{8181485,
  author={Tripathi, Anand and Hoang, Henry},
  booktitle={2017 IEEE 3rd International Conference on Collaboration and Internet Computing (CIC)}, 
  title={Design of a Location-Based Publish/Subscribe Service Using a Graph-Based Computing Model}, 
  year={2017},
  volume={},
  number={},
  pages={97-106},
  abstract={We present here the initial results of our investigation of a system architecture for location-based publish/subscribe services utilizing a graph-based model for managing data and computations. This architecture is implemented on a cluster computer using the facilities and the computation model provided by the Beehive framework which supports a transactional model of parallel computing on dynamic graph data structures. We implemented a Museum Visitor Service as an example of a location-based publish/subscribe system to study and evaluate the performance this approach. This service includes features utilizing location-based publish/subscribe functions for supporting coordination and collaboration among members in a social group visiting the museum. We implemented a testbed system for this service and evaluated its performance on a cluster computer. Our work also illustrates that weaker consistency models for transactions can be utilized in such services to achieve higher performance and scalability.},
  keywords={},
  doi={10.1109/CIC.2017.00024},
  ISSN={},
  month={Oct},}
@INPROCEEDINGS{8227780,
  author={Meidlinger, Michael and Matz, Gerald},
  booktitle={2017 IEEE 18th International Workshop on Signal Processing Advances in Wireless Communications (SPAWC)}, 
  title={On irregular LDPC codes with quantized message passing decoding}, 
  year={2017},
  volume={},
  number={},
  pages={1-5},
  abstract={Irregular low-density parity-check (LDPC) codes are among the best codes currently known. Unfortunately, the performance of existing codes may deteriorate substantially with practical finite-precision decoder implementations. This motivates us to extend our previous work on finite-alphabet decoders based on look-up tables (LUTs) to irregular LDPC codes. We devise a joint design of the LUTs used for different node degrees and present a strategy to optimize the degree distribution (DD) of the LDPC code under LUT decoding. Numerical simulations show that with 4-bit LUT decoding the resulting codes outperform state-of-the-art codes with floating point min-sum (MS) decoding.},
  keywords={},
  doi={10.1109/SPAWC.2017.8227780},
  ISSN={1948-3252},
  month={July},}
@INPROCEEDINGS{8227386,
  author={Vu, Huynh The and Wilkinson, Richardt H. and Lech, Margaret and Cheng, Eva},
  booktitle={2017 International Conference on Digital Image Computing: Techniques and Applications (DICTA)}, 
  title={A Comparison between Anatomy-Based and Data-Driven Tree Models for Human Pose Estimation}, 
  year={2017},
  volume={},
  number={},
  pages={1-7},
  abstract={Tree structures are commonly used to model relationships between body parts for articulated Human Pose Estimation (HPE). Tree structures can be used to model relationships among feature maps of joints in a structured learning framework using Convolutional Neural Networks (CNNs). This paper proposes new data-driven tree models for HPE. The data-driven tree structures were obtained using the Chow-Liu Recursive Grouping (CLRG) algorithm, representing the joint distribution of human body joints and tested using the Leeds Sports Pose (LSP) dataset. The paper analyzes the effect of the variation of the number of nodes on the accuracy of the HPE. Experimental results showed that the data-driven tree model obtained 1% higher HPE accuracy compared to the traditional anatomy-based model. A further improvement of 0.5% was obtained by optimizing the number of nodes in the traditional anatomy-based model.},
  keywords={},
  doi={10.1109/DICTA.2017.8227386},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{8240193,
  author={Teague, Bryan and Liu, Zhenyu and Meyer, Florian and Win, Moe Z.},
  booktitle={2017 IEEE 9th Latin-American Conference on Communications (LATINCOM)}, 
  title={Peregrine: 3-D network localization and navigation}, 
  year={2017},
  volume={},
  number={},
  pages={1-6},
  abstract={Location-aware devices will create new services and applications in emerging fields such as autonomous driving, smart cities, and the Internet of Things. Many existing localization systems rely on anchors such as satellites at known positions which broadcast radio signals. However, such signals may be blocked by obstacles, corrupted by multipath propagation, or provide insufficient localization accuracy. Therefore, ubiquitous localization remains an extremely challenging problem. This paper introduces Peregrine, a 3-D cooperative network localization and navigation (NLN) system. Peregrine nodes are low-cost business-card-sized devices, consisting of a microprocessor, a commercially available ultra-wideband (UWB) radio module, and a small battery. Recently developed distributed algorithms are used in Peregrine to solve the highly interrelated problems of node inference and node activation in real-time, enabling resource efficiency, scalability, and accuracy for NLN. Node inference-based on the recently introduced sigma point belief propagation (SPBP) algorithm-enables spatiotemporal cooperation in realtime and estimates the nodes' positions accurately from UWB distance measurements. A distributed node activation algorithm controls channel access to improve the efficiency and reduce the localization error of the network. Contributions of each algorithmic component to overall system performance are validated through indoor localization experiments. Our results show that Peregrine achieves decimeter-level 3-D position accuracy in a challenging propagation environment.},
  keywords={},
  doi={10.1109/LATINCOM.2017.8240193},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{8241093,
  author={Younge, Andrew J. and Pedretti, Kevin and Grant, Ryan E. and Brightwell, Ron},
  booktitle={2017 IEEE International Conference on Cloud Computing Technology and Science (CloudCom)}, 
  title={A Tale of Two Systems: Using Containers to Deploy HPC Applications on Supercomputers and Clouds}, 
  year={2017},
  volume={},
  number={},
  pages={74-81},
  abstract={Containerization, or OS-level virtualization has taken root within the computing industry. However, container utilization and its impact on performance and functionality within High Performance Computing (HPC) is still relatively undefined. This paper investigates the use of containers with advanced supercomputing and HPC system software. With this, we define a model for parallel MPI application DevOps and deployment using containers to enhance development effort and provide container portability from laptop to clouds or supercomputers. In this endeavor, we extend the use of Sin- gularity containers to a Cray XC-series supercomputer. We use the HPCG and IMB benchmarks to investigate potential points of overhead and scalability with containers on a Cray XC30 testbed system. Furthermore, we also deploy the same containers with Docker on Amazon's Elastic Compute Cloud (EC2), and compare against our Cray supercomputer testbed. Our results indicate that Singularity containers operate at native performance when dynamically linking Cray's MPI libraries on a Cray supercomputer testbed, and that while Amazon EC2 may be useful for initial DevOps and testing, scaling HPC applications better fits supercomputing resources like a Cray.},
  keywords={},
  doi={10.1109/CloudCom.2017.40},
  ISSN={2330-2186},
  month={Dec},}
@INPROCEEDINGS{8243569,
  author={Wang, Silu and Su, Lingfeng and Zhang, Jingrui},
  booktitle={2017 Chinese Automation Congress (CAC)}, 
  title={MPI based PSO algorithm for the optimization problem in micro-grid energy management system}, 
  year={2017},
  volume={},
  number={},
  pages={4479-4483},
  abstract={Most artificial intelligence optimization algorithms tend to increase the size of the population to get better global search capability. However, the increase of population size will add operation time. In order to improve the operational efficiency, this paper proposes a message passing interface (MPI) based particle swarm optimization (PSO) algorithm to solve the multi-period optimization problem in micro-grid energy management system. MPI based PSO algorithm splits the original single process task into multi-process parallel tasks. It can greatly improves the operation speed by making full use of the server's logical Central Processing Unit (CPU). The IEEE 9 buses system is employed to test the presented method. The obtained result shows the merit of the proposed method in improving operation time.},
  keywords={},
  doi={10.1109/CAC.2017.8243569},
  ISSN={},
  month={Oct},}
@INPROCEEDINGS{8241534,
  author={Arellanes, Damian and Lau, Kung-Kiu},
  booktitle={2017 IEEE 10th Conference on Service-Oriented Computing and Applications (SOCA)}, 
  title={Exogenous Connectors for Hierarchical Service Composition}, 
  year={2017},
  volume={},
  number={},
  pages={125-132},
  abstract={Service composition is currently done by (hierarchical) orchestration and choreography. However, these approaches do not support explicit control flow and total compositionality, which are crucial for the scalability of service-oriented systems. In this paper, we propose exogenous connectors for service composition. These connectors support both explicit control flow and total compositionality in hierarchical service composition. To validate and evaluate our proposal, we present a case study based on the popular MusicCorp.},
  keywords={},
  doi={10.1109/SOCA.2017.25},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{8254230,
  author={Chi, Yuhao and Liu, Lei and Song, Guanghui and Yuen, Chau and Guan, Yong Liang and Li, Ying},
  booktitle={GLOBECOM 2017 - 2017 IEEE Global Communications Conference}, 
  title={Message Passing in C-RAN: Joint User Activity and Signal Detection}, 
  year={2017},
  volume={},
  number={},
  pages={1-6},
  abstract={In cloud radio access network (C-RAN), remote radio heads (RRHs) and users are uniformly distributed in a large area such that the channel matrix can be considered as sparse. Based on this phenomenon, RRHs only need to detect the relatively strong signals from nearby users and ignore the weak signals from far users, which is helpful to develop low-complexity detection algorithms without causing much performance loss. However, before detection, RRHs require to obtain the realtime user activity information by the dynamic grant procedure, which causes the enormous latency. To address this issue, in this paper, we consider a grant-free C-RAN system and propose a low- complexity Bernoulli-Gaussian message passing (BGMP) algorithm based on the sparsified channel, which jointly detects the user activity and signal. Since active users are assumed to transmit Gaussian signals at any time, the user activity can be regarded as a Bernoulli variable and the signals from all users obey a Bernoulli-Gaussian distribution. In the BGMP, the detection functions for signals are designed with respect to the Bernoulli-Gaussian variable. Numerical results demonstrate the robustness and effectivity of the BGMP. That is, for different sparsified channels, the BGMP can approach the mean-square error (MSE) of the genie-aided sparse minimum mean-square error (GA- SMMSE) which exactly knows the user activity information. Meanwhile, the fast convergence and strong recovery capability for user activity of the BGMP are also verified.},
  keywords={},
  doi={10.1109/GLOCOM.2017.8254230},
  ISSN={},
  month={Dec},}
@ARTICLE{8204560,
  author={Daszczuk, Wiktor B.},
  journal={The Computer Journal}, 
  title={Communication and Resource Deadlock Analysis Using IMDS Formalism and Model Checking}, 
  year={2017},
  volume={60},
  number={5},
  pages={729-750},
  abstract={Modern static deadlock detection techniques deal with the global properties of the verified systems, using methods that explore the state space. Local features, like partial deadlocks or individual process terminations, are not easily expressed or checked by such methods. Also the distinction between communication deadlocks and resource deadlocks, common in dynamic waits-for methods, cannot be addressed or verified by static methods. An Integrated Model of Distributed Systems (IMDS) is proposed which specifies distributed systems as sets of servers’ states, sets of messages and sets of actions. The message passing/resource sharing dualism of distributed systems is provided by projections: on servers (server view) and on agents (agent view), yet the uniform specification of a verified system is preserved. A progress of computation is defined in terms of actions which change (local) states and generate messages. Distributed actions do not depend on global states and are independent from one another. Therefore, local features of subsystems can be easily described in IMDS. Communication and resource deadlocks can be handled separately and total and partial deadlocks and terminations can be distinguished from each other. Integration of IMDS with model checking is outlined and temporal formulas for deadlock and termination checking are discussed.},
  keywords={},
  doi={10.1093/comjnl/bxw099},
  ISSN={1460-2067},
  month={April},}
@INPROCEEDINGS{8264848,
  author={Sterz, Artur and Baumgärtner, Lars and Mogk, Ragnar and Mezini, Mira and Freisleben, Bernd},
  booktitle={2017 IFIP Networking Conference (IFIP Networking) and Workshops}, 
  title={DTN-RPC: Remote procedure calls for disruption-tolerant networking}, 
  year={2017},
  volume={},
  number={},
  pages={1-9},
  abstract={Remote Procedure Calls (RPCs) realize client-server interactions via a request-response message-passing protocol. They simplify distributed application programming by eliminating the need for explicitly having to code the details of a remote interaction. However, none of the existing RPC implementations are designed to work properly for Delay/Disruption-Tolerant Networking (DTN) where network connectivity is periodic, intermittent, and prone to disruptions. In this paper, we present DTN- RPC, a new approach to provide RPCs for DTN environments. DTN-RPC relies on (a) control and data channels to cope with potentially short contact durations in DTN where large amounts of data cannot be transmitted, (b) explicit and implicit modes to address remote servers, (c) Non-DTN and DTN transport protocols for issuing calls and receiving results, and (d) predicates that servers check to decide whether a procedure should be executed. The implementation of DTN-RPC is based on Serval, an open-source, disruption-tolerant wireless ad-hoc networking system. Our experimental results indicate that the measured CPU and network overheads for DTN-RPC are reasonably low so that it can be executed on smartphones or routers, and that the round-trip times and the number of successful RPCs are highly satisfactory in dynamic networks with unstable links.},
  keywords={},
  doi={10.23919/IFIPNetworking.2017.8264848},
  ISSN={},
  month={June},}
@INPROCEEDINGS{8269200,
  author={Hou, Lu and Lei, Lei and Zheng, Kan},
  booktitle={2017 IEEE Globecom Workshops (GC Wkshps)}, 
  title={Design on Publish/Subscribe Message Dissemination for Vehicular Networks with Mobile Edge Computing}, 
  year={2017},
  volume={},
  number={},
  pages={1-6},
  abstract={The safety messages in vehicular networks require to be transmitted as fast as possible. On the other hand, the high mobility of vehicles poses an other major challenge on efficient message disseminations. In this paper, we present a design on publish/subscribe message dissemination (DPSMD) for vehicular networks with Mobile Edge Computing (MEC). Our design consists of message brokers that provide message exchange services, message handlers that excavate the potential value of messages and message hubs that bridge different parts of the system. MEC can be made use of in DPSMD to provide low-latency message services for vehicle users, while wide- area message disseminations are also well supported. The detailed descriptions is then given, including topic designs, subscription, publishing processes and message validating. Finally, a testbed is built up to evaluate the performance of the DPSMD in terms of the average time of message distributions.},
  keywords={},
  doi={10.1109/GLOCOMW.2017.8269200},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{8273306,
  author={Kulikov, Igor and Chernykh, Igor},
  booktitle={2017 Ivannikov ISPRAS Open Conference (ISPRAS)}, 
  title={Numerical Modeling of Jellyfish Galaxy at Intel Xeon Phi Supercomputers}, 
  year={2017},
  volume={},
  number={},
  pages={104-109},
  abstract={In this paper we propose several AstroPhi code tests for numerical modeling of astrophysical flows. We used RSC PetaStream architecture supercomputers based on Intel Xeon Phi accelerators for this tests. The co-design of a computational model for the description of astrophysical objects is described in his paper. The parallel implementation and scalability tests of the AstroPhi code are presented. The research of the gas giant atmosphere behavior at their interaction with a stellar wind is given in paper. We achieve a 134x speedup with one Intel Xeon Phi accelerator and 75% weak scaling efficiency with using of 224x Intel Xeon Phi accelerators.},
  keywords={},
  doi={10.1109/ISPRAS.2017.00024},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{8287756,
  author={Potluri, Sreeram and Goswami, Anshuman and Rossetti, Davide and Newburn, C.J. and Venkata, Manjunath Gorentla and Imam, Neena},
  booktitle={2017 IEEE 24th International Conference on High Performance Computing (HiPC)}, 
  title={GPU-Centric Communication on NVIDIA GPU Clusters with InfiniBand: A Case Study with OpenSHMEM}, 
  year={2017},
  volume={},
  number={},
  pages={253-262},
  abstract={GPUs have become an essential component for building compute clusters with high compute density and high performance per watt. As such clusters scale to have 1000s of GPUs, efficiently moving data between the GPUs becomes imperative to get maximum performance. NVSHMEM is an implementation of the OpenSHMEM standard for NVIDIA GPU clusters which allows communication to be issued from inside GPU kernels. In earlier work, we have shown how NVSHMEM can be used to achieve better application performance on GPUs connected through PCIe or NVLink. As part of this effort, we implement IB verbs for Mellanox InfiniBand adapters in CUDA. We evaluate different design alternatives, taking into consideration the relaxed memory model, automatic memory access coalescing and thread hierarchy on the GPU. We also consider correctness issues that arise in these designs. We take advantage of these designs transparently or through API extensions in NVSHMEM. With micro-benchmarks, we show that a Nvidia Pascal P100 GPU is able saturate the network bandwidth using only one or two of its 56 available streaming multiprocessors (SM). On a single GPU using a single IB EDR adapter, we achieve a throughput of around 90 million messages per second. In addition, we implement a 2dstencil application kernel using NVSHMEM and compare its performance with a CUDA-aware MPI-based implementation that uses GPUDirect RDMA. Speedups in the range of 23% to 42% are seen for input sizes large enough to fill the occupancy of Nvidia Pascal P100 GPUs on 2 to 4 nodes indicating that there are gains to be had by eliminating the CPU from the communication path when all computation runs on the GPU.},
  keywords={},
  doi={10.1109/HiPC.2017.00037},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{8291951,
  author={Saxena, Gaurav and Jimack, Peter K. and Walkley, Mark A.},
  booktitle={2017 IEEE 19th International Conference on High Performance Computing and Communications; IEEE 15th International Conference on Smart City; IEEE 3rd International Conference on Data Science and Systems (HPCC/SmartCity/DSS)}, 
  title={A Cache-Aware Approach to Adaptive Mesh Refinement in Parallel Stencil-Based Solvers}, 
  year={2017},
  volume={},
  number={},
  pages={364-371},
  abstract={In prior-research the authors have demonstrated that, for stencil-based numerical solvers for Partial Differential Equations (PDEs), the parallel performance can be significantly improved by selecting sub-domains that are not cubic in shape (Saxena et. al., HPCS 2016, pp. 875-885). This is achieved through accounting for cache utilization in both the message passing and the computational kernel, where it is demonstrated that the optimal domain decompositions not only depend on the communication and load balance but also on the cache-misses, amongst other factors. In this work we demonstrate that those conclusions may also be extended to more advanced numerical discretizations, based upon Adaptive Mesh Refinement (AMR). In particular, we show that when basing our AMR strategy on the local refinement of patches of the mesh, the optimal patch shape is not typically cubic. We provide specific examples, with accompanying explanation, to show that communication minimizing strategies are not necessarily the best choice when applying AMR in parallel. All numerical tests undertaken in this work are based upon the open source BoxLib library.},
  keywords={},
  doi={10.1109/HPCC-SmartCity-DSS.2017.48},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{8291974,
  author={Cui, Xiaolong and Znati, Taieb and Melhem, Rami},
  booktitle={2017 IEEE 19th International Conference on High Performance Computing and Communications; IEEE 15th International Conference on Smart City; IEEE 3rd International Conference on Data Science and Systems (HPCC/SmartCity/DSS)}, 
  title={Rejuvenating Shadows: Fault Tolerance with Forward Recovery}, 
  year={2017},
  volume={},
  number={},
  pages={547-554},
  abstract={In today's large-scale High Performance Computing (HPC) systems, an increasing portion of the computing capacity is wasted due to failures and recoveries. It is expected that exascale machines will decrease the mean time between failures to a few hours, making fault tolerance a major challenge. This work explores novel methodologies to fault tolerance that achieve forward recovery, power-awareness, and scalability. The proposed model, referred to as Rejuvenating Shadows, is able to deal with multiple types of failure and maintain consistent level of resilience. An implementation is provided for MPI, and empirically evaluated with various benchmark applications that represent a wide range of HPC workloads. The results demonstrate Rejuvenating Shadows' ability to tolerate high failure rates, and to outperform in-memory checkpointing/restart in both execution time and resource utilization.},
  keywords={},
  doi={10.1109/HPCC-SmartCity-DSS.2017.71},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{8299744,
  author={Patel, Dharmesh J. and Engineer, Pinalkumar},
  booktitle={2017 International Conference on Wireless Communications, Signal Processing and Networking (WiSPNET)}, 
  title={Design and implementation of quasi cyclic low density parity check (QC-LDPC) code on FPGA}, 
  year={2017},
  volume={},
  number={},
  pages={181-185},
  abstract={Low density parity check (LDPC) code is a widely used error correcting code in various applications such as Wi-Fi, Wi-Max and Digital Video Broadcasting - Satellite - Second Generation (DVB-S2). Proposed work is focused on LDPC decoder design using soft decision iterative message passing for a code length 222 bits, 546 bits, 642 bits, 648 bits and 1152 bits that gives BER of 10-5 with coding gain of approximately 4 dB. Proposed work shows fully parallel design on isolated shifted identity matrices based on structured construction quasi cyclic low density parity check code (QC-LDPC) that give throughput of 2 Gbps.},
  keywords={},
  doi={10.1109/WiSPNET.2017.8299744},
  ISSN={},
  month={March},}
@INPROCEEDINGS{8323593,
  author={Huang, Song},
  booktitle={2017 Eighth International Green and Sustainable Computing Conference (IGSC)}, 
  title={Research on power saving and energy efficiency for data-centric computing on production HPC systems}, 
  year={2017},
  volume={},
  number={},
  pages={1-3},
  abstract={Energy consumption has become one of the four key challenges when Department of Energy (DOE) plans to deploy its first exascale supercomputer by 2021. With advanced power management technologies, building a power-saving and energy-efficient exascale computer with faster computing capability becomes possible. To achieve this goal, it is crucial to characterize the power and energy consumption on modern computer hardware and runtime systems. In my dissertation research, I configure the execution environment in various settings and profile and characterize the power and energy consumption on Intel Haswell Enterprise processor, which is currently used in the new Trinity supercomputer hosted at Los Alamos National Laboratory. I also study the power and energy characteristics of a data-centric HPC runtime system, i.e., the Legion runtime and applications, jointed developed by Stanford University and Los Alamos National Laboratory. The experimental results show that the settings of P-States and hyperthreading have a significant impact on the power and energy consumption. Additionally, the data-centric Legion runtime and applications achieve better energy efficiency compared with the MPI computing paradigm.},
  keywords={},
  doi={10.1109/IGCC.2017.8323593},
  ISSN={},
  month={Oct},}
@INPROCEEDINGS{8326618,
  author={Takayanagi, Masatoshi and Suzuki, Tomohiro},
  booktitle={2017 IEEE 11th International Symposium on Embedded Multicore/Many-core Systems-on-Chip (MCSoC)}, 
  title={Construction of Performance Model of Tile CAQR and Performance Result of the Implementation}, 
  year={2017},
  volume={},
  number={},
  pages={151-157},
  abstract={Highly parallel computational resources can be exploited by asynchronously executing many fine-grained tasks. The tile algorithm for matrix decomposition can generate many fine-grained tasks, so is suitable for modern multicore/manycore architectures. However, the performance of this algorithm significantly depends on the tile size. We implement the tile algorithm in OpenMP/MPI hybrid fashion on a cluster system and construct a performance model that tunes the tile size by measuring the performance of simple computational kernels in our implementation. In this report, we test our communication-avoiding tile QR implementation for tall and skinny matrices on the K computer, and demonstrate the applicability of the performance model.},
  keywords={},
  doi={10.1109/MCSoC.2017.18},
  ISSN={},
  month={Sep.},}
@INPROCEEDINGS{8326619,
  author={Li, Zuqing and Goyal, Aakashdeep and Kimm, Haklin},
  booktitle={2017 IEEE 11th International Symposium on Embedded Multicore/Many-core Systems-on-Chip (MCSoC)}, 
  title={Parallel Longest Common Sequence Algorithm on Multicore Systems Using OpenACC, OpenMP and OpenMPI}, 
  year={2017},
  volume={},
  number={},
  pages={158-165},
  abstract={The longest common subsequence (LCS) problem is one of the most useful algorithms being applied in various research areas. This problem is known to be NP-hard for arbitrary data. In this paper, we present a parallel LCS algorithm using the GPU-based OpenACC model, which is based on the existing dynamic approach and parallel anti-diagonal scheme that is applied in order to eliminate the data dependencies. The proposed algorithm in this paper has been benchmarked using four different computing models: OpenMPI, OpenMP, hybrid OpenMPI&OpenMP, and OpenACC model. The parallel LCS algorithm has been implemented using Swiss-Prot databases over these computing models, so that their execution times, speed-ups and speed-ratios have been measured and analogized among them extensively. Our experimental results reveal that the computation of our algorithm on OpenACC (on GPU) is around 16 times faster than the execution on a single CPU, and around 2 times faster than on the octa-core processor systems. The performance of the OpenACC model stands out among the four tested models in solving the LCS problem.},
  keywords={},
  doi={10.1109/MCSoC.2017.13},
  ISSN={},
  month={Sep.},}
@INPROCEEDINGS{8332562,
  author={Sandeep, P.R. and Yerragudi, V. S. and Gangadhar, N.D.},
  booktitle={2017 IEEE International Conference on Cloud Computing in Emerging Markets (CCEM)}, 
  title={CANTAV: A Cloud Centric Framework for Navigation and Control of Autonomous Road Vehicles}, 
  year={2017},
  volume={},
  number={},
  pages={99-106},
  abstract={Autonomous vehicles are becoming a new trend in automotive industry. The rapid developments in this field portend to a future where current vehicles are replaced by autonomous ones. There is a need for sophisticated and responsive traffic control mechanisms for such future systems. There is also a need for generic framework for developing and studying autonomous road traffic systems. This paper describes the design and development of a Cloud centric Architecture and simulation framework for Navigation and Traffic control of Autonomous Vehicles (CANTAV) for developing navigation and control systems for automated vehicles and vehicular traffic. The framework is based on message passing which is extensible. It is designed to provide facilities for navigating the vehicle, clear traffic congestion by re-routing traffic. As interfacing such an architecture with real world autonomous vehicles is not feasible, and no existing simulation framework supports such an architecture, an agent based simulation framework, CANTAV simulation framework, is developed for simulation and visualisation of road networks and autonomous vehicular traffic on them. The developed system was tested and validated successfully using several scenarios. Performance of the system is analysed from the system and vehicle perspectives for different transportation network and vehicle arrangements in the system.},
  keywords={},
  doi={10.1109/CCEM.2017.20},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{8345458,
  author={Boku, Taisuke and Ishikawa, Ken-Ichi and Kuramashi, Yoshinobu and Meadows, Lawrence},
  booktitle={2017 Fifth International Symposium on Computing and Networking (CANDAR)}, 
  title={Mixed Precision Solver Scalable to 16000 MPI Processes for Lattice Quantum Chromodynamics Simulations on the Oakforest-PACS System}, 
  year={2017},
  volume={},
  number={},
  pages={362-368},
  abstract={Lattice Quantum Chromodynamics (Lattice QCD) is a quantum field theory on a finite discretized space-time box so as to numerically compute the dynamics of quarks and gluons to explore the nature of subatomic world. Solving the equation of motion of quarks (quark solver) is the most compute-intensive part of the lattice QCD simulations and is one of the legacy HPC applications. We have developed a mixed-precision quark solver for a large Intel Xeon Phi (KNL) system named "Oakforest-PACS", employing the O(a)-improved Wilson quarks as the discretized equation of motion. The nested-BiCGSTab algorithm for the solver was implemented and optimized using mixed-precision, communication-computation overlapping with MPI-offloading, SIMD vectorization, and thread stealing techniques. The solver achieved 2.6 PFLOPS in the single-precision part on a 400^3 × 800 lattice using 16000 MPI processes on 8000 nodes on the system.},
  keywords={},
  doi={10.1109/CANDAR.2017.69},
  ISSN={2379-1896},
  month={Nov},}
@INPROCEEDINGS{8368425,
  author={Latham, Rob and Bautista-Gomez, Leonardo and Balaji, Pavan},
  booktitle={2017 IEEE 23rd International Conference on Parallel and Distributed Systems (ICPADS)}, 
  title={Portable Topology-Aware MPI-I/O}, 
  year={2017},
  volume={},
  number={},
  pages={710-719},
  abstract={Recent advances in storage devices are opening new opportunities in high-performance computing (HPC). Technologies such as solid-state drives (SSD) and non-volatile memories (NVM) are becoming increasingly popular because of the important gains they can represent for HPC. Indeed, novel architectures with deeper storage hierarchies populated with SSDs and/or NVM offer new ways to improve applications' performance. For instance, fast multilevel checkpointing or in-situ data analysis are some of the techniques that can be greatly improved thanks to these new technologies. However, optimizations made for one system can impose performance costs in another machine due to topology differences. To take advantage of increasingly complex systems, we propose extensions to MPI enabling codes to determine which nodes of a system share common features. Our approach provides a portable mechanism for resource discovery. It also lays the foundation for additional optimizations in checkpointing and in ROMIO. In this paper we present the design and implementation of such a feature and test it with multiple benchmarks. Our results demonstrate the benefits of this portable resource discovery functionality.},
  keywords={},
  doi={10.1109/ICPADS.2017.00096},
  ISSN={1521-9097},
  month={Dec},}
@INPROCEEDINGS{8371946,
  author={Li, Xue and Zhang, Richong and Li, Jianxin},
  booktitle={2017 IEEE 29th International Conference on Tools with Artificial Intelligence (ICTAI)}, 
  title={User Interest Propagation and Its Application in Recommender System}, 
  year={2017},
  volume={},
  number={},
  pages={218-222},
  abstract={User interest prediction plays an important role in online services, such as electronic commerce, social network, and online advertising. This information is not always explicitly available for online systems. To identify the interests, existing studies merely focused on modeling the relationships between user generated contents and user interests. However, the interests of a user should not only be inferred by user generated contents, but also the relationships between users which might imply the user interests. In this paper, our goal is to unveil the true interests of users based on user generated contents as well as relationships between users. We built a probabilistic user interests model and proposed a user interests propagation algorithm (UIP) to tackle this problem. A factor graph-based approach is utilized to estimate the distribution of the interests of users. We conducted experiments on real-world datasets to validate the effectiveness of the model. Furthermore, we integrated our UIP algorithm with the classical matrix factorization algorithm to deal with the rating prediction task. Experimental studies confirm the superiority of the proposed approach.},
  keywords={},
  doi={10.1109/ICTAI.2017.00043},
  ISSN={2375-0197},
  month={Nov},}
@INPROCEEDINGS{8411994,
  author={Borovska, Plamenka and Gancheva, Veska and Georgiev, Ivailo and Ivanova, Desislava},
  booktitle={2017 European Conference on Electrical Engineering and Computer Science (EECS)}, 
  title={Hybrid Parallel Multiple Sequence Alignment Based on Artificial Bee Colony on the Supercomputer JUQUEEN}, 
  year={2017},
  volume={},
  number={},
  pages={47-51},
  abstract={The paper focuses on performance investigation and improvement of multiple biological sequence alignment software MSA_BG on the BlueGene/Q supercomputer JUQUEEN. For this purpose, scientific experiments in the area of bioinformatics have been carried out, using as case study influenza virus sequences. The objectives of the investigation are code optimization, porting, scaling, profiling and performance evaluation of MSA_BG software. To this end we have developed hybrid MPI/OpenMP parallelization on the top of the MPI only code and we showcase the advantages of this approach through the results of benchmark tests, performed on JUQUEEN. The experimental results show that the hybrid parallel implementation provides considerably better performance than the original code.},
  keywords={},
  doi={10.1109/EECS.2017.18},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{8463871,
  author={Mikhail, Abrosimov and Kareem, Hayder Hussein and Mahajan, Hemant},
  booktitle={2017 International Conference on Computing, Communication, Control and Automation (ICCUBEA)}, 
  title={Fault Tolerance to Balance for Messaging Layers in Communication Society}, 
  year={2017},
  volume={},
  number={},
  pages={1-5},
  abstract={The present communication societies are based on use of High-Performance Computing (HPC) systems for balancing the messaging layers. However the HPC systems are vulnerable to different types of software and hardware failures which resulted into extra efforts to resume the working of such systems. Into the communication framework because of this type of vulnerabilities it was creating misbalancing around the layers of message passing. Hence there is need of fault tolerance methods in such HPC systems. There are different solutions proposed for efficient fault tolerance in HPC systems, but suffered from various limitations. The check pointing/restart technique is most commonly & frequently studied technique. Therefore in this research goal is to present efficient and new check pointing/restart method of fault tolerance in HPC systems for MPI (Message Passing Interface) application in order to balance the messaging layers. For fault tolerant systems checking the pointing consist as most important function, but additional overhead was the main problem of restriction for the method of fault tolerance due to the pointing check or the extra storage wanted to be both or check the pointer it is creating the issues to program added time. Hence, we wanted to develop the new enhanced application which helped to checkpoint restart technique for the applications of MPI. this check point method are supported by efficient & trusted distributed storage system, This kind of checkpoints assuring the availability of data at the time of hardware failure.},
  keywords={},
  doi={10.1109/ICCUBEA.2017.8463871},
  ISSN={},
  month={Aug},}
@INPROCEEDINGS{8560922,
  author={Yao, Zhuo and Wang, Dali and Sun, Jinyuan and Zhong, Dong},
  booktitle={2017 International Conference on Computational Science and Computational Intelligence (CSCI)}, 
  title={A Unit Testing Framework for Scientific Legacy Code}, 
  year={2017},
  volume={},
  number={},
  pages={940-944},
  abstract={Large-scale scientific applications play important roles in supporting research. However, it is often very expensive and time-consuming to make changes to, maintain and evolve the scientific code due to its complexity and poor programming skills of researchers. Therefore, in order to visualize scientific code architecture to optimize software design, understand undocumented source code, and analyze software flow and functionality, we first introduce a unit testing framework (UTF). Then, because such infrastructure's performance is very crucial in practical use since the scientific legacy applications simulate instances in a long period of time, we improve the UTF by applying Message Passing based Parallelization and parallel I/O operations. Furthermore, due to the scientific code has enormous state data and the I/O capacity on the server is limited, we apply in situ data analysis method to encounter fewer resource limitations, and adopt signal processing to greatly reduce data transfer. Last, we demonstrated the correctness and high-efficiency of our framework for legacy Earth model on Titan supercomputer.},
  keywords={},
  doi={10.1109/CSCI.2017.163},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{9926258,
  author={Liao, Chunhua and Lin, Pei-Hung and Asplund, Joshua and Schordan, Markus and Karlin, Ian},
  booktitle={SC17: International Conference for High Performance Computing, Networking, Storage and Analysis}, 
  title={DataRaceBench: A Benchmark Suite for Systematic Evaluation of Data Race Detection Tools}, 
  year={2017},
  volume={},
  number={},
  pages={1-14},
  abstract={Data races in multi-threaded parallel applications are notoriously damaging while extremely difficult to detect. Many tools have been developed to help programmers find data races. However, there is no dedicated OpenMP benchmark suite to systematically evaluate data race detection tools for their strengths and limitations. In this paper, we present DataRaceBench, an open-source benchmark suite designed to systematically and quantitatively evaluate the effectiveness of data race detection tools. We focus on data race detection in programs written in OpenMP, the popular parallel programming model for multi-threaded applications. In particular, DataRaceBench includes a set of microbenchmark programs with or without data races. These microbenchmarks are either manually written, extracted from real scientific applications, or automatically generated optimization variants. We also define several metrics to represent effectiveness and efficiency of data race detection tools. Using DataRaceBench and its metrics, we evaluate four different data race detection tools: Helgrind, ThreadSanitizer, Archer, and Intel Inspector. The evaluation results show that DataRaceBench is effective to provide comparable, quantitative results and discover strengths and weaknesses of the tools being evaluated. CCS Concepts • Software and its engineering $\rightarrow$ Software verification and validation; Correctness; • Computing methodologies $\rightarrow$ Parallel programming languages;},
  keywords={},
  doi={},
  ISSN={2167-4337},
  month={Nov},}
@INPROCEEDINGS{9926240,
  author={Li, Hongbo and Chen, Zizhong and Gupta, Rajiv},
  booktitle={SC17: International Conference for High Performance Computing, Networking, Storage and Analysis}, 
  title={ParaStack: Efficient Hang Detection for MPI Programs at Large Scale}, 
  year={2017},
  volume={},
  number={},
  pages={1-12},
  abstract={While program hangs on large parallel systems can be detected via the widely used timeout mechanism, it is difficult for the users to set the timeout-too small a timeout leads to high false alarm rates and too large a timeout wastes a vast amount of valuable computing resources. To address the above problems with hang detection, this paper presents ParaStack, an extremely lightweight tool to detect hangs in a timely manner with high accuracy, negligible overhead with great scalability, and without requiring the user to select a timeout value. For a detected hang, it provides direction for further analysis by telling users whether the hang is the result of an error in the computation phase or the communication phase. For a computation-error induced hang, our tool pinpoints the faulty process by excluding hundreds and thousands of other processes. We have adapted ParaStack to work with the Torque and Slurm parallel batch schedulers and validated its functionality and performance on Tianhe-2 and Stampede that are respectively the world’s current 2nd and 12th fastest supercomputers. Experimental results demonstrate that ParaStack detects hangs in a timely manner at negligible overhead with over 99% accuracy. No false alarm is observed in correct runs taking 66 hours at scale of 256 processes and 39.7 hours at scale of 1024 processes. ParaStack accurately reports the faulty process for computation-error induced hangs.},
  keywords={},
  doi={},
  ISSN={2167-4337},
  month={Nov},}
@ARTICLE{7581042,
  author={Kargarian, Amin and Mohammadi, Javad and Guo, Junyao and Chakrabarti, Sambuddha and Barati, Masoud and Hug, Gabriela and Kar, Soummya and Baldick, Ross},
  journal={IEEE Transactions on Smart Grid}, 
  title={Toward Distributed/Decentralized DC Optimal Power Flow Implementation in Future Electric Power Systems}, 
  year={2018},
  volume={9},
  number={4},
  pages={2574-2594},
  abstract={This paper reviews distributed/decentralized algorithms to solve the optimal power flow (OPF) problem in electric power systems. Six decomposition coordination algorithms are studied, including analytical target cascading, optimality condition decomposition, alternating direction method of multipliers, auxiliary problem principle, consensus+innovations, and proximal message passing. The basic concept, the general formulation, the application for dc-OPF, and the solution methodology for each algorithm are presented. We apply these six decomposition coordination algorithms on a test system, and discuss their key features and simulation results.},
  keywords={},
  doi={10.1109/TSG.2016.2614904},
  ISSN={1949-3061},
  month={July},}
@ARTICLE{7802590,
  author={Sumati, Vuppuluri and Patvardhan, C.},
  journal={IEEE Transactions on Fuzzy Systems}, 
  title={Interval Type-2 Mutual Subsethood Fuzzy Neural Inference System (IT2MSFuNIS)}, 
  year={2018},
  volume={26},
  number={1},
  pages={203-215},
  abstract={This paper presents an interval type-2 mutual subsethood fuzzy neural inference system (IT2MSFuNIS). A mutual subsethood measure between two interval type-2 fuzzy sets (IT2 FS) has been derived and has been used in determining the similarity between the IT2 FS inputs and IT2 FS antecedents. The consequent weights are taken to be interval sets. The inputs to the system are fuzzified into IT2 FSs with Gaussian primary membership function having fixed center and uncertain variance. Aggregation of type-2 mutual subsethood based activation spreads is performed using product operator. The output is obtained using simplified type-reduction followed by defuzzification. The system learns using memetic procedure involving differential evolution for global search and gradient descent for local exploitation in solution space. The mathematical modeling and empirical studies of IT2MSFuNIS bring forth its efficacy in problems pertaining to function approximation, time-series prediction, control, and classification. Comparisons with other type-1 and type-2 neuro-fuzzy systems verify that IT2MSFuNIS compares excellently with other models with a performance better than most of them both in terms of total number of trainable parameters and result accuracy. Empirical studies indicate the intelligent decision making capability of the proposed model. The main contribution of this paper lies in the identification of mutual subsethood to find out the correlation between IT2 FSs and to find out its applicability in diverse application domains. The improved performance of the proposed method can be attributed to the better contrast handling capacity of mutual subsethood method and uncertainty handling capacity of IT2 FSs. The integration of mutual subsethood with interval type-2 fuzzy logic puts forth a novel model with various merits as demonstrated amply with the help of well-known problems reported in the literature.},
  keywords={},
  doi={10.1109/TFUZZ.2016.2646750},
  ISSN={1941-0034},
  month={Feb},}
@ARTICLE{7932530,
  author={Bianchi, Francesco Adalberto and Margara, Alessandro and Pezzè, Mauro},
  journal={IEEE Transactions on Software Engineering}, 
  title={A Survey of Recent Trends in Testing Concurrent Software Systems}, 
  year={2018},
  volume={44},
  number={8},
  pages={747-783},
  abstract={Many modern software systems are composed of multiple execution flows that run simultaneously, spanning from applications designed to exploit the power of modern multi-core architectures to distributed systems consisting of multiple components deployed on different physical nodes. We collectively refer to such systems as concurrent systems. Concurrent systems are difficult to test, since the faults that derive from their concurrent nature depend on the interleavings of the actions performed by the individual execution flows. Testing techniques that target these faults must take into account the concurrency aspects of the systems. The increasingly rapid spread of parallel and distributed architectures led to a deluge of concurrent software systems, and the explosion of testing techniques for such systems in the last decade. The current lack of a comprehensive classification, analysis and comparison of the many testing techniques for concurrent systems limits the understanding of the strengths and weaknesses of each approach and hampers the future advancements in the field. This survey provides a framework to capture the key features of the available techniques to test concurrent software systems, identifies a set of classification criteria to review and compare the available techniques, and discusses in details their strengths and weaknesses, leading to a thorough assessment of the field and paving the road for future progresses.},
  keywords={},
  doi={10.1109/TSE.2017.2707089},
  ISSN={1939-3520},
  month={Aug},}
@ARTICLE{7990272,
  author={Kim, Jonghoon and Mamou, Jonathan and Hill, Paul R. and Canagarajah, Nishan and Kouamé, Denis and Basarab, Adrian and Achim, Alin},
  journal={IEEE Transactions on Ultrasonics, Ferroelectrics, and Frequency Control}, 
  title={Approximate Message Passing Reconstruction of Quantitative Acoustic Microscopy Images}, 
  year={2018},
  volume={65},
  number={3},
  pages={327-338},
  abstract={A novel framework for compressive sensing (CS) data acquisition and reconstruction in quantitative acoustic microscopy (QAM) is presented. Three different CS patterns, adapted to the specifics of QAM systems, were investigated as an alternative to the current raster-scanning approach. They consist of diagonal sampling, a row random, and a spiral scanning pattern and can all significantly reduce both the acquisition time and the amount of sampled data. For subsequent image reconstruction, we design and implement an innovative technique, whereby a recently proposed approximate message passing method is adapted to account for the underlying data statistics. A Cauchy maximum a posteriori image denoising algorithm is thus employed to account for the non-Gaussianity of QAM wavelet coefficients. The proposed methods were tested retrospectively on experimental data acquired with a 250- or 500-MHz QAM system. The experimental data were obtained from a human lymph node sample (250 MHz) and human cornea (500 MHz). Reconstruction results showed that the best performance is obtained using a spiral sensing pattern combined with the Cauchy denoiser in the wavelet domain. The spiral sensing matrix reduced the number of spatial samples by a factor of 2 and led to an excellent peak signal-to-noise ratio of 43.21 dB when reconstructing QAM speed-of-sound images of a human lymph node. These results demonstrate that the CS approach could significantly improve scanning time, while reducing costs of future QAM systems.},
  keywords={},
  doi={10.1109/TUFFC.2017.2731627},
  ISSN={1525-8955},
  month={March},}
@ARTICLE{8010315,
  author={Pakazad, Sina Khoshfetrat and Hansson, Anders and Andersen, Martin S. and Rantzer, Anders},
  journal={IEEE Transactions on Automatic Control}, 
  title={Distributed Semidefinite Programming With Application to Large-Scale System Analysis}, 
  year={2018},
  volume={63},
  number={4},
  pages={1045-1058},
  abstract={Distributed algorithms for solving coupled semidefinite programs commonly require many iterations to converge. They also put high computational demand on the computational agents. In this paper, we show that in case the coupled problem has an inherent tree structure, it is possible to devise an efficient distributed algorithm for solving such problems. The proposed algorithm relies on predictor-corrector primal-dual interior-point methods, where we use a message-passing algorithm to compute the search directions distributedly. Message passing here is closely related to dynamic programming over trees. This allows us to compute the exact search directions in a finite number of steps. This is because computing the search directions requires a recursion over the tree structure and, hence, terminates after an upward and downward pass through the tree. Furthermore, this number can be computed a priori and only depends on the coupling structure of the problem. We use the proposed algorithm for analyzing robustness of large-scale uncertain systems distributedly. We test the performance of this algorithm using numerical examples.},
  keywords={},
  doi={10.1109/TAC.2017.2739644},
  ISSN={1558-2523},
  month={April},}
@ARTICLE{8068239,
  author={Panadero, Javier and Wong, Alvaro and Rexachs, Dolores and Luque, Emilio},
  journal={IEEE Transactions on Parallel and Distributed Systems}, 
  title={P3S: A Methodology to Analyze and Predict Application Scalability}, 
  year={2018},
  volume={29},
  number={3},
  pages={642-658},
  abstract={Executing message-passing parallel applications on a large number of resources in an efficient way is not a trivial task. Due to the complex interaction between the parallel applications and the HPC system, many applications may suffer performance inefficiencies when they scale. To achieve an efficient use of these large-scale systems using thousands of cores, a point to consider before executing an application is to know its behavior in the system. In this work, we propose a novel methodology called P3S (Prediction of Parallel Program Scalability), which allows us to analyze and predict the scalability of message-passing applications on a given system. The methodology strives to use a bounded analysis time, and a reduced set of resources to predict the application behavior for large-scale. The experimental validation proves that the P3S is able to predict the application scalability with an average accuracy greater than 95 percent using a reduced set of resources.},
  keywords={},
  doi={10.1109/TPDS.2017.2763148},
  ISSN={1558-2183},
  month={March},}
@ARTICLE{8074806,
  author={Al-Shoukairi, Maher and Schniter, Philip and Rao, Bhaskar D.},
  journal={IEEE Transactions on Signal Processing}, 
  title={A GAMP-Based Low Complexity Sparse Bayesian Learning Algorithm}, 
  year={2018},
  volume={66},
  number={2},
  pages={294-308},
  abstract={In this paper, we present an algorithm for the sparse signal recovery problem that incorporates damped Gaussian generalized approximate message passing (GGAMP) into expectation-maximization-based sparse Bayesian learning (SBL). In particular, GGAMP is used to implement the E-step in SBL in place of matrix inversion, leveraging the fact that GGAMP is guaranteed to converge with appropriate damping. The resulting GGAMP-SBL algorithm is much more robust to arbitrary measurement matrix A than the standard damped GAMP algorithm while being much lower complexity than the standard SBL algorithm. We then extend the approach from the single measurement vector case to the temporally correlated multiple measurement vector case, leading to the GGAMP-TSBL algorithm. We verify the robustness and computational advantages of the proposed algorithms through numerical experiments.},
  keywords={},
  doi={10.1109/TSP.2017.2764855},
  ISSN={1941-0476},
  month={Jan},}
@ARTICLE{8113527,
  author={Ghanaatian, Reza and Balatsoukas-Stimming, Alexios and Müller, Thomas Christoph and Meidlinger, Michael and Matz, Gerald and Teman, Adam and Burg, Andreas},
  journal={IEEE Transactions on Very Large Scale Integration (VLSI) Systems}, 
  title={A 588-Gb/s LDPC Decoder Based on Finite-Alphabet Message Passing}, 
  year={2018},
  volume={26},
  number={2},
  pages={329-340},
  abstract={An ultrahigh throughput low-density parity-check (LDPC) decoder with an unrolled full-parallel architecture is proposed, which achieves the highest decoding throughput compared to previously reported LDPC decoders in the literature. The decoder benefits from a serial message-transfer approach between the decoding stages to alleviate the well-known routing congestion problem in parallel LDPC decoders. Furthermore, a finite-alphabet message passing algorithm is employed to replace the VN update rule of the standard min-sum (MS) decoder with lookup tables, which are designed in a way that maximizes the mutual information between decoding messages. The proposed algorithm results in an architecture with reduced bit-width messages, leading to a significantly higher decoding throughput and to a lower area compared to an MS decoder when serial message transfer is used. The architecture is placed and routed for the standard MS reference decoder and for the proposed finite-alphabet decoder using a custom pseudo-hierarchical backend design strategy to further alleviate routing congestions and to handle the large design. Postlayout results show that the finite-alphabet decoder with the serial message-transfer architecture achieves a throughput as large as 588 Gb/s with an area of 16.2 mm2 and dissipates an average power of 22.7 pJ per decoded bit in a 28-nm fully depleted silicon on isulator library. Compared to the reference MS decoder, this corresponds to 3.1 times smaller area and 2 times better energy efficiency.},
  keywords={},
  doi={10.1109/TVLSI.2017.2766925},
  ISSN={1557-9999},
  month={Feb},}
@ARTICLE{8207605,
  author={Liu, Xingcheng and Xiong, Feng and Wang, Zhongfeng and Liang, Shuo},
  journal={IEEE Transactions on Communications}, 
  title={Design of Binary LDPC Codes With Parallel Vector Message Passing}, 
  year={2018},
  volume={66},
  number={4},
  pages={1363-1375},
  abstract={Many studies were carried out for the construction of low density parity-check (LDPC) codes. They usually focused on introducing the construction methods for good LDPC codes instead of a general method for code optimization. This paper proposes a method with high versatility, called the parallel vector message passing-based edge exchange (PMPE), for optimizing a type of graph-based LDPC codes, without changing the code parameters of mother codes, such as the code length, code rate, and degree distribution. With the approximately nearest codewords searching approach, we find the optimization method can increase the Hamming distance of the LDPC codes. For the quasi-cyclic (QC) LDPC codes, an optimization method, called the parallel vector message passing oriented-to the QC-LDPC codes (QC-PMP), is further suggested, with which the quasi-cyclic characteristics of QC-LDPC codes can remain unchanged in the optimization. To evaluate the performance of the parity-check matrix corresponding to a Tanner graph, a very simple metric, the cycles metric, is introduced to work with the proposed PMPE and QC-PMP algorithms. The experimental results show that the performance of the LDPC codes optimized with the proposed PMPE can be improved significantly at low BER range compared with the mother codes of the random codes, including the regular MacKay code of rate 0.5 and the regular PEG code of rate 0.9. For the case of the regular and irregular QC-LDPC codes with different code lengths and code rates, the optimized LDPC codes with the proposed QC-PMP algorithm significantly outperform the mother codes.},
  keywords={},
  doi={10.1109/TCOMM.2017.2783624},
  ISSN={1558-0857},
  month={April},}
@ARTICLE{8293844,
  author={Li, Shang and Wang, Xiaodong},
  journal={IEEE Transactions on Information Theory}, 
  title={Fully Distributed Sequential Hypothesis Testing: Algorithms and Asymptotic Analyses}, 
  year={2018},
  volume={64},
  number={4},
  pages={2742-2758},
  abstract={This paper analyzes the asymptotic performances of fully distributed sequential hypothesis testing procedures as the type-I and type-II error rates approach zero, in the context of a sensor network without a fusion center. In particular, the sensor network is defined by an undirected graph, where each sensor can observe samples over time, access the information from the adjacent sensors, and perform the sequential test based on its own decision statistic. Different from most literature, the sampling process and the information exchange process in our framework take place simultaneously (or, at least in comparable time-scales), thus cannot be decoupled from one another. Our goal is to achieve second-order asymptotically optimal performance at every sensor, i.e., the average detection delay is within a constant gap from the centralized optimal sequential test as the error rates approach zero for the fixed number of sensors. To that end, a type of test procedure that resembles the well-known sequential probability ratio test (SPRT), termed as distributed SPRT (DSPRT) in this paper, is studied based on two message-passing schemes, respectively. The first scheme features the dissemination of the raw samples. In specific, every sample propagates over the network by being relayed from one sensor to another until it reaches all the sensors in the network. Although the sample propagation-based DSPRT is shown to yield the asymptotically optimal performance at each sensor, it incurs excessive intersensor communication overhead due to the exchange of raw samples with index information. The second scheme adopts the consensus algorithm, where the local decision statistic is exchanged between sensors instead of the raw samples, thus significantly lowering the communication requirement compared with the first scheme. In particular, the decision statistic for DSPRT at each sensor is updated by the weighted average of the decision statistics in the neighborhood at every message-passing step. We show that, under certain regularity conditions, the consensus algorithm-based DSPRT also yields the secondorder asymptotically optimal performance at all sensors given a fixed number of sensors. Our asymptotic analyses of the two message-passing-based DSPRTs are then corroborated by simulations using the Gaussian and Laplacian samples.},
  keywords={},
  doi={10.1109/TIT.2018.2806961},
  ISSN={1557-9654},
  month={April},}
@INPROCEEDINGS{8301671,
  author={Freedman, Riana J. and Valles, Damian},
  booktitle={2018 IEEE 8th Annual Computing and Communication Workshop and Conference (CCWC)}, 
  title={A communication benchmark tailored to intel broadwell nodes and tuned to the DEAC cluster}, 
  year={2018},
  volume={},
  number={},
  pages={502-508},
  abstract={Various benchmarks exist for assessing performance characteristics of commodity hardware utilized in high performance computing (HPC) cluster environments. An additional assessment of bandwidth for Intel's 44-core processors considers network saturation via message passing focused on indirectly connected cores. The benchmark developed in this work provides a means of measuring bandwidth of two Broadwell nodes when communicating inter-chassis with all cores of each node utilized. This benchmark was developed in three phases using Message Passing Interface (MPI). First, the bandwidth measure was tested for MPI_Send operations in point-to-point communication. Second, the merge sort algorithm was implemented as a means of assessing bandwidth and a tree-structured communication algorithm was developed and implemented to maximize internode communication and minimize intra-node communication. Third, the benchmark was tuned to the configuration of the Distributed Environment for Academic Computing (DEAC) Cluster. A second benchmark removing local computation from the merge sort algorithm effectively performs a gather operation in a tree-structure. These benchmarks were tested and compared with relevant Intel MPI Benchmarks (IMB) tests. In the developed benchmarks, the nodes requested significantly more bandwidth than in the existing MPI_Gather operation and IMB benchmarks due to the large size of the messages simultaneously placed on the network.},
  keywords={},
  doi={10.1109/CCWC.2018.8301671},
  ISSN={},
  month={Jan},}
@ARTICLE{8307171,
  author={Barakatain, Masoud and Kschischang, Frank R.},
  journal={Journal of Lightwave Technology}, 
  title={Low-Complexity Concatenated LDPC-Staircase Codes}, 
  year={2018},
  volume={36},
  number={12},
  pages={2443-2449},
  abstract={A low-complexity soft-decision concatenated FEC scheme, consisting of an inner LDPC code and an outer staircase code, is proposed. The inner code is tasked with reducing the bit error probability below the outer-code threshold. The concatenated code is obtained by optimizing the degree distribution of the inner-code ensemble to minimize estimated data-flow, for various choices of outer staircase codes. A key feature that emerges from this optimization is that it pays to leave some inner codeword bits completely uncoded, thereby greatly reducing a significant portion of the decoding complexity. The tradeoff between required signal-to-noise ratio and decoding complexity of the designed codes is characterized by a Pareto frontier. Computer simulations of the resulting codes reveals that the net coding-gains of existing designs can be achieved with up to 71% reduction in complexity. A hardware-friendly quasi-cyclic construction is given for the inner codes, which can realize an energy-efficient decoder implementation, and even further complexity reductions via a layered message-passing decoder schedule.},
  keywords={},
  doi={10.1109/JLT.2018.2812738},
  ISSN={1558-2213},
  month={June},}
@ARTICLE{8307478,
  author={Soatti, Gloria and Nicoli, Monica and Garcia, Nil and Denis, Benoît and Raulefs, Ronald and Wymeersch, Henk},
  journal={IEEE Transactions on Intelligent Transportation Systems}, 
  title={Implicit Cooperative Positioning in Vehicular Networks}, 
  year={2018},
  volume={19},
  number={12},
  pages={3964-3980},
  abstract={Absolute positioning of vehicles is based on Global Navigation Satellite Systems (GNSSs) combined with on-board sensors and high-resolution maps. In cooperative intelligent transportation systems, the positioning performance can be augmented by means of vehicular networks that enable vehicles to share location-related information. This paper presents an implicit cooperative positioning (ICP) algorithm that exploits the Vehicle-to-Vehicle (V2V) connectivity in an innovative manner, avoiding the use of explicit V2V measurements such as ranging. In the ICP approach, vehicles jointly localize non-cooperative physical features (such as people, traffic lights, or inactive cars) in the surrounding areas, and use them as common noisy reference points to refine their location estimates. Information on sensed features are fused through V2V links by a consensus procedure, nested within a message passing algorithm, to enhance the vehicle localization accuracy. As positioning does not rely on explicit ranging information between vehicles, the proposed ICP method is amenable to implementation with off-the-shelf vehicular communication hardware. The localization algorithm is validated in different traffic scenarios, including a crossroad area with heterogeneous conditions in terms of feature density and V2V connectivity, and a real urban area by using Simulation of Urban MObility (SUMO) for traffic data generation. Performance results show that the proposed ICP method can significantly improve the vehicle location accuracy compared to the stand-alone GNSS, especially in harsh environments, such as in urban canyons, where the GNSS signal is highly degraded or denied.},
  keywords={},
  doi={10.1109/TITS.2018.2794405},
  ISSN={1558-0016},
  month={Dec},}
@ARTICLE{8316261,
  author={Yuan, Weijie and Wu, Nan and Guo, Qinghua and Li, Yonghui and Xing, Chengwen and Kuang, Jingming},
  journal={IEEE Transactions on Wireless Communications}, 
  title={Iterative Receivers for Downlink MIMO-SCMA: Message Passing and Distributed Cooperative Detection}, 
  year={2018},
  volume={17},
  number={5},
  pages={3444-3458},
  abstract={The rapid development of mobile communications requires even higher spectral efficiency. Non-orthogonal multiple access (NOMA) has emerged as a promising technology to further increase the access efficiency of wireless networks. Among several NOMA schemes, it has been shown that sparse code multiple access (SCMA) is able to achieve better performance. In this paper, we consider a downlink MIMO-SCMA system over frequency selective fading channels. For optimal detection, the complexity increases exponentially with the product of the number of users, the number of antennas and the channel length. To tackle this challenge, we propose near optimal low-complexity iterative receivers based on factor graph. By introducing auxiliary variables, a stretched factor graph is constructed and a hybrid belief propagation (BP) and expectation propagation (EP) receiver, named stretch-BP-EP, is proposed. Considering the convergence problem of BP algorithm on loopy factor graph, we convexify the Bethe free energy and propose a convergence-guaranteed BP-EP receiver, named conv-BP-EP. We further consider cooperative network and propose two distributed cooperative detection schemes to exploit the diversity gain, namely, belief consensus-based algorithm and the Bregman alternative direction method of multipliers (ADMM)-based method. Simulation results verify the superior performance of the proposed conv-BP-EP receiver compared with other methods. The two proposed distributed cooperative detection schemes can improve the bit error rate performance by exploiting the diversity gain. Moreover, Bregman ADMM method outperforms the belief consensus-based algorithm in noisy inter-user links.},
  keywords={},
  doi={10.1109/TWC.2018.2813378},
  ISSN={1558-2248},
  month={May},}
@ARTICLE{8325488,
  author={Berghoff, Marco and Kondov, Ivan and Hötzer, Johannes},
  journal={IEEE Transactions on Parallel and Distributed Systems}, 
  title={Massively Parallel Stencil Code Solver with Autonomous Adaptive Block Distribution}, 
  year={2018},
  volume={29},
  number={10},
  pages={2282-2296},
  abstract={In the last decades, simulations have been established in several fields of science and industry to study various phenomena by solving, inter alia, partial differential equations. For an efficient use of current and future high performance computing systems, with many thousands of computation ranks, high node-level performance, scalable communication, and the omission of unnecessary calculations are of high priority in the development of new solvers. The challenge of contemporary simulation applications is to bridge the gap between the scales of the various physical processes. We introduce the NAStJA framework, a block-based MPI parallel solver for arbitrary algorithms, based on stencil code or other regular grid methods. NAStJA decomposes the domain of spatially complex structures into small cuboid blocks. A special feature of NAStJA is the dynamic block adaption which modifies the calculation domain around the region where the computation currently takes place, and hence avoids unnecessary calculations. This often occurs, inter alia, in phase-field simulations. Block creation and deletion is managed autonomously within local neighborhoods. A basic load balancing mechanism allows a re-distribution of newly created blocks to the involved computing ranks. The use of a multi-hop network, to distribute information to the entire domain, avoids collective all-gather communications. Thus, we can demonstrate excellent scaling. The present scaling tests substantiate the enormous advantage of this adaptive method. For certain simulation scenarios, we can show that the calculation effort and memory consumption can be reduced to only 3.5 percent, compared to the classical full-domain reference simulation. The overhead of 70-100 percent for the dynamic adapting block creation is significantly lower than the gain. The approach is not restricted to phase-field simulations, and can be employed in other domains of computational science to exploit sparsity of computing regions.},
  keywords={},
  doi={10.1109/TPDS.2018.2819672},
  ISSN={1558-2183},
  month={Oct},}
@INPROCEEDINGS{8328220,
  author={Saxena, Neetesh and Grijalva, Santiago and Choi, Bong Jun},
  booktitle={2018 10th International Conference on Communication Systems & Networks (COMSNETS)}, 
  title={Securing restricted publisher-subscriber communications in smart grid substations}, 
  year={2018},
  volume={},
  number={},
  pages={364-371},
  abstract={Smart Grid applications require accurate and correct data transmission from publisher to subscribers with critical communication latency requirements. Since the smart grid is being supported by distributed communication networks, deployed using various wired and wireless technologies, including IP-based networks, securing the communication infrastructure is both critically important and challenging. In this paper, we propose a secure and efficient data delivery scheme, based on a restricted yet dynamic publisher-subscriber architecture, for the published messages from a publisher to the subscribers distributed in the smart grid network. The scheme ensures that the published message is delivered from an authentic publisher to only those authorized subscribers by verifying publisher's signature and access structure of all subscribers. Operation overheads are reduced by performing only one encryption and decryption or hashing per subscriber location using a proxy node as a remote terminal unit. Our analysis shows that the scheme is resistant against replay, man-in-the-middle, and impersonation attacks. Performance evaluation shows that the scheme can support 600 subscribers given the communication latency requirement of 3 ms. We provide the performance of the scheme under different scenarios, and observe that the efficiency of our scheme increases as the ratio of the geographical locations within a substation to the number of subscribers increases.},
  keywords={},
  doi={10.1109/COMSNETS.2018.8328220},
  ISSN={2155-2509},
  month={Jan},}
@ARTICLE{8345273,
  author={Takahashi, Keichi and Date, Susumu and Khureltulga, Dashdavaa and Kido, Yoshiyuki and Yamanaka, Hiroaki and Kawai, Eiji and Shimojo, Shinji},
  journal={IEEE Access}, 
  title={UnisonFlow: A Software-Defined Coordination Mechanism for Message-Passing Communication and Computation}, 
  year={2018},
  volume={6},
  number={},
  pages={23372-23382},
  abstract={Message passing interface (MPI) communication performance is becoming one of the key factors heavily affecting the total performance of data-intensive applications running on computer clusters. Our software-defined networking (SDN)-enhanced MPI improves the performance of communication over interconnects by integrating flexible and dynamic network controllability of SDN into MPI. We have demonstrated that the acceleration of individual MPI communication primitives is feasible through our past work on the SDN-enhanced MPI. However, real-world MPI applications have not benefited from such accelerated communication primitives through our research achievements to date, because each of the distinct network control algorithms designed for various MPI communication primitives cannot be activated and coordinated with the execution of the MPI application. Therefore, this paper proposes UnisonFlow, a software-defined coordination mechanism for the SDN-enhanced MPI that performs network control in synchronization with the execution of applications. An experiment conducted on a real-computer cluster verifies that the interconnect control can be successfully performed in synchronization with the execution of the application. Furthermore, the synchronization is performed with a low overhead and its performance penalty is practically negligible.},
  keywords={},
  doi={10.1109/ACCESS.2018.2829532},
  ISSN={2169-3536},
  month={},}
@INPROCEEDINGS{8346363,
  author={Akram, Wasim and Hussain, Tassadaq and Ayguade, Eduard},
  booktitle={2018 International Conference on Computing, Mathematics and Engineering Technologies (iCoMET)}, 
  title={FPGA and ARM processor based supercomputing}, 
  year={2018},
  volume={},
  number={},
  pages={1-5},
  abstract={The low-cost and low-power heterogeneous architecture platform such as Xilinx Zynq SoC provides an extensive combination of ARM multi-core processor with FPGA accelerator for acceleration of high performance computing applications. In this paper, we proposed an FPGA and ARM processor based supercomputer system composed of five Zynq SoCs compute-nodes. The design system uses message passing interface libraries for communication between compute-nodes while AXI4-stream interfaces between ARM processor and FPGA inside a compute-node. An FIR filter application is used to test the performance of the system with and without FPGA accelerators. The results show that the performance of ARM based supercomputer with FPGA accelerators is 8.56 times higher than similar system without FPGA accelerators.},
  keywords={},
  doi={10.1109/ICOMET.2018.8346363},
  ISSN={},
  month={March},}
@ARTICLE{8359193,
  author={Lalitha, Anusha and Javidi, Tara and Sarwate, Anand D.},
  journal={IEEE Transactions on Information Theory}, 
  title={Social Learning and Distributed Hypothesis Testing}, 
  year={2018},
  volume={64},
  number={9},
  pages={6161-6179},
  abstract={This paper considers a problem of distributed hypothesis testing over a network. Individual nodes in a network receive noisy local (private) observations whose distribution is parameterized by a discrete parameter (hypothesis). The marginals of the joint observation distribution conditioned on each hypothesis are known locally at the nodes, but the true parameter/hypothesis is not known. An update rule is analyzed in which nodes first perform a Bayesian update of their belief (distribution estimate) of each hypothesis based on their local observations, communicate these updates to their neighbors, and then perform a “non-Bayesian” linear consensus using the log-beliefs of their neighbors. Under mild assumptions, we show that the belief of any node on a wrong hypothesis converges to zero exponentially fast. We characterize the exponential rate of learning, which we call the network divergence, in terms of the nodes’ influence of the network and the divergences between the observations’ distributions. For a broad class of observation statistics which includes distributions with unbounded support such as Gaussian mixtures, we show that rate of rejection of wrong hypothesis satisfies a large deviation principle, i.e., the probability of sample paths on which the rate of rejection of wrong hypothesis deviates from the mean rate vanishes exponentially fast and we characterize the rate function in terms of the nodes’ influence of the network and the local observation models.},
  keywords={},
  doi={10.1109/TIT.2018.2837050},
  ISSN={1557-9654},
  month={Sep.},}
@INPROCEEDINGS{8361297,
  author={Duan, Liming and Gai, Rongli and Guo, Ruifeng and Zhong, Ray Y. and Wang, Fenghai},
  booktitle={2018 IEEE 15th International Conference on Networking, Sensing and Control (ICNSC)}, 
  title={Linking events-based communication mechanism in multi-agent systems}, 
  year={2018},
  volume={},
  number={},
  pages={1-5},
  abstract={Multi-agent systems (MAS) consist of several independent agents with decision-making ability. Each agent has the ability of communication and perception. It can adjust the running state through messages interaction for achieving global optimization. The accuracy and efficiency of messages transfer among agents has a decisive impact on the performance of the MAS due to the complexity between problems. In this paper, the transfer of the messages in large distributed MAS is studied and the method of messages transfer through linking events is proposed. Firstly, the characteristics of messages in MAS are analyzed and the information model based on MAS is defined. Then, the messages are formatted and classified and the relationship between different events is established. After that, the messages can be transmitted according to the relationship between events. The proposed messages transfer method through linking events is validated by applying this method in an industry information system. The results show a efficient transmission of messages between agents. Furthermore, it can extract associated events from mess messages, and provides feedback of the running state of MAS.},
  keywords={},
  doi={10.1109/ICNSC.2018.8361297},
  ISSN={},
  month={March},}
@INPROCEEDINGS{8363398,
  author={Madritsch, Christian and Klinger, Thomas},
  booktitle={2018 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Work in progress: Computing cluster using IoT technologies}, 
  year={2018},
  volume={},
  number={},
  pages={1428-1431},
  abstract={This paper describes the design, implementation, and practical use in Engineering Education of a Computing Cluster using IoT Technologies. First, the development goal and its expected application is explained. Current lectures in Computer Science, Computer Engineering and Image Processing will benefit of the massive parallel computing cluster. Next, the design and implementation - carried out by a group of students - are described in detail. Finally, the practical use of the cluster including a test application is shown. Here, current supercomputing methods like Message Passing Interface (MPI) and Open Multi Processing (OpenMP) are used to show the ability and functionality go the cluster.},
  keywords={},
  doi={10.1109/EDUCON.2018.8363398},
  ISSN={2165-9567},
  month={April},}
@INPROCEEDINGS{8374458,
  author={Monil, Mohammad Alaul Haque and Malony, Allen D. and Toomey, Doug and Huck, Kevin},
  booktitle={2018 26th Euromicro International Conference on Parallel, Distributed and Network-based Processing (PDP)}, 
  title={Stingray-HPC: A Scalable Parallel Seismic Raytracing System}, 
  year={2018},
  volume={},
  number={},
  pages={204-213},
  abstract={The Stingray raytracer was developed for marine seismology to compute minimum travel time from all sources in an earth model to determine the 3D geophysical structure below the ocean floor. The original sequential implementation of Stingray used Dijkstra's single-source, shortest-path (SSSP) algorithm. A data parallel version of Stingray was developed based on the Bellman-Ford-Moore iterative SSSP algorithm. Single node experiments demonstrated performance improvements from parallelization with multicore (using OpenMP) and manycore processors (using CUDA). Calculating seismic ray paths for larger earth models requires distributed, multi-node algorithms utilizing domain decomposition methods. Preliminary 2D decomposition strategies show promising scaling results. However, a general 3D decomposition methodology is needed to handle any seismic raytracing problem on any HPC computing platform. In this paper, we present Stingray-HPC, a framework for scalable seismic raytracing which can automatically decompose a 3D earth model across nodes in a distributed environment, allocate ghost cell regions for iterative updates, coordinate ghost cell communications, and test for global convergence. Stingray-HPC is implemented with MPI and either OpenMP or CUDA for node- level calculations. Our results validate Stingray-HPC's ability to handle large models (over a billion points) and to solve these models efficiently at scale up to 512 GPU nodes.},
  keywords={},
  doi={10.1109/PDP2018.2018.00035},
  ISSN={2377-5750},
  month={March},}
@INPROCEEDINGS{8374462,
  author={Tran, Van Long and Renault, Éric and Do, Xuan Huyen and Ha, Viet Hai},
  booktitle={2018 26th Euromicro International Conference on Parallel, Distributed and Network-based Processing (PDP)}, 
  title={A New Execution Model for Improving Performance and Flexibility of CAPE}, 
  year={2018},
  volume={},
  number={},
  pages={234-238},
  abstract={Checkpointing-Aided Parallel Execution (CAPE) is a framework that is based on checkpointing technique and serves to automatically translates and execute OpenMP programs on distributed-memory architectures. In some comparisons with MPI, CAPE have demonstrated high-performance and the potential for fully compatibility with OpenMP on distributed-memory systems. However, it should be continued to improve the performance, flexibility, portability and capability. This paper presents the new execution model for CAPE that improves its performance and makes CAPE even more flexible.},
  keywords={},
  doi={10.1109/PDP2018.2018.00039},
  ISSN={2377-5750},
  month={March},}
@INPROCEEDINGS{8374478,
  author={Liu, Chao and Leeser, Miriam},
  booktitle={2018 26th Euromicro International Conference on Parallel, Distributed and Network-based Processing (PDP)}, 
  title={Local and Global Shared Memory for Task Based HPC Applications on Heterogeneous Platforms}, 
  year={2018},
  volume={},
  number={},
  pages={316-320},
  abstract={With the prevalence of multicore and manycore processors, developing parallel applications to benefit from massively parallel resources is important. In this work, we introduce a hybrid shared memory mechanism based on a high-level task design. We implemented task scoped global shared data based on the one-sided communication feature of MPI-3 and enable users to implement and create multi-threaded tasks that can execute either on a single node or on multiple nodes. Task threads of distributed nodes can share data sets through global shared data objects using one-sided remote memory access. We ported and developed a set of benchmark applications and tested on a cluster platform. The high-level task design and hybrid shared memory help users develop and maintain parallel programs easily, and the results show that the global shared data can deliver good RMA performance; the multi-threaded task implementations perform up to 20% faster than ordinary OpenMP programs and have better scaling performance than MPI programs on multiple nodes.},
  keywords={},
  doi={10.1109/PDP2018.2018.00055},
  ISSN={2377-5750},
  month={March},}
@INPROCEEDINGS{8374438,
  author={Ramos Carneiro, André and Bez, Jean Luca and Zanon Boito, Francieli and Alves Fagundes, Bruno and Osthoff, Carla and Navaux, Philippe O.A.},
  booktitle={2018 26th Euromicro International Conference on Parallel, Distributed and Network-based Processing (PDP)}, 
  title={Collective I/O Performance on the Santos Dumont Supercomputer}, 
  year={2018},
  volume={},
  number={},
  pages={45-52},
  abstract={The historical gap between processing and data access speeds causes many applications to spend a large portion of their execution on I/O operations. From the point of view of a large-scale, expensive, supercomputer, it is important to ensure applications achieve the best I/O performance to promote an efficient usage of the machine. In this paper, we evaluate the I/O infrastructure of the Santos Dumont supercomputer, the largest one from Latin America. More specifically, we investigate the performance of collective I/O operations. By conducting an analysis of a scientific application that uses the machine, we identify large performance differences between the available MPI implementations. We then further study the observed phenomenon using the BT-IO and IOR benchmarks, in addition to a custom microbenchmark. We conclude that the customized MPI implementation by Bull (used by more than 20% of the jobs) presents the worst performance for small collective write operations. Our results are being used to help the Santos Dumont users to achieve the best performance for their applications. Additionally, by investigating the observed phenomenon, we provide information to help improve future MPI-IO collective write implementations.},
  keywords={},
  doi={10.1109/PDP2018.2018.00015},
  ISSN={2377-5750},
  month={March},}
@INPROCEEDINGS{8374455,
  author={Ashraf, Rizwan A. and Hukerikar, Saurabh and Engelmann, Christian},
  booktitle={2018 26th Euromicro International Conference on Parallel, Distributed and Network-based Processing (PDP)}, 
  title={Shrink or Substitute: Handling Process Failures in HPC Systems Using In-Situ Recovery}, 
  year={2018},
  volume={},
  number={},
  pages={178-185},
  abstract={Efficient utilization of today's high-performance computing (HPC) systems with complex software and hardware components requires that the HPC applications are designed to tolerate process failures at runtime. With low mean-time-to-failure (MTTF) of current and future HPC systems, long running simulations on these systems requires capabilities for gracefully handling process failures by the applications themselves. In this paper, we explore the use of fault tolerance extensions to Message Passing Interface (MPI) called user-level failure mitigation (ULFM) for handling process failures without the need to discard the progress made by the application. We explore two alternative recovery strategies, which use ULFM along with application-driven in-memory checkpointing. In the first case, the application is recovered with only the surviving processes, and in the second case, spares are used to replace the failed processes, such that the original configuration of the application is restored. Our experimental results demonstrate that graceful degradation is a viable alternative for recovery in environments where spares may not be available.},
  keywords={},
  doi={10.1109/PDP2018.2018.00032},
  ISSN={2377-5750},
  month={March},}
@INPROCEEDINGS{8374540,
  author={Engwer, Christian and Altenbernd, Mirco and Dreier, Nils-Arne and Göddeke, Dominik},
  booktitle={2018 26th Euromicro International Conference on Parallel, Distributed and Network-based Processing (PDP)}, 
  title={A High-Level C++ Approach to Manage Local Errors, Asynchrony and Faults in an MPI Application}, 
  year={2018},
  volume={},
  number={},
  pages={714-721},
  abstract={C++ advocates exceptions as the preferred way to handle unexpected behaviour of an implementation in the code. This does not integrate well with the error handling of MPI, which more or less always results in program termination in case of MPI failures. In particular, a local C++ exception can currently lead to a deadlock due to unfinished communication requests on remote hosts. At the same time, future MPI implementations are expected to include an API to continue computations even after a hard fault (node loss), i.e. the worst possible unexpected behaviour. In this paper we present an approach that adds extended exception propagation support to C++ MPI programs. Our technique allows to propagate local exceptions to remote hosts to avoid deadlocks, and to map MPI failures on remote hosts to local exceptions. A use case of particular interest are asynchronous 'local failure local recovery' resilience approaches. Our prototype implementation uses MPI-3.0 features only. In addition we present a dedicated implementation, which integrates seamlessly with MPI-ULFM, i.e. the most prominent proposal for extending MPI towards fault tolerance. Our implementation is available at https://gitlab.dune-project.org/christi/test-mpi-exceptions.},
  keywords={},
  doi={10.1109/PDP2018.2018.00117},
  ISSN={2377-5750},
  month={March},}
@INPROCEEDINGS{8377230,
  author={Yi, Gong and Shengchu, Wang and Lin, Zhang},
  booktitle={2018 IEEE Wireless Communications and Networking Conference (WCNC)}, 
  title={Approximate message passing based cooperative localization in WSN with AOA measurements}, 
  year={2018},
  volume={},
  number={},
  pages={1-6},
  abstract={Cooperative localization (CL) based on the angle-of-arrival (AOA) measurements is a promising positioning technique for the wireless sensor network (WSN). This is because CL reaches high localization precision and robustness by exploiting the relative ranging measurements among the agents. In addition, the AOA interpretation involves no propagation parameters, and its acquisition does not require strict time-synchronization among the WSN nodes. In this paper, we firstly categorize the AOA-CL problem as a generalized linear-mixing problem under the phase-only measurements, and then resolve it by our developed phase-only generalized approximate message passing (POG-AMP) algorithm. The POG-AMP localizer is warm-started by developing an incremental localizer assisting by anchor-connectivity and region-boundary constraints. It calls for sparse matrix-vector multiplications (MVMs) as its most complex operations, and can be implemented in a distributed manner. Therefore, it has low computational complexity, and is suitable for WSN hardware implementation. Simulation results validate the state-of-the-art performance and cooperation gains of the POG-AMP localizer.},
  keywords={},
  doi={10.1109/WCNC.2018.8377230},
  ISSN={1558-2612},
  month={April},}
@ARTICLE{8385174,
  author={Milicevic, Mario and Gulak, P. Glenn},
  journal={IEEE Transactions on Very Large Scale Integration (VLSI) Systems}, 
  title={A Multi-Gb/s Frame-Interleaved LDPC Decoder With Path-Unrolled Message Passing in 28-nm CMOS}, 
  year={2018},
  volume={26},
  number={10},
  pages={1908-1921},
  abstract={This paper presents a frame-interleaved low-density parity-check (LDPC) decoder architecture with a new interconnect partitioning scheme and time-distributed Min-Sum decoding schedule. The architecture exploits the cyclic structure of the parity-check matrix by unrolling each check node update in time over all connected variable nodes in order to minimize wiring complexity and power. Multiple frames are interleaved to maximize hardware utilization, while coarse-grained clock gating is used to systematically turn off inactive logic and memories to save power. To demonstrate the scalability of the proposed architecture, a multirate LDPC decoder test chip was fabricated for the IEEE 802.11ad standard in the 28-nm CMOS technology node. The design occupies an area of 1.99 mm2, contains 160 Kb of embedded static random-access memory, and achieves a throughput of 6.78 Gb/s at 10 decoding iterations for all four code rates specified in the standard. With early decoding termination, the fabricated chip consumes between 104 and 279 mW of power at a target bit error rate of 10−6 under nominal operation at 0.9-V supply and 202-MHz clock rate, resulting in an energy efficiency between 1.53 and 4.12 pJ/bit/iteration. With clock-frequency and voltage scaling, the fabricated chip achieves an energy efficiency between 1.1 and 3.1 pJ/bit/iteration. This paper achieves the highest normalized energy efficiency among recently published CMOS-based decoders for the IEEE 802.11ad standard at nominal clock frequency and supply voltage.},
  keywords={},
  doi={10.1109/TVLSI.2018.2838591},
  ISSN={1557-9999},
  month={Oct},}
@ARTICLE{8387467,
  author={Wu, Kuan and Jiang, Ming and Tan, Hong-Zhou},
  journal={IEEE Transactions on Vehicular Technology}, 
  title={D2D Relay Selection Based on Joint Fuzzy and Entropy Theories With Social Similarity}, 
  year={2018},
  volume={67},
  number={9},
  pages={8796-8807},
  abstract={The employment of social similarity (SS) aware device-to-device (D2D) user equipment (UE)-to-network (UE-NW) relay helps to improve system capacity and UEs' accessability to the evolved Node B (eNB), where a crucial aspect is the design of the relay helper UE (HUE) selection process. However, few existing studies jointly consider the diverse impacts from various design criteria on the performance of HUE selection. In this paper, we formulate the SS-aware D2D UE-NW relay selection (RS) issue as a multiobjective binary integer linear programming (MOBILP) problem under the constraints of several criteria. Then, we propose a new two-stage D2D UE-NW selection scheme. Specifically, a joint algorithm exploiting the intuitionistic fuzzy analytic hierarchy process and the entropy weight generation method is designed for stage one, which provides both subjective and objective preferences for assisting decision making. In stage two, with the constructed decision weights, the MOBILP can be transformed to a simpler binary integer linear programming problem and thus be solved distributively through an efficient message passing method. Based on realistic social data traces, our simulation results validate the benefits of the proposed two-stage scheme, which ensures high system performances in terms of throughput, fairness and energy efficiency.},
  keywords={},
  doi={10.1109/TVT.2018.2848544},
  ISSN={1939-9359},
  month={Sep.},}
@INPROCEEDINGS{8396831,
  author={Kun, David},
  booktitle={2018 IEEE Aerospace Conference}, 
  title={High throughput GPU LDPC encoder and decoder for DVB-S2}, 
  year={2018},
  volume={},
  number={},
  pages={1-9},
  abstract={Previous studies that used Graphics Processing Units (GPUs) to decode Low Density Parity Check (LDPC) codes for DVB-S2 employed inter-codeword parallelism and/or Turbo Decoding Message Passing (TDMP) to achieve high throughput. By converting the LDPC parity check matrix into a quasi-cyclic structure, we show that LDPC encoding can be efficiently implemented on a GPU, and a different approach to LDPC decoding with intra-codeword parallelism and early termination that can achieve approximately 100 Mbps increase in throughput per 0.1 dB increase in signal-to-noise ratio and, for some cases, achieve 1 Gbps or greater overall throughput.},
  keywords={},
  doi={10.1109/AERO.2018.8396831},
  ISSN={},
  month={March},}
@INPROCEEDINGS{8398997,
  author={Praveena, H. and Kalyani, K.},
  booktitle={2018 2nd International Conference on Inventive Systems and Control (ICISC)}, 
  title={FPGA implementation of Parity Check Matrix based Low Density Parity Check Decoder}, 
  year={2018},
  volume={},
  number={},
  pages={1214-1217},
  abstract={Low Density Parity Check (LDPC) error correction decoders have become popular in diverse communication systems, owing to their strong error correction performance and their suitability to parallel hardware implementation. Low Density Parity Check Decoder is a class of Forward Error Correction Codes. The parameterization of a particular LDPC code is defined by its Parity Check Matrix. Parity Check matrix which describes the specific logical combination of the transmitted message bits into parity checks. PCMs are sparse matrices having far more zero entries than nonzero. It allows LDPC codes to be iteratively decoded using a low complexity message passing algorithm. Thus the objective of this project is to implement a PCM based LDPC decoder architecture on FPGA. Initially the components of LDPC decoder are identified then Verilog HDL coding for these components have been written, simulated using Altera Quartus II software. The implementation of these components are done on Altera Cyclone II FPGA kit to improve the error correction performance of communication system.},
  keywords={},
  doi={10.1109/ICISC.2018.8398997},
  ISSN={},
  month={Jan},}
@INPROCEEDINGS{8400116,
  author={Klinger, Thomas and Madritsch, Christian},
  booktitle={2018 41st International Convention on Information and Communication Technology, Electronics and Microelectronics (MIPRO)}, 
  title={Parallel computing for education using single-board computers}, 
  year={2018},
  volume={},
  number={},
  pages={0616-0619},
  abstract={This paper describes the design, implementation, and practical use of a Computing Cluster using IoT Technologies in Engineering Education. First, the development goal and its expected application are explained. Current lectures in Computer Science, Computer Engineering, and Image Processing will benefit of the massive parallel computing cluster. Next, the design and implementation - carried out by a group of students - are described in detail. Finally, the practical use of the cluster including a test application is shown. Here, current super-computing methods like Message Passing Interface (MPI) and Open Multi Processing (OpenMP) are used to show the ability and functionality of the cluster.},
  keywords={},
  doi={10.23919/MIPRO.2018.8400116},
  ISSN={},
  month={May},}
@INPROCEEDINGS{8406856,
  author={Ding, Mingyue and Wang, Shengchu and Huang, Zhongyan and Zhu, Konglin and Zhang, Ling},
  booktitle={IEEE INFOCOM 2018 - IEEE Conference on Computer Communications Workshops (INFOCOM WKSHPS)}, 
  title={Message-passing cooperative localization in sensor networks with AOA measurements}, 
  year={2018},
  volume={},
  number={},
  pages={724-729},
  abstract={This paper proposes an approximate message passing cooperative localizer (AMP-CL) for wireless sensor networks (WSNs) with angle-of-arrival (AOA) ranging measurements and unknown orientation angles. At first, an incremental localizer is developed to provide initial position estimations. Subsequently, orientation angles of WSN nodes are separately estimated based on current node position estimations and AOA observations by maximum-likelihood (ML) method. Based on the current orientation estimations, cooperative localization problem is converted as a generalized linear mixing problem, and resolved by AMP algorithm. Finally, AMP-CL will iterate between AMP-based positioning recovery and ML orientation angle estimation until convergence conditions are satisfied. It is featured on low-computational complexity, and distributed implementation manner. Simulation results also validate the state-of-the-art positioning performance and cooperative gains of AMP-CL after comparing itself with some main-stream localizers under different communication ranges and noise contaminations.},
  keywords={},
  doi={10.1109/INFCOMW.2018.8406856},
  ISSN={},
  month={April},}
@INPROCEEDINGS{8408957,
  author={Buyuk, Oguzhan Oktay and Camurcu, Ali Yilmaz},
  booktitle={2018 6th International Istanbul Smart Grids and Cities Congress and Fair (ICSG)}, 
  title={A novel actual time cyber security approach to smart grids}, 
  year={2018},
  volume={},
  number={},
  pages={129-133},
  abstract={The purpose of this paper was to develop a novel actual time cyber security approach to smart grids. The developed way securely backed the smart meters among smart grids against external attacks in a distribution substation. Security is provided using Message Passing Interface (MPI). Newly configured Floyd-Warshall Algorithm was applied to MPI so as to represent a distribution of key pairs which was generated by Homomorphic Encryption. Simulation case studies were conducted on Raspberry Pi 2 Model B in order to illustrate how the mentioned approach can be built to execute the cyber security essentials via parallel programming techniques and Valgrind tools on a virtual distributed mechanism. Simulation results which use real world attack data demonstrated that the developed way is capable of accomplishing cyber security against outer attacks accurately, quickly and real time based sorting of the key pairs into each smart meter node in the demanded area.},
  keywords={},
  doi={10.1109/SGCF.2018.8408957},
  ISSN={},
  month={April},}
@INPROCEEDINGS{8411073,
  author={Cai, Ying and Yang, Chao and Ma, Wenjing and Ao, Yulong},
  booktitle={2018 18th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing (CCGRID)}, 
  title={Extreme-Scale Realistic Stencil Computations on Sunway TaihuLight with Ten Million Cores}, 
  year={2018},
  volume={},
  number={},
  pages={566-571},
  abstract={Stencil computation arises from a large variety of scientific and engineering applications and often plays a critical role in the performance of extreme-scale simulations. Due to the memory bound nature, it is a challenging task to optimize stencil computation kernels on many leadership supercomputers, such as Sunway TaihuLight, which has relatively high computing throughput whilst relatively low data-moving capability. In this white paper, we show the efforts we have been making during the past two years in developing end-to-end implementation and optimization techniques for extreme-scale stencil computations on Sunway TaihuLight. We started with a work on optimizing the 3-D 2nd-order 13-point stencil for nonhydrostatic atmospheric dynamics simulation, which is an important part of the 2016 ACM Gordon Bell Prize winning work, and extended it in ways that can handle a broader range of realistic and challenging problems, such as the HPGMG benchmark that consists of memory-hungry stencils and the gaseous wave detonation simulation that relies on complex high-order stencils. The presented stencil computation paradigm on Sunway TaihuLight includes not only multilevel parallelization to exploit the parallelism on different hardware levels, but also systematic performance optimization techniques for communication, memory access, and computation. We show by extreme-scale tests that the proposed systematic stencil computation paradigm can successfully deliver remarkable performance on Sunway TaihuLight with ten million heterogeneous cores. In particular, we achieve an aggregate performance of 23.12 Pflops for the 3-D 5th order WENO stencil computation in gaseous wave detonation simulation, which is the highest performance result for high-order stencil computations as far as we know, and an aggregate performance of solving over one trillion unknowns per second in the HPGMG benchmark, which ranks the first place in the HPGMG List of Nov 2017.},
  keywords={},
  doi={10.1109/CCGRID.2018.00086},
  ISSN={},
  month={May},}
@INPROCEEDINGS{8411016,
  author={Rolinger, Thomas B. and Simon, Tyler A. and Krieger, Christopher D.},
  booktitle={2018 18th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing (CCGRID)}, 
  title={An Empirical Evaluation of Allgatherv on Multi-GPU Systems}, 
  year={2018},
  volume={},
  number={},
  pages={123-132},
  abstract={Applications for deep learning and big data analytics have compute and memory requirements that exceed the limits of a single GPU. However, effectively scaling out an application to multiple GPUs is challenging due to the complexities of communication between the GPUs, particularly for collective communication with irregular message sizes. In this work, we provide a performance evaluation of the Allgatherv routine on multi-GPU systems, focusing on GPU network topology and the communication library used. We present results from the OSU-micro benchmark as well as conduct a case study for sparse tensor factorization, one application that uses Allgatherv with highly irregular message sizes. We extend our existing tensor factorization tool to run on systems with different node counts and varying number of GPUs per node. We then evaluate the communication performance of our tool when using traditional MPI, CUDA-aware MVAPICH and NCCL across a suite of real-world data sets on three different systems: a 16-node cluster with one GPU per node, NVIDIA's DGX-1 with 8 GPUs and Cray's CS-Storm with 16 GPUs. Our results show that irregularity in the tensor data sets produce trends that contradict those in the OSU micro-benchmark, as well as trends that are absent from the benchmark.},
  keywords={},
  doi={10.1109/CCGRID.2018.00027},
  ISSN={},
  month={May},}
@INPROCEEDINGS{8411077,
  author={Laccetti, Giuliano and Lapegna, Marco and Montella, Raffaele},
  booktitle={2018 18th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing (CCGRID)}, 
  title={A Scalable Unified Model for Dynamic Data Structures in Message Passing (Clusters) and Shared Memory (multicore CPUs) Computing environments}, 
  year={2018},
  volume={},
  number={},
  pages={599-608},
  abstract={Concurrent data structures are widely used in many software stack levels, ranging from high level parallel scientific applications to low level operating systems. The key issue of these objects is their concurrent use by several computing units (threads or process) so that the design of these structures is much more difficult compared to their sequential counterpart, because of their extremely dynamic nature requiring protocols to ensure data consistency, with a significant cost overhead. At this regard, several studies emphasize a tension between the needs of sequential correctness of the concurrent data structures and scalability of the algorithms, and in many cases it is evident the need to rethink the data structure design, using approaches based on randomization and/or redistribution techniques in order to fully exploit the computational power of the recent computing environments. The problem is grown in importance with the new generation High Performance Computing systems aimed to achieve extreme performance. It is easy to observe that such systems are based on heterogeneous architectures integrating several independent nodes in the form of clusters or MPP systems, where each node is composed by powerful computing elements (CPU core, GPUs or other acceleration devices) sharing resources in a single node. These systems therefore make massive use of communication libraries to exchange data among the nodes, as well as other tools for the management of the shared resources inside a single node. For such a reason, the development of algorithms and scientific software for dynamic data structures on these heterogeneous systems implies a suitable combination of several methodologies and tools to deal with the different kinds of parallelism corresponding to each specific device, so that to be aware of the underlying platform. The present work is aimed to introduce a scalable model to manage a special class of dynamic data structure known as heap based priority queue (or simply heap) on these heterogeneous architectures. A heap is generally used when the applications needs set of data not requiring a complete ordering, but only the access to some items tagged with high priority. In order to ensure a tradeoff between the correct access to high priority items by the several computing units with a low communication and synchronization overhead, a suitable reorganization of the heap is needed. More precisely we introduce a unified scalable model that can be used, with no modifications, to redeploy the items of a heap both in message passing environments (such as clusters and or MMP multicomputers with several nodes) as well as in shared memory environments (such as CPUs and multiprocessors with several cores) with an overhead independent of the number of computing units. Computational results related to the application of the proposed strategy on some numerical case studies are presented for different types of computing environments.},
  keywords={},
  doi={10.1109/CCGRID.2018.00007},
  ISSN={},
  month={May},}
@ARTICLE{8413099,
  author={Huang, Chongwen and Liu, Lei and Yuen, Chau},
  journal={IEEE Transactions on Vehicular Technology}, 
  title={Asymptotically Optimal Estimation Algorithm for the Sparse Signal With Arbitrary Distributions}, 
  year={2018},
  volume={67},
  number={10},
  pages={10070-10075},
  abstract={In this paper, we propose a sparse signal estimation algorithm that is suitable for many wireless communication systems, especially for the future millimeter wave and underwater communication systems. This algorithm is not only asymptotically optimal, but also robust to the distribution of nonzero entries of the sparse signal. Then, we derive its upper bound and lower bound, and show that the mean square error of the proposed algorithm can approach the minimum mean square error bound when the signal noise ratio goes to infinite or zero. Numerical simulations verify our theoretical analysis and also show that the proposed algorithm converges faster than existing algorithms, e.g., turbo-type signal recovery-discrete fourier transform, approximate message passing, etc.},
  keywords={},
  doi={10.1109/TVT.2018.2857480},
  ISSN={1939-9359},
  month={Oct},}
@INPROCEEDINGS{8417730,
  author={Yuan, Weijie and Shi, Qiaolin and Wu, Nan and Guo, Qinghua and Huang, Xiaojing},
  booktitle={2018 IEEE 87th Vehicular Technology Conference (VTC Spring)}, 
  title={Gaussian Message Passing Based Passive Localization in the Presence of Receiver Detection Failures}, 
  year={2018},
  volume={},
  number={},
  pages={1-5},
  abstract={This paper considers the issue of passive localization based on time of arrival (TOA) measurement in the presence of receiver detection failures. In passive localization, the signal sent from the transmitter is reflected or relayed by "passive" target and then received at several distributed receivers. The target's position can be determined by collecting range mea- surements from all receivers. With a linearized model for range measurements, we build a factor graph model and implement Gaussian message passing algorithm to obtain target location and detect link failures. The Cramer-rao bound (CRB) is also derived to evaluate the performance of proposed algorithm. Simulation results verify the effectiveness of proposed factor graph approach.},
  keywords={},
  doi={10.1109/VTCSpring.2018.8417730},
  ISSN={2577-2465},
  month={June},}
@ARTICLE{8423459,
  author={Chi, Yuhao and Liu, Lei and Song, Guanghui and Yuen, Chau and Guan, Yong Liang and Li, Ying},
  journal={IEEE Transactions on Wireless Communications}, 
  title={Practical MIMO-NOMA: Low Complexity and Capacity-Approaching Solution}, 
  year={2018},
  volume={17},
  number={9},
  pages={6251-6264},
  abstract={MIMO-NOMA combines multiple-input multiple-output (MIMO) and non-orthogonal multiple access (NOMA) techniques to address heterogeneous challenges, such as massive connectivity, low latency, and high reliability in the 5G cellular communication system and beyond. In this paper, a coded MIMO-NOMA system with capacity-approaching performance and low implementation complexity is proposed. Specifically, the proposed MIMO receiver consists of a linear minimum mean-square error (LMMSE) multi-user detector and a bank of single-user message-passing decoders, which decompose the overall NOMA signal recovery into distributed low-complexity computations with iterative processing. An asymptotic extrinsic information transfer analysis is employed to model the overall performance, and a novel class of multi-user irregular repeat-accumulate channel codes that match with the LMMSE multi-user detector in the iterative decoding process are constructed for the system. As a result, the proposed coded MIMO-NOMA system achieves asymptotic performance within 0.2 dB from the theoretical capacity. Simulation results validate the reliability and robustness of the proposed system in practical settings that include different system loads, iteration numbers, code lengths, fast/block fading, and imperfect channel estimation.},
  keywords={},
  doi={10.1109/TWC.2018.2858222},
  ISSN={1558-2248},
  month={Sep.},}
@INPROCEEDINGS{8425180,
  author={Lavrijsen, Wim and Iancu, Costin and Pan, Xing},
  booktitle={2018 IEEE International Parallel and Distributed Processing Symposium (IPDPS)}, 
  title={Improving Network Throughput with Global Communication Reordering}, 
  year={2018},
  volume={},
  number={},
  pages={266-275},
  abstract={We present a methodology to improve network throughput by reordering communication in HPC codes. In contrast to all previous work, our approach does not require any information about network and application communication topology. We implement on-the-fly algorithms that reorder message streams based on statistics inferred during execution. Our intuition is that long operations that occur in ranks that exhibit large execution variability need to be prioritized. We consider two approaches: 1) reorder using statistics of a group of significant ranks; and 2) reorder around an outlier rank. For robustness on noisy systems, our final algorithm combines group and outlier reordering and it allows continuous adaptation of the schedule. We validate on two different networks: Cray Aries and InfiniBand. Micro-benchmarks show that performance between two different schedules of communication can be as high as 74%. Given an initial ordering, our algorithm can recuperate as much as 90% from the potential perfor-mance improvements. When employed in applications, we see improvements as large as 70% in communication times. If interference is present, the algorithm additionally reduces outliers and variance in the communication times.},
  keywords={},
  doi={10.1109/IPDPS.2018.00036},
  ISSN={1530-2075},
  month={May},}
@INPROCEEDINGS{8425251,
  author={Dang, Hoang-Vu and Dathathri, Roshan and Gill, Gurbinder and Brooks, Alex and Dryden, Nikoli and Lenharth, Andrew and Hoang, Loc and Pingali, Keshav and Snir, Marc},
  booktitle={2018 IEEE International Parallel and Distributed Processing Symposium (IPDPS)}, 
  title={A Lightweight Communication Runtime for Distributed Graph Analytics}, 
  year={2018},
  volume={},
  number={},
  pages={980-989},
  abstract={Distributed-memory multi-core clusters enable in-memory processing of very large graphs with billions of nodes and edges. Recent distributed graph analytics systems have been built on top of MPI. However, communication in graph applications is very irregular, and each host exchanges different amounts of non-contiguous data with other hosts. MPI does not support such a communication pattern well, and it has limited ability to integrate communication with serialization, deserialization, and graph computation tasks. In this paper, we describe a lightweight communication runtime called LCI that supports a large number of threads on each host and avoids the semantic mismatches between the requirements of graph computations and the communication library in MPI. The implementation of LCI is informed by lessons learnt from two baseline MPI-based implementations. We have successfully integrated LCI with two state-of-the-art graph analytics systems - Gemini and Abelian. LCI improves the latency up to 3.5× for microbenchmarks compared to MPI solutions and improves the end-to-end performance of distributed graph algorithms by up to 2×.},
  keywords={},
  doi={10.1109/IPDPS.2018.00107},
  ISSN={1530-2075},
  month={May},}
@INPROCEEDINGS{8425240,
  author={Li, Hongbo and Li, Sihuan and Benavides, Zachary and Chen, Zizhong and Gupta, Rajiv},
  booktitle={2018 IEEE International Parallel and Distributed Processing Symposium (IPDPS)}, 
  title={COMPI: Concolic Testing for MPI Applications}, 
  year={2018},
  volume={},
  number={},
  pages={865-874},
  abstract={MPI is widely used as the bedrock of HPC applications, but there are no effective systematic software testing techniques for MPI programs. In this paper we develop COMPI, the first practical concolic testing tool for MPI applications. COMPI tackles two major challenges. First, it provides an automated testing tool for MPI programs - it performs concolic execution on a single process and records branch coverage across all. Infusing MPI semantics such as MPI rank and MPI_COMM_WORLD into COMPI enables it to automatically direct testing with various processes' executions as well as automatically determine the total number of processes used in the testing. Second, COMPI employs three techniques to effectively control the cost of testing as too high a cost may prevent its adoption. By capping input values, COMPI is made practical as too large an input can make the testing extremely slow and sometimes even fail as memory needed could exceed the computing platform's memory limit. With two-way instrumentation, we reduce the unnecessary memory and I/O overhead of COMPI and the target program. With constraint set reduction, COMPI keeps significantly fewer constraints by removing redundant ones in the presence of loops so as to avoid redundant tests against these branches. Our evaluation of COMPI uncovered four new bugs in a complex application and achieved 69-86% branch coverage which far exceeds the 1.8-38% coverage achieved via random testing.},
  keywords={},
  doi={10.1109/IPDPS.2018.00096},
  ISSN={1530-2075},
  month={May},}
@INPROCEEDINGS{8425384,
  author={Pennefather, Sean and Bradshaw, Karen and Irwin, Barry},
  booktitle={2018 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)}, 
  title={Exploration and Design of a Synchronous Message Passing Framework for a CPU-NPU Heterogeneous Architecture}, 
  year={2018},
  volume={},
  number={},
  pages={46-56},
  abstract={In this paper we present the development of a framework for communication between an NPU (network processing unit) and CPU through synchronous message passing that is compliant with the synchronous communication events of the CSP formalisms. This framework is designed to be used for passing generic information between application components operating on both architectures and is intended to operate in conjunction with existing datapaths present on the NPU which in turn are responsible for network traffic transmission. An investigation of different message passing topologies is covered before the proposed message passing fabric is presented. As a proof of concept, an initial implementation of the fabric is developed and tested to determine its viability and correctness. Through testing it is shown that the implemented framework operates as intended. However, it is noted the throughput of the exploratory implementation is not considered suitable for high-performance applications and further evaluation is required.},
  keywords={},
  doi={10.1109/IPDPSW.2018.00017},
  ISSN={},
  month={May},}
@INPROCEEDINGS{8425540,
  author={Wagle, Bibek and Kellar, Samuel and Serio, Adrian and Kaiser, Hartmut},
  booktitle={2018 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)}, 
  title={Methodology for Adaptive Active Message Coalescing in Task Based Runtime Systems}, 
  year={2018},
  volume={},
  number={},
  pages={1133-1140},
  abstract={Overheads associated with fine grained communication in task based runtime systems are one of the major bottlenecks that limit the performance of distributed applications. In this research, we provide methodology and metrics for analyzing network overheads using the introspection capabilities of HPX, a task based runtime system. We demonstrate that our metrics show a strong correlation with the overall runtime of our test applications. Our aim is to eventually use these metrics to tune, at runtime, parameters relating to active message coalescing. This method improves on the postmortem analysis techniques that are currently employed to tune network settings in distributed applications.},
  keywords={},
  doi={10.1109/IPDPSW.2018.00173},
  ISSN={},
  month={May},}
@INPROCEEDINGS{8425452,
  author={Chen, Jun and Zou, Peigang},
  booktitle={2018 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)}, 
  title={Implementing a Parallel Graph Clustering Algorithm with Sparse Matrix Computation}, 
  year={2018},
  volume={},
  number={},
  pages={487-496},
  abstract={Graph clustering is a task that classifies vertices in a graph into many clusters according to their correlations. It is now widely used in many fields such as machine learning and so on, and the size of graph is increasing with the more complicated problem. It is difficult to implement parallel graph clustering for big graph with high performance on distributed memory systems because of its irregular access patterns. Here we design a scalable parallel algorithm for peer pressure clustering, a graph clustering algorithm based on random walk method. This graph clustering algorithm is firstly represented as parallel sparse matrix computations, then split these computations into parallel basic linear algebra operations. At last, a MPI implementation is built on top of the matrix algebra building blocks in the sparse matrix infrastructures of Combinatorial BLAS. Many experiment tests are completed where the inputs are permuted R-MAT graphs of various scales with self-loops added. The results show that our parallel implementation achieves a high degree of parallelism and good scalability on thousands cores of a Dawning supercomputer.},
  keywords={},
  doi={10.1109/IPDPSW.2018.00085},
  ISSN={},
  month={May},}
@INPROCEEDINGS{8425443,
  author={Li, Hongbo and Chen, Zizhong and Gupta, Rajiv and Xie, Min},
  booktitle={2018 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)}, 
  title={Non-intrusively Avoiding Scaling Problems in and out of MPI Collectives}, 
  year={2018},
  volume={},
  number={},
  pages={415-424},
  abstract={It has been observed that scaling problems are highly likely to manifest when MPI applications are launched at a large scale where the scale is characterized by the degree of parallelism and the problem size. As the complexity of MPI collectives is directly impacted by both parallelism scale and problem size, their use often triggers scaling problems. Scaling problems' root cause can be outside of MPI libraries and these can be easily exposed via the dynamic interaction between user code and MPI library as the scale goes up. Specifically, irregular collectives suffer the most as the C int displacement array can easily be corrupted with integer overflow. Scaling problems can also result from a bug inside the released MPI libraries due to the lack of a systematic testing of MPI libraries as well as the platform or environment dependency of some scaling problems. Hence it is important for library users to perform testing on their platform to expose potential scaling problems. Fixing a scaling problem is challenging, and thus it usually takes much time for users to wait for an official fix, which sometimes is not even possible due to the difficulty of bug reproduction, root-cause identification, and fix development. To improve users' productivity, we establish the necessity of user side testing and provide a protection layer to avoid scaling problems non-intrusively, i.e., without requiring any changes to the MPI library or user programs. This provides an immediate remedy when an official fix is not readily available.},
  keywords={},
  doi={10.1109/IPDPSW.2018.00076},
  ISSN={},
  month={May},}
@INPROCEEDINGS{8425491,
  author={Aravind, Alex},
  booktitle={2018 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)}, 
  title={Barrier Synchronization: Simplified, Generalized, and Solved Without Mutual Exclusion}, 
  year={2018},
  volume={},
  number={},
  pages={773-782},
  abstract={Barrier synchronization is a fundamental concurrency issue encountered in a large number of concurrent and parallel applications that involve parallel processes cooperatively solving complex problems. Barrier synchronization essentially forces these parallel processes to wait until each one of them has reached a certain point in execution. Therefore, barrier synchronization has been considered as an inevitable synchronization construct for most parallel applications. Hence barrier synchronization or its variant has become an integral component of the most widely used parallel programming models such as OpenMP, MPI, MapReduce, and the bulk synchronous parallel (BSP) models. A recent work stated that the performance of BSP model depends on 4 parameters - the number of nodes, the speed of each node, the communication cost, and the synchronization cost. Among these, the synchronization cost is considered critical in improving the performance of any BSP implementation. From parallel algorithm design and implementation perspective, we consider that the synchronization component is the most important one and its cost is the most critical performance factor for almost all the parallel programming models including BSP. This paper presents a class of simple barrier synchronization algorithms for shared memory systems. It includes general, efficient, and universal algorithms that are appealing from both practical and theoretical point of view. The correctness of the algorithms are proved. The algorithms are briefly analyzed to expose their strengths and weaknesses.},
  keywords={},
  doi={10.1109/IPDPSW.2018.00124},
  ISSN={},
  month={May},}
@ARTICLE{8434352,
  author={Rosnes, Eirik and Graell i Amat, Alexandre},
  journal={IEEE Transactions on Information Theory}, 
  title={Asymptotic Analysis and Spatial Coupling of Counter Braids}, 
  year={2018},
  volume={64},
  number={11},
  pages={7242-7263},
  abstract={A counter braid (CB) is a novel counter architecture introduced by Lu et al. in 2007 for per-flow measurements on high-speed links which can be decoded with low complexity using message passing (MP). CBs achieve an asymptotic compression rate (under optimal decoding) that matches the entropy lower bound of the flow size distribution. In this paper, we apply the concept of spatial coupling to CBs to improve the performance of the original CBs and analyze the performance of the resulting spatially-coupled CBs (SC-CBs). We introduce an equivalent bipartite graph representation of CBs with identical iteration-by-iteration finite-length and asymptotic performance. Based on this equivalent representation, we then analyze the asymptotic performance of single-layer CBs and SC-CBs under the MP decoding algorithm proposed by Lu et al.. In particular, we derive the potential threshold of the uncoupled system and show that it is equal to the area threshold. We also derive the Maxwell decoder for CBs and prove that the potential threshold is an upper bound on the Maxwell decoding threshold, which, in turn, is a lower bound on the maximum a posteriori (MAP) decoding threshold. We then show that the area under the extended MP extrinsic information transfer curve (defined for the equivalent graph), computed for the expected residual CB graph when a peeling decoder equivalent to the MP decoder stops, is equal to zero precisely at the area threshold. This, combined with the analysis of the Maxwell decoder and simulation results, leads us to the conjecture that the potential threshold is, in fact, equal to the Maxwell decoding threshold and hence a lower bound on the MAP decoding threshold. Interestingly, SC-CBs do not show the well-known phenomenon of threshold saturation of the MP decoding threshold to the potential threshold characteristic of spatially-coupled low-density parity-check codes and other coupled systems. However, SC-CBs yield better MP decoding thresholds than their uncoupled counterparts. Finally, we also consider SC-CBs as a compressed sensing scheme and show that low undersampling factors can be achieved.},
  keywords={},
  doi={10.1109/TIT.2018.2864945},
  ISSN={1557-9654},
  month={Nov},}
@INPROCEEDINGS{8432254,
  author={Dulay, Naranker and Micheletti, Matteo and Mostarda, Leonardo and Piermarteri, Andrea},
  booktitle={2018 IEEE 32nd International Conference on Advanced Information Networking and Applications (AINA)}, 
  title={PICO-MP: De-centralised Macro-Programming for Wireless Sensor and Actuator Networks}, 
  year={2018},
  volume={},
  number={},
  pages={289-296},
  abstract={Macro-programming advocates the use of high-level abstractions to specify distributed systems as a whole. However, macro-programming implementations are often centralised. In this paper we present PICO-MP, the first fully decentralised macro-programming middleware for wireless sensor and actuator network (WSAN) applications. PICO-MP incorporates a novel publish-subscribe service that can correlate events scattered across a WSAN using global formulae specifications that are automatically checked in a distributed fashion. PICO-MP has been implemented for the TinyOS operating system and validated on a case study that uses global formulae to improve energy efficiency (lifetime) of the implementation.},
  keywords={},
  doi={10.1109/AINA.2018.00052},
  ISSN={2332-5658},
  month={May},}
@ARTICLE{8438324,
  author={Lu, Xiaoyan and Szymanski, Boleslaw K.},
  journal={IEEE Transactions on Computational Social Systems}, 
  title={Scalable Prediction of Global Online Media News Virality}, 
  year={2018},
  volume={5},
  number={3},
  pages={858-870},
  abstract={News reports shape the public perception of the critical social, political, and economical events around the world. Yet, the way in which emergent phenomena are reported in the news makes the early prediction of such phenomena a challenging task. We propose a scalable community-based probabilistic framework to model the spreading of news about events in online media. Our approach exploits the latent community structure in the global news media and uses the affiliation of the early adopters with a variety of communities to identify the events widely reported in the news at the early stage .of their spread. The time complexity of our approach is linear in the number of news reports. It is also amenable to efficient parallelization. To demonstrate these features, the inference algorithm is parallelized for message passing paradigm and tested on the Rensselaer Polytechnic Institute Advanced Multiprocessing Optimized System, one of the fastest Blue Gene/Q supercomputers in the world. Thanks to the community-level features of the early adopters, the model gains an improvement of 20% in the early detection of the most massively reported events compared with the feature-based machine learning algorithm. Its parallelization scheme achieves orders of magnitude speedup.},
  keywords={},
  doi={10.1109/TCSS.2018.2857479},
  ISSN={2329-924X},
  month={Sep.},}
@ARTICLE{8421558,
  author={Li, Jianjiang and Wei, Peng and Yang, Shaofeng and Wu, Jie and Liu, Peng and He, Xinfu},
  journal={Tsinghua Science and Technology}, 
  title={Crystal-KMC: parallel software for lattice dynamics monte carlo simulation of metal materials}, 
  year={2018},
  volume={23},
  number={4},
  pages={501-510},
  abstract={Kinetic Monte Carlo (KMC) is a widely used method for studying the evolution of materials at the microcosmic level. At present, while there are many simulation software programs based on this algorithm, most focus on the verification of a certain phenomenon and have no analog-scale requirement, so many are serial in nature. The dynamic Monte Carlo algorithm is implemented using a parallel framework called SPPARKS, but it does not support the Embedded Atom Method (EAM) potential, which is commonly used in the dynamic simulation of metal materials. Metal material - the preferred material for most containers and components - plays an important role in many fields, including construction engineering and transportation. In this paper, we propose and describe the development of a parallel software program called Crystal-KMC, which is specifically used to simulate the lattice dynamics of metallic materials. This software uses MPI to achieve a parallel multiprocessing mode, which avoid the limitations of serial software in the analog scale. Finally, we describe the use of the parallel-KMC simulation software Crystal-KMC in simulating the diffusion of vacancies in iron, and analyze the experimental results. In addition, we tested the performance of Crystal-KMC in “meta -Era” supercomputing clusters, and the results show the Crystal-KMC parallel software to have good parallel speedup and scalability.},
  keywords={},
  doi={10.26599/TST.2018.9010107},
  ISSN={1007-0214},
  month={August},}
@INPROCEEDINGS{8442109,
  author={Vrettos, Georgios and Logaras, Evangelos and Kalligeros, Emmanouil},
  booktitle={2018 IEEE 13th International Symposium on Industrial Embedded Systems (SIES)}, 
  title={Towards Standardization of MQTT-Alert-based Sensor Networks: Protocol Structures Formalization and Low-End Node Security}, 
  year={2018},
  volume={},
  number={},
  pages={1-4},
  abstract={We present a small scale sensor network application as a testbench to explore different setups in terms of hardware/ software, network protocol and data processing/storage scheme options, focusing on alert-based sensor systems with long idle times. Our specifications required the deployment of the network using the MQTT protocol over an encrypted TLS connection. We focused on using sensor nodes with low-power consumption profile, as well as on the formalization of the MQTT protocol's basic elements, by clearly defining the topic/message scheme used across the network. In addition, we experimented on how to combine locally stored information with data from popular cloud-based platforms and also acquired results regarding the processing performance of the nodes using different data exchange formats and database technologies. Work in progress includes data preprocessing on the network edge targeting distribution of the processing power across the network and network-traffic limitation, and also big data post-processing on server side or on dedicated high performance nodes to reveal hidden data patterns.},
  keywords={},
  doi={10.1109/SIES.2018.8442109},
  ISSN={2150-3117},
  month={June},}
@ARTICLE{8447059,
  author={Wang, Zhaoyang and Zhang, Baihai and Wang, Xiaoyi and Chai, Senchun and Bai, Yuting},
  journal={IEEE Access}, 
  title={Cooperative Localization With Bounding Constraints in Mobile Wireless Sensor Networks}, 
  year={2018},
  volume={6},
  number={},
  pages={47011-47025},
  abstract={In mobile wireless sensor networks (WSNs), error accumulation, and outlier problem seriously decrease the localization accuracy. To find a more accurate and cost-effective localization algorithm, cooperative localization with bounding constraints is proposed in this paper. By depicting the factor graph, the cooperative localization combines the trajectory prediction and observation correction of adjacent node. The trajectory prediction utilizes the polynomial Newton interpolation and bounding box which avoid the gross error. The observation correction explores the belief propagation and variational message passing, which are improved by judgment factor and punctuation function. Experiments are conducted to verify the proposed method in the aspect of algorithm parameter configuration, experiment parameter configuration, and distribution parameter configuration. The experiment results show that the proposed method in this paper outperforms than existing methods in large-scale WSNs.},
  keywords={},
  doi={10.1109/ACCESS.2018.2867338},
  ISSN={2169-3536},
  month={},}
@ARTICLE{8451972,
  author={Ozik, Jonathan and Collier, Nicholson T. and Wozniak, Justin M. and Macal, Charles M. and An, Gary},
  journal={IEEE Transactions on Computational Social Systems}, 
  title={Extreme-Scale Dynamic Exploration of a Distributed Agent-Based Model With the EMEWS Framework}, 
  year={2018},
  volume={5},
  number={3},
  pages={884-895},
  abstract={Agent-based models (ABMs) integrate the multiple scales of behavior and data to produce higher order dynamic phenomena and are increasingly used in the study of important social complex systems in biomedicine, socioeconomics, and ecology/ resource management. However, the development, validation, and use of ABMs are hampered by the need to execute very large numbers of simulations in order to identify their behavioral properties, a challenge accentuated by the computational cost of running realistic, large-scale, potentially distributed ABM simulations. In this paper, we describe the Extreme-scale Model Exploration with Swift (EMEWS) framework that is capable of efficiently composing and executing large ensembles of simulations and other “black box” scientific applications while integrating model exploration (ME) algorithms developed with the use of widely available third-party libraries written in popular languages, such as R and Python. EMEWS combines novel stateful tasks with traditional run-to-completion many-task computing and solves many problems relevant to high-performance workflows, including scaling to very large numbers (millions) of tasks, maintaining state and locality information, and enabling effective multiple-language problem solving. We present the high-level programming model of the EMEWS framework and demonstrate how it is used to integrate an active learning ME algorithm to dynamically and efficiently characterize the parameter space of a large and complex, distributed message passing interface agent-based infectious disease model.},
  keywords={},
  doi={10.1109/TCSS.2018.2859189},
  ISSN={2329-924X},
  month={Sep.},}
@INPROCEEDINGS{8450453,
  author={Swain, Pravati and Christophorou, Christophoros and Bhattacharjee, Upasana and Silva, Cristiano M. and Pitsillides, Andreas},
  booktitle={2018 14th International Wireless Communications & Mobile Computing Conference (IWCMC)}, 
  title={Selection of UE-based Virtual Small Cell Base Stations using Affinity Propagation Clustering}, 
  year={2018},
  volume={},
  number={},
  pages={1104-1109},
  abstract={5G will require a number of Key Technological Components to meet its very ambitious goals, including Heterogeneous Networks a nd Small Cells. The Dense Deployme nt of Small Cell Base Stations (SBSs) will play a major role as they can be installed in a more targeted manner to relieve traffic in hot spot areas, increase coverage, and spectral efficiency. However, the current deployment of the SBS is static (examples include Femto, Pico, and Nano cells), normally deployed on demand around hotspots. In the scenario of unpredictable crowd movement, these static deployment of small cell can be inefficient with high CAPEX and OPEX. This paper focuses on the scenario where UE-based Virtual Small Cell Base Stations (UE-VBSs) can be dynamically selected among UEs to deal effectively with the non-stationary, non-uniform distribution of mobile traffic with respect to time and space domain. To implement this concept, we propose an efficient clustering technique (Affinity Propagation Clustering) to select the best set of UE-VBSs to supplement an overlay loaded SBS. Simulative evaluation highlights salient features of the technique, as well as its limitations with regard to scalability. Further, we discuss the modification of the algorithm according to our objec tive sc enario focusing on red ucing the message passing procedure to and from only a number of eligible UE-VBSs using the power received by a UE from the eligible UE-VBSs as a parameter. The algorithm is implemented and evaluated in MATLAB and, also validated using NS3 simulator.},
  keywords={},
  doi={10.1109/IWCMC.2018.8450453},
  ISSN={2376-6506},
  month={June},}
@INPROCEEDINGS{8452015,
  author={Schmitt, Jonas and Köstler, Harald and Eitzinger, Jan and Membarth, Richard},
  booktitle={2018 17th International Symposium on Parallel and Distributed Computing (ISPDC)}, 
  title={Unified Code Generation for the Parallel Computation of Pairwise Interactions Using Partial Evaluation}, 
  year={2018},
  volume={},
  number={},
  pages={17-24},
  abstract={The evaluation of pairwise interactions is fundamental for the simulation of most molecular processes. Their efficient computation is therefore crucial for the overall performance of these simulations on modern computer architectures. We show how code for the computation of pairwise interactions on parallel and heterogeneous platforms can be generated from a unified base through partial evaluation of higher-order functions. For this purpose we introduce a complete implementation of the neighbor list algorithm based on the AnyDSL framework, from which we are able to generate executables for both CPU and GPU through compile-time specialization. Furthermore, we discuss the advantages and disadvantages of our approach and compare it with the miniMD simulation package from the Mantevo project, which is implemented in the C++ programming language and uses a similar computational core as the widely used molecular dynamics package LAMMPS. Finally, we assess the performance of our implementation in a number of test cases on modern CPU and GPU hardware.},
  keywords={},
  doi={10.1109/ISPDC2018.2018.00012},
  ISSN={},
  month={June},}
@INPROCEEDINGS{8449646,
  author={Yu, Hengbiao},
  booktitle={2018 IEEE/ACM 40th International Conference on Software Engineering: Companion (ICSE-Companion)}, 
  title={Combining Symbolic Execution and Model Checking to Verify MPI Programs}, 
  year={2018},
  volume={},
  number={},
  pages={527-529},
  abstract={Message Passing Interface (MPI) has become the standard programming paradigm in high performance computing. It is challenging to verify MPI programs because of high parallelism and non-determinism. This paper presents MPI symbolic verifier (MPI-SV), the first symbolic execution based tool for verifying MPI programs having both blocking and non-blocking operations. MPI-SV exploits symbolic execution to automatically generate path-level models, and performs model checking on the models w.r.t. expected properties. The results of model checking are leveraged to prune redundant paths. We have implemented MPI-SV and the extensive evaluation demonstrates MPI-SV's effectiveness and efficiency.},
  keywords={},
  doi={},
  ISSN={2574-1934},
  month={May},}
@INPROCEEDINGS{8453195,
  author={Lange, Julien and Ng, Nicholas and Toninho, Bernardo and Yoshida, Nobuko},
  booktitle={2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)}, 
  title={A Static Verification Framework for Message Passing in Go Using Behavioural Types}, 
  year={2018},
  volume={},
  number={},
  pages={1137-1148},
  abstract={The Go programming language has been heavily adopted in industry as a language that efficiently combines systems programming with concurrency. Go's concurrency primitives, inspired by process calculi such as CCS and CSP, feature channel-based communication and lightweight threads, providing a distinct means of structuring concurrent software. Despite its popularity, the Go programming ecosystem offers little to no support for guaranteeing the correctness of message-passing concurrent programs. This work proposes a practical verification framework for message passing concurrency in Go by developing a robust static analysis that infers an abstract model of a program's communication behaviour in the form of a behavioural type, a powerful process calculi typing discipline. We make use of our analysis to deploy a model and termination checking based verification of the inferred behavioural type that is suitable for a range of safety and liveness properties of Go programs, providing several improvements over existing approaches. We evaluate our framework and its implementation on publicly available real-world Go code.},
  keywords={},
  doi={10.1145/3180155.3180157},
  ISSN={1558-1225},
  month={May},}
@INPROCEEDINGS{8457176,
  author={Pechwises, Chayawat and Chanchio, Kasidit},
  booktitle={2018 15th International Joint Conference on Computer Science and Software Engineering (JCSSE)}, 
  title={A Transparent Hypervisor-level Checkpoint-Restart Mechanism for a Cluster of Virtual Machines}, 
  year={2018},
  volume={},
  number={},
  pages={1-6},
  abstract={A cluster of virtual machines is a common platform for running MPI applications in cloud computing environments. However, most traditional methods to provide fault tolerance to these applications are not fully transparent and require specific, checkpointing-enabled MPI software. This paper presents a novel Transparent Hypervisor-level Checkpoint-Restart mechanism, namely the Virtual Cluster Checkpoint-Restart (VCCR), to perform checkpoint and restart operations at hypervisor-level. VCCR is highly transparent to MPI applications and guest OS. In VCCR, a software framework consisting of a controller and agent processes is created to perform checkpoint and restart operations for the entire cluster. The checkpoint and restart protocols of VCCR are designed based on the principles of barrier synchronization and virtual time to maintain global consistency and efficiency. We have developed a prototype of VCCR on top the QEMU-KVM software and conducted two preliminary experiments using NAS Parallel Benchmark. Experimental results confirm that VCCR can correctly and efficiently checkpoint and restart a cluster of virtual machines.},
  keywords={},
  doi={10.1109/JCSSE.2018.8457176},
  ISSN={},
  month={July},}
@INPROCEEDINGS{8468297,
  author={Krinkin, Kirill and Filatov, Antoni and Filatov, Artyom and Kurishev, Oleg and Lyanguzov, Alexander},
  booktitle={2018 22nd Conference of Open Innovations Association (FRUCT)}, 
  title={Data Distribution Services Performance Evaluation Framework}, 
  year={2018},
  volume={},
  number={},
  pages={94-100},
  abstract={DDS (data distribution service) is a middleware protocol and API standard for data transferring using a publisher-subscriber model from the Object Management Group (OMG). There exist various open source and commercial implementations of DDS standard that provides API and services for data distribution. Every developer claims that his implementation fits standard and provides the best possible parameters for data transferring. Three different implementations of DDS are compared to determine their usability and performance characteristics. This paper presents a testing framework that allows to evaluate different implementations in the same experiments and moreover to include another DDS.},
  keywords={},
  doi={10.23919/FRUCT.2018.8468297},
  ISSN={2305-7254},
  month={May},}
@INPROCEEDINGS{8473351,
  author={Deogirikar, Jyoti and Vidhate, Amarsinh},
  booktitle={2018 Second International Conference on Inventive Communication and Computational Technologies (ICICCT)}, 
  title={A Comprehensive Development and Testing of Improved Publish-Subscribe Method for IoT}, 
  year={2018},
  volume={},
  number={},
  pages={1796-1801},
  abstract={Internet of Things (IoT) is a network of smart devices which communicate with each other to accomplish task or provide any particular service. In IoT, smart objects have to provide services continuously by realizing requirement of a person without disturbing him. To accomplish this task, IoT devices need to share information with each other as soon as it updates. In such condition, request-response technique creates overhead on the system. So publish-subscribe technique is used to get an immediate response as soon as data changes. Service consumer or subscriber needs to send a request for particular service to the broker. The broker will maintain the list of the subscriber and will forward data to all subscribers as it updates. But this broker creates single point bottleneck in publish-subscribe communication. In this paper, distributed publish-subscribe techniques has been proposed which will distribute publishers and subscribers on the different brokers removing single point bottleneck. It will also distribute the load of brokers and improve the availability of service. For simulation purpose, we have used QualNet 5.1 simulation tool. Simulation is done by using parameters like number of total packets received by all nodes in simulation, end to end delay as number of nodes increases also number of total packets received by all nodes in simulation as number of transaction increases.},
  keywords={},
  doi={10.1109/ICICCT.2018.8473351},
  ISSN={},
  month={April},}
@INPROCEEDINGS{8479004,
  author={House, Amy and Tang, Peiyi},
  booktitle={SoutheastCon 2018}, 
  title={A TLA+ Module for Asynchronous Message-Passing Systems}, 
  year={2018},
  volume={},
  number={},
  pages={1-7},
  abstract={The combinatorial explosion of states makes distributed, asynchronous systems difficult for humans to reason about. Leslie Lamport's TLA+, a specification language based on Temporal Logic of Actions, provides a precise, formal language for discussing such systems without needing high-level mathematics. In this paper, we provide a reusable TLA+ module for specifying and model checking asynchronous message-passing systems. TLA+ syntax and semantics are introduced as we describe the module.},
  keywords={},
  doi={10.1109/SECON.2018.8479004},
  ISSN={1558-058X},
  month={April},}
@INPROCEEDINGS{8488651,
  author={Zhang, Yu and Zhang, Yuxiang},
  booktitle={2018 4th International Conference on Big Data Computing and Communications (BIGCOM)}, 
  title={Making Halide Efficient for Multicore Systems}, 
  year={2018},
  volume={},
  number={},
  pages={213-218},
  abstract={Graphics and imaging applications, especially emerging medical imaging or self-driving cars, demand orders of magnitude more computation, and require efficient image processing pipeline implementations. Halide is domain-specific language and compiler designed to make it easier write high performance image processing code. It separates what is being computed from how to compute, enabling programmers to tune to find a high performance schedule. However, Halide applications suffer poor scalability on large number of CPU cores. In this paper, we first perform a detailed parallelism and performance analysis of Halide applications on a 4x8-physical core Linux system. Our analysis shows that page faults and contention on shared address space as well as unaligned packed data movements are part of reasons for poor scalability. To improve the performance of Halide, we propose a novel thread model-Sthread-and adopt it to reimplement Halide runtime, i.e. Shalide, without modifying the Halide language, compiler and the runtime interface. The Sthread model allows each thread has its own memory management structure, and directly shares heap objects, globals and stack data with other threads. On six image processing benchmarks, Shalide shows better speedup and gives up to 1.53x faster than the original Halide.},
  keywords={},
  doi={10.1109/BIGCOM.2018.00041},
  ISSN={},
  month={Aug},}

@INPROCEEDINGS{8486361,
  author={Liu, Shuhao and Chen, Li and Li, Baochun and Carnegie, Aiden},
  booktitle={IEEE INFOCOM 2018 - IEEE Conference on Computer Communications}, 
  title={A Hierarchical Synchronous Parallel Model for Wide-Area Graph Analytics}, 
  year={2018},
  volume={},
  number={},
  pages={531-539},
  abstract={Graph analytics has emerged as one of the fundamental techniques to support modern Internet applications. As real-world graph data is generated and stored globally, the scale of the graph that needs to be processed keeps growing. It is critical to efficiently process graphs across multiple geographically distributed datacenters, running wide-area graph analytics. Existing graph analytics frameworks are not designed to run across multiple datacenters well, as they implement a Bulk Synchronous Parallel model that requires excessive wide-area data transfers. In this paper, we present a new Hierarchical Synchronous Parallel model designed and implemented for synchronization across datacenters with a much improved efficiency in inter-datacenter communication. Our new model requires no modifications to graph analytics applications, yet guarantees their convergence and correctness. Our prototype implementation on Apache Spark can achieve up to 32% lower WAN bandwidth usage, 49% faster convergence, and 30% less total cost for benchmark graph algorithms, with input data stored across five geographically distributed datacenters.},
  keywords={},
  doi={10.1109/INFOCOM.2018.8486361},
  ISSN={},
  month={April},}
@INPROCEEDINGS{8495217,
  author={Oswald, Nicholas and Monismith, David R.},
  booktitle={2018 IEEE Symposium on Electromagnetic Compatibility, Signal Integrity and Power Integrity (EMC, SI & PI)}, 
  title={Radar Cross Sections of Objects with Simulated Defects Using the Parallel FDTD Method}, 
  year={2018},
  volume={},
  number={},
  pages={12-17},
  abstract={In this paper, we investigate radar cross-section (RCS) variations in objects coated with radar absorbent material (RAM). These objects have RAM defects of varying size and placement. Preliminary analysis of these RCS variations provides a starting point to determine defect tolerance levels for RAM-coated objects such as wind turbines. This is of great importance to air traffic control (ATC) because turbine blades are coated with RAM to prevent electromagnetic interference with ATC radars. To complete our analysis, we compute the RCS of objects with introduced defects using an MPI finite-difference time-domain (FDTD) algorithm. We first present background information on the FDTD algorithm, including development of our message passing interface (MPI) FDTD algorithm and its current performance and scaling results. Next, comparisons for validation of MPI-FDTD results are made against results from the Analytic Solution to the RCS of a perfect electric conductor (PEC) Sphere with a Dielectric coating. We begin our investigation by computing the RCS of PEC spheres and flat plates, coated with RAM, and including various simulated defects. Finally, we present results from a parameter sweep varying the size and shape of simulated defects. These results show the relationship between the RCS of pristine objects and objects with defects, and they will be useful for future maintenance of coated objects.},
  keywords={},
  doi={10.1109/EMCSI.2018.8495217},
  ISSN={},
  month={July},}
@INPROCEEDINGS{8514890,
  author={Garg, Rohan and Mohan, Apoorve and Sullivan, Michael and Cooperman, Gene},
  booktitle={2018 IEEE International Conference on Cluster Computing (CLUSTER)}, 
  title={CRUM: Checkpoint-Restart Support for CUDA's Unified Memory}, 
  year={2018},
  volume={},
  number={},
  pages={302-313},
  abstract={Unified Virtual Memory (UVM) was recently introduced with CUDA version 8 and the Pascal GPU. The older CUDA programming style is akin to older large-memory UNIX applications which used to directly load and unload memory segments. Newer CUDA programs have started taking advantage of UVM for the same reasons of superior programmability that UNIX applications long ago switched to assuming the presence of virtual memory. Therefore, checkpointing of UVM has become increasing important, especially as NVIDIA CUDA continues to gain wider popularity: 87 of the top 500 supercomputers in the latest listings use NVIDIA GPUs, with a current trend of ten additional NVIDIA-based supercomputers each year. A new scalable checkpointing mechanism, CRUM (Checkpoint-Restart for Unified Memory), is demonstrated for hybrid CUDA/MPI computations across multiple computer nodes. The support for UVM is particularly attractive for programs requiring more memory than resides on the GPU, since the alternative to UVM is for the application to directly copy memory between device and host. Furthermore, CRUM supports a fast, forked checkpointing, which mostly overlaps the CUDA computation with storage of the checkpoint image in stable storage. The runtime overhead of using CRUM is 6% on average, and the time for forked checkpointing is seen to be a factor of up to 40 times less than traditional, synchronous checkpointing.},
  keywords={},
  doi={10.1109/CLUSTER.2018.00047},
  ISSN={2168-9253},
  month={Sep.},}
@INPROCEEDINGS{8514893,
  author={Hunold, Sascha and Carpen-Amarie, Alexandra},
  booktitle={2018 IEEE International Conference on Cluster Computing (CLUSTER)}, 
  title={Hierarchical Clock Synchronization in MPI}, 
  year={2018},
  volume={},
  number={},
  pages={325-336},
  abstract={MPI benchmarks are used for analyzing or tuning the performance of MPI libraries. Generally, every MPI library should be adjusted to the given parallel machine, especially on supercomputers. System operators can define which algorithm should be selected for a specific MPI operation, and this decision which algorithm to select is usually made after analyzing bench-mark results. The problem is that the latency of communication operations in MPI is very sensitive to the chosen data acquisition and data processing method. For that reason, depending on how the performance is measured, system operators may end up with a completely different MPI library setup. In the present work, we focus on the problem of precisely measuring the latency of collective operations, in particular, for small payloads, where external experimental factors play a significant role. We present a novel clock synchronization algorithm, which exploits the hierarchical architecture of compute clusters, and we show that it outperforms previous approaches, both in run-time and in precision. We also propose a different scheme to obtain precise MPI run-time measurements (called Round-Time), which is based on given, fixed time slices, as opposed to the traditional way of measuring for a predefined number of repetitions. We also highlight that the use of MPI_Barrier has a significant effect on experimentally determined latency values of MPI collectives. We argue that MPI_Barrier should be avoided if the average run-time of the barrier function is in the same order of magnitude as the run-time of the MPI function to be measured.},
  keywords={},
  doi={10.1109/CLUSTER.2018.00050},
  ISSN={2168-9253},
  month={Sep.},}
@INPROCEEDINGS{8514912,
  author={Weeks, Nathan and Luecke, Glenn and Maris, Pieter and Vary, James},
  booktitle={2018 IEEE International Conference on Cluster Computing (CLUSTER)}, 
  title={Challenges in Developing MPI Fault-Tolerant Fortran Applications}, 
  year={2018},
  volume={},
  number={},
  pages={524-531},
  abstract={Powerful high performance computing systems of the future are expected to have higher failure rates than current systems. As a result, HPC applications running on such future systems are more likely to encounter a system failure than on today's machines. Application fault tolerance is therefore becoming more important to avoid costly waste of resources associated with rerunning failed applications. The MPI 3.1 standard does not address the issue of MPI process failures. Checkpoint/restart is commonly used to add fault tolerance to MPI applications. However, there can be complicated issues impacting an MPI application's ability to correctly and efficiently write checkpoint files, particularly if Fortran I/O statements are used. Moreover, it may be inefficient restart a large number MPI processes from a checkpoint. Several MPI fault tolerance libraries, such as ULFM, are being developed to enabl MPI programs to recover from MPI process failures. This can circumvent much of the overhead of an application restart, including rescheduling, launching, initializing, and reading checkpoint data. Each library uses a different approach to recovery from MPI process failures. Unfortunately, some of the proposed recovery models are incompatible with Fortran. This paper intends to help Fortran MPI application developers avoid problems when developing fault-tolerant MPI applications.},
  keywords={},
  doi={10.1109/CLUSTER.2018.00068},
  ISSN={2168-9253},
  month={Sep.},}
@INPROCEEDINGS{8514894,
  author={Samfass, Philipp and Klinkenberg, Jannis and Bader, Michael},
  booktitle={2018 IEEE International Conference on Cluster Computing (CLUSTER)}, 
  title={Hybrid MPI+OpenMP Reactive Work Stealing in Distributed Memory in the PDE Framework sam(oa)^2}, 
  year={2018},
  volume={},
  number={},
  pages={337-347},
  abstract={"Equal work results in equal execution time" is an assumption that has fundamentally driven design and implementation of parallel applications for decades. However, increasing hardware variability on current architectures (e.g., through Turbo Boost, dynamic voltage and frequency scaling or thermal effects) necessitate a revision of this assumption. Expecting an increase of these effects on future (exascale-)systems, in this paper, we present reactive work stealing across nodes on distributed memory machines using only MPI and OpenMP. We develop a novel distributed work stealing concept that - based on on-line performance monitoring - selectively steals and remotely executes tasks across MPI boundaries. This concept has been implemented in the parallel adaptive mesh refinement (AMR) framework sam(oa)2 for OpenMP tasks of traversing a grid section. Corresponding performance measurements in the presence of enforced CPU clock frequency imbalances demonstrate that a state-of-the-art cost-based (chains-on-chains partitioning) load balancing mechanism is insufficient and can even degrade performance while distributed work stealing successfully mitigates the frequency-induced imbalances. Furthermore, our results indicate that our approach is also suitable for load balancing work-induced imbalances in a realistic AMR test case.},
  keywords={},
  doi={10.1109/CLUSTER.2018.00051},
  ISSN={2168-9253},
  month={Sep.},}
@INPROCEEDINGS{8514406,
  author={González, Patricia and Losada, Nuria and Martín, María J.},
  booktitle={2018 International Conference on High Performance Computing & Simulation (HPCS)}, 
  title={Insights into Application-level Solutions towards Resilient MPI Applications}, 
  year={2018},
  volume={},
  number={},
  pages={610-613},
  abstract={Current petascale systems, formed by hundreds of thousands of cores, are highly dynamic, which causes that hardware failure rates are relatively high. Failure data collected from two large high-performance computing sites have been analysed in [1], showing failure rates from 20 to more than 1,000 failures per year, depending mostly on system size. This can be translated in a failure every 8.7 hours. Future exascale systems, formed by several millions of cores, will be hit by error/faults even more frequently due to their scale and complexity [2]. Thus, long-running applications in these systems will need to use fault tolerance techniques to ensure the successful execution completion.},
  keywords={},
  doi={10.1109/HPCS.2018.00101},
  ISSN={},
  month={July},}
@INPROCEEDINGS{8514407,
  author={Butelle, Franck and Coti, Camille},
  booktitle={2018 International Conference on High Performance Computing & Simulation (HPCS)}, 
  title={Distributed Snapshot for Rollback-Recovery with One-Sided Communications}, 
  year={2018},
  volume={},
  number={},
  pages={614-620},
  abstract={Traditional interprocess communication requires cooperation and synchronization between sender and receiver. The One-sided communication model is a new way and very promising model: processes can directly read or write in the memory of another process. In such a model, fault tolerance is a challenging problem. In this paper, we present algorithms to be able to do rollback-recovery based on global snapshot in a distributed system with one-sided communications.},
  keywords={},
  doi={10.1109/HPCS.2018.00102},
  ISSN={},
  month={July},}
@INPROCEEDINGS{8535938,
  author={Yang, Dongsheng and Lian, Mengjia and Zhang, Zhan and Li, Mingshi},
  booktitle={2018 IEEE International Conference on Intelligence and Safety for Robotics (ISR)}, 
  title={The research and design of Pub/Sub Communication Based on Subscription Aging}, 
  year={2018},
  volume={},
  number={},
  pages={475-479},
  abstract={The large-scale distributed systems usually use publish/subscribe to implement asynchronous and loosely-coupled communication, which well satisfies the requirements for resource sharing and work coordination between distributed applications. When a large number of messages are transmitted in traditional pub/sub communication system, the message server often suffers from performance bottlenecks and single point of failure. Hence this article proposes a pub/sub communication model based on subscription aging, which is an improvement over the traditional pub/sub model. It sets the priority of subscribers according to the timeliness of subscription conditions, introduces subscriber groups to classify the subscribers, and then adopts multicast transmission method to send data to the sub_group. The way improves the efficiency and performance of the pub/sub system. Multiple priority cache queues were designed based on the mapping relationship between priority and hot topics. According to experimental tests, this method has good communication performance when the number of subscribers gradually increase, and the caching mechanism ensures the reliability of the system.},
  keywords={},
  doi={10.1109/IISR.2018.8535938},
  ISSN={},
  month={Aug},}
@ARTICLE{8540343,
  author={Sohn, Illsoo and Lee, Sang Hyun},
  journal={IEEE Access}, 
  title={A Message-Passing Approach to Self-Organizing Internet-of-Things Based Public Safety Networks}, 
  year={2018},
  volume={6},
  number={},
  pages={71783-71792},
  abstract={This paper develops a distributed self-organizing strategy for an Internet-of-Things (IoT)-based public safety network (IPSN). Recent advances in wireless broadband and multimedia services have evolved PSNs extensively. Third generation partnership project long term evolution (3GPP-LTE) becomes a basic platform for deploying public safety networks around the world. There have been extensive studies on LTE-based PSNs satisfying mission-critical requirements. However, most studies focus on investigating PSNs with network infrastructure, and there is little progress on infrastructure-less PSNs, where base stations and network coordinators become destroyed or impaired. This paper focuses on infrastructure-less PSNs, where battery-powered individual IoT devices cooperate to construct the network without any central coordination. It is aimed at maximizing the network survival time of the IPSN while satisfying mission-critical requirements. A highly nonlinear nature of the network construction problem with several constraints renders the optimization task very challenging. In addition, no coordinator exists in IPSNs and all nodes are subject to the identification of distributed strategy to achieve the goal. To this end, a state-of-the-art message-passing framework is introduced to develop a novel distributed algorithm. The major benefit originates from the controllability of the limit on wireless link hops to meet the data reliability and transmission latency required for mission-critical IPSNs. We also establish the proof on the optimality. The proposed technique converges rapidly and keeps the computation load per IoT device low, which makes it attractive for practical implementation. Simulation results verify that the proposed approach outperforms various existing approaches considerably and consistently.},
  keywords={},
  doi={10.1109/ACCESS.2018.2882250},
  ISSN={2169-3536},
  month={},}
@ARTICLE{8540813,
  author={Zhang, Guozhen and Liu, Yi and Yang, Hailong and Qian, Depei},
  journal={IEEE Access}, 
  title={A Lightweight and Flexible Tool for Distinguishing Between Hardware Malfunctions and Program Bugs in Debugging Large-Scale Programs}, 
  year={2018},
  volume={6},
  number={},
  pages={71892-71905},
  abstract={In this paper, we propose a new technique to distinguish the reason for program failure between hardware malfunctions and program bugs, which mitigates the impact of shorter mean time between failures to the debugging process on the future exa-scale supercomputers and improves the productivity of debugging large-scale parallel programs. Our technique detects program failures by observing the abnormal message passing behaviors with distributed monitors and leverages event-driven mechanism to trigger global status checking among different node groups concurrently. Besides, both coarse-grained execution snapshots and fine-grained failure events can be provided for further failure diagnosis and bug analysis. We implement this technique as a user-space library named failure cause resolver (FCR). Experimental results on the Tianhe-2 supercomputer demonstrate that the latency of FCR for failure detection is acceptable with negligible overhead. In addition, FCR does not require administrative privilege and can be easily integrated into existing large-scale parallel programs.},
  keywords={},
  doi={10.1109/ACCESS.2018.2882394},
  ISSN={2169-3536},
  month={},}
@INPROCEEDINGS{8546166,
  author={Peryshkova, Eugene N. and Kurnosov, Mikhail G.},
  booktitle={2018 XIV International Scientific-Technical Conference on Actual Problems of Electronics Instrument Engineering (APEIE)}, 
  title={Experimental Study of Network Contention Effects on All-to-All Operation}, 
  year={2018},
  volume={},
  number={},
  pages={506-510},
  abstract={Interconnection networks of modern high-performance distributed computer systems are now deep hierarchical. In such systems, communication time between processors depends on their replacement in a computer system. In large-scale NUMA/SMP computer clusters network switches form the first level of this hierarchy and the second level is represented by a shared memory of computer nodes. In this paper we present a benchmark for estimating the message passing time when MPI-processes share the interconnection network. We studied the dependence of the execution time of the All-to-all collective operation on the message size and the number of processes sharing the communication channel. Authors developed a software for predicting the completion time of the All-to-all operation depending on the nodes allocation determined by the Resources and Jobs Management System. The software uses the results of an experimental estimate of the performance degradation for the MPI_Send/MPI_Recv operations during simultaneous (concurrent) usage of the communication channel by a set of processes. In future, we will develop structurally oriented algorithms for the determined nodes allocation.},
  keywords={},
  doi={10.1109/APEIE.2018.8546166},
  ISSN={2473-8573},
  month={Oct},}
@INPROCEEDINGS{8563809,
  author={Mei, WuJie and Bai, Yang and Zuo, Sheng and Doñoro, Daniel García and Zhang, Yu},
  booktitle={2018 International Conference on Microwave and Millimeter Wave Technology (ICMMT)}, 
  title={A Memory Reduction Scheme for Parallel Finite Element Method Sparse Matrix Equation Solving}, 
  year={2018},
  volume={},
  number={},
  pages={1-3},
  abstract={Focusing on the huge memory requirements of finite element method, when solving complex electric large size problem, a memory reduction scheme based on schur complement (MRS-SC) for parallel finite element method sparse matrix equation solving is proposed in this paper. The scheme's main idea is to convert the global system of equations to a local system of equations for each MPI (message passing interface) process through schur complement. The accuracy of the method and the memory saving efficiency are verified by numerical examples. As the scale of the problem increases, this method can achieve about a 40% reduction in memory usage over the traditional approach.},
  keywords={},
  doi={10.1109/ICMMT.2018.8563809},
  ISSN={},
  month={May},}
@INPROCEEDINGS{8533491,
  author={Xiong, Qingqing and Skjellum, Anthony and Herbordt, Martin C.},
  booktitle={2018 28th International Conference on Field Programmable Logic and Applications (FPL)}, 
  title={Accelerating MPI Message Matching through FPGA Offload}, 
  year={2018},
  volume={},
  number={},
  pages={191-1914},
  abstract={The Message Passing Interface (MPI) is the de facto communication standard for distributed-memory High-Performance Computing (HPC) systems. Ultra-low latency communication in HPC is difficult to achieve because of MPI processing requirements, in particular matching requests and messages done by traversing the corresponding queues. Many researchers have addressed this issue by redesigning queues or by offloading them to hardware accelerators. However, state-of-art software approaches cannot free CPUs “from the misery” and hardware approaches either lack scalability or still leave substantial room for further improvement. With the emergence of numerous tightly coupled CPU-FPGA computing architectures, offload of MPI functionality to user-controlled hardware is now becoming viable; we find it productive to revisit hardware approaches. To maintain the generality necessary to support MPI while preventing high resource utilization, we design our MPI queue processing offload based on a recent analysis of performance characteristics in HPC applications. We propose a novel, two-level message queue design: a content addressable memory (CAM) coupled with a resource-saving hardware linked-list. We also propose an optimization that maintains high speed in the cases when the queue is long. To test our design, we create an SOC-based testbed consisting of softcore processors and hardware implementations of the MPI communication stacks. Even while using only a small fraction of the Stratix-V logic, our design can be one to two orders of magnitude faster than two well-known hardware designs.},
  keywords={},
  doi={10.1109/FPL.2018.00039},
  ISSN={1946-1488},
  month={Aug},}
@INPROCEEDINGS{8564482,
  author={Losada, Nuria and Bautista-Gomez, Leonardo and Keller, Kai and Unsal, Osman},
  booktitle={2018 IEEE/ACM 8th Workshop on Fault Tolerance for HPC at eXtreme Scale (FTXS)}, 
  title={Towards Ad Hoc Recovery for Soft Errors}, 
  year={2018},
  volume={},
  number={},
  pages={1-10},
  abstract={The coming exascale era is a great opportunity for high performance computing (HPC) applications. However, high failure rates on these systems will hazard the successful completion of their execution. Bit-flip errors in dynamic random access memory (DRAM) account for a noticeable share of the failures in supercomputers. Hardware mechanisms, such as error correcting code (ECC), can detect and correct single-bit errors and can detect some multi-bit errors while others can go undiscovered. Unfortunately, detected multi-bit errors will most of the time force the termination of the application and lead to a global restart. Thus, other strategies at the software level are needed to tolerate these type of faults more efficiently and to avoid a global restart. In this work, we extend the FTI checkpointing library to facilitate the implementation of custom recovery strategies for MPI applications, minimizing the overhead introduced when coping with soft errors. The new functionalities are evaluated by implementing local forward recovery on three HPC benchmarks with different reliability requirements. Our results demonstrate a reduction on the recovery times by up to 14%.},
  keywords={},
  doi={10.1109/FTXS.2018.00004},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{8588213,
  author={Palanciuc Mawas, Dorin Mihai},
  booktitle={2018 IEEE International Conference on Computational Science and Engineering (CSE)}, 
  title={Analysis and Design of DOORS, in the Context of Consistency, Availability, Partitioning and Latency}, 
  year={2018},
  volume={},
  number={},
  pages={12-18},
  abstract={DOORS is a distributed system proposal that provides execution and storage services in the form of "objects", which encapsulate both state and behaviour. We start by briefly describing the current state of the DOORS solution, as detailed in previous work. We then outline the class of problems that we aim to solve with DOORS, and provide brief motivations for the architectural choices. As direct consequences of the chosen architecture (distributed message passing in favour of shared memory) we analyse the following critical aspects: concurrency control, replication and the choice between consistency and availability. With the support of this analysis, we identify and present 3 different "kinds" of inter-node communication. In spite of their apparent similarity, these scenarios are addressed differently into the design, such that the implementation of DOORS remains correct, consistent and useful.},
  keywords={},
  doi={10.1109/CSE.2018.00009},
  ISSN={},
  month={Oct},}
@INPROCEEDINGS{8595058,
  author={Coti, Camille and Evangelista, Sami and Petrucci, Laure},
  booktitle={2018 23rd International Conference on Engineering of Complex Computer Systems (ICECCS)}, 
  title={State Compression Based on One-Sided Communications for Distributed Model Checking}, 
  year={2018},
  volume={},
  number={},
  pages={41-50},
  abstract={We propose a distributed implementation of the collapse compression technique used by explicit state model checkers to reduce memory usage. This adapatation makes use of lock-free distributed hash tables based on one-sided communication primitives provided by libraries such as OpenSHMEM. We implemented this technique in the distributed version of the model checker Helena. We report on experiments performed on the Grid'5000 cluster with an implementation over OpenMPI. These reveal that, for some models, this distributed implementation can altogether preserve the memory reduction provided by collapse compression and reduce execution times by allowing the exchanges of compressed states between processes.},
  keywords={},
  doi={10.1109/ICECCS2018.2018.00013},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{8599762,
  author={Sabbah, Ayman and Jarwan, Abdallah and Al-Shiab, Ismael and Ibnkahla, Mohamed and Wang, Maoyu},
  booktitle={MILCOM 2018 - 2018 IEEE Military Communications Conference (MILCOM)}, 
  title={Emulation of Large-Scale LTE Networks in NS-3 and CORE: A Distributed Approach}, 
  year={2018},
  volume={},
  number={},
  pages={1-6},
  abstract={Long Term Evolution (LTE) is a promising technology to be used for Mission-Critical Networks (MCNs); emulating such technology is important to test different scenarios before real deployment. However, using the Network Simulator (NS-3) to simulate large-scale LTE networks has proven to be very time consuming. Hence, there is a need to speed up such simulations in order to facilitate real-time emulation and interaction of large-scale LTE networks with external systems. In this paper, we propose a new approach to enable the emulation of large-scale LTE networks by employing distributed topologies along with the Message Passing Interface (MPI) protocol. The proposed approach is integrated with the Common Open Research Emulator (CORE) to enable exchange of real-time traffic between the simulated LTE network and Hardware-In-the Loop (HIL). Performance studies were carried out to evaluate the scaling performance of emulated LTE networks in real time. The results show that distributed implementation succeeds in running scenarios within the wall-clock time.},
  keywords={},
  doi={10.1109/MILCOM.2018.8599762},
  ISSN={2155-7586},
  month={Oct},}
@INPROCEEDINGS{8600934,
  author={Nigro, Libero and Sciammarella, Paolo F.},
  booktitle={2018 IEEE/ACM 22nd International Symposium on Distributed Simulation and Real Time Applications (DS-RT)}, 
  title={Time Synchronization in Wireless Sensor Networks: A Modeling and Analysis Experience Using Theatre}, 
  year={2018},
  volume={},
  number={},
  pages={1-8},
  abstract={This paper describes a modelling and analysis experience concerning time synchronization in wireless sensor networks (WSN). A fully distributed algorithm is formally modelled and its properties assessed through statistical model checking. The described work is based on the Theatre framework which rests on actors and asynchronous message passing. Theatre can be reduced to the Uppaal Statistical Model Checker (SMC). The paper discusses the chosen time synchronization algorithm, outlines the Theatre modelling features and its mapping on to Uppaal Smc, and shows a Theatre model for the selected time synchronization algorithm enhanced with a new adaptation mechanism for energy saving. The model is then analyzed through simulations.},
  keywords={},
  doi={10.1109/DISTRA.2018.8600934},
  ISSN={1550-6525},
  month={Oct},}
@INPROCEEDINGS{8613974,
  author={Melnyk, Darya and Wattenhofer, Roger},
  booktitle={2018 IEEE 37th Symposium on Reliable Distributed Systems (SRDS)}, 
  title={Byzantine Agreement with Interval Validity}, 
  year={2018},
  volume={},
  number={},
  pages={251-260},
  abstract={To solve Byzantine agreement, n nodes with real input values, among which t <; n/3 are Byzantine, have to agree on a common consensus value. Previous research has mainly focused on determining a consensus value equal to an input value of some arbitrary node. In this work we instead assume that the values of the nodes are ordered and introduce a novel validity condition which accepts consensus values that are close to the k-th smallest value of the correct nodes. We propose a deterministic algorithm that approximates the k-th smallest value and show that this approximation is the best possible for the synchronous message passing model. Our approach is furthermore extended to multiple dimensions, where the order is not well-defined, and we show that our algorithm can be applied to determine a value that lies within a box around all correct input vectors.},
  keywords={},
  doi={10.1109/SRDS.2018.00036},
  ISSN={2575-8462},
  month={Oct},}
@INPROCEEDINGS{8622893,
  author={Hoque, Reazul and Shamis, Pavel},
  booktitle={2018 IEEE 20th International Conference on High Performance Computing and Communications; IEEE 16th International Conference on Smart City; IEEE 4th International Conference on Data Science and Systems (HPCC/SmartCity/DSS)}, 
  title={Distributed Task-Based Runtime Systems - Current State and Micro-Benchmark Performance}, 
  year={2018},
  volume={},
  number={},
  pages={934-941},
  abstract={High Performance Computing Systems are moving heavily towards many-core processors with a deep hierarchy of memory. Accelerators like GPUs are widely being used for general purpose computing and processor architectures are becoming increasingly complex to accommodate performance boost. This trend towards complex heterogeneous architecture makes the job of scientific application developers difficult in terms of performance, portability and productivity. With memory being distributed, this challenge becomes even more complex. Programming many-core shared memory systems are most widely accomplished using OpenMP, while MPI is used to manage the communications in a distributed system. Even though MPI provides a rich set of features, it is too explicit making users responsible for overlapping communication and computation. Task-based runtime systems have emerged as a solution to this challenge of programming these modern complex systems. This study surveys the landscape of task-based runtime systems that support distributed memory and presents a set of benchmark for evaluating and understanding runtime-performance and overheads of these systems.},
  keywords={},
  doi={10.1109/HPCC/SmartCity/DSS.2018.00155},
  ISSN={},
  month={June},}
@INPROCEEDINGS{8628861,
  author={Tian, Tian and Yang, Su and Gong, Dunwei},
  booktitle={2018 IEEE Symposium Series on Computational Intelligence (SSCI)}, 
  title={An Enhanced Set-based Evolutionary Algorithm for Generating Test Data that Cover Multiple Paths of a Parallel Program}, 
  year={2018},
  volume={},
  number={},
  pages={688-695},
  abstract={Although the traditional set-based evolutionary algorithm can generate test data covering multiple paths, it does not make full use of the uncertainty of parallel programs, information provided by the population during the evolution, and knowledge related to the domain, which makes the efficiency remain to be improved. This paper focuses on the problem of generating test data for multiple paths coverage of message-passing parallel programs, and proposes an enhanced set-based evolutionary algorithm that is suitable for parallel programs based on the evaluation of scheduling sequences to improve the efficiency in generating test data. We apply the proposed algorithm to nine message-passing parallel programs, and compare it with the traditional set-based evolutionary algorithm. The experimental results show that the proposed algorithm reduces the number of generations and the time consumption in test data generation.},
  keywords={},
  doi={10.1109/SSCI.2018.8628861},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{8628507,
  author={Setiawan, Ivan Pandu and Sukaridhoto, Sritrusta and Pramadihanto, Dadet},
  booktitle={2018 International Electronics Symposium on Knowledge Creation and Intelligent Computing (IES-KCIC)}, 
  title={Message Passing Support for FLoW Microkernel}, 
  year={2018},
  volume={},
  number={},
  pages={17-22},
  abstract={The demand for faster computation speed in modern digital signal processing is huge. However, the computation speed that single processor can provide is limited. To address this demand, both distributed system and parallel processing are becoming a requirement in an embedded system. Therefore, research about algorithm and application of parallel processing is very important to be conducted. Implementing MPI's standard to an embedded system will increase the application portability, therefore parallel programming will be easier to be implemented. This paper presents a novel design and implementation of MPI on top of our microkernel named FLoW which are built and run on an embedded system. To decrease communication latency, we propose a communication layer design based on MPI. On this layer, a process manager is made to handle multi-processes and routing services mechanism. In addition, a mailbox system is created to temporarily keep the message which is sent when the collective operation occurs. From our experiments, the time required to complete the data transmission process ranges from 400 to 500 microseconds for each process, and in parallel task testing using MPI, the speedup can achieve up to 40-50%.},
  keywords={},
  doi={10.1109/KCIC.2018.8628507},
  ISSN={},
  month={Oct},}
@INPROCEEDINGS{8631769,
  author={Kumar, Dileep and Memon, Sheeraz and Thebo, Liaquat Ali},
  booktitle={2018 12th International Conference on Signal Processing and Communication Systems (ICSPCS)}, 
  title={Design, Implementation & Performance Analysis of Low Cost High Performance Computing (HPC) Clusters}, 
  year={2018},
  volume={},
  number={},
  pages={1-6},
  abstract={More accuracy and minimizing time needed for the scientific calculations in the field of computing has become an important task currently. Scientific problems are computationally intensive and a lot of time is acquired to get the outcomes by utilizing computer with one processing element. High Performance Computing (HPC) describes utilization of many processors executes a computationally intensive task in parallel, which reduces the processing time. At present, one of the leading and fastest parallel computers is supercomputer contains the processing elements hundreds to thousands. A lot of effort and cost is needed to build very fast and dedicated supercomputers. Alternative is to build low cost HPC clusters using inexpensive hardware. In this paper, we implemented tested, compared and analyzed the processing ability of 3 different ×86-based and ARM-based low cost HPC clusters in terms of execution time and speedups. Finally concluded that in spite of the performance, clusters build with ARM-based single board computers are functional and handy for academic point of view due to its low-price and value to the restrictions of electricity.},
  keywords={},
  doi={10.1109/ICSPCS.2018.8631769},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{8634057,
  author={Wang, Lu and Guo, Lixin and Meng, Xiao},
  booktitle={2018 12th International Symposium on Antennas, Propagation and EM Theory (ISAPE)}, 
  title={Research on Electromagnetic Scattering Characteristics of Kelvin Wake of Ship Based on MPI}, 
  year={2018},
  volume={},
  number={},
  pages={1-4},
  abstract={An parallel small slope approximation acceleration algorithm based on MPI is improved to calculate the electromagnetic scattering of the ship's wake on the sea surface in this paper. The parallel algorithm calculates the backscattering coefficient at different angles by starting multiple processes, and can solve the electrical large scale electromagnetic scattering problem. The Kelvin wake model of the ship is established by the point source perturbation method. The Elfouhaily spectrum is adopted to construct the rough sea surface. Then the parallel small slope approximation method is used to calculate the electromagnetic scattering of the Kelvin wake produced by the ship. The electromagnetic scattering results were compared with those of pure sea surface. In addition, the effect of different wind speeds and different ship speeds on the electromagnetic scattering characteristics of the ship's Kelvin wake are also discussed. The acceleration ratio of different frequencies and different numbers of samples were calculated to further verify the effectiveness of the parallel algorithm.},
  keywords={},
  doi={10.1109/ISAPE.2018.8634057},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{8638405,
  author={Ye, Fangke and Schordan, Markus and Liao, Chunhua and Lin, Pei-Hung and Karlin, Ian and Sarkar, Vivek},
  booktitle={2018 IEEE/ACM 2nd International Workshop on Software Correctness for HPC Applications (Correctness)}, 
  title={Using Polyhedral Analysis to Verify OpenMP Applications are Data Race Free}, 
  year={2018},
  volume={},
  number={},
  pages={42-50},
  abstract={Among the most common and hardest to debug types of bugs in concurrent systems are data races. In this paper, we present an approach for verifying that an OpenMP program is data race free. We use polyhedral analysis to verify those parts of the program where we detect parallel affine loop nests. We show the applicability of polyhedral analysis with analysis-enabling program transformations for data race detection in HPC applications. We evaluate our approach with the dedicated data race benchmark suite DataRaceBench and the LLNL Proxy Application AMG2013 which consists of 75,000 LOC. Our evaluation shows that polyhedral analysis can classify 40% of the DataRaceBench 1.2.0 benchmarks as either data race free or having data races and verify that 41 of the 114 (36%) loop nests of AMG2013 are data race free.},
  keywords={},
  doi={10.1109/Correctness.2018.00010},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{8638356,
  author={Huchant, Pierre and Saillard, Emmanuelle and Barthou, Denis and Brunie, Hugo and Carribault, Patrick},
  booktitle={2018 IEEE/ACM 2nd International Workshop on Software Correctness for HPC Applications (Correctness)}, 
  title={PARCOACH Extension for a Full-Interprocedural Collectives Verification}, 
  year={2018},
  volume={},
  number={},
  pages={69-76},
  abstract={The advent to exascale requires more scalable and efficient techniques to help developers to locate, analyze and correct errors in parallel applications. PARallel COntrol flow Anomaly CHecker (PARCOACH) is a framework that detects the origin of collective errors in applications using MPI and/or OpenMP. In MPI, such errors include collective operations mismatches. In OpenMP, a collective error can be a barrier not called by all tasks in a team. In this paper, we present an extension of PARCOACH which improves its collective errors detection. We show our analysis is more precise and accurate than the previous one on different benchmarks and real applications.},
  keywords={},
  doi={10.1109/Correctness.2018.00013},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{8638388,
  author={Luo, Ziqing and Siegel, Stephen F.},
  booktitle={2018 IEEE/ACM 2nd International Workshop on Software Correctness for HPC Applications (Correctness)}, 
  title={Towards Deductive Verification of Message-Passing Parallel Programs}, 
  year={2018},
  volume={},
  number={},
  pages={59-68},
  abstract={Program verification techniques based on deductive reasoning can provide a very high level of assurance of correctness. These techniques are capable of proving correctness without placing artificial bounds on program parameters or on the sizes of inputs. While there are a number of mature frameworks for deductive verification of sequential programs, there is much less for parallel programs, and very little for message-passing. We propose a method for the deductive verification of message-passing programs that involves transforming the program into an annotated sequential program that can be verified with off-the-shelf deductive tools, such as Frama-C. The method can prove user-specified correctness properties without any bounds on the number of processes or other parameters. We illustrate this method on a toy example, and analyze its strengths and weaknesses.},
  keywords={},
  doi={10.1109/Correctness.2018.00012},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{8638148,
  author={Guo, Jia and Agrawal, Gagan},
  booktitle={2018 IEEE 25th International Conference on High Performance Computing (HiPC)}, 
  title={Achieving Performance and Programmability for MapReduce(-Like) Frameworks}, 
  year={2018},
  volume={},
  number={},
  pages={314-323},
  abstract={Programmability and performance are often considered alternatives in the context of HPC programming systems. For example, general purpose frameworks like MPI are associated with high performance, and though MapReduce and similar frameworks have demonstrated high programmability, it is also well accepted that they fall short in terms of performance. Providing abstractions that maintain high programmability and performance remains an open question. In this paper, we introduce two different variations of the original MapReduce API, We demonstrate efficient implementations of the three APIs, focusing on how the API differences impact middleware implementation, and examine the resulting performance. Furthermore, to understand how application characteristics impact relative performance of the three systems, we develop and validate a performance model. Overall, we show that a MapReduce-like AP that only requires small additional effort from programmers can provide high performance, outperforming Spark significantly.},
  keywords={},
  doi={10.1109/HiPC.2018.00043},
  ISSN={2640-0316},
  month={Dec},}
@INPROCEEDINGS{8638410,
  author={Nguyen Ba, Trung and Arora, Ritu},
  booktitle={2018 IEEE/ACM Workshop on Education for High-Performance Computing (EduHPC)}, 
  title={Towards Developing a Repository of Logical Errors Observed in Parallel Code for Teaching Code Correctness}, 
  year={2018},
  volume={},
  number={},
  pages={69-77},
  abstract={Debugging parallel programs can be a challenging task, especially for the beginners. While the debuggers like DDT and TotalView can be extremely useful in tracking down the program statements that are connected to the bugs, often the onus is on the programmers to reason about the logic of the program statements in order to fix the bugs in them. These debuggers may neither be able to precisely indicate the logical errors in the parallel programs nor they may provide information on fixing those errors. Therefore, there is a need for developing tools and educational content on teaching the pitfalls in parallel programming and writing correct code. Such content can be useful to guide the beginners in avoiding commonly observed logical errors and in verifying the correctness of their parallel programs. In this paper, we 1) enumerate some of the logical errors that we have seen in the parallel programs (OpenMP, MPI, and CUDA) that were written by the beginners working with us, and 2) discuss the ways to fix those errors. The errors are mainly related to the data distribution, exiting distributed for-loops, and workload-imbalance. The documentation on these logical errors can contribute in enhancing the productivity of the beginners, and can potentially help them in their debugging efforts. We have added the code samples containing logical errors and their solutions in a Github repository so that the others in the community can reproduce the errors on their systems and learn from them. The content presented in this paper may also be useful for those developing high-level tools for detecting and removing logical errors in parallel programs.},
  keywords={},
  doi={10.1109/EduHPC.2018.00011},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{8638598,
  author={McCaskey, Alexander and Dumitrescu, Eugene and Liakh, Dmitry and Humble, Travis},
  booktitle={2018 IEEE International Conference on Rebooting Computing (ICRC)}, 
  title={Hybrid Programming for Near-Term Quantum Computing Systems}, 
  year={2018},
  volume={},
  number={},
  pages={1-12},
  abstract={Recent computations involving quantum processing units (QPUs) have demonstrated a series of challenges inherent to hybrid classical-quantum programming, compilation, execution, and verification and validation. Despite considerable progress, system-level noise, limited low-level instructions sets, remote access models, and an overall lack of portability and classical integration presents near-term programming challenges that must be overcome in order to enable reliable scientific quantum computing and support robust hardware benchmarking. In this work, we draw on our experience in programming QPUs to identify common concerns and challenges, and detail best practices for mitigating these challenges within the current hybrid classical-quantum computing paradigm. Following this discussion, we introduce the XACC quantum compilation and execution framework as a hardware and language independent solution that addresses many of these hybrid programming challenges. XACC supports extensible methodologies for managing a variety of programming, compilation, and execution concerns across the increasingly diverse set of QPUs. We use recent nuclear physics simulations to illustrate how the framework mitigates programming, compilation, and execution challenges and manages the complex workflow present in QPU-enhanced scientific applications. Finally, we codify the resulting hybrid scientific computing workflow in order to identify key areas requiring future improvement.},
  keywords={},
  doi={10.1109/ICRC.2018.8638598},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{8638639,
  author={Dryden, Nikoli and Maruyama, Naoya and Moon, Tim and Benson, Tom and Yoo, Andy and Snir, Marc and Van Essen, Brian},
  booktitle={2018 IEEE/ACM Machine Learning in HPC Environments (MLHPC)}, 
  title={Aluminum: An Asynchronous, GPU-Aware Communication Library Optimized for Large-Scale Training of Deep Neural Networks on HPC Systems}, 
  year={2018},
  volume={},
  number={},
  pages={1-13},
  abstract={The following topics are dealt with: learning (artificial intelligence); parallel processing; neural nets; convolutional neural nets; data analysis; stochastic processes; gradient methods; image classification; message passing; evolutionary computation.},
  keywords={},
  doi={10.1109/MLHPC.2018.8638639},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{8638481,
  author={Jin, Charles and Baskaran, Muthu},
  booktitle={2018 IEEE/ACM 4th International Workshop on Extreme Scale Programming Models and Middleware (ESPM2)}, 
  title={Analysis of Explicit vs. Implicit Tasking in OpenMP Using Kripke}, 
  year={2018},
  volume={},
  number={},
  pages={62-70},
  abstract={Dynamic task-based parallelism has become a widely-accepted paradigm in the quest for exascale computing. In this work, we deliver a non-trivial demonstration of the advantages of explicit over implicit tasking in OpenMP 4.5 in terms of both expressiveness and performance. We target the Kripke benchmark, a mini-application used to test the performance of discrete particle codes, and find that the dependence structure of the core “sweep” kernel is well-suited for dynamic task-based systems. Our results show that explicit tasking delivers a 31.7% and 8.1% speedup over a pure implicit implementation for a small and large problem, respectively, while a hybrid variant also underperforms the explicit variant by 13.1% and 5.8%, respectively.},
  keywords={},
  doi={10.1109/ESPM2.2018.00012},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{8638485,
  author={Wilke, Jeremiah J. and Hollman, David S. and Lewis, Cannada and Markosyan, Aram and Morals, Nicolas},
  booktitle={2018 IEEE/ACM 4th International Workshop on Extreme Scale Programming Models and Middleware (ESPM2)}, 
  title={Distributed Memory Futures for Compile-Time, Deterministic-by-Default Concurrency in Distributed C++ Applications}, 
  year={2018},
  volume={},
  number={},
  pages={1-8},
  abstract={Futures are a widely-used abstraction for enabling deferred execution in imperative programs. Deferred execution enqueues tasks rather than explicitly blocking and waiting for them to execute. Many task-based programming models with some form of deferred execution rely on explicit parallelism that is the responsibility of the programmer. Deterministic-by-default (implicitly parallel) models instead use data effects to derive concurrency automatically, alleviating the burden of concurrency management. Both implicitly and explicitly parallel models are particularly challenging for imperative object-oriented programming. Fine-granularity parallelism across member functions or amongst data members may exist, but is often ignored. In this work, we define a general permissions model that leverages the C++ type system and move semantics to define an asynchronous programming model embedded in the C++ type system. Although a default distributed memory semantic is provided, the concurrent semantics are entirely configurable through C++ constexpr integers. Correct use of the defined semantic is verified at compile-time, allowing deterministic-by-default concurrency to be safely added to applications. Here we demonstrate the use of these ``extended futures'' for distributed memory asynchronous communication and load balancing. An MPI particle in-cell application is modified with the wrapper class using this task model, with results presented for a Haswell system up to 64 nodes.},
  keywords={},
  doi={10.1109/ESPM2.2018.00004},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{8641632,
  author={Shan, Hongzhang and Williams, Samuel and Johnson, Calvin W.},
  booktitle={2018 IEEE/ACM Performance Modeling, Benchmarking and Simulation of High Performance Computer Systems (PMBS)}, 
  title={Improving MPI Reduction Performance for Manycore Architectures with OpenMP and Data Compression}, 
  year={2018},
  volume={},
  number={},
  pages={1-11},
  abstract={The following topics are dealt with: parallel processing; learning (artificial intelligence); graphics processing units; message passing; parallel machines; data analysis; benchmark testing; parallel architectures; multiprocessing systems; application program interfaces.},
  keywords={},
  doi={10.1109/PMBS.2018.8641632},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{8648053,
  author={Stark, Maximilian and Lewandowsky, Jan and Bauch, Gerhard},
  booktitle={2018 IEEE Global Communications Conference (GLOBECOM)}, 
  title={Information-Optimum LDPC Decoders with Message Alignment for Irregular Codes}, 
  year={2018},
  volume={},
  number={},
  pages={1-6},
  abstract={In practical implementations, message passing decoding of LDPC codes has to be implemented with finite precision, i.e., the messages are quantized with a small number of bits. This results in a significant performance degradation with respect to decoding with high-precision messages. Recently, we have proposed so-called information bottleneck decoders to design finite-precision decoders with error-correction performance close to high-precision belief-propagation decoding. Earlier works solely focus on the design of information bottleneck decoders for regular LDPC codes or specifically optimized irregular LDPC codes. In this paper, we extend the concept of information bottleneck decoders to irregular LDPC with arbitrary degree distribution. We show that this extension is not straightforward and requires an additional information-optimum step. Therefore, we devise a novel intermediate construction step which we call message alignment. Exemplary numerical simulations using an irregular LDPC code taken from the IEEE 802.11 standard show that incorporating message alignment in the construction yields a 4-bit information bottleneck decoder which performs only 0.15 dB worse than a double-precision belief propagation decoder and outperforms a min-sum decoder.},
  keywords={},
  doi={10.1109/GLOCOM.2018.8648053},
  ISSN={2576-6813},
  month={Dec},}
@INPROCEEDINGS{8644528,
  author={Hussain, Zaeem and Cui, Xiaolong and Znati, Taieb and Melhem, Rami},
  booktitle={2018 IEEE 24th International Conference on Parallel and Distributed Systems (ICPADS)}, 
  title={CoLoR: Co-Located Rescuers for Fault Tolerance in HPC Systems}, 
  year={2018},
  volume={},
  number={},
  pages={569-576},
  abstract={With the increase in scale of HPC systems, the frequency of system wide failures is expected to increase. The performance of Coordinated Checkpoint/Restart (C/R), the traditional fault tolerance technique, degrades under high failure rates because of frequent global rollbacks, which themselves are susceptible to failures. We propose CoLoR, a fault tolerance scheme that i)requires only the failing process to recover, ii)overlaps reexecution with restart, and iii)avoids the cumulative effect of successive failures. Our theoretical analysis reveals that such a scheme results in lower expected completion time than coordinated C/R. We also provide a proof-of-concept implementation in MPI using receiver based message logging and colocated rescuer (CoLoR)processes, and evaluate its performance on several HPC benchmarks. Our experimental results, combined with observations from the theoretical analysis, show that CoLoR can outperform both traditional C/R and replication over a large range of system sizes, without using extra logger nodes.},
  keywords={},
  doi={10.1109/PADSW.2018.8644528},
  ISSN={1521-9097},
  month={Dec},}
@INPROCEEDINGS{8645863,
  author={L. Grim, Luís Fernando and Gradvohl, André Leon S.},
  booktitle={2018 30th International Symposium on Computer Architecture and High Performance Computing (SBAC-PAD)}, 
  title={High-Performance Ensembles of Online Sequential Extreme Learning Machine for Regression and Time Series Forecasting}, 
  year={2018},
  volume={},
  number={},
  pages={394-401},
  abstract={Ensembles of Online Sequential Extreme Learning Machine algorithm are suitable for forecasting Data Streams with Concept Drifts. Nevertheless, data streams forecasting require high-performance implementations due to the high incoming samples rate. In this work, we proposed to tune-up three ensembles, which operates with the Online Sequential Extreme Learning Machine, using high-performance techniques. We reim-plemented them in the C programming language with Intel MKL and MPI libraries. The Intel MKL provides functions that explore the multithread features in multicore CPUs, which expands the parallelism to multiprocessors architectures. The MPI allows us to parallelize tasks with distributed memory on several processes, which can be allocated within a single computational node, or spread over several nodes. In summary, our proposal consists of a two-level parallelization, where we allocated each ensemble model into an MPI process, and we parallelized the internal functions of each model in a set of threads through Intel MKL. Thus, the objective of this work is to verify if our proposals provide a significant improvement in execution time when compared to the respective conventional serial approaches. For the experiments, we used a synthetic and a real dataset. Experimental results showed that, in general, the high-performance ensembles improve the execution time, when compared with its serial version, performing up to 10-fold faster.},
  keywords={},
  doi={10.1109/CAHPC.2018.8645863},
  ISSN={1550-6533},
  month={Sep.},}
@INPROCEEDINGS{8645942,
  author={Coleman, Evan and Jensen, Erik J. and Sosonkina, Masha},
  booktitle={2018 30th International Symposium on Computer Architecture and High Performance Computing (SBAC-PAD)}, 
  title={Impacts of Three Soft-Fault Models on Hybrid Parallel Asynchronous Iterative Methods}, 
  year={2018},
  volume={},
  number={},
  pages={458-465},
  abstract={This study seeks to understand the soft error vulnerability of asynchronous iterative methods, with a focus on stationary iterative solvers such as Jacobi. The implementations make use of hybrid parallelism where the computational work is distributed over multiple nodes using MPI and parallelized on each node using openMP. A series of experiments is conducted to measure the impact of an undetected soft fault on an asynchronous iterative method, and to compare and contrast several techniques for simulating the occurrence of a fault and then recovering from the effects of the faults. The data shows that the two numerical soft-fault models tested here more consistently than a “bit-flip” model produce bad enough behavior to test a variety of recovery strategies, such as those based on partial checkpointing.},
  keywords={},
  doi={10.1109/CAHPC.2018.8645942},
  ISSN={1550-6533},
  month={Sep.},}
@INPROCEEDINGS{8645880,
  author={Checkaraou, Abdoul Wahid Mainassara and Rousset, Alban and Besseron, Xavier and Varrette, Sébastien and Peters, Bernhard},
  booktitle={2018 30th International Symposium on Computer Architecture and High Performance Computing (SBAC-PAD)}, 
  title={Hybrid MPI+openMP Implementation of eXtended Discrete Element Method}, 
  year={2018},
  volume={},
  number={},
  pages={450-457},
  abstract={The Extended Discrete Element Method (XDEM) is a novel and innovative numerical simulation technique that extends classical Discrete Element Method (DEM) (which simulates the motion of granular material), by additional properties such as the chemical composition, thermodynamic state, stress/strain for each particle. It has been applied successfully to numerous industries involving the processing of granular materials such as sand, rock, wood or coke [16], [17]. In this context, computational simulation with (X)DEM has become a more and more essential tool for researchers and scientific engineers to set up and explore their experimental processes. However, increasing the size or the accuracy of a model requires the use of High Performance Computing (HPC) platforms over a parallelized implementation to accommodate the growing needs in terms of memory and computation time. In practice, such a parallelization is traditionally obtained using either MPI (distributed memory computing), openMP (shared memory computing) or hybrid approaches combining both of them. In this paper, we present the results of our effort to implement an openMP version of XDEM allowing hybrid MPI+openMP simulations (XDEM being already parallelized with MPI). Far from the basic openMP paradigm and recommendations (which simply summarizes by decorating the main computation loops with a set of openMP pragma), the openMP parallelization of XDEM required a fundamental code re-factoring and careful tuning in order to reach good performance. There are two main reasons for those difficulties. Firstly, XDEM is a legacy code developed for more than 10 years, initially focused on accuracy rather than performance. Secondly, the particles in a DEM simulation are highly dynamic: they can be added, deleted and interaction relations can change at any timestep of the simulation. Thus this article details the multiple layers of optimization applied, such as a deep data structure profiling and reorganization, the usage of fast multithreaded memory allocators and of advanced process/thread-to-core pinning techniques. Experimental results evaluate the benefit of each optimization individually and validate the implementation using a real-world application executed on the HPC platform of the University of Luxembourg. Finally, we present our Hybrid MPI+openMP results with a 15%-20% performance gain and how it overcomes scalability limits (by increasing the number of compute cores without dropping of performances) of XDEM-based pure MPI simulations.},
  keywords={},
  doi={10.1109/CAHPC.2018.8645880},
  ISSN={1550-6533},
  month={Sep.},}
@INPROCEEDINGS{8664311,
  author={Osamura, Akira and Song, Guanghui and Cheng, Jun and Cai, Kui},
  booktitle={2018 International Symposium on Information Theory and Its Applications (ISITA)}, 
  title={Sparse Multiple Access and Code Design with Near Channel Capacity Performance}, 
  year={2018},
  volume={},
  number={},
  pages={139-143},
  abstract={For the problem of multiple users simultaneously communicating with a single receiver, a sparse multiple access scheme is proposed. Each user employs a low-density parity-check (LDPC) code. To mitigate multi-user interference, the codeword of each user is randomly punctured and the punctured bits are replaced by idle slots. That is, only a small random set of users are active at each time. The restriction of number of concurrent users significantly reduces the multi-user decoding complexity. Moreover, this puncture facilitates an efficient message-passing decoding over a sparse graph. With a joint optimization of the degree distribution of the LDPC code and the column weight distribution of the puncture matrix, capacity-approaching performance is achieved.},
  keywords={},
  doi={10.23919/ISITA.2018.8664311},
  ISSN={},
  month={Oct},}
@INPROCEEDINGS{8663759,
  author={Li, Chuanying and Quan, Zhe and Xiao, Xiong and Yi, Dajiang},
  booktitle={2018 IEEE 9th International Conference on Software Engineering and Service Science (ICSESS)}, 
  title={Research on MpiP Performance Based on Parallel Programs}, 
  year={2018},
  volume={},
  number={},
  pages={897-902},
  abstract={With the wide application of high-performance computing, more and more users use parallel execution programs to improve the execution speed of large-scale programs and improve overall execution performance, which is accompanied by a well-portable messaging interface. widely used. We use MPI-based performance analysis tool mpiP to analyze the performance of the program, and use the matrix multiplication example model as a test case, carry out a large number of targeted experiments, and improve the performance of mpiP in performance analysis. The main work we do is to add data sorting module, heap memory footprint collection module, generate timeline module and I/O port data collection module to improve the overall performance analysis efficiency, and also to obtain the entire program execution process more conveniently. The execution status of each process.},
  keywords={},
  doi={10.1109/ICSESS.2018.8663759},
  ISSN={2327-0594},
  month={Nov},}
@INPROCEEDINGS{8662889,
  author={Sudhan, Amool and Nene, Manisha J},
  booktitle={2018 Second International Conference on Intelligent Computing and Control Systems (ICICCS)}, 
  title={Peer Selection Techniques for Enhanced Transaction Propagation in Bitcoin Peer-to-Peer Network}, 
  year={2018},
  volume={},
  number={},
  pages={679-684},
  abstract={The Bitcoin protocol, based on a peer-to-peer network enables transactions and blocks to be propagated to all the nodes in a decentralized manner. The information is verified and stored across the nodes as a distributed data ledger, the Blockchain. A node can have a maximum of 8 outgoing connections. The selection of outgoing connections are carried out in a random manner and information is broadcasted to these nodes by flooding. Transaction propagation delays in the network results in temporary inconsistencies in the ledger information resulting in blockchain forks. These can lead to possible double spending attacks. This paper addresses the issue of transaction propagation delay in the network. We present a simulation model of Bitcoin network. The effect of varying the number of outgoing connections and its implication in propagation delay is analyzed to determine the optimum limit of outgoing connections. Further, the idea of selection of nodes based on combination of two parameters, proximity to the sending node and random selection and its effect on transaction propagation delay is explored. Simulation results prove that this method further decreases transaction propagation delay.},
  keywords={},
  doi={10.1109/ICCONS.2018.8662889},
  ISSN={},
  month={June},}
@INPROCEEDINGS{8665803,
  author={Hussain, Zaeem and Znati, Taieb and Melhem, Rami},
  booktitle={SC18: International Conference for High Performance Computing, Networking, Storage and Analysis}, 
  title={Partial Redundancy in HPC Systems with Non-Uniform Node Reliabilities}, 
  year={2018},
  volume={},
  number={},
  pages={566-576},
  abstract={We study the usefulness of partial redundancy in HPC message passing systems where individual node failure distributions are not identical. Prior research works on fault tolerance have generally assumed identical failure distributions for the nodes of the system. In such settings, partial replication has never been shown to outperform the two extremes(full and no-replication) for any significant range of node counts. In this work, we argue that partial redundancy may provide the best performance under the more realistic assumption of non-identical node failure distributions. We provide theoretical results on arranging nodes with different reliability values among replicas such that system reliability is maximized. Moreover, using system reliability to compute MTTI (mean-time-to-interrupt) and expected completion time of a partially replicated system, we numerically determine the optimal partial replication degree. Our results indicate that partial replication can be a more efficient alternative to full replication at system scales where Checkpoint/Restart alone is not sufficient.},
  keywords={},
  doi={10.1109/SC.2018.00047},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{8665805,
  author={Ye, Fangke and Zhao, Jisheng and Sarkar, Vivek},
  booktitle={SC18: International Conference for High Performance Computing, Networking, Storage and Analysis}, 
  title={Detecting MPI Usage Anomalies via Partial Program Symbolic Execution}, 
  year={2018},
  volume={},
  number={},
  pages={794-806},
  abstract={MPI is a message passing based programming model for distributed-memory parallelism that is widely used for programming supercomputers. However, debugging and verification of MPI programs is generally recognized to be a deep technical challenge. This challenge is further exacerbated by a recent increase in the use of nonblocking MPI operations for improved scalability, since incorrect use of these operations can introduce new classes of bugs related to data races. In this paper, we introduce a new debugging approach based on partial symbolic execution to identify anomalies in MPI usage. Our approach avoids the false positives inherent in static analysis, while still scaling to large programs. Further, our approach can be applied to incomplete programs and explore multiple execution paths, thereby leading to increased coverage compared with dynamic approaches. An experimental comparison with state-of-the-art tools for debugging MPI applications show that our approach delivers demonstrably better precision than a state-of-the art static tool (MPI-Checker) and a state-of-the art dynamic tool (MUST), without incurring excessive overheads.},
  keywords={},
  doi={10.1109/SC.2018.00066},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{8668647,
  author={Diwedi, Diwakar V. and Sharma, Satish J.},
  booktitle={2018 IEEE Global Conference on Wireless Computing and Networking (GCWCN)}, 
  title={Development of a Low Cost Cluster Computer Using Raspberry Pi}, 
  year={2018},
  volume={},
  number={},
  pages={11-15},
  abstract={A cluster computer provides much faster processing speed, larger storage capacity, better data integrity, superior reliability and wider availability of resources. In the present work, we have developed a cluster computer using five Raspberry Pi's (one master and four slave nodes) that acts as a single computer with enhanced processing speed. A Linux based operating system, Raspbian is used in the present work, to manage and access the Raspberry Pi in master node. Message Pass Interface (MPI) protocol is used to share the task among the nodes for parallel processing. The designed cluster computer has been tested using standard programs in C and python. The developed cluster computer is found to work successfully. The facilities of the present cluster computer would be extended to develop a virtual private network (VPN) server for clustering the computer present at the different geographical locations and data mining.},
  keywords={},
  doi={10.1109/GCWCN.2018.8668647},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{8672334,
  author={Arabnejad, Hamid and Bispo, João and G. Barbosa, Jorge and M.P. Cardoso, João},
  booktitle={2018 IEEE Intl Conf on Parallel & Distributed Processing with Applications, Ubiquitous Computing & Communications, Big Data & Cloud Computing, Social Computing & Networking, Sustainable Computing & Communications (ISPA/IUCC/BDCloud/SocialCom/SustainCom)}, 
  title={An OpenMP Based Parallelization Compiler for C Applications}, 
  year={2018},
  volume={},
  number={},
  pages={915-923},
  abstract={Directive-drive programming models, such as OpenMP, are one solution for exploiting the potential of multicore architectures, and enable developers to accelerate software applications by adding annotations on for-type loops and other code regions. However, manual parallelization of applications is known to be a non trivial and time consuming process, requiring parallel programming skills. Automatic parallelization approaches can reduce the burden on the application development side. This paper presents an OpenMP based automatic parallelization compiler, named AutoPar-Clava, for automatic identification and annotation of loops in C code. By using static analysis, parallelizable regions are detected, and a compilable OpenMP parallel code from the sequential version is produced. In order to reduce the accesses to shared memory by each thread, each variable is categorized into the proper OpenMP scoping. Also, AutoPar-Clava is able to support reduction on arrays, which is available since OpenMP 4.5. The effectiveness of AutoPar-Clava is evaluated by means of the Polyhedral Benchmark suite, and targeting a N-cores x86-based computing platform. The achieved results are very promising and compare favorably with closely related auto-parallelization compilers such as Intel C/C++ Compiler (i.e., icc), ROSE, TRACO, and Cetus.},
  keywords={},
  doi={10.1109/BDCloud.2018.00135},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{8672310,
  author={Qian, Shiyou and Mao, Weichao and Cao, Jian and Xue, Guangtao and Yu, Jiadi and Zhu, Yanmin and Li, Minglu and Li, Wenjuan},
  booktitle={2018 IEEE Intl Conf on Parallel & Distributed Processing with Applications, Ubiquitous Computing & Communications, Big Data & Cloud Computing, Social Computing & Networking, Sustainable Computing & Communications (ISPA/IUCC/BDCloud/SocialCom/SustainCom)}, 
  title={Adjusting Matching Algorithm to Adapt to Dynamic Subscriptions in Content-Based Publish/Subscribe Systems}, 
  year={2018},
  volume={},
  number={},
  pages={369-376},
  abstract={Content-based publish/subscribe systems enable on-demand event distribution based on users' interests. In dynamic environments, such as social networks and stock exchanges, the subscriptions that express users' interests update frequently, which changes the subscriptions' matchability which is defined as the matching probability of subscriptions with events. In the presence of dynamic subscriptions, it is challenging to maintain the performance stability of matching algorithms as the subscriptions' matchability is an important factor that impacts the performance of matching algorithms. So far, this issue has not been well addressed in the literature. In this paper, we design a matching algorithm that has the ability to adjust its behavior to adapt to dynamic subscriptions, aiming at stabilizing the performance of matching algorithms. To achieve this objective, a lightweight adjustment mechanism is proposed and adopted on a selected test bench, which gives rise to Maema, a matchability adaptive event matching algorithm. The effectiveness of Maema is extensively evaluated through a series of experiments using both synthetic and real-world data. Experiment results show that Maema not only possesses the beneficial adaptability, but also performs more efficiently.},
  keywords={},
  doi={10.1109/BDCloud.2018.00064},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{8675055,
  author={Sudhakar, Chapram and Ramesh, T and Waghmare, Kunal},
  booktitle={2018 International Conference on Computing, Power and Communication Technologies (GUCON)}, 
  title={Path Based Optimization of MPI Collective Communication Operation in Cloud}, 
  year={2018},
  volume={},
  number={},
  pages={595-599},
  abstract={There has been a considerable research in collective communication operations, especially in MPI Broadcast and Gather operations, on message passing platforms. Majority of the research work is done, to improve efficiency of the collective communication operations for specific architectures by considering either their communication network or platform parameters. In this work, a simple and general approach to optimize legacy MPI collective communication algorithms for cloud environment, is proposed. Cloud Computing is one of the prominent technologies as a new platform for distributed, large scale applications. Cloud services reduce investment in hardware cost and make application development and deployment faster. Because of the use of hardware virtualization, it is flexible and elastic in terms of resource provisioning. This virtualization hides the network topology information. Scalable parallel programs can be efficiently and effectively expressed using MPI library, which is powerful and portable. System performance is mostly affected by its collective communication operations. The use of hardware virtualization, makes topology aware communication algorithm ineffective. Thus the main focus in this paper is on improving the efficiency of MPI collective communication operations, especially on MPI Broadcast, Gather and exploring cost optimizations for MPI. Therefore, a new approach to improve broadcast and gather operation based on network performance matrices, is developed. The proposed approach is tested on LAN environment and a HPC cluster. The experimental results are improved compared to the existing MPICH2 library.},
  keywords={},
  doi={10.1109/GUCON.2018.8675055},
  ISSN={},
  month={Sep.},}
@INPROCEEDINGS{8690613,
  author={Meng, Xiangming and Wu, Yiqun and Wang, Chao and Chen, Yan},
  booktitle={2018 IEEE 88th Vehicular Technology Conference (VTC-Fall)}, 
  title={Turbo-Like Iterative Multi-User Receiver Design for 5G Non-Orthogonal Multiple Access}, 
  year={2018},
  volume={},
  number={},
  pages={1-5},
  abstract={Non-orthogonal multiple access (NoMA) as an efficient way of radio resource sharing has been identified as a promising technology in 5G to help improving system capacity, user connectivity, and service latency in 5G communications. This paper provides a brief overview of the progress of NoMA transceiver study in 3GPP, with special focus on the design of turbo-like iterative multi-user (MU) receivers. There are various types of MU receivers depending on the combinations of MU detectors and interference cancellation (IC) schemes. Link-level simulations show that expectation propagation algorithm (EPA) with hybrid parallel interference cancellation (PIC) is a promising MU receiver, which can achieve fast convergence and similar performance as message passing algorithm (MPA) with much lower complexity.},
  keywords={},
  doi={10.1109/VTCFall.2018.8690613},
  ISSN={2577-2465},
  month={Aug},}
@INPROCEEDINGS{8742254,
  author={Chen, Qiangpu and Shen, Minghua and Xiao, Nong},
  booktitle={2018 International Conference on Field-Programmable Technology (FPT)}, 
  title={DP-Pack: Distributed Parallel Packing for FPGAs}, 
  year={2018},
  volume={},
  number={},
  pages={282-285},
  abstract={Packing is one of the most critical stages in the FPGA physical syntheses flow. In this paper, we propose DP-Pack, a distributed parallel packing approach. DP-Pack consists of two primary steps. First, all of the minimal circuit units are assigned into several subsets where the conflicting units are located in the same subset and the non-conflicting units are distributed in different subsets. Then, the non-conflicting subsets are partitioned by round robin such that the number of subsets in each processor core is equal approximately, leading to good load balance in parallel packing. Second, the parallelization between processor cores is implemented by the MPI-based message queue in a distributed platform. Note that DP-Pack has been integrated into the VTR 7.0 tool. Experimental results show that our DP-Pack scales to 8 processor cores to provide about 1.4~3.2× runtime advantages with acceptable quality degradation, comparing to the academic state-of-the-art AAPack.},
  keywords={},
  doi={10.1109/FPT.2018.00054},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{8748921,
  author={Marques Garcia, Adriano and Schepke, Claudio and Gonçalves Girardi, Alessandro and Almeida da Silva, Sherlon},
  booktitle={2018 Symposium on High Performance Computing Systems (WSCAD)}, 
  title={Power Consumption of Parallel Programming Interfaces in Multicore Architectures: A Case Study}, 
  year={2018},
  volume={},
  number={},
  pages={77-83},
  abstract={This paper evaluates the power consumption of different parallel programming interfaces (PPI) in a multicore architecture. These PPIs are: PThreads, OpenMP, MPI-1 and MPI-2 (spawn). We measure the total energy and execution time of 11 applications in a single architecture, varying the number of threads/processes. The goal is to show that these applications can be used as a parallel benchmark to evaluate the power consumption of different PPIs. The results show that PThreads has the lowest power consumption among the interfaces, consuming less than the sequential version for memory-bound applications.},
  keywords={},
  doi={10.1109/WSCAD.2018.00021},
  ISSN={},
  month={Oct},}
@INPROCEEDINGS{8750728,
  author={Radu Adrian, Ometita},
  booktitle={2018 20th International Symposium on Symbolic and Numeric Algorithms for Scientific Computing (SYNASC)}, 
  title={The Blockchain, Today and Tomorrow}, 
  year={2018},
  volume={},
  number={},
  pages={458-462},
  abstract={Software engineering principles have enabled us to continually increase the complexity of the problems that we can solve using software by promoting the sensible use of abstraction, separation, composition and generalisation. Writing software for a public blockchain makes the code we write publicly available for inspection, and potential exploits may result in the loss of funds that the program manages. This unprecedented level of exposure and ease of exploitation requires new methods to improve our confidence in the correctness of the code that we write. This paper explores the main current techniques used to achieve this increased level of confidence, especially in the area of programming language design, starting from the first Turing Complete blockchain implementation Ethereum, and ending with some of the more principled approaches, Scilla and Rholang.},
  keywords={},
  doi={10.1109/SYNASC.2018.00077},
  ISSN={},
  month={Sep.},}
@INPROCEEDINGS{9045047,
  author={Zheng, Kexin and Yang, Jingli and Zheng, Shuai},
  booktitle={2018 Eighth International Conference on Instrumentation & Measurement, Computer, Communication and Control (IMCCC)}, 
  title={Prediction Model for Information Transmission Performance of Publish/Subscribe Systems with Heterogeneous Servers}, 
  year={2018},
  volume={},
  number={},
  pages={426-430},
  abstract={A novel prediction model for information trans-mission performance is presented in this paper, which is suitable for publish/subscribe systems with heterogeneous servers. Firstly, a uniform business logic model is developed by analyzing the principle of several typical types of publish/subscribe distributed systems. In addition, a mathematical model named MMPP(2)/G/1 cascaded queuing model is proposed by introducing heterogeneous server weighting factors into classical queuing model and Markov modulated Poisson process, which can eliminate iteration errors of the queuing model. The proposed prediction model is fully verified by carrying out a series of experiments in an Internet test platform. The results of the experiments illustrate that the proposed prediction model can achieve a higher prediction accuracy than the traditional model.},
  keywords={},
  doi={10.1109/IMCCC.2018.00096},
  ISSN={2373-6844},
  month={July},}
@ARTICLE{8168278,
  author={Li, Jianxin and Cao, Yingjie and Zhang, Yangyang and Bhuiyan, Md Zakirul Alam and Li, Bo},
  journal={IEEE Transactions on Sustainable Computing}, 
  title={SPFC: An Effective Optimization for Vertex-Centric Graph Processing Systems}, 
  year={2019},
  volume={4},
  number={1},
  pages={118-131},
  abstract={The real-world demands of mining big data and smart data of graph structure have led to an active research of distributed graph processing. Many distributed graph processing systems [19], [22], [23] adopt a vertex-centric programming paradigm. In these systems, messages are passed between vertices to propagate the latest states. The communication efficiency and the high overhead of synchronization are two key considerations of these systems [8], [12]. In this paper, we propose a Slow Passing Fast Consuming (SPFC) approach which can effectively improve the overall performance of vertex-centric graph processing systems. In our approach, the message passing is slow but the consuming is fast. More specifically, at the message sender side, priority is given to those smart messages which contribute more to the algorithm convergence, and at the message receiver side, messages are consumed right after arriving without any delay and intermediate buffer. Besides, by using a two-phase termination check protocol, the global synchronous barrier can be completely eliminated. In addition, based on the slow message passing strategy, further performance improvement can be achieved with some accuracy loss by eliminating those messages which are less useful for algorithm convergence. We implement our approach based on Apache Giraph [1] and evaluate it on a 12-machine cluster. The experimental results show that our method can effectively reduce the amount of message traffic and achieve up to an order of magnitude performance improvement compared with Giraph and GraphLab [3].},
  keywords={},
  doi={10.1109/TSUSC.2017.2780320},
  ISSN={2377-3782},
  month={Jan},}
@ARTICLE{8434235,
  author={Chan, Kheong Sann and Rahardja, Susanto},
  journal={IEEE Transactions on Broadcasting}, 
  title={Analysis of the Joint Viterbi Detector/Decoder (JVDD) Over a Coded AWGN/ISI System ss an LDPC Alternative}, 
  year={2019},
  volume={65},
  number={1},
  pages={1-9},
  abstract={The joint Viterbi detector/decoder (JVDD) has been proposed as an alternative to the powerful and ubiquitous low-density parity check (LDPC) coding schemes, that are used in the majority of channel coding applications today. At shorter block lengths, the JVDD is able to outperform the state-of-the-art LDPC decoder that can be found in many of today's systems, from deep-space communications to the digital video broadcasting standard, to the advanced television standard committee 3.0. Researchers have developed the tools to analyze the performance of the LDPC decoder, which is known as the sum-product algorithm or message passing algorithm. These tools include density evolution (DE) and extrinsic information transfer (EXIT) charts. To date, no similar such analysis exists for the JVDD. In the current paper we perform a similar preliminary analysis on the JVDD algorithm akin to what DE and EXIT charts are for the LDPC decoder. The current new analysis of the JVDD allows prediction of its probability of error based on the probability distribution functions of the metrics used within the algorithm. Our analysis plays a similar role to the abovementioned tools developed for the LDPC decoder: it allows us to predict the performance of the JVDD under various conditions (such as varying SNR's, thresholds, and block lengths), it improves our understanding of the JVDD algorithm and the match against Monte-Carlo simulations verifies our assumptions on the main error-causing mechanisms within the JVDD.},
  keywords={},
  doi={10.1109/TBC.2018.2855646},
  ISSN={1557-9611},
  month={March},}
@ARTICLE{8449124,
  author={Attiya, Hagit and Chung, Hyun Chul and Ellen, Faith and Kumar, Saptaparni and Welch, Jennifer L.},
  journal={IEEE Transactions on Parallel and Distributed Systems}, 
  title={Emulating a Shared Register in a System That Never Stops Changing}, 
  year={2019},
  volume={30},
  number={3},
  pages={544-559},
  abstract={Emulating a shared register can mask the intricacies of designing algorithms for asynchronous message-passing systems subject to crash failures, since it allows them to run algorithms designed for the simpler shared-memory model. Typically such emulations replicate the value of the register in multiple servers and require readers and writers to communicate with a majority of servers. The success of this approach for static systems, where the set of nodes (readers, writers, and servers) is fixed, has motivated several similar emulations for dynamic systems, where nodes may enter and leave. However, existing emulations need to assume that the system eventually stops changing for a long enough period or that the system size is bounded. This paper presents the first emulation of a register supporting any number of readers and writers in a crash-prone system that can withstand nodes continually entering and leaving and imposes no upper bound on the system size. The algorithm works as long as the number of nodes entering and leaving during a fixed time interval is at most a constant fraction of the system size at the beginning of the interval, and as long as the number of crashed nodes in the system is at most a constant fraction of the current system size. The paper includes a lower bound on the fraction of correct nodes that is strictly larger than the fraction sufficient to solve the problem in the static case.},
  keywords={},
  doi={10.1109/TPDS.2018.2867479},
  ISSN={1558-2183},
  month={March},}
@ARTICLE{8482295,
  author={Zaitsev, Dmitry and Tomov, Stanimire and Dongarra, Jack},
  journal={IEEE Transactions on Parallel and Distributed Systems}, 
  title={Solving Linear Diophantine Systems on Parallel Architectures}, 
  year={2019},
  volume={30},
  number={5},
  pages={1158-1169},
  abstract={Solving linear Diophantine systems of equations is applied in discrete-event systems, model checking, formal languages and automata, logic programming, cryptography, networking, signal processing, and chemistry. For modeling discrete systems with Petri nets, a solution in non-negative integer numbers is required, which represents an intractable problem. For this reason, solving such kinds of tasks with significant speedup is highly appreciated. In this paper we design a new solver of linear Diophantine systems based on the parallel-sequential composition of the system clans. The solver is studied and implemented to run on parallel architectures using a two-level parallelization concept based on MPI and OpenMP. A decomposable system is usually represented by a sparse matrix; a minimal clan size of the decomposition restricts the granulation of the technique. MPI is applied for solving systems for clans using a parallel-sequential composition on distributed-memory computing nodes, while OpenMP is applied in solving a single indecomposable system on a single node using multiple cores. A dynamic task-dispatching subsystem is developed for distributing systems on nodes in the process of compositional solution. Computational speedups are obtained on a series of test examples, e.g., illustrating that the best value constitutes up to 45 times speedup obtained on 5 nodes with 20 cores each.},
  keywords={},
  doi={10.1109/TPDS.2018.2873354},
  ISSN={1558-2183},
  month={May},}
@ARTICLE{8526323,
  author={Dass, Jyotikrishna and Sarin, Vivek and Mahapatra, Rabi N.},
  journal={IEEE Transactions on Parallel and Distributed Systems}, 
  title={Fast and Communication-Efficient Algorithm for Distributed Support Vector Machine Training}, 
  year={2019},
  volume={30},
  number={5},
  pages={1065-1076},
  abstract={Support Vector Machines (SVM) are widely used as supervised learning models to solve the classification problem in machine learning. Training SVMs for large datasets is an extremely challenging task due to excessive storage and computational requirements. To tackle so-called big data problems, one needs to design scalable distributed algorithms to parallelize the model training and to develop efficient implementations of these algorithms. In this paper, we propose a distributed algorithm for SVM training that is scalable and communication-efficient. The algorithm uses a compact representation of the kernel matrix, which is based on the QR decomposition of low-rank approximations, to reduce both computation and storage requirements for the training stage. This is accompanied by considerable reduction in communication required for a distributed implementation of the algorithm. Experiments on benchmark data sets with up to five million samples demonstrate negligible communication overhead and scalability on up to 64 cores. Execution times are vast improvements over other widely used packages. Furthermore, the proposed algorithm has linear time complexity with respect to the number of samples making it ideal for SVM training on decentralized environments such as smart embedded systems and edge-based internet of things, IoT.},
  keywords={},
  doi={10.1109/TPDS.2018.2879950},
  ISSN={1558-2183},
  month={May},}
@ARTICLE{8580585,
  author={Meng, Xiangming and Zhu, Jiang},
  journal={IEEE Access}, 
  title={Bilinear Adaptive Generalized Vector Approximate Message Passing}, 
  year={2019},
  volume={7},
  number={},
  pages={4807-4815},
  abstract={This paper considers the generalized bilinear recovery problem, which aims to jointly recover the vector b and the matrix X from componentwise nonlinear measurements  ${\text {Y}}\sim p({\text {Y}}|{\text {Z}})=\prod \limits _{i,j}p(Y_{ij}|Z_{ij})$ , where  ${\text {Z}}={\text {A}}({\text {b}}){\text {X}}$ ,  ${\text {A}}(\cdot)$  is a known affine linear function of b, and  $p(Y_{ij}|Z_{ij})$  is a scalar conditional distribution that models the general output transform. A wide range of real-world applications, e.g., quantized compressed sensing with matrix uncertainty, blind self-calibration and dictionary learning from nonlinear measurements, one-bit matrix completion, and joint channel and data decoding, can be cast as the generalized bilinear recovery problem. To address this problem, we propose a novel algorithm called the Bilinear Adaptive Generalized Vector Approximate Message Passing (BAd-GVAMP), which extends the recently proposed Bilinear Adaptive Vector AMP algorithm to incorporate arbitrary distributions on the output transform. The numerical results on various applications demonstrate the effectiveness of the proposed BAd-GVAMP algorithm.},
  keywords={},
  doi={10.1109/ACCESS.2018.2887261},
  ISSN={2169-3536},
  month={},}
@ARTICLE{8588369,
  author={Lakhlef, Hicham and Raynal, Michel and Taïani, François},
  journal={IEEE Transactions on Parallel and Distributed Systems}, 
  title={Vertex Coloring with Communication Constraints in Synchronous Broadcast Networks}, 
  year={2019},
  volume={30},
  number={7},
  pages={1672-1686},
  abstract={This paper considers distributed vertex-coloring in broadcast/receive networks suffering from conflicts and collisions. (A collision occurs when, during the same round, messages are sent to the same process by too many neighbors; a conflict occurs when a process and one of its neighbors broadcast during the same round.) More specifically, the paper focuses on multi-channel networks, in which a process may either broadcast a message to its neighbors or receive a message from at most γ of them. The paper first provides a new upper bound on the corresponding graph coloring problem (known as frugal coloring) in general graphs, proposes an exact bound for the problem in trees, and presents a deterministic, parallel, color-optimal, collision- and conflict-free distributed coloring algorithm for trees, and proves its correctness.},
  keywords={},
  doi={10.1109/TPDS.2018.2889688},
  ISSN={1558-2183},
  month={July},}
@ARTICLE{8594658,
  author={Zhu, Jiang and Han, Lin and Meng, Xiangming},
  journal={IEEE Access}, 
  title={An AMP-Based Low Complexity Generalized Sparse Bayesian Learning Algorithm}, 
  year={2019},
  volume={7},
  number={},
  pages={7965-7976},
  abstract={In this paper, an approximate message passing-based generalized sparse Bayesian learning (AMP-Gr-SBL) algorithm is proposed to reduce the computation complexity of the Gr-SBL algorithm, meanwhile improving the robustness of the GAMP algorithm against the measurement matrix deviated from the independent and identically distributed Gaussian matrix for the generalized linear model (GLM). According to expectation propagation, the original GLM is iteratively decoupled into two sub-modules: the standard linear model (SLM) module and the minimum mean-square-error module. For the SLM module, we apply the SBL algorithm, where the expectation step is replaced by the AMP algorithm to reduce the computation complexity significantly. The numerical results demonstrate the effectiveness of the proposed AMP-Gr-SBL algorithm.},
  keywords={},
  doi={10.1109/ACCESS.2018.2890146},
  ISSN={2169-3536},
  month={},}
@ARTICLE{8626478,
  author={Liu, Shengheng and Wu, Hancong and Huang, Yongming and Yang, Yunjie and Jia, Jiabin},
  journal={IEEE Transactions on Industrial Informatics}, 
  title={Accelerated Structure-Aware Sparse Bayesian Learning for Three-Dimensional Electrical Impedance Tomography}, 
  year={2019},
  volume={15},
  number={9},
  pages={5033-5041},
  abstract={In this paper, we consider the reconstruction of three-dimensional (3-D) conductivity distribution using electrical impedance tomography (EIT) technique. A high-resolution and efficient algorithm is developed to solve the EIT inverse problem. The presented algorithm is extended upon a recently proposed novel EIT reconstruction approach based on structure-aware sparse Bayesian learning (SA-SBL). The correlation between proximal layers in the 3-D geometry are incorporated into the structure prior to improve the reconstruction accuracy. In addition, an efficient approach based on approximate message passing is developed to accelerate the large-scale 3-D learning process. To validate the algorithm, numerical experiments using real recorded data are conducted. The visual and quantitative-metric comparisons show that the proposed method outperforms the existing methods in terms of reconstruction accuracy and computational complexity in all test cases. The SA-SBL-based reconstruction approach can preserve the 3-D structure of medical volume, reduce the systematic artifacts, and improve the computational efficiency.},
  keywords={},
  doi={10.1109/TII.2019.2895469},
  ISSN={1941-0050},
  month={Sep.},}
@ARTICLE{8630463,
  author={Bai, Bo and Li, Wanyi and Wang, Li and Zhang, Gong},
  journal={IEEE Transactions on Communications}, 
  title={Coded Caching in Fog-RAN:  $b$ -Matching Approach}, 
  year={2019},
  volume={67},
  number={5},
  pages={3753-3767},
  abstract={Fog radio access network (Fog-RAN), which pushes caching and computing capabilities to the network edge, is capable of efficiently delivering content to users by using carefully designed caching placement and content replacement algorithms. In this paper, the transmission scheme design and coding parameter optimization will be considered for coded caching in FogRAN, where the reliability of content delivery, i.e., content outage probability, is used as the performance metric. The problem will be formulated as a complicated multi-objective probabilistic combinatorial optimization. A novel maximum b-matching approach will then be proposed to obtain the Pareto optimal solution with fairness constraint. Based on the fast message passing approach, a distributed algorithm with a low memory usage of O(M + N) is also proposed, where M is the number of users and N is the number of fog access points (Fog-APs). Although it is usually very difficult to derive the closed-form formulas for the optimal solution, the approximation formulas of the content outage probability will also be obtained as a function of coding parameters. The asymptotic optimal coding parameters can then be obtained by defining and deriving the outage exponent region and diversity-multiplexing region. Simulation results will illustrate the accuracy of the theoretical derivations, and verify the outage performance of the proposed approach. Therefore, this paper not only proposes a practical distributed Fog-AP selection algorithm for coded caching but also provides a systematic way to evaluate and optimize the performance of Fog-RANs.},
  keywords={},
  doi={10.1109/TCOMM.2019.2896026},
  ISSN={1558-0857},
  month={May},}
@ARTICLE{8632716,
  author={Shudler, Sergei and Berens, Yannick and Calotoiu, Alexandru and Hoefler, Torsten and Strube, Alexandre and Wolf, Felix},
  journal={IEEE Transactions on Parallel and Distributed Systems}, 
  title={Engineering Algorithms for Scalability through Continuous Validation of Performance Expectations}, 
  year={2019},
  volume={30},
  number={8},
  pages={1768-1785},
  abstract={Many libraries in the HPC field use sophisticated algorithms with clear theoretical scalability expectations. However, hardware constraints or programming bugs may sometimes render these expectations inaccurate or even plainly wrong. While algorithm and performance engineers have already been advocating the systematic combination of analytical performance models with practical measurements for a very long time, we go one step further and show how this comparison can become part of automated testing procedures. The most important applications of our method include initial validation, regression testing, and benchmarking to compare implementation and platform alternatives. Advancing the concept of performance assertions, we verify asymptotic scaling trends rather than precise analytical expressions, relieving the developer from the burden of having to specify and maintain very fine-grained and potentially non-portable expectations. In this way, scalability validation can be continuously applied throughout the whole development cycle with very little effort. Using MPI and parallel sorting algorithms as examples, we show how our method can help uncover non-obvious limitations of both libraries and underlying platforms.},
  keywords={},
  doi={10.1109/TPDS.2019.2896993},
  ISSN={1558-2183},
  month={Aug},}
@ARTICLE{8667610,
  author={Barjon, Matthieu and Casteigts, Arnaud and Chaumette, Serge and Johnen, Colette and Neggaz, Yessin M and Santone, Antonella},
  journal={The Computer Journal}, 
  title={Maintaining a Distributed Spanning Forest in Highly Dynamic Networks}, 
  year={2019},
  volume={62},
  number={2},
  pages={231-246},
  abstract={Highly dynamic networks are characterized by frequent changes in the availability of communication links. These networks are often partitioned into several components, which split and merge unpredictably. We present a distributed algorithm that maintains a forest of (as few as possible) spanning trees in such a network, with no restriction on the rate of change. Our algorithm is inspired by high-level graph transformations, which we adapt here in a (synchronous) message passing model for dynamic networks. The resulting algorithm has the following properties. First, every decision is purely local—in each round, a node only considers its role and that of its neighbors in the tree, with no further information propagation (in particular, no wave mechanisms). Second, whatever the rate and scale of the changes, the algorithm guarantees that, by the end of every round, the network is covered by a forest of spanning trees in which (1) no cycle occur, (2) every node belongs to exactly one tree and (3) every tree contains exactly one root. We primarily focus on the correctness of this algorithm, which is established rigorously. While performance is not the main focus, we suggest new complexity metrics for such problems, and report on preliminary experimentation results validating our algorithm in a practical scenario.},
  keywords={},
  doi={10.1093/comjnl/bxy069},
  ISSN={1460-2067},
  month={Feb},}
@INPROCEEDINGS{8668036,
  author={Dilley, Nicolas and Lange, Julien},
  booktitle={2019 IEEE 26th International Conference on Software Analysis, Evolution and Reengineering (SANER)}, 
  title={An Empirical Study of Messaging Passing Concurrency in Go Projects}, 
  year={2019},
  volume={},
  number={},
  pages={377-387},
  abstract={Go is a popular programming language renowned for its good support for system programming and its channel-based message passing concurrency mechanism. These strengths have made it the language of choice of many platform software such as Docker and Kubernetes. In this paper, we analyse 865 Go projects from GitHub in order to understand how message passing concurrency is used in publicly available code. Our results include the following findings: (1) message passing primitives are used frequently and intensively, (2) concurrency-related features are generally clustered in specific parts of a Go project, (3) most projects use synchronous communication channels over asynchronous ones, and (4) most Go projects use simple concurrent thread topologies, which are however currently unsupported by existing static verification frameworks.},
  keywords={},
  doi={10.1109/SANER.2019.8668036},
  ISSN={1534-5351},
  month={Feb},}
@INPROCEEDINGS{8692929,
  author={Burich, Mariano Eduardo and Souza, Richard Demo and Garcia-Frias, Javier},
  booktitle={2019 53rd Annual Conference on Information Sciences and Systems (CISS)}, 
  title={Non-Linear Rate Compatible Modulation : Invited Presentation}, 
  year={2019},
  volume={},
  number={},
  pages={1-5},
  abstract={We propose a novel coding scheme that generalizes Rate Compatible Modulation (RCM). The idea is to maintain the graphical structure in RCM, but substituting the linear combinations that generate the random projections by non-linear functions directly mapping bits into constellation symbols. This is done in a computationally efficient and straightforward manner. By eliminating the linearity conditions we are able to improve the RCM performance, while we still benefit from the simple graphical structure.},
  keywords={},
  doi={10.1109/CISS.2019.8692929},
  ISSN={},
  month={March},}
@INPROCEEDINGS{8703924,
  author={Jahić, Jasmin and Kumar, Varun and Antonino, Pablo Oliveira and Wirrer, Gerhard},
  booktitle={2019 IEEE International Conference on Software Architecture (ICSA)}, 
  title={Testing the Implementation of Concurrent AUTOSAR Drivers Against Architecture Decisions}, 
  year={2019},
  volume={},
  number={},
  pages={171-180},
  abstract={Concurrent software based on a shared-memory model is predominant in industrial applications that cannot afford to execute complex message-passing libraries. However, direct access to shared memory creates implicit dependencies between concurrently executing components. Therefore, the development and maintenance of such software is hard. In this paper, we argue the need to manage, at the architectural level, the implicitly high coupling between concurrent components that share memory. We suggest an approach that verifies architectural specifications against the implementation and finds potential mismatches. While static analysis approaches can be complete and verify all possible mismatches, they are often imprecise, leading to a large number of false warnings, especially in concurrent software. Instead, we built our approach, using dynamic analysis, on top of one of the most well-known algorithms for detecting data races, Eraser Lockset, and extended its model to support features required for the verification process. Since Lockset operates on the execution traces, test cases that produce these traces must ensure proper coverage. Therefore, we argue the need to use test cases conforming to the strict modified condi-tion/decision coverage criteria (MC/DC). Our version of Lockset takes advantage of the fact that possible shared memory locations are known in advance. We further improved its precision by considering atomic operations as a synchronization mechanism. The approach was evaluated on industrial AUTOSAR drivers that execute concurrently.},
  keywords={},
  doi={10.1109/ICSA.2019.00026},
  ISSN={},
  month={March},}
@ARTICLE{8714043,
  author={Soldi, Giovanni and Meyer, Florian and Braca, Paolo and Hlawatsch, Franz},
  journal={IEEE Transactions on Signal Processing}, 
  title={Self-Tuning Algorithms for Multisensor-Multitarget Tracking Using Belief Propagation}, 
  year={2019},
  volume={67},
  number={15},
  pages={3922-3937},
  abstract={Situation-aware technologies enabled by multitarget tracking algorithms will create new services and applications in emerging fields such as autonomous navigation and maritime surveillance. The system models underlying multitarget tracking algorithms often involve unknown parameters that are potentially time-varying. A manual tuning of unknown model parameters by the user is prone to errors and can, thus, dramatically reduce target detection and tracking performance. We address this challenge by proposing a framework of “self-tuning” multisensor-multitarget tracking algorithms. These algorithms adapt in an online manner to time-varying system models by continuously inferring unknown model parameters along with the target states. We describe the evolution of the parameters by a Markov chain and incorporate them in a factor graph that represents the statistical structure of the tracking problem. We then use a belief propagation scheme to efficiently calculate the marginal posterior distributions of the targets and model parameters. As a concrete example, we develop a self-tuning tracking algorithm for maneuvering targets with multiple dynamic models and sensors with time-varying detection probabilities. The performance of the algorithm is validated for simulated scenarios and for a real scenario using measurements from two high-frequency surfacewave radars.},
  keywords={},
  doi={10.1109/TSP.2019.2916764},
  ISSN={1941-0476},
  month={Aug},}
@ARTICLE{8732673,
  author={Miri Rostami, Seyyed Reza and Ghaffari-Miab, Mohsen},
  journal={IEEE Transactions on Antennas and Propagation}, 
  title={Finite Difference Generated Transient Potentials of Open-Layered Media by Parallel Computing Using OpenMP, MPI, OpenACC, and CUDA}, 
  year={2019},
  volume={67},
  number={10},
  pages={6541-6550},
  abstract={The implementation of time-domain Green's functions (TDGFs) in the graphics processing unit (GPU) and the central processing unit (CPU) using a finite-difference scheme is shown. The TDGFs represent the transient electric scalar and magnetic vector potentials due to a horizontal electric dipole (TIED) in open-layered media. The layered media is bounded with a perfectly matched layer (PML), symmetry axis, and perfect electric conductor (PEC). We adopted four different parallel approaches as follows: 1) open multiprocessing (OpenMP) CPU implementation; 2) message passing interface (MPI) CPU implementation; 3) open accelerators (OpenACC) GPU implementation; and 4) compute unified device architecture (CUDA) GPU implementation. The accuracy and efficiency of the utilized programming models are validated by comparing and verifying the obtained results using a sequential CPU implementation. Compared to single threaded CPU implementation, speed-ups obtained by the OpenMP, MPI, OpenACC, and CUDA programming models are 4.8×, 6.12×, 45.97×, and 96.53× higher, respectively. The final result shows that GPU implementation leads to a considerable speed-up while the solution's accuracy is fixed.},
  keywords={},
  doi={10.1109/TAP.2019.2920253},
  ISSN={1558-2221},
  month={Oct},}
@ARTICLE{8737900,
  author={Usman, Sardar and Mehmood, Rashid and Katib, Iyad and Albeshri, Aiiad},
  journal={IEEE Access}, 
  title={ZAKI+: A Machine Learning Based Process Mapping Tool for SpMV Computations on Distributed Memory Architectures}, 
  year={2019},
  volume={7},
  number={},
  pages={81279-81296},
  abstract={Smart cities and other cyber-physical systems (CPSs) rely on various scientific, engineering, business, and social applications that provide timely intelligence for their design, operations, and management. Many of these scientific and analytics applications require the solution of sparse linear equation systems, where sparse matrix-vector (SpMV) product is a key computing operation. Several factors determine the performance of parallel SpMV computations, including matrix characteristics, storage formats, and the rising complexity and heterogeneity of computer systems. There is a pressing need for new ways of exploiting parallelism, and mapping data and applications to the computing resources. We propose here ZAKI+, a data-driven machine-learning approach, allowing users to automatically, effortlessly, and speedily obtain the best configuration (the data distribution, the optimal number of processes, and mapping strategy) and performance for the execution of the parallel SpMV computations on distributed memory machines. We train and test the tool using three machine learning methods-decision trees, random forest, and Xtreme boosting-and nearly 2000 real-world matrices obtained from 45 application domains, including computer vision and robotics. ZAKI+ provides optimal process mapping and outperforms the MPI default mapping policy by a factor of 4.24. This is the first work where the sparsity structure of matrices has been exploited to predict the optimal mapping of processes and data in distributed-memory environments by using different base and ensemble machine learning methods. Various CPSs comprise compute-intensive machine learning applications, such as the SpMV, and hence, the process and data mapping contributions of this paper would be of paramount impact for the CPSs.},
  keywords={},
  doi={10.1109/ACCESS.2019.2923565},
  ISSN={2169-3536},
  month={},}
@ARTICLE{8756119,
  author={Qin, Xin and Yang, Chuanchuan and Zheng, Ziyuan and Wang, Ziyu},
  journal={IEEE Photonics Technology Letters}, 
  title={Optimization of QC-LDPC Codes by Edge Exchange Method Based on ACE}, 
  year={2019},
  volume={31},
  number={17},
  pages={1401-1404},
  abstract={Long quasi-cyclic low-density parity check (QC-LDPC) codes have been chosen as one of the forward error correction (FEC) schemes in passive optical network (PON) systems benefiting from the excellent performance. About how to get the appropriate LDPC codes, some traditional methods which focus on obtaining large girth or flat approximated cycle extrinsic message degree (ACE) spectrums are proposed for the design of LDPC codes. These methods which may still make the existence of small stopping sets containing short cycles probably are not so useful for long QC-LDPC codes. Recently, the parallel vector message passing (PMP) algorithm oriented-to decreasing the number of short cycles is proved to be an effective method to optimize LDPC codes. Since ignoring short cycles with poor connectivity which can induce error floor, this method cannot guarantee its effectiveness for long QC-LDPC codes. In this letter, an edge exchange optimization method based on the global properties of ACE and girth called EEA method is proposed, which tries to reduce cycles with low ACE in the order of cycle length. The numerical results prove that our EEA method can bring the improvements of error floor up to two orders of magnitude to long QC-LDPC codes and obviously outperforms PMP algorithm.},
  keywords={},
  doi={10.1109/LPT.2019.2927029},
  ISSN={1941-0174},
  month={Sep.},}
@INPROCEEDINGS{8752949,
  author={Ueno, Yuichiro and Yokota, Rio},
  booktitle={2019 19th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing (CCGRID)}, 
  title={Exhaustive Study of Hierarchical AllReduce Patterns for Large Messages Between GPUs}, 
  year={2019},
  volume={},
  number={},
  pages={430-439},
  abstract={Data-parallel distributed deep learning requires an AllReduce operation between all GPUs with message sizes in the order of hundreds of megabytes. The popular implementation of AllReduce for deep learning is the Ring-AllReduce, but this method suffers from latency when using thousands of GPUs. There have been efforts to reduce this latency by combining the ring with more latency-optimal hierarchical methods. In the present work, we consider these hierarchical communication methods as a general hierarchical Ring-AllReduce with a pure Ring-AllReduce on one end and Rabenseifner's algorithm on the other end of the spectrum. We exhaustively test the various combinations of hierarchical partitioning of processes on the ABCI system in Japan on up to 2048 GPUs. We develop a performance model for this generalized hierarchical Ring-AllReduce and show the lower-bound of the effective bandwidth achievable for the hierarchical NCCL communication on thousands of GPUs. Our measurements agree well with our performance model. We also find that the optimal large-scale process hierarchy contains the optimal small-scale process hierarchy so the search space for the optimal communication will be reduced.},
  keywords={},
  doi={10.1109/CCGRID.2019.00057},
  ISSN={},
  month={May},}
@INPROCEEDINGS{8759366,
  author={Rocha, Rafael and Ferreira, Luis Lino and Maia, Claudio and Souto, Pedro and Varga, Pal},
  booktitle={2019 IEEE 22nd International Symposium on Real-Time Distributed Computing (ISORC)}, 
  title={Improving the performance of a Publish-Subscribe message broker}, 
  year={2019},
  volume={},
  number={},
  pages={91-92},
  abstract={The Arrowhead Framework, a SOA-based framework for IoT applications, provides the Event Handler system: a publish/subscribe broker implemented with REST/HTTP(S). However, the existing implementation of the Event Handler suffers from message latency problems that are not acceptable for industrial applications. Thus, this paper describes the refactoring process of this system that enabled it to reach acceptable levels of latency.},
  keywords={},
  doi={10.1109/ISORC.2019.00027},
  ISSN={2375-5261},
  month={May},}
@ARTICLE{8760407,
  author={Liu, Jia and Xue, Yong and Ren, Kaijun and Song, Junqiang and Windmill, Christopher and Merritt, Patrick},
  journal={IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing}, 
  title={High-Performance Time-Series Quantitative Retrieval From Satellite Images on a GPU Cluster}, 
  year={2019},
  volume={12},
  number={8},
  pages={2810-2821},
  abstract={The quality and accuracy of remote sensing instruments continue to increase, allowing geoscientists to perform various quantitative retrieval applications to observe the geophysical variables of land, atmosphere, ocean, etc. The explosive growth of time-series remote sensing (RS) data over large-scales poses great challenges on managing, processing, and interpreting RS ``Big Data.'' To explore these time-series RS data efficiently, in this paper, we design and implement a high-performance framework to address the time-consuming time-series quantitative retrieval issue on a graphics processing unit cluster, taking the aerosol optical depth (AOD) retrieval from satellite images as a study case. The presented framework exploits the multilevel parallelism for time-series quantitative RS retrieval to promote efficiency. At the coarse-grained level of parallelism, the AOD time-series retrieval is represented as multidirected acyclic graph workflows and scheduled based on a list-based heuristic algorithm, heterogeneous earliest finish time, taking the idle slot and priorities of retrieval jobs into account. At the fine-grained level, the parallel strategies for the major remote sensing image processing algorithms divided into three categories, i.e., the point or pixel-based operations, the local operations, and the global or irregular operations have been summarized. The parallel framework was implemented with message passing interface and compute unified device architecture, and experimental results with the AOD retrieval case verify the effectiveness of the presented framework.},
  keywords={},
  doi={10.1109/JSTARS.2019.2920077},
  ISSN={2151-1535},
  month={Aug},}
@ARTICLE{8763893,
  author={Yang, Ming-Lin and Wu, Bi-Yi and Gao, Hong-Wei and Sheng, Xin-Qing},
  journal={IEEE Transactions on Antennas and Propagation}, 
  title={A Ternary Parallelization Approach of MLFMA for Solving Electromagnetic Scattering Problems With Over 10 Billion Unknowns}, 
  year={2019},
  volume={67},
  number={11},
  pages={6965-6978},
  abstract={In this paper, we present a flexible and efficient ternary parallelization approach for the multilevel fast multipole algorithm (MLFMA) for the solution of extremely large 3-D scattering problems with over 10 billion unknowns. In the ternary parallelization approach, a binary clustering tree of all the message passing interface (MPI) processes is built first. Then, the MLFMA tree is categorized into plane wave partitioning, hierarchical-structure partitioning, and box partitioning (BP) levels via a top-down approach to match the process clustering tree. Compared with the bottom-up approach, interprocess communications in the far interaction are reduced. An inner-group transition level is designed for switching partitions on the intermediate level between the hierarchical-structure partitioning and BP levels. The ternary strategy can realize as high parallel efficiency as the hierarchical partitioning strategy while maintaining flexibility in selecting the total number of processes. An auxiliary-tree-based parallel mesh refinement technique and a hybrid octree storage strategy are designed to facilitate the realization of fast full-wave simulation on a scale of over 10 billion unknowns with the ternary MLFMA. The accuracy of the solutions is validated by comparing the radar cross sections (RCSs) of a sphere of diameter 3042 wavelengths with 10 773 415 728 unknowns via the MLFMA and the Mie series, which is the largest number of unknowns to be computed via full wave numerical methods to date. Furthermore, the solutions for complicated objects, namely a ship and an aircraft model, both of which have maximum lengths that exceed 10 000 wavelengths and over 10 billion unknowns, are presented.},
  keywords={},
  doi={10.1109/TAP.2019.2927660},
  ISSN={1558-2221},
  month={Nov},}
@ARTICLE{8766141,
  author={Sun, Wei-Cheng and Su, Yu-Chieh and Ueng, Yeong-Luh and Yang, Chia-Hsiang},
  journal={IEEE Transactions on Circuits and Systems I: Regular Papers}, 
  title={An LDPC-Coded SCMA Receiver With Multi-User Iterative Detection and Decoding}, 
  year={2019},
  volume={66},
  number={9},
  pages={3571-3584},
  abstract={This paper presents the first low-complexity realization of an LDPC-code sparse code multiple access (SCMA) receiver with a high-throughput LDPC decoder and a multi-mode SCMA detector. The minimum mean-square error with parallel interference cancellation (MMSE-PIC) algorithm is adopted in the SCMA detection. The modified user-node operations in the MMSE-PIC-based message-passing detector improve the convergence rate in error performance. The proposed receiver also supports multi-user iterative detection and decoding (MU-IDD) to improve the error rate performance. The proposed receiver supports both 4×6 and 8×12 SCMA systems. The proposed MU LDPC decoder has a 57.1% lower hardware complexity than the direct-mapped design that is achieved through hardware sharing and memory access scheduling. Designed in a 40-nm CMOS technology, the SCMA receiver integrates 10.9M logic gates in an area of 3.382 × 3.382 mm2. The proposed design achieves a gross throughput of 1.198 Gb/s and 599 Mb/s for 8 × 12 and 4 × 6 SCMA systems, respectively, under a practical situation. It dissipates 813 mW at a clock frequency of 300 MHz from a 0.9-V supply.},
  keywords={},
  doi={10.1109/TCSI.2019.2925826},
  ISSN={1558-0806},
  month={Sep.},}
@ARTICLE{8768221,
  author={Wasson, Mitchell and Milicevic, Mario and Draper, Stark C. and Gulak, Glenn},
  journal={IEEE Transactions on Signal Processing}, 
  title={Hardware-Based Linear Program Decoding With the Alternating Direction Method of Multipliers}, 
  year={2019},
  volume={67},
  number={19},
  pages={4976-4991},
  abstract={We present a hardware-based implementation of linear program (LP) decoding for binary linear codes. LP decoding frames error-correction as an optimization problem. In contrast, variants of belief propagation (BP) decoding frame error-correction as a problem of graphical inference. LP decoding has several advantages over BP-based methods, including convergence guarantees and better error-rate performance in high-reliability channels. The latter makes LP decoding attractive for optical transport and storage applications. However, LP decoding, when implemented with general solvers, does not scale to large blocklengths and is not suitable for a parallelized implementation in hardware. It has been recently shown that the alternating direction method of multipliers (ADMM) can be applied to decompose the LP decoding problem. The result is a message-passing algorithm with a structure very similar to BP. We present modifications to this algorithm, resulting in a more intuitive and hardware-compatible form. This is particularly true for projection onto the parity polytope: the major computational primitive for ADMM-LP decoding. Furthermore, we present results for a fixed-point Verilog implementation of ADMM-LP decoding. This implementation targets a field-programmable gate array (FPGA) platform to evaluate error-rate performance and estimate resource usage. We show that frame error rate performance well within 0.5 dB of double-precision implementations is possible with 10-bit messages. Finally, we outline research opportunities that should be explored en route to an application-specific integrated circuit (ASIC) implementation that is capable of Gigabit-per-second throughput.},
  keywords={},
  doi={10.1109/TSP.2019.2929944},
  ISSN={1941-0476},
  month={Oct},}
@ARTICLE{8770141,
  author={Yuan, Weijie and Wu, Nan and Guo, Qinghua and Huang, Xiaojing and Li, Yonghui and Hanzo, Lajos},
  journal={IEEE Transactions on Communications}, 
  title={TOA-Based Passive Localization Constructed Over Factor Graphs: A Unified Framework}, 
  year={2019},
  volume={67},
  number={10},
  pages={6952-6965},
  abstract={Passive localization based on time of arrival (TOA) measurements is investigated, where the transmitted signal is reflected by a passive target and then received at several distributed receivers. After collecting all measurements at receivers, we can determine the target location. The aim of this paper is to provide a unified factor graph-based framework for passive localization in wireless sensor networks based on TOA measurements. Relying on the linearization of range measurements, we construct a Forney-style factor graph model and conceive the corresponding Gaussian message passing algorithm to obtain the target location. It is shown that the factor graph can be readily modified for handling challenging scenarios such as uncertain receiver positions and link failures. Moreover, a distributed localization method based on consensus-aided operation is proposed for a large-scale resource constrained network operating without a fusion center. Furthermore, we derive the Cramér-Rao bound (CRB) to evaluate the performance of the proposed algorithm. Our simulation results verify the efficiency of the proposed unified approach and of its distributed implementation.},
  keywords={},
  doi={10.1109/TCOMM.2019.2930517},
  ISSN={1558-0857},
  month={Oct},}
@INPROCEEDINGS{8778420,
  author={Yu, Fan and Strazdins, Peter and Henrichs, Joerg and Pugh, Tim},
  booktitle={2019 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)}, 
  title={Shared Memory and GPU Parallelization of an Operational Atmospheric Transport and Dispersion Application}, 
  year={2019},
  volume={},
  number={},
  pages={729-738},
  abstract={The HYSPLIT air concentration model is an operational Lagrangian trajectory and dispersion model that calculates the concentration or the distribution of pollutants by releasing and tracking particles or puffs. It is widely used for tracking and forecasting the release of pollutants such as radioactive material, dust storms and volcanic ash. Due to the massively parallel nature of the particle tracking system, the HYSPLIT model shows potential to be accelerated by multiple CPUs and GPUs. However, porting such a legacy application to a GPU requires non-trivial work to isolate the parallel code regions and correctly adapt the code to a parallel programming model. This paper presents methods to port the current HYSPLIT code to the shared-memory OpenMP and the CUDA programming models. In the OpenMP approach, the original HYSPLIT concentration model is analyzed, profiled and refactored to remove barriers for parallelizing on multi-core CPUs. A linear speed-up with some serial overhead is achieved for the OpenMP version. In the CUDA approach, we utilize the computing power of NVIDIA GTX960 and Tesla P100 GPUs, providing 4-5× faster overall performance than the original. With the help of GPU coarse-grained parallelism, a maximum 12.9× speedup has been measured, compared to the original program running on a CPU. The disturbance of different parallelization approaches to the original code base shows that most of the highly difficult work is in the refactoring, and that CUDA requires extensive, but mostly relatively shallow, changes.},
  keywords={},
  doi={10.1109/IPDPSW.2019.00121},
  ISSN={},
  month={May},}
@INPROCEEDINGS{8778334,
  author={Danner, Andrew and Newhall, Tia and Webb, Kevin C.},
  booktitle={2019 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)}, 
  title={ParaVis: A Library for Visualizing and Debugging Parallel Applications}, 
  year={2019},
  volume={},
  number={},
  pages={326-333},
  abstract={This paper presents ParaVis, a visualization library designed to aid programmers' understanding of their parallel programs and to help them identify bugs with parallelization. ParaVis is particularly targeted for programmers who are first learning parallel programming or learning a new parallel language. It provides easy-to-use C and C++ interfaces to create 2D animations of parallel computation that help programmers understand parallel data decomposition patterns. These visualizations are also helpful in illustrating errors in parallel programs. Additionally, because students often find visualization fun, the use of our library often results in students developing interesting extensions to problems, thus promoting a deeper understanding and richer experience with parallel computing. Currently we provide support and sample implementations for pthreads, OpenMP, CUDA, and sequential applications. To test its effectiveness for parallel computing education, we deployed ParaVis for lab assignments in both intermediate and upper level courses. We present example applications, and evaluate the use of the library across our undergraduate CS curriculum.},
  keywords={},
  doi={10.1109/IPDPSW.2019.00062},
  ISSN={},
  month={May},}
@INPROCEEDINGS{8791953,
  author={Rho, Seungwoo and Choi, Ji Eun and Park, Geunchul and Park, Chan-Yeol},
  booktitle={2019 IEEE 4th International Workshops on Foundations and Applications of Self* Systems (FAS*W)}, 
  title={Performance Analysis of Various Multi-and Many-Core Systems Centered on Memory}, 
  year={2019},
  volume={},
  number={},
  pages={194-199},
  abstract={Herein, we evaluated and analyzed the major benchmark performance of various multiple-core systems to identify their structures and characteristics. To this end, we developed a benchmark automation tool and selected five Intel and AMD systems. We also chose three key benchmarks, namely STREAM, High-Performance Linpack (HPL), and High-Performance Conjugate Gradient (HPCG), to evaluate the memory, CPU, and aggregate performance. In the STREAM experiment, the high-bandwidth memory (MCDRAM) performance of the KNL was reduced by more than 50% at a specific point owing to the accuracy of the input array size which can be ignored in DDR memory. In the HPL experiment, KNL using MCDRAM exhibited the best optimization performance, but in the experiment without optimization, the performance of MCDRAM was rather lower than DDR or cache. Thus, MCDRAM code optimization may be required to utilize MCDRAM at peak performance in the many-core environment. In the HPCG experiment, the performance variance was large depending on the combination of the MPI process and the number of shared threads. When the number of MPI processes is set to 2 or 4 and the total number of shared threads is equal to the number of physical cores in the system, excellent performance was obtained. Moreover, the maximum performance of each single system was proportional to the memory performance.},
  keywords={},
  doi={10.1109/FAS-W.2019.00053},
  ISSN={},
  month={June},}
@INPROCEEDINGS{8814959,
  author={Dibaji, Seyed Mehran and Safi, Mostafa and Ishii, Hideaki},
  booktitle={2019 American Control Conference (ACC)}, 
  title={Resilient Distributed Averaging}, 
  year={2019},
  volume={},
  number={},
  pages={96-101},
  abstract={In this paper, a fully distributed averaging algorithm in the presence of adversarial Byzantine agents is proposed. The algorithm is based on a resilient retrieval procedure, where all non-Byzantine nodes send their own initial values and retrieve those of other agents. We establish that the convergence of the proposed algorithm relies on strong robustness of the graph, which is a connectivity notion. Simulation results are provided to verify the effectiveness of the proposed algorithms.},
  keywords={},
  doi={10.23919/ACC.2019.8814959},
  ISSN={2378-5861},
  month={July},}
@INPROCEEDINGS{8819837,
  author={Chaparala, Pushya and Atmakuri, Aparna Rajesh and Rao, S. Siva Sankara},
  booktitle={2019 3rd International Conference on Computing Methodologies and Communication (ICCMC)}, 
  title={3 -Phase Leader Election Algorithm for Distributed Systems}, 
  year={2019},
  volume={},
  number={},
  pages={898-904},
  abstract={Election plays a foremost part in distributed systems. The reason behind the Election process in distributed system is to optimize in terms of load and improving the efficiency of the system there by improving the process of group communication. Choosing a node to be a leader in a distributed environment is intricate. Over years, there are so much of exploitations in the existing techniques such as ring and bully but these algorithms could not able to provide an appropriate solution in terms of message complexity. In this paper, we proposed a novel method known as "3-Phase Leader Election Algorithm" that consists of three phases. Firstly, it identifies and filters the nodes for election. Secondly, the filtered nodes are been validated for determination of prime node via which the group communication takes place. Finally, the Prime node will be identified and accepted in the acceptance phase. Our approach is based on understanding the complexity involved behind a message and improving the efficiency of the system via following performance metrics such as Time and Communication complexity.},
  keywords={},
  doi={10.1109/ICCMC.2019.8819837},
  ISSN={},
  month={March},}
@INPROCEEDINGS{8821007,
  author={Bachan, John and Baden, Scott B. and Hofmeyr, Steven and Jacquelin, Mathias and Kamil, Amir and Bonachea, Dan and Hargrove, Paul H. and Ahmed, Hadia},
  booktitle={2019 IEEE International Parallel and Distributed Processing Symposium (IPDPS)}, 
  title={UPC++: A High-Performance Communication Framework for Asynchronous Computation}, 
  year={2019},
  volume={},
  number={},
  pages={963-973},
  abstract={UPC++ is a C++ library that supports high-performance computation via an asynchronous communication framework. This paper describes a new incarnation that differs substantially from its predecessor, and we discuss the reasons for our design decisions. We present new design features, including future-based asynchrony management, distributed objects, and generalized Remote Procedure Call (RPC). We show microbenchmark performance results demonstrating that one-sided Remote Memory Access (RMA) in UPC++ is competitive with MPI-3 RMA; on a Cray XC40 UPC++ delivers up to a 25% improvement in the latency of blocking RMA put, and up to a 33% bandwidth improvement in an RMA throughput test. We showcase the benefits of UPC++ with irregular applications through a pair of application motifs, a distributed hash table and a sparse solver component. Our distributed hash table in UPC++ delivers near-linear weak scaling up to 34816 cores of a Cray XC40. Our UPC++ implementation of the sparse solver component shows robust strong scaling up to 2048 cores, where it outperforms variants communicating using MPI by up to 3.1x. UPC++ encourages the use of aggressive asynchrony in low overhead RMA and RPC, improving programmer productivity and delivering high performance in irregular applications.},
  keywords={},
  doi={10.1109/IPDPS.2019.00104},
  ISSN={1530-2075},
  month={May},}
@ARTICLE{8827501,
  author={Zhang, Hao and Fu, You and Feng, Lu-Bin and Zhang, Yue and Hua, Rong},
  journal={IEEE Access}, 
  title={Implementation of Hybrid Alignment Algorithm for Protein Database Search on the SW26010 Many-Core Processor}, 
  year={2019},
  volume={7},
  number={},
  pages={128054-128063},
  abstract={In biological research, biology sequence alignment algorithm aims to find similarities between sequences. As the size of biological database increases exponentially, the complexity of sequence alignment process also increases rapidly, which results in a large amount of computational time. The Sunway TaihuLight is the world's first heterogeneous supercomputer with peak performance over 100 PFlops and provides a new hardware platform for database search. In this paper we present an efficient method of protein database search based on Sunway TaihuLight supercomputer. Furthermore, we also optimize protein database search on Sunway TaihuLight to give full play to the performance of the SW26010 processor. In our proposed approach, we design hybrid sequence alignment by combining the Smith-Waterman local alignment algorithm and the Needleman-Wunsch global alignment algorithm. The protein database search is paralleled by message passing interface (MPI) and accelerated thread library (Athread). Experiment results with the Swiss-Prot database show that our implementation can effectively leverage the SW26010 processor's special hardware architecture and achieve a speedup to 15.91 times on a single node. In addition, we expand the scale to 64 nodes to test the scalability of the parallel method on the Sunway TaihuLight system, and the results show that our parallel implementation of protein database search have a good expansibility and reliability.},
  keywords={},
  doi={10.1109/ACCESS.2019.2940044},
  ISSN={2169-3536},
  month={},}
@ARTICLE{8835040,
  author={Jabari, Saif Eddin G. and Dilip, Deepthi Mary and Lin, Dianchao and Thonnam Thodi, Bilal},
  journal={IEEE Access}, 
  title={Learning Traffic Flow Dynamics Using Random Fields}, 
  year={2019},
  volume={7},
  number={},
  pages={130566-130577},
  abstract={This paper presents a mesoscopic traffic flow model that explicitly describes the spatio-temporal evolution of the probability distributions of vehicle trajectories. The dynamics are represented by a sequence of factor graphs, which enable learning of traffic dynamics from limited Lagrangian measurements using an efficient message passing technique. The approach ensures that estimated speeds and traffic densities are non-negative with probability one. The estimation technique is tested using vehicle trajectory datasets generated using an independent microscopic traffic simulator and is shown to efficiently reproduce traffic conditions with probe vehicle penetration levels as little as 10%. The proposed algorithm is also compared with state-of-the-art traffic state estimation techniques developed for the same purpose and it is shown that the proposed approach can outperform the state-of-the-art techniques in terms reconstruction accuracy.},
  keywords={},
  doi={10.1109/ACCESS.2019.2941088},
  ISSN={2169-3536},
  month={},}
@INPROCEEDINGS{8835311,
  author={Lobma, Fadhil and Gunawan, P. H.},
  booktitle={2019 7th International Conference on Information and Communication Technology (ICoICT)}, 
  title={Computing UDCHR Scheme for simulating underwater sediment movement using OpenMP}, 
  year={2019},
  volume={},
  number={},
  pages={1-5},
  abstract={Parallel computing with OpenMP platform in numerical simulation of underwater sediment movement is elaborated. The result shown computer I with processor type Intel Core i7-7500U has better speedup performance ( 3.291493 times of serial computing) than Computer II with processor type AMD Ryzen 5 2400G. Meanwhile, using computer II, the speedup of parallel computing is obtained 3.751561 times of serial computing. Indeed this discrepancy occurs because of the processor type of Computer I is higher than Computer II. Moreover, the efficiency of Computer II is 11.5% lower than computer II which is conducted 91.1367% efficiency. This means using Computer II the ability of parallel codes to achieve best performance proportional to the number of processor is obtained. Furthermore, the numerical simulation using UDCHR is shown in a good agreement with the staggered grid scheme of two-layer SWE and SWE-Exner model.},
  keywords={},
  doi={10.1109/ICoICT.2019.8835311},
  ISSN={},
  month={July},}
@INPROCEEDINGS{8839375,
  author={Gava, Jonas and Bandeira, Vitor and Reis, Ricardo and Ost, Luciano},
  booktitle={2019 IEEE Computer Society Annual Symposium on VLSI (ISVLSI)}, 
  title={Evaluation of Compilers Effects on OpenMP Soft Error Resiliency}, 
  year={2019},
  volume={},
  number={},
  pages={259-264},
  abstract={Software engineers are using different compilers and parallel programming models (e.g., Pthreads, OpenMP) to take the best performance offered by multicore systems. Both programming models and compilers have specific characteristics, which directly impact on applications code footprint, performance, power-efficiency and reliability. The occurrence of soft errors in multicore systems is a growing reliability issue in several domains (e.g., automotive, medical, avionics). In this scenario, this paper investigates the impact of widely adopted compilers on the soft error reliability of applications implemented with OpenMP library. Fault injection campaigns consider 3 open-source compilers (GNU/GCC 5.5.0, 7.3.1, Clang 6.0.1), 16 OpenMP benchmarks executing on single, dual and quad-core versions of the Arm Cortex-A72 processor. Results show that, on average, Clang is 15.85% more reliable than both versions of GCC, which demonstrate to be more sensitive to the optimisation flags when compared to Clang.},
  keywords={},
  doi={10.1109/ISVLSI.2019.00055},
  ISSN={2159-3477},
  month={July},}
@INPROCEEDINGS{8843636,
  author={Ouni, Hiba and Klai, Kais and Abid, Chiheb Ameur and Zouari, Belhassen},
  booktitle={2019 19th International Conference on Application of Concurrency to System Design (ACSD)}, 
  title={Towards Parallel Verification of Concurrent Systems using the Symbolic Observation Graph}, 
  year={2019},
  volume={},
  number={},
  pages={23-32},
  abstract={An efficient way to cope with the combinatorial explosion problem induced by the model checking process is to compute the Symbolic Observation Graph (SOG). Given an stuttering invariant event-based LTL formula φ, involving a subset of actions E (called observed actions), the SOG is a condensed representation of the state space graph based on a symbolic encoding of the nodes (sets of states linked with unobserved actions) and an explicit representation of the edges (labelled with observed actions only). It has the advantage to be much reduced comparing to the original state space graph while being equivalent with respect to linear time properties (i.e., the original state space graph satisfies φ if and only if the corresponding SOG satisfies φ). Aiming to go further in the process of tackling the state space explosion problem, we propose in this paper to parallelize the construction of the SOG using a hybrid approach (distributed+shared memory). Doing so, we take advantage of the recent advances in computer hardware, by distributing the construction process over a large number of multi-core processors. We studied the performances of our new approach comparing to both distributed and shared memory approaches on one side, and to the sequential construction of the SOG, on the other hand. The obtained results show that the proposed approach offers an interesting alternative allowing to completely exploit the available distributed architecture while offering significant speedup.},
  keywords={},
  doi={10.1109/ACSD.2019.00007},
  ISSN={2374-8567},
  month={June},}
@INPROCEEDINGS{8845079,
  author={Gokalgandhi, Bhargav and Seskar, Ivan},
  booktitle={IEEE INFOCOM 2019 - IEEE Conference on Computer Communications Workshops (INFOCOM WKSHPS)}, 
  title={Distributed Processing for Encoding and Decoding of Binary LDPC codes using MPI}, 
  year={2019},
  volume={},
  number={},
  pages={596-601},
  abstract={Low Density Parity Check (LDPC) codes are linear error correcting codes used in communication systems for Forward Error Correction (FEC). But, intensive computation is required for encoding and decoding of LDPC codes, making it difficult for practical usage in general purpose software based signal processing systems. In order to accelerate the encoding and decoding of LDPC codes, distributed processing over multiple multi-core CPUs using Message Passing Interface (MPI) is performed. Implementation is done using Stream Processing and Batch Processing mechanisms and the execution time for both implementations is compared w.r.t variation in number of CPUs and number of cores per CPU. Performance evaluation of distributed processing is shown by variation in execution time w.r.t. increase in number of processors (CPU cores).},
  keywords={},
  doi={10.1109/INFCOMW.2019.8845079},
  ISSN={},
  month={April},}
@INPROCEEDINGS{8849292,
  author={Barbi, Roberta and Felber, Pascal and Hayez, Laurent and Mercier, Hugues},
  booktitle={2019 IEEE International Symposium on Information Theory (ISIT)}, 
  title={Convolutional LPDC codes for Distributed Storage Systems}, 
  year={2019},
  volume={},
  number={},
  pages={1572-1576},
  abstract={We study convolutional LDPC codes over the binary erasure channel for immutable distributed storage systems. These codes allow the archival of data objects in a sequential fashion on an increasing number of storage nodes as they arrive in the system, as well as fast repair using a simple message passing decoder. We further target systematic codes, high code rates and low locality, which are paramount in this setting. We describe a family of codes that split each archived data object in s blocks, entangle them with t = s + p blocks already archived, and generate p parity blocks per archived data object. We carefully choose the parity-check matrix and the blocks already archived to maximize the repair capability of the resulting codes, and describe the best constructions for 1 ≤ s ≤ 5 and p = 2. A Markov analysis shows that for the same storage overhead, our codes are orders of magnitude more reliable than state-of-the-art Reed-Solomon and locally repairable codes.},
  keywords={},
  doi={10.1109/ISIT.2019.8849292},
  ISSN={2157-8117},
  month={July},}
@INPROCEEDINGS{8855310,
  author={Li, Ming and Hawrylak, Peter and Hale, John},
  booktitle={2019 2nd International Conference on Data Intelligence and Security (ICDIS)}, 
  title={Concurrency Strategies for Attack Graph Generation}, 
  year={2019},
  volume={},
  number={},
  pages={174-179},
  abstract={The network attack graph is a powerful tool for analyzing network security, but the generation of a large-scale graph is non-trivial. The main challenge is from the explosion of network state space, which greatly increases time and storage costs. In this paper, three parallel algorithms are proposed to generate scalable attack graphs. An OpenMP-based programming implementation is used to test their performance. Compared with the serial algorithm, the best performance from the proposed algorithms provides a 10X speedup.},
  keywords={},
  doi={10.1109/ICDIS.2019.00033},
  ISSN={},
  month={June},}
@INPROCEEDINGS{8855563,
  author={Hu, Guangchao and Zhang, Yang and Chen, Wenbo},
  booktitle={2019 IEEE 21st International Conference on High Performance Computing and Communications; IEEE 17th International Conference on Smart City; IEEE 5th International Conference on Data Science and Systems (HPCC/SmartCity/DSS)}, 
  title={Exploring the Performance of Singularity for High Performance Computing Scenarios}, 
  year={2019},
  volume={},
  number={},
  pages={2587-2593},
  abstract={Traditional hypervisor-based virtualization solutions have not been commonly used in High Performance Computing (HPC) due to the performance overhead. Container-based virtualization technologies represented by Linux Container and Docker can provide better resource sharing, customized environments and low overhead. However, they still can't satisfy the functional and security needs in HPC environments. Singularity is an attractive container-based approach to meet the requirements of scientific applications. Its characteristics such as mobility of compute, reproducibility, user freedom and support on existing traditional HPC, can effectively solve some flaws compared to other virtualization technologies. In this paper, we conducted a detailed performance evaluation of CPU, memory and network bandwidth between Singularity and bare metal by using HPL, STREAM and OSU Micro benchmarks. Four typical HPC applications such as NAMD, VASP, AMBER, and WRF are deployed to further validate the performance overhead of Singularity. Furthermore, migration and compatibility of Singularity are also investigated. Results from the experiments show that Singularity can achieve near-native performance in MPI and GPU parallel applications, which also demonstrate that it has a greater application prospect in HPC.},
  keywords={},
  doi={10.1109/HPCC/SmartCity/DSS.2019.00362},
  ISSN={},
  month={Aug},}
@INPROCEEDINGS{8855450,
  author={Qi, Xiao and Liu, Bin and Li, Yuancheng and Du, Yanning and Li, Yuxiang and Niu, Dangdang},
  booktitle={2019 IEEE 21st International Conference on High Performance Computing and Communications; IEEE 17th International Conference on Smart City; IEEE 5th International Conference on Data Science and Systems (HPCC/SmartCity/DSS)}, 
  title={A Parallel BMH String Matching Algorithm Based on OpenMP}, 
  year={2019},
  volume={},
  number={},
  pages={75-81},
  abstract={BMH(Boyer-Moore-Horspool) string matching algorithms have played an important role in the field of biological sequence alignment, text processing, spell checking, and computer virus signature matching. However, with the explosive growth of the data, the serial string matching algorithm is too slow to finish the matching task within an acceptable time. This paper proposed a parallel BMH string matching algorithm based on OpenMP. The parallelism of the BMH algorithm is first identified by theoretical analysis. Then, the sequential algorithm is designed as a parallel algorithm in a data-parallel form and the larger string matching task is divided into multiple sub-string matching tasks by partitioning strategy. Furthermore, using the thread-level parallel technique, each thread carries out string matching operations on different sub-string blocks in parallel. Compared with the serial BMH algorithm, the parallel BMH matching algorithm with 8 threads can achieve up to 3.53 times speedup. On the OpenMP platform, experimental results show that the proposed parallel algorithm can acquire a significant increase in speedup. Under the accuracy of ensuring the string matching, the optimal number of threads and the most optimal block segmentation scheme are obtained through experimental tests. It indicates that the OpenMP-based parallel BMH algorithm has excellent acceleration performance, and an advantageous application prospect in various field.},
  keywords={},
  doi={10.1109/HPCC/SmartCity/DSS.2019.00026},
  ISSN={},
  month={Aug},}
@INPROCEEDINGS{8855601,
  author={Zheng, Wenxu and Fang, Jianbin and Juan, Chen and Wu, Feihao and Pan, Xiaodong and Wang, Hao and Sun, Xiaole and Yuan, Yuan and Xie, Min and Huang, Chun and Tang, Tao and Wang, Zheng},
  booktitle={2019 IEEE 21st International Conference on High Performance Computing and Communications; IEEE 17th International Conference on Smart City; IEEE 5th International Conference on Data Science and Systems (HPCC/SmartCity/DSS)}, 
  title={Auto-Tuning MPI Collective Operations on Large-Scale Parallel Systems}, 
  year={2019},
  volume={},
  number={},
  pages={670-677},
  abstract={MPI libraries are widely used in applications of high performance computing. Yet, effective tuning of MPI colletives on large parallel systems is an outstanding challenge. This process often follows a trial-and-error approach and requires expert insights into the subtle interactions between software and the underlying hardware. This paper presents an empirical approach to choose and switch MPI communication algorithms at runtime to optimize the application performance. We achieve this by first modeling offline, through microbenchmarks, to find how the runtime parameters with different message sizes affect the choice of MPI communication algorithms. We then apply the knowledge to automatically optimize new unseen MPI programs. We evaluate our approach by applying it to NPB and HPCC benchmarks on a 384-node computer cluster of the Tianhe-2 supercomputer. Experimental results show that our approach achieves, on average, 22.7% (up to 40.7%) improvement over the default setting.},
  keywords={},
  doi={10.1109/HPCC/SmartCity/DSS.2019.00101},
  ISSN={},
  month={Aug},}
@INPROCEEDINGS{8884924,
  author={Shi, Shaohuai and Wang, Qiang and Zhao, Kaiyong and Tang, Zhenheng and Wang, Yuxin and Huang, Xiang and Chu, Xiaowen},
  booktitle={2019 IEEE 39th International Conference on Distributed Computing Systems (ICDCS)}, 
  title={A Distributed Synchronous SGD Algorithm with Global Top-k Sparsification for Low Bandwidth Networks}, 
  year={2019},
  volume={},
  number={},
  pages={2238-2247},
  abstract={Distributed synchronous stochastic gradient descent (S-SGD) with data parallelism has been widely used in training large-scale deep neural networks (DNNs), but it typically requires very high communication bandwidth between computational workers (e.g., GPUs) to exchange gradients iteratively. Recently, Top-k sparsification techniques have been proposed to reduce the volume of data to be exchanged among workers and thus alleviate the network pressure. Top-k sparsification can zero-out a significant portion of gradients without impacting the model convergence. However, the sparse gradients should be transferred with their indices, and the irregular indices make the sparse gradients aggregation difficult. Current methods that use AllGather to accumulate the sparse gradients have a communication complexity of O(kP), where P is the number of workers, which is inefficient on low bandwidth networks with a large number of workers. We observe that not all top-k gradients from P workers are needed for the model update, and therefore we propose a novel global Top-k (gTop-k) sparsification mechanism to address the difficulty of aggregating sparse gradients. Specifically, we choose global top-k largest absolute values of gradients from P workers, instead of accumulating all local top-k gradients to update the model in each iteration. The gradient aggregation method based on gTop-k sparsification, namely gTopKAllReduce, reduces the communication complexity from O(kP) to O(k log P). Through extensive experiments on different DNNs, we verify that gTop-k S-SGD has nearly consistent convergence performance with S-SGD, and it has only slight degradations on generalization performance. In terms of scaling efficiency, we evaluate gTop-k on a cluster with 32 GPU machines which are interconnected with 1 Gbps Ethernet. The experimental results show that our method achieves 2.7-12× higher scaling efficiency than S-SGD with dense gradients and 1.1-1.7× improvement than the existing Top-k S-SGD.},
  keywords={},
  doi={10.1109/ICDCS.2019.00220},
  ISSN={2575-8411},
  month={July},}
@INPROCEEDINGS{8891033,
  author={Naser, Abu and Gavahi, Mohsen and Wu, Cong and Hoang, Viet Tung and Wang, Zhi and Yuan, Xin},
  booktitle={2019 IEEE International Conference on Cluster Computing (CLUSTER)}, 
  title={An Empirical Study of Cryptographic Libraries for MPI Communications}, 
  year={2019},
  volume={},
  number={},
  pages={1-11},
  abstract={As High Performance Computing (HPC) applications with data security requirements are increasingly moving to execute in the public cloud, there is a demand that the cloud infrastructure for HPC should support privacy and integrity. Incorporating privacy and integrity mechanisms in the communication infrastructure of today's public cloud is challenging because recent advances in the networking infrastructure in data centers have shifted the communication bottleneck from the network links to the network end points and because encryption is computationally intensive. In this work, we consider incorporating encryption to support privacy and integrity in the Message Passing Interface (MPI) library, which is widely used in HPC applications. We empirically study four contemporary cryptographic libraries, OpenSSL, BoringSSL, Libsodium, and CryptoPP using micro-benchmarks and NAS parallel benchmarks to evaluate their overheads for encrypting MPI messages on two different networking technologies, 10Gbps Ethernet and 40Gbps InfiniBand. The results indicate that (1) the performance differs drastically across cryptographic libraries, and (2) effectively supporting privacy and integrity in MPI communications on high speed data center networks is challenging-even with the most efficient cryptographic library, encryption can still introduce very significant overheads in some scenarios such as a single MPI communication operation on InfiniBand, but (3) the overall overhead may not be prohibitive for practical uses since there can be multiple concurrent communications.},
  keywords={},
  doi={10.1109/CLUSTER.2019.8891033},
  ISSN={2168-9253},
  month={Sep.},}
@INPROCEEDINGS{8892329,
  author={Al-Twajre, Baseem A.},
  booktitle={2019 XIth International Scientific and Practical Conference on Electronics and Information Technologies (ELIT)}, 
  title={Performance Analysis of Messages Queue in the Different Actor System Implementation}, 
  year={2019},
  volume={},
  number={},
  pages={127-131},
  abstract={The level of design and implement models and platform of Internet of things products have many options when choosing the computational model. One of the fittest models for the Internet of things is the actor model due to excellent performance on internal concurrency controls, scalability, and fault-tolerance that make it a promising approach for developing concurrent systems. In this paper, we focusing on some existing different actor system implementation like Lift, Akka, and Scalaz using comparative analysis to provide an overview of the success rate of the designed actor model and overcome the challenges for quickly develop concurrent and distributed applications. The results of benchmarks will guide developers in selecting a suitable actor implementation for their application and facilitate in the development of other actor model implementation. The used benchmarks show that Scalaz has the best performance between actor system implementations as related to throughput and latency on another hand Akka Actor implementation best in Actor life cycle management. The future work will be focusing on improving a messages queue to increase the performance of the actor model implementation.},
  keywords={},
  doi={10.1109/ELIT.2019.8892329},
  ISSN={},
  month={Sep.},}

@INPROCEEDINGS{8903792,
  author={Lakhlef, Hicham and Imine, Youcef and Bouabdallah, Abdelmadjid},
  booktitle={2019 International Conference on Software, Telecommunications and Computer Networks (SoftCOM)}, 
  title={A Distributed Collision-free Distance-2 Coloring Algorithm for Ring Networks}, 
  year={2019},
  volume={},
  number={},
  pages={1-6},
  abstract={This work considers the problem of communication in resource limited wireless nodes. In this kind of networks, a massive amount of data is becoming increasingly available, and consequently implementing protocols achieving error-free communication channels constitutes an important challenge. Indeed, in this kind of networks, the prevention of message conflicts and message collisions is a crucial issue. In terms of graph theory, solving this issue amounts to solve the distance-2 coloring problem on the network. This paper presents a distributed algorithm for ring networks, providing the nodes with such a coloring. Contrary to existing works, this algorithm is itself collision-free and conflict-free. It is particularly suited to wireless networks composed of nodes with communication or local memory constraints. The proposed protocol is implemented and tested using Omnet++ simulator.},
  keywords={},
  doi={10.23919/SOFTCOM.2019.8903792},
  ISSN={1847-358X},
  month={Sep.},}
@INPROCEEDINGS{8909189,
  author={Arapoglu, Ozkan and Dagdeviren, Orhan},
  booktitle={2019 International Symposium on Networks, Computers and Communications (ISNCC)}, 
  title={An Asynchronous Self-Stabilizing Maximal Independent Set Algorithm in Wireless Sensor Networks Using Two-Hop Information}, 
  year={2019},
  volume={},
  number={},
  pages={1-5},
  abstract={Maximal independent set (MIS) has significantly important in practical applications for wireless sensor networks (WSNs). A distributed self-stabilizing system can initially start at any illegal state and takes back a legal state as long as there is no external intervention. We propose a novel distributed self-stabilizing MIS algorithm using two-hop information. It stabilizes an unstable system at most n-1 moves under an unfair distributed scheduler where n is the number of nodes in the graph. We use the message passing model as the communication model where this model is very appropriate for WSNs. The communication consumes the most energy in WSNs. So, move count is at least as important as round count where reducing the move count prolongs the lifetime of the network. We analyzed theoretically and tested it on SimPy discrete event simulator on randomly generated connected simple undirected graphs to compare with its counterparts in terms of transmitted bit count and move count against various node degrees and node counts.},
  keywords={},
  doi={10.1109/ISNCC.2019.8909189},
  ISSN={},
  month={June},}
@INPROCEEDINGS{8916253,
  author={Kain, Evan and Wildenstein, Diego and Pineda, Andrew C.},
  booktitle={2019 IEEE High Performance Extreme Computing Conference (HPEC)}, 
  title={Embedded GPU Cluster Computing Framework for Inference of Convolutional Neural Networks}, 
  year={2019},
  volume={},
  number={},
  pages={1-7},
  abstract={The growing need for on-board image processing for space vehicles requires computing solutions that are both low-power and high-performance. Parallel computation using low-power embedded Graphics Processing Units (GPUs) satisfy both requirements. Our experiment involves the use of OpenMPI domain decomposition of an image processing algorithm based upon a pre-trained convolutional neural network (CNN) developed by the U.S. Air Force Research Laboratory (AFRL). Our testbed consists of six NVIDIA Jetson TX2 development boards operating in parallel. This parallel framework results in a speedup of $4.3 \times $ on six processing nodes. This approach also leads to a linear decay in parallel efficiency as more processing nodes are added to the network. By replicating the data across processors in addition to distributing, we also characterize the best-case impact of adding triple modular redundancy (TMR) to our application.},
  keywords={},
  doi={10.1109/HPEC.2019.8916253},
  ISSN={2643-1971},
  month={Sep.},}
@INPROCEEDINGS{8916552,
  author={Guan, Hongtao and Dong, Xiaofeng and Xue, Chen and Luo, Zhirong and Yang, Hao and Wu, Tao},
  booktitle={2019 Seventh International Conference on Advanced Cloud and Big Data (CBD)}, 
  title={Optimization of POM Based on Parallel Supercomputing Grid Cloud Platform}, 
  year={2019},
  volume={},
  number={},
  pages={49-54},
  abstract={As the ocean model continues to improve, the resolution of the model continues to increase. However, this also puts higher and higher requirements on the computing power of the running platform, which makes the existing POM mode operating platform face more and more pressure. In this paper, the POM model based on MPI parallel optimization is transplanted to the high-performance scientific computing and system simulation platform based on Intel Xeon. Through extensive testing of the POM model, we analyzed the problems in the model and developed an optimization strategy to improve the POM model from the function level. The experimental results show that our optimization strategy can effectively reduce the execution time of POM mode, and the parallel acceleration ratio reached 111.26%, which makes the POM mode well improved.},
  keywords={},
  doi={10.1109/CBD.2019.00019},
  ISSN={},
  month={Sep.},}
@INPROCEEDINGS{8916436,
  author={Sindi, Mohamad and Williams, John R.},
  booktitle={2019 IEEE High Performance Extreme Computing Conference (HPEC)}, 
  title={Using Container Migration for HPC Workloads Resilience}, 
  year={2019},
  volume={},
  number={},
  pages={1-10},
  abstract={We share experiences in implementing a containerbased HPC environment that could help sustain running HPC workloads on clusters. By running workloads inside containers, we are able to migrate them from cluster nodes anticipating hardware problems, to healthy nodes while the workloads are running. Migration is done using the CRIU tool with no application modification. No major interruption or overhead is introduced to the workload. Various real HPC applications are tested. Tests are done with different hardware node specs, network interconnects, and MPI implementations. We also benchmark the applications on containers and compare performance to native. Results demonstrate successful migration of HPC workloads inside containers with minimal interruption, while maintaining the integrity of the results produced. We provide several YouTube videos demonstrating the migration tests. Benchmarks also show that application performance on containers is close to native. We discuss some of the challenges faced during implementation and solutions adopted. To the best of our knowledge, we believe this work is the first to demonstrate successful migration of real MPI-based HPC workloads using CRIU and containers.},
  keywords={},
  doi={10.1109/HPEC.2019.8916436},
  ISSN={2643-1971},
  month={Sep.},}
@INPROCEEDINGS{8916378,
  author={Ellis, J. Austin and Rajamanickam, Sivasankaran},
  booktitle={2019 IEEE High Performance Extreme Computing Conference (HPEC)}, 
  title={Scalable Inference for Sparse Deep Neural Networks using Kokkos Kernels}, 
  year={2019},
  volume={},
  number={},
  pages={1-7},
  abstract={Over the last decade, hardware advances have led to the feasibility of training and inference for very large deep neural networks. Sparsified deep neural networks (DNNs) can greatly reduce memory costs and increase throughput of standard DNNs, if loss of accuracy can be controlled. The IEEE HPEC Sparse Deep Neural Network Graph Challenge serves as a testbed for algorithmic and implementation advances to maximize computational performance of sparse deep neural networks. We base our sparse network for DNNs, KK-SpDNN, on the sparse linear algebra kernels within the Kokkos Kernels library. Using the sparse matrix-matrix multiplication in Kokkos Kernels allows us to reuse a highly optimized kernel. We focus on reducing the single node and multi-node runtimes for 12 sparse networks. We test KK-SpDNN on Intel Skylake and Knights Landing architectures and see 120-500x improvement on single node performance over the serial reference implementation. We run in data-parallel mode with MPI to further speed up network inference, ultimately obtaining an edge processing rate of 1.16e+12 on 20 Skylake nodes. This translates to a 13x speed up on 20 nodes compared to our highly optimized multithreaded implementation on a single Skylake node.},
  keywords={},
  doi={10.1109/HPEC.2019.8916378},
  ISSN={2643-1971},
  month={Sep.},}
@INPROCEEDINGS{8916302,
  author={Acer, Seher and Yaşar, Abdurrahman and Rajamanickam, Sivasankaran and Wolf, Michael and Catalyürek, Ümit V.},
  booktitle={2019 IEEE High Performance Extreme Computing Conference (HPEC)}, 
  title={Scalable Triangle Counting on Distributed-Memory Systems}, 
  year={2019},
  volume={},
  number={},
  pages={1-5},
  abstract={Triangle counting is a foundational graph-analysis kernel in network science. It has also been one of the challenge problems for the “Static Graph Challenge”. In this work, we propose a novel, hybrid, parallel triangle counting algorithm based on its linear algebra formulation. Our framework uses MPI and Cilk to exploit the benefits of distributed-memory and shared-memory parallelism, respectively. The problem is partitioned among MPI processes using a two-dimensional (2D) Cartesian block partitioning. One-dimensional (1D) rowwise partitioning is used within the Cartesian blocks for shared-memory parallelism using the Cilk programming model. Besides exhibiting very good strong scaling behavior in almost all tested graphs, our algorithm achieves the fastest time on the 1.4B edge real-world twitter graph, which is 3.217 seconds, on 1,092 cores. In comparison to past distributed-memory parallel winners of the graph challenge, we demonstrate a speed up of 2.7× on this twitter graph. This is also the fastest time reported for parallel triangle counting on the twitter graph when the graph is not replicated.},
  keywords={},
  doi={10.1109/HPEC.2019.8916302},
  ISSN={2643-1971},
  month={Sep.},}
@INPROCEEDINGS{8916366,
  author={Merwe, Mark Van der and Joseph, Vinu and Gopalakrishnan, Ganesh},
  booktitle={2019 IEEE High Performance Extreme Computing Conference (HPEC)}, 
  title={Message Scheduling for Performant, Many-Core Belief Propagation}, 
  year={2019},
  volume={},
  number={},
  pages={1-7},
  abstract={Belief Propagation (BP) is a message-passing algorithm for approximate inference over Probabilistic Graphical Models (PGMs), finding many applications such as computer vision, error-correcting codes, and protein-folding. While general, the convergence and speed of the algorithm has limited its practical use on difficult inference problems. As an algorithm that is highly amenable to parallelization, many-core Graphical Processing Units (GPUs) could significantly improve BP performance. Improving BP through many-core systems is non-trivial: the scheduling of messages in the algorithm strongly affects performance. We present a study of message scheduling for BP on GPUs. We demonstrate that BP exhibits a tradeoff between speed and convergence based on parallelism and show that existing message schedulings are not able to utilize this tradeoff. To this end, we present a novel randomized message scheduling approach, Randomized BP (RnBP), which outperforms existing methods on the GPU.},
  keywords={},
  doi={10.1109/HPEC.2019.8916366},
  ISSN={2643-1971},
  month={Sep.},}
@INPROCEEDINGS{8914447,
  author={Dey, Ajeyo and Dash, Satyabrata and Tumati, Likhita and Sharma, Saumitra and Megharajani, Nikhil and Janveja, Meenali and Rodríguez, Ismael and Trivedi, Gaurav},
  booktitle={2019 IEEE International Conference on Systems, Man and Cybernetics (SMC)}, 
  title={A Cooperative Co-evolution based Scalable Framework for Solving Large-Scale Global optimization Problems}, 
  year={2019},
  volume={},
  number={},
  pages={1689-1694},
  abstract={The Cooperative Co-evolution framework is an effective approach for decomposing large scale global optimization problems into multiple sub-components. Every subcomponent uses different optimization algorithms which evolve cooperatively and are independent of each other. These subcomponents contribute in a different way to the overall improvement of the optimal solution. Hence, the computation cost can be decreased by separating out the stagnant subcomponents of the population. Therefore, it is appropriate to allocate resources in an intelligent manner to increase the computational efficiency. In this paper, we illustrate a decomposition strategy to solve large scale global optimization problems which is scalable to millions of variables. The proposed strategy improves computational efficiency and enables embracing parallelization. The framework presented in this paper constitutes Cooperative Co-evolution based Genetic Algorithm with Scalar Distance Grouping technique (CCGA-SDG) derived from Cooperative Co-evolution based Genetic Algorithm (CCGA). In our proposed scheme, a novel scalar distance grouping technique is employed that collates the dependent variables together. The stagnant sub-components of the population are detected using this grouping method and resource reallocation is performed accordingly to increase the computational efficiency. Using our proposed methodology, a benchmark function $f_{6}$ of CEC'08 benchmark composed of 10 million variables is evaluated in 1759.79 seconds using 04 processors connected with Message Passing Interface (MPI) exhibiting better accuracy as compared to other methods. Moreover, for ${f}3$ and $f_{6}$ functions we achieve a better accuracy and for rest of the benchmark functions we achieve acceptable solutions.},
  keywords={},
  doi={10.1109/SMC.2019.8914447},
  ISSN={2577-1655},
  month={Oct},}
@INPROCEEDINGS{8942036,
  author={Gancheva, Veska and Georgiev, Ivaylo},
  booktitle={2019 IEEE 19th International Conference on Bioinformatics and Bioengineering (BIBE)}, 
  title={Multithreaded Parallel Sequence Alignment Based on Needleman-Wunsch Algorithm}, 
  year={2019},
  volume={},
  number={},
  pages={165-169},
  abstract={Biocomputing and molecular biology are areas that change knowledge and skills for acquisition, storing, management, analysis, interpretation and dissemination of biological information. This requires the utilization of high performance computers and innovative software tools for management of the vast information, as well as deployment of innovative algorithmic techniques for analysis, interpretation and prognostication of data in order to get to insight of the design and validation of life-science experiments. Sequence alignment is an important method in DNA and protein analysis. The paper describes the computational challenges in biological sequence processing. The great challenges are to propose parallel computational models and parallel program implementations based on the algorithms for biological sequence alignment. An investigation of the efficiency of sequence alignment based on parallel multithreaded program implementation of Needleman-Wunsch algorithm is presented in this paper. Parallel computational model based on Needleman-Wunsch algorithm is designed. The proposed parallel model is verified by multithreaded parallel program implementation utilizing OpenMP. A number of experiments have been carried out for the case of various data sets and a various number of threads. Parallel performance parameters execution time and speedup are estimated experimentally. The performance estimation and scalability analyses show that the suggested model has good scalability both in respect to the workload and machine size.},
  keywords={},
  doi={10.1109/BIBE.2019.00037},
  ISSN={2471-7819},
  month={Oct},}
@INPROCEEDINGS{8945096,
  author={Maley, F. Miller and DeVinney, Jason G.},
  booktitle={2019 IEEE/ACM 9th Workshop on Irregular Applications: Architectures and Algorithms (IA3)}, 
  title={Conveyors for Streaming Many-To-Many Communication}, 
  year={2019},
  volume={},
  number={},
  pages={1-8},
  abstract={We report on a software package that offers high-bandwidth and memory-efficient ways for a parallel application to transmit numerous small data items among its processes. The package provides a standalone library that can integrated into any SHMEM, UPC, or MPI application. It defines a simple interface to parallel objects called conveyors, and it provides a variety of conveyor implementations. Often the most efficient type of conveyor is an asynchronous three-hop conveyor, which makes heavy use of fast intranode communication. This type also uses the least memory internally. Conveyors of this type scale well to 100,000 processes and beyond. Our experience with conveyors applied to irregular algorithms at scale has convinced us of the necessity and profitability of message aggregation. The conveyor interface is a low-level C API that is intended to guide future hardware and runtime improvements and to be a foundation for future parallel programming models.},
  keywords={},
  doi={10.1109/IA349570.2019.00007},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{8954164,
  author={Agresti, Gianluca and Schaefer, Henrik and Sartor, Piergiorgio and Zanuttigh, Pietro},
  booktitle={2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Unsupervised Domain Adaptation for ToF Data Denoising With Adversarial Learning}, 
  year={2019},
  volume={},
  number={},
  pages={5579-5586},
  abstract={Time-of-Flight data is typically affected by a high level of noise and by artifacts due to Multi-Path Interference (MPI). While various traditional approaches for ToF data improvement have been proposed, machine learning techniques have seldom been applied to this task, mostly due to the limited availability of real world training data with depth ground truth. In this paper, we avoid to rely on labeled real data in the learning framework. A Coarse-Fine CNN, able to exploit multi-frequency ToF data for MPI correction, is trained on synthetic data with ground truth in a supervised way. In parallel, an adversarial learning strategy, based on the Generative Adversarial Networks (GAN) framework, is used to perform an unsupervised pixel-level domain adaptation from synthetic to real world data, exploiting unlabeled real world acquisitions. Experimental results demonstrate that the proposed approach is able to effectively denoise real world data and to outperform state-of-the-art techniques.},
  keywords={},
  doi={10.1109/CVPR.2019.00573},
  ISSN={2575-7075},
  month={June},}
@INPROCEEDINGS{8951036,
  author={Lin, Pei-Hung and Liao, Chunhua and Schordan, Markus and Karlin, Ian},
  booktitle={2019 IEEE/ACM 3rd International Workshop on Software Correctness for HPC Applications (Correctness)}, 
  title={Exploring Regression of Data Race Detection Tools Using DataRaceBench}, 
  year={2019},
  volume={},
  number={},
  pages={11-18},
  abstract={DataRaceBench is an OpenMP benchmark suite designed to systematically and quantitatively evaluate data race detection tools. It has been used by several research and development groups to measure the quality of their tools. In this paper we explore how to evaluate the regression of data race detection tools in the presence of observed tool errors. We define how to generating consistent, reproducible, and comparable evaluation results and a detailed evaluation process with a set of configuration and execution rules. We also outline differences in the evaluation of dynamic and static data race detection tools. In addition to the evaluation results, we explore and suggest different ways to process and present the data, with a focus on tool errors. Using DataRaceBench we show an accuracy regression for several popular data race detection tools in recent release cycles.},
  keywords={},
  doi={10.1109/Correctness49594.2019.00007},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{8952145,
  author={Hamid, Brahim and Rouland, Quentin and Jaskolka, Jason},
  booktitle={2019 IEEE 24th Pacific Rim International Symposium on Dependable Computing (PRDC)}, 
  title={Distributed Maintenance of a Spanning Tree of k-Connected Graphs}, 
  year={2019},
  volume={},
  number={},
  pages={217-21709},
  abstract={This work is devoted to the problem of spanning trees maintenance in the presence of crash failures in a distributed environment using only local knowledge. Using a pre-constructed spanning tree of a k-connected graph, we present a protocol to maintain a spanning tree in the presence of k-1 consecutive failures. The contribution of this paper is threefold. First, the problem is formalized as an occurrence of Menger's theorem in a distributed setting. The second result shows an implementation of the protocol which is composed of a set of modules encoded using a graph relabeling systems model. The last contribution is the implementation of this protocol in the asynchronous message passing model. For a given graph G =(V,E), where M is the number of its edges, N is the number of its nodes, and Δ is its degree; After each failure occurrence, our algorithms need the following requirements: The first one uses O(Δ × N) steps and O(Δ) bits per node. The second one uses O(N+M) messages and O(N) time and O(Δ) bits per node. In addition, we investigate the possible specification and verification of the presented algorithm using Alloy as a tooled formal language.},
  keywords={},
  doi={10.1109/PRDC47002.2019.00052},
  ISSN={2473-3105},
  month={Dec},}
@INPROCEEDINGS{8955253,
  author={Agarwal, Megha and Singhvi, Divyansh and Malakar, Preeti and Byna, Suren},
  booktitle={2019 IEEE/ACM Fourth International Parallel Data Systems Workshop (PDSW)}, 
  title={Active Learning-based Automatic Tuning and Prediction of Parallel I/O Performance}, 
  year={2019},
  volume={},
  number={},
  pages={20-29},
  abstract={Parallel I/O is an indispensable part of scientific applications. The current stack of parallel I/O contains many tunable parameters. While changing these parameters can increase I/O performance many-fold, the application developers usually resort to default values because tuning is a cumbersome process and requires expertise. We propose two auto-tuning models, based on active learning that recommend a good set of parameter values (currently tested with Lustre parameters and MPI-IO hints) for an application on a given system. These models use Bayesian optimization to find the values of parameters by minimizing an objective function. The first model runs the application to determine these values, whereas, the second model uses an I/O prediction model for the same. Thus the training time is significantly reduced in comparison to the first model (e.g., from 800 seconds to 18 seconds). Also both the models provide flexibility to focus on improvement of either read or write performance. To keep the tuning process generic, we have focused on both read and write performance. We have validated our models using an I/O benchmark (IOR) and 3 scientific application I/O kernels (S3D-IO, BT-IO and GenericIO) on two supercomputers (HPC2010 and Cori). Using the two models, we achieve an increase in I/O bandwidth of up to 11× over the default parameters. We got up to 3× improvements for 37 TB writes, corresponding to 1 billion particles in GenericIO. We also achieved up to 3.2× higher bandwidth for 4.8 TB of noncontiguous I/O in BT-IO benchmark.},
  keywords={},
  doi={10.1109/PDSW49588.2019.00007},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{8958670,
  author={Sirjani, Marjan},
  booktitle={2019 IEEE/ACM 23rd International Symposium on Distributed Simulation and Real Time Applications (DS-RT)}, 
  title={Analysing Real-time Distributed Systems using Timed Actors}, 
  year={2019},
  volume={},
  number={},
  pages={1-1},
  abstract={I will introduce timed actors for modeling distributed systems and will explain our theories, techniques and tools for model checking and performance evaluation of such models. Timed Rebeca can be used to model asynchronous event-based components in systems, and real time constraints can be captured in the language. I will explain how floating-time transition system can be used for model checking of such models when we are interested in event-based properties, and how it helps in state space reduction. I will show different applications of our approach including analysing a wireless sensor network application, mobile ad-hoc network protocols, network-on-chip designs, and a macroscopic agent-based simulation of urban planning.},
  keywords={},
  doi={10.1109/DS-RT47707.2019.8958670},
  ISSN={1550-6525},
  month={Oct},}
@INPROCEEDINGS{8958682,
  author={Sirjani, Marjan and Khamespanah, Ehsan and Ghassemi, Fatemeh},
  booktitle={2019 IEEE/ACM 23rd International Symposium on Distributed Simulation and Real Time Applications (DS-RT)}, 
  title={Reactive Actors: Isolation for Efficient Analysis of Distributed Systems}, 
  year={2019},
  volume={},
  number={},
  pages={1-10},
  abstract={In this paper we explain how the isolation or decoupling of actors can help in developing efficient analysis techniques. The Reactive Object Language, Rebeca, and its timed extension are introduced as actor-based languages for modeling and analyzing distributed systems. We show how floating-time transition system can be used for model checking of timed actor models when we are interested in event-based properties, and how it helps in state space reduction. We explain how the model of computation of actors helps in devising an efficient state distribution policy in distributed model checking. We show how we use Rebeca to verify the routing algorithms of mobile adhoc networks. The paper is written in a way to make the ideas behind each technique clear such that it can be reused in similar domains.},
  keywords={},
  doi={10.1109/DS-RT47707.2019.8958682},
  ISSN={1550-6525},
  month={Oct},}
@INPROCEEDINGS{8969500,
  author={Guo, Mangqing and Gursoy, M. Cenk},
  booktitle={2019 IEEE Global Conference on Signal and Information Processing (GlobalSIP)}, 
  title={Distributed Sparse Activity Detection in Cell-Free Massive MIMO Systems}, 
  year={2019},
  volume={},
  number={},
  pages={1-5},
  abstract={Distributed sparse activity detection in cell-free massive multiple-input multiple-output (MIMO) systems is considered in this paper. At the beginning of each channel coherence interval, all the active users send pilots to the access points (APs). Then, each AP makes its own decision on the activity of all the users based on the approximate message passing (AMP) iterative procedure. Following this, the optimal fusion rule is used at the fusion center to make the final decisions on the activity of all the users based on the individual decisions and the corresponding reliability obtained at all the APs. The performance levels of this distributed sparse activity detection method are analyzed with Monte Carlo simulations.},
  keywords={},
  doi={10.1109/GlobalSIP45357.2019.8969500},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{8980352,
  author={Du, Dong and Hua, Zhichao and Xia, Yubin and Zang, Binyu and Chen, Haibo},
  booktitle={2019 ACM/IEEE 46th Annual International Symposium on Computer Architecture (ISCA)}, 
  title={XPC: Architectural Support for Secure and Efficient Cross Process Call}, 
  year={2019},
  volume={},
  number={},
  pages={671-684},
  abstract={Microkernel has many intriguing features like security, fault-tolerance, modularity and customizability, which recently stimulate a resurgent interest in both academia and industry (including seL4, QNX and Google's Fuchsia OS). However, IPC (inter-process communication), which is known as the Achilles' Heel of microkernels, is still the major factor for the overall (poor) OS performance. Besides, IPC also plays a vital role in monolithic kernels like Android Linux, as mobile applications frequently communicate with plenty of user-level services through IPC. Previous software optimizations of IPC usually cannot bypass the kernel which is responsible for domain switching and message copying/remapping; hardware solutions like tagged memory or capability replace page tables for isolation, but usually require non-trivial modification to existing software stack to adapt the new hardware primitives. In this paper, we propose a hardware-assisted OS primitive, XPC (Cross Process Call), for fast and secure synchronous IPC. XPC enables direct switch between IPC caller and callee without trapping into the kernel, and supports message passing across multiple processes through the invocation chain without copying. The primitive is compatible with the traditional address space based isolation mechanism and can be easily integrated into existing microkernels and monolithic kernels. We have implemented a prototype of XPC based on a Rocket RISC-V core with FPGA boards and ported two microkernel implementations, seL4 and Zircon, and one monolithic kernel implementation, Android Binder, for evaluation. We also implement XPC on GEM5 simulator to validate the generality. The result shows that XPC can reduce IPC call latency from 664 to 21 cycles, up to 54.2× improvement on Android Binder, and improve the performance of real-world applications on microkernels by 1.6× on Sqlite3 and 10× on an HTTP server with minimal hardware resource cost.},
  keywords={},
  doi={},
  ISSN={2575-713X},
  month={June},}
@INPROCEEDINGS{8996300,
  author={Zhang, Wenyu and Lu, Yanfeng and Li, Yi and Qiao, Hong},
  booktitle={2019 Chinese Automation Congress (CAC)}, 
  title={Convolutional Neural Networks on Apache Storm}, 
  year={2019},
  volume={},
  number={},
  pages={2399-2404},
  abstract={the performance of deep learning largely depends on the size of data. One data source is real-time streaming data, produced from mobile devices, sensors or social media, etc. Streaming data is high-speed and large-scale, which needs real-time processing. However, current mainstream frameworks are mainly designed for off-line data. To suit this, we first propose a deep learning framework based on Apache Storm, which is a distributed stream processing frame, fast and fault-tolerant. Our framework implements the distributed training of CNNs. which is different from MMLSpark or TensorFlowOnSpark that is a pure Java implementation. The design of message passing and synchronization is also suitable to other MapReduce-family distributed computing platforms. To validate our work, MNIST and Cifar -10 datasets are used for evaluation and comparison with similar architectures. The results show our framework, in resource-limited environment, realizes about 10 times speedup.},
  keywords={},
  doi={10.1109/CAC48633.2019.8996300},
  ISSN={2688-0938},
  month={Nov},}
@INPROCEEDINGS{9008822,
  author={Zhou, Yang and While, Zachary and Kalogerakis, Evangelos},
  booktitle={2019 IEEE/CVF International Conference on Computer Vision (ICCV)}, 
  title={SceneGraphNet: Neural Message Passing for 3D Indoor Scene Augmentation}, 
  year={2019},
  volume={},
  number={},
  pages={7383-7391},
  abstract={In this paper we propose a neural message passing approach to augment an input 3D indoor scene with new objects matching their surroundings. Given an input, potentially incomplete, 3D scene and a query location, our method predicts a probability distribution over object types that fit well in that location. Our distribution is predicted though passing learned messages in a dense graph whose nodes represent objects in the input scene and edges represent spatial and structural relationships. By weighting messages through an attention mechanism, our method learns to focus on the most relevant surrounding scene context to predict new scene objects. We found that our method significantly outperforms state-of-the-art approaches in terms of correctly predicting objects missing in a scene based on our experiments in the SUNCG dataset. We also demonstrate other applications of our method, including context-based 3D object recognition and iterative scene generation.},
  keywords={},
  doi={10.1109/ICCV.2019.00748},
  ISSN={2380-7504},
  month={Oct},}
@INPROCEEDINGS{9012183,
  author={Li, Yue-Xin and Zhan, Zhi-Hui and Jin, Hu and Zhang, Jun},
  booktitle={2019 Tenth International Conference on Intelligent Control and Information Processing (ICICIP)}, 
  title={Cloudde-based Distributed Differential Evolution for Solving Dynamic Optimization Problems}, 
  year={2019},
  volume={},
  number={},
  pages={94-99},
  abstract={Although evolutionary algorithms (EAs) have been widely applied in static optimization problems (SOPs), it is still a great challenge for EAs to solve dynamic optimization problems (DOPs). This paper proposes a Cloudde-based differential evolution (CDDE) algorithm based on Message Passing Interface (MPI) technology to solve DOPs. During the evolutionary process, different populations are sent to different slave processes to perform mutation and crossover operations independently using different evolution strategies and then return to the master process to apply migration operation under an adaptive probability. Experimental studies were taken on several DOPs generated by the Generalized Dynamic Benchmark Generator (GDBG) which was used in 2009 IEEE Congress on Evolutionary Computation (CEC2009). The simulation result indicates that the proposed algorithm achieves promising performance in a statistical efficient manner.},
  keywords={},
  doi={10.1109/ICICIP47338.2019.9012183},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{9029019,
  author={Joseph, Francis C and Gurrala, Gurunath},
  booktitle={2019 20th International Conference on Parallel and Distributed Computing, Applications and Technologies (PDCAT)}, 
  title={Scalability of Parareal for Large Power Grid Simulations}, 
  year={2019},
  volume={},
  number={},
  pages={295-300},
  abstract={The Parareal in time algorithm belongs to a class of temporal decomposition for a time parallel solution of differential equations. This paper investigates the approaches through which the Parareal algorithm can be deployed under a Message Passing Interface (MPI) environment. A state space model of a 10 state cascaded π network model of a transmission line, representing the computational load and nature of ordinary differential equations (ODE) in an electrical power grid/system, is used for experimentation. Two types of implementation approaches, Master Worker and Distributed, are discussed and scaling tests are performed. Analytical expressions for each approach based on the idling and non-idling processor deployment are derived. Using the expressions, weak scaling is performed to show the conditional scalability of Parareal under growing state size and integration steps.},
  keywords={},
  doi={10.1109/PDCAT46702.2019.00061},
  ISSN={2640-6721},
  month={Dec},}
@INPROCEEDINGS{9047421,
  author={Lei, Yu and Zhang, Xingjun and Han, Li and Dong, Xiaoshe and Li, Jingbo},
  booktitle={2019 IEEE Intl Conf on Parallel & Distributed Processing with Applications, Big Data & Cloud Computing, Sustainable Computing & Communications, Social Computing & Networking (ISPA/BDCloud/SocialCom/SustainCom)}, 
  title={MIC-THPCM: MIC-Based Heterogeneous Parallel Optimization for Axial Compressor Rotor}, 
  year={2019},
  volume={},
  number={},
  pages={646-653},
  abstract={The computational scale of many computational fluid dynamics (CFD) numerical simulations is very large, such as fluid mechanics numerical simulation. The continuous development of high performance computers and parallel programming models provides a new way for CFD numerical simulation. How to adjust large CFD applications to adapt to heterogeneous system architecture and make full use of computing resources is still an urgent problem to be solved. This paper proposes a MIC-THPCM (MIC-based Three-layers Heterogeneous Parallel Computing Model) model for the application characteristics of the axial compressor rotor and the structural characteristics of the CPU + MIC (Intel Many Integrated Core Architecture) heterogeneous system. The MIC-THPCM model is realized by using the MPI (Message Passing Interface) + OpenMP (Open Multi-Processing) + Offload three-layer programming model. By analyzing data dependencies and parallel features of hotspots, the hotspots are parallelized from the aspects of multi-threading, vectorization, data transmission, and memory access based on MIC hardware features. The experimental results show that the MIC-THPCM achieves better system performance under the premise of ensuring the correctness of fluid mechanical simulation. Compared with CPU multi-threaded calculation, the MIC-THPCM has a 33.9% improvement in single-channel performance. The speedup of the hotspot optimized on the MIC can be up to 24. The results show that the parallel optimization of coprocessor computationally intensive tasks has a huge benefit for the overall performance improvement of the program.},
  keywords={},
  doi={10.1109/ISPA-BDCloud-SustainCom-SocialCom48970.2019.00098},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{9060245,
  author={Endeley, Ranti and Fleming, Tom and Jin, Nanlin and Fehringer, Gerhard and Cammish, Steve},
  booktitle={2019 IEEE SmartWorld, Ubiquitous Intelligence & Computing, Advanced & Trusted Computing, Scalable Computing & Communications, Cloud & Big Data Computing, Internet of People and Smart City Innovation (SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI)}, 
  title={A Smart Gateway Enabling OPC UA and DDS Interoperability}, 
  year={2019},
  volume={},
  number={},
  pages={88-93},
  abstract={Interoperability is one of the major challenges of adoption of the Industrial Internet of Things. OPC UA is one of the main industrial standards for the Request-reply messaging pattern, and DDS is one of the main industrial standards for the Publish-subscribe messaging pattern. How to ensure data is communicated, understandable, and interoperable between the systems implemented by OPC UA and DDS is an industrial concern to address. This study proposes a novel middleware solution which enables effective communication between these two message patterns. We evaluate our work by testing the middleware's performance on a scenario using a Raspberry Pi and the software middleware connected to a private LAN, measuring response times and reliability.},
  keywords={},
  doi={10.1109/SmartWorld-UIC-ATC-SCALCOM-IOP-SCI.2019.00058},
  ISSN={},
  month={Aug},}
@INPROCEEDINGS{9062701,
  author={Pei, Yu and Bosilca, George and Yamazaki, Ichitaro and Ida, Akihiro and Dongarra, Jack},
  booktitle={2019 IEEE/ACM Parallel Applications Workshop, Alternatives To MPI (PAW-ATM)}, 
  title={Evaluation of Programming Models to Address Load Imbalance on Distributed Multi-Core CPUs: A Case Study with Block Low-Rank Factorization}, 
  year={2019},
  volume={},
  number={},
  pages={25-36},
  abstract={To minimize data movement, many parallel ap- plications statically distribute computational tasks among the processes. However, modern simulations often encounters ir- regular computational tasks whose computational loads change dynamically at runtime or are data dependent. As a result, load imbalance among the processes at each step of simulation is a natural situation that must be dealt with at the programming level. The de facto parallel programming approach, flat MPI (one process per core), is hardly suitable to manage the lack of balance, imposing significant idle time on the simulation as processes have to wait for the slowest process at each step of simulation. One critical application for many domains is the LU factor- ization of a large dense matrix stored in the Block Low-Rank (BLR) format. Using the low-rank format can significantly reduce the cost of factorization in many scientific applications, including the boundary element analysis of electrostatic field. However, the partitioning of the matrix based on underlying geometry leads to different sizes of the matrix blocks whose numerical ranks change at each step of factorization, leading to the load imbalance among the processes at each step of factorization. We use BLR LU factorization as a test case to study the programmability and performance of five different programming approaches: (1) flat MPI, (2) Adaptive MPI (Charm++), (3) MPI + OpenMP, (4) parameterized task graph (PTG), and (5) dynamic task discovery (DTD). The last two versions use a task-based paradigm to express the algorithm; we rely on the PaRSEC run- time system to execute the tasks. We first point out programming features needed to efficiently solve this category of problems, hinting at possible alternatives to the MPI+X programming paradigm. We then evaluate the programmability of the different approaches, detailing our experience implementing the algorithm using each of the models. Finally, we show the performance result on the Intel Haswell-based Bridges system at the Pittsburgh Supercomputing Center (PSC) and analyze the effectiveness of the implementations to address the load imbalance.},
  keywords={},
  doi={10.1109/PAW-ATM49560.2019.00008},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{9065100,
  author={Rudraraju, Srinivasa Raju and Suryadevara, Nagender Kumar and Negi, Atul},
  booktitle={2019 IEEE International Conference on Signal Processing, Information, Communication & Systems (SPICSCON)}, 
  title={Face Recognition in the Fog Cluster Computing}, 
  year={2019},
  volume={},
  number={},
  pages={45-48},
  abstract={This work proposes a cluster computing based facial recognition system in a fog computing environment under Internet of Things theme. The proposed system uses Haar Cascades to detect faces in a test image and uses Local Binary Pattern Histogram algorithm to recognize them in parallel by making use of computing power of several Raspberry Pi nodes in the cluster. The cluster uses Simple Linux Utility for Resource Management scheduler to schedule various jobs among the nodes and Message Passing Interface to facilitate communication among various processes running in the cluster. The system uses aggregated computation of the cluster. The facial recognition tasks were executed parallelly for obtaining better performance in terms of execution time. The proposed system can be extended to detect and recognize multiple objects in an image, which has several benefits in other applications.},
  keywords={},
  doi={10.1109/SPICSCON48833.2019.9065100},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{9068158,
  author={Khaled, H.},
  booktitle={2019 14th International Conference on Computer Engineering and Systems (ICCES)}, 
  title={Enhancing Recursive Brute Force Algorithm with Static Memory Allocation: Solving Motif Finding Problem as a Case Study}, 
  year={2019},
  volume={},
  number={},
  pages={66-70},
  abstract={Parallel Recursive Brute Force (PRBF) is one of the algorithms that need high memory. Memory allocation techniques play an important role and have a great effect on the performance of the PRBF. This paper proposes a modified implementation of the PRBF algorithm that uses the static memory allocation technique instead of dynamic memory allocation techniques. This is to avoid the memory management overhead and heap contention problems associated with dynamic memory allocation technique. This paper uses the Motif Finding Problem (MFP), one of the well-known computationally intensive problems in the field of bioinformatics, as a case study. The exponential memory requirements based on the problem size of the MFP make it very challenging to use static memory allocation. Experimental results show that the use of static memory allocation has achieved a significant speedup factor when using 16 MPI rank in comparison with the same implementation using dynamic memory allocation. The proposed R-BF modification scalability is also tested by using different number of MPI nodes and distributing the search space among them, and the results proved a significant reduction in the execution time by increasing the number of working MPI nodes.},
  keywords={},
  doi={10.1109/ICCES48960.2019.9068158},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{9070304,
  author={Gopalakrishnan, Aravind and Cabral, Matias A. and Erwin, James P. and Ganapathi, Ravindra Babu},
  booktitle={2019 IEEE Symposium on High-Performance Interconnects (HOTI)}, 
  title={Improved MPI Multi-Threaded Performance using OFI Scalable Endpoints}, 
  year={2019},
  volume={},
  number={},
  pages={36-39},
  abstract={Message Passing Interface (MPI) applications are launched as a set of parallel homogeneous processes, commonly with one to one mapping between MPI processes and compute cores. With the growing complexity of MPI applications and compute node processors consisting of large numbers of cores, launching a small number of MPI processes with several lightweight threads per process is becoming popular. Task based programming models in combination with MPI also provide several benefits for the application to exploit intra node parallelism. Naïve implementation of MPI THREAD MULTIPLE can be expensive with minimal or no performance benefits. We demonstrate a high-performance end to end multi-threading solution across the MPI application and MPI runtime, with threads mapping to hardware resources. We demonstrate our solution with Open MPI using Libfabric (a.k.a. OpenFabrics Interfaces OFI) and its Intel R Omni-Path Performance Scaled Messaging 2 (PSM2) provider. Our tests with Intel MPI Benchmarks Multi Thread set (IMB-MT) show BW improvement for large message sizes when running with multiple threads. We also demonstrate up to 2.5× performance improvements with Baidu All-Reduce. Even though the experiments were run on Intel R Omni-Path Architecture fabric, the solution can be applied to other fabrics with the capability of allocating resources among multiple threads.},
  keywords={},
  doi={10.1109/HOTI.2019.00022},
  ISSN={2332-5569},
  month={Aug},}
@INPROCEEDINGS{9071424,
  author={Jamieson, Peter and Herbordt, Martin and Kinsy, Michel},
  booktitle={2019 International Conference on Computational Science and Computational Intelligence (CSCI)}, 
  title={A Case Study: Undergraduate Self-Learning in HPC Including OpenMP, MPI, OpenCL, and FPGAs}, 
  year={2019},
  volume={},
  number={},
  pages={782-787},
  abstract={High Performance Computing (HPC) continues to develop and encroach on higher-education in the computing fields. With the ubiquitous availability and growth in commercial cloud computing and the diminishing performance returns on sequential programs, many developers must be able to understand and exploit parallel computing paradigms for certain applications. Focusing on Computer Engineering undergraduates, who arguably, will be future leaders in these parallel domains, the CE2016 recommended curriculum has a number of hours dedicated for parallel and distributed computing where approximately 10 core hours are to be taught in parallel programming, other ideas are taught in and among networking and embedded systems, and an entire section on digital design (50 hours). In reality, this is not enough time to become competent in the broader HPC field, nor do we expect standard undergraduate curriculum to develop competent undergraduate into parallel programmers. However, as demand increases for HPC developers, one wonders how students will attain this knowledge. Many people learn HPC competencies in graduate work and industrial work, but what might be done early. In this paper, we look at what a developer can possibly learn in the HPC world, and what tools and understanding is needed to build and experiment with parallel implementations. Our goal is to look at aspects of HPC given the constraints of a typical laptop, and we ask what can a developer test and learn about on their system in the HPC domain. The benefits of this work is a better understanding of what tool sets students will need to understand to develop simple parallel implementations, what HPC platforms can be used for courses or personalized learning, and we provide a basic framework and code samples for people to start from.},
  keywords={},
  doi={10.1109/CSCI49370.2019.00149},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{9079987,
  author={Mikailov, Mike and Petrick, Nicholas and Azarbaijani, Yasameen and Luo, Fu-Jyh and Valleru, Lohit and Whitney, Stephen and Torosyan, Yelizaveta},
  booktitle={2019 International Conference on Advances in Computing and Communication Engineering (ICACCE)}, 
  title={Scaling and Parallelization of Big Data Analysis on HPC and Cloud Systems}, 
  year={2019},
  volume={},
  number={},
  pages={1-8},
  abstract={Big data analysis can exhibit significant scaling problems when migrated to High Performance Computing (HPC) clusters and/or cloud computing platforms if traditional software parallelization techniques such as POSIX multi-threading and Message Passing Interface (MPI) are used. This paper introduces a novel scaling technique based on a-well-known array job mechanism to enable a team of FDA researchers to validate a method for identifying evidence of possible adverse events in very large sets of patient medical records. The analysis employed the widely-used basic Statistical Analysis Software (SAS) package, and the proposed parallelization approach dramatically increased the scaling and thus the speed of job completion for this application and is applicable to any similar software written in any other programming language. The new scaling technique offers O(T) theoretical speedup in comparison to multi-threading and MPI techniques. Here T is the number of array job tasks. The basis of the new approach is the segmentation of both (a) the big data set being analyzed and (b) the large number of SAS analysis types applied to each data segment. The large number of unique pairs of data set segment and analysis type segment are then each processed by a separate computing node (core) in pseudo-parallel manner. As a result, a SAS big data analysis which required more than 10 days to complete and consumed more than a terabyte of RAM on a single multi-core computing node completed in less than an hour parallelized over a large number of nodes, none of which needed more than 50 GB of RAM. The massive increase in the number of tasks when running an analysis job with this degree of segmentation reduces the size, scope and execution time of each task. Besides the significant speed improvement, additional benefits include fine-grained checkpointing and increased flexibility of job submission.},
  keywords={},
  doi={10.1109/ICACCE46606.2019.9079987},
  ISSN={},
  month={April},}
@INPROCEEDINGS{9095030,
  author={Bin, Li and Xingmin, Wang and Jun, Shen},
  booktitle={2019 3rd International Conference on Electronic Information Technology and Computer Engineering (EITCE)}, 
  title={Reliability Evaluation Method of DDS-based Distributed System}, 
  year={2019},
  volume={},
  number={},
  pages={2028-2033},
  abstract={This paper proposes a new reliability evaluation method for effective evaluation of the reliability of DDS-based distributed system according to the characteristics of data publish/subscribe in the system. Firstly it introduces the necessity of evaluation of the reliability of DDS-based distributed system, and points out the shortcomings of reliability evaluation method of the traditional software system. Puts a new reliability evaluation method which is based on the traditional method Considered the complexity of component interaction by combining the characteristics of data publish/subscribe in the system.Finally, this paper proves the correctness of the method by comparing the verification examples.},
  keywords={},
  doi={10.1109/EITCE47263.2019.9095030},
  ISSN={},
  month={Oct},}
@INPROCEEDINGS{9124816,
  author={Fu, Yanfang and Hao, Lingling and Guo, DengDeng},
  booktitle={2019 IEEE International Conference on Unmanned Systems and Artificial Intelligence (ICUSAI)}, 
  title={Application Research of Distributed Simulation System Based on Data Distribution}, 
  year={2019},
  volume={},
  number={},
  pages={268-273},
  abstract={DDS (Data Distribution Service) is a set of API and interoperability protocol specifications developed by OMG. It adopts a datacentric publish/subscribe architecture to meet the demand of high efficiency and real-time communication, This paper designed a kind of DDS based on data distribution system and used in distributed simulation system at first through the analysis of DDS communication principle. Then, it achieved the system from the design of communication interface to the construction of distributed simulation system. And by means of Quality of Service (QoS) Strategy in DDS, the particularly modified QoS Strategy designed for distributed simulation system is proposed. Finally, through the analysis on effect of disturbance (system average transmission delay, jittering and the amount of packet loss) on real-time and reliability requirements of system, the test results indicates that The distributed simulation system based on DDS can meet the real-time and reliability of general distributed systems.},
  keywords={},
  doi={10.1109/ICUSAI47366.2019.9124816},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{9188089,
  author={Gómez, Óscar and López-Espín, Jose J. and Peñalver, Antonio},
  booktitle={2019 International Conference on High Performance Computing & Simulation (HPCS)}, 
  title={Parallel algorithm for prediction of variables in Simultaneous Equation Models}, 
  year={2019},
  volume={},
  number={},
  pages={1032-1035},
  abstract={Simultaneous equation models (SEM) are multivariate techniques that reflect the presence of jointly endogenous variables. Traditionally, these models have been used in economy, expanding in last decades into other disciplines. One of usefulness of the SEM is the future estimation of the endogenous variables once the coefficient of the model has been obtained. This estimation is made using the actual information of endogenous and exogenous variables, as well as the matrices of the model. This work studies a parallel algorithm for the future prediction of the endogenous variables of an SEM model. Experimental tests comparing shared memory and message passing algorithms are made when varying the problem size, in order to check the behaviour of the algorithm and the ideal resources to use.},
  keywords={},
  doi={10.1109/HPCS48598.2019.9188089},
  ISSN={},
  month={July},}
@INPROCEEDINGS{9188147,
  author={Mietzsch, Nicco and Fuerlinger, Karl},
  booktitle={2019 International Conference on High Performance Computing & Simulation (HPCS)}, 
  title={Investigating Performance and Potential of the Parallel STL Using NAS Parallel Benchmark Kernels}, 
  year={2019},
  volume={},
  number={},
  pages={136-144},
  abstract={In recent years, multicore shared memory architectures have become more and more powerful. To effectively use such machines, many frameworks are available, including OpenMP and Intel threading building blocks (TBB). Since the 2017 version of its standard, C++ provides parallel algorithmic building blocks in the form of the Parallel Standard Template Library (pSTL). Unfortunately, compiler and runtime support for these new features improves slowly and few studies on the performance and potential of the pSTL are available.Our goal in this work is to evaluate the applicability of the Parallel STL in the context of scientific and technical parallel computing. To this end, we assess the performance of the pSTL using the NAS Parallel Benchmarks (NPB). Our study shows that, while there are algorithms which are difficult to implement using the pSTL, most kernels can easily be transformed into a pSTL version, with their performance approximately on par with other parallelization approaches.},
  keywords={},
  doi={10.1109/HPCS48598.2019.9188147},
  ISSN={},
  month={July},}
@INPROCEEDINGS{9188088,
  author={Hoppe, Nils and Adami, Stefan and Adams, Nikolaus A. and Pasichnyk, Igor and Allalen, Momme},
  booktitle={2019 International Conference on High Performance Computing & Simulation (HPCS)}, 
  title={Node-Level optimization of a 3D Block-Based Multiresolution Compressible Flow Solver with Emphasis on Performance Portability}, 
  year={2019},
  volume={},
  number={},
  pages={732-740},
  abstract={Despite the enormous increase in computational power in the last decades, the numerical study of complex flows remains challenging. State-of-the-art techniques to simulate hyperbolic flows with discontinuities rely on computationally demanding nonlinear schemes, such as Riemann solvers with weighted essentially non-oscillatory (WENO) stencils and characteristic decompositioning. To handle this complexity the numerical load can be reduced via a multiresolution (MR) algorithm with local time stepping (LTS) running on modern high-performance computing (HPC) systems. Eventually, the main challenge lies in an efficient utilization of the available HPC hardware. In this work, we evaluate the performance improvement for a Message Passing Interface (MPI)-parallelized MR solver using single instruction multiple data (SIMD) optimizations. We present straight-forward code modifications that allow for auto-vectorization by the compiler, while maintaining the modularity of the code at comparable performance. We demonstrate performance improvements for representative Euler flow examples on both Intel Haswell and Intel Knights Landing Xeon Phi microarchitecture (KNL) clusters. The tests show single-core speedups of 1.7 (1.9) and average speedups of 1.4 (1.6) for the Haswell (KNL).},
  keywords={},
  doi={10.1109/HPCS48598.2019.9188088},
  ISSN={},
  month={July},}
@INPROCEEDINGS{9188103,
  author={Ruiz, Daniel and Spiga, Filippo and Casas, Marc and Garcia-Gasulla, Marta and Mantovani, Filippo},
  booktitle={2019 International Conference on High Performance Computing & Simulation (HPCS)}, 
  title={Open-Source Shared Memory implementation of the HPCG benchmark: analysis, improvements and evaluation on Cavium ThunderX2}, 
  year={2019},
  volume={},
  number={},
  pages={225-232},
  abstract={The High Performance Conjugate Gradient (HPCG) benchmark complements the LINPACK benchmark in the performance evaluation coverage of large High Performance Computing (HPC) systems. Due to its lower arithmetic intensity and higher memory pressure, HPCG is recognized as a more representative benchmark for data-center and irregular memory access pattern workloads, therefore its popularity has been steadily raising within the HPC community. As only a small fraction of the reference version of the HPCG benchmark is parallelized with shared memory techniques (OpenMP), in this paper we introduce and evaluate in-depth two OpenMP parallelization strategies for the Gauss-Seidel preconditioner. Due to the increasing attractiveness of Arm architecture and Arm ecosystem in HPC, we evaluate our modified HPCG version on a state-of-the-art HPC system based on Cavium ThunderX2 SoC. We consider our work as a broader contribution not exclusively to the Arm: along with this paper, the source code of the modified HPCG has been made publicly available on GitLab to enable further optimizations at benefit of all HPC community.},
  keywords={},
  doi={10.1109/HPCS48598.2019.9188103},
  ISSN={},
  month={July},}
@INPROCEEDINGS{9188183,
  author={Giorgi, Roberto and Procaccini, Marco},
  booktitle={2019 International Conference on High Performance Computing & Simulation (HPCS)}, 
  title={Bridging a Data-Flow Execution Model to a Lightweight Programming Model}, 
  year={2019},
  volume={},
  number={},
  pages={165-168},
  abstract={Starting from a Data-Flow execution model called “DF-Threads”, we defined a minimalistic API to enable an efficient implementation in the hardware of the distribution of the threads across the cores of a single multi-core system and across the remote cores of a cluster. We aim at proposing this API as a simple programming model in C language that can potentially permit an easy interface between DF-Threads and generic programming models. Clusters are typically programmed with MPI, therefore we evaluated our approach against OpenMPI. If we consider the delivered GFLOPS per core, DF-Threads are also competitive in respect to CUDA. In the basic examples, that we used in this initial investigation, DF-Threads achieve better performance-per-core compared to OpenMPI and CUDA. In particular, OpenMPI has a large portion of OS-kernel activity, which is slowing down its performance.},
  keywords={},
  doi={10.1109/HPCS48598.2019.9188183},
  ISSN={},
  month={July},}
@ARTICLE{8645759,
  author={Luo, Jie and Ye, Zhihong and Liao, Cheng},
  journal={IEEE Transactions on Electromagnetic Compatibility}, 
  title={A MPI-Based Parallel FDTD-TL Method for the EMI Analysis of Transmission Lines in Cavity Excited by Ambient Wave}, 
  year={2020},
  volume={62},
  number={1},
  pages={212-217},
  abstract={At present, the existing electromagnetic interference (EMI) analysis methods for the cavity with transmission lines (TLs) often need a large number of meshes to satisfy certain accuracy, which would seriously affect the calculation time, memory, and efficiency. Therefore, this paper presents a time-domain parallel method consisting of finite-difference time-domain method, TL equations, and message passing interface library. This method has two obvious advantages: one is that it does not need to mesh the TLs, which can reduce a lot of computational memory; and the other is that it can run on multiple processors or computers to save a lot of computational time. In order to verify the accuracy and validity of this method, the intracavity transmission of multiconductor TLs and coaxial cable under ambient wave excitation is simulated numerically and compared with the traditional method. The results show that the method can be well applied for the EMI analysis of the TLs in cavity under ambient excitation.},
  keywords={},
  doi={10.1109/TEMC.2019.2896997},
  ISSN={1558-187X},
  month={Feb},}
@ARTICLE{8701489,
  author={Cherubin, Stefano and Cattaneo, Daniele and Chiari, Michele and Bello, Antonio Di and Agosta, Giovanni},
  journal={IEEE Embedded Systems Letters}, 
  title={TAFFO: Tuning Assistant for Floating to Fixed Point Optimization}, 
  year={2020},
  volume={12},
  number={1},
  pages={5-8},
  abstract={While many approximate computing methods are quite application-dependent, reducing the size of the data representation used in the computation has a more general applicability. We present a tuning assistant for floating to fixed point optimization (TAFFO), an LLVM-based framework designed to assist programmers in the precision tuning of software. We discuss the framework architecture and we provide guidelines to effectively tradeoff precision to improve the time-to-solution. We evaluate our framework on a well-known approximate computing benchmark suite, AxBench, achieving a speedup on 5 out of 6 benchmarks (up to 366%) with only a limited loss in precision (<3% for all benchmarks). Contrary to most related tools, TAFFO supports both C and C++ programs. It is provided as a plugin for LLVM, a design solution that improves significantly the maintainability of the tool and its ease of use.},
  keywords={},
  doi={10.1109/LES.2019.2913774},
  ISSN={1943-0671},
  month={March},}
@ARTICLE{8765766,
  author={Xiao, Tannan and Tong, Weilin and Wang, Jianquan},
  journal={IEEE Transactions on Power Systems}, 
  title={Study on Reducing the Parallel Overhead of the BBDF Method for Power System Transient Stability Simulations}, 
  year={2020},
  volume={35},
  number={1},
  pages={539-550},
  abstract={In the power system parallel transient stability simulation (TSS), the parallel overhead will rise significantly with the increase in concurrency, which will seriously affect the efficiency of parallel computing. However, there are relatively few studies on the parallel overhead in the power system research field at present. In this paper, the geneses of the parallel overhead are introduced from the point of view of computer technology. The composition of the parallel overhead of the bordered block diagonal form (BBDF) method and the nested BBDF (NBBDF) method of the power system parallel TSS is analyzed. The time consumption of computing tasks and the parallel overhead of the BBDF method and the NBBDF method implemented by message passing interface (MPI) and OpenMP under different thread scheduling patterns are tested in detail in the 2383wp system and two practical power systems (13 490 node and 24 886 node). On this basis, an efficient implementation of the NBBDF method based on subnet-core mapping and mixed programming of MPI and OpenMP is suggested, which can further reduce the parallel overhead and increase the speedup ratio to more than 17x with 64 cores in the 24 886-node system. At last, some rules are summarized based on the test results.},
  keywords={},
  doi={10.1109/TPWRS.2019.2929775},
  ISSN={1558-0679},
  month={Jan},}
@ARTICLE{8796433,
  author={Wang, Cheng and Li, Jun and Kong, Lingjun and Shu, Feng and Lau, Francis C. M.},
  journal={IEEE Transactions on Circuits and Systems II: Express Briefs}, 
  title={Adaptive 2-D Scheduling-Based Nonbinary Majority-Logic Decoding for NAND Flash Memory}, 
  year={2020},
  volume={67},
  number={7},
  pages={1349-1353},
  abstract={This brief presents a nonbinary adaptive 2D scheduling-based majority logic decoding (NB-ATS-MLGD) algorithm for NAND flash memory. The proposed algorithms provide considerable tradeoff between error-correcting capability and decoding complexity, and make the NB-MLGD decoding more attractive for practical purposes in the multi-level cells (MLC) NAND flash memory. The most significant feature of the proposed NB-ATS-MLGD algorithm is the 2D layered scheduling strategy, where the decoding orders of check nodes (CNs) and variable nodes (VNs) are both adaptive. By leveraging on the MLC flash memory bit error patterns, an early-correcting (EC) criterion is incorporated into the NB-ATS-MLGD algorithm. Furthermore, the simplification and parallelization of proposed algorithms make them more practical in NAND flash memory. Simulation results show that the proposed algorithms increase the lifetime of MLC flash memory up to 3000 program-and-erase (PE) cycles and have desirable convergence speed compared with the conventional non-binary MLGD algorithm. When at low PE cycles, the NB-EC-ATS-MLGD algorithm improves frame error rate (FER) performance by more than 3 order of magnitudes compared with the conventional non-binary MLGD algorithm.},
  keywords={},
  doi={10.1109/TCSII.2019.2935031},
  ISSN={1558-3791},
  month={July},}
@ARTICLE{8851267,
  author={Meidlinger, Michael and Matz, Gerald and Burg, Andreas},
  journal={IEEE Transactions on Communications}, 
  title={Design and Decoding of Irregular LDPC Codes Based on Discrete Message Passing}, 
  year={2020},
  volume={68},
  number={3},
  pages={1329-1343},
  abstract={We consider discrete message passing (MP) decoding of low-density parity check (LDPC) codes based on information-optimal symmetric look-up table (LUT). A link between discrete message labels and the associated log-likelihood ratio values (defined in terms of density evolution distributions) is established. This link gives rise to an algebraic structure on the message labels and leads to an interpretation of LUT decoding as a form of quantized belief propagation. We then exploit the algebraic structure for low-complexity LUT decoder designs. Our LUT decoding framework is the first to also apply to irregular LDPC codes by taking into account the degree distribution in a joint LUT design. We exploit the relation between LUT decoding and belief propagation to obtain stability conditions and irregular LDPC code designs optimized for LUT decoding. The resulting decoders outperform floating-point precision min-sum decoders at LUT resolutions as low as 3 bit s for regular codes and 4 bits for irregular codes.},
  keywords={},
  doi={10.1109/TCOMM.2019.2944159},
  ISSN={1558-0857},
  month={March},}
@ARTICLE{8935206,
  author={Lopez, Henry and Chan, Hsun-Wei and Chiu, Kang-Lun and Tsai, Pei-Yun and Jou, Shyh-Jye Jerry},
  journal={IEEE Transactions on Very Large Scale Integration (VLSI) Systems}, 
  title={A 75-Gb/s/mm2 and Energy-Efficient LDPC Decoder Based on a Reduced Complexity Second Minimum Approximation Min-Sum Algorithm}, 
  year={2020},
  volume={28},
  number={4},
  pages={926-939},
  abstract={This article presents a high-throughput and low-routing complexity low-density parity check (LDPC) decoder design based on a novel second minimum approximation min-sum (SAMS) algorithm. The routing congestion is mitigated by reducing the required interconnections in the critical path of the routing network. The implementation and postlayout results with 28-nm 1P9M CMOS process show that the proposed design can achieve a throughput of 10.5 Gb/s for a millimeter-wave 60-GHz baseband system while satisfying the low bit error rate (BER) requirements (10-7). The proposed design reduces the wiring in the routing network by 21% and improves the area by 12% compared to the conventional min-sum (MS) and normalized MS (NMS) algorithm. Additional hardware optimizations are obtained by considering the internal message passing resolution based on the BER and signal-to-noise ratio (SNR) requirements for a practical baseband system. The power consumption is efficiently reduced by the employment of a shared address generator that exploits the degree of parallelism to reduce the switching activity on a group of memory elements. The LDPC decoder is implemented with a core area of 0.14 mm2, power consumption of 81 mW at 312.5 MHz, and the area and power efficiency of 75 Gb/s/mm2 and 10.2 pJ/bit, respectively.},
  keywords={},
  doi={10.1109/TVLSI.2019.2955925},
  ISSN={1557-9999},
  month={April},}
@ARTICLE{8941298,
  author={Turchetto, Massimiliano and Palù, Alessandro Dal and Vacondio, Renato},
  journal={IEEE Transactions on Parallel and Distributed Systems}, 
  title={A General Design for a Scalable MPI-GPU Multi-Resolution 2D Numerical Solver}, 
  year={2020},
  volume={31},
  number={5},
  pages={1036-1047},
  abstract={This article presents a multi-GPU implementation of a Finite-Volume solver on a multi-resolution grid. The implementation completely offloads the computation to the GPUs and communications between different GPUs are implemented by means of the Message Passing Interface (MPI) API. Different domain decomposition techniques have been considered and the one based on the Hilbert Space Filling Curves (HSFC) showed optimal scalability. Several optimizations are introduced: One-to-one MPI communications among MPI ranks are completely masked by GPU computations on internal cells and a novel dynamic load balancing algorithm is introduced to minimize the waiting times at global MPI synchronization barriers. Such algorithm adapts the computational load of ranks in response to dynamical changes in the execution time of blocks and in network performances; Its capability to converge to a balanced computation has been empirically shown by numerical experiments. Tests exploit up to 64 GPUs and 83M cells and achieve an efficiency of 90 percent in weak scalability and 85 percent for strong scalability. The framework is general and the results of the article can be ported to a wide range of explicit 2D Partial Differential Equations solvers.},
  keywords={},
  doi={10.1109/TPDS.2019.2961909},
  ISSN={1558-2183},
  month={May},}
@ARTICLE{8950409,
  author={Liu, An and Lian, Lixiang and Lau, Vincent and Liu, Guanying and Zhao, Min-Jian},
  journal={IEEE Transactions on Signal Processing}, 
  title={Cloud-Assisted Cooperative Localization for Vehicle Platoons: A Turbo Approach}, 
  year={2020},
  volume={68},
  number={},
  pages={605-620},
  abstract={Due to the high resolution of angles of arrivals (AoAs) provided by the massive MIMO base station in 5 G wireless systems, it is promising to integrate 5G-based localization technology into autonomous driving to improve the accuracy and robustness of vehicle localization. In this paper, we investigate the problem of 5G cloud-assisted cooperative localization for vehicle platoons. The existing 5G-based localization algorithms focused on single-user localization and are not efficient for the localization of vehicle platoon where the positions of the vehicles are highly correlated. To the best of our knowledge, cloud-assisted cooperative localization tailored to vehicle platoons has not been studied before. To address this challenging problem, we first propose a Gamma-Markov-Group-Sparse (GMGS) model to capture the joint distribution of the vehicle positions in a vehicle platoon. Then we formulate the vehicle platoon cooperative localization as a sparse Bayesian inference (SBI) problem. The existing standard SBI algorithms such as variational Bayesian inference (VBI) and approximate message passing (AMP) cannot be applied to our platoon localization problem due to the complicated GMGS prior and the ill-conditioned measurement matrix. As such, we propose a novel turbo vehicle platoon cooperative localization (Turbo-VPCL) algorithm to fully exploit the correlations of the vehicle positions (as captured by the GMGS prior) under the ill-conditioned measurement matrix. Simulation results verify that the proposed Turbo-VPCL can achieve significant gain over the-state-of-art SBI algorithms.},
  keywords={},
  doi={10.1109/TSP.2020.2964198},
  ISSN={1941-0476},
  month={},}
@ARTICLE{8951280,
  author={Karsavuran, M. Ozan and Acer, Seher and Aykanat, Cevdet},
  journal={IEEE Transactions on Parallel and Distributed Systems}, 
  title={Reduce Operations: Send Volume Balancing While Minimizing Latency}, 
  year={2020},
  volume={31},
  number={6},
  pages={1461-1473},
  abstract={Communication hypergraph model was proposed in a two-phase setting for encapsulating multiple communication cost metrics (bandwidth and latency), which are proven to be important in parallelizing irregular applications. In the first phase, computational-task-to-processor assignment is performed with the objective of minimizing total volume while maintaining computational load balance. In the second phase, communication-task-to-processor assignment is performed with the objective of minimizing total number of messages while maintaining communication-volume balance. The reduce-communication hypergraph model suffers from failing to correctly encapsulate send-volume balancing. We propose a novel vertex weighting scheme that enables part weights to correctly encode send-volume loads of processors for send-volume balancing. The model also suffers from increasing the total communication volume during partitioning. To decrease this increase, we propose a method that utilizes the recursive bipartitioning framework and refines each bipartition by vertex swaps. For performance evaluation, we consider column-parallel SpMV, which is one of the most widely known applications in which the reduce-task assignment problem arises. Extensive experiments on 313 matrices show that, compared to the existing model, the proposed models achieve considerable improvements in all communication cost metrics. These improvements lead to an average decrease of 30 percent in parallel SpMV time on 512 processors for 70 matrices with high irregularity.},
  keywords={},
  doi={10.1109/TPDS.2020.2964536},
  ISSN={1558-2183},
  month={June},}
@ARTICLE{8959231,
  author={Hou, Junjie and Zhu, Yongxin and Du, Sen and Song, Shijin and Song, Yuefeng},
  journal={IEEE Access}, 
  title={FPGA-Based Scale-Out Prototyping of Degridding Algorithm for Accelerating Square Kilometre Array Telescope Data Processing}, 
  year={2020},
  volume={8},
  number={},
  pages={15586-15597},
  abstract={The SKA (Square Kilometre Array) radio telescope will become the most sensitive telescope by correlating a large number of antenna nodes to form a giant antenna array. The data generated from such a large number of antenna nodes will pose a huge storage problem and require real-time data processing to make the best use of data, and the SKA Scientific Data Processing becomes the bottleneck of the whole processing flow. However, the existing high-performance CPU- and GPU (Graphics Processing Unit)-based solutions cannot satisfy the performance requirements and power budget requirements well [1]. Due to the consideration of the high energy efficiency of hardware accelerators and the flexibility and cost of prototype design, in this paper, we explore the FPGA(Field Programmable Gate Array)-based prototype of one of the most computationally demanding procedures in SKA scientific data processing: degridding. Through the analysis of algorithm behavior and bottlenecks, we design and optimize the memory architecture and computing logic of an FPGA-based prototype. Besides, with the consideration of the relations between the required data of processing multiple spectral channels, we reuse the shared data in processing neighboring spectral channels, and the performance further improves. The functionality and performance of our design have been verified on the target FPGA board, and the software-based benchmarks were also measured on comparable CPU and GPU platforms, indicating that the FPGA-based prototype achieves 2.74 times and 2.03 times speedup, 7.64 times and 7.42 times energy efficiency than the MPI(Message Passing Interface)-based CPU benchmark and the CUDA (Compute Unified Device Architecture)-based GPU benchmark, respectively.},
  keywords={},
  doi={10.1109/ACCESS.2020.2966666},
  ISSN={2169-3536},
  month={},}
@ARTICLE{9028221,
  author={Zou, Qiuyun and Zhang, Haochuan and Cai, Donghong and Yang, Hongwen},
  journal={IEEE Signal Processing Letters}, 
  title={Message Passing Based Joint Channel and User Activity Estimation for Uplink Grant-Free Massive MIMO Systems With Low-Precision ADCs}, 
  year={2020},
  volume={27},
  number={},
  pages={506-510},
  abstract={This letter considers the problem of a joint estimation for channel fading and user activity in an uplink grant-free massive MIMO system equipped with low-precision analog-to-digital converters (ADCs). Different from existing works, the joint estimation is formalized as a non-overlapping group problem, where the components of compound channel involving user activity indicator and channel fading are independent with condition distribution rather than independent Bernoulli-Gaussian. Based on this new formulation, a new algorithm leveraging hybrid generalized approximate passing (HyGAMP) is then developed including GAMP part (channel estimation) and loopy belief propagation (LBP) part (user activity detection), where the strong correlation among elements in each row of the channel matrix can be decoupled in LBP part. By exchanging the information between the GAMP part and the LBP part, the proposed algorithm improves the performance of channel estimation and user activity detection as compared to earlier results. In addition, the simulation results verify that the proposed algorithm develops the performance of conventional methods dramatically.},
  keywords={},
  doi={10.1109/LSP.2020.2979534},
  ISSN={1558-2361},
  month={},}
@INPROCEEDINGS{9070370,
  author={Pulshashi, Iq Reviessay and Bae, Hyerim and Sutrisnowati, Riska Asriana},
  booktitle={2020 IEEE International Conference on Big Data and Smart Computing (BigComp)}, 
  title={Container-Based Coloured Petri-Net Co-simulation Framework}, 
  year={2020},
  volume={},
  number={},
  pages={393-395},
  abstract={Coloured Petri-net (CPN) is an extended version of Petri-net that allows tokens to carry data and the enabling and firing rules are executed based on the data. Simulation of a large and complex CPN needs heavy computational resources especially when an external subsystem is also introduced. A cosimulation is an alternative solution to deal with this problem. In this paper, we present a new approach for co-simulating CPN models based on a publisher-subscriber approach. The prototype is implemented by extending Access/CPN 2.0 on containerization technology. The approach is then validated using a case study of supply chain model.},
  keywords={},
  doi={10.1109/BigComp48618.2020.00-43},
  ISSN={2375-9356},
  month={Feb},}
@ARTICLE{9076031,
  author={Jiang, Chengxin and Wang, Yafeng},
  journal={IEEE Access}, 
  title={An Uplink SCMA Codebook Design Combining Probabilistic Shaping and Geometric Shaping}, 
  year={2020},
  volume={8},
  number={},
  pages={76726-76736},
  abstract={Sparse Code Multiple Access (SCMA) is a promising non-orthogonal multiple access scheme owning to the shaping gain of its multi-dimensional codebook. Most of the existing designs of the codebook are based on geometric shaping (GS), while probabilistic shaping (PS) has important advantages in increasing channel capacity and reducing bit error rate. In this paper, an uplink SCMA codebook optimization algorithm which combines PS and GS is proposed. The algorithm adopts the bare bones particle swarm optimization algorithm based on maximizing the AMI. Based on the non-equiprobable codebook, a message passing algorithm with non-equalprobable distribution is introduced as the multiuser detection algorithm for SCMA scheme. We theoretically analyze the superiority of the codebooks combining PS and GS over others in terms of the average mutual information (AMI). Simulation results show that our proposed codebooks outperform the reference GS based codebooks under different overloading, different channels and different codebook sizes, and with the increase of overloading or codebook sizes, the gains are greater, which is up to 2.1dB gain in terms of block error rate performance. This observation also validates the theoretical analysis based on the AMI.},
  keywords={},
  doi={10.1109/ACCESS.2020.2989448},
  ISSN={2169-3536},
  month={},}
@ARTICLE{9078353,
  author={Wang, Xiaoyue and Chen, Qi and Li, Mingzhi},
  journal={IEEE Transactions on Electron Devices}, 
  title={Multiple-GPU-Based Simulation of Ka-Band Helix Traveling Wave Tube}, 
  year={2020},
  volume={67},
  number={6},
  pages={2585-2592},
  abstract={The finite-difference time-domain (FDTD) algorithm and the particle-in-cell (PIC) method-based simulation are classic approaches to design and optimize the helix traveling wave tubes (TWTs). In this article, a multiple-graphics processing unit (GPU)-based 3-D-FDTD-PIC parallel program is developed to complete the full-wave simulation of a Ka-band helix TWT in the time domain. The specific parallel simulation scheme is given. The code based on compute unified device architecture (CUDA) and message passing interface (MPI) can run on a scalable heterogeneous cluster consisting of multiple CPUs and GPUs, substantially improving the simulation speed and shortening the development period of TWTs. In this article, the specific parameters of the experimental TWT are given. The simulation results are found basically consistent with the measured values and theoretical analysis, verifying the correctness of this code. Moreover, this program can realistically restore the physical processes occurring in the tube in a short period of time, which means it can be applied as an efficient simulation tool for further research of TWTs or even other microwave power devices based on beam-wave interaction.},
  keywords={},
  doi={10.1109/TED.2020.2986931},
  ISSN={1557-9646},
  month={June},}
@ARTICLE{9087908,
  author={Saad, Abdallah and El-Mahdy, Ahmed},
  journal={IEEE Access}, 
  title={HPCCloud Seer: A Performance Model Based Predictor for Parallel Applications on the Cloud}, 
  year={2020},
  volume={8},
  number={},
  pages={87978-87993},
  abstract={With the continual increase in the high performance computing (HPC) market share, the need for a cheaper and widely available system rather than the expensive typical HPC systems increases. A promising alternative to HPC typical systems is the cloud computing environment which is characterised by being cheap, flexible, scalable and available. However, the cloud is based on virtualization which increases the latency to access the processing and network resources due to resource sharing. This makes the cloud an unpredictable environment to long run time programs such as HPC applications. Hence, modelling and understanding performance is essential for exploiting such environment. In this paper we propose a predictor for the execution time of the message passing interface (MPI) based applications on the cloud, as they are a major class of HPC applications. The predictor is based on an analytical performance model through considering the cloud resources as a queueing network, and the parallel applications as jobs contesting for the shared resources. The prediction based on the proposed model is measured on both a cluster of bare-metal servers and on a group of virtual machines. The overall accuracy of this prediction is 88% for 10 benchmarks, 5 from SPEC-MPI and 5 from NASA parallel benchmarks.},
  keywords={},
  doi={10.1109/ACCESS.2020.2992880},
  ISSN={2169-3536},
  month={},}
@ARTICLE{9091527,
  author={Alghamdi, Abdullah S. Almalaise and Alghamdi, Ahmed Mohammed and Eassa, Fathy Elbouraey and Khemakhem, Maher Ali},
  journal={IEEE Access}, 
  title={ACC_TEST: Hybrid Testing Techniques for MPI-Based Programs}, 
  year={2020},
  volume={8},
  number={},
  pages={91488-91500},
  abstract={Recently, MPI has become widely used in many scientific applications, including different non-computer science fields, for parallelizing their applications. An MPI programming model is used for supporting parallelism in several programming languages, including C, C++, and Fortran. MPI also supports integration with some programming models and has several implementations from different vendors, including open-source and commercial implementations. However, testing parallel programs is a difficult task, especially when using programming models with different behaviours and types of error based on the programming model type. In addition, the increased use of these programming models by non-computer science specialists can cause several errors due to lack of experience in programming, which needs to be considered when using any testing tools. We noticed that dynamic testing techniques have been used for testing the majority of MPI programs. The dynamic testing techniques detect errors by analyzing the source code during runtime, which will cause overheads, and this will affect the program’s performance, especially when targeting massive parallel applications generating thousands or millions of threads. In this paper, we enhance ACC_TEST to have the ability to test MPI-based programs and detect runtime errors occurring with different types of MPI communications. We decided to use hybrid-testing techniques by combining both static and dynamic testing techniques to gain the benefit of each and reduce the cost.},
  keywords={},
  doi={10.1109/ACCESS.2020.2994172},
  ISSN={2169-3536},
  month={},}
@INPROCEEDINGS{9092361,
  author={Sommer, Lukas and Stock, Florian and Solis-Vasquez, Leonardo and Koch, Andreas},
  booktitle={2020 28th Euromicro International Conference on Parallel, Distributed and Network-Based Processing (PDP)}, 
  title={Using Parallel Programming Models for Automotive Workloads on Heterogeneous Systems - a Case Study}, 
  year={2020},
  volume={},
  number={},
  pages={17-21},
  abstract={Due to the ever-increasing computational demand of automotive applications, and in particular autonomous driving functionalities, the automotive industry and supply vendors are starting to adopt parallel and heterogeneous embedded platforms for their products.However, C and C++, the currently dominating programming languages in this industry, do not provide sufficient mechanisms to target such platforms. Established parallel programming models such as OpenMP and OpenCL on the other hand are tailored towards HPC systems.In this case study, we investigate the applicability of established parallel programming models to automotive workloads on heterogeneous platforms. We pursue a practical approach by re-enacting a typical development process for typical embedded platforms and representative benchmarks.},
  keywords={},
  doi={10.1109/PDP50117.2020.00010},
  ISSN={2377-5750},
  month={March},}
@INPROCEEDINGS{9092407,
  author={Oden, Lena},
  booktitle={2020 28th Euromicro International Conference on Parallel, Distributed and Network-Based Processing (PDP)}, 
  title={Lessons learned from comparing C-CUDA and Python-Numba for GPU-Computing}, 
  year={2020},
  volume={},
  number={},
  pages={216-223},
  abstract={Python as programming language is increasingly gaining importance, especially in data science, scientific, and parallel programming. It is faster and easier to learn than classical programming languages such as C. However, usability often comes at the cost of performance and applications written in Python are considered to be much slower than applications written in C or FORTRAN. Further, it does not allow the usage of GPUs-besides of pre-compiled libraries.However, the Numba package promises performance similar to C code for compute intensive parts of a Python application and it supports CUDA, which allows the use of GPUs inside a Python application.In this paper we compare the performance of Numba-CUDA and C -CUDA for different kinds of applications. For compute intensive benchmarks, the performance of the Numba version only reaches between 50% and 85% performance of the CCUDA version, despite the reduction operation, where the Numba version outperforms CUDA. Analyzing the PTX code and CUDA performance counters revealed that index-calculation is one limiting factor in Numba. Another problem is the type interference for single precision computations, as some values are computed in double precision. By optimizing this within the Numba package, the performance of Numba improves. However, C-CUDA applications still outperform the Numba versions. Further analysis with the CloverLeav Mini App shows that Numba performance further decreases for applications with multiple different compute kernels. The non-GPU part slows down these applications, due to the slow Python interpreter. This leads to a worse GPU utilization.Today Python is widely used in industry and academia and has been the first choice of coding languages among software programmers in the last years. Currently, according to the TIOBE index [5], it is the 3rd most popular programming language and the number one in IEEE Spectrum's fifth annual interactive ranking of the top programming languages [4]. One reason for this is that is easier to learn than classical programming languages like C. However, the other reason is the increasing popularity of Data Science, where Python is the most used language. A collection of libraries such as NumPy [22], and Matplotlib [1] or Scipy [8] provide a rich set of functions for scientific computing [16]. Packages like Dask [19], PyCompss [21] and MPI for Python [6] allow running Python applications on large, parallel machines, promising high performance. However, the performance of Python is considered slow compared to compiled languages such as C, C++, and FORTRAN, especially for heavy computations. In recent years, more and more tools have been developed to counter this prejudice. Numpy [22], for example, uses C-like arrays to store data and offers fast functions implemented in C to speed up calculations. The CuPy [14] package provides a similar set of functions, but these functions are implemented for GPUs using CUDA. The SciPy library is based on NumPy and provides a rich set on functionalities for scientific computing. Still, the high performance of these libraries is provided by the underling C-implementations. Internally, they use libraries like OpenBlas or IntelMKL to reach high performance and therefore, they are limited by the functions which are provided by theses libraries. Therefore, a performance problem always arises when the required functionality is not implemented within these libraries. In this case, the application falls back to the Python interpreter. Compared to "bare metal" code, interpreted code is slow. In addition, in Python it is not possible to use GPUs or other accelerators directly, as the Python interpreter cannot execute code on these machines. Therefore, the usage is only possible with precompiled libraries. To overcome this limitation, different approaches where developed to mix C, CUDA or OpenCL with Python. Cython [2] allows integrating C-code in Python applications to improve performance of critical sections. It also allows an easy development of wrappers for C-libraries. Similar, packages such as PyCuda and PyOpenCL [9] support wrappers for CUDA or OpenCL code within a Python script. Both approaches require the mixture of different programming languages.Numba [10] follows a different approach. Instead of merging C/CUDA code with Python, it allows the development of efficient applications for both, CPUs and GPUs in Python style. When a Python script using Numba is executed, marked functions are compiled just-in-time (JIT) using the LLVM framework. Using Python for GPU programming can mean a considerable simplification in the development of parallel applications.But often a simplification of comes at the expense of performance, and one expects a performance loss from Python compared to pure C code. In this paper, we want to understand the differences between native C-CUDA code and CUDA-code written in Python with Numba. We also want to share some basic tips how to improve the performance of applications written in Numba.We will first analyse a few micro benchmarks in detail. We are using these simple benchmarks, as it is easier to understand the differences with small code examples. We will use the collected information to derive some optimization for Numba. Finally, we evaluate and compare the performance of a more application like mini-app, written in C-CUDA and Numba accelerated Python. We will evaluate if our insights from the microbenchmarks to real applications.},
  keywords={},
  doi={10.1109/PDP50117.2020.00041},
  ISSN={2377-5750},
  month={March},}
@INPROCEEDINGS{9092341,
  author={Araujo, Gabriell Alves de and Griebler, Dalvan and Danelutto, Marco and Fernandes, Luiz Gustavo},
  booktitle={2020 28th Euromicro International Conference on Parallel, Distributed and Network-Based Processing (PDP)}, 
  title={Efficient NAS Parallel Benchmark Kernels with CUDA}, 
  year={2020},
  volume={},
  number={},
  pages={9-16},
  abstract={NAS Parallel Benchmarks (NPB) are one of the standard benchmark suites used to evaluate parallel hardware and software. There are many research efforts trying to provide different parallel versions apart from the original OpenMP and MPI. Concerning GPU accelerators, there are only the OpenCL and OpenACC available as consolidated versions. Our goal is to provide an efficient parallel implementation of the five NPB kernels with CUDA. Our contribution covers different aspects. First, best parallel programming practices were followed to implement NPB kernels using CUDA. Second, the support of larger workloads (class B and C) allow to stress and investigate the memory of robust GPUs. Third, we show that it is possible to make NPB efficient and suitable for GPUs although the benchmarks were designed for CPUs in the past. We succeed in achieving double performance with respect to the state-of-the-art in some cases as well as implementing efficient memory usage. Fourth, we discuss new experiments comparing performance and memory usage against OpenACC and OpenCL state-of-the-art versions using a relative new GPU architecture. The experimental results also revealed that our version is the best one for all the NPB kernels compared to OpenACC and OpenCL. The greatest differences were observed for the FT and EP kernels.},
  keywords={},
  doi={10.1109/PDP50117.2020.00009},
  ISSN={2377-5750},
  month={March},}
@ARTICLE{9095258,
  author={Dang, Huynh Tu and Bressana, Pietro and Wang, Han and Lee, Ki Suh and Zilberman, Noa and Weatherspoon, Hakim and Canini, Marco and Pedone, Fernando and Soulé, Robert},
  journal={IEEE/ACM Transactions on Networking}, 
  title={P4xos: Consensus as a Network Service}, 
  year={2020},
  volume={28},
  number={4},
  pages={1726-1738},
  abstract={In this paper, we explore how a programmable forwarding plane offered by a new breed of network switches might naturally accelerate consensus protocols, specifically focusing on Paxos. The performance of consensus protocols has long been a concern. By implementing Paxos in the forwarding plane, we are able to significantly increase throughput and reduce latency. Our P4-based implementation running on an ASIC in isolation can process over 2.5 billion consensus messages per second, a four orders of magnitude improvement in throughput over a widely-used software implementation. This effectively removes consensus as a bottleneck for distributed applications in data centers. Beyond sheer performance, our approach offers several other important benefits: it readily lends itself to formal verification; it does not rely on any additional network hardware; and as a full Paxos implementation, it makes only very weak assumptions about the network.},
  keywords={},
  doi={10.1109/TNET.2020.2992106},
  ISSN={1558-2566},
  month={Aug},}
@ARTICLE{9094650,
  author={Tachibana, Junta and Ohtsuki, Tomoaki},
  journal={IEEE Access}, 
  title={Learning and Analysis of Damping Factor in Massive MIMO Detection Using BP Algorithm With Node Selection}, 
  year={2020},
  volume={8},
  number={},
  pages={96859-96866},
  abstract={In a massive multiple-input multiple-output (MIMO) system, belief propagation (BP) detection is known as a method to separate and detect received signals. In BP detection, a MIMO channel is represented by a factor graph and the transmitted symbols are estimated by message passing. However, the convergence property of BP deteriorates due to multiple loops included in the MIMO channel. As a method to improve the convergence property and the detection performance, the damped BP that averages two successive messages with a weighing factor (called damping factor) is known. To train the damping factors off-line for each antenna configuration, deep neural network-based damped BP (DNN-dBP) has been reported. The problem with DNN-dBP is that the detection performance deteriorates when there is a difference of the channel correlation between training and test. This is because the optimal damping factors vary with the channel correlation. In this paper, to solve this issue, we derive the damping factors of BP with the node selection (NS) method that selects nodes to be updated to lower spatial correlation using DNN-dBP. By applying the NS method, the channel correlation among the selected nodes in BP detection is lowered. Therefore, the proposed method can improve the detection performance deterioration due to the mismatches of the channel correlations between training and test in DNN-dBP. In addition, the convergence property of BP is improved by applying the NS method. Therefore, the proposed method has the same detection performance with low computational complexity as the conventional DNN-dBP. By computer simulation, it is shown that the proposed method significantly improves the bit error rate (BER) performance deterioration due to the mismatches of the channel correlations between training and test in DNN-dBP. The results also show that the proposed method can show the same BER performance with low computational complexity as the conventional DNN-dBP. We also investigate the distribution of the trained damping factors and evaluate the tendency of that.},
  keywords={},
  doi={10.1109/ACCESS.2020.2995171},
  ISSN={2169-3536},
  month={},}
@ARTICLE{9109637,
  author={Cesarini, Daniele and Bartolini, Andrea and Borghesi, Andrea and Cavazzoni, Carlo and Luisier, Mathieu and Benini, Luca},
  journal={IEEE Transactions on Parallel and Distributed Systems}, 
  title={Countdown Slack: A Run-Time Library to Reduce Energy Footprint in Large-Scale MPI Applications}, 
  year={2020},
  volume={31},
  number={11},
  pages={2696-2709},
  abstract={The power consumption of supercomputers is a major challenge for system owners, users, and society. It limits the capacity of system installations, it requires large cooling infrastructures, and it is the cause of a large carbon footprint. Reducing power during application execution without changing the application source code or increasing time-to-completion is highly desirable in real-life high-performance computing scenarios. The power management run-time frameworks proposed in the last decade are based on the assumption that the duration of communication and application phases in an MPI application can be predicted and used at run-time to trade-off communication slack with power consumption. In this article, we first show that this assumption is too general and leads to mispredictions, slowing down applications, thereby jeopardizing the claimed benefits. We then propose a new approach based on (i) the separation of communication phases and slack during MPI calls and (ii) a timeout algorithm to cope with the hardware power management latency, which jointly makes it possible to achieve performance-neutral power saving in MPI applications without requiring labor-intensive and risky application source code modifications. We validate our approach in a tier-1 production environment with widely adopted scientific applications. Our approach has a time-to-completion overhead lower than 1 percent, while it successfully exploits slack in communication phases to achieve an average energy saving of 10 percent. If we focus on a large-scale application runs, the proposed approach achieves 22 percent energy saving with an overhead of only 0.4 percent. With respect to state-of-the-art approaches, COUNTDOWN Slack is the only that always leads to an energy saving with negligible overhead (<; 3 percent).},
  keywords={},
  doi={10.1109/TPDS.2020.3000418},
  ISSN={1558-2183},
  month={Nov},}
@ARTICLE{9109678,
  author={Kang, Qiao and Lee, Sunwoo and Hou, Kaiyuan and Ross, Robert and Agrawal, Ankit and Choudhary, Alok and Liao, Wei-keng},
  journal={IEEE Transactions on Parallel and Distributed Systems}, 
  title={Improving MPI Collective I/O for High Volume Non-Contiguous Requests With Intra-Node Aggregation}, 
  year={2020},
  volume={31},
  number={11},
  pages={2682-2695},
  abstract={Two-phase I/O is a well-known strategy for implementing collective MPI-IO functions. It redistributes I/O requests among the calling processes into a form that minimizes the file access costs. As modern parallel computers continue to grow into the exascale era, the communication cost of such request redistribution can quickly overwhelm collective I/O performance. This effect has been observed from parallel jobs that run on multiple compute nodes with a high count of MPI processes on each node. To reduce the communication cost, we present a new design for collective I/O by adding an extra communication layer that performs request aggregation among processes within the same compute nodes. This approach can significantly reduce inter-node communication contention when redistributing the I/O requests. We evaluate the performance and compare it with the original two-phase I/O on Cray XC40 parallel computers (Theta and Cori) with Intel KNL and Haswell processors. Using I/O patterns from two large-scale production applications and an I/O benchmark, we show our proposed method effectively reduces the communication cost and hence maintains the scalability for a large number of processes.},
  keywords={},
  doi={10.1109/TPDS.2020.3000458},
  ISSN={1558-2183},
  month={Nov},}
@INPROCEEDINGS{9116230,
  author={Munera, Adrian and Royuela, Sara and Quiñones, Eduardo},
  booktitle={2020 Design, Automation & Test in Europe Conference & Exhibition (DATE)}, 
  title={Towards a Qualifiable OpenMP Framework for Embedded Systems}, 
  year={2020},
  volume={},
  number={},
  pages={903-908},
  abstract={OpenMP is a very convenient programming model for critical real-time parallel applications due to its powerful tasking model and its proven time predictability. However, current implementations are not suitable for critical environments based on the intensive use of dynamically allocated memory needed to efficiently manage the parallel execution. This jeopardizes the qualification processes needed to ensure that the integrated software stack is compliant with system requirements. This paper proposes a novel OpenMP framework that statically allocates the data structures needed to efficiently manage the parallel execution of OpenMP tasks. Our framework is composed of a compiler that captures the environment of the OpenMP tasks instantiated along the parallel execution and bounds the exposed parallelism, and a runtime implementing a lazy task creation policy that significantly reduces the runtime memory requirements, whilst exploiting parallelism efficiently. The evaluation shows that our tool achieves the same performance as current OpenMP implementations, while bounds and drastically reduces the dynamic memory requirements at run-time.},
  keywords={},
  doi={10.23919/DATE48585.2020.9116230},
  ISSN={1558-1101},
  month={March},}
@INPROCEEDINGS{9116313,
  author={Shen, Minghua and Xiao, Nong},
  booktitle={2020 Design, Automation & Test in Europe Conference & Exhibition (DATE)}, 
  title={Towards Serial-Equivalent Multi-Core Parallel Routing for FPGAs}, 
  year={2020},
  volume={},
  number={},
  pages={1139-1144},
  abstract={In this paper, we present a serial-equivalent parallel router for FPGAs on modern multi-core processors. We are based on the inherent net order of serial router to schedule all the nets into a series of stages, where the non-conflicting nets are scheduled in same stage and the conflicting nets are scheduled in different stages. We explore the parallel routing of non-conflicting nets on multi-core processors for a significant speedup. We perform the data synchronization of conflicting stages using MPI-based message queue for a feasible routing solution. Note that load balance is always used to guide the multi-core parallel routing. Experimental results show that our parallel router provides about 19.13× speedup on average using 32 processor cores comparing to the serial router. Notably, our parallel router generates exactly the same wirelength as the serial router satisfying serial equivalency.},
  keywords={},
  doi={10.23919/DATE48585.2020.9116313},
  ISSN={1558-1101},
  month={March},}
@ARTICLE{9123951,
  author={Cai, Peixiang and Zhang, Yu and Pan, Changyong},
  journal={IEEE Wireless Communications Letters}, 
  title={Coordination Graph-Based Deep Reinforcement Learning for Cooperative Spectrum Sensing Under Correlated Fading}, 
  year={2020},
  volume={9},
  number={10},
  pages={1778-1781},
  abstract={In this letter, cooperative spectrum sensing (CSS) under correlated fading in cognitive radio networks is modeled, and the distributed deep reinforcement learning method is adopted to learn the optimal CSS strategy. To reduce the dimension of the solution space in large networks, this letter takes advantage of the coordination graph to decompose the problem into a max-plus problem and employs the message passing to obtain the optimal strategy sequentially. The simulation results verify the superior performance of the proposed algorithm by comparison with the conventional reinforcement learning implementations.},
  keywords={},
  doi={10.1109/LWC.2020.3004687},
  ISSN={2162-2345},
  month={Oct},}
@INPROCEEDINGS{9139781,
  author={Ding, Tianchen and Qian, Shiyou and Cao, Jian and Xue, Guangtao and Li, Minglu},
  booktitle={2020 IEEE International Parallel and Distributed Processing Symposium (IPDPS)}, 
  title={SCSL: Optimizing Matching Algorithms to Improve Real-time for Content-based Pub/Sub Systems}, 
  year={2020},
  volume={},
  number={},
  pages={148-157},
  abstract={Although many matching algorithms have been proposed to improve the matching efficiency of the content-based publish/subscribe system, existing work seldom consider the real-time of event dissemination from the perspective of event matching. On the basis of two existing matching algorithms, in this paper, we propose a subscription-classifying and structure-layering (SCSL) optimization method for matching algorithms, aiming to improve real-time by shortening the determining time of matching subscriptions. The basic idea of SCSL is that subscriptions with high matching probabilities should be processed first in the process of event matching and their storage positions in the data structure should be adjusted in line with changing probabilities. One challenge of SCSL is the trade-off that needs to be made between the gains of improving real-time performance by identifying matching subscriptions earlier and the cost of increasing matching time due to subscription classification and adjustment. We design a concise scheme to classify subscriptions, establish a lightweight adjustment mechanism to deal with dynamics and propose an efficient greedy algorithm to compute the adjustment solution, which alleviates the impact of SCSL on matching performance. The experiment results show that the 95th percentile of the determining time of matching subscriptions is improved by about 70%. Furthermore, we integrate SCSL into Apache Kafka to augment it as a content-based publish/subscribe system and test the effect of SCSL based on real-world stock trace data, which witnesses about 40% improvement on the average event transfer latency and confirms that SCSL can effectively improve the real-time performance of content-based publish/subscribe systems.},
  keywords={},
  doi={10.1109/IPDPS47924.2020.00025},
  ISSN={1530-2075},
  month={May},}
@INPROCEEDINGS{9139789,
  author={Liu, Wenjie and Huang, Ping and He, Xubin},
  booktitle={2020 IEEE International Parallel and Distributed Processing Symposium (IPDPS)}, 
  title={StragglerHelper: Alleviating Straggling in Computing Clusters via Sharing Memory Access Patterns}, 
  year={2020},
  volume={},
  number={},
  pages={602-611},
  abstract={Clusters have been a prevalent and successful computing framework for processing large amount of data due to their distributed and parallelized working paradigm. A task submitted to a cluster is typically divided into a number of subtasks which are designated to different work nodes running the same code but dealing with different equal portion of the dataset to be processed. Due to the existence of heterogeneity, it could easily result in stragglers unfairly slowing down the entire processing, because work nodes finish their subtasks at different rates. In this study, we aim to speed up straggling work nodes to quicken the overall processing by leveraging exhibited performance variation. More specifically, we propose StragglerHelper which conveys the memory access characteristics experienced by the forerunner to the stragglers such that stragglers can be sped up due to the accurately informed memory prefetching. A Progress Monitor is deployed to supervise the respective progresses of the work nodes and inform the memory access patterns of forerunner to straggling nodes. Our evaluation results with the SPEC MPI 2007 and BigDataBench on a cluster of 64 work nodes have shown that StragglerHelper is able to improve the execution time of stragglers by up to 99.5% with an average of 61.4%, contributing to an overall improvement of the entire cohort of the cluster by up to 46.7% with an average of 9.9% compared to the baseline cluster.},
  keywords={},
  doi={10.1109/IPDPS47924.2020.00068},
  ISSN={1530-2075},
  month={May},}
@INPROCEEDINGS{9148664,
  author={Behrens, Hans Walter and Candan, K. Selçuk},
  booktitle={ICC 2020 - 2020 IEEE International Conference on Communications (ICC)}, 
  title={Pando: Efficient Byzantine-Tolerant Distributed Sensor Fusion using Forest Ensembles}, 
  year={2020},
  volume={},
  number={},
  pages={1-6},
  abstract={Ad hoc communication networks provide a robust and low-power method for sensors to return their observations to an authority. However, ensuring that the returned values accurately represent the environment being sensed poses challenges. In particular, malicious sensors controlled by an adversary may collude to return systematically misleading or falsified results. Previous work examines this challenge for weak adversaries and under strong assumptions, limiting practical applicability. In this work, we propose Pando, a novel approach for mitigating the Byzantine distributed sensor fusion problem. We introduce an approach for the decentralized creation of a forest ensemble, made up of overlapping, hierarchical message passing routes that provide robust and efficient delivery while also mitigating adversarial interference. We then leverage a modified, homomorphic Merkle tree structure to create a novel Byzantine-tolerant message passing protocol. Finally, we propose a classification-informed data fusion algorithm based on these methods. We evaluate the correctness and efficiency of our approach under several attack models, and discuss functionality improvements over the state of the art.},
  keywords={},
  doi={10.1109/ICC40277.2020.9148664},
  ISSN={1938-1883},
  month={June},}
@INPROCEEDINGS{9150399,
  author={Sugihara, Kohei and Tatebe, Osamu},
  booktitle={2020 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)}, 
  title={Design of Locality-aware MPI-IO for Scalable Shared File Write Performance}, 
  year={2020},
  volume={},
  number={},
  pages={1080-1089},
  abstract={Difficult and challenging I/O access pattern among applications is N-1 access pattern such that multiple N processes share and access a single file. This I/O pattern is commonly and widely used because it can reduce the number of output files, while there is a problem of I/O performance degradation due to lock conflicts in a parallel file system among processes. In this study, we propose a locality-aware MPI-IO to improve N-1 write performance by using node-local storage. Our method achieved a significantly scalable performance with N-1 noncollective write performance reaching 1062.36 GiB/s for read and 268.08 GiB/s for write using 256 nodes. The parallel efficiency of N-1 noncollective write was 58% using 256 nodes and that of N-1 collective write was 63% using 72 nodes. The scalability of the proposed method outperforms the Lustre and BeeOND. It also achieves a scalable performance for real application benchmarks such as S3D-IO, LES-IO and VPIC-IO, which shows that it is promising for Exascale systems.},
  keywords={},
  doi={10.1109/IPDPSW50202.2020.00179},
  ISSN={},
  month={May},}
@INPROCEEDINGS{9150146,
  author={Vaughn, Nathan and Wilson, Leighton and Krasny, Robert},
  booktitle={2020 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)}, 
  title={A GPU-Accelerated Barycentric Lagrange Treecode}, 
  year={2020},
  volume={},
  number={},
  pages={701-710},
  abstract={We present an MPI + OpenACC implementation of the kernel-independent barycentric Lagrange treecode (BLTC) for fast summation of particle interactions on GPUs. The distributed memory parallelization uses recursive coordinate bisection for domain decomposition and MPI remote memory access to build locally essential trees on each rank. The particle interactions are organized into target batch/source cluster interactions which efficiently map onto the GPU; target batching provides an outer level of parallelism, while the direct sum form of the barycentric particle-cluster approximation provides an inner level of parallelism. The GPU-accelerated BLTC performance is demonstrated on several test cases up to 1 billion particles interacting via the Coulomb potential and Yukawa potential.},
  keywords={},
  doi={10.1109/IPDPSW50202.2020.00125},
  ISSN={},
  month={May},}
@INPROCEEDINGS{9150426,
  author={Saxena, Manvi and Jha, Shweta and Khan, Saba and Rodgers, John and Lindner, Peggy and Gabriel, Edgar},
  booktitle={2020 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)}, 
  title={Comparison of MPI and Spark for Data Science Applications}, 
  year={2020},
  volume={},
  number={},
  pages={682-690},
  abstract={Data Science applications represent a growing fraction of the scientific computing workload, many of them written in Python. The goal of this paper is to compare two popular parallel programming models, namely MPI and Apache Spark for Python based Data Science applications. The paper presents communication and file I/O microbenchmarks to evaluate the MPI support for Python applications, and uses two applications use-cases from Natural Language Processing to compare the performance of the MPI and the Spark versions. Our results indicate that the MPI version shows better scalability and performance than the PySpark version of the code. On the other hand, the MPI applications are significantly larger than their PySpark counterparts, and took significantly longer to develop due to the necessity to implement some of the built-in functionality provided by Spark.},
  keywords={},
  doi={10.1109/IPDPSW50202.2020.00123},
  ISSN={},
  month={May},}
@INPROCEEDINGS{9150458,
  author={Guo, Jia and Agrawal, Gagan},
  booktitle={2020 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)}, 
  title={Smart Streaming: A High-Throughput Fault-tolerant Online Processing System}, 
  year={2020},
  volume={},
  number={},
  pages={396-405},
  abstract={In recent years, there has been considerable interest in developing frameworks for processing streaming data. Like the precursor commercial systems for data-intensive processing, these systems have largely not used methods popular within the HPC community (for example, MPI for communication). In this paper, we demonstrate a system for stream processing that offers a high-level API to the users (similar to MapReduce), is fault-tolerant, and is also more efficient and scalable than current solutions. Particularly, a cost-efficient MPI/OpenMP based fault-tolerant scheme is incorporated so that the system can survive node failures with only a modest degradation of performance. We evaluate both the functionality and efficiency of Smart Streaming using four common applications in machine learning and data analytics. A comparison against state-of-the-art streaming frameworks shows our system boosts the throughput of test cases by up to 10X and achieve desirable parallelism when scaled out. Additionally, the performance loss upon failures is only proportional to the share of failed resources.},
  keywords={},
  doi={10.1109/IPDPSW50202.2020.00075},
  ISSN={},
  month={May},}
@INPROCEEDINGS{9150353,
  author={Feki, Raafat and Gabriel, Edgar},
  booktitle={2020 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)}, 
  title={On Overlapping Communication and File I/O in Collective Write Operation}, 
  year={2020},
  volume={},
  number={},
  pages={1-8},
  abstract={Many parallel scientific applications spend a significant amount of time reading and writing data files. Collective I/O operations allow to optimize the file access of a process group by redistributing data across processes to match the data layout on the file system. In most parallel I/O libraries, the implementation of collective I/O operations is based on the two-phase I/O algorithm, which consists of a communication phase and a file access phase. This papers evaluates various design options for overlapping two internal cycles of the two-phase I/O algorithm, and explores using different data transfer primitives for the shuffle phase, including non-blocking two-sided communication and multiple versions of one-sided communication. The results indicate that overlap algorithms incorporating asynchronous I/O outperform overlapping approaches that only rely on nonblocking communication. However, in the vast majority of the testcases one-sided communication did not lead to performance improvements over two-sided communication.},
  keywords={},
  doi={10.1109/IPDPSW50202.2020.00175},
  ISSN={},
  month={May},}
@INPROCEEDINGS{9155639,
  author={Bachiega, Naylor G. and de Souza, Paulo S. L. and Bruschi, Sarita M. and de Souza, Simone do R. S.},
  booktitle={2020 IEEE International Conference on Software Testing, Verification and Validation Workshops (ICSTW)}, 
  title={Performance Evaluation of Container’s Shared Volumes}, 
  year={2020},
  volume={},
  number={},
  pages={114-123},
  abstract={Performance is one example of the Extra-Functional Properties (EFPs), an essential part of software development with limited resources. In such a context of software development, containers represent a widely used abstraction technology that requires fewer resources, when compared to hypervisor-based virtualization. Containers provide access to environments and speed up development by abstracting the underlying infrastructure layer for different application domains. Volume sharing is a usual abstraction provided by containers for data persistence, which can be accomplished, especially with Network File System (NFS) or Docker's sharing method. Evaluate the performance of these volumes in containers is critical to software development; however, we did not find available in the literature such evaluation. This paper describes the volume sharing performance for containers using NFS and Docker, which is essential for data persistence. We evaluated the performance of these shared volumes by simulating three application domains: database accesses from a benchmark, direct reads and writes in the file systems and concurrent accesses from an MPI parallel program. Our results show significant differences among the distinct volume sharing methods analyzed for Docker and NFS. While asynchronous NFS has better performances for the set composed of heavy workloads, bursting read and write sequences, the Docker volumes, by the other hand, outperformed for processes with concurrent accesses when using a parallel program.},
  keywords={},
  doi={10.1109/ICSTW50294.2020.00031},
  ISSN={},
  month={Oct},}
@INPROCEEDINGS{9164236,
  author={Pan, Yijun and Zheng, Zeyu},
  booktitle={2020 Chinese Control And Decision Conference (CCDC)}, 
  title={Bayesian online change point detection method for process monitoring}, 
  year={2020},
  volume={},
  number={},
  pages={3389-3393},
  abstract={Aiming at the problem of a large amount of unlabeled observations collected in the industrial processes, an unsupervised Bayesian online change point detection method is adopted for fault detection. Firstly, a prior probability of fault occurrence is set based on the significance level. Secondly, the predictive distribution is calculated using the exponential family likelihoods as a new observation arrives. Finally, based on the observed data, a recursive message-passing algorithm is applied for calculating the fault occurrence probability at the current sampling point. The power of the Bayesian method for fault detection is tested in a numerical simulation and the Tennessee-Eastman (TE) process.},
  keywords={},
  doi={10.1109/CCDC49329.2020.9164236},
  ISSN={1948-9447},
  month={Aug},}
@INPROCEEDINGS{9166319,
  author={Barus, Dandi T. and Elfarizy, R. and Masri, F. and Gunawan, P. H.},
  booktitle={2020 8th International Conference on Information and Communication Technology (ICoICT)}, 
  title={Parallel Programming of Churn Prediction Using Gaussian Naïve Bayes}, 
  year={2020},
  volume={},
  number={},
  pages={1-4},
  abstract={This paper presents churn predictions with the Gaussian Naïve Bayes method. Churn prediction is a forecasting method to predict customer decisions in a company's service or product (churn). With high public enthusiasm and an increasing number of customers in the Big Data era, a fast computing process is needed to predict churn as quickly as possible. In this paper, computing is accelerated by the OpenMP platform parallel algorithm. Churn prediction experiments are performed with different amounts of test data, ranging from 100, 300, 500, 700, to 900 data. The results obtained show that implementing OpenMP in predicting churn is faster than serial processing. The obtained speedup and efficiency reached more than 1.49 and 37%, even for test data of 300 and 500, based on the tests, the speedup and efficiency reached 1.99 and 50%.},
  keywords={},
  doi={10.1109/ICoICT49345.2020.9166319},
  ISSN={},
  month={June},}
@INPROCEEDINGS{9174146,
  author={Cademartori, Collin and Rush, Cynthia},
  booktitle={2020 IEEE International Symposium on Information Theory (ISIT)}, 
  title={Exponentially Fast Concentration of Vector Approximate Message Passing to its State Evolution}, 
  year={2020},
  volume={},
  number={},
  pages={2670-2675},
  abstract={Vector Approximate Message Passing is a computationally-efficient iterative algorithm for estimation in high-dimensional regression problems. Due to the presence of an `Onsager' correction term in its iterates, for a wide class of N × M design matrices, namely those that are right orthogonally-invariant, the asymptotic distribution of the algorithm's estimate of the signal at any iteration can be exactly characterized in the large system limit as M/N → δ ∈ (0,∞) via a scalar recursion referred to as state evolution. In this paper, we show that appropriate functionals of the iterates in fact concentrate around their limiting values predicted by these asymptotic distributions with rates exponentially fast in N.},
  keywords={},
  doi={10.1109/ISIT44484.2020.9174146},
  ISSN={2157-8117},
  month={June},}
@INPROCEEDINGS{9173999,
  author={Takahashi, Takashi and Kabashima, Yoshiyuki},
  booktitle={2020 IEEE International Symposium on Information Theory (ISIT)}, 
  title={Macroscopic Analysis of Vector Approximate Message Passing in a Model Mismatch Setting}, 
  year={2020},
  volume={},
  number={},
  pages={1403-1408},
  abstract={Vector approximate message passing (VAMP) is an efficient approximate inference algorithm used for generalized linear models. Although VAMP exhibits excellent performance, particularly when measurement matrices are sampled from rotationally invariant ensembles, existing convergence and performance analyses have been limited mostly to cases in which the correct posterior distribution is available. Here, we extend the analyses for cases in which the correct posterior distribution is not used in the inference stage. We derive state evolution equations, which macroscopically describe the dynamics of VAMP, and show that their fixed point is consistent with the replica symmetric solution obtained by the replica method of statistical mechanics. We also show that the fixed point of VAMP can exhibit a microscopic instability, the critical condition of which agrees with that for breaking the replica symmetry. The results of numerical experiments support our findings.},
  keywords={},
  doi={10.1109/ISIT44484.2020.9173999},
  ISSN={2157-8117},
  month={June},}
@INPROCEEDINGS{9188280,
  author={Tanaka, Kenji and Arikawa, Yuki and Ito, Tsuyoshi and Morita, Kazutaka and Nemoto, Naru and Miura, Fumiaki and Terada, Kazuhiko and Teramoto, Junji and Sakamoto, Takeshi},
  booktitle={2020 IEEE Symposium on High-Performance Interconnects (HOTI)}, 
  title={Communication-Efficient Distributed Deep Learning with GPU-FPGA Heterogeneous Computing}, 
  year={2020},
  volume={},
  number={},
  pages={43-46},
  abstract={Distributed deep learning has an inevitable bottleneck in communication between GPUs. This bottleneck is due to the difference in the data transfer latency of internode and intra-node communication. Here, we propose a GPU-FPGA (field programmable gate array) heterogeneous computing system and a hardware-specific communication module with parameter-based computation/communication overlap. In our system, we configure a network interface card (NIC) with a data aggregation function. To reduce the load on CPUs, we developed a device driver for remote direct memory access between GPUs and FPGAs. The hardware and software can be run with TensorFlow and Horovod. For comparison, we compared our system with the conventional GPUDirect RDMA system. Results of the measurement show Allreduce latency is reduced to 1/4 by offloading Allreduce to FPGA NICs. Our hardware/software co-design can also conceal about 90% of the communication overhead and improve scalability by 20%. The end-to-end time consumed for training in distributed deep learning with ResNet-50 and ImageNet is reduced to 87.3% without any degradation in validation accuracy.},
  keywords={},
  doi={10.1109/HOTI51249.2020.00021},
  ISSN={2332-5569},
  month={Aug},}
@ARTICLE{9190140,
  author={Li, Chao and Jiang, Ting and Wu, Sheng},
  journal={China Communications}, 
  title={Speech enhancement based on approximate message passing}, 
  year={2020},
  volume={17},
  number={8},
  pages={187-198},
  abstract={To overcome the limitations of conventional speech enhancement methods, such as inaccurate voice activity detector (VAD) and noise estimation, a novel speech enhancement algorithm based on the approximate message passing (AMP) is adopted. AMP exploits the difference between speech and noise sparsity to remove or mute the noise from the corrupted speech. The AMP algorithm is adopted to reconstruct the clean speech efficiently for speech enhancement. More specifically, the prior probability distribution of speech sparsity coefficient is characterized by Gaussian-model, and the hyper-parameters of the prior model are excellently learned by expectation maximization (EM) algorithm. We utilize the k-nearest neighbor (k-NN) algorithm to learn the sparsity with the fact that the speech coefficients between adjacent frames are correlated. In addition, computational simulations are used to validate the proposed algorithm, which achieves better speech enhancement performance than other four baseline methods-Wiener filtering, subspace pursuit (SP), distributed sparsity adaptive matching pursuit (DSAMP), and expectation-maximization Gaussian-model approximate message passing (EM-GAMP) under different compression ratios and a wide range of signal to noise ratios (SNRs).},
  keywords={},
  doi={10.23919/JCC.2020.08.015},
  ISSN={1673-5447},
  month={Aug},}
@INPROCEEDINGS{9200914,
  author={Perez, Ramon and Garcia-Reinoso, Jaime and Zabala, Aitor and Serrano, Pablo and Banchs, Albert},
  booktitle={2020 European Conference on Networks and Communications (EuCNC)}, 
  title={A Monitoring Framework for Multi-Site 5G Platforms}, 
  year={2020},
  volume={},
  number={},
  pages={52-56},
  abstract={The fifth generation (5G) of mobile networks will have to accommodate different types of use cases, each of them with different and stringent requirements and key performance indicators (KPIs). To support this, apart from novel technologies such as network slicing or artificial intelligence, 5G will require a flexible and efficient monitoring system. The collected metrics serve to optimize the performance of the network, and to confirm the achievement of the KPIs. Furthermore, in the envisioned multi-site, multi-stakeholder scenarios, having a common monitoring system is even more critical for an efficient optimization and service provisioning. In this paper, we present a Monitoring architecture for the distribution and consumption of metrics and KPIs for 5G multi-site platforms, where different verticals from different stakeholders are implemented over a shared infrastructure. We also assess the performance of the implemented publish-subscribe paradigm, to confirm that it suits the requirements of these scenarios, and discuss how the architecture could be mapped to other 5G scenarios.},
  keywords={},
  doi={10.1109/EuCNC48522.2020.9200914},
  ISSN={2575-4912},
  month={June},}
@ARTICLE{9201010,
  author={Liang, Shansuo and Liang, Chulong and Ma, Junjie and Ping, Li},
  journal={IEEE Transactions on Communications}, 
  title={Compressed Coding, AMP-Based Decoding, and Analog Spatial Coupling}, 
  year={2020},
  volume={68},
  number={12},
  pages={7362-7375},
  abstract={This paper considers a compressed-coding scheme that combines compressed sensing with forward error control coding. Approximate message passing (AMP) is used to decode the message. Based on the state evolution analysis of AMP, we derive the performance limit of compressed-coding. We show that compressed-coding can approach Gaussian capacity at a very low compression ratio. Further, the results are extended to systems involving non-linear effects such as clipping. We show that the capacity approaching property can still be maintained when generalized AMP is used to decode the message. To approach the capacity, a low-rate underlying code should be designed according to the curve matching principle, which is complicated in practice. Instead, analog spatial-coupling is used to avoid sophisticated low-rate code design. In the end, we study the coupled scheme in a multiuser environment, where analog spatial-coupling can be realized in a distributive way. The overall block length can be shared by many users, which reduces block length per-user.},
  keywords={},
  doi={10.1109/TCOMM.2020.3024871},
  ISSN={1558-0857},
  month={Dec},}
@INPROCEEDINGS{9201723,
  author={Ruhland, Fabian and Krakowski, Filip and Schöttner, Michael},
  booktitle={2020 19th International Symposium on Parallel and Distributed Computing (ISPDC)}, 
  title={Performance analysis and evaluation of Java-based InfiniBand Solutions}, 
  year={2020},
  volume={},
  number={},
  pages={20-28},
  abstract={Low-latency network interconnects, such as InfiniBand, are widely used in HPC centers and are becoming available in public cloud offerings, too. For MPI applications accessing InfiniBand is transparent, but many big-data applications are written in Java, which does not provide direct access to InfiniBand networks, but relies on thid-party libraries. In this paper, we present Observatory, a benchmark for evaluating low-level libraries, providing InfiniBand access for Java applications. Observatory can be used for evaluating and comparing socket- and verbs-based libraries regarding throughput and latency. With transparency often traded for performance and vice versa, the benchmark helps developers with studying the pros and cons of each solution and supports them in their decision which solution is more suitable for their existing or new use-case. We also give an overview of existing and maintained InfiniBand libraries for Java and evaluate them with the proposed benchmark.},
  keywords={},
  doi={10.1109/ISPDC51135.2020.00013},
  ISSN={2379-5352},
  month={July},}
@INPROCEEDINGS{9202840,
  author={Alshammari, Nayef H.},
  booktitle={2020 IEEE 44th Annual Computers, Software, and Applications Conference (COMPSAC)}, 
  title={Message-Passing Based Communication via Synchronous Execution (Channels)}, 
  year={2020},
  volume={},
  number={},
  pages={1483-1489},
  abstract={Runtime Verification (RV) is the discipline that allows monitoring systems at runtime in order to check the satisfaction or violation of a given correctness property. Parallel systems are more complicated than sequential systems. Therefore, systems that run in parallel need a parallel runtime verification framework to monitor their behaviour and guarantee correctness properties. Parallel systems have correctness properties different from correctness properties of sequential systems. For instance, as a correctness property of parallel systems, absence of deadlock has to be guaranteed and mutual exclusion mechanism has to be applied in case a resource is shared between more than one system and the parallelism form is true concurrency. Therefore, sequential runtime verification framework can not handle systems that run in parallel due to the singularity issue of this kind of framework as they are built to handle a single system at a time, whereas for parallel systems a framework has to handle many systems at a time. In this paper, I propose a Parallel Runtime Verification Framework (PRVF) that can handle systems which use message-passing based communication via synchronous execution mode. The proposed model can check system behaviour at runtime in order to either guarantee satisfaction or detect violations of correctness properties. My technique is based on Interval Temporal Logic (ITL).},
  keywords={},
  doi={10.1109/COMPSAC48688.2020.00-45},
  ISSN={0730-3157},
  month={July},}
@INPROCEEDINGS{9208338,
  author={Jalal Apostal, Sara Faraji and Apostal, David and Marsh, Ronald},
  booktitle={2020 IEEE International Conference on Electro Information Technology (EIT)}, 
  title={Improving Numerical Reproducibility of Scientific Software in Parallel Systems}, 
  year={2020},
  volume={},
  number={},
  pages={066-074},
  abstract={Recently, numerical reproducibility has received increased emphasis from the scientific community. Software results that are not reproducible make it difficult to examine the science the software supports. A common source of numerical reproducibility errors in computational science occurs during floating-point arithmetic. Finite precisions and limited storage for floating-point numbers require computers to truncate and round results of some math operations. As a consequence, an approximate value is stored instead of the exact result. One programming idiom that is not always reproducible is the global sum reduction of a distributed array. Changing the number of compute units changes the order array elements are added together which, in turn, changes the truncation and rounding. This may change the result of individual add operations and the resulting global sum. Therefore, floating-point addition is not always associative. This research has improved the numerical reproducibility of scientific applications on parallel systems. Automating the improvement of reproducibility in scientific software is the innovative contribution of this research. Two reproducible global sum reduction functions have been implemented and packaged in a software library. The automated improving of reproducibility has been done by developing a source code scanner to recognize certain MPI-based global sum reductions that may have reproducibility errors. The scanner replaces those reductions with calls to the library function containing reproducible codes. Reproducibility and performance testing have demonstrated the effectiveness of the system. This will extend the usefulness of legacy software and can lead to faster rates of discovery, and more efficient application of scientists' time.},
  keywords={},
  doi={10.1109/EIT48999.2020.9208338},
  ISSN={2154-0373},
  month={July},}
@INPROCEEDINGS{9190642,
  author={Peng, Yaopeng and Chen, Danny Z. and Lin, Lanfen},
  booktitle={2020 IEEE International Conference on Image Processing (ICIP)}, 
  title={Visual Relationship Detection With A Deep Convolutional Relationship Network}, 
  year={2020},
  volume={},
  number={},
  pages={1461-1465},
  abstract={Visual relationship is crucial to image understanding and can be applied to many tasks (e.g., image caption and visual question answering). Despite great progress on many vision tasks, relationship detection remains a challenging problem due to the complexity of modeling the widely spread and imbalanced distribution of {subject - predicate - object} triplets. In this paper, we propose a new framework to capture the relative positions and sizes of the subject and object in the feature map and add a new branch to filter out some object pairs that are unlikely to have relationships. In addition, an activation function is trained to increase the probability of some feature maps given an object pair. Experiments on two large datasets, the Visual Relationship Detection (VRD) and Visual Genome (VG) datasets, demonstrate the superiority of our new approach over state-of-the-art methods. Further, ablation study verifies the effectiveness of our techniques.},
  keywords={},
  doi={10.1109/ICIP40778.2020.9190642},
  ISSN={2381-8549},
  month={Oct},}
@INPROCEEDINGS{9213705,
  author={Cicirelli, Franco and Nigro, Libero},
  booktitle={2020 IEEE/ACM 24th International Symposium on Distributed Simulation and Real Time Applications (DS-RT)}, 
  title={Model Checking Actor-based Cyber-Physical Systems}, 
  year={2020},
  volume={},
  number={},
  pages={1-8},
  abstract={Cyber-physical systems (CPSs) integrate continuous behavior of a physical controlled plant with discrete behavior provided by a controlling cyber (software) part. The integration is challenging because continuous, Newtonian time of the physical part needs be reconciled with discrete time of the cyber part. In this work, the event-based asynchronous actors of Theatre extended with continuous modes, are used for modelling and analyzing CPSs. Continuous modes capture the dynamic laws (ODEs) of variation of physical/environmental variables. Theatre is control-based and distributed. It is implemented in Java, which is used both as the modelling language and as the target implementation language. Specific control forms were developed for simulating a distributed CPS and for assessing its functional/temporal behavior. Continuous modes exploit suitable ODE solvers to predict the future values of selected variables at specific time points. Although classical actors depend on non-deterministic message passing, a Theatre model can be designed to have a deterministic behavior. A hybrid Theatre model can be analyzed by exhaustive model checking by having, for instance, that the computations of the ODE solvers are, preliminarily, offline collected and reused during verification. This paper describes Theatre, summarizes its operational semantics and illustrates a model reduction onto Uppaal timed automata. Then an automotive deterministic model based on both wired and Controller Area Network transmitted messages is presented and thoroughly analysed.},
  keywords={},
  doi={10.1109/DS-RT50469.2020.9213705},
  ISSN={1550-6525},
  month={Sep.},}
@INPROCEEDINGS{9216827,
  author={Reitz, Jan and Roßmann, Jürgen},
  booktitle={2020 IEEE 16th International Conference on Automation Science and Engineering (CASE)}, 
  title={Automatic Integration of Simulated Systems into OPC UA Networks}, 
  year={2020},
  volume={},
  number={},
  pages={697-702},
  abstract={This paper demonstrates the integration of OPC Unified Architecture (OPC UA) communication capabilities in a simulation framework. The proposed approach is based on a data mapping from the simulation's meta data model to the OPC UA information model and a concurrent architecture based on message passing between the OPC UA server and the simulation software. The data mapping utilizes the simulation's and OPC UA's reflection mechanisms to automatically generate OPC UA address spaces from simulation models. The inverse mapping is used to automatically generate simulation model structure from queries to an existing OPC UA server. The concurrent architecture enables large numbers of simulated objects to be equipped with individual and independent OPC UA servers and clients. This allows the simulation of entire scenarios with simulated objects communicating with each other and with external software. The usefulness extends to distributed simulation use cases, where models populate individual instances of the simulation software and communicate over a real network. The implementation is applied to simulate an automotive production line, where multiple machines are equipped with individual OPC UA servers and communicate with 3rd party software. Stress tests show, that the implementation can handle significant network load.},
  keywords={},
  doi={10.1109/CASE48305.2020.9216827},
  ISSN={2161-8089},
  month={Aug},}
@INPROCEEDINGS{9217232,
  author={He, Mengxia and Wang, Shengchu},
  booktitle={2020 IEEE 31st Annual International Symposium on Personal, Indoor and Mobile Radio Communications}, 
  title={Sparse Channel Estimation in Nonlinear MIMO with Magnitude/Phase Measurements}, 
  year={2020},
  volume={},
  number={},
  pages={1-6},
  abstract={The spatio-temporal sparsity (STS) is exploited to improve the channel estimation (CE) for nonlinear multiple input multiple output (NL-MIMO), whose base station (BS) acquires only phases-or-magnitudes of the received complex signals through low-power and low-cost phase/envelope detectors. The sparse CE problem is formulated as the generalized linear mixing one and resolved by a modified generalized vector approximate message passing (GVAMP) algorithm with expectation maximization (EM) mechanism. The prior distribution of sparse channel is modeled as Bernoulli Gaussian-mixture (BGM). Consequently, NL-MIMO channel responses and unknown parameters including BGM parameters and noise variance are updated by the GVAMP and EM procedure alternatingly. A gradient descent (GD) method is proposed for EM update of noise variance in NL-MIMO, where closed-form solution is missed due to the complex formulas of likelihood under phase/magnitude observations. Monte Carlo integration technique is exploited to numerically derive the gra-dient of the noise variance under phase/magnitude observations. Simulation results show that the transmission power and pilot length are significantly saved after exploiting the STS, and both the EM-GVAMP and GD estimators are validated.},
  keywords={},
  doi={10.1109/PIMRC48278.2020.9217232},
  ISSN={2166-9589},
  month={Aug},}
@INPROCEEDINGS{9217738,
  author={Silva, João A. and Vieira, Pedro and Paulino, Hervé},
  booktitle={2020 IEEE 21st International Symposium on "A World of Wireless, Mobile and Multimedia Networks" (WoWMoM)}, 
  title={Data Storage and Sharing for Mobile Devices in Multi-region Edge Networks}, 
  year={2020},
  volume={},
  number={},
  pages={40-49},
  abstract={The edge computing paradigm has been recently introduced with the aim of bringing cloud services closer to endusers. It provides an intermediate layer between devices and the actual cloud infrastructure, resulting in faster response times. In this paper, we propose a framework that leverages stationary nodes within the edge infrastructure to provide a persistent publish/subscribe system to a set of mobile devices, distributed across multiple network regions. We combine device-to-device and device-to-edge interactions with the goal of optimizing access to relevant data and allowing such data to be available to all users, hence creating a persistent, local-area data storage and dissemination network. Our experimental results show adequate response times for interactive usage and low energy consumption. We also evaluate our system against a cloud solution and verify that our proposal yields considerable latency speedups.},
  keywords={},
  doi={10.1109/WoWMoM49955.2020.00021},
  ISSN={},
  month={Aug},}
@INPROCEEDINGS{9235064,
  author={Pinho, Vitoria and Yviquel, Hervé and Machado Pereira, Marcio and Araujo, Guido},
  booktitle={2020 IEEE 32nd International Symposium on Computer Architecture and High Performance Computing (SBAC-PAD)}, 
  title={OmpTracing: Easy Profiling of OpenMP Programs}, 
  year={2020},
  volume={},
  number={},
  pages={249-256},
  abstract={One of the greatest challenges of modern computing is the development of software for parallel execution. To address such challenge, programmers use profiling tools to record relevant operations, like the communications that the different parts of an application carried out during its execution. Profilers can be used to analyze the execution of the application as they enable the programmer to check its performance hot spots and sources of overhead. This paper introduces the OmpTracing library, a lightweight tool that eases the task of profiling OpenMP based applications without the need to inject expensive profiling code into the program. OmpTracing leverages on OMPT, an application programming interface that provides an introspection mechanism of the OpenMP runtime, and that enables the programmer to capture execution details of the parallelized application while generating notifications about significant program events.},
  keywords={},
  doi={10.1109/SBAC-PAD49847.2020.00042},
  ISSN={2643-3001},
  month={Sep.},}
@INPROCEEDINGS{9235040,
  author={Zhang, Xi and Sun, Xu and Guo, Xiaohu and Du, Yunfei and Lu, Yutong and Liu, Yang},
  booktitle={2020 IEEE 32nd International Symposium on Computer Architecture and High Performance Computing (SBAC-PAD)}, 
  title={Re-evaluation of Atomic Operations and Graph Coloring for Unstructured Finite Volume GPU Simulations}, 
  year={2020},
  volume={},
  number={},
  pages={297-304},
  abstract={In general, race condition can be resolved by introducing synchronisations or breaking data dependencies. Atomic operations and graph coloring are the two typical approaches to avoid race condition. Graph coloring algorithms have been generally considered winning algorithms in the literature due to their lock free implementations. In this paper, we present the GPU-accelerated algorithms of the unstructured cell-centered finite volume Computational Fluid Dynamics (CFD) software framework named PHengLEI which was originally developed for aerodynamics applications with arbitrary hybrid meshes. Overall, the newly developed GPU framework demonstrate up to 4.8 speedup comparing with 18 MPI tasks run on the latest Intel CPU node. Furthermore, the enormous efforts have been invested to optimize data dependencies which could lead to race condition due to unstructured mesh indirect addressing and related reduction math operations. With careful comparison between our optimised graph coloring and atomic operations using a series of numerical tests with different mesh sizes, the results show that atomic operations are more efficient than our optimised graph coloring in all of the test cases on Nvidia Tesla GPU V100. Specifically, for the summation operation, using atomicAdd is twice as fast as graph coloring. For the maximum operation, a speedup of 1.5 to 2 is found for atomicMax vs. graph coloring.},
  keywords={},
  doi={10.1109/SBAC-PAD49847.2020.00048},
  ISSN={2643-3001},
  month={Sep.},}
@INPROCEEDINGS{9229595,
  author={Devarajan, Hariharan and Kougkas, Anthony and Bateman, Keith and Sun, Xian-He},
  booktitle={2020 IEEE International Conference on Cluster Computing (CLUSTER)}, 
  title={HCL: Distributing Parallel Data Structures in Extreme Scales}, 
  year={2020},
  volume={},
  number={},
  pages={248-258},
  abstract={Most parallel programs use irregular control flow and data structures, which are perfect for one-sided communication paradigms such as MPI or PGAS programming languages. However, these environments lack the presence of efficient function-based application libraries that can utilize popular communication fabrics such as TCP, Infinity Band (IB), and RDMA over Converged Ethernet (RoCE). Additionally, there is a lack of high-performance data structure interfaces. We present Hermes Container Library (HCL), a high-performance distributed data structures library that offers high-level abstractions including hash-maps, sets, and queues. HCL uses a RPC over RDMA technology that implements a novel procedural programming paradigm. In this paper, we argue a RPC over RDMA technology can serve as a high-performance, flexible, and co-ordination free backend for implementing complex data structures. Evaluation results from testing real workloads shows that HCL programs are 2x to 12x faster compared to BCL, a state-of-the-art distributed data structure library.},
  keywords={},
  doi={10.1109/CLUSTER49012.2020.00035},
  ISSN={2168-9253},
  month={Sep.},}
@INPROCEEDINGS{9229573,
  author={Luo, Xi and Wu, Wei and Bosilca, George and Pei, Yu and Cao, Qinglei and Patinyasakdikul, Thananon and Zhong, Dong and Dongarra, Jack},
  booktitle={2020 IEEE International Conference on Cluster Computing (CLUSTER)}, 
  title={HAN: a Hierarchical AutotuNed Collective Communication Framework}, 
  year={2020},
  volume={},
  number={},
  pages={23-34},
  abstract={High-performance computing (HPC) systems keep growing in scale and heterogeneity to satisfy the increasing computational need, and this brings new challenges to the design of MPI libraries, especially with regard to collective operations. To address these challenges, we present “HAN,” a new hierarchical autotuned collective communication framework in Open MPI, which selects suitable homogeneous collective communication modules as submodules for each hardware level, uses collective operations from the submodules as tasks, and organizes these tasks to perform efficient hierarchical collective operations. With a task-based design, HAN can easily swap out submodules, while keeping tasks intact, to adapt to new hardware. This makes HAN suitable for the current platform and provides a strong and flexible support for future HPC systems. To provide a fast and accurate autotuning mechanism, we present a novel cost model based on benchmarking the tasks instead of a whole collective operation. This method drastically reduces tuning time, as the cost of tasks can be reused across different message sizes, and is more accurate than existing cost models. Our cost analysis suggests the autotuning component can find the optimal configuration in most cases. The evaluation of the HAN framework suggests our design significantly improves the default Open MPI and achieves decent speedups against state-of-the-art MPI implementations on tested applications.},
  keywords={},
  doi={10.1109/CLUSTER49012.2020.00013},
  ISSN={2168-9253},
  month={Sep.},}
@INPROCEEDINGS{9244045,
  author={Sommer, Lukas and Koch, Andreas},
  booktitle={2020 International Conference on Embedded Software (EMSOFT)}, 
  title={OpenMP Device Offloading for Embedded Heterogeneous Platforms - Work-in-Progress}, 
  year={2020},
  volume={},
  number={},
  pages={4-6},
  abstract={The growing computational demands of automotive applications require the use of powerful embedded, heterogeneous computing platforms in vehicles. OpenMP, and in particular its device offloading features, are a promising candidate programming model for these platforms. In this work, we show how typical automotive workloads can be implemented and optimized with OpenMP device offloading. To this end, we also adapt the LLVM OpenMP runtime to embedded, heterogeneous platforms. Our evaluation shows that OpenMP device offloading can deliver performance similar to that of optimized CUDA implementations.},
  keywords={},
  doi={10.1109/EMSOFT51651.2020.9244045},
  ISSN={},
  month={Sep.},}
@INPROCEEDINGS{9251089,
  author={Wu, Han and Shang, Zhihao and Peng, Guang and Wolter, Katinka},
  booktitle={2020 IEEE 31st International Symposium on Software Reliability Engineering (ISSRE)}, 
  title={A Reactive Batching Strategy of Apache Kafka for Reliable Stream Processing in Real-time}, 
  year={2020},
  volume={},
  number={},
  pages={207-217},
  abstract={Modern stream processing systems need to process large volumes of data in real-time. Various stream processing frameworks have been developed and messaging systems are widely applied to transfer streaming data among different applications. As a distributed messaging system with growing popularity, Apache Kafka processes streaming data in small batches for efficiency. However, the robustness of Kafka's batching method against variable operating conditions is not known. In this paper we study the impact of the batch size on the performance of Kafka. Both configuration parameters, the spatial and temporal batch size, are considered. We build a Kafka testbed using Docker containers to analyze the distribution of Kafka's end-to-end latency. The experimental results indicate that evaluating the mean latency only is unreliable in the context of real-time systems. In the experiments where network faults are injected, we find that the batch size affects the message loss rate in the presence of an unstable network connection. However, allocating resources for message processing and delivery that will violate the reliability requirements implemented as latency constraints of a real-time system is inefficient To address these challenges we propose a reactive batching strategy. We evaluate our batching strategy in both good and poor network conditions. The results show that the strategy is powerful enough to meet both latency and throughput constraints even when network conditions are variable.},
  keywords={},
  doi={10.1109/ISSRE5003.2020.00028},
  ISSN={2332-6549},
  month={Oct},}
@INPROCEEDINGS{9251927,
  author={Nelson, Jacob and Palmieri, Roberto},
  booktitle={2020 International Symposium on Reliable Distributed Systems (SRDS)}, 
  title={Performance Evaluation of the Impact of NUMA on One-sided RDMA Interactions}, 
  year={2020},
  volume={},
  number={},
  pages={288-298},
  abstract={Remote direct memory access (RDMA) and non-uniform memory access (NUMA) are critical technologies of modern high-performance computing platforms. RDMA allows nodes to directly access memory on remote machines. Multiprocessor architectures implement NUMA to scale up memory access performance. When paired together, these technologies exhibit performance penalties under certain configurations. This paper is the first study to explore these configurations to provide quantitative findings on the impact of NUMA for RDMA-based systems. One of the consequences of ultra-fast networks is that known implications of NUMA locality now constitute a higher relative impact on the performance of RDMA-enabled distributed systems. Our study quantifies its role and uncovers unexpected behavior. In summary, poor NUMA locality of remotely accessible memory can lead to an automatic 20% performance degradation. Additionally, local workloads operating on remotely accessible memory can lead to 300% performance gap depending on memory locality. Surprisingly, configurations demonstrating this result contradict the presumed impact of NUMA locality. Our findings are validated using two generations of RDMA cards, a synthetic benchmark, and the popular application Memcached ported for RDMA.},
  keywords={},
  doi={10.1109/SRDS51746.2020.00036},
  ISSN={2575-8462},
  month={Sep.},}
@INPROCEEDINGS{9251254,
  author={Guo, Luanzheng and Georgakoudis, Giorgis and Parasyris, Konstantinos and Laguna, Ignacio and Li, Dong},
  booktitle={2020 IEEE International Symposium on Workload Characterization (IISWC)}, 
  title={MATCH: An MPI Fault Tolerance Benchmark Suite}, 
  year={2020},
  volume={},
  number={},
  pages={60-71},
  abstract={MPI has been ubiquitously deployed in flagship HPC systems aiming to accelerate distributed scientific applications running on tens of hundreds of processes and compute nodes. Maintaining the correctness and integrity of MPI application execution is critical, especially for safety-critical scientific applications. Therefore, a collection of effective MPI fault tolerance techniques have been proposed to enable MPI application execution to efficiently resume from system failures. However, there is no structured way to study and compare different MPI fault tolerance designs, so to guide the selection and development of efficient MPI fault tolerance techniques for distinct scenarios. To solve this problem, we design, develop, and evaluate a benchmark suite called MATCH to characterize, research, and comprehensively compare different combinations and configurations of MPI fault tolerance designs. Our investigation derives useful findings: (1) Reinit recovery in general performs better than ULFM recovery; (2) Reinit recovery is independent of the scaling size and the input problem size, whereas ULFM recovery is not; (3) Using Reinit recovery with FTI checkpointing is a highly efficient fault tolerance design. MATCH code is available at https://github.com/kakulo/MPI-FT-Bench.},
  keywords={},
  doi={10.1109/IISWC50251.2020.00015},
  ISSN={},
  month={Oct},}
@INPROCEEDINGS{9270373,
  author={Chen, Zhenbang and Yu, Hengbiao and Fu, Xianjin and Wang, Ji},
  booktitle={2020 IEEE/ACM 42nd International Conference on Software Engineering: Companion Proceedings (ICSE-Companion)}, 
  title={MPI-SV: A Symbolic Verifier for MPI Programs}, 
  year={2020},
  volume={},
  number={},
  pages={93-96},
  abstract={Message passing is the primary programming paradigm in high-performance computing. However, developing message passing programs is challenging due to the non-determinism caused by parallel execution and complex programming features such as non-deterministic communications and asynchrony. We present MPI-SV, a symbolic verifier for verifying the parallel C programs using message passing interface (MPI). MPI-SV combines symbolic execution and model checking in a synergistic manner to improve the scalability and enlarge the scope of verifiable properties. We have applied MPI-SV to real-world MPI C programs. The experimental results indicate that MPI-SV can, on average, achieve 19x speedups in verifying deadlock-freedom and 5x speedups in finding counter-examples. MPI-SV can be accessed at https://mpi-sv.github.io, and the demonstration video is at https://youtu.be/zzCY0CPDNCw.},
  keywords={},
  doi={},
  ISSN={2574-1926},
  month={Oct},}
@INPROCEEDINGS{9274081,
  author={Kılıç, Baran and Özturan, Can and Sen, Alper},
  booktitle={2020 Second International Conference on Blockchain Computing and Applications (BCCA)}, 
  title={A Cluster Based System for Analyzing Ethereum Blockchain Transaction Data}, 
  year={2020},
  volume={},
  number={},
  pages={59-65},
  abstract={Ability to perform fast analysis on massive public blockchain transaction data is needed in various finance applications such as tracing of fraudulent activities. The blockchain data that is synced as a node is accessible as a sequence of blocks containing transactions. This way of accessing transaction data, however, is too slow for applications that require a transaction graph to be constructed. We develop a cluster based system that constructs a distributed transaction graph in parallel. Since blockchain data is continuously growing, our parallel system also offers the advantage of being able to scale by simply increasing the number of nodes in the cluster. Our system has been developed using the MPI message passing interface. We report performance results from our system operating on the whole 9.5 million block (roughly 4 year) Ethereum mainnet blockchain data. We report timings obtained from tests involving distributed transaction graph construction, partitioning, page ranking of addresses, degree distribution and token transaction counting on a 16 node economical cluster set up on the Amazon cloud. In particular, our system is able to construct distributed graph of 658 million ether and 31 major token transactions in 188 seconds.},
  keywords={},
  doi={10.1109/BCCA50787.2020.9274081},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{9284263,
  author={Zhao, Liqing and Cheng, Bo and Chen, Junliang},
  booktitle={2020 IEEE 13th International Conference on Cloud Computing (CLOUD)}, 
  title={LambDP: Data Processing Framework for Terminal Applications in IoTs Services}, 
  year={2020},
  volume={},
  number={},
  pages={16-18},
  abstract={Data processing is the basis and kernel for implementing terminal applications in Internet of Things(IoTs) services. As a large amount of sensing devices need to be connected to the IoTs service, it will bring an enormous number of heterogeneous data, and the data is difficult to be directly used by terminal applications in upper layer. So we need a data processing framework to achieve data integration and processing in IoTs services. In this paper, we introduce a data processing framework, LambDP, which includes a protocol stack system, a publish/subscribe system and a data processing platform. Protocol stack system offers dynamical protocol adaptation. Publish/subscribe center is a message queue, which can provide transfer and distribution for data. Data processing platform is based on lambda theory to implement parallel computing streaming mode and batch mode of data. In addition, we use the workflow pattern to encapsulate the business logic in LambDP into components, which can provide data processing services to upper layers applications. As for the performance of the data processing framework based on Lambda, we will deploy the data processing platform to give the verification.},
  keywords={},
  doi={10.1109/CLOUD49709.2020.00012},
  ISSN={2159-6190},
  month={Oct},}

@INPROCEEDINGS{9286232,
  author={Samsi, Siddharth and Prout, Andrew and Jones, Michael and Kirby, Andrew and Arcand, Bill and Bergeron, Bill and Bestor, David and Byun, Chansup and Gadepally, Vijay and Houle, Michael and Hubbell, Matthew and Klein, Anna and Michaleas, Peter and Milechin, Lauren and Mullen, Julie and Rosa, Antonio and Yee, Charles and Reuther, Albert and Kepner, Jeremy},
  booktitle={2020 IEEE High Performance Extreme Computing Conference (HPEC)}, 
  title={Benchmarking network fabrics for data distributed training of deep neural networks}, 
  year={2020},
  volume={},
  number={},
  pages={1-6},
  abstract={Artificial Intelligence/Machine Learning applications require the training of complex models on large amounts of labelled data. The large computational requirements for training deep models have necessitated the development of new methods for faster training. One such approach is the data parallel approach, where the training data is distributed across multiple compute nodes. This approach is simple to implement and supported by most of the commonly used machine learning frameworks. The data parallel approach leverages MPI for communicating gradients across all nodes. In this paper, we examine the effects of using different physical hardware interconnects and network-related software primitives for enabling data distributed deep learning. We compare the effect of using GPUDirect and NCCL on Ethernet and OmniPath fabrics. Our results show that using Ethernet-based networking in shared HPC systems does not have a significant effect on the training times for commonly used deep neural network architectures or traditional HPC applications such as Computational Fluid Dynamics.},
  keywords={},
  doi={10.1109/HPEC43674.2020.9286232},
  ISSN={2643-1971},
  month={Sep.},}
@INPROCEEDINGS{9296938,
  author={Pollard, Samuel D. and Norris, Boyana},
  booktitle={2020 IEEE/ACM 4th International Workshop on Software Correctness for HPC Applications (Correctness)}, 
  title={A Statistical Analysis of Error in MPI Reduction Operations}, 
  year={2020},
  volume={},
  number={},
  pages={49-57},
  abstract={This work explores the effects of nonassociativity of floating-point addition on Message Passing Interface (MPI) reduction operations. Previous work indicates floating-point summation error is comprised of two independent factors: error based on the summation algorithm and error based on the summands themselves. We find evidence to suggest, for MPI reductions, the error based on summands has a much greater effect than the error based on the summation algorithm. We begin by sampling from the state space of all possible summation orders for MPI reduction algorithms. Next, we show the effect of different random number distributions on summation error, taking a 1000-digit precision floating-point accumulator as ground truth. Our results show empirical error bounds that are much tighter than existing analytical bounds. Last, we simulate different allreduce algorithms on the high performance computing (HPC) proxy application Nekbone and find that the error is relatively stable across algorithms. Our approach provides HPC application developers with more realistic error bounds of MPI reduction operations. Quantifying the small-but nonzero-discrepancies between reduction algorithms can help developers ensure correctness and aid reproducibility across MPI implementations and cluster topologies.},
  keywords={},
  doi={10.1109/Correctness51934.2020.00011},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{9296940,
  author={Nguyen, Van Man and Saillard, Emmanuelle and Jaeger, Julien and Barthou, Denis and Carribault, Patrick},
  booktitle={2020 IEEE/ACM 4th International Workshop on Software Correctness for HPC Applications (Correctness)}, 
  title={PARCOACH Extension for Static MPI Nonblocking and Persistent Communication Validation}, 
  year={2020},
  volume={},
  number={},
  pages={31-39},
  abstract={The Message Passing Interface (MPI) is a parallel programming model used to exchange data between working units in different nodes of a supercomputer. While MPI blocking operations return when the communication is complete, non-blocking and persistent operations return before the communication is complete, enabling a developer to hide communication latency. However the usage of these latter comes with additional rules the user has to abide to. This is error prone, which makes verification tools valuable for MPI program writers. PARCOACH is a framework that detects MPI collective errors using a static/dynamic analysis. In this paper we present an extension of PARCOACH static analysis to detect misuse of MPI nonblocking and persistent communications. Our new analysis adds the detection of four new error classes related to these types of communications. Its implementation was tested on several MPI micro-benchmarks, and on some CORAL or Mantevo benchmarks on which we observed an acceptable overhead at compile-time.},
  keywords={},
  doi={10.1109/Correctness51934.2020.00009},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{9286122,
  author={Huang, Yu and Ogles, Benjamin and Mercer, Eric},
  booktitle={2020 35th IEEE/ACM International Conference on Automated Software Engineering (ASE)}, 
  title={A Predictive Analysis for Detecting Deadlock in MPI Programs}, 
  year={2020},
  volume={},
  number={},
  pages={18-28},
  abstract={A common problem in MPI programs is deadlock: when two or more processes are blocked indefinitely due to a circular communication dependency. Automatically detecting deadlock is difficult due to its schedule-dependent nature. This paper presents a predictive analysis for single-path MPI programs that observes a single program execution and then determines whether any other feasible schedule of the program can lead to a deadlock. The analysis works by identifying problematic communication patterns in a dependency graph to form a set of deadlock candidates. The deadlock candidates are filtered by an abstract machine and ultimately tested for reachability by an SMT solver with an efficient encoding for deadlock. This approach quickly yields a set of high probability deadlock candidates useful for reasoning about complex codes and yields higher performance overall in many cases compared to other state-of-the-art analyses. The analysis is sound and complete for single-path MPI programs on a given input.},
  keywords={},
  doi={},
  ISSN={2643-1572},
  month={Sep.},}
@INPROCEEDINGS{9307009,
  author={Kolla, Hemanth and Mayo, Jackson R. and Teranishi, Keita and Armstrong, Robert C.},
  booktitle={2020 IEEE/ACM 10th Workshop on Fault Tolerance for HPC at eXtreme Scale (FTXS)}, 
  title={Improving Scalability of Silent-Error Resilience for Message-Passing Solvers via Local Recovery and Asynchrony}, 
  year={2020},
  volume={},
  number={},
  pages={1-10},
  abstract={Benefits of local recovery (restarting only a failed process or task) have been previously demonstrated in parallel solvers. Local recovery has a reduced impact on application performance due to masking of failure delays (for message-passing codes) or dynamic load balancing (for asynchronous many-task codes). In this paper, we implement MPI-process-local checkpointing and recovery of data (as an extension of the Fenix library) in combination with an existing method for local detection of silent errors in partial-differential-equation solvers, to show a path for incorporating lightweight silent-error resilience. In addition, we demonstrate how asynchrony introduced by maximizing computation-communication overlap can halt the propagation of delays. For a prototype stencil solver (including an iterative-solver-like variant) with injected memory bit flips, results show greatly reduced overhead under weak scaling compared to global recovery, and high failure-masking efficiency. The approach is expected to be generalizable to other MPI-based solvers.},
  keywords={},
  doi={10.1109/FTXS51974.2020.00006},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{9307059,
  author={Shahneous Bari, Md Abdullah and Basu, Debasmita and Lu, Wenbin and Curtis, Tony and Chapman, Barbara},
  booktitle={2020 IEEE/ACM 10th Workshop on Fault Tolerance for HPC at eXtreme Scale (FTXS)}, 
  title={Checkpointing OpenSHMEM Programs Using Compiler Analysis}, 
  year={2020},
  volume={},
  number={},
  pages={51-60},
  abstract={The importance of fault tolerance continues to increase for HPC applications. The continued growth in size and complexity of HPC systems, and of the applications themselves, is leading to an increased likelihood of failures during execution. However, most HPC programming models do not have a built-in fault tolerance mechanism. Instead, application developers usually rely on external support such as application-level checkpoint-restart (C/R) libraries to make their codes fault tolerant. However, this increases the burden on the application developer, who must use the libraries carefully to ensure correct behavior and to minimize the overheads. The C/R routines will be employed to save the values of all needed program variables at the places in the code where they are invoked. It is important for correctness that the program data is in a consistent state at these places. It is non-trivial to determine such points in OpenSHMEM, which relies upon single-sided communications to provide high performance. The amount of data to be collected, and the frequency with which this is performed, must also be carefully tuned, as the overheads introduced by C/R calls can be extremely high. There is very little prior work on checkpoint-restart support in the context of the OpenSHMEM programming interface. In this paper, we introduce OpenSHMEM and describe the challenges it poses for checkpointing. We identify the safest places for inserting C/R calls in an OpenSHMEM program and describe a straightforward approach for identifying the data that needs to be checkpointed at these positions in the code. We provide these two functionalities in a tool that exploits compiler analyses to propose checkpoints and the sets of data for saving at them, to the application developer.},
  keywords={},
  doi={10.1109/FTXS51974.2020.00011},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{9307141,
  author={Carns, Philip and Harms, Kevin and Settlemyer, Bradley W. and Atkinson, Brian and Ross, Robert B.},
  booktitle={2020 IEEE/ACM Fifth International Parallel Data Systems Workshop (PDSW)}, 
  title={Keeping It Real: Why HPC Data Services Don't Achieve I/O Microbenchmark Performance}, 
  year={2020},
  volume={},
  number={},
  pages={1-6},
  abstract={HPC storage software developers rely on benchmarks as reference points for performance evaluation. Low-level synthetic microbenchmarks are particularly valuable for isolating performance bottlenecks in complex systems and identifying optimization opportunities. The use of low-level microbenchmarks also entails risk, however, especially if the benchmark behavior does not reflect the nuances of production data services or applications. In those cases, microbenchmark measurements can lead to unrealistic expectations or misdiagnosis of performance problems. Neither benchmark creators nor software developers are necessarily at fault in this scenario, however. The underlying problem is more often a subtle disconnect between the objective of the benchmark and the objective of the developer. In this paper we investigate examples of discrepancies between microbenchmark behavior and software developer expectations. Our goal is to draw attention to these pitfalls and initiate a discussion within the community about how to improve the state of the practice in performance engineering for HPC data services.},
  keywords={},
  doi={10.1109/PDSW51947.2020.00006},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{9307882,
  author={Hunold, Sascha and Steiner, Sebastian},
  booktitle={2020 IEEE/ACM Performance Modeling, Benchmarking and Simulation of High Performance Computer Systems (PMBS)}, 
  title={Benchmarking Julia’s Communication Performance: Is Julia HPC ready or Full HPC?}, 
  year={2020},
  volume={},
  number={},
  pages={20-25},
  abstract={Julia has quickly become one of the main programming languages for computational sciences, mainly due to its speed and flexibility. The speed and efficiency of Julia are the main reasons why researchers in the field of High Performance Computing have started porting their applications to Julia.Since Julia has a very small binding-overhead to C, many efficient computational kernels can be integrated into Julia without any noticeable performance drop. For that reason, highly tuned libraries, such as the Intel MKL or OpenBLAS, will allow Julia applications to achieve similar computational performance as their C counterparts. Yet, two questions remain: 1) How fast is Julia for memory-bound applications? 2) How efficient can MPI functions be called from a Julia application?In this paper, we will assess the performance of Julia with respect to HPC. To that end, we examine the raw throughput achievable with Julia using a new Julia port of the well-known STREAM benchmark. We also compare the running times of the most commonly used MPI collective operations (e.g., MPI_Allreduce) with their C counterparts. Our analysis shows that HPC performance of Julia is on-par with C in the majority of cases.},
  keywords={},
  doi={10.1109/PMBS51919.2020.00008},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{9307863,
  author={Groves, Taylor and Brock, Ben and Chen, Yuxin and Ibrahim, Khaled Z. and Oliker, Lenny and Wright, Nicholas J. and Williams, Samuel and Yelick, Katherine},
  booktitle={2020 IEEE/ACM Performance Modeling, Benchmarking and Simulation of High Performance Computer Systems (PMBS)}, 
  title={Performance Trade-offs in GPU Communication: A Study of Host and Device-initiated Approaches}, 
  year={2020},
  volume={},
  number={},
  pages={126-137},
  abstract={Network communication on GPU-based systems is a significant roadblock for many applications with small but frequent messaging requirements. One common question for application developers is, "How can they reduce the overheads and achieve the best communication performance on GPUs?" This work examines device initiated versus host initiated inter-node GPU communication using NVSHMEM. We derive basic communication model parameters for single message and batched communication before validating our model against distributed GEMM benchmarks. We use our model to estimate performance benefits for applications transitioning from CPUs to GPUS for fixed-size and scaled workloads and provide general guidelines for reducing communication overheads. Our findings show that the host-initiated approach generally outperforms the device-initiated approach for the system evaluated.},
  keywords={},
  doi={10.1109/PMBS51919.2020.00016},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{9308653,
  author={Hanford, Nathan and Pankajakshan, Ramesh and León, Edgar A. and Karlin, Ian},
  booktitle={2020 Workshop on Exascale MPI (ExaMPI)}, 
  title={Challenges of GPU-aware Communication in MPI}, 
  year={2020},
  volume={},
  number={},
  pages={1-10},
  abstract={GPUs are increasingly popular in HPC systems and applications. However, the communication bottleneck between GPUs, distributed across HPC nodes within a cluster, has limited achievable scalability of GPU-centric applications. Advances in inter-node GPU communication such as NVIDIA's GPUDirect have made great strides in addressing this issue. The added software development complexity has been addressed by simplified GPU programming paradigms such as Unified or Managed Memory. To understand the performance of these new features, new benchmarks were developed. Unfortunately, these benchmark efforts do not include correctness checking and certain messaging patterns used in applications. In this paper we highlight important gaps in communication benchmarks and motivate a methodology to help application developers understand the performance tradeoffs of different data movement options. Furthermore, we share systems tuning and deployment experiences across different GPU-aware MPI implementations. In particular, we demonstrate correctness testing is needed along with performance testing through modifications to an existing benchmark. In addition, we present a case study where existing benchmarks fail to characterize how data is moved within SW4, a seismic wave application, and create a benchmark to model this behavior. Finally, we motivate the need for an application-inspired benchmark methodology to assess system performance and guide application programmers on how to use the system more efficiently.},
  keywords={},
  doi={10.1109/ExaMPI52011.2020.00006},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{9308652,
  author={Schafer, Derek and Laguna, Ignacio and Skjellum, Anthony and Sultana, Nawrin and Mohror, Kathryn},
  booktitle={2020 Workshop on Exascale MPI (ExaMPI)}, 
  title={Extending the MPI Stages Model of Fault Tolerance}, 
  year={2020},
  volume={},
  number={},
  pages={52-61},
  abstract={Here, we expand upon our effective, checkpoint-based approach of fault tolerance for MPI-"MPI Stages," an extension of the Reinit model of fault-tolerant MPI introduced by some of us and others, notably without the use of setjmp/longjmp. MPI Stages saves internal MPI state in a separate checkpoint in coordination with application state saved by the application. While it is currently implemented based on the ExaMPI research implementation of MPI (designed to simplify checkpointing of state through a new, OO design), MPI Stages' downward requirement on any MPI implementation primarily inheres in internal-state checkpointability, apart from the new syntax and semantics of the MPI Stages model itself.As of now, MPI Stages supports communicators, groups, and limited forms of derived datatypes used with point-to-point and collective communication. We report on success with a substantial MPI application, SW4, which utilizes many of the common subset of features of many data-parallel MPI applications. We reinforce the model of a pre-main-type resilience interposition model, and introduce MPI opaque object serialization and deserialization. We also introduce new functions to better support use of the Stages model in hierarchical code and legacy software that does not sample MPI error codes faithfully. These MPI-Stages concepts appear useful for other fault tolerant MPI models and so are near-term standardization targets.We describe future steps needed to make MPI Stages more production ready, standardizable, and integrable with other MPI fault-tolerance models.},
  keywords={},
  doi={10.1109/ExaMPI52011.2020.00011},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{9308072,
  author={Wylie, Brian J. N.},
  booktitle={2020 IEEE/ACM International Workshop on HPC User Support Tools (HUST) and Workshop on Programming and Performance Visualization Tools (ProTools)}, 
  title={Exascale potholes for HPC: Execution performance and variability analysis of the flagship application code HemeLB}, 
  year={2020},
  volume={},
  number={},
  pages={59-70},
  abstract={Performance measurement and analysis of parallel applications is often challenging, despite many excellent commercial and open-source tools being available. Currently envisaged exascale computer systems exacerbate matters by requiring extremely high scalability to effectively exploit millions of processor cores. Unfortunately, significant application execution performance variability arising from increasingly complex interactions between hardware and system software makes this situation much more difficult for application developers and performance analysts alike. This work considers the performance assessment of the HemeLB exascale flagship application code from the EU HPC Centre of Excellence (CoE) for Computational Biomedicine (CompBioMed) running on the SuperMUC-NG Tier-0 leadership system, using the methodology of the Performance Optimisation and Productivity (POP) CoE. Although 80% scaling efficiency is maintained to over 100,000 MPI processes, disappointing initial performance with more processes and corresponding poor strong scaling was identified to originate from the same few compute nodes in multiple runs, which later system diagnostic checks found had faulty DIMMs and lacklustre performance. Excluding these compute nodes from subsequent runs improved performance of executions with over 300,000 MPI processes by a factor of five, resulting in 190 x speed-up compared to 864 MPI processes. While communication efficiency remains very good up to the largest scale, parallel efficiency is primarily limited by load balance found to be largely due to core-to-core and run-to-run variability from excessive stalls for memory accesses, that affect many HPC systems with Intel Xeon Scalable processors. The POP methodology for this performance diagnosis is demonstrated via a detailed exposition with widely deployed `standard' measurement and analysis tools.},
  keywords={},
  doi={10.1109/HUSTProtools51951.2020.00014},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{9311347,
  author={Ko, Soon-Heum and Gancheva, Veska},
  booktitle={2020 International Conference Automatics and Informatics (ICAI)}, 
  title={An Approach for Parallel Reading in Multiple Sequence Alignment}, 
  year={2020},
  volume={},
  number={},
  pages={1-6},
  abstract={We propose an approach for faster file reading of multiple sequence alignment input through the use of MPI-I/O over a subset of MPI cores. The idea is to allow a subset of MPI cores that perform I/O operations and to broadcast locally on individual neighbors, so the code is less sensitive to the stability of the parallel file system. It is achieved by creating a number of subgroups under a global MPI communicator. The size of each subgroup and the buffer size of each reading operation are tuned through the synthetic benchmark. We verify the performance of our approach by comparing it with the traditional way of "sequential file reading and global broadcast", and apply it to the existing MPI version of multiple sequence alignment software ClustalW. In the production run over 8192 BlueGene/Q cores, the current approach provides 6.8 times acceleration of the existing ClustalW-MPI implementation.},
  keywords={},
  doi={10.1109/ICAI50593.2020.9311347},
  ISSN={},
  month={Oct},}
@INPROCEEDINGS{9307083,
  author={Gratien, Jean-Marc},
  booktitle={2020 IEEE/ACM 6th Workshop on the LLVM Compiler Infrastructure in HPC (LLVM-HPC) and Workshop on Hierarchical Parallelism for Exascale Computing (HiPar)}, 
  title={Introducing multi-level parallelism, at coarse, fine and instruction level to enhance the performance of iterative solvers for large sparse linear systems on Multi- and Many-core architecture}, 
  year={2020},
  volume={},
  number={},
  pages={85-95},
  abstract={With the evolution of High Performance Computing, multi-core and many-core systems are now a common feature of new hardware architectures. The introduction of very large number of cores at the processor level is challenging because it requires to handle multi level parallelism at various levels either coarse or fine to fully take advantage of the offered computing power. The induced programming effort can be fixed with parallel programming models based on the data flow model and the task programming paradigm [1]. To do so many of the standard numerical algorithms must be revisited as they cannot be easily parallelized at the finest levels. Iterative linear solvers are a key part of petroleum reservoir simulation as they can represent up to 80% of the total computing time. In these algorithms, the standard preconditioning methods for large, sparse and unstructured matrices - such as Incomplete LU Factorization (ILU) or Algebraic Multigrid (AMG) - fail to scale on shared-memory architectures with large number of cores. In this paper we reconsider preconditioning algorithms to better introduce multi-level parallelism at both coarse level with MPI, fine level with threads and at the instruction level to enable SIMD optimizations. This paper illustrates how we enhance the implementation of preconditioners like the multilevel domain decomposition (DDML) preconditioners [2], based on the popular Additive Schwartz Method (ASM), or the classical ILU0 preconditioner with the fine grained parallel fixed point variant presented in [3]. Our approach is validated on linear systems extracted from realistic petroleum reservoir simulations. The robustness of the preconditioners is tested with respect to the data heterogeneities of the study cases. We evaluate the extensibility of our implementation regarding the model sizes and its scalability regarding the large number of cores provided by new KNL processors or multi-nodes clusters.},
  keywords={},
  doi={10.1109/LLVMHPCHiPar51896.2020.00014},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{9322482,
  author={Chen, Jianqiao and Zhang, Xi},
  booktitle={GLOBECOM 2020 - 2020 IEEE Global Communications Conference}, 
  title={Super-Resolution Block-Sparse Channel Estimation Over Uplink M-MIMO 5G Mobile Wireless Networks}, 
  year={2020},
  volume={},
  number={},
  pages={1-6},
  abstract={In this paper, we develop a novel super-resolution block-sparse channel estimation approach for uplink massive multi-input multi-output (MIMO) based 5G mobile wireless networks. We first introduce a pattern-coupled Bernoulli-Gaussian (PC-BG) prior to characterize block-sparse channels resulting from a small number of scatterers with a small range of angular spread in the angular domain. Then, we propose a Bayesian inference method to infer the channel vector as well as its hyperparameters associated with the PC-BG prior. Specifically, the proposed algorithm is developed within an expectation-maximization (EM) framework and integrated with the generalized approximate message passing (GAMP) technique of approximating the intractable posterior distribution. Finally, instead of adopting some predefined basis/dictionary, such as a discrete Fourier transform (DFT) basis, we propose to learn the offgrid gap between sampled grid-point and true angle of arrivals (AoAs) iteratively for better sparse channel representation, which thus can improve the sparse channel recovery performance. Our numerical analyses validate and evaluate the effectiveness of our proposed scheme.},
  keywords={},
  doi={10.1109/GLOBECOM42002.2020.9322482},
  ISSN={2576-6813},
  month={Dec},}
@INPROCEEDINGS{9342837,
  author={Ananthakrishnan, S and Tahiliani, Mohit P. and Tandur, Deepaknath and Satheesh, Hariram},
  booktitle={2020 IEEE International Conference on Advanced Networks and Telecommunications Systems (ANTS)}, 
  title={Group based Publisher-Subscriber Communication Primitives for ndnSIM}, 
  year={2020},
  volume={},
  number={},
  pages={1-6},
  abstract={Named Data Networking (NDN), an information centric network architecture, aims to provide an efficient and scalable alternative for content distribution. Modern Internet applications have more emphasis on data, and are less concerned about the location from where data is retrieved. NDN's communication primitives being strictly pull based help in bringing this focus shift from location of data to the data itself. A concern for NDN is to enable the support of other popular communication primitives, such as the Publisher-Subscriber (Pub-Sub) model, seamlessly. The Pub-Sub model is well suited for applications that require periodic retrieval of data or event triggered data, such as in Industrial Automation Control Systems (IACS). This paper presents the design and development of a model to support the group based Pub-Sub communication primitives in ndnSIM, a popular ns-3 based network simulator for NDN. The functionality of the proposed model is tested by developing an end-to-end simulation environment in ndnSIM that is representative of the popular use cases of Pub-Sub communication primitives.},
  keywords={},
  doi={10.1109/ANTS50601.2020.9342837},
  ISSN={2153-1684},
  month={Dec},}
@INPROCEEDINGS{9343570,
  author={Xie, Linshen and Wu, Wei and Zhu, Xiangqin},
  booktitle={2020 IEEE MTT-S International Conference on Numerical Electromagnetic and Multiphysics Modeling and Optimization (NEMO)}, 
  title={Quantitative Analysis of Field Uniformity in “Spring-Thunder” Bounded-Wave EMP Simulator}, 
  year={2020},
  volume={},
  number={},
  pages={1-3},
  abstract={The peak-value distribution of electric fields in testing area in " Spring-Thunder" bounded-wave electromagnetic pulse (EMP) simulator based on parallel finite-difference time-domain (FDTD) method on Message Passing Interface (MPI) platform is given. The experiment results are also presented. The field uniformity in "Spring-Thunder" bounded-wave EMP simulator is quantitatively analyzed. The mean value, standard deviation, and the field uniformity of the simulation and the experiment results are got. Both of the field uniformity agree well. It's useful for the selection of the size and the location of the equipment under test (EUT) in the simulator in experiment.},
  keywords={},
  doi={10.1109/NEMO49486.2020.9343570},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{9341232,
  author={Hołobut, Paweł and Bordas, Stéphane P. A. and Lengiewicz, Jakub},
  booktitle={2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, 
  title={Autonomous model-based assessment of mechanical failures of reconfigurable modular robots with a Conjugate Gradient solver}, 
  year={2020},
  volume={},
  number={},
  pages={11696-11702},
  abstract={Large-scale 3D autonomous self-reconfigurable modular robots are made of numerous interconnected robotic modules that operate in a close packing. The modules are assumed to have their own CPU and memory, and are only able to communicate with their direct neighbors. As such, the robots embody a special computing architecture: a distributed memory and distributed CPU system with a local message-passing interface. The modules can move and rearrange themselves changing the robot's connection topology. This may potentially cause mechanical failures (e.g., overloading of some inter-modular connections), which are irreversible and need to be detected in advance. In the present contribution, we further develop the idea of performing model-based detection of mechanical failures, posed in the form of balance equations solved by the modular robot itself in a distributed manner. A special implementation of the Conjugate Gradient iterative solution method is proposed and shown to greatly reduce the required number of iterations compared with the weighted Jacobi method used previously. The algorithm is verified in a virtual test bed-the VisibleSim emulator of the modular robot. The assessments of time-, CPU-, communication- and memory complexities of the proposed scheme are provided.},
  keywords={},
  doi={10.1109/IROS45743.2020.9341232},
  ISSN={2153-0866},
  month={Oct},}
@INPROCEEDINGS{9344976,
  author={Nengzhi, Jin and Jianwu, Zhe and Haili, Xiao and Xiaoning, Wang and Yulin, Shen},
  booktitle={2020 IEEE 6th International Conference on Computer and Communications (ICCC)}, 
  title={Comparative Research on High-Speed Networks of High Performance Computing Cluster Based on MPIGRAPH}, 
  year={2020},
  volume={},
  number={},
  pages={579-583},
  abstract={With the rapid development of high performance computing, many fields of scientific and engineering computing have been inseparable from the support of high performance computing. The internal high-speed internet has become one of the key elements restricting the high performance computing cluster to a certain extent. In this paper, two sets of high performance computing clusters with the same processor and memory and internal high-speed interconnection network are Infiniband and Intel Omni-Path respectively are taken as test object. Benchmark software mpigraph 1.4 is compiled with different MPI software such as Intel MPI 2019 update 5, mvapich2 2.3.4 and openmpi 3.1.6 to test the differences between the two networks and the differences between different MPI software. The results show that Infiniband has better performance in small-scale parallel, and Intel Omni-Path has better performance in large-scale parallel. The performance of intelmpi is similar to that of openmpi, which is better than mvapich2 in Intel Omni-Path and worse than mvapich2 in Infiniband. This is very important for cluster usage, application software compilation and optimization.},
  keywords={},
  doi={10.1109/ICCC51575.2020.9344976},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{9352396,
  author={Liu, Fei and Qiang, Fangyuan and Tian, Chao and Shi, Ke and Wang, Lei and Hu, Donggang},
  booktitle={2020 IEEE 3rd Student Conference on Electrical Machines and Systems (SCEMS)}, 
  title={Research on Hierarchical Autonomous Operation Monitoring of Energy Stations Based on Cloud Technology}, 
  year={2020},
  volume={},
  number={},
  pages={403-408},
  abstract={To solve the problem of remote monitoring and hierarchical autonomy of distributed energy stations, the hierarchical autonomous operation monitoring platform of energy stations is studied based on cloud technology. The flow computing framework and wide area message queue technology are introduced to realize distributed data collection and distributed data processing. The platform defines the operators of basic operation of flow data on wide area message queue, and supports the modeling, discovery, programming, providing and hosting of flow computing services; the distributed data acquisition and processing includes channel parser, data aggregation group, channel supervision service, repeater, message service, data calculation, alarm processing and control Each component independently constitutes a docker operator in the flow computing framework to complete the data processing of the configuration or monitoring model specified segments; through the research of data acquisition and processing and equipment operation data analysis and early warning technology, it provides customers with a reasonable, clean and reliable energy supply mode of distributed autonomous operation for power and hot / cold energy required by production. In the simulation environment of open stack and docker, the feasibility of integrated information collection and monitoring and hierarchical monitoring of distributed energy station is verified.},
  keywords={},
  doi={10.1109/SCEMS48876.2020.9352396},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{9355233,
  author={Suh, Hansol and Isaac, Tobin},
  booktitle={SC20: International Conference for High Performance Computing, Networking, Storage and Analysis}, 
  title={Evaluation of a Minimally Synchronous Algorithm for 2:1 Octree Balance}, 
  year={2020},
  volume={},
  number={},
  pages={1-12},
  abstract={The p4est library implements octree-based adaptive mesh refinement (AMR) and has demonstrated parallel scalability beyond 100,000 MPI processes in previous weak scaling studies. This work focuses on the strong scalability of mesh adaptivity in p4est, where the communication pattern of the existing 2:1-balance is a latency bottleneck. The sorting-based algorithm of Malhotra and Biros has balanced communication, but synchronizes all processes. We propose an algorithm that combines sorting and neighbor-to-neighbor exchange to minimize the number of processes each process synchronizes with. We measure the performance of these algorithms on several test problems on Stampede2 at TACC. Both the parallel-sorting and minimally-synchronous algorithms significantly outperform the existing algorithm and have nearly identical performance out to 1,024 Xeon Phi KNL nodes, meaning the asymptotic advantage of the minimally-synchronous algorithm does not translate to improved performance at this scale. We conclude by showing that global metadata communication will limit future strong scaling.},
  keywords={},
  doi={10.1109/SC41405.2020.00027},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{9355849,
  author={Watanabe, Yuto and Fukushi, Masaru},
  booktitle={2020 Eighth International Symposium on Computing and Networking Workshops (CANDARW)}, 
  title={A Parallel Volunteer Computing Based on Server Assisted Communications}, 
  year={2020},
  volume={},
  number={},
  pages={242-247},
  abstract={Toward the realization of parallel volunteer computing (VC), this paper proposes a parallel computing method based on the concept of server assisted communications and develops a prototype parallel VC system. In VC, individual nodes cannot directly communicate with each other; hence, application of current VC is limited to bag-of-tasks computation, and this prevents widespread use of VC. The proposed method replaces an inter-node communication with two request-driven communications between sender/server and server/receiver. In our parallel VC system, a VC server consists of an Apache web server and a MySQL database server, and several worker nodes are implemented in C++. A software tool is also developed to convert a parallel program written in an MPI communication library into a program with a standard socket library with HTTP protocol. We have confirmed the correct behavior of one-to-one and collective communication functions and evaluated the execution time.},
  keywords={},
  doi={10.1109/CANDARW51189.2020.00054},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{9355862,
  author={Reguly, István Z. and Mudalige, Gihan R.},
  booktitle={2020 Eighth International Symposium on Computing and Networking Workshops (CANDARW)}, 
  title={Modernising an Industrial CFD Application}, 
  year={2020},
  volume={},
  number={},
  pages={191-196},
  abstract={Rolls-Royce Hydra is an industrial Computational Fluid Dynamics (CFD) code used for the design of turbomachinery. In this paper we describe the modernisation effort that takes the current MPI-only version and migrates it to use the OP2 Domain Specific Language (DSL), which enables OpenMP as well as CUDA parallelisations on top of MPI. We discuss the issue of the the original codebase being under continuous development, and having to keep upstreaming the modernised version using a set of conversion scripts that help to automate the process. The result is a single, easy to maintain, source code that can target modern CPUs and GPUs. We evaluate the performance and scalability of the modernised version on a set of the latest Intel CPUs and NVIDIA GPUs. Results demonstrate matching performance to the original production code using the same parallelization model (MPI) on CPUs, but further speedups of up to 2.8× on modern many-core architectures.},
  keywords={},
  doi={10.1109/CANDARW51189.2020.00046},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{9355713,
  author={Di Luna, Giuseppe Antonio and Anceaume, Emmanuelle and Bonomi, Silvia and Querzoni, Leonardo},
  booktitle={2020 IEEE 40th International Conference on Distributed Computing Systems (ICDCS)}, 
  title={Synchronous Byzantine Lattice Agreement in O(log(f) Rounds}, 
  year={2020},
  volume={},
  number={},
  pages={146-156},
  abstract={In the Lattice Agreement (LA) problem, originally proposed by Attiya et al. [1], a set of processes has to decide on a chain of a lattice. More precisely, each correct process proposes an element e of a certain join-semi lattice L and it has to decide on a value that contains e. Moreover, any pair pi, pj of correct processes has to decide two values deci and decj that are comparable (e.g., deci ≤ decj or decj <; deci). In this paper we present new contributions for the synchronous case. We investigate the problem in the usual message passing model for a system of n processes with distinct unique IDs. We first prove that, when only authenticated channels are available, the problem cannot be solved if f = n/3 or more processes are Byzantine. We then propose a novel algorithm that works in a synchronous system model with signatures (i.e., the authenticated message model), tolerates up to f byzantine failures (where f <; n/3) and that terminates in O(log f) rounds. We discuss how to remove authenticated messages at the price of algorithm resiliency (f <; n/4). Finally, we present a transformer that converts any synchronous LA algorithm to an algorithm for synchronous Generalised Lattice Agreement.},
  keywords={},
  doi={10.1109/ICDCS47774.2020.00056},
  ISSN={2575-8411},
  month={Nov},}
@INPROCEEDINGS{9359190,
  author={Yang, Ziye and Walker, Ben and Harris, James R and Li, Yadong and Cao, Gang},
  booktitle={2020 IEEE 26th International Conference on Parallel and Distributed Systems (ICPADS)}, 
  title={Optimal Use Of The TCP/IP Stack in User-space Storage Applications with ADQ feature in NIC}, 
  year={2020},
  volume={},
  number={},
  pages={363-371},
  abstract={For storage applications based on TCP/IP, performance of the TCP/IP stack is often the dominant driver of the application's overall performance. In this paper, we introduce Tbooster, which is a library designed for TCP/IP based storage applications that optimally leverages the Linux kernel's TCP/IP stack and the socket interface to improve performance. This library allows for efficient grouping of connections onto threads and asynchronous, poll-mode operation, scaling to a massive number of TCP connections on each thread. Tbooster is designed to avoid making expensive system calls by batching and merging operations into a single operation per connection for each poll loop. Further, Tbooster leverages the Application Device Queues (ADQ) feature available in some Network Interface Cards to steer incoming data to the correct NIC receive queue. This avoids expensive coordination and message passing within the kernel when handling incoming data and especially improves outlier tail latencies of requests. Compared with a more standard usage of the Linux kernel TCP/IP stack, Tbooster improves storage I/O per second significantly (e.g., 9% to 22.7% IOPS improvement for an iSCSI target at 4KiB I/O size, 36.3% to 59.4% IOPS improvement for NVMe-oF TCP target on 8KiB I/O size). Moreover, when using the ADQ feature from Intel's 100GbE NIC, it demonstrates 30% average time reduction of 99.99% long tail latency under heavy workloads for NVMe-oF TCP.},
  keywords={},
  doi={10.1109/ICPADS51040.2020.00056},
  ISSN={2690-5965},
  month={Dec},}
@INPROCEEDINGS{9365206,
  author={Hu, Jiazhe and Qin, Xin and Yang, Chuanchuan},
  booktitle={2020 Asia Communications and Photonics Conference (ACP) and International Conference on Information Photonics and Optical Communications (IPOC)}, 
  title={An Optimized Lifting Method Based on PMP for LDPC in PON System}, 
  year={2020},
  volume={},
  number={},
  pages={1-3},
  abstract={We propose a new lifting method based on parallel vector message passing (PMP) called LPMP to generate quasi-cyclic LDPC codes, which can derive a (BER) performance improvement up to 0.4dB.},
  keywords={},
  doi={},
  ISSN={},
  month={Oct},}
@INPROCEEDINGS{9372456,
  author={Li, Xiang-Lin and Wei, Bing and He, Xin-Bo and Gao, Zhi-Wei},
  booktitle={2020 Cross Strait Radio Science & Wireless Technology Conference (CSRSWTC)}, 
  title={Parallel FDFD Algorithm Based on MPI and Its Application}, 
  year={2020},
  volume={},
  number={},
  pages={1-3},
  abstract={In order to solve the problem of slow computation speed and difficulty in solving electromagnetic response of electrically large targets by using finite difference frequency domain (FDFD) serial method, a parallel FDFD calculation method based on MPI memory sharing mechanism is proposed. In the method, the complex sparse matrix is allocated to each sub process by row, and the intermediate matrix used in all processes is stored in the shared memory to reduce the memory consumption. The conjugate gradient method is used to obtain the solution of the equation. Numerical results show the correctness and efficiency of the proposed method.},
  keywords={},
  doi={10.1109/CSRSWTC50769.2020.9372456},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{9407866,
  author={Wang, Bei and Chen, Yifeng and Hou, Chaofeng},
  booktitle={2020 IEEE 22nd International Conference on High Performance Computing and Communications; IEEE 18th International Conference on Smart City; IEEE 6th International Conference on Data Science and Systems (HPCC/SmartCity/DSS)}, 
  title={Communication Optimization Strategy for Molecular Dynamics Simulation on Sunway TaihuLight}, 
  year={2020},
  volume={},
  number={},
  pages={571-578},
  abstract={Molecular dynamics simulation defined as simple state updates over multiple time steps is the main approach to the description of the chemical, mechanical and electrical processes in many real-world application. Currently, most optimization methods focus on simplifying forces or computing parallelization. However, modern general-purpose supercomputers have succeeded on compute-intensive or memory/bandwidth-intensive applications, but the improvement of network bandwidth/latency is fairly limited. The communication overhead is critical, and severely degrades the overall performance and scalability. In this paper, we propose a communication optimization strategy to reduce inter-nodes communication overheads, including a ghost communication mode to reduce the total amount of message, a shift communication algorithm to reduce the total number of messages and a zero-copy RDMA (Remote Direct Memory Access) communication method to reduce inter-nodes memory copy overheads. We implement our ghost communication, shift communication and zero-copy RDMA communication on the third highest performance supercomputer Sunway TaihuLight in the world (before June 2020). We test molecular dynamics simulation of condensed covalent materials and scale the simulation up to 8,519,680 cores to simulate more than 50.4 million silicon atoms, where the parallel efficiency is over 80% on the whole machine. Results show that the communication optimization strategy reduces the communication time by nearly 75% compared with traditional inter-nodes MPI (Message Passing Interface) communication with memory copy and the dimension of the simulated system significantly exceeds the experimentally measurable range. Our simulation enables virtual experiments on real-world applications and makes the technology more accessible to the general scientific users by using general-purpose supercomputers.},
  keywords={},
  doi={10.1109/HPCC-SmartCity-DSS50907.2020.00072},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{9408015,
  author={Schonbein, Whit and Levy, Scott and Marts, W. Pepper and Dosanjh, Matthew G. F. and Grant, Ryan E.},
  booktitle={2020 IEEE 22nd International Conference on High Performance Computing and Communications; IEEE 18th International Conference on Smart City; IEEE 6th International Conference on Data Science and Systems (HPCC/SmartCity/DSS)}, 
  title={Low-cost MPI Multithreaded Message Matching Benchmarking}, 
  year={2020},
  volume={},
  number={},
  pages={170-179},
  abstract={The Message Passing Interface (MPI) standard allows user-level threads to concurrently call into an MPI library. While this feature is currently rarely used, there is considerable interest from developers in adopting it in the near future. There is reason to believe that multithreaded communication may incur additional message processing overheads in terms of number of items searched during demultiplexing and amount of time spent searching because it has the potential to increase the number of messages exchanged and to introduce non-deterministic message ordering. Therefore, understanding the implications of adding multithreading to MPI applications is important for future application development.One strategy for advancing this understanding is through `low-cost' benchmarks that emulate full communication patterns using fewer resources. For example, while a complete, `real-world' multithreaded halo exchange requires 9 or 27 nodes, the low-cost alternative needs only two, making it deployable on systems where acquiring resources is difficult because of high utilization (e.g., busy capacity-computing systems), or impossible because the necessary resources do not exist (e.g., testbeds with too few nodes). While such benchmarks have been proposed, the reported results have been limited to a single architecture or derived indirectly through simulation, and no attempt has been made to confirm that a low-cost benchmark accurately captures features of full (non-emulated) exchanges. Moreover, benchmark code has not been made publicly available.The purpose of the study presented in this paper is to quantify how accurately the low-cost benchmark captures the matching behavior of the full, real-world benchmark. In the process, we also advocate for the feasibility and utility of the low-cost benchmark. We present a `real-world' benchmark implementing a full multithreaded halo exchange on 9 and 27 nodes, as defined by 5-point and 9-point 2D stencils, and 7-point and 27-point 3D stencils. Likewise, we present a `low-cost' benchmark that emulates these communication patterns using only two nodes. We then confirm, across multiple architectures, that the low-cost benchmark gives accurate estimates of both number of items searched during message processing, and time spent processing those messages. Finally, we demonstrate the utility of the low-cost benchmark by using it to profile the performance impact of state-of-the-art Mellanox ConnectX-5 hardware support for offloaded MPI message demultiplexing. To facilitate further research on the effects of multithreaded MPI on message matching behavior, the source of our two benchmarks is to be included in the next release version of the Sandia MPI Micro-Benchmark Suite.},
  keywords={},
  doi={10.1109/HPCC-SmartCity-DSS50907.2020.00022},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{9406610,
  author={Shafi, Aamir and Hashmi, Jahanzeb Maqbool and Subramoni, Hari and Panda, Dhabaleswar K.},
  booktitle={2020 IEEE 27th International Conference on High Performance Computing, Data, and Analytics (HiPC)}, 
  title={Blink: Towards Efficient RDMA-based Communication Coroutines for Parallel Python Applications}, 
  year={2020},
  volume={},
  number={},
  pages={111-120},
  abstract={Python is emerging as a popular language in the data science community due to its ease-of-use, vibrant community, and rich set of libraries. Dask is a popular Python-based distributed computing framework that allows users to process large amounts of data on parallel hardware. The Dask distributed package is a non-blocking, asynchronous, and concurrent library that offers support for distributed execution of tasks on datacenter and HPC environments. A few key requirements of designing high-performance communication backends for Dask distributed is to provide scalable support for coroutines that are unlike regular Python functions and can only be invoked from asynchronous applications. In this paper, we present Blink-a high-performance communication library for Dask on high-performance RDMA networks like InfiniBand. Blink offers a multi-layered architecture that matches the communication requirements of Dask and exploits high-performance interconnects using a Cython wrapper layer to the C backend. We evaluate the performance of Blink against other counterparts using various micro-benchmarks and application kernels on three different cluster testbeds with varying interconnect speeds. Our micro-benchmark evaluation reveals that Blink outperforms other communication backends by more than 3× for message sizes ranging from 1 Byte to 64 KByte, and by a factor of 2× for message sizes ranging from 128 KByte to 8 MByte. Using various application-level evaluations, we demonstrate that Dask achieves up to 7% improvement in application throughput (e.g., total worker throughput).},
  keywords={},
  doi={10.1109/HiPC50609.2020.00025},
  ISSN={2640-0316},
  month={Dec},}
@INPROCEEDINGS{9443542,
  author={Li, Xuhong and Leitinger, Erik and Tufvesson, Fredrik},
  booktitle={2020 54th Asilomar Conference on Signals, Systems, and Computers}, 
  title={RSS-Based Localization of Low-Power IoT Devices Exploiting AoA and Range Information}, 
  year={2020},
  volume={},
  number={},
  pages={651-656},
  abstract={We present a localization algorithm for low-power long-range Internet-of-things (IoT) networks, which exploits angle of arrival (AoA) and range information from non-coherent received signal strength (RSS) measurements. In this work, each anchor node is equipped with array antennas of known geometry and radiation patterns. The position of the target node and the path-loss exponent to each anchor are unknown and possibly time-varying. The joint estimation problem is formulated with a Bayesian model, where the likelihood functions are derived from the classical path-loss model and an RSS difference model. A message passing method is then exploited for efficient computation of the marginal posterior distribution of each unknown variable. The proposed algorithm is validated using real outdoor measurements from a low-power wide area network based IoT system in a challenging scenario. Results show that the proposed algorithm can adapt to dynamic propagation conditions, and improve the localization accuracy compared to a method that exploits only single geometric feature. Furthermore, the algorithm scales well in different antenna array configurations, and is compatible with various existing IoT standards.},
  keywords={},
  doi={10.1109/IEEECONF51394.2020.9443542},
  ISSN={2576-2303},
  month={Nov},}
@INPROCEEDINGS{9457721,
  author={Kundu, Krishnendu and Dutta, Animesh},
  booktitle={2020 IEEE/WIC/ACM International Joint Conference on Web Intelligence and Intelligent Agent Technology (WI-IAT)}, 
  title={Multi-agent Based Distributed MIS Selection for Dynamic Job Scheduling}, 
  year={2020},
  volume={},
  number={},
  pages={234-241},
  abstract={This paper presents a distributed approach to solve dynamic Job Scheduling problem using the notion of distributed Maximal Independent Set (MIS) problem. Initial MIS selection may become improper due to the addition and deletion of vertices in a dynamic graph. This paper introduces a multiagent based P-MIS algorithm to find out a dynamic schedule without violating the predefined constraints. Theoretical analysis of message passing complexity and anti-starvation property of the proposed distributed algorithm is provided in this paper. Using benchmark graph instances, experimental results are analyzed to compare the performance of proposed P-MIS with IoA-based and cooperative approach for job scheduling.},
  keywords={},
  doi={10.1109/WIIAT50758.2020.00035},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{9505498,
  author={Morán, Marina and Balladini, Javier and Rexachs, Dolores and Rucci, Enzo},
  booktitle={2020 IEEE Congreso Bienal de Argentina (ARGENCON)}, 
  title={Towards Management of Energy Consumption in HPC Systems with Fault Tolerance}, 
  year={2020},
  volume={},
  number={},
  pages={1-8},
  abstract={High-performance computing continues to increase its computing power and energy efficiency. However, energy consumption continues to rise and finding ways to limit and/or decrease it is a crucial point in current research. For high-performance MPI applications, there are rollback recovery based fault tolerance methods, such as uncoordinated checkpoints. These methods allow only some processes to go back in the face of failure, while the rest of the processes continue to run. In this article, we focus on the processes that continue execution, and propose a series of strategies to manage energy consumption when a failure occurs and uncoordinated checkpoints are used. We present an energy model to evaluate strategies and through simulation we analyze the behavior of an application under different configurations and failure time. As a result, we show the feasibility of improving energy efficiency in HPC systems in the presence of a failure.},
  keywords={},
  doi={10.1109/ARGENCON49523.2020.9505498},
  ISSN={},
  month={Dec},}
@ARTICLE{8951109,
  author={Wang, Shengchu and Jiang, Xianbo},
  journal={IEEE Transactions on Intelligent Transportation Systems}, 
  title={Three-Dimensional Cooperative Positioning in Vehicular Ad-hoc Networks}, 
  year={2021},
  volume={22},
  number={2},
  pages={937-950},
  abstract={In this paper, a three-dimensional universal cooperative localizer (3D UCL) is proposed for vehicular ad-hoc networks (VANETs) in 3D space under varied types of ranging measurements including time-of-arrival (TOA), received signal strength (RSS), angle-of-arrival (AOA), and Doppler frequency. Its core idea is to exploit generalized approximate message passing (GAMP) to resolve the 3D cooperative positioning problem after converting it as a generalized linear mixing problem. Unfortunately, the positioning performance of 3D UCL is severely degraded by the inaccurate ranging measurements from the non-line-of-sight (NLOS) links. Therefore, a 3D geographical information enhanced UCL (3D GIE-UCL) is developed by combining 3D UCL with a NLOS identification mechanism assisted by geographical information. Finally, 3D UCL is accelerated by graphics processing unit (GPU) parallelization, particle reduction and message censoring. 3D GIE-UCL is accelerated by particle reduction and anchor upgrading. Simulation results validate state-of-the-art positioning performances and cooperative gains of both 3D UCL and 3D GIE-UCL after comparing them with existing cooperative localizers. 3D GIE-UCL approaches to its performance upper bound provided by its correspondence with oracle link-type information. 3D UCL and GIE-UCL show 241× and 3.3× speedup after adopting the acceleration techniques, respectively.},
  keywords={},
  doi={10.1109/TITS.2019.2961452},
  ISSN={1558-0016},
  month={Feb},}
@ARTICLE{9165191,
  author={Wong, Alvaro and Heymann, Elisa and Rexachs, Dolores and Luque, Emilio},
  journal={IEEE Transactions on Parallel and Distributed Systems}, 
  title={Middleware to Manage Fault Tolerance Using Semi-Coordinated Checkpoints}, 
  year={2021},
  volume={32},
  number={2},
  pages={254-268},
  abstract={Compute node failures are becoming a normal event for many long-running and scalable MPI applications. Keeping within the MPI standards and applying some of the methods developed so far in terms of fault tolerance, we developed a methodology that allows applications to tolerate failures through the creation of semi-coordinated checkpoints within the RADIC architecture. To do this, we developed the ULSC2-RADIC middleware that divides the application into independent MPI worlds where each MPI world would correspond to a compute node and make use of the DMTCP checkpoint library in a semi-coordinated environment. We performed experimental results using scientific applications and the NAS Parallel Benchmarks to assess the overhead and also the functionality in case of a node failure. We evaluated the computational cost of the semi-coordinated checkpoints compared with the coordinated checkpoints.},
  keywords={},
  doi={10.1109/TPDS.2020.3015615},
  ISSN={1558-2183},
  month={Feb},}
@ARTICLE{9174777,
  author={Ke, Malong and Gao, Zhen and Wu, Yongpeng and Gao, Xiqi and Wong, Kai-Kit},
  journal={IEEE Journal on Selected Areas in Communications}, 
  title={Massive Access in Cell-Free Massive MIMO-Based Internet of Things: Cloud Computing and Edge Computing Paradigms}, 
  year={2021},
  volume={39},
  number={3},
  pages={756-772},
  abstract={This article studies massive access in cell-free massive multi-input multi-output (MIMO)-based Internet of Things and solves the challenging active user detection (AUD) and channel estimation (CE) problems. For the uplink transmission, we propose an advanced frame structure design to reduce the access latency. Moreover, by considering the cooperation of all access points (APs), we investigate two processing paradigms at the receiver for massive access: cloud computing and edge computing. For cloud computing, all APs are connected to a centralized processing unit (CPU), and the signals received at all APs are centrally processed at the CPU. While for edge computing, the central processing is offloaded to part of APs equipped with distributed processing units, so that the AUD and CE can be performed in a distributed processing strategy. Furthermore, by leveraging the structured sparsity of the channel matrix, we develop a structured sparsity-based generalized approximated message passing (SS-GAMP) algorithm for reliable joint AUD and CE, where the quantization accuracy of the processed signals is taken into account. Based on the SS-GAMP algorithm, a successive interference cancellation-based AUD and CE scheme is further developed under two paradigms for reduced access latency. Simulation results validate the superiority of the proposed approach over the state-of-the-art baseline schemes. Besides, the results reveal that the edge computing can achieve the similar massive access performance as the cloud computing, and the edge computing is capable of alleviating the burden on CPU, having a faster access response, and supporting more flexible AP cooperation.},
  keywords={},
  doi={10.1109/JSAC.2020.3018807},
  ISSN={1558-0008},
  month={March},}
@ARTICLE{9199557,
  author={Lee, Sang Hyun and Kim, Mintae and Shin, Hunmin and Lee, Inkyu},
  journal={IEEE Transactions on Wireless Communications}, 
  title={Belief Propagation for Energy Efficiency Maximization in Wireless Heterogeneous Networks}, 
  year={2021},
  volume={20},
  number={1},
  pages={56-68},
  abstract={In this article, we study an energy efficient management of two-tier heterogeneous cellular networks (HetNets) which consist of one macro base station (BS) and multiple micro base stations. This article presents a distributed user association algorithm that maximizes the network-wide energy efficiency (EE) in HetNets. A subset of BSs that support only a small number of users can be turned off to save the energy consumption. By turning off BSs in the HetNet and offloading serving users to adjacent active BSs, the network-wide energy consumption is minimized, while the sum throughput is maximized. To solve the problem efficiently, we introduce a new approach based on a message-passing framework and derive a distributed load balancing algorithm. The proposed method provides a very efficient solution with reduced computational complexity compared to existing schemes. Simulation results verify that the proposed algorithm outperforms other conventional load balancing strategies.},
  keywords={},
  doi={10.1109/TWC.2020.3023079},
  ISSN={1558-2248},
  month={Jan},}
@ARTICLE{9240002,
  author={Khaled, Mahmoud and Zamani, Majid},
  journal={IEEE Design & Test}, 
  title={Cloud-Ready Acceleration of Formal Method Techniques for Cyber–Physical Systems}, 
  year={2021},
  volume={38},
  number={5},
  pages={25-34},
  abstract={Controller synthesis using formal specifications has shown considerable promise in recent years. However, it is computationally very expensive. This article shows how cloud computing can come to the rescue. },
  keywords={},
  doi={10.1109/MDAT.2020.3034048},
  ISSN={2168-2364},
  month={Oct},}
@ARTICLE{9298875,
  author={Jung, Alexander and SarcheshmehPour, Yasmin},
  journal={IEEE Signal Processing Letters}, 
  title={Local Graph Clustering With Network Lasso}, 
  year={2021},
  volume={28},
  number={},
  pages={106-110},
  abstract={We study the statistical and computational properties of a network Lasso method for local graph clustering. The clusters delivered by nLasso can be characterized elegantly via network flows between cluster boundaries and seed nodes. While spectral clustering methods are guided by a minimization of the graph Laplacian quadratic form, nLasso minimizes the total variation of cluster indicator signals. As demonstrated theoretically and numerically, nLasso methods can handle very sparse clusters (chain-like) which are difficult for spectral clustering. We also verify that a primal-dual method for non-smooth optimization allows to approximate nLasso solutions with optimal worst-case convergence rate.},
  keywords={},
  doi={10.1109/LSP.2020.3045832},
  ISSN={1558-2361},
  month={},}
@ARTICLE{9301369,
  author={Hao, Meng and Zhang, Weizhe and Wang, Yiming and Lu, Gangzhao and Wang, Farui and Vasilakos, Athanasios V.},
  journal={IEEE Transactions on Parallel and Distributed Systems}, 
  title={Fine-Grained Powercap Allocation for Power-Constrained Systems Based on Multi-Objective Machine Learning}, 
  year={2021},
  volume={32},
  number={7},
  pages={1789-1801},
  abstract={Power capping is an important solution to keep the system within a fixed power constraint. However, for the over-provisioned and power-constrained systems, especially the future exascale supercomputers, powercap needs to be reasonably allocated according to the workloads of compute nodes to achieve trade-offs among performance, energy and powercap. Thus it is necessary to model performance and energy and to predict the optimal powercap allocation strategies. Existing power allocation approaches have insufficient granularity within nodes. Modeling approaches usually model performance and energy separately, ignoring the correlation between objectives, and do not expose the Pareto-optimal powercap configurations. Therefore, this article combines the powercap with uncore frequency scaling and proposes an approach to predict the Pareto-optimal powercap configurations on the power-constrained system for input MPI and OpenMP parallel applications. Our approach first uses the elaborately designed micro-benchmarks and a small number of existing benchmarks to build the training set, and then applies a multi-objective machine learning algorithm which combines the stacked single-target method with extreme gradient boosting to build multi-objective models of performance and energy. The models can be used to predict the optimal processor and memory powercap settings, helping compute nodes perform fine-grained powercap allocation. When the optimal powercap configuration is determined, the uncore frequency scaling is used to further optimize the energy consumption. Compared with the reference powercap configuration, the predicted optimal configurations predicted by our method can achieve an average powercap reduction of 31.35 percent, an average energy reduction of 12.32 percent, and average performance degradation of only 2.43 percent.},
  keywords={},
  doi={10.1109/TPDS.2020.3045983},
  ISSN={1558-2183},
  month={July},}
@ARTICLE{9309265,
  author={Sfeir, Elie and Mitra, Rangeet and Kaddoum, Georges and Bhatia, Vimal},
  journal={IEEE Communications Letters}, 
  title={Performance Analysis of Maximum-Correntropy Based Detection for SCMA}, 
  year={2021},
  volume={25},
  number={4},
  pages={1114-1118},
  abstract={Non-orthogonal multiple access (NOMA) has emerged as a promising multiple-access technique capable of accommodating many users over limited time-frequency resources. Among several NOMA techniques, sparse code multiple access (SCMA) has emerged as viable due to its promise of high coding-gain by appropriate codebook-design and simplistic detection using message-passing algorithm (MPA). However, the performance of classic SCMA based systems are severely impaired by impulsive noise (IN), which causes outages and therefore non-negligible degradations to the bit-error-rate (BER) performance. Exploiting the robustness of the maximum correntropy criterion (MCC) to non-Gaussian noise processes, an MPA based detector is formulated with message-functions derived from the MCC criterion. Based on the said MCC criterion, concurrent-adaptation of the MCC’s spread-parameter is proposed in this letter. Lastly, analytical results for the proposed approach’s BER performance are presented with corresponding validation by computer-simulations.},
  keywords={},
  doi={10.1109/LCOMM.2020.3047782},
  ISSN={1558-2558},
  month={April},}
@ARTICLE{9321696,
  author={Kayraklioglu, Engin and Favry, Erwan and El-Ghazawi, Tarek},
  journal={IEEE Transactions on Parallel and Distributed Systems}, 
  title={A Machine-Learning-Based Framework for Productive Locality Exploitation}, 
  year={2021},
  volume={32},
  number={6},
  pages={1409-1424},
  abstract={Data locality is of extreme importance in programming distributed-memory architectures due to its implications on latency and energy consumption. Automated compiler and runtime system optimization studies have attempted to improve data locality exploitation without burdening the programmer. However, due to the difficulty of static code analysis, conservatism in compiler optimizations to avoid errors, and cost of dynamic analysis, the efficacy of automated optimizations is limited. Therefore, programmers need to spend significant effort in optimizing locality while creating applications for distributed memory parallel systems. We present a machine-learning based framework to automatically exploit locality in distributed memory applications. This framework takes application source whose time-critical blocks are marked by pragmas, and produces optimized source code that uses a regressor for efficient data movement. The regressor is trained with automatically-collected application profiles with very small input data sizes. We integrate our prototype in the Chapel language stack. In our experiments, we show that the Elastic Net model is the ideal regressor for our case and applications that utilize Elastic Net can perform very similarly to programmer-optimized versions. We also show that such regressors can be trained within few minutes on a cluster or within 30 minutes on a workstation, including data collection.},
  keywords={},
  doi={10.1109/TPDS.2021.3051348},
  ISSN={1558-2183},
  month={June},}
@ARTICLE{9343251,
  author={George, Anjus and Ravindran, Arun and Mendieta, Matías and Tabkhi, Hamed},
  journal={IEEE Access}, 
  title={Mez: An Adaptive Messaging System for Latency-Sensitive Multi-Camera Machine Vision at the IoT Edge}, 
  year={2021},
  volume={9},
  number={},
  pages={21457-21473},
  abstract={Mez is a novel publish-subscribe messaging system for latency sensitive multi-camera machine vision applications at the IoT Edge. The unlicensed wireless communication in IoT Edge systems are characterized by large latency variations due to intermittent channel interference. To achieve user specified latency in the presence of wireless channel interference, Mez takes advantage of the ability of machine vision applications to temporarily tolerate lower quality video frames if overall application accuracy is not too adversely affected. Control knobs that involve lossy image transformation techniques that modify the frame size, and thereby the video frame transfer latency, are identified. Mez implements a network latency feedback controller that adapts to channel conditions by dynamically adjusting the video frame quality using the image transformation control knobs, so as to simultaneously satisfy latency and application accuracy requirements. Additionally, Mez uses an application domain specific design of the storage layer to provide low latency operations. Experimental evaluation on an IoT Edge testbed with a pedestrian detection machine vision application indicates that Mez is able to tolerate latency variations of up to 10x with a worst-case reduction of 4.2% of the application accuracy F1 score metric. The performance of Mez is also experimentally evaluated against state-of-the-art low latency NATS messaging system.},
  keywords={},
  doi={10.1109/ACCESS.2021.3055775},
  ISSN={2169-3536},
  month={},}
@ARTICLE{9345722,
  author={Abdi, Younes and Ristaniemi, Tapani},
  journal={IEEE Transactions on Communications}, 
  title={Modeling and Mitigating Errors in Belief Propagation for Distributed Detection}, 
  year={2021},
  volume={69},
  number={5},
  pages={3286-3297},
  abstract={We study the behavior of the belief-propagation (BP) algorithm affected by erroneous data exchange in a wireless sensor network (WSN). The WSN conducts a distributed multidimensional hypothesis test over binary random variables. The joint statistical behavior of the sensor observations is modeled by a Markov random field whose parameters are used to build the BP messages exchanged between the sensing nodes. Through linearization of the BP message-update rule, we analyze the behavior of the resulting erroneous decision variables and derive closed-form relationships that describe the impact of stochastic errors on the performance of the BP algorithm. We then develop a decentralized distributed optimization framework to enhance the system performance by mitigating the impact of errors via a distributed linear data-fusion scheme. Finally, we compare the results of the proposed analysis with the existing works and visualize, via computer simulations, the performance gain obtained by the proposed optimization.},
  keywords={},
  doi={10.1109/TCOMM.2021.3056679},
  ISSN={1558-0857},
  month={May},}
@INPROCEEDINGS{9352856,
  author={Saha, Dibakar and Mandal, Partha Sarathi},
  booktitle={2021 International Conference on COMmunication Systems & NETworkS (COMSNETS)}, 
  title={A Distributed Algorithm for Overlapped Community Detection in Large-Scale Networks}, 
  year={2021},
  volume={},
  number={},
  pages={483-491},
  abstract={Overlapped community detection in social networks has become an important research area with the increasing popularity and complexity of the networks. Most of the existing solutions are either centralized or parallel algorithms, which are computationally intensive - require complete knowledge of the entire network. But it isn't easy to collect entire network data because the size of the actual network may be prohibitively large. It may result from either privacy concerns (users of a social network may be unwilling to reveal their social links) or technological impediments (implementation of an efficient web crawler). Performing in-network computation solves both problems utilizing the computational capability of the individual nodes of the network. Simultaneously, nodes communicate and share data with their neighbours via message passing, which may go a long way toward mitigating individual nodes' privacy concerns in the network. All the concerns mentioned above motivated us to design a decentralized or distributed technique to detect overlapped communities in a large-scale network. It is desirable because this technique does not offer a single point of failure, and the system as a whole can continue to function even when many of the nodes fail. To overcome the disadvantages of the existing solutions, in this paper, we address the overlapped community detection problem for large-scale networks. We present an efficient distributed algorithm, named DOCD, to identify the overlapped communities in the network. The efficiency of DOCD algorithm is verified with extensive simulation study on some networks such as, Dolphin, Zachary karate club, Football club, and Facebook ego networks. We show that DOCD algorithm is capable of keeping the asymptotically same results with the existing classical centralized algorithms [1]-[5] in terms of community modularity and the number of identified communities. The DOCD algorithm can also efficiently identify the overlapped nodes and overlapped communities with a small number of rounds of communication and computation.},
  keywords={},
  doi={10.1109/COMSNETS51098.2021.9352856},
  ISSN={2155-2509},
  month={Jan},}
@ARTICLE{9358173,
  author={Akbari, Amir and Giannacopoulos, Dennis D.},
  journal={IEEE Transactions on Magnetics}, 
  title={Efficient Solver for a Simplified Model of the Multi-Physics Heat Transfer Problem in Radio Frequency Ablation of Hepatic Tumors}, 
  year={2021},
  volume={57},
  number={6},
  pages={1-4},
  abstract={Mathematical modeling and computer simulation of heat transfer in the liver play a key role in prediction of radio frequency ablation outcome. While multi-physics modeling should be used for accurate simulation of heat transfer in a highly perfused organ like the liver, the computational cost of such a problem could have a negative impact on the simulation time. This article extends a highly parallel finite element-based method to simulate the multi-physics heat transfer problem in the liver efficiently. A message passing interface (MPI)-based strong coupling method is developed and tested on cluster nodes. The scalability of this work is assessed by performing simulations on up to 1024 cores.},
  keywords={},
  doi={10.1109/TMAG.2021.3060628},
  ISSN={1941-0069},
  month={June},}
@ARTICLE{9359736,
  author={Kulhandjian, Michel and Kulhandjian, Hovannes and D’amours, Claude and Hanzo, Lajos},
  journal={IEEE Access}, 
  title={Low-Density Spreading Codes for NOMA Systems and a Gaussian Separability-Based Design}, 
  year={2021},
  volume={9},
  number={},
  pages={33963-33993},
  abstract={Improved low-density spreading (LDS) code designs based on the Gaussian separability criterion are conceived. We show that the bit error rate (BER) hinges not only on the minimum distance criterion, but also on the average Gaussian separability margin. If two code sets have the same minimum distance, the code set having the highest Gaussian separability margin will lead to a lower BER. Based on the latter criterion, we develop an iterative algorithm that converges to the best known solution having the lowest BER. Our improved LDS code set outperforms the existing LDS designs in terms of its BER performance both for binary phase-shift keying (BPSK) and for quadrature amplitude modulation (QAM) transmissions. Furthermore, we use an appallingly low-complexity minimum mean-square estimation (MMSE) and parallel interference cancellation (PIC) (MMSE-PIC) technique, which is shown to have comparable BER performance to the potentially excessive-complexity maximum-likelihood (ML) detector. This MMSE-PIC algorithm has a much lower computational complexity than the message passing algorithm (MPA).Code sets for MPA are designed similar to low-density parity-check (LDPC) codes to avoid cycles and to increase girth of the Tanner graph, code sets that are “optimal” for MMSE-PIC might not be optimal for MPA.},
  keywords={},
  doi={10.1109/ACCESS.2021.3060879},
  ISSN={2169-3536},
  month={},}
@ARTICLE{9366805,
  author={Wei, Li and Huang, Chongwen and Alexandropoulos, George C. and Yuen, Chau and Zhang, Zhaoyang and Debbah, Mérouane},
  journal={IEEE Transactions on Communications}, 
  title={Channel Estimation for RIS-Empowered Multi-User MISO Wireless Communications}, 
  year={2021},
  volume={69},
  number={6},
  pages={4144-4157},
  abstract={Reconfigurable Intelligent Surfaces (RISs) have been recently considered as an energy-efficient solution for future wireless networks due to their fast and low-power configuration, which has increased potential in enabling massive connectivity and low-latency communications. Accurate and low-overhead channel estimation in RIS-based systems is one of the most critical challenges due to the usually large number of RIS unit elements and their distinctive hardware constraints. In this paper, we focus on the uplink of a RIS-empowered multi-user Multiple Input Single Output (MISO) uplink communication systems and propose a channel estimation framework based on the parallel factor decomposition to unfold the resulting cascaded channel model. We present two iterative estimation algorithms for the channels between the base station and RIS, as well as the channels between RIS and users. One is based on alternating least squares (ALS), while the other uses vector approximate message passing to iteratively reconstruct two unknown channels from the estimated vectors. To theoretically assess the performance of the ALS-based algorithm, we derived its estimation Cramér-Rao Bound (CRB). We also discuss the downlink achievable sum rate computation with estimated channels and different precoding schemes for the base station. Our extensive simulation results show that our algorithms outperform benchmark schemes and that the ALS technique achieves the CRB. It is also demonstrated that the sum rate using the estimated channels always reach that of perfect channels under various settings, thus, verifying the effectiveness and robustness of the proposed estimation algorithms.},
  keywords={},
  doi={10.1109/TCOMM.2021.3063236},
  ISSN={1558-0857},
  month={June},}
@INPROCEEDINGS{9417577,
  author={Jiang, Xianbo and Wang, Shengchu},
  booktitle={2021 IEEE Wireless Communications and Networking Conference (WCNC)}, 
  title={Three-Dimensional Cooperative Positioning for VANETs with AOA Measurements}, 
  year={2021},
  volume={},
  number={},
  pages={1-6},
  abstract={In this paper, positioning performances of vehicular ad-hoc networks (VANETs) are significantly enhanced by cooperative localization (CL) based on the three dimensional (3D) angle-of-arrival (AOA) measurements. Localizers are proposed based on generalized approximate message passing (GAMP), which works under (un-)known Euler rotation angles, and π/2π-periodic azimuth AOAs. Firstly, when the Euler angles are known, GAMP localizer is obtained by categorizing the AOACL problem as a generalized linear mixing one, and then resolved by GAMP, whose mean-and-variance messages involving 3D AOAs are evaluated by importance sampling technique. Secondly, when the Euler angles are unknown, the expectation maximization (EM) framework is combined with GAMP, where vehicle positions and Euler angles are alternatively updated through one-step GAMP iteration and maximizing conditional probability distribution functions (pdfs) expected over hybrid variables, which are obtained by subtracting the xyz position of the vehicle receiving measurements with the position of its pairing neighbor, respectively. Simulation results validate that the proposed localizers outperform existing localizers. Positioning accuracy can be significantly enhanced compared with global navigation satellite system (GNSS).},
  keywords={},
  doi={10.1109/WCNC49053.2021.9417577},
  ISSN={1558-2612},
  month={March},}
@INPROCEEDINGS{9417571,
  author={Yang, Chuang and Tang, Leiming and Wang, Zheng},
  booktitle={2021 IEEE Wireless Communications and Networking Conference (WCNC)}, 
  title={Enhanced Channel Hardening-Exploiting Message Passing Algorithm For Large-scale MIMO Detection}, 
  year={2021},
  volume={},
  number={},
  pages={1-5},
  abstract={In this paper, the enhanced channel hardening-exploiting message passing (ECHEMP) algorithm is proposed for large-scale MIMO detection to improve the decoding performance with less complexity cost, so as to a better decoding tradeoff. Specifically, the proposed algorithm consists of two stages. In the first stage, to enhance the convergence performance of the iterative detection symbols estimation, we propose to use the discrete Gaussian distribution rather than the uniform one as the default initial probability distribution, and give the initial estimation as the mean of the discrete Gaussian distribution under channel hardening phenomenon. In the second stage, compared to iterative calculations of all detection symbols, the number of calculations of detection symbols in the iterative process is reduced through a probability threshold, which efficiently reduces computational complexity. Finally, simulation results about MIMO detection are presented to verify the performance improvement and the complexity reduction.},
  keywords={},
  doi={10.1109/WCNC49053.2021.9417571},
  ISSN={1558-2612},
  month={March},}
@INPROCEEDINGS{9417121,
  author={Wei, Li and Huang, Chongwen and Alexandropoulos, George C. and Yang, Zhaohui and Yuen, Chau and Zhang, Zhaoyang},
  booktitle={2021 IEEE Wireless Communications and Networking Conference (WCNC)}, 
  title={Joint Channel Estimation and Signal Recovery in RIS-Assisted Multi-User MISO Communications}, 
  year={2021},
  volume={},
  number={},
  pages={1-6},
  abstract={Reconfigurable Intelligent Surfaces (RISs) have been recently considered as an energy-efficient solution for future wireless networks. Their dynamic and low-power configuration enables coverage extension, massive connectivity, and low-latency communications. Channel estimation and signal recovery in RIS-based systems are among the most critical technical challenges, due to the large number of unknown variables referring to the RIS unit elements and the transmitted signals. In this paper, we focus on the downlink of a RIS-assisted multi-user Multiple Input Single Output (MISO) communication system and present a joint channel estimation and signal recovery scheme based on the PARAllel FACtor (PARAFAC) decomposition. This decomposition unfolds the cascaded channel model and facilitates signal recovery using the Bilinear Generalized Approximate Message Passing (BiG-AMP) algorithm. The proposed method includes an alternating least squares algorithm to iteratively estimate the equivalent matrix, which consists of the transmitted signals and the channels between the base station and RIS, as well as the channels between the RIS and the multiple users. Our selective simulation results show that the proposed scheme outperforms a benchmark scheme that uses genie-aided information knowledge. We also provide insights on the impact of different RIS parameter settings on the proposed scheme.},
  keywords={},
  doi={10.1109/WCNC49053.2021.9417121},
  ISSN={1558-2612},
  month={March},}
@ARTICLE{9435018,
  author={Chapp, Dylan and Tan, Nigel and Bhowmick, Sanjukta and Taufer, Michela},
  journal={IEEE Transactions on Parallel and Distributed Systems}, 
  title={Identifying Degree and Sources of Non-Determinism in MPI Applications Via Graph Kernels}, 
  year={2021},
  volume={32},
  number={12},
  pages={2936-2952},
  abstract={As the scientific community prepares to deploy an increasingly complex and diverse set of applications on exascale platforms, the need to assess reproducibility of simulations and identify the root causes of reproducibility failures increases correspondingly. One of the greatest challenges facing reproducibility issues at exascale is the inherent non-determinism at the level of inter-process communication. The use of non-deterministic communication constructs is necessary to boost performance, but communication non-determinism can also hamper software correctness and result reproducibility. To address this challenge, we propose a software framework for identifying the percentage and sources of communication non-determinism. We model parallel executions as directed graphs and leverage graph kernels to characterize run-to-run variations in inter-process communication. We demonstrate the effectiveness of graph kernel similarity as a proxy for non-determinism, by showing that these kernels can quantify the type and degree of non-determinism present in communication patterns. To demonstrate our framework’s ability to link and quantify runtime non-determinism to root sources, demonstrate with present for an adaptive mesh refinement application, where our framework automatically quantifies the impact of function calls on non-determinism, and a Monte Carlo application, where our framework automatically quantifies the impact of parameter configurations on non-determinism.},
  keywords={},
  doi={10.1109/TPDS.2021.3081530},
  ISSN={1558-2183},
  month={Dec},}
@INPROCEEDINGS{9440148,
  author={Bagies, Taghreed and Jannesari, Ali},
  booktitle={2021 IEEE International Conference on Software Testing, Verification and Validation Workshops (ICSTW)}, 
  title={An Empirical Study of Parallelizing Test Execution Using CUDA Unified Memory and OpenMP GPU Offloading}, 
  year={2021},
  volume={},
  number={},
  pages={271-278},
  abstract={The execution of software testing is costly and time-consuming. To accelerate the test execution, researchers have applied several methods to run the testing in parallel. One method of parallelizing the test execution is by using a GPU to distribute test inputs among several threads running in parallel. In this paper, we investigate three programming models CUDA Unified Memory, CUDA Non-Unified Memory, and OpenMP GPU offloading to parallelize the test execution and discuss the challenges using these programming models. We use eleven benchmarks and parallelize their test suites by using these models. Our study shows some limitations (e.g. cache size, branch divergence, and load imbalance) when using GPUs to execute the testing in parallel.},
  keywords={},
  doi={10.1109/ICSTW52544.2021.00052},
  ISSN={},
  month={April},}
@ARTICLE{9446137,
  author={Liu, Lei and Liang, Chulong and Ma, Junjie and Ping, Li},
  journal={IEEE Transactions on Information Theory}, 
  title={Capacity Optimality of AMP in Coded Systems}, 
  year={2021},
  volume={67},
  number={7},
  pages={4429-4445},
  abstract={This paper studies a large random matrix system (LRMS) model involving an arbitrary signal distribution and forward error control (FEC) coding. We establish an area property based on the approximate message passing (AMP) algorithm. Under the assumption that the state evolution for AMP is correct for the coded system, the achievable rate of AMP is analyzed. We prove that AMP achieves the constrained capacity of the LRMS with an arbitrary signal distribution provided that a matching condition is satisfied. As a byproduct, we provide an alternative derivation for the constraint capacity of an LRMS using a proved property of AMP. We discuss realization techniques for the matching principle of binary signaling using irregular low-density parity-check (LDPC) codes and provide related numerical results. We show that the optimized codes demonstrate significantly better performance over un-matched ones under AMP. For quadrature phase shift keying (QPSK) modulation, bit error rate (BER) performance within 1 dB from the constrained capacity limit is observed.},
  keywords={},
  doi={10.1109/TIT.2021.3083748},
  ISSN={1557-9654},
  month={July},}
@ARTICLE{9448496,
  author={Yan, Dapeng and Cao, Hui and Wang, Tao and Chen, Ruilin and Xue, Shuangsi},
  journal={IEEE Transactions on Artificial Intelligence}, 
  title={Graph-Based Knowledge Acquisition With Convolutional Networks for Distribution Network Patrol Robots}, 
  year={2021},
  volume={2},
  number={5},
  pages={384-393},
  abstract={With the popularization of smart grids, patrol robots have become critical devices in the distribution networks to check the state of equipment. In order to enrich the knowledge of patrol robots in this complex scenario, this article presents the graph-based knowledge acquisition method with convolutional networks for distribution network patrol robots. The proposed method uses a graph convolutional network-based path-related embedding algorithm to complete the knowledge of the distribution network knowledge graph. The proposed algorithm generates the embeddings of entities and relations through aggregating the associated entities in the associated paths, instead of only the connected entities. The graph convolutional network consists of multiple graph convolution layers, and the message-passing process treats different entities discriminatorily according to the association strengths. For determining the plausibility of the knowledge, a scoring function is provided with the convolution operator. The experimental datasets are from a real grid company and contain four kinds of equipment. The experiments apply the proposed method to the equipment defects analysis, including the defect gradation, the coarse defect classification, and the fine defect classification. The proposed method is compared with some embedding methods. The experimental results verify that the proposed method outperforms the other methods for the real distribution network datasets, and the proposed method can analyze the defects effectively.},
  keywords={},
  doi={10.1109/TAI.2021.3087116},
  ISSN={2691-4581},
  month={Oct},}
@INPROCEEDINGS{9445916,
  author={Li, Mingliang and Pang, Jianmin and Yue, Feng and Wang, Qihan},
  booktitle={2021 International Conference on Communications, Information System and Computer Engineering (CISCE)}, 
  title={OpenMP automatic translation framework for Sunway TaihuLight}, 
  year={2021},
  volume={},
  number={},
  pages={400-404},
  abstract={The Sunway processor is a unique heterogeneous many-core processor used by Sunway TaihuLight supercomputer. However, developing parallel programs on the Sunway processor is still complex. In this paper, a source-to-source translation framework for the Sunway heterogeneous many-core processors is designed and implemented, which can transform OpenMP programs into many-core accelerated programs amenable to the Sunway architecture. Considering differences between the OpenMP shared-memory programming model and the Sunway programming model, a translation model has been proposed for converting OpenMP programs. A set of runtime functions based on the Sunway architecture has been implemented, including a tree-based reduction algorithm and an effective distributed lock mechanism. The experimental results show that the translation framework can correctly translate OpenMP programs, and the proposed lock mechanism reduces the overhead by up to 90% against the baseline.},
  keywords={},
  doi={10.1109/CISCE52179.2021.9445916},
  ISSN={},
  month={May},}
@INPROCEEDINGS{9455331,
  author={Li, Yuansheng and Wei, Ping and Chen, Yiqi and Wei, Yifan and Zhang, Huaguo},
  booktitle={2021 IEEE Radar Conference (RadarConf21)}, 
  title={Message passing based extended objects tracking with measurement rate and extension estimation}, 
  year={2021},
  volume={},
  number={},
  pages={1-6},
  abstract={This paper addresses the problem of multiple extended objects (EOs) tracking, which has attracted increasing attention recently due to the developments of high-resolution sensors. Specifically, the state of an EO is modeled by the Gamma-Gaussian-inverse-Wishart (GGIW) distribution, and the message passing inference method, which provides a high efficient implementation for multi-target tracking, is adopted to propagate the posterior of the distributions of multiple EOs. The performance of proposed method is verified via simulation experiments.},
  keywords={},
  doi={10.1109/RadarConf2147009.2021.9455331},
  ISSN={2375-5318},
  month={May},}
@INPROCEEDINGS{9460577,
  author={Fan, Ke and Micinski, Kristopher and Gilray, Thomas and Kumar, Sidharth},
  booktitle={2021 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)}, 
  title={Exploring MPI Collective I/O and File-per-process I/O for Checkpointing a Logical Inference Task}, 
  year={2021},
  volume={},
  number={},
  pages={965-972},
  abstract={We present a scalable parallel I/O system for a logical-inferencing application built atop a deductive database. Deductive databases can make logical deductions (i.e. conclude additional facts), based on a set of program rules, derived from facts already in the database. Datalog is a language or family of languages commonly used to specify rules and queries for a deductive database. Applications built using Datalog can range from graph mining (such as computing transitive closure or k-cliques) to program analysis (control and data-flow analysis). In our previous papers, we presented the first implementation of a data-parallel Datalog built using MPI. In this paper, we present a parallel I/O system used to checkpoint and restart applications built on top of our Datalog system. State of the art Datalog implementations, such as Soufflé, only support serial I/O, mainly because the implementation itself does not support many-node parallel execution.Computing the transitive closure of a graph is one of the simplest logical-inferencing applications built using Datalog; we use it as a micro-benchmark to demonstrate the efficacy of our parallel I/O system. Internally, we use a nested B-tree data-structure to facilitate fast and efficient in-memory access to relational data. Our I/O system therefore involves two steps, converting the application data-layout (a nested B-tree) to a stream of bytes followed by the actual parallel I/O. We explore two popular I/O techniques POSIX I/O and MPI collective I/O. For extracting performance out of MPI Collective I/O we use adaptive striping, and for POSIX I/O we use file-per-process I/O. We demonstrate the scalability of our system at up to 4,096 processes on the Theta supercomputer at the Argonne National Laboratory.},
  keywords={},
  doi={10.1109/IPDPSW52791.2021.00153},
  ISSN={},
  month={June},}
@INPROCEEDINGS{9460611,
  author={Bağbaba, Ayşe and Wang, Xuan},
  booktitle={2021 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)}, 
  title={Improving the MPI-IO Performance of Applications with Genetic Algorithm based Auto-tuning}, 
  year={2021},
  volume={},
  number={},
  pages={798-805},
  abstract={Parallel I/O is an essential part of scientific applications running on high-performance computing systems. Understanding an application’s parallel I/O behavior and identifying sources of performance bottlenecks require a multi-layer view of the I/O. Typical parallel I/O stack layers offer many tunable parameters that can achieve the best possible I/O performance. However, scientific users do often not have the time nor the experience for investigating the proper combination of these parameters for each application use-case. Auto-tuning can help users by automatically tuning I/O parameters at various layers transparently. In auto-tuning, using naïve strategy, running an application by trying all possible combinations of tunable parameters for all layers of the I/O stack to find the best settings is an exhaustive search through the huge parameter space. This strategy is infeasible because of the long execution times of trial runs. In this paper, we propose a genetic algorithm-based parallel I/O auto-tuning approach that can hide the complexity of the I/O stack from users and auto-tune a set of parameter values for an application on a given system to improve the I/O performance. In particular, our approach tests a set of parameters and then, modifies the combination of these parameters for further testing based on the I/O performance. We have validated our model using two I/O benchmarks, namely IOR and MPI-Tile-IO. We achieved an increase in I/O bandwidth of up to 7.74×over the default parameters for IOR and 5.59×over the default parameters for MPI-Tile-IO.},
  keywords={},
  doi={10.1109/IPDPSW52791.2021.00118},
  ISSN={},
  month={June},}
@INPROCEEDINGS{9460632,
  author={Nakajima, Kengo and Ogita, Takseshi and Kawai, Masatoshi},
  booktitle={2021 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)}, 
  title={Efficient Parallel Multigrid Methods on Manycore Clusters with Double/Single Precision Computing}, 
  year={2021},
  volume={},
  number={},
  pages={760-769},
  abstract={The parallel multigrid method is expected to play an important role in scientific computing on exa-scale supercomputer systems for solving large-scale linear equations with sparse coefficient matrices. Because solving sparse linear systems is a very memory-bound process, efficient method for storage of coefficient matrices is a crucial issue. In the previous works, authors implemented sliced ELL method to parallel conjugate gradient solvers with multigrid preconditioning (MGCG) for the application on 3D groundwater flow through heterogeneous porous media (pGW3D-LVM), and excellent performance has been obtained on large-scale multicore/manycore clusters. In the present work, authors introduced SELL-C-σ with double/single precision computing to the MGCG solver, and evaluated the performance of the solver with OpenMP/MPI hybrid parallel programing models on the Oakforest-PACS (OLP) system at JCAHPC using up to 2,048 nodes of Intel Xeon Phi. Because SELL-C-σ is suitable for wide-SIMD architecture, such as Xeon Phi, improvement of the performance over the sliced ELL was more than 35% for double precision and more than 45% for single precision on OFP. Finally, accuracy verification was conducted based on the method proposed by authors for solving linear equations with sparse coefficient matrices with M-property.},
  keywords={},
  doi={10.1109/IPDPSW52791.2021.00114},
  ISSN={},
  month={June},}
@INPROCEEDINGS{9460650,
  author={Sasidharan, Aparna},
  booktitle={2021 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)}, 
  title={Performance Models for Hybrid Programs Accelerated by GPUs}, 
  year={2021},
  volume={},
  number={},
  pages={641-651},
  abstract={This paper describes the use of statistical tools to model the performance of mixed device (hosts and devices) programs where hosts are CPUs and devices are GPUs. The purpose of GPUs is to accelerate compute-intensive sections of a program, thereby reducing total execution time, with side-effects including reduced machine usage and energy consumption. To model major and minor factors that affect the execution time of offloaded programs, we used a compute-intensive program with several GPU kernels. We have abstracted the hybrid program as a sequence of computations that access various types of memories (device caches, device shared memory, memory of other devices and host memory). In the programming model discussed, the role of a host is reduced to scheduling and coordinating execution of kernels across devices and communicating with other hosts. It can be extended to models where hosts perform computations or are obliterated. Experiments were designed to include a range of memory sizes and types. The performance models were trained, and their predictions were verified using test data.},
  keywords={},
  doi={10.1109/IPDPSW52791.2021.00098},
  ISSN={},
  month={June},}
@INPROCEEDINGS{9460498,
  author={Yu, Lechen and Protze, Joachim and Hernandez, Oscar and Sarkar, Vivek},
  booktitle={2021 IEEE International Parallel and Distributed Processing Symposium (IPDPS)}, 
  title={ARBALEST: Dynamic Detection of Data Mapping Issues in Heterogeneous OpenMP Applications}, 
  year={2021},
  volume={},
  number={},
  pages={464-474},
  abstract={From OpenMP 4.0 onwards, programmers can offload code regions to accelerators by using the target offloading feature. However, incorrect usage of target offloading constructs may incur data mapping issues. A data mapping issue occurs when the host fails to observe updates on the accelerator or vice versa. It may further lead to multiple memory issues such as use of uninitialized memory, use of stale data, and data race. To the best of our knowledge, currently there is no prior work on dynamic detection of data mapping issues in heterogeneous OpenMP applications.In this paper, we identify possible root causes of data mapping issues in OpenMP's standard memory model and the unified memory model. We find that data mapping issues primarily result from incorrect settings of map and nowait clauses in target offloading constructs. Further, the novel unified memory model introduced in OpenMP 5.0 cannot avoid the occurrence of data mapping issues. To mitigate the difficulty of detecting data mapping issues, we propose ARBALEST, an on-the-fly data mapping issue detector for OpenMP applications. For each variable mapped to the accelerator, ARBALEST's detection algorithm leverages a state machine to track the last write's visibility. ARBALEST requires constant storage space for each memory location and takes amortized constant time per memory access. To demonstrate ARBALEST's effectiveness, an experimental comparison with four other dynamic analysis tools (Valgrind, Archer, AddressSanitizer, MemorySanitizer) has been carried out on a number of open-source benchmark suites. The evaluation results show that ARBALEST delivers demonstrably better precision than the other four tools, and its execution time overhead is comparable to that of state-of-the-art dynamic analysis tools.},
  keywords={},
  doi={10.1109/IPDPS49936.2021.00055},
  ISSN={1530-2075},
  month={May},}
@INPROCEEDINGS{9474070,
  author={Hamad, Mohammad and Regnath, Emanuel and Lauinger, Jan and Prevelakis, Vassilis and Steinhorst, Sebastian},
  booktitle={2021 Design, Automation & Test in Europe Conference & Exhibition (DATE)}, 
  title={SPPS: Secure Policy-based Publish/Subscribe System for V2C Communication}, 
  year={2021},
  volume={},
  number={},
  pages={529-534},
  abstract={The Publish/Subscribe (Pub/Sub) pattern is an attractive paradigm for supporting Vehicle to Cloud (V2C) communication. However, the security threats on confidentiality, integrity, and access control of the published data challenge the adoption of the Pub/Sub model. To address that, our paper proposes a secure policy-based Pub/Sub model for V2C communication, which allows to encrypt and control the access to messages published by vehicles. A vehicle encrypts messages with a symmetric key while saving the key in distributed shares on semi-honest services, called KeyStores, using the concept of secret sharing. The security policy, generated by the same vehicle, authorizes certain cloud services to obtain the shares from the KeyStores. Here, granting access rights takes place without violating the decoupling requirement of the Pub/Sub model. Experimental results show that, besides the end-to-end security protection, our proposed system introduces significantly less overhead (almost 70% less) than the state-of-the-art approach SSL when reestablishing connections, which is a common scenario in the V2C context due to unreliable network connection.},
  keywords={},
  doi={10.23919/DATE51398.2021.9474070},
  ISSN={1558-1101},
  month={Feb},}
@INPROCEEDINGS{9499495,
  author={Parasyris, Konstantinos and Georgakoudis, Giorgis and Bautista-Gomez, Leonardo and Laguna, Ignacio},
  booktitle={2021 IEEE/ACM 21st International Symposium on Cluster, Cloud and Internet Computing (CCGrid)}, 
  title={Co-Designing Multi-Level Checkpoint Restart for MPI Applications}, 
  year={2021},
  volume={},
  number={},
  pages={103-112},
  abstract={HPC systems continue to scale by including more hardware components for supporting larger application deployments. Critically, this scaling tends to decrease the mean time between failures, thus renders fault tolerance an increasingly important challenge. The standard practice in HPC for fault tolerance is checkpoint/restart. There have been significant but separate efforts to create fast application-layer checkpoint recovery techniques and fast recovery techniques at the MPI layer. However, those techniques operate in isolation and although they presuppose each other they have not been designed to jointly optimize end-to-end application recovery.We present FRAME, a fault-tolerance solution that significantly reduces application recovery time by combining, for the first time, an asynchronous multi-level checkpoint library, called Fault Tolerant Interface (FTI), with an online, fault tolerance solution for MPI, called Reinit. Our approach co-designs optimizations that speed up application recovery. Specifically, FRAME leverages the Reinit-enabled MPI to extract the topology of failures and optimize checkpoint retrieval in FTI to save significant overhead from identifying and fetching the most recent available checkpoint in the system. FRAME optimization reduces the time to retrieve checkpoints up to 67% when compared with baseline FTI. Results that include Reinit-based recovery for MPI show that our approach reduces end-to-end recovery time up to 360% when recovering 1.3 TB of checkpointed data in a large scale execution deployment of 32,768 MPI ranks.},
  keywords={},
  doi={10.1109/CCGrid51090.2021.00020},
  ISSN={},
  month={May},}
@INPROCEEDINGS{9499420,
  author={Xie, Bing and Tang, Houjun and Byna, Suren and Hanley, Jesse and Koziol, Quincey and Li, Tonglin and Oral, Sarp},
  booktitle={2021 IEEE/ACM 21st International Symposium on Cluster, Cloud and Internet Computing (CCGrid)}, 
  title={Battle of the Defaults: Extracting Performance Characteristics of HDF5 under Production Load}, 
  year={2021},
  volume={},
  number={},
  pages={51-60},
  abstract={Popular parallel I/O libraries, such as HDF5, provide tuning parameters to obtain superior performance. However, the selection of effective parameters on production systems is complex due to the interdependence of I/O software and file system layers. Hence, application developers typically use the default parameters and often experience poor I/O performance. This work conducts a benchmarking-based analysis on the HDF5 behaviors with a wide variety of I/O patterns to extract performance characteristics under the production workload. To make the analysis well controlled, we exercise I/O benchmarks on POSIX-IO, MPI-IO, and HDF5 using the same I/O patterns and in the same jobs. To address high performance variability in production environments, we repeat the benchmarks across I/O patterns, storage devices, and time intervals. Based on the results, we identified consistent HDF5 behaviors that appropriate configurations and operations on dataset layout and file-metadata placement can improve performance significantly. We apply our findings and evaluate the tuned I/O library on two supercomputers: Summit and Cori. The results show that our tuned parameters can achieve more than 10× I/O performance speedup than that with default parameters on both systems, suggesting the effectiveness, stability, and generality of our solution.},
  keywords={},
  doi={10.1109/CCGrid51090.2021.00015},
  ISSN={},
  month={May},}
@INPROCEEDINGS{9511992,
  author={Jia, Zheng Lang and Wang, Pan Pan and Zhang, Huan Huan and Ding, Da Zhi},
  booktitle={2021 13th Global Symposium on Millimeter-Waves & Terahertz (GSMM)}, 
  title={Electromagnetic-Circuital-Thermal Multiphysics Simulation Based on DGTD and FETD Method with Higher-Order Basis Functions}, 
  year={2021},
  volume={},
  number={},
  pages={1-1},
  abstract={With the continuous improvement of the technological level of integrated circuits (ICs), the operating frequency and integration density are becoming higher and higher, which brings huge challenges to the simulation of integrated circuits. On one hand, the wave effect becomes noticeable as the working frequency increases. For instance, the electromagnetic coupling between the interconnects and package will lead to the signal integrity problem. In this situation, the simulation accuracy cannot be guaranteed if only the classical circuit theory is adopted. Therefore, full-wave electromagnetic simulation method must be included to implement electromagnetic-circuital cosimulation. On the other hand, high integration level will not only raise the density of the devices and interconnects, but also increase the power density, resulting in difficulties in thermal management. As a result, the mutual effects between EM and thermal must also be taken into account. To sum up, the electromagnetic-circuital-thermal multiphysics simulation becomes necessary and significant in the design of ICs. In this paper, an electromagnetic-thermal co-simulation method based on discontinuous Galerkin time-domain (DGTD) method and finite-element time-domain (FETD) method with higher order basis functions is proposed. The DGTD method is utilized for EM simulation [2], while the FETD method is adopted for thermal simulation [3]-[5]. The higher order hierachical basis function is utilized to decrease the mesh density and reduce the number of spatial unknowns. The large-scale parallel computing technique based on message passing interface (MPI) is employed to accelerate both the DGTD and FETD algorithm. Numerical examples are computed on distributed clusters to validate the accuracy and efficiency of the proposed method.},
  keywords={},
  doi={10.1109/GSMM53250.2021.9511992},
  ISSN={2694-2968},
  month={May},}
@INPROCEEDINGS{9513757,
  author={van Erp, Bart and Şenöz, İsmail and de Vries, Bert},
  booktitle={2021 IEEE Statistical Signal Processing Workshop (SSP)}, 
  title={Variational Log-Power Spectral Tracking for Acoustic Signals}, 
  year={2021},
  volume={},
  number={},
  pages={311-315},
  abstract={This paper proposes a generative hierarchical probabilistic model for acoustic signals where both the frequency decomposition and log-power spectrum appear as latent variables. In order to facilitate efficient inference, we represent the model in a factor graph that includes a probabilistic Fourier transform and a Gaussian scale model as modules. We derive novel ways of performing variational message passing-based inference in the Gaussian scale model. As a result, in this model a probabilistic representation of the log-power spectrum of an acoustic signal can be effectively inferred online. The proposed model may find applications as a front end wherever probabilistic log-power spectral features of a signal are needed. We validate the model and message passing-based inference methods by tracking the log-power spectrum of a speech signal.},
  keywords={},
  doi={10.1109/SSP49050.2021.9513757},
  ISSN={2693-3551},
  month={July},}
@ARTICLE{9525382,
  author={Han, Yanjun and Özgür, Ayfer and Weissman, Tsachy},
  journal={IEEE Transactions on Information Theory}, 
  title={Geometric Lower Bounds for Distributed Parameter Estimation Under Communication Constraints}, 
  year={2021},
  volume={67},
  number={12},
  pages={8248-8263},
  abstract={We consider parameter estimation in distributed networks, where each sensor in the network observes an independent sample from an underlying distribution and has  $k$  bits to communicate its sample to a centralized processor which computes an estimate of a desired parameter. We develop lower bounds for the minimax risk of estimating the underlying parameter for a large class of losses and distributions. Our results show that under mild regularity conditions, the communication constraint reduces the effective sample size by a factor of  $d$  when  $k$  is small, where  $d$  is the dimension of the estimated parameter. Furthermore, this penalty reduces at most exponentially with increasing  $k$ , which is the case for some models, e.g., estimating high-dimensional distributions. For other models however, we show that the sample size reduction is re-mediated only linearly with increasing  $k$ , e.g. when some sub-Gaussian structure is available. We apply our results to the distributed setting with product Bernoulli model, multinomial model, Gaussian location models, and logistic regression which recover or strengthen existing results. Our approach significantly deviates from existing approaches for developing information-theoretic lower bounds for communication-efficient estimation. We circumvent the need for strong data processing inequalities used in prior work and develop a geometric approach which builds on a new representation of the communication constraint. This approach allows us to strengthen and generalize existing results with simpler and more transparent proofs.},
  keywords={},
  doi={10.1109/TIT.2021.3108952},
  ISSN={1557-9654},
  month={Dec},}
@INPROCEEDINGS{9517786,
  author={Gholami, Roya and Cottatellucci, Laura and Slock, Dirk},
  booktitle={2021 IEEE International Symposium on Information Theory (ISIT)}, 
  title={Tackling Pilot Contamination in Cell-Free Massive MIMO by Joint Channel Estimation and Linear Multi-User Detection}, 
  year={2021},
  volume={},
  number={},
  pages={2828-2833},
  abstract={In this paper we consider cell-free (CF) massive MIMO (MaMIMO) systems, which comprise a very large number of geographically distributed access points (APs) serving a much smaller number of users. We exploit channel sparsity to tackle pilot contamination, which originates from the reuse of pilot sequences. Specifically, we consider semi-blind methods for joint channel estimation and data detection. Under the challenging assumption of deterministic parameters, we determine sufficient conditions and necessary conditions for semi-blind identifiability, which guarantee the non-singularity of the Fisher Information Matrix (FIM) and the existence of the Cramer-Rao bound (CRB). We propose a message passing (MP) algorithm which determines the exact channel coefficients in the case of semiblind identifiability. We show that the system is identifiable if the Karp-Sipser algorithm yields an empty core. Additionally, we propose a Bayesian semi-blind approach which results in an effective algorithm for joint channel estimation and multi-user detection. This algorithm alternates between channel estimation and linear multi-user detection. Numerical simulations verify the analytical derivations.},
  keywords={},
  doi={10.1109/ISIT45174.2021.9517786},
  ISSN={},
  month={July},}
@INPROCEEDINGS{9518123,
  author={Liu, Lei and Huang, Shunqi and Kurkoski, Brian M.},
  booktitle={2021 IEEE International Symposium on Information Theory (ISIT)}, 
  title={Memory Approximate Message Passing}, 
  year={2021},
  volume={},
  number={},
  pages={1379-1384},
  abstract={Approximate message passing (AMP) is a low-cost iterative parameter-estimation technique for certain high-dimensional linear systems with non-Gaussian distributions. However, AMP only applies to independent identically distributed (IID) transform matrices, but may become unreliable for other matrix ensembles, especially for ill-conditioned ones. To handle this difficulty, orthogonal/vector AMP (OAMP/VAMP) was proposed for general right-unitarily-invariant matrices. However, the Bayes-optimal OAMP/VAMP requires high-complexity linear minimum mean square error estimator. To solve the disadvantages of AMP and OAMP/VAMP, this paper proposes a memory AMP (MAMP), in which a long-memory matched filter is proposed for interference suppression. The complexity of MAMP is comparable to AMP. The asymptotic Gaussianity of estimation errors in MAMP is guaranteed by the orthogonality principle. A state evolution is derived to asymptotically characterize the performance of MAMP. Based on the state evolution, the relaxation parameters and damping vector in MAMP are optimized. For all right-unitarily-invariant matrices, the optimized MAMP converges to OAMP/VAMP, and thus is Bayes-optimal if it has a unique fixed point. Finally, simulations are provided to verify the validity and accuracy of the theoretical results.},
  keywords={},
  doi={10.1109/ISIT45174.2021.9518123},
  ISSN={},
  month={July},}
@INPROCEEDINGS{9518062,
  author={Liu, Lei and Liang, Chulong and Ma, Junjie and Ping, Li},
  booktitle={2021 IEEE International Symposium on Information Theory (ISIT)}, 
  title={Capacity Optimality of AMP in Coded Systems}, 
  year={2021},
  volume={},
  number={},
  pages={1588-1593},
  abstract={This paper studies a large random matrix system (LRMS) model involving an arbitrary signal distribution and forward error control (FEC) coding. We establish an area property based on the approximate message passing (AMP) algorithm. Under the assumption that the state evolution for AMP is correct for the coded system, the achievable rate of AMP is analyzed. We prove that AMP achieves the constrained capacity of the LRMS with an arbitrary signal distribution provided that a matching condition is satisfied. We provide related numerical results of binary signaling using irregular low-density parity-check (LDPC) codes. We show that the optimized codes demonstrate significantly better performance over unmatched ones under AMP. For quadrature phase shift keying (QPSK) modulation, bit error rate (BER) performance within 1 dB from the constrained capacity limit is observed.},
  keywords={},
  doi={10.1109/ISIT45174.2021.9518062},
  ISSN={},
  month={July},}
@INPROCEEDINGS{9517816,
  author={Amalladinne, Vamsi K. and Hao, Allen and Rini, Stefano and Chamberland, Jean-Francois},
  booktitle={2021 IEEE International Symposium on Information Theory (ISIT)}, 
  title={Multi-Class Unsourced Random Access via Coded Demixing}, 
  year={2021},
  volume={},
  number={},
  pages={3080-3085},
  abstract={Unsourced random access (URA) is a recently proposed communication paradigm attuned to machine-driven data transfers. In the original URA formulation, all the active devices share the same number of bits per packet. The scenario where several classes of devices transmit concurrently has so far received little attention. An initial solution to this problem takes the form of group successive interference cancellation, where codewords from a class of devices with more resources are recovered first, followed by the decoding of the remaining messages. This article introduces a joint iterative decoding approach rooted in approximate message passing. This framework has a concatenated coding structure borrowed from the single-class coded compressed sensing and admits a solution that offers performance improvement at little added computational complexity. Our findings point to new connections between multiclass URA and compressive demixing. The performance of the envisioned algorithm is validated through numerical simulations.},
  keywords={},
  doi={10.1109/ISIT45174.2021.9517816},
  ISSN={},
  month={July},}
@INPROCEEDINGS{9524942,
  author={Hu, Yao and Koibuchi, Michihiro},
  booktitle={2021 IEEE 46th Conference on Local Computer Networks (LCN)}, 
  title={Accelerating MPI Communication Using Floating-point Compression on Lossy Interconnection Networks}, 
  year={2021},
  volume={},
  number={},
  pages={355-358},
  abstract={Approximate communication has arisen as a new opportunity for improving the efficiency of communication in parallel computer systems, which can significantly reduce the communication time by transmitting partial or imprecise messages. In this study, we explore application-level approximate communication techniques on lossy high-performance interconnection networks that leave bit flips. Although existing compression techniques do not assume lossy interconnection networks, our approximate-communication challenge is to co-design a lossy floating-point compression algorithm and a critical bit-flip recovery scheme optimized to a given bit error rate (BER) on a target lossy interconnection network. Our objective is to transfer the maximum amount of approximate data over the least amount of compression overhead and bit-flip recovery time. Our scheme is implemented into several representative communication-intensive MPI (Message Passing Interface) applications, and it is shown that our approximate communication scheme effectively speeds up the total execution time without much loss in the quality of the result.},
  keywords={},
  doi={10.1109/LCN52139.2021.9524942},
  ISSN={0742-1303},
  month={Oct},}
@ARTICLE{9550776,
  author={Zhang, Dongwen and Qi, Penghao and Zhang, Yang},
  journal={IEEE Access}, 
  title={GoDetector: Detecting Concurrent Bug in Go}, 
  year={2021},
  volume={9},
  number={},
  pages={136302-136312},
  abstract={Go provides a new concurrency mechanism based on message-passing, which brings a series of new concurrency bugs. The existing tools are highly dependent on model-checking methods in which they take the source program as the input of model-checking tools to detect the potential concurrent bugs. However, these methods can only qualitatively obtain the concurrency of the program but not obtain the exact number of concurrency bugs in the program. Meanwhile, these approaches are not sensitive to dead codes, which are prone to false negatives. Furthermore, few works have been done on detecting WaitGroup-related bugs in Go concurrent programming, which may cause deadlock. To this end, this paper proposes a novel approach GoDetector to detect concurrent bugs. GoDetector uses a detecting algorithm and a pushdown automaton to verify the channel-related concurrent bugs and WaitGroup-related concurrent bugs separately. To support the evaluation of the tool, 30 benchmarks are collected from the existing tools. GoDetector reports 2 channel safety errors, 29 deadlocks, and 11 WaitGroup-related errors. Compared with the existing tool Godel, GoDetector has the capacity to report more concurrency bugs and fewer false positives. GoDetector also offers additional support for the detection of WaitGroup variables. The experimental results indicate that GoDetector is more efficient at detecting the concurrency in regards to accuracy and diversity.},
  keywords={},
  doi={10.1109/ACCESS.2021.3116027},
  ISSN={2169-3536},
  month={},}
@ARTICLE{9556593,
  author={Xia, Shuhao and Shi, Yuanming and Zhou, Yong and Yuan, Xiaojun},
  journal={IEEE Transactions on Signal Processing}, 
  title={Reconfigurable Intelligent Surface for Massive Connectivity: Joint Activity Detection and Channel Estimation}, 
  year={2021},
  volume={69},
  number={},
  pages={5693-5707},
  abstract={This paper considers the massive connectivity with the aid of a reconfigurable intelligent surface (RIS), where an enormous number of devices transmit sporadically to a base station (BS). The RIS establishes favorable signal propagation environments to enhance data transmission in massive connectivity in such a scenario. Nevertheless, the BS needs to detect active devices and estimate channels to support data transmission in RIS-assisted massive access systems. Furthermore, due to a large number of devices, it is impossible to assign orthogonal signature sequences to the devices as in most of the existing works on RIS-related channel estimation, which yields unique challenges. This paper shall consider a RIS-assisted uplink IoT network and solve the RIS-related activity detection and channel estimation problem. The BS detects the active devices and estimates the separated channels of the RIS-to-device link and the RIS-to-BS link by using non-orthogonal pilot sequences. Due to limited scattering between the RIS and the BS, we model the RIS-to-BS channel as a sparse channel. As a result, by simultaneously exploiting both the sparsity of sporadic transmission in massive connectivity and the RIS-to-BS channels, we formulate the RIS-related activity detection and channel estimation problem as a sparse matrix factorization problem. Furthermore, we develop an approximate message passing (AMP) based algorithm to solve the problem based on the Bayesian inference framework and reduce the computational complexity by approximating the algorithm with the central limit theorem and Taylor series expansion. Finally, extensive numerical experiments are conducted to verify the effectiveness of the proposed algorithm.},
  keywords={},
  doi={10.1109/TSP.2021.3115938},
  ISSN={1941-0476},
  month={},}
@INPROCEEDINGS{9556066,
  author={Gurhem, Jérôme and Vandromme, Maxence and Tsuji, Miwako and Petiton, Serge G. and Sato, Mitsuhisa},
  booktitle={2021 IEEE International Conference on Cluster Computing (CLUSTER)}, 
  title={Sequences of Sparse Matrix-Vector Multiplication on Fugaku’s A64FX processors}, 
  year={2021},
  volume={},
  number={},
  pages={751-758},
  abstract={We implement parallel and distributed versions of the sparse matrix-vector product and the sequence of matrix-vector product operations, using OpenMP, MPI, and the ARM SVE intrinsic functions, for different matrix storage formats. We investigate the efficiency of these implementations on one and two A64FX processors, using a variety of sparse matrices as input. The matrices have different properties in size, sparsity and regularity. We observe that a parallel and distributed implementation shows good scaling on two nodes for cases where the matrix is close to a diagonal matrix, but the performances degrade quickly with variations to the sparsity or regularity of the input.},
  keywords={},
  doi={10.1109/Cluster48925.2021.00111},
  ISSN={2168-9253},
  month={Sep.},}
@INPROCEEDINGS{9556081,
  author={Yin, Jie and Hori, Atsushi and Gerofi, Balazs and Ishikawa, Yutaka},
  booktitle={2021 IEEE International Conference on Cluster Computing (CLUSTER)}, 
  title={A Scalability Study of Data Exchange in HPC Multi-component Workflows}, 
  year={2021},
  volume={},
  number={},
  pages={642-648},
  abstract={Multi-component workflows play a significant role in High-Performance Computing and Big Data applications. They usually contain multiple, independently developed components that execute side-by-side to perform sophisticated computation and data exchange through file I/O over parallel file system. However, file I/O can become an impediment in such systems and cause undesirable performance degradation due to its relatively low speed (compared to the interconnect fabric), which is unacceptable especially for applications with strict time constraints. The Data Transfer Framework (DTF) is an I/O arbitration layer working with the PnetCDF I/O library aiming at eliminating the bottleneck by transparently redirecting file I/O operations through the parallel file system to message passing via the high-speed interconnect between coupled components. Scalable and high-speed data transfer between components can be thus easily achieved with minimal development effort by using DTF. However, previous work provides insufficient scalability evaluation of the framework. In order to comprehensively evaluate the scalability of an I/O middleware like DTF and highlight its major advantages, we develop an I/O benchmark for multicomponent workflows. Using the benchmark we conduct large-scale scalability evaluation using up to 32,768 compute nodes on supercomputer Fugaku and 2,048 compute nodes on Oakforest-PACS by comparing direct data transfer to file I/O performed on Lustre file system and Fugaku’s Lightweight Layered IO-Accelerator (LLIO). We provide insights into DTF’s scalability and performance enhancements with the intention to impact future I/O middleware and inter-component data exchange design in multi-component workflows.},
  keywords={},
  doi={10.1109/Cluster48925.2021.00099},
  ISSN={2168-9253},
  month={Sep.},}
@INPROCEEDINGS{9556020,
  author={Marts, W. Pepper and Dosanjh, Matthew G. F. and Levy, Scott and Schonbein, Whit and Grant, Ryan E. and Bridges, Patrick G.},
  booktitle={2021 IEEE International Conference on Cluster Computing (CLUSTER)}, 
  title={MiniMod: A Modular Miniapplication Benchmarking Framework for HPC}, 
  year={2021},
  volume={},
  number={},
  pages={12-22},
  abstract={The HPC application community has proposed many new application communication structures, middleware interfaces, and communication models to improve HPC application performance. Modifying proxy applications is the standard practice for the evaluation of these novel methodologies. Currently, this requires the creation of a new version of the proxy application for each combination of the approach being tested. In this article, we present a modular proxy-application framework, MiniMod, that enables evaluation of a combination of independently written computation kernels, data transfer logic, communication access, and threading libraries. MiniMod is designed to allow rapid development of individual modules which can be combined at runtime. Through MiniMod, developers only need a single implementation to evaluate application impact under a variety of scenarios.We demonstrate the flexibility of MiniMod’s design by using it to implement versions of a heat diffusion kernel and the miniFE finite element proxy application, along with a variety of communication, granularity, and threading modules. We examine how changing communication libraries, communication granularities, and threading approaches impact these applications on an HPC system. These experiments demonstrate that MiniMod can rapidly improve the ability to assess new middleware techniques for scientific computing applications and next-generation hardware platforms.},
  keywords={},
  doi={10.1109/Cluster48925.2021.00028},
  ISSN={2168-9253},
  month={Sep.},}
@INPROCEEDINGS{9556100,
  author={Neuwirth, Sarah},
  booktitle={2021 IEEE International Conference on Cluster Computing (CLUSTER)}, 
  title={Toward a Comprehensive Benchmark Suite for Evaluating GASPI in HPC Environments}, 
  year={2021},
  volume={},
  number={},
  pages={827-828},
  abstract={With the forthcoming age of exascale computing, the efficient support of different programming models has become a crucial performance factor for high-performance computing systems. When adopting novel programming paradigms, the performance assessment through standardized and comparable benchmarks plays an essential role in both the effective use of the heterogeneous system hardware and the application performance tuning. Alternatives to MPI such as the partitioned global address space (PGAS) model have become increasingly popular. One such PGAS API is the Global Address Space Programming Interface (GASPI). This paper introduces the GASPI Benchmark Suite (GBS), which combines a comprehensive, standardized set of microbenchmarks with application kernels. The microbenchmarks target common GASPI communication patterns, including onesided, collective, passive, and global atomics, while the application kernels stress communication schemes commonly found in real HPC applications. The effectiveness of GBS is demonstrated by evaluating the GASPI communication performance for the two networking communication standards Ethernet and InfiniBand.},
  keywords={},
  doi={10.1109/Cluster48925.2021.00082},
  ISSN={2168-9253},
  month={Sep.},}
@INPROCEEDINGS{9556051,
  author={Banchelli, Fabio and Peiro, Kilian and Ramirez-Gargallo, Guillem and Vinyals, Joan and Vicente, David and Garcia-Gasulla, Marta and Mantovani, Filippo},
  booktitle={2021 IEEE International Conference on Cluster Computing (CLUSTER)}, 
  title={Cluster of emerging technology: evaluation of a production HPC system based on A64FX}, 
  year={2021},
  volume={},
  number={},
  pages={741-750},
  abstract={Clusters of emerging technologies are appearing with more and more frequency in HPC. After years of skepticism, data-centers are adopting them as production systems thanks to several geopolitical and technological factors. The most honorable example is the Fugaku supercomputer, powered by the latest Fujitsu A64FX CPU. Which is the behavior of mature HPC codes on such emerging technology clusters? Which performance will obtain scientists when running their HPC applications “as is” on these clusters? This paper presents the evaluation of CTE-Arm, a Fugaku-like system, including both fine-tuned micro-benchmarks and five scientific applications run without prior fine-tuning: Alya, NEMO, Gromacs, OpenIFS, and WRF. Results show that while micro-architectural benchmarks show performance as expected, the performance obtained running HPC applications not tuned for a specific architecture are between $2\times $ and $4\times $ slower compared with a standard Intel-based HPC system. Therefore further effort is needed to improve tools (e.g., compilers) and system software (e.g., MPI libraries) to ease applications deployment and improve their performance.},
  keywords={},
  doi={10.1109/Cluster48925.2021.00110},
  ISSN={2168-9253},
  month={Sep.},}
@INPROCEEDINGS{9562185,
  author={Wang, Xuebo and Mow, Wai Ho},
  booktitle={2021 17th International Symposium on Wireless Communication Systems (ISWCS)}, 
  title={Decoding and Convergence Analysis for Distributed Low Density Lattice Codes}, 
  year={2021},
  volume={},
  number={},
  pages={1-6},
  abstract={Distributed low density lattice codes (D-LDLCs) have been proposed for application in cooperative communication networks. D-LDLCs are able to achieve a higher coding gain than LDLCs under the same code length and transmission power. However, an efficient decoder for D-LDLCs is still lacking. The state-of-the-art message passing decoder for LDLCs can be extended to decode D-LDLCs, but its complexity analysis requires an asymptotic characterization of the decoding behavior in terms of the convergence of the message variances. In this paper, we prove that as the number of iterations tends to infinity, the message variances converge to some constants determined by the code parameters of D-LDLCs. Based on the convergence analysis of message variances, we can further show that the extended decoder achieves linear complexity with respect to the column degree of the D-LDLC check matrix.},
  keywords={},
  doi={10.1109/ISWCS49558.2021.9562185},
  ISSN={2154-0225},
  month={Sep.},}
@ARTICLE{9591481,
  author={Gang, Arpita and Xiang, Bingqing and Bajwa, Waheed U.},
  journal={IEEE Transactions on Signal and Information Processing over Networks}, 
  title={Distributed Principal Subspace Analysis for Partitioned Big Data: Algorithms, Analysis, and Implementation}, 
  year={2021},
  volume={7},
  number={},
  pages={699-715},
  abstract={Principal Subspace Analysis (PSA)—and its sibling, Principal Component Analysis (PCA)—is one of the most popular approaches for dimensionality reduction in signal processing and machine learning. But centralized PSA/PCA solutions are fast becoming irrelevant in the modern era of Big Data, in which the number of samples and/or the dimensionality of samples often exceed the storage and/or computational capabilities of individual machines. This has led to the study of distributed PSA/PCA solutions, in which the data are partitioned across multiple machines and an estimate of the principal subspace is obtained through collaboration among the machines. It is in this vein that this paper revisits the problem of distributed PSA/PCA under the general framework of an arbitrarily connected network of machines that lacks a central server. The main contributions of the paper in this regard are threefold. First, two algorithms are proposed in the paper that can be used for distributed PSA/PCA, with one in the case of data partitioned across samples and the other in the case of data partitioned across (raw) features. Second, in the case of sample-wise partitioned data, the proposed algorithm and a variant of it are analyzed, and their convergence to the true subspace at linear rates is established. Third, extensive experiments on both synthetic and real-world data are carried out to validate the usefulness of the proposed algorithms. In particular, in the case of sample-wise partitioned data, an MPI-based distributed implementation is carried out to study the interplay between network topology and communications cost as well as to study the effects of straggler machines on the proposed algorithms.},
  keywords={},
  doi={10.1109/TSIPN.2021.3122297},
  ISSN={2373-776X},
  month={},}
@INPROCEEDINGS{9586122,
  author={Stevens, Jacob R. and Das, Dipankar and Avancha, Sasikanth and Kaul, Bharat and Raghunathan, Anand},
  booktitle={2021 58th ACM/IEEE Design Automation Conference (DAC)}, 
  title={GNNerator: A Hardware/Software Framework for Accelerating Graph Neural Networks}, 
  year={2021},
  volume={},
  number={},
  pages={955-960},
  abstract={Graph Neural Networks (GNNs) apply deep learning to inputs represented as graphs. They use fully-connected layers to extract features from the nodes/edges of a graph and aggregate these features using message passing between nodes, thereby combining two distinct computational patterns: dense, regular computations and sparse, irregular computations. To address the computational challenges posed by GNNs, we propose GNNERATOR, an accelerator with heterogeneous compute engines optimized for these two patterns. Further, we propose feature-blocking, a novel GNN dataflow that beneficially trades off irregular memory accesses during aggregation for regular memory accesses during feature extraction. We show that GNNERATOR achieves speedups of 5.7-37x over an NVIDIA RTX 2080-Ti, and 2.3x-3.8x over HyGCN, a state-of-the-art GNN accelerator.},
  keywords={},
  doi={10.1109/DAC18074.2021.9586122},
  ISSN={0738-100X},
  month={Dec},}
@INPROCEEDINGS{9597042,
  author={Todorov, D. and Zdraveski, V. and Kostoska, M. and Gusev, M.},
  booktitle={2021 44th International Convention on Information, Communication and Electronic Technology (MIPRO)}, 
  title={Parallelization of a Neural Network Algorithm for Handwriting Recognition: Can we Increase the Speed, Keeping the Same Accuracy}, 
  year={2021},
  volume={},
  number={},
  pages={932-937},
  abstract={This paper examines the problem of parallelizing neural network training using the back-propagation neural network, as a breakthrough example in the field of deep learning. The challenge of our solution is to twist the algorithm in such a way so it can be executed in parallel, rather than sequentially. In this paper, we test validity of a research hypothesis if the speed can be increased by parallelizing the back-propagation algorithm and keep the same accuracy. For this purpose, we developed a use-case of a handwriting recognition algorithm and conducted several experiments to test the performance, both in execution speed and accuracy. At the end, we examine just how much it benefits to write a parallel program for a neural network, with regards to the time it takes to train the neural network and the accuracy of the predictions. Our handwriting problem is that of classification, and in order to implement any sort of solution, we must have data. The MNIST dataset of handwritten digits provides necessary data to solve the problem.},
  keywords={},
  doi={10.23919/MIPRO52101.2021.9597042},
  ISSN={2623-8764},
  month={Sep.},}
@INPROCEEDINGS{9600006,
  author={Papageorgiou, Vasileios and Nichoritis, Athanasios and Vasilakopoulos, Panagiotis and Vougioukas, Georgios and Bletsas, Aggelos},
  booktitle={2021 17th International Conference on Distributed Computing in Sensor Systems (DCOSS)}, 
  title={Towards Ambiently Powered Inference on Wireless Sensor Networks: Asynchrony is the Key!}, 
  year={2021},
  volume={},
  number={},
  pages={458-465},
  abstract={Is it possible to build ultra-low power wireless sensor networks (WSN) that exploit the inherent parallel and distributed nature of powerful message passing/inference algorithms, embrace ultra-low power communication principles and make autonomous, in-network decisions, solely powered by the environment? While edge and cloud computing emerge, this work points towards the opposite direction, inspired by the fact that ambient energy, either from radio frequency (RF), sun, motion, temperature or even living organisms, has fixed (on average) density per surface (or volume). It is shown, perhaps for the first time in the literature (to the best of our knowledge), a proof of concept, where a WSN harvests energy from the environment and processes itself the collected information in a distributed manner, by converting the (network) inference task to a probabilistic, message passing problem. Examples from Gaussian Belief Propagation and Average Consensus are offered; ambient energy harvesting and availability are quantified, controling the probability of successful (or not) message passing. Such interrupted communication requires distributed algorithms robust to asynchrony, at the expense of increased overall delay. Simulation and experimental validation are offered in a WSN testbed with solar energy harvesting. Future work will focus on overall delay minimization.},
  keywords={},
  doi={10.1109/DCOSS52077.2021.00077},
  ISSN={2325-2944},
  month={July},}
@INPROCEEDINGS{9605415,
  author={Liu, Qingyue and Varman, Peter},
  booktitle={2021 IEEE International Conference on Networking, Architecture and Storage (NAS)}, 
  title={Decoupling Control and Data Transmission in RDMA Enabled Cloud Data Centers}, 
  year={2021},
  volume={},
  number={},
  pages={1-8},
  abstract={Advances in storage, processing, and networking hardware are changing the structure of distributed applications. RDMA networks provide multiple communication mechanisms that enable novel hybrid protocols specialized to different data transfer requirements. In this paper, we present a distributed communication scheme that separates control and data communication channels directly at the RNIC rather than the application level. We develop a new communication artifact, a remote random access buffer, to efficiently implement this separation. Data messages are sent silently to the receiver, which is informed of the location of the data by a subsequent control message. Experiments on an RDMA-enabled cluster with micro benchmarks and two distributed applications validate the performance benefits of our approach.},
  keywords={},
  doi={10.1109/NAS51552.2021.9605415},
  ISSN={},
  month={Oct},}
@INPROCEEDINGS{9611415,
  author={Zhang, Hang and Abdi, Afshin and Fekri, Faramarz},
  booktitle={2021 IEEE Information Theory Workshop (ITW)}, 
  title={A General Framework for the Design of Compressive Sensing using Density Evolution}, 
  year={2021},
  volume={},
  number={},
  pages={1-6},
  abstract={This paper proposes a general framework to design a sparse sensing matrix ${\mathbf {A}} \in \mathbb{R}^{m\times n}$, in a linear measurement system ${\mathbf {y = Ax}}^{\sharp } + {\mathbf {w}}$, where ${\mathbf {y}} \in \mathbb{R}^{n}, {\mathbf {x}}^{\sharp } \in \mathbb{R}^{n}$, and w denote the measurements, the signal with certain structures, and the measurement noise, respectively. By viewing the signal reconstruction from the measurements as a message passing algorithm over a graphical model, we leverage tools from coding theory in the design of low density parity check codes, namely the density evolution, and provide a framework for the design of matrix A. Particularly, compared to the previous methods, our proposed framework enjoys the following desirable properties: (i) Universality: the design supports both regular sensing and preferential sensing, and incorporates them in a single frame-work; (ii) Flexibility: the framework can easily adapt the design of A to a signal $x^{\sharp }$ with different underlying structures. As an illustration, we consider the $\ell_{1}$ regularizer, which correspond to Lasso, for both the regular sensing and preferential sensing scheme. Noteworthy, our framework can reproduce the classical result of Lasso, i.e., $m \geq c_{0}k\log (n/k)$ (the regular sensing) with regular design after proper distribution approximation, where $c_{0}\gt 0$ is some fixed constant. We also provide numerical experiments to confirm the analytical results and demonstrate the superiority of our framework whenever a preferential treatment of a sub-block of vector $x^{\sharp }$ is required.},
  keywords={},
  doi={10.1109/ITW48936.2021.9611415},
  ISSN={},
  month={Oct},}
@INPROCEEDINGS{9636035,
  author={Zeng, Wenyuan and Liang, Ming and Liao, Renjie and Urtasun, Raquel},
  booktitle={2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, 
  title={LaneRCNN: Distributed Representations for Graph-Centric Motion Forecasting}, 
  year={2021},
  volume={},
  number={},
  pages={532-539},
  abstract={Forecasting the future behaviors of dynamic actors is an important task in many robotics applications such as self-driving. It is extremely challenging as actors have latent intentions and their trajectories are governed by complex interactions between the other actors, themselves, and the map. In this paper, we propose LaneRCNN, a graph-centric motion forecasting model that captures the actor-to-actor and the actor-to-map relations in a distributed and structured manner. Relying on a specially designed graph encoder, we learn a local graph representation per actor (LaneRoI) to encode its past motions and the local map topology. We further develop an interaction module which permits efficient message passing among local graph representations within a shared global lane graph. Moreover, we parameterize the output trajectories based on lane graphs, a more amenable prediction parameterization. We demonstrate the effectiveness of our approach on the challenging Argoverse [1] motion forecasting benchmark and achieve state-of-the-art performance.},
  keywords={},
  doi={10.1109/IROS51168.2021.9636035},
  ISSN={2153-0866},
  month={Sep.},}
@INPROCEEDINGS{9636129,
  author={Colledanchise, Michele and Cicala, Giuseppe and Domenichelli, Daniele E. and Natale, Lorenzo and Tacchella, Armando},
  booktitle={2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, 
  title={Formalizing the Execution Context of Behavior Trees for Runtime Verification of Deliberative Policies}, 
  year={2021},
  volume={},
  number={},
  pages={9841-9848},
  abstract={In this paper, we enable automated property verification of deliberative components in robot control architectures. We focus on formalizing the execution context of Behavior Trees (BTs) to provide a scalable, yet formally grounded, methodology to enable runtime verification and prevent unexpected robot behaviors. To this end, we consider a message-passing model that accommodates both synchronous and asynchronous composition of parallel components, in which BTs and other components execute and interact according to the communication patterns commonly adopted in robotic software architectures. We introduce a formal property specification language to encode requirements and build runtime monitors. We performed a set of experiments, both on simulations and on the real robot, demonstrating the feasibility of our approach in a realistic application and its integration in a typical robot software architecture. We also provide an OS-level virtualization environment to reproduce the experiments in the simulated scenario.},
  keywords={},
  doi={10.1109/IROS51168.2021.9636129},
  ISSN={2153-0866},
  month={Sep.},}
@INPROCEEDINGS{9651261,
  author={Yellapragada, Sushma and Wang, Chen and Snir, Marc},
  booktitle={2021 IEEE/ACM Sixth International Parallel Data Systems Workshop (PDSW)}, 
  title={Verifying IO Synchronization from MPI Traces}, 
  year={2021},
  volume={},
  number={},
  pages={41-46},
  abstract={The paper addresses the following question: Are IO operations of HPC applications properly synchronized? We focus on parallel file systems that satisfy POSIX semantics. The outcome of I/O operations is well-defined provided that conflicting accesses to a file location are not concurrent, but are ordered. Accesses to distinct processes are ordered by the executed MPI communication. We derive the "happens-before" relation between I/O calls of HPC runs by analyzing traces collected during program execution. Various optimizations reduce the analysis overhead. We collected traces from 17 representative HPC applications. We found that 10 of them do not perform conflicting I/O accesses and, hence, are properly synchronized by default. The remaining 7 applications properly synchronize the conflicting I/O accesses.},
  keywords={},
  doi={10.1109/PDSW54622.2021.00012},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{9651246,
  author={Liem, Radita and Povaliaiev, Dmytro and Lofstead, Jay and Kunkel, Julian and Terboven, Christian},
  booktitle={2021 IEEE/ACM Sixth International Parallel Data Systems Workshop (PDSW)}, 
  title={User-Centric System Fault Identification Using IO500 Benchmark}, 
  year={2021},
  volume={},
  number={},
  pages={35-40},
  abstract={I/O performance in a multi-user environment is difficult to predict. Users do not know what I/O performance to expect when running and tuning applications. We propose to use the IO500 benchmark as a way to guide user expectations on their application&#x2019;s performance and to aid identifying root causes of their I/O problems that might come from the system. Our experiments describe how we manage user expectation with IO500 and provide a mechanism for system fault identification. This work also provides us with information of the tail latency problem that needs to be addressed and granular information about the impact of I/O technique choices (POSIX and MPI-IO).},
  keywords={},
  doi={10.1109/PDSW54622.2021.00011},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{9651305,
  author={Bora, Utpal and Vaishay, Shraiysh and Joshi, Saurabh and Upadrasta, Ramakrishna},
  booktitle={2021 IEEE/ACM 7th Workshop on the LLVM Compiler Infrastructure in HPC (LLVM-HPC)}, 
  title={OpenMP aware MHP Analysis for Improved Static Data-Race Detection}, 
  year={2021},
  volume={},
  number={},
  pages={1-11},
  abstract={Data races, a major source of bugs in concurrent programs, can result in loss of manpower and time as well as data loss due to system failures. OpenMP, the de facto shared memory parallelism framework used in the HPC community, also suffers from data races. To detect race conditions in OpenMP programs and improve turnaround time and/or developer productivity, we present a data flow analysis based, fast, static data race checker in the LLVM compiler framework. Our tool can detect races in the presence or absence of explicit barriers, with implicit or explicit synchronization. In addition, our tool effectively works for the OpenMP target offloading constructs and also supports the frequently used OpenMP constructs.We formalize and provide a data flow analysis framework to perform Phase Interval Analysis (PIA) of OpenMP programs. Phase intervals are then used to compute the MHP (and its complement NHP) sets for the programs, which, in turn, are used to detect data races statically.We evaluate our work using multiple OpenMP race detection benchmarks and real world applications. Our experiments show that the checker is comparable to the state-of-the-art in various performance metrics with around 90% accuracy, almost perfect recall, and significantly lower runtime and memory footprint.},
  keywords={},
  doi={10.1109/LLVMHPC54804.2021.00006},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{9638100,
  author={Xiao, Tannan and Tong, Weilin and Wang, Jianquan and Chen, Ying},
  booktitle={2021 IEEE Power & Energy Society General Meeting (PESGM)}, 
  title={A Fully Parallel Nested BBDF Method for Power System Transient Stability Simulations}, 
  year={2021},
  volume={},
  number={},
  pages={01-05},
  abstract={A fully parallel nested bordered block diagonal form (BBDF) method for power system transient stability simulations is proposed in this paper. The fully parallel nested BBDF (FNBBDF) method is developed by combining the fully parallel BBDF method with the nested BBDF method based on subnet-core mapping and mixed programming of MPI and OpenMP. The FNBBDF method is compared with existing methods from the perspectives of computational burden, parallel overhead, and subnet-core mapping. Detailed tests of the FNBBDF method are carried out in the 2383wp system and two practical power systems (13490-node and 24886-node). The test results prove the efficiency of the proposed method. The FNBBDF method can increase the speedup ratio to more than 21x with 64 CPU cores in the 24886-node test power system.},
  keywords={},
  doi={10.1109/PESGM46819.2021.9638100},
  ISSN={1944-9933},
  month={July},}
@INPROCEEDINGS{9644213,
  author={Köhler, Sven and Wenzel, Lukas and Plauth, Max and Böning, Pawel and Gampe, Philipp and Geier, Leonard and Polze, Andreas},
  booktitle={2021 Ninth International Symposium on Computing and Networking Workshops (CANDARW)}, 
  title={Recognizing HPC Workloads Based on Power Draw Signatures}, 
  year={2021},
  volume={},
  number={},
  pages={278-284},
  abstract={The power draw of computing infrastructure— besides being a critical operating resource—can give valuable insights into the type and behavior of workloads running on it. In consequence, runtime power analysis can be a promising non-invasive monitoring approach. Recent work has shown that a system’s power draw can support reliable conclusions about running workloads, which serves as a basis for runtime placement decisions to adapt the system’s cumulative energy demand to the available energy supply in a volatile electricity grid.In this work, we reproduce earlier findings on the classification of running workload from a set of previously known workloads purely through external power measurements. Using a k-nearest neighbors classifier, we identify workloads of the NAS benchmark suite with a macro F1-score of 98% for OpenMP-based implementations and 85% for MPI-based implementations.},
  keywords={},
  doi={10.1109/CANDARW53999.2021.00053},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{9651288,
  author={Protze, Joachim and Th&#x00E4;rigen, Isabel and Wahle, Jonas},
  booktitle={2021 IEEE/ACM 5th International Workshop on Software Correctness for HPC Applications (Correctness)}, 
  title={Understanding the Performance of Dynamic Data Race Detection}, 
  year={2021},
  volume={},
  number={},
  pages={33-40},
  abstract={With increasing per-node concurrency, the interest in dynamic data race detection for OpenMP applications increased significantly in recent years. Benchmarks such as DataRaceBench (DRB) help evaluate the classification quality of data race detection tools for simple memory access patterns. Various publications use short-running benchmark kernels from OmpSRC and DRB also for performance benchmarking of data race detection tools. Due to the short execution time, one-time initialization overhead dominates the measurement. Such results are not representative for the overhead with real codes. This paper proposes a new problem class for the SPEC OMP 2012 benchmark designed to analyze the runtime overhead of data race detection tools. Prior work reported runtime overheads of 80 &#x00D7; and higher for the OpenMP data race detection tool Archer (i.e., execution time with the tool is 80 times as long as without a tool). For a specific application, we report 500 &#x00D7; runtime overhead in this paper. This overhead stands in contrast to the 2&#x2013;20 &#x00D7; runtime overhead claimed by the underlying tool ThreadSanitizer. We use our newly proposed input data set to observe and investigate significant runtime overhead of dynamic data race detection for specific applications. With the help of performance analysis tools and hardware performance counters, we can identify massively concurrent read accesses of the same shared variable as the root cause. We identify parallel matrix-vector multiplication as an application pattern responsible for such huge runtime overheads in data race analysis. Finally, we propose a modification of ThreadSanitizer, limiting the runtime overhead for these applications to less than 40&#x00D7;.},
  keywords={},
  doi={10.1109/Correctness54621.2021.00010},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{9647230,
  author={Chen, Fengting and Che, Yonggang and Wang, Wenke and Ma, Jian},
  booktitle={2021 IEEE 3rd International Conference on Frontiers Technology of Information and Computer (ICFTIC)}, 
  title={Performance and Portability Analysis of OPS Structured Grid Parallel Library}, 
  year={2021},
  volume={},
  number={},
  pages={555-563},
  abstract={The complexity and diversity of high-performance computer architectures have brought great challenges to parallel application development. Using DSL (Domain Specific Language) to achieve multi-platform automatic parallelization is a solution to this problem. This paper tests and analyzes the multi-platform parallel performance of OPS (Oxford Parallel Library for Structured Mesh Solvers), a typical DSL framework for scientific applications. Two representative structured mesh applications are used in our evaluation. The performance of their MPI, hybrid MPI/OpenMP and CUDA versions generated by OPS are evaluated on the Intel Xeon E5-2600 V3 CPU and the NVIDIA Tesla K80 GPU. The performance of OPS generated codes are compared against the corresponding manually parallelized and optimized codes. The results show that for the two applications, OPS based approach can generate parallel codes with comparable performance to manually parallelized and optimized codes. This paper further analyzes the differences between OPS-based multi-platform parallel code generation and manual parallelization approaches and their impact on performance. It also quantitatively evaluates the cross-platform portability of OPS, and points out some possible directions of improvement.},
  keywords={},
  doi={10.1109/ICFTIC54370.2021.9647230},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{9652868,
  author={Brewer, Wesley and Martinez, Daniel and Boyer, Mathew and Jude, Dylan and Wissink, Andy and Parsons, Ben and Yin, Junqi and Anantharaj, Valentine},
  booktitle={2021 IEEE/ACM Workshop on Machine Learning in High Performance Computing Environments (MLHPC)}, 
  title={Production Deployment of Machine-Learned Rotorcraft Surrogate Models on HPC}, 
  year={2021},
  volume={},
  number={},
  pages={21-32},
  abstract={We explore how to optimally deploy several different types of machine-learned surrogate models used in rotorcraft aerodynamics on HPC. We first developed three different rotorcraft models at three different orders of magnitude (2M, 44M, and 212M trainable parameters) to use as test models. Then we developed a benchmark, which we call “smiBench”, that uses synthetic data to test a wide range of alternative configurations to study optimal deployment scenarios. We discovered several different types of optimal deployment scenarios depending on the model size and inference frequency. For most cases, it makes sense to use multiple inference servers, each bound to a GPU with a load balancer distributing the requests across multiple GPUs. We tested three different types of inference server deployments: (1) a custom Flask-based HTTP inference server, (2) TensorFlow Serving with gRPC protocol, and (3) RedisAI server with SmartRedis clients using the RESP protocol. We also tested three different types of load balancing techniques for multi-GPU inferencing: (1) Python concurrent.futures thread pool, (2) HAProxy, and (3) mpi4py. We investigated deployments on both DoD HPCMP’s SCOUT and DoE OLCF’s Summit POWER9 supercomputers, demonstrated the ability to inference a million samples per second using 192 GPUs, and studied multiple scenarios on both Nvidia T4 and V100 GPUs. Moreover, we studied a range of concurrency levels, both on the client-side and the server-side, and provide optimal configuration advice based on the type of deployment. Finally, we provide a simple Python-based framework for benchmarking machine-learned surrogate models using the various inference servers.},
  keywords={},
  doi={10.1109/MLHPC54614.2021.00008},
  ISSN={2768-4253},
  month={Nov},}
@INPROCEEDINGS{9652607,
  author={Chang, Yan-Tyng Sherry and Heistand, Steve and Hood, Robert and Jin, Henry},
  booktitle={2021 3rd International Workshop on Containers and New Orchestration Paradigms for Isolated Environments in HPC (CANOPIE-HPC)}, 
  title={Feasibility of Running Singularity Containers with Hybrid MPI on NASA High-End Computing Resources}, 
  year={2021},
  volume={},
  number={},
  pages={17-28},
  abstract={This work investigates the feasibility of a Singularity container-based solution to support a customizable computing environment for running users' MPI applications in “hybrid” MPI mode-where the MPI on the host machine works in tandem with MPI inside the container-on NASA's High-End Computing Capability (HECC) resources. Two types of real-world applications were tested: traditional High-Performance Computing (HPC) and Artificial Intelligence/Machine Learning (AI/ML). On the traditional HPC side, two JEDI containers built with Intel MPI for Earth science modeling were tested on both HECC in-house and HECC AWS Cloud CPU resources. On the AI/ML side, a NVIDIA TensorFlow container built with OpenMPI was tested with a Neural Collaborative Filtering recommender system and the ResNet-50 computer image system on the HECC in-house V100 GPUs. For each of these applications and resource environments, multiple hurdles were overcome after lengthy debugging efforts. Among them, the most significant ones were due to the conflicts between a host MPI and a container MPI and the complexity of the communication layers underneath. Although porting containers to run with a single node using just the container MPI is quite straightforward, our exercises demonstrate that running across multiple nodes in hybrid MPI mode requires knowledge of Singularity, MPI libraries, the operating system image, and the communication infrastructure such as the transport and network layers, which are traditionally handled by support staff of HPC centers and hardware or software vendors. In conclusion, porting and running Singularity containers on HECC resources or other data centers with similar environments is feasible but most users would need help to run them in hybrid MPI mode.},
  keywords={},
  doi={10.1109/CANOPIEHPC54579.2021.00007},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{9652844,
  author={Miao, Zheng and Calhoun, Jon C. and Ge, Rong},
  booktitle={2021 IEEE/ACM 11th Workshop on Fault Tolerance for HPC at eXtreme Scale (FTXS)}, 
  title={Relaxed Replication for Energy Efficient and Resilient GPU Computing}, 
  year={2021},
  volume={},
  number={},
  pages={41-50},
  abstract={Power and reliability are two intertwined challenges in GPU-accelerated large-scale computing. Aggressive power reduction pushes hardware to its operating limit and increases the failure rate. Resilience allows programs to progress when subjected to faults and is an integral component of large-scale systems, but incurs significant time and energy overhead. Managing power and resilience is challenging, due to the heterogeneous compute capability, power consumption, and varying failure rates between CPUs and GPUs. Previous works have shown that redundancy-based approaches are more energy efficient than checkpointing/restart at extreme-scales, but current solutions only support parallel programs running on CPU-based homogeneous systems. Simply extending redundancy approaches from CPU-based systems results in sub-optimal performance and/or energy efficiency because existing redundancy solutions typically rely on identical replicas with expensive synchronization. In this work, we explore redundancy techniques and energy efficient techniques for GPU-accelerated systems running MPI parallel workloads. Specifically, we design a novel redundancy technique that relaxes the requirement of synchronization and identicalness for replica processes and allows them to run in lower-precision and at lower power/performance states with periodical rejuvenation or asynchronization, enabling resources and power reduction. This relaxed replication mechanism complicates fault detection and recovery over the homogeneous exact replication. We discuss techniques to handle and mitigate these complexities for both process/node failures and silent data corruption. Evaluation results on a 16-GPU cluster show our techniques reduce energy by up to 15% for unmodified programs and 32% for programs that are able to adapt the precision of the replicas.},
  keywords={},
  doi={10.1109/FTXS54580.2021.00009},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{9652669,
  author={Hunold, Sascha and Ajanohoun, Jordy I. and Carpen-Amarie, Alexandra},
  booktitle={2021 International Workshop on Performance Modeling, Benchmarking and Simulation of High Performance Computer Systems (PMBS)}, 
  title={MicroBench Maker: Reproduce, Reuse, Improve}, 
  year={2021},
  volume={},
  number={},
  pages={69-74},
  abstract={Benchmarking is one of the fundamental methods for analyzing the performance of computational processes or threads. In the domain of high performance computing, benchmarks are essential to assess computer systems, e.g., the TOP500 or the Green500 benchmarks are used to define the performance of machines. We address the problem of benchmarking MPI code. A common benchmarking pattern is to repetitively execute a specific code block and to take the start and the finish timestamp of each run of this code block, while iterations are logically separated using a barrier operation. Although this benchmarking scheme is very simple, it may lead to wrong conclusions, especially if the runtime of the code under investigation is very short, e.g., a reduction operation. In such scenarios, precise and reproducible measurements require accurate process synchronization methods and low overhead clocks. We present a library-based approach to MPI benchmarking. Our library can be used to conduct precise measurements without having to reinvent the benchmarking wheel. This novel library is based on the ReproMPI benchmark and supports source-code annotations. An experimenter can add annotations to lines of code that should be benchmarked. This annotated code is then transformed into a benchmark code, which allows for a clear separation of concerns, as the algorithm designer can define the test scenarios while the benchmarking expert conducts experiments independently. We show the general applicability of our approach in different use cases. In one particular study, we replace all timing and synchronization code from a well-known OSU micro-benchmark with our benchmark annotations. We demonstrate that the resulting code allows to tailor the benchmark options for allowing a fine-grained performance inspection.},
  keywords={},
  doi={10.1109/PMBS54543.2021.00013},
  ISSN={},
  month={Nov},}

@INPROCEEDINGS{9648648,
  author={Pham, Nghia and Hoang, Diep Thi},
  booktitle={2021 13th International Conference on Knowledge and Systems Engineering (KSE)}, 
  title={A distributed algorithm for the parsimony bootstrap approximation}, 
  year={2021},
  volume={},
  number={},
  pages={1-6},
  abstract={Accelerating phylogenetic tree reconstruction and bootstrapping is critical, especially to support the study of the evolution of dangerous viruses. In this paper, we propose the MPBoot-MPI, a distributed algorithm efficiently implementing the idea of bootstrap approximation in MPBoot for a parallel computing environment of multiple computational nodes. MPBoot-MPI employs the master-worker paradigm and divides the work in MPBoot into three phases, each with a separate strategy to distribute computing among processes. Since the bootstrap trees are not calculated independently, processes must share results throughout task execution. We propose that when arriving at a checkpoint to report their results to the master process, worker processes apply a stochastic strategy to determine whether to perform the sending, thereby reducing the effect of latency caused by the large size of the message sent. Experiments on simulation and real benchmark datasets showed that MPBoot- MPI on multiple processes obtained MP scores and bootstrap accuracy comparable to MPBoot while achieving a promising speedup ratio. We implemented the proposed method in the MPBoot-MPI program, which is publicly accessible at https://github.com/diepthihoang/mpboot/tree/mpboot-mpi-dev.},
  keywords={},
  doi={10.1109/KSE53942.2021.9648648},
  ISSN={2694-4804},
  month={Nov},}
@INPROCEEDINGS{9652831,
  author={Schafer, Derek and Hines, Thomas and Suggs, Evan Drake and Rüfenacht, Martin and Skjellum, Anthony},
  booktitle={2021 Workshop on Exascale MPI (ExaMPI)}, 
  title={Overlapping Communication and Computation with ExaMPI's Strong Progress and Modern C++ Design}, 
  year={2021},
  volume={},
  number={},
  pages={18-26},
  abstract={ExaMPI is a modern, C++17+ Mpi implementation designed for modularity, extensibility, and understandability. In this work, we overview functionality new to ExaMPI since its initial release, including Libfabric-based network transport support. We also explain our rationale for why and how we choose to add new MPI features (and defer others). Lastly, we measured the latency of the aforementioned transports in ExaMPI and found that ExaMPI, while having slightly higher latency than other production MPI's, is competitive. It is no longer uncommon to see MPI applications using extra MPI calls during non-blocking MPI operations to coax MPI's progress engine. Strong, asynchronous progress (aka application bypass) in MPI is instead based on the premise that an application asks MPI to perform a non-blocking communication in the background and MPI completes said communication without requiring any additional MPI calls from the application to advance the underlying transport. Strong progress often requires an additional background thread, but with the current trend in exascale computing, cores appear to be in excess. Indeed, for earlier MPI implementations that supported it well, strong progress enabled overlap and reduced time to completion for some MPI applications. However, enabling or adding strong progress to existing MPI implementations is not straightforward; changing such implementations is cumbersome, difficult, invasive, and time-consuming-a key motivation for our research MPI implementation, ExaMPI. Specifically, we tested the ability for ExaMPI's strong progress engine to enable overlap communication and computation, finding that considerable overlap is achieved without needing additional MPI “helper” calls such as MPI Test.},
  keywords={},
  doi={10.1109/ExaMPI54564.2021.00008},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{9649926,
  author={Oo, Nwe Zin and Chaikan, Panyayot},
  booktitle={2021 21st International Conference on Control, Automation and Systems (ICCAS)}, 
  title={The Effect of Core Parking for Energy-efficient Matrix-Matrix Multiplication by using AVX and OpenMP}, 
  year={2021},
  volume={},
  number={},
  pages={307-310},
  abstract={Today&#x0027;s modern computers support multi-core processors architecture that enhances parallel computing with single instruction multiple data computing. According to memory structure, the CPU core performance is a vital role in power-saving profiling across the multi-core architecture. Although CPU parking was controlled entirely by the operating system of both laptops and desktops computers, the performance can be boost by tweaking CPU core parking and changing frequency scaling in real-time. In this paper, the effect of core parking for parallel matrix-matrix multiplication on shared memory is proposed by utilizing AVX and OpenMP. When the large matrix sizes are multiplied parallelly on shared memory, the overheads of memory capacity and data transferring become the main issues not only for increased power consumption but also for decrease performance. The large square matrix multiplications are tested that range from 1024&#x00D7;1024 to 16384&#x00D7;16384 by utilizing Advanced Vector Extensions (AVX) intrinsics and OpenMP, and varying the different power-saving profiling dynamically. The default power-saving profile in a computer is the balanced mode and we tested for performance by tweaking CPU parking with four different modes (Balanced, High Performance, Bitsum Highest Performance, and Power Saving). According to tested results, the Bitsum Highest Performance mode obtained the maximum performance and minimum power and energy consumption than other profiling modes.},
  keywords={},
  doi={10.23919/ICCAS52745.2021.9649926},
  ISSN={2642-3901},
  month={Oct},}
@INPROCEEDINGS{9651615,
  author={Loch, Wilton Jaciel and Koslovski, Guilherme Piêgas},
  booktitle={2021 IEEE 33rd International Symposium on Computer Architecture and High Performance Computing (SBAC-PAD)}, 
  title={Sparbit: a new logarithmic-cost and data locality-aware MPI Allgather algorithm}, 
  year={2021},
  volume={},
  number={},
  pages={167-176},
  abstract={The collective operations are considered critical for improving the performance of exascale-ready and highperformance computing applications. On this paper we focus on the Message-Passing Interface (MPI) Allgather many to many collective, which is amongst the most called and time-consuming operations. Each MPI algorithm for this call suffers from different operational and performance limitations, that might include only working for restricted cases, requiring linear amounts of communication steps with the growth in number of processes, memory copies and shifts to assure correct data organization, and non-local data exchange patterns, most of which negatively contribute to the total operation time. All these characteristics create an environment where there is no algorithm which is the best for all cases and this consequently implies that careful choices of alternatives must be made to execute the call. Considering such aspects, we propose the Stripe Parallel Binomial Trees (Sparbit) algorithm, which has optimal latency and bandwidth time costs with no usage restrictions. It also maintains a much more local communication pattern that minimizes the delays due to long range exchanges, allowing the extraction of more performance from current systems when compared with asymptotically equivalent alternatives. On its best scenario, Sparbit surpassed the traditional MPI algorithms on 46.43% of test cases with mean (median) improvements of 34.7% (26.16%) and highest reaching 84.16%.},
  keywords={},
  doi={10.1109/SBAC-PAD53543.2021.00028},
  ISSN={2643-3001},
  month={Oct},}
@INPROCEEDINGS{9655795,
  author={Mohammed, Abdulrahim and Khedr, Ahmed and AlHaj, Duaa and Al Khalifa, Reem and Alqaddoumi, Abdulla},
  booktitle={2021 International Conference on Data Analytics for Business and Industry (ICDABI)}, 
  title={Time-Series Cross-Validation Parallel Programming using MPI}, 
  year={2021},
  volume={},
  number={},
  pages={553-556},
  abstract={Time-series data has a natural chronological arrangement with modeling and cross-validation techniques, highly dependent on sequential processing of data, which challenges its parallelization. Since the running time of the modeling algorithm largely consists of a main operation of solving the modeling algorithm several times with various training and testing dataset sizes, it is the prime target for optimizing the running time. This research presents a parallel implementation of time-series cross-validation on a rolling basis that involves using a subset of the dataset for training purposes, expanding each dataset with each run to obtain test accuracy. The evaluation is conducted using parallel speedup, parallel efficiency, and computational time. The proposed algorithm distributes the task of modeling among several processors to run independently and obtain results. The computational time recorded ranged from 15.47 seconds at best with five processors to 28.33 seconds at worst when done with a single processor. The parallel system speedup was found to be sub-linear with an efficiency decreasing with the increase in the number of processors.},
  keywords={},
  doi={10.1109/ICDABI53623.2021.9655795},
  ISSN={},
  month={Oct},}
@INPROCEEDINGS{9661891,
  author={Luo, Ziyuan and Xie, Qingyi and Xiao, Shanlin and Yu, Zhiyi},
  booktitle={2021 IEEE International Conference on Integrated Circuits, Technologies and Applications (ICTA)}, 
  title={A high throughput spatially coupled low density generator matrix coding system}, 
  year={2021},
  volume={},
  number={},
  pages={228-229},
  abstract={Spatially coupled low density generator matrix (SC- LDGM) code is a novel code proposed in recent years but not implemented in hardware platform yet. We designed a hardware architecture for the encoder and decoder of SC-LDGM code, and proposed an efficient storage scheme for the message passing within decoder. We have validated our design using Xilinx evaluation board and conducted a bit error rate simulation. Results shows that our design achieves a throughput of 1.6Gbps and net coding gain of 7.3dB at BER of 10-4.},
  keywords={},
  doi={10.1109/ICTA53157.2021.9661891},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{9660574,
  author={Park, Hyunmok and Yoon, Kijung},
  booktitle={2021 7th IEEE International Conference on Network Intelligence and Digital Content (IC-NIDC)}, 
  title={Degree Matters: Assessing the Generalization of Graph Neural Network}, 
  year={2021},
  volume={},
  number={},
  pages={71-75},
  abstract={Graph neural network (GNN) is a general framework for using deep neural networks on graph data. The defining feature of a GNN is that it uses a form of neural message passing where vector messages are exchanged between nodes and updated using neural networks. The message passing operation that underlies GNNs has recently been applied to develop neural approximate inference algorithms, but little work has been done on understanding under what conditions GNNs can be used as a core module for building general inference models. To study this question, we consider the task of out-of-distribution generalization where training and test data have different distributions, by systematically investigating how the graph size and structural properties affect the inferential performance of GNNs. We find that (1) the average unique node degree is one of the key features in predicting whether GNNs can generalize to unseen graphs; (2) the graph size is not a fundamental limiting factor of the generalization in GNNs when the average node degree remains invariant across training and test distributions; (3) despite the size-invariant generalization, training GNNs on graphs of high degree (and of large size consequently) is not trivial (4) neural inference by GNNs outperforms algorithmic inferences especially when the pairwise potentials are strong, which naturally makes the inference problem harder.},
  keywords={},
  doi={10.1109/IC-NIDC54101.2021.9660574},
  ISSN={2575-4955},
  month={Nov},}
@INPROCEEDINGS{9659711,
  author={Bağbaba, Ayşe and Wang, Xuan and Niethammer, Christoph and Gracia, José},
  booktitle={2021 International Conference on Engineering and Emerging Technologies (ICEET)}, 
  title={Improving the I/O Performance of Applications with Predictive Modeling based Auto-tuning}, 
  year={2021},
  volume={},
  number={},
  pages={1-6},
  abstract={Parallel I/O is an essential part of scientific applications running on high performance computing systems. Typically, parallel I/O stacks offer many parameters that need to be tuned to achieve the best possible I/O performance. Unfortunately, there is no default best configuration of parameters; in practice, these differ not only between systems but often also from one application use-case to the other. However, scientific users often do not have the time nor the experience to explore the parameter space sensibly and choose the proper configuration for each application use-case. This paper proposes an auto-tuning approach based on I/O monitoring and predictive modeling, which can find a good set of I/O parameter values on a given system and application use-case. We demonstrate the feasibility to auto-tune parameters related to the Lustre file system and the MPI-IO ROMIO library transparently to the user. In particular, the model predicts for a given I/O pattern the best configuration from a history of I/O usages. We have validated the model with two I/O benchmarks, namely IOR and MPI-Tile-IO, and a real Molecular Dynamics code, namely ls1 Mardyn. We achieve an increase of I/O bandwidth by a factor of up to 18 over the default parameters for collective I/O in the IOR and a factor of up to 5 for the non-contiguous I/O in the MPI-Tile-IO. Finally, we obtain an improvement of check-point writing time over the default parameters of up to 32 in ls1 Mardyn.},
  keywords={},
  doi={10.1109/ICEET53442.2021.9659711},
  ISSN={2409-2983},
  month={Oct},}
@INPROCEEDINGS{9659670,
  author={Bilekdemir, Gokhan},
  booktitle={2021 15th Turkish National Software Engineering Symposium (UYMS)}, 
  title={Clock Drift Analysis In a Multihost System}, 
  year={2021},
  volume={},
  number={},
  pages={1-5},
  abstract={The demand for new software-based features in automotive systems is increasing day by day. This leads to the increasing complexity of embedded systems. A distributed real-time system consists of a set of nodes that are interconnected by a local area network and communicate via message passing only. The order of the events can be interpreted by time. Clocks are typically local counters that are increased with a predefined rate according to real-time. Clock synchronization algorithms ensure that any two clocks in the system read the same value at about the same point in realtime. This is achieved by clock synchronization that changes the current values of the clocks, the clocks' rate, or both. Synchronization ensures that operations occur in the logically correct order. Clock drift happens when the local clock gets calculated incorrectly, causing it to slowly drift in real-time. Larger deviations and increased drift are observed while the system is running without any synchronization. This paper is aimed to present a process to find the root cause of a clock drift problem.},
  keywords={},
  doi={10.1109/UYMS54260.2021.9659670},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{9671385,
  author={Alemany, Sheila and Nucciarone, Jason and Pissinou, Niki},
  booktitle={2021 IEEE International Conference on Big Data (Big Data)}, 
  title={Jespipe: A Plugin-Based, Open MPI Framework for Adversarial Machine Learning Analysis}, 
  year={2021},
  volume={},
  number={},
  pages={3663-3670},
  abstract={Research is increasingly showing the tremendous vulnerability in machine learning models to seemingly undetectable adversarial inputs. One of the current limitations in adversarial machine learning research is the incredibly time-consuming testing of novel defenses against various attacks and across multiple datasets, even with high computing power. To address this limitation, we have developed Jespipe as a new plugin-based, parallel-by-design Open MPI framework that aids in evaluating the robustness of machine learning models. The plugin-based nature of this framework enables researchers to specify any pre-training data manipulations, machine learning models, adversarial models, and analysis or visualization metrics with their input Python files. Because this framework is plugin-based, a researcher can easily incorporate model implementations using popular deep learning libraries such as PyTorch, Keras, TensorFlow, Theano, or MXNet, or adversarial robustness tools such as IBM’s Adversarial Robustness Toolbox or Foolbox. The parallelized nature of this framework also enables researchers to evaluate various learning or attack models with multiple datasets simultaneously by specifying all the models and datasets they would like to test with our XML control file template. Overall, Jespipe shows promising results by reducing latency in adversarial machine learning algorithm development and testing compared to traditional Jupyter notebook workflows.},
  keywords={},
  doi={10.1109/BigData52589.2021.9671385},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{9669317,
  author={Thavappiragasam, Mathialakan and Kale, Vivek and Hernandez, Oscar and Sedova, Ada},
  booktitle={2021 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)}, 
  title={Addressing Load Imbalance in Bioinformatics and Biomedical Applications: Efficient Scheduling across Multiple GPUs}, 
  year={2021},
  volume={},
  number={},
  pages={1992-1999},
  abstract={Computational bioinformatics and biomedical applications frequently contain heterogeneously sized units of work or tasks, for instance due to variability in the sizes of biological sequences and molecules. Variable-sized workloads lead to load imbalances in parallel implementations which detract from efficiency and performance. Many modern computing resources now have multiple graphics processing units(GPUs) per computer for acceleration. These multiple GPU resources need to be used efficiently through balancing of workloads across the GPUs. OpenMP is a portable directive-based parallel programming API used ubiquitously in bioscience applications to program CPUs; recently, the use of OpenMP directives for GPU acceleration has become possible. Here, motivated by experiences with imbalanced loads in GPU-accelerated bioinformatics applications, we address the load balancing problem using OpenMP task-to-GPU scheduling combined with OpenMP GPU offloading for multiply heterogeneous workloads – loads with both variable input sizes, and simultaneously, variable convergence rates for algorithms with a stochastic component – scheduled across multiple GPUs. We aim to develop strategies which are both easy to use and have lower overheads, and may be incorporated incrementally in existing programs which already make use of OpenMP for CPU-based threading in order to make use of multi-GPU computers. We test different combinations of input size variability and convergence rate variability, and characterize the effects of these different scenarios on the performance of scheduling strategies across multiple GPUs with OpenMP. We present several dynamic scheduling solutions for different parallel patterns, explore optimizations, and provide publicly available example computational kernels to make these strategies easy to use in programs. This work will enable application developers to efficiently and easily use multiple GPUs for imbalanced workloads found in bioinformatics and biomedical applications.},
  keywords={},
  doi={10.1109/BIBM52615.2021.9669317},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{9680456,
  author={Gueroudji, Amal and Bigot, Julien and Raffin, Bruno},
  booktitle={2021 IEEE 28th International Conference on High Performance Computing, Data, and Analytics (HiPC)}, 
  title={DEISA: Dask-Enabled In Situ Analytics}, 
  year={2021},
  volume={},
  number={},
  pages={11-20},
  abstract={A widening performance gap is separating CPU performance and IO bandwidth on large scale systems. In some fields such as weather forecast and nuclear fusion, numerical models generate such amounts of data that classical post hoc processing is not feasible anymore due to the limits in both storage capacity and IO performance. In situ approaches are attractive to bypass disk accesses in these cases and fully leverage the HPC platform. They are however often complex to set up and can require to re-develop parallel versions of the analysis from scratch. In this paper we propose a hybrid model that is well suited for in situ workflows that combine regular simulations and irregular analytics. Our model couples the bulk synchronous parallel paradigm for simulation with a distributed task-based one for analysis. This reduces complexity and leverages the best of each of these two powerful paradigms. We validate the model with a prototype, called DEISA, that supports coupling MPI parallel codes with analyses written using Dask. This implementation requires minimal modifications of both the simulation and analysis codes compared to their post hoc counterpart. It give access to an already existing rich ecosystem to be used in situ such as the parallel versions of Numpy, Pandas and scikit-learn. Experiments in configurations up to 1024 cores show that DEISA can improve the simulation wallclock time (excluding analysis) by a factor up to 3 and the total experiment (including analysis) hour. core cost by a factor of up to 5 compared to parallel post hoc with plain Dask while requiring the modification of only two lines of python code, three of YAML, and none at all in a C simulation code already instrumented with PDI Data Interface.},
  keywords={},
  doi={10.1109/HiPC53243.2021.00015},
  ISSN={2640-0316},
  month={Dec},}
@ARTICLE{9691018,
  author={Ivkovic, Mladen and Teyssier, Romain},
  journal={Monthly Notices of the Royal Astronomical Society}, 
  title={ACACIA: a new method to produce on-the-fly merger trees in the RAMSES code}, 
  year={2021},
  volume={510},
  number={1},
  pages={959-979},
  abstract={The implementation of ACACIA, a new algorithm to generate dark matter halo merger trees with the Adaptive Mesh Refinement code RAMSES, is presented. The algorithm is fully parallel and based on the Message Passing Interface. As opposed to most available merger tree tools, it works on the fly during the course of the N-body simulation. It can track dark matter substructures individually using the index of the most bound particle in the clump. Once a halo (or a sub-halo) merges into another one, the algorithm still tracks it through the last identified most bound particle in the clump, allowing to check at later snapshots whether the merging event was definitive, or whether it was only temporary, with the clump only traversing another one. The same technique can be used to track orphan galaxies that are not assigned to a parent clump anymore because the clump dissolved due to numerical overmerging. We study in detail the impact of various parameters on the resulting halo catalogues and corresponding merger histories. We then compare the performance of our method using standard validation diagnostics, demonstrating that we reach a quality similar to the best available and commonly used merger tree tools. As a proof of concept, we use our merger tree algorithm together with a parametrized stellar-mass-to-halo-mass relation and generate a mock galaxy catalogue that shows good agreement with observational data.},
  keywords={},
  doi={10.1093/mnras/stab3329},
  ISSN={1365-2966},
  month={Nov},}
@INPROCEEDINGS{9686405,
  author={Tsao, Yung-Chung and Kuo, Yaw-Wen and Wu, Chia-Chun and Tsai, Yin-Te and Hsu, Chih-Cheng},
  booktitle={2021 International Conference on Electronic Communications, Internet of Things and Big Data (ICEIB)}, 
  title={Development of an Electricity Loop Current Monitor System Based on MQTT Broker}, 
  year={2021},
  volume={},
  number={},
  pages={101-104},
  abstract={The energy monitoring system is always a critical and popular issue for a long time, although many information systems have been built and deployed into schools, factories, schools, commercial organizations, and governments. For many years, most of them have closed systems based on their business considerations, so add-on sensor types or heterogeneous hardware and software integrations are the bottlenecks. The study is carried out to integrate the internet of thing (IoT) and message queue telemetry transport (MQTT) to design a mechanism and to implement a prototyping clouding platform as the proposed system to develop the AC collectors with electricity loop current sensors connected to the proposed controller with Ameba 8195 AM in the study. The AC collectors are deployed in labs and classrooms in the National Chi Nan University and classrooms in Xinhe Elementary School to validate the usability and feasibility of the proposed controllers and the prototyping web system. A distributed message-deliver is developed as a publisher based on MQTT Broker to implement a central message-collector as a subscriber to transmit all data into the proposed system. The analytical and visualized reports are created for users and administrators in the proposed system to offer useful and real-time information as feedback to be the proof of concept (PoC).},
  keywords={},
  doi={10.1109/ICEIB53692.2021.9686405},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{9691975,
  author={Dehnavi, Saeid and Goswami, Dip and Goossens, Kees},
  booktitle={2021 IEEE 14th International Symposium on Embedded Multicore/Many-core Systems-on-Chip (MCSoC)}, 
  title={Analyzable Publish-Subcribe Communication Through a Wait-Free FIFO Channel for MPSoC Real-Time Applications}, 
  year={2021},
  volume={},
  number={},
  pages={388-395},
  abstract={As a transparent communication protocol for concurrent distributed applications, the Publish-Subscribe (Pub-Sub) paradigm is a trending programming model in many recent industrial use-cases in robotics and avionics. To apply the Pub-Sub programming model for safety-critical concurrent realtime applications in Multi-Processor Systems on Chip (MPSoC) environments, a non-blocking wait-free First-In-First-Out (FIFO) channel is a fundamental requirement. However, the proposed approaches in the literature have no proven real-time guarantees. In this paper, we propose a novel wait-free FIFO approach for single-producer-single-consumer core-to-core communication through shared memory. By analyzing the execution paths of each involved process, we prove that the execution time of each read/write operation is bounded by a Worst Case Execution Time (WCET). Moreover, we define a Timed Automata model of our approach. Using the UPPAAL model checker, we prove freedom of deadlock and starvation. For the performance evaluation of the proposed approach, we apply a stochastic analysis technique on the defined UPPAAL model. Finally, we implement the proposed approach on the CompSOC platform as the underlying realtime MPSoC to show that the implementation conforms to the proposed formal model and to experimentally validate the formal properties. The experimental evaluation on an instance of CompSOC that works at 40 MHz has a throughput of 109K tokens per second.},
  keywords={},
  doi={10.1109/MCSoC51149.2021.00064},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{9705019,
  author={Wright, Jordan and Fink, Zane and Gowanlock, Michael and Philabaum, Christopher and Donnelly, Brian and Cambou, Bertrand},
  booktitle={2021 IEEE Conference on Communications and Network Security (CNS)}, 
  title={A Symmetric Cipher Response-Based Cryptography Engine Accelerated Using GPGPU}, 
  year={2021},
  volume={},
  number={},
  pages={146-154},
  abstract={Many low-powered devices, such as those in the Internet of Things (IoT), require high levels of security. One shortfall of cryptographic systems is the storage of private key information in non-volatile memory that an opponent can read. Client devices can generate private keys on-demand using a physically unclonable function (PUF) to obviate this problem. However, low-powered devices may not have the computational resources to correct for the error in the PUF relative to the initially recorded PUF challenge. Response-based cryptography (RBC), when combined with encrypting schemes such as the Advanced Encryption Standard (AES), addresses this problem by having a secure server perform a search over the key space starting from a client device’s initially recorded challenge. We propose an RBC engine based on symmetric ciphers that uses graphics processing units (GPUs). We use the GPU to perform a massively parallel search over the key space to authenticate the client’s key(s). The computational requirements for executing the search and authenticating the user within a time threshold, T, increase exponentially. This limits the classes of computers that are able to perform the search. To address this problem, we employ a scheme that generates subkeys from the PUF. This increases the granularity of computational capabilities that are able to perform the RBC search within the selected $T=5$ s authentication threshold. We compare our algorithm, GRBC, to an OpenSSL-based MPI reference implementation executed on up to 512 CPU cores. Our approach using the GPU achieves superior key search throughput over the CPU.},
  keywords={},
  doi={10.1109/CNS53000.2021.9705019},
  ISSN={},
  month={Oct},}
@INPROCEEDINGS{9703612,
  author={Zribi, Amin and Song, Shulin and Matsumoto, Tad},
  booktitle={2021 IEEE Conference on Antenna Measurements & Applications (CAMA)}, 
  title={LDPC-based multi-relay lossy forwarding for correlated source transmission over orthogonal Rayleigh fading channels}, 
  year={2021},
  volume={},
  number={},
  pages={579-583},
  abstract={In this paper, we design a communication and coding strategy for Lossy Forwarding (LF) systems with multiple relay nodes or helpers based on Low-Density Parity-check Codes (LDPC) with message passing decoding applied on a Tanner-graph that maps all the network. The system performance is investigated under the cases of a fixed number of helpers, and a random multiple shifted-Poisson distributed helpers for orthogonal Rayleigh fading channels. All the practical results will be also compared and validated with respect to theoretical outage probabilities.},
  keywords={},
  doi={10.1109/CAMA49227.2021.9703612},
  ISSN={2643-6795},
  month={Nov},}
@INPROCEEDINGS{9721343,
  author={Xu, Yao and Zhao, Zhengji and Garg, Rohan and Khetawat, Harsh and Hartman–Baker, Rebecca and Cooperman, Gene},
  booktitle={2021 SC Workshops Supplementary Proceedings (SCWS)}, 
  title={MANA-2.0: A Future-Proof Design for Transparent Checkpointing of MPI at Scale}, 
  year={2021},
  volume={},
  number={},
  pages={68-78},
  abstract={MANA-2.0 is a scalable, future-proof design for transparent checkpointing of MPI-based computations. Its network transparency (“network-agnostic”) feature ensures that MANA-2.0 will provide a viable, efficient mechanism for trans-parently checkpointing MPI applications on current and future supercomputers. MANA-2.0 is an enhancement of previous work, the original MANA, which interposes MPI calls, and is a work in progress intended for production deployment. MANA-2.0 implements a series of new algorithms and features that improve MANA's scalability and reliability, enabling transparent checkpoint-restart over thousands of MPI processes. MANA-2.0 is being tested on today's Cori supercomputer at NERSC using Cray MPICH library over the Cray GNI network, but it is designed to work over any standard MPI running over an arbitrary network. Two widely-used HPC applications were selected to demonstrate the enhanced features of MANA-2.0: GROMACS, a molecular dynamics simulation code with frequent point-to-point communication, and VASP, a materials science code with frequent MPI collective communication. Perhaps the most important lesson to be learned from MANA-2.0 is a series of algorithms and data structures for library-based transformations that enable MPI-based computations over MANA-2.0 to reliably survive the checkpoint-restart transition.},
  keywords={},
  doi={10.1109/SCWS55283.2021.00019},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{9721328,
  author={Kamil, Amir and Bonachea, Dan},
  booktitle={2021 SC Workshops Supplementary Proceedings (SCWS)}, 
  title={Optimization of Asynchronous Communication Operations through Eager Notifications}, 
  year={2021},
  volume={},
  number={},
  pages={23-32},
  abstract={UPC++ is a C++ library implementing the Asynchronous Partitioned Global Address Space (APGAS) model. We propose an enhancement to the completion mechanisms of UPC++ used to synchronize communication operations that is designed to reduce overhead for on-node operations. Our enhancement permits eager delivery of completion notification in cases where the data transfer semantics of an operation happen to complete synchronously, for example due to the use of shared-memory bypass. This semantic relaxation allows removing significant overhead from the critical path of the implementation in such cases. We evaluate our results on three different representative systems using a combination of microbenchmarks and five variations of the the HPCChallenge RandomAccess benchmark implemented in UPC++ and run on a single node to accentuate the impact of locality. We find that in RMA versions of the benchmark written in a straightforward manner (without manually optimizing for locality), the new eager notification mode can provide up to a 25% speedup when synchronizing with promises and up to a 13.5x speedup when synchronizing with conjoined futures. We also evaluate our results using a graph matching application written with UPC++ RMA communication, where we measure overall speedups of as much as 11% in single-node runs of the unmodified application code, due to our transparent enhancements.},
  keywords={},
  doi={10.1109/SCWS55283.2021.00014},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{9723203,
  author={Gholami, Roya and Cottatellucci, Laura and Slock, Dirk},
  booktitle={2021 55th Asilomar Conference on Signals, Systems, and Computers}, 
  title={Message Passing for a Bayesian Semi-Blind Approach to Cell-Free Massive MIMO}, 
  year={2021},
  volume={},
  number={},
  pages={1237-1241},
  abstract={In this paper, we consider cell-free (CF) massive MIMO systems employing a massive number of access points (APs) geographically distributed over a wide area to jointly serve a smaller number of users over the same time-frequency resources. We consider semi-blind methods for channel estimation in the presence of Gaussian i.i.d. data to resolve the pilot contamination. This task is further aided by exploiting prior channel information in a Bayesian formulation. We propose a variable level expectation propagation (VL-EP) algorithm for message passing (MP) style semi-blind channel estimation which provides an approximate minimum mean square error (MMSE) channel estimator (which itself can not be found analytically). Numerical simulations verify the analytical derivations and the proposed algorithm.},
  keywords={},
  doi={10.1109/IEEECONF53345.2021.9723203},
  ISSN={2576-2303},
  month={Oct},}
@INPROCEEDINGS{9763717,
  author={Krakowski, Filip and Ruhland, Fabian and Schöttner, Michael},
  booktitle={2021 IEEE 27th International Conference on Parallel and Distributed Systems (ICPADS)}, 
  title={Infinileap: Modern High-Performance Networking for Distributed Java Applications based on RDMA}, 
  year={2021},
  volume={},
  number={},
  pages={652-659},
  abstract={In this paper, we propose Infinileap, a modern networking framework enabling high-performance memory transfer mechanisms like Remote Direct Memory Access (RDMA) for applications written in Java. Infinileap is based on the Open Communication X (UCX) framework, which is accessed from Java. This is accomplished through Oracle's Project Panama, which is currently in the preview phase and aims to significantly improve interoperability between Java and “foreign” languages, such as C. In contrast to often used internal and unsupported JDK APIs, Project Panama's APIs are explicitly intended for use and developers are encouraged to adapt their existing code accordingly. Using Project Panama, we implement an object as well as future-oriented framework based on UCX. Our experiments show that Infinileap and thus Project Panama's innovations work reliably and efficiently under heavy load and also, within benchmarks implemented for this purpose based on the Java Microbenchmark Harness (JMH), achieve very good performance results with over 110 million messages per second and round-trip latencies below two microseconds with a single ConnectX-5 InfiniBand (single-port) network interface controller.},
  keywords={},
  doi={10.1109/ICPADS53394.2021.00087},
  ISSN={2690-5965},
  month={Dec},}
@INPROCEEDINGS{9763673,
  author={Siebert, Christian},
  booktitle={2021 IEEE 27th International Conference on Parallel and Distributed Systems (ICPADS)}, 
  title={Highly Scalable Parallel Checksums}, 
  year={2021},
  volume={},
  number={},
  pages={812-818},
  abstract={Checksums are used to detect errors that might occur while storing or communicating data. Checking the integrity of data is well-established, but only for smaller data sets. Contrary, supercomputers have to deal with huge amounts of data, which introduces failures that may remain undetected. Therefore, additional protection becomes a necessity at large scale. However, checking the integrity of larger data sets, especially in case of distributed data, clearly requires parallel approaches. We show how popular checksums, such as CRC-32 or Adler-32, can be parallelized efficiently. This also disproves a widespread belief that parallelizing aforementioned checksums, especially in a scalable way, is not possible. The mathematical properties behind these checksums enable a method to combine partial checksums such that its result corresponds to the checksum of the concatenated partial data. Our parallel checksum algorithm utilizes this combination idea in a scalable hierarchical reduction scheme to combine the partial checksums from an arbitrary number of processing elements. Although this reduction scheme can be implemented manually using most parallel programming interfaces, we use the Message Passing Interface, which supports such a functionality directly via non-commutative user-defined reduction operations. In conjunction with the efficient checksum capabilities of the zlib library, our algorithm can not only be implemented conveniently and in a portable way, but also very efficiently. Additional shared-memory parallelization within compute nodes completes our hybrid parallel checksum solutions, which show a high scalability of up to 524,288 threads. At this scale, computing the checksums of 240 TiB data took only 3.4 seconds for CRC-32 and 2.6 seconds for Adler-32. Finally, we discuss the APES application as a representative of dynamic supercomputer applications. Thanks to our scalable checksum algorithm, even such applications are now able to detect many errors within their distributed data sets.},
  keywords={},
  doi={10.1109/ICPADS53394.2021.00107},
  ISSN={2690-5965},
  month={Dec},}
@INPROCEEDINGS{9774494,
  author={Chester, Dean G. and Groves, Taylor and Hammond, Simond D. and Law, Tim and Wright, Steven A. and Smedley-Stevenson, Richard and Fahmy, Suhaib A. and Mudalidge, Gihan R. and Jarvis, Stephen A.},
  booktitle={2021 IEEE High Performance Extreme Computing Conference (HPEC)}, 
  title={StressBench: A Configurable Full System Network and I/O Benchmark Framework}, 
  year={2021},
  volume={},
  number={},
  pages={1-8},
  abstract={We present StressBench, a network benchmarking framework written for testing MPI operations and file I/O concurrently. It is designed specifically to execute MPI communication and file access patterns that are representative of real-world scientific applications. Existing tools consider either the worst case congestion with small abstract patterns or peak performance with simplistic patterns. StressBench allows for a richer study of congestion by allowing orchestration of network load scenarios that are representative of those typically seen at HPC centres, something that is difficult to achieve with existing tools. We demonstrate the versatility of the framework from micro benchmarks through to finely controlled congested runs across a cluster. Validation of the results using four proxy application communication schemes within StressBench against parent applications shows a maximum difference of 15%. Using the I/O modeling capabilities of StressBench, we are able to quantify the impact of file I/O on application traffic showing how it can be used in procurement and performance studies.},
  keywords={},
  doi={10.1109/HPEC49654.2021.9774494},
  ISSN={2643-1971},
  month={Sep.},}
@INPROCEEDINGS{9781127,
  author={Chen, Mingkang and Sun, Jingtao and Aida, Kento and Figueiredo, Renato J. and Ku, Yun-Jung and Subratie, Kensworth},
  booktitle={2021 IEEE 23rd Int Conf on High Performance Computing & Communications; 7th Int Conf on Data Science & Systems; 19th Int Conf on Smart City; 7th Int Conf on Dependability in Sensor, Cloud & Big Data Systems & Application (HPCC/DSS/SmartCity/DependSys)}, 
  title={Intelligent Live Video Streaming for Object Detection}, 
  year={2021},
  volume={},
  number={},
  pages={1427-1434},
  abstract={These days, sensors and cameras are being deployed on an increasingly large scale. Furthermore, the rapid development of machine learning models for computer vision now presents novel opportunities for the use of artificial intelligence (AI) and Internet of Things (IoT) combinations in various application scenarios. However, challenges remain in supporting low-latency video streaming from distributed mobile IoT devices under dynamic network environments, and overcoming video data quality degradation that results from weather “noise”, which reduces the accuracy of AI-based data analyses such as object detection. In this paper, we propose a live video stream processing system for supporting intelligent services that integrates the following features. First, to cope with dynamic networks and achieve low latency, our approach employs a peer-to-peer (P2P)-based virtual network at the edge and a multi-tiered architecture composed of IoT cameras, edge, and cloud servers. Second, we construct a flexible messaging system for video analysis built upon SINETStream, which is a messaging system that adopts a topic-based pub/sub model. Third, we implement a framework that can remove weather-related (rain, snow, and fog) noise by applying weather classification and adaptive noise removal models that improve the accuracy of video analysis from data collected outdoors. The latency, throughput, and image quality benchmark experiments conducted to validate the feasibility of our proposed system showed that the process resulted in image quality improvements of approximately 30% (on average).},
  keywords={},
  doi={10.1109/HPCC-DSS-SmartCity-DependSys53884.2021.00214},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{9910065,
  author={Häner, Thomas and Steiger, Damian S. and Hoefler, Torsten and Troyer, Matthias},
  booktitle={SC21: International Conference for High Performance Computing, Networking, Storage and Analysis}, 
  title={Distributed Quantum Computing with QMPI}, 
  year={2021},
  volume={},
  number={},
  pages={1-15},
  abstract={Practical applications of quantum computers require millions of physical qubits and it will be challenging for individual quantum processors to reach such qubit numbers. It is therefore timely to investigate the resource requirements of quantum algorithms in a distributed setting, where multiple quantum processors are inter-connected by a coherent network. We introduce an extension of the Message Passing Interface (MPI) to enable high-performance implementations of distributed quantum algorithms. In turn, these implementations can be used for testing, debugging, and resource estimation. In addition to a prototype implementation of quantum MPI, we present a performance model for distributed quantum computing, SENDQ. The model is inspired by the classical LogP model, making it useful to inform algorithmic decisions when program-ming distributed quantum computers. Specifically, we consider several optimizations of two quantum algorithms for problems in physics and chemistry, and we detail their effects on performance in the SENDQ model.},
  keywords={},
  doi={10.1145/3458817.3476172},
  ISSN={2167-4337},
  month={Nov},}
@ARTICLE{9290413,
  author={Ascensión, Alex M. and Araúzo-Bravo, Marcos J.},
  journal={IEEE/ACM Transactions on Computational Biology and Bioinformatics}, 
  title={BigMPI4py: Python Module for Parallelization of Big Data Objects Discloses Germ Layer Specific DNA Demethylation Motifs}, 
  year={2022},
  volume={19},
  number={3},
  pages={1507-1522},
  abstract={Parallelization in Python integrates Message Passing Interface via the mpi4py module. Since mpi4py does not support parallelization of objects greater than $2^{31}$231 bytes, we developed BigMPI4py, a Python module that wraps mpi4py, supporting object sizes beyond this boundary. BigMPI4py automatically determines the optimal object distribution strategy, and uses vectorized methods, achieving higher parallelization efficiency. BigMPI4py facilitates the implementation of Python for Big Data applications in multicore workstations and High Performance Computer systems. We use BigMPI4py to speed-up the search for germ line specific de novo DNA methylated/unmethylated motifs from the 59 whole genome bisulfite sequencing DNA methylation samples from 27 human tissues of the ENCODE project. We developed a parallel implementation of the Kruskall-Wallis test to find CpGs with differential methylation across germ layers. The parallel evaluation of the significance of 55 million CpG achieved a 22x speedup with 25 cores allowing us an efficient identification of a set of hypermethylated genes in ectoderm and mesoderm-related tissues, and another set in endoderm-related tissues and finally, the discovery of germ layer specific DNA demethylation motifs. Our results point out that DNA methylation signal provide a higher degree of information for the demethylated state than for the methylated state. BigMPI4py is available at https://https://www.arauzolab.org/tools/bigmpi4py and https://gitlab.com/alexmascension/bigmpi4py and the Jupyter Notebook with WGBS analysis at https://gitlab.com/alexmascension/wgbs-analysis.},
  keywords={},
  doi={10.1109/TCBB.2020.3043979},
  ISSN={1557-9964},
  month={May},}
@ARTICLE{9328547,
  author={Fernandez, Arturo},
  journal={IEEE Transactions on Cloud Computing}, 
  title={Evaluation of the Performance of Tightly Coupled Parallel Solvers and MPI Communications in IaaS From the Public Cloud}, 
  year={2022},
  volume={10},
  number={4},
  pages={2613-2622},
  abstract={IaaS from the public cloud is becoming a new option for organizations in need of HPC capabilities. IaaS offers greater flexibility in hardware choices and operational costs. Furthermore, IaaS enables small organizations to access resources previously reserved for organizations with larger capitals. This article uses the HPCG benchmark to assess the performance of parallel solvers, which are critical in computational engineering, and microbenchmarks to measure collective MPI operations. The benchmarks encompass IaaS from five cloud vendors (AWS, Google Cloud Platform, Azure, Oracle CIoud Infrastructure, and Packet), and two architectures, ARM and x86_64. The benchmarks cover clusters with up to 4500 cores and illustrate the benefits of higher network bandwidth when scaling up clusters. The results for some of the clusters are particularly promising as they exhibit good scalability and compare well to on-premises supercomputers. Additionally, the study includes a preliminary cost estimate based on on-demand prices for IaaS computational power and memory.},
  keywords={},
  doi={10.1109/TCC.2021.3052844},
  ISSN={2168-7161},
  month={Oct},}
@ARTICLE{9438942,
  author={Zhu, Xiaoxiong and Liu, Jie and Cui, Yian and Gong, Chunye},
  journal={IEEE Transactions on Geoscience and Remote Sensing}, 
  title={A Scalable Parallel Algorithm for 3-D Magnetotelluric Finite Element Modeling in Anisotropic Media}, 
  year={2022},
  volume={60},
  number={},
  pages={1-14},
  abstract={3-D magnetotelluric (MT) forward modeling has always been faced with the problems of high memory requirements and long computing time. In this article, we design a scalable parallel algorithm for 3-D MT finite element modeling in anisotropic media. The parallel algorithm is based on the distributed mesh storage, including multiple parallel granularities, and is implemented through multiple tools. Message-passing interface (MPI) is used to exploit process parallelisms for subdomains, frequencies, and solving equations. Thread parallelisms for merge sorting, element analysis, matrix assembly, and imposing Dirichlet boundary conditions are developed by Open Multi-Processing (OpenMP). We validate the algorithm through several model simulations and study the effects of topography and conductivity anisotropy on apparent resistivities and phase responses. Scalability tests are performed on the Tianhe-2 supercomputer to analyze the parallel performance of different parallel granularities. Three parallel direct solvers Supernodal LU (SUPERLU), MUltifrontal Massively Parallel sparse direct Solver (MUMPS), and Parallel Sparse matriX package (PASTIX) are compared in solving sparse systems of equations. As a result, reasonable parallel parameters are suggested for practical applications. The developed parallel algorithm is proven to be efficient and scalable.},
  keywords={},
  doi={10.1109/TGRS.2021.3078735},
  ISSN={1558-0644},
  month={},}
@ARTICLE{9459479,
  author={Tang, Houjun and Koziol, Quincey and Ravi, John and Byna, Suren},
  journal={IEEE Transactions on Parallel and Distributed Systems}, 
  title={Transparent Asynchronous Parallel I/O Using Background Threads}, 
  year={2022},
  volume={33},
  number={4},
  pages={891-902},
  abstract={Moving toward exascale computing, the size of data stored and accessed by applications is ever increasing. However, traditional disk-based storage has not seen improvements that keep up with the explosion of data volume or the speed of processors. Multiple levels of non-volatile storage devices are being added to handle bursty I/O, however, moving data across the storage hierarchy can take longer than the data generation or analysis. Asynchronous I/O can reduce the impact of I/O latency as it allows applications to schedule I/O early and to check their status later. I/O is thus overlapped with application communication or computation or both, effectively hiding some or all of the I/O latency. POSIX and MPI-I/O provide asynchronous read and write operations, but lack the support for non-data operations such as file open and close. Users also have to manually manage data dependencies and use low-level byte offsets, which requires significant effort and expertise to adopt. In this article, we present an asynchronous I/O framework that supports all types of I/O operations, manages data dependencies transparently and automatically, provides implicit and explicit modes for application flexibility, and error information retrieval. We implemented these techniques in HDF5. Our evaluation of several benchmarks and application workloads demonstrates it effectiveness on hiding the I/O cost from the application.},
  keywords={},
  doi={10.1109/TPDS.2021.3090322},
  ISSN={1558-2183},
  month={April},}
@ARTICLE{9511802,
  author={Papadopoulos, Lazaros and Soudris, Dimitrios and Kessler, Christoph and Ernstsson, August and Ahlqvist, Johan and Vasilas, Nikos and Papadopoulos, Athanasios I. and Seferlis, Panos and Prouveur, Charles and Haefele, Matthieu and Thibault, Samuel and Salamanis, Athanasios and Ioakimidis, Theodoros and Kehagias, Dionysios},
  journal={IEEE Transactions on Parallel and Distributed Systems}, 
  title={EXA2PRO: A Framework for High Development Productivity on Heterogeneous Computing Systems}, 
  year={2022},
  volume={33},
  number={4},
  pages={792-804},
  abstract={Programming upcoming exascale computing systems is expected to be a major challenge. New programming models are required to improve programmability, by hiding the complexity of these systems from application developers. The EXA2PRO programming framework aims at improving developers’ productivity for applications that target heterogeneous computing systems. It is based on advanced programming models and abstractions that encapsulate low-level platform-specific optimizations and it is supported by a runtime that handles application deployment on heterogeneous nodes. It supports a wide variety of platforms and accelerators (CPU, GPU, FPGA-based Data-Flow Engines), allowing developers to efficiently exploit heterogeneous computing systems, thus enabling more HPC applications to reach exascale computing. The EXA2PRO framework was evaluated using four HPC applications from different domains. By applying the EXA2PRO framework, the applications were automatically deployed and evaluated on a variety of computing architectures, enabling developers to obtain performance results on accelerators, test scalability on MPI clusters and productively investigate the degree by which each application can efficiently use different types of hardware resources.},
  keywords={},
  doi={10.1109/TPDS.2021.3104257},
  ISSN={1558-2183},
  month={April},}
@ARTICLE{9524502,
  author={Dichev, Kiril and De Sensi, Daniele and Nikolopoulos, Dimitrios S. and Cameron, Kirk W. and Spence, Ivor},
  journal={IEEE Transactions on Parallel and Distributed Systems}, 
  title={Power Log’n’Roll: Power-Efficient Localized Rollback for MPI Applications Using Message Logging Protocols}, 
  year={2022},
  volume={33},
  number={6},
  pages={1276-1288},
  abstract={In fault tolerance for parallel and distributed systems, message logging protocols have played a prominent role in the last three decades. Such protocols enable local rollback to provide recovery from fail-stop errors. Global rollback techniques can be straightforward to implement but at times lead to slower recovery than local rollback. Local rollback is more complicated but can offer faster recovery times. In this work, we study the power and energy efficiency implications of global and local rollback. We propose a power-efficient version of local rollback to reduce power consumption for non-critical, blocked processes, using Dynamic Voltage and Frequency Scaling (DVFS) and clock modulation (CM). Our results for 3 different MPI codes on 2 parallel systems show that power-efficient local rollback reduces CPU energy waste up to 50% during the recovery phase, compared to existing global and local rollback techniques, without introducing significant overheads. Furthermore, we show that savings manifest for all blocked processes, which grow linearly with the process count. We estimate that for settings with high recovery overheads the total energy waste of parallel codes is reduced with the proposed local rollback.},
  keywords={},
  doi={10.1109/TPDS.2021.3107745},
  ISSN={1558-2183},
  month={June},}
@ARTICLE{9585108,
  author={Guo, Mangqing and Gursoy, M. Cenk},
  journal={IEEE Transactions on Communications}, 
  title={Joint Activity Detection and Channel Estimation in Cell-Free Massive MIMO Networks With Massive Connectivity}, 
  year={2022},
  volume={70},
  number={1},
  pages={317-331},
  abstract={Cell-free massive MIMO is one of the key technologies for future wireless communications, in which users are simultaneously and jointly served by all access points (APs). In this paper, we investigate the minimum mean square error (MMSE) estimation of effective channel coefficients in cell-free massive MIMO systems with massive connectivity. To facilitate the theoretical analysis, only single measurement vector (SMV) based MMSE estimation is considered in this paper, i.e., the MMSE estimation is performed based on the received pilot signals at each AP separately. Inspired by the decoupling principle of replica symmetric postulated MMSE estimation of sparse signal vectors with independent and identically distributed (i.i.d.) non-zero components, we develop the corresponding decoupling principle for the SMV based MMSE estimation of sparse signal vectors with independent and non-identically distributed (i.n.i.d.) non-zero components, which plays a key role in the theoretical analysis of SMV based MMSE estimation of the effective channel coefficients in cell-free massive MIMO systems with massive connectivity. Subsequently, based on the obtained decoupling principle of MMSE estimation, likelihood ratio test and the optimal fusion rule, we perform user activity detection based on the received pilot signals at only one AP, or cooperation among the entire set of APs for centralized or distributed detection. Via theoretical analysis, we show that the error probabilities of both centralized and distributed detection tend to zero when the number of APs tends to infinity while the asymptotic ratio between the number of users and pilots is kept constant. We also investigate the asymptotic behavior of oracle estimation in cell-free massive MIMO systems with massive connectivity via random matrix theory. Moreover, in order to demonstrate the potential performance loss of SMV based MMSE estimation, which does not employ the correlation between the received pilot signals at different APs, the multiple measurement vector (MMV) based MMSE estimation, i.e., joint MMSE estimation with pilot signals from all APs, is analyzed via numerical results. Numerical analysis shows that the theoretical analyze with our decoupling principle for the SMV based MMSE estimation of sparse signal vectors with i.n.i.d. non-zero components matches well with the numerical results.},
  keywords={},
  doi={10.1109/TCOMM.2021.3122471},
  ISSN={1558-0857},
  month={Jan},}
@ARTICLE{9612082,
  author={Liu, Yuchen and Meng, Yixuan and Xu, Kaiyuan and Xu, Zijun and Wu, Tianyuan and Yang, Yiwei and Yin, Shu},
  journal={IEEE Transactions on Parallel and Distributed Systems}, 
  title={Reproducibility: Performance Evaluation of MemXCT on Azure CycleCloud Platform}, 
  year={2022},
  volume={33},
  number={9},
  pages={2047-2049},
  abstract={Memory-Centric X-ray Computational Tomography(CT) is an iterative reconstruction technique that trades compute simplifications with higher memory accesses. MemXCT implements a sparse matrix-vector multiplication(SpMV) with multi-stage buffering and two-level pseudo-Hilbert ordering for optimization. Motivated by the need to validate conclusions from previous work, we reproduce the numerical results, the algorithm’s performance, and the scaling behavior of the algorithms as the number of MPI processes increases on Azure. Digital artifacts from these experiments are available at: 10.5281/zenodo.5598108},
  keywords={},
  doi={10.1109/TPDS.2021.3127450},
  ISSN={1558-2183},
  month={Sep.},}
@ARTICLE{9618848,
  author={Cai, Haipeng and Fu, Xiaoqin},
  journal={IEEE Transactions on Software Engineering}, 
  title={D$^2$2Abs: A Framework for Dynamic Dependence Analysis of Distributed Programs}, 
  year={2022},
  volume={48},
  number={12},
  pages={4733-4761},
  abstract={As modern software systems are increasingly developed for running in distributed environments, it is crucial to provide fundamental techniques such as dependence analysis for checking, diagnosing, and evolving those systems. However, traditional dependence analysis is either inapplicable or of very limited utility for distributed programs due to the decoupled components of these programs which run in concurrent processes at physically separated machines. Motivated by the need for dependence analysis of distributed software and the diverse cost-effectiveness needs of dependence-based applications, this paper presents D$^2$2Abs, a framework of dynamic dependence analysis for distributed programs. By partially ordering distributed method execution events and inferring causality from the ordered events, D$^2$2Abs computes method-level dependencies both within and across process boundaries. Further, by exploiting message-passing semantics across processes, and incorporating static dependencies and statement coverage within individual components, D$^2$2Abs offers three additional instantiations that trade efficiency for better precision. We present the design of the D$^2$2Abs framework and evaluate the four instantiations of D$^2$2Abs on distributed systems of various architectures and scales using our implementation for Java. Our empirical results show that D$^2$2Abs is significantly more effective than existing options while offering varying levels of cost-effectiveness tradeoffs. As our framework essentially computes whole-system run-time dependencies, it naturally empowers a range of other dependence-based applications.},
  keywords={},
  doi={10.1109/TSE.2021.3124795},
  ISSN={1939-3520},
  month={Dec},}
@ARTICLE{9628092,
  author={Nassaji, Ehsan and Bashir, Murwan and Truhachev, Dmitri},
  journal={IEEE Transactions on Communications}, 
  title={Unsourced Random Access Over Fading Channels via Data Repetition, Permutation, and Scrambling}, 
  year={2022},
  volume={70},
  number={2},
  pages={1029-1042},
  abstract={We focus on an unsourced random access (URA) system for communication over fading channels where the payload of each packet is encoded for error-correction, repeated, permuted, and scrambled. Each packet is also equipped with a preamble that is used for channel estimation and detection of permutation and scrambling sequences utilized for payload encoding. We propose an algorithm to resolve multiple-access preamble transmission, based on the approximate message-passing (AMP), that is capable to support high numbers of active users and achieve low probabilities of miss-detection. We also develop a parallel interference cancellation technique for payload reception that iteratively refines the channel estimates and attempts to minimize the mean squared error (MSE) of the users’ data via selective error-correction decoding. Finally, we derive a detailed system performance analysis that closely matches the obtained numerical results. We demonstrate that the presented system can more than double the number of active users, supported by the state-of-the-art systems. Large gains in terms of the minimal required signal-to-noise ratios (SNR)s are also demonstrated for a wide range of active user numbers.},
  keywords={},
  doi={10.1109/TCOMM.2021.3131622},
  ISSN={1558-0857},
  month={Feb},}
@ARTICLE{9656896,
  author={Farsiabi, Ali and Banihashemi, Amir H.},
  journal={IEEE Communications Letters}, 
  title={Error Floor Analysis of LDPC Column Layered Decoders}, 
  year={2022},
  volume={26},
  number={3},
  pages={485-489},
  abstract={In this letter, we analyze the error floor of column layered decoders, also known as shuffled decoders, for low-density parity-check (LDPC) codes under saturating sum-product algorithm (SPA). To estimate the error floor, we evaluate the failure rate of different trapping sets (TSs) that contribute to the frame error rate in the error floor region. For each such TS, we model the dynamics of SPA in the vicinity of the TS by a linear state-space model that incorporates the information of the layered message-passing schedule. Consequently, the model parameters and the failure rate of the TS change as a result of the change in the order by which the messages of different layers are updated. This, in turn, causes the error floor of the code to change as a function of scheduling. Based on the proposed analysis, we then devise an efficient search algorithm to find a schedule that minimizes the error floor. Simulation results are presented to verify the accuracy of the proposed error floor estimation technique.},
  keywords={},
  doi={10.1109/LCOMM.2021.3137203},
  ISSN={1558-2558},
  month={March},}
@ARTICLE{9658308,
  author={Wu, Di and Zeng, Zhanxiu and Shi, Fengrui and Yu, Weiren and Wu, Tao and Liu, Qiang},
  journal={IEEE Transactions on Intelligent Transportation Systems}, 
  title={Human as a Service: Towards Resilient Parking Search System With Sensorless Sensing}, 
  year={2022},
  volume={23},
  number={8},
  pages={13863-13877},
  abstract={The high demand for ubiquitous availability of reliable parking spaces in cities faces challenges on timely information sharing and low-cost infrastructure deployment. In this paper, we propose a mobile crowdsensing system, namely ParkHop, to aggregate on-street and roadside parking space information through sensorless sensing, and disseminate this information to urban drivers in a resilient manner. ParkHop targets special social groups that have stable work routines to serve as crowd workers. We propose a crowdsensing algorithm employing a joint estimator to process crowdsensed data, and evaluate the reliability of crowd workers based on the veracity of their answers to a series of control questions. In addition, the specific worker selection method to speed up the crowdsensing process and incentive scheme to achieve fair reward distribution have been carefully designed in ParkHop. Our system disseminates the availability of parking spaces and their up-to-date price information to drivers with on-demand needs via a publish-subscribe messaging pattern. The efficacy of ParkHop for aggregation and dissemination of parking space information has been evaluated in both real-world tests and simulations. Our results show the system is robust and agile enough to cope with different crowdsensing scenarios.},
  keywords={},
  doi={10.1109/TITS.2021.3133713},
  ISSN={1558-0016},
  month={Aug},}
@ARTICLE{9686365,
  author={Jang, Hyeryung and Song, Hyungseok and Yi, Yung},
  journal={IEEE/ACM Transactions on Networking}, 
  title={On Cost-Efficient Learning of Data Dependency}, 
  year={2022},
  volume={30},
  number={3},
  pages={1382-1394},
  abstract={In this paper, we consider the problem of learning a tree graph structure that represents the statistical data dependency among nodes for a set of data samples generated by nodes, which provides the basic structure to perform a probabilistic inference task. Inference in the data graph includes marginal inference and maximum a posteriori (MAP) estimation, and belief propagation (BP) is a commonly used algorithm to compute the marginal distribution of nodes via message-passing, incurring non-negligible amount of communication cost. We inevitably have the trade-off between the inference accuracy and the message-passing cost because the learned structure of data dependency and physical connectivity graph are often highly different. In this paper, we formalize this trade-off in an optimization problem which outputs the data dependency graph that jointly considers learning accuracy and message-passing costs. We focus on two popular implementations of BP, ASYNC-BP and SYNC-BP, which have different message-passing mechanisms and cost structures. In ASYNC-BP, we propose a polynomial-time learning algorithm that is optimal, motivated by finding a maximum weight spanning tree of a complete graph. In SYNC-BP, we prove the NP-hardness of the problem and propose a greedy heuristic. For both BP implementations, we quantify how the error probability that the learned cost-efficient data graph differs from the ideal one decays as the number of data samples grows, using the large deviation principle, which provides a guideline on how many samples are necessary to obtain a certain trade-off. We validate our theoretical findings through extensive simulations, which confirms that it has a good match.},
  keywords={},
  doi={10.1109/TNET.2022.3141128},
  ISSN={1558-2566},
  month={June},}
@ARTICLE{9686627,
  author={Wang, Xinhua and Ashikhmin, Alexei and Dong, Zhicheng and Zhai, Chao},
  journal={IEEE Journal on Selected Areas in Communications}, 
  title={Two-Stage Channel Estimation Approach for Cell-Free IoT With Massive Random Access}, 
  year={2022},
  volume={40},
  number={5},
  pages={1428-1440},
  abstract={We investigate the activity detection and channel estimation issues for cell-free Internet of Things (IoT) networks with massive random access. In each time slot, only partial devices are active and communicate with neighboring access points (APs) using non-orthogonal random pilot sequences. Different from the centralized processing in cellular networks, the activity detection and channel estimation in cell-free IoT is more challenging due to the distributed and user-centric architecture. We propose a two-stage approach to detect the random activities of devices and estimate their channel states. In the first stage, the activity of each device is jointly detected by its adjacent APs based on the vector approximate message passing (Vector AMP) algorithm. In the second stage, each AP re-estimates the channel using the linear minimum mean square error (LMMSE) method based on the detected activities to improve the channel estimation accuracy. We derive closed-form expressions for the activity detection error probability and the mean-squared channel estimation errors for a typical device. Finally, we analyze the performance of the entire cell-free IoT network in terms of coverage probability. Simulation results validate the derived closed-form expressions and show that the cell-free IoT significantly outperforms the collocated massive MIMO and small-cell schemes in terms of coverage probability.},
  keywords={},
  doi={10.1109/JSAC.2022.3143213},
  ISSN={1558-0008},
  month={May},}
@ARTICLE{9727080,
  author={Shah, Manthan A. and Tokgöz, Çağatay and Salau, Babajide A.},
  journal={IEEE Transactions on Antennas and Propagation}, 
  title={Radar Cross Section Prediction Using Iterative Physical Optics With Physical Theory of Diffraction}, 
  year={2022},
  volume={70},
  number={6},
  pages={4683-4690},
  abstract={A new approach is presented to predict radar cross section (RCS) of electrically large conducting geometries using iterative physical optics (IPO) in conjunction with physical theory of diffraction (PTD). IPO is based on iterative refinement of physical optics (PO) currents to include multiple reflections. However, IPO does not yield sufficient accuracy in diffraction dominant regions since it does not properly include effects of edge diffractions. Hence, the proposed approach includes diffraction effects using PTD, which introduces edge currents. Diffracted fields due to these edge currents are radiated on triangular facets to modify the PO currents before IPO iterations. Scattered fields are computed from converged IPO surface currents and PTD edge currents. A new set of PTD edge currents excited by the fields due to the IPO currents are also found and the fields radiated by these PTD edge currents are added to the scattered fields. Therefore, interactions between the surface and edge currents are included. Computations are accelerated by parallel processing using message passing interface (MPI). Monostatic and bistatic RCS are predicted using the proposed approach for tail-wing and trihedral corner reflector geometries. The IPO-PTD results are compared with method of moments (MoM) and multilevel fast multipole method results obtained using field calculations involving bodies of arbitrary shape (FEKO) commercial electromagnetic simulation software for validation.},
  keywords={},
  doi={10.1109/TAP.2021.3137202},
  ISSN={1558-2221},
  month={June},}
@ARTICLE{9745052,
  author={Takahashi, Takashi and Kabashima, Yoshiyuki},
  journal={IEEE Transactions on Information Theory}, 
  title={Macroscopic Analysis of Vector Approximate Message Passing in a Model-Mismatched Setting}, 
  year={2022},
  volume={68},
  number={8},
  pages={5579-5600},
  abstract={In this study, macroscopic properties of the vector approximate message passing (VAMP) algorithm for inference of generalized linear models are investigated using a non-rigorous heuristic method of statistical mechanics when the true posterior cannot be used and the measurement matrix is a sample from rotation-invariant random matrix ensembles. The focus is on the correspondence between the non-rigorous replica analysis of statistical mechanics and the performance assessment of VAMP in the model-mismatched setting. The correspondence of this kind is well-known when the measurement matrix has independent and identically distributed entries. However, when the measurement matrix follows a general rotation-invariant matrix ensemble, the correspondence has been validated only under limited cases, such as the Bayes optimal inference or the convex empirical risk minimization. The result presented in this paper is to extend the scope of such correspondence. Herein, we heuristically derive the explicit formula of state-evolution equations, which macroscopically describe VAMP dynamics for the current model-mismatched case, and show that their fixed point is generally consistent with the replica symmetric solution obtained by the replica method of statistical mechanics. We also show that the fixed point of VAMP can exhibit a microscopic instability, which indicates that message variables continue to move by VAMP while their macroscopically summarized quantities converge to fixed values. The critical condition the for microscopic instability agrees with that for breaking the replica symmetry that is derived within the non-rigorous replica analysis. The results of the numerical experiments cross-check our findings.},
  keywords={},
  doi={10.1109/TIT.2022.3163342},
  ISSN={1557-9654},
  month={Aug},}
@ARTICLE{9749613,
  author={Mitra, Rangeet and Kaddoum, Georges},
  journal={IEEE Transactions on Cognitive Communications and Networking}, 
  title={Random Fourier Feature-Based Deep Learning for Wireless Communications}, 
  year={2022},
  volume={8},
  number={2},
  pages={468-479},
  abstract={Deep-learning (DL) has emerged as a powerful machine-learning technique for several problems encountered in generic wireless communications. Also, random Fourier Features (RFF) based DL has emerged as an attractive solution for several machine-learning problems; yet existing works lack rigorous analytical results to justify the viability of RFF based DL. To address this gap, we analytically quantify the viability of RFF based DL in this paper. Precisely, we present analytical proofs which show that the RFF based DL architectures have lower approximation-error and a lower probability of misclassification as compared to classical DL architectures for a fixed dataset-size. In addition, a new distribution-dependent RFF (DDRFF) is proposed to facilitate DL architectures with low training-complexity. The presented analytical contributions and the DDRFF are validated by relevant case-studies such as: a) line of sight (LOS)/non-line of sight (NLOS) classification, and b) message-passing based detection of low-density parity check (LDPC) codes over nonlinear visible light communication (VLC) channels. Especially, in the low training-data regime, the presented simulations depict significant performance gains for RFF based DL. Lastly, in all the presented simulations, it is observed that the proposed DDRFFs significantly outperform RFFs, which make them useful for potential machine-learning/DL applications for communication systems.},
  keywords={},
  doi={10.1109/TCCN.2022.3164898},
  ISSN={2332-7731},
  month={June},}
@INPROCEEDINGS{9744891,
  author={Huang, Zhiguo and Qian, Ling and Cai, Dunbo},
  booktitle={2022 IEEE International Conference on Electrical Engineering, Big Data and Algorithms (EEBDA)}, 
  title={A quantum computing simulator scheme using MPI technology on cloud platform}, 
  year={2022},
  volume={},
  number={},
  pages={752-754},
  abstract={With the deeply studied of quantum computing by research fellows, the computational complexity and time complexity of quantum algorithms gradually increase. The quantum computing simulator provides an effective platform for the development and verification of quantum algorithms. However, the running time and memory overhead during calculation will increase exponentially with the number of qubits. Therefore, the difficulty of high-speed quantum computing on classical computers will gradually increase. At present, a single node has been unable to meet the resource requirements of the algorithm in the quantum computing process, and it is necessary to expand the memory resources in the multi-node computing cluster. Message passing interface has high performance inter-process communication capabilities, which can balance the data transmission between different hosts. Quantum computing tasks can be distributed on several servers to work together to solve the same problem. Therefore, this paper designs an advanced scheme of deploying quantum computing programs on cloud computing platform to support message exchanging between servers using message passing interface to accelerate quantum computing.},
  keywords={},
  doi={10.1109/EEBDA53927.2022.9744891},
  ISSN={},
  month={Feb},}
@INPROCEEDINGS{9756699,
  author={Da Silva, Hígor Uélinton and Schepke, Claudio and Lucca, Natiele and Da Cruz Cristaldo, César Flaubiano and De Oliveira, Dalmo Paim},
  booktitle={2022 30th Euromicro International Conference on Parallel, Distributed and Network-based Processing (PDP)}, 
  title={Parallel OpenMP and OpenACC Mixing Layer Simulation}, 
  year={2022},
  volume={},
  number={},
  pages={181-188},
  abstract={It is estimated that up to 25% of the grain crop ends up being lost in the post-harvest. The correct drying of the beans is one of the measures to contain this loss. As the grain mass is a set of solid and empty spaces, its drying could be considered a problem of the coupled open-porous medium. In this paper, a mathematical and computer simulation model was proposed, which describes the convection in a free flow with a porous obstacle applied to the drying of the grain. A computational fluid dynamics scheme was implemented in FORTRAN using Finite Volume to simulate and compute the numerical solutions. The code is parallel implemented using OpenMP and OpenACC programming interfaces. As a result, there was a significant reduction in processing time in both cases. The total simulation time was eight times less for a multicore architecture (16 physical cores) and 17.3 times using a single GPU (Quadro M5000).},
  keywords={},
  doi={10.1109/PDP55904.2022.00036},
  ISSN={2377-5750},
  month={March},}
@INPROCEEDINGS{9756726,
  author={Feki, Raafat and Gabriel, Edgar},
  booktitle={2022 30th Euromicro International Conference on Parallel, Distributed and Network-based Processing (PDP)}, 
  title={Design and Evaluation of Multi-threaded Optimizations for Individual MPI I/O Operations}, 
  year={2022},
  volume={},
  number={},
  pages={122-126},
  abstract={Todays high-end parallel clusters are architecturally very complex. Most large scale applications nowadays are utilizing multiple parallel programming paradigms to achieve the required scalability, with MPI+threads being the most common approach. Yet, as of today, there is no parallel I/O library that matches this hybrid programming model. File I/O operations are typically executed by a single thread for each process. This paper explores multi-threaded optimizations for individual MPI I/O operations, an important step towards matching the execution model of modern parallel applications. We describe the changes necessary to the internal processing in the MPI I/O library as well as to the file access phase. We demonstrate the performance improvement of the redesigned functions using multiple benchmarks and on multiple platforms for many scenarios over the original, single-threaded version.},
  keywords={},
  doi={10.1109/PDP55904.2022.00027},
  ISSN={2377-5750},
  month={March},}
@ARTICLE{9770439,
  author={Hück, Alexander and Kreutzer, Sebastian and Protze, Joachim and Lehr, Jan-Patrick and Bischof, Christian and Terboven, Christian and Müller, Matthias S.},
  journal={IT Professional}, 
  title={Compiler-Aided Type Correctness of Hybrid MPI-OpenMP Applications}, 
  year={2022},
  volume={24},
  number={2},
  pages={45-51},
  abstract={Hybrid MPI–OpenMP applications employ message-passing interface (MPI)-enabled process-level, distributed computations on many compute nodes in conjunction with OpenMP shared-memory, thread-level parallelism for the most efficient computation. This poses challenges on the dynamic MPI correctness tool MUST and TypeART, its memory allocation tracking sanitizer extension based on the LLVM compiler framework. In particular, at the thread-level granularity of a process, MPI calls and memory allocations, which are both tracked for our analysis, can occur concurrently. To correctly handle this situation, we: 1) extended our compiler extension to handle OpenMP and 2) introduced thread-safety mechanisms to our runtime libraries, thus keeping the tracking of data consistent and avoiding data races. Our approach exhibits acceptable runtime and memory overheads, both typically below 30%.},
  keywords={},
  doi={10.1109/MITP.2021.3093949},
  ISSN={1941-045X},
  month={March},}
@INPROCEEDINGS{9774698,
  author={Tzenetopoulos, Achilleas and Masouros, Dimosthenis and Koliogeorgi, Konstantina and Xydis, Sotirios and Soudris, Dimitrios and Chazapis, Antony and Kozanitis, Christos and Bilas, Angelos and Pinto, Christian and Nguyen, Huy-Nam and Louloudakis, Stelios and Gardikis, Georgios and Vamvakas, George and Aubrun, Michelle and Symeonidou, Christy and Spitadakis, Vassilis and Xylogiannopoulos, Konstantinos and Peischl, Bernhard and Kalayci, Tahir Emre and Stocker, Alexander and Acquaviva, Jean-Thomas},
  booktitle={2022 Design, Automation & Test in Europe Conference & Exhibition (DATE)}, 
  title={EVOLVE: Towards Converging Big-Data, High-Performance and Cloud-Computing Worlds}, 
  year={2022},
  volume={},
  number={},
  pages={975-980},
  abstract={EVOLVE is a pan European Innovation Action that aims to fully-integrate High-Performance-Computing (HPC) hardware with state-of-the-art software technologies under a unique testbed, that enables the convergence of HPC, Cloud and Big-Data worlds and increases our ability to extract value from massive and demanding datasets. EVOLVE's advanced compute platform combines HPC-enabled capabilities, with transparent deployment in high abstraction level, and a versatile Big-Data processing stack for end-to-end workflows. Hence, domain experts have the potential to improve substantially the efficiency of existing services or introduce new models in the respective domains, e.g., automotive services, bus transportation, maritime surveillance and others. In this paper, we describe EVOLVE's testbed, and evaluate the performance of the integrated pilots from different domains.},
  keywords={},
  doi={10.23919/DATE54114.2022.9774698},
  ISSN={1558-1101},
  month={March},}
@INPROCEEDINGS{9787820,
  author={Yu, Hengbiao and Yin, Banghu and Yi, Xin},
  booktitle={2022 IEEE Conference on Software Testing, Verification and Validation (ICST)}, 
  title={Symbolic Verification of Message Signatures in MPI}, 
  year={2022},
  volume={},
  number={},
  pages={185-195},
  abstract={The Message Passing Interface (MPI) is the standard paradigm of programming in high performance computing. However, the inherent complexity and the large size of MPI standard make it difficult for programmers to use the MPI APIs correctly. This paper focuses on the mismatch errors of message signatures. Considering that MPI errors may occur during some intricate, low probability interleavings under specific inputs, we adopt symbolic verification to verify the correct match of message signatures. Specifically, we propose a precise method for modeling the match of message signatures of an execution path in terms of communicating sequential processes. To improve the scalability, we give a partial order reduction based optimization to reduce the complexity of path-level communication models. We have implemented our method as a prototype tool and evaluated it on the typical correctness benchmark MPI-Corbench and 8 real-world open source MPI programs, totaling 37K lines of code. The experimental results demonstrate the effectiveness and scalability of our method.},
  keywords={},
  doi={10.1109/ICST53961.2022.00029},
  ISSN={2159-4848},
  month={April},}
@ARTICLE{9797240,
  author={Wan, Lei and Zhu, Jiang and Cheng, En and Xu, Zhiwei},
  journal={IEEE Journal of Oceanic Engineering}, 
  title={Joint CFO, Gridless Channel Estimation and Data Detection for Underwater Acoustic OFDM Systems}, 
  year={2022},
  volume={47},
  number={4},
  pages={1215-1230},
  abstract={In this article, we propose an iterative receiver based on gridless variational Bayesian line spectra estimation (VALSE), named JCCD-VALSE, that jointly estimates the carrier frequency offset (CFO), the channel with high resolution and carries out data decoding. Based on a modularized point of view and motivated by the high resolution and low-complexity gridless VALSE algorithm, three modules named the VALSE module, the CFO estimation (CFO est.) module, and the decoder module are built. Soft information is exchanged between the modules to progressively improve the channel estimation and data decoding accuracy. Since the delays of multipath of the channel are treated as continuous parameters instead of on a grid, the leakage effect is avoided. Beside, the proposed approach is a more complete Bayesian approach as all the nuisance parameters, such as the noise variance, the parameters of the prior distribution of the channel, and the number of paths are automatically estimated. Numerical simulations and sea test data are utilized to demonstrate that the proposed approach performs better than the existing grid-based joint channel and data decoding approaches. Furthermore, it is also verified that joint processing, including CFO estimation, provides performance gain.},
  keywords={},
  doi={10.1109/JOE.2022.3162025},
  ISSN={1558-1691},
  month={Oct},}
@ARTICLE{9805776,
  author={Liu, Lei and Huang, Shunqi and Kurkoski, Brian M.},
  journal={IEEE Transactions on Information Theory}, 
  title={Memory AMP}, 
  year={2022},
  volume={68},
  number={12},
  pages={8015-8039},
  abstract={Approximate message passing (AMP) is a low-cost iterative parameter-estimation technique for certain high-dimensional linear systems with non-Gaussian distributions. AMP only applies to independent identically distributed (IID) transform matrices, but may become unreliable (e.g., perform poorly or even diverge) for other matrix ensembles, especially for ill-conditioned ones. To solve this issue, orthogonal/vector AMP (OAMP/VAMP) was proposed for general right-unitarily-invariant matrices. However, the Bayes-optimal OAMP/VAMP (BO-OAMP/VAMP) requires a high-complexity linear minimum mean square error (MMSE) estimator. This prevents OAMP/VAMP from being used in large-scale systems. To address the drawbacks of AMP and BO-OAMP/VAMP, this paper offers a memory AMP (MAMP) framework based on the orthogonality principle, which ensures that estimation errors in MAMP are asymptotically IID Gaussian. To realize the required orthogonality for MAMP, we provide an orthogonalization procedure for the local memory estimators. In addition, we propose a Bayes-optimal MAMP (BO-MAMP), in which a long-memory matched filter is used for interference suppression. The complexity of BO-MAMP is comparable to AMP. To asymptotically characterize the performance of BO-MAMP, a state evolution is derived. The relaxation parameters and damping vector in BO-MAMP are optimized based on state evolution. Most crucially, the state evolution of the optimized BO-MAMP converges to the same fixed point as that of the high-complexity BO-OAMP/VAMP for all right-unitarily-invariant matrices, and achieves the Bayes optimal MSE predicted by the replica method if its state evolution has a unique fixed point. Finally, simulations are provided to verify the theoretical results’ validity and accuracy.},
  keywords={},
  doi={10.1109/TIT.2022.3186166},
  ISSN={1557-9654},
  month={Dec},}
@INPROCEEDINGS{9803591,
  author={Mijić, Nenad and Davidović, Davor},
  booktitle={2022 45th Jubilee International Convention on Information, Communication and Electronic Technology (MIPRO)}, 
  title={Batched matrix operations on distributed GPUs with application in theoretical physics}, 
  year={2022},
  volume={},
  number={},
  pages={293-299},
  abstract={One of the most important and commonly used operations in many linear algebra functions is matrix-matrix multiplication (GEMM), which is also a key component in obtaining high performance of many scientific codes. It is a computationally intensive function requiring O(n3) operations, and its high computational intensity makes it well-suited to be significantly accelerated with GPUs. Today, many research problems require solving a very large number of relatively small GEMM operations that cannot utilise the entire GPU. To overcome this bottleneck, special functions have been developed that pack several GEMM operations into one and then compute them simultaneously on a GPU, which is called a batch operation. In this research work, we have proposed a different approach based on linking multiple GEMM operations to Message Passing Interface (MPI) processes and then binding multiple MPI processes to a single GPU. To increase GPU utilisation, more MPI processes (i.e. GEMM operations) are added. We implement and test this approach in the field of theoretical physics to compute entanglement properties through simulated annealing Monte Carlo simulation of quantum spin chains. For the specific use case, we were able to simulate a much larger spin system and achieve a speedup of up to 35× compared to the parallel CPU-only version.},
  keywords={},
  doi={10.23919/MIPRO55190.2022.9803591},
  ISSN={2623-8764},
  month={May},}
@INPROCEEDINGS{9814591,
  author={Yuan, Jide and Alexandropoulos, George C. and Kofidis, Eleftherios and Jensen, Tobias Lindstrom and De Carvalho, Elisabeth},
  booktitle={2022 IEEE International Conference on Communications Workshops (ICC Workshops)}, 
  title={Channel Tracking for RIS-Enabled Multi-User SIMO Systems in Time-Varying Wireless Channels}, 
  year={2022},
  volume={},
  number={},
  pages={145-150},
  abstract={Estimation of channel state information, balancing accuracy and pilot overhead, is critical for Single-Input Multiple-Output communication (SIMO) systems empowered by the emerging technology of Reconfigurable Intelligent Surfaces (RISs). Due to the predominantly passive nature of the RIS, the reflected signals are coupled together, rendering the estimation of the multiple cascaded channels a challenging task. Additionally, the time-varying feature of most of the realistic wireless channels drives up the cost of real-time channel tracking significantly, especially when RISs with massive numbers of unit elements are deployed. In this paper, capitalizing on a PARAllel FACtor (PARAFAC) decomposition of the received signal model, we unfold the three-dimension signal into matrices and present a low complexity channel tracking framework for the uplink of RIS-enabled multi-user SIMO communication systems. The proposed algorithm incorporates a PARAFAC-based estimator together with the generalized approximate message passing technique, combining their advantages for reducing the computational complexity and pilot overhead of channel tracking, while maintaining improved accuracy. Our numerical results validate the feasibility and efficiency of the proposed channel tracking approach for various system parameters.},
  keywords={},
  doi={10.1109/ICCWorkshops53468.2022.9814591},
  ISSN={2694-2941},
  month={May},}
@INPROCEEDINGS{9820686,
  author={Karamati, Sara and Hughes, Clayton and Hemmert, K. Scott and Grant, Ryan E. and Schonbein, W. Whit and Levy, Scott and Conte, Thomas M. and Young, Jeffrey and Vuduc, Richard W.},
  booktitle={2022 IEEE International Parallel and Distributed Processing Symposium (IPDPS)}, 
  title={“Smarter” NICs for faster molecular dynamics: a case study}, 
  year={2022},
  volume={},
  number={},
  pages={583-594},
  abstract={This work evaluates the benefits of using a “smart” network interface card (SmartNIC) as a compute accelerator for the example of the MiniMD molecular dynamics proxy application. The accelerator is NVIDIA's BlueField-2 card, which includes an 8-core Arm processor along with a small amount of DRAM and storage. We test the networking and data movement performance of these cards compared to a standard Intel server host using microbenchmarks and MiniMD. In MiniMD, we identify two distinct classes of computation, namely core computation and maintenance computation, which are executed in sequence. We restructure the algorithm and code to weaken this dependence and increase task parallelism, thereby making it possible to increase utilization of the BlueField-2 concurrently with the host. We evaluate our implementation on a cluster consisting of 16 dual-socket Intel Broadwell host nodes with one BlueField-2 per host-node. Our results show that while the overall compute performance of BlueField-2 is limited, using them with a modified MiniMD algorithm allows for up to 20% speedup over the host CPU baseline with no loss in simulation accuracy.},
  keywords={},
  doi={10.1109/IPDPS53621.2022.00063},
  ISSN={1530-2075},
  month={May},}
@INPROCEEDINGS{9825025,
  author={Yekbote, Pavan and Raj, Poojita and Anupindi, Ravi S. and B, Sudarshan T S},
  booktitle={2022 3rd International Conference for Emerging Technology (INCET)}, 
  title={An Extensible Framework for Task Partitioning on Heterogeneous Systems}, 
  year={2022},
  volume={},
  number={},
  pages={1-5},
  abstract={High performance computing applications have witnessed significant speedups in performance from leveraging the compute capabilities of heterogeneous platforms. These speedups are seldom taken advantage of in practice partly due to the inefficacy of mapping parallel sections of an application to specific processing units. Ascertaining this mapping necessitates taking into account the run time and compile time features of the application on a heterogeneous platform. This paper proposes a framework capable of classifying a high performance computing application to its optimal partitioning in a heterogeneous CPU-GPU target system. This classifier has been trained on a combination of run time execution metrics and compile time static code features of applications from different domains collected from benchmark suites such as Rodinia [1] and OmpSCR [2]. The contribution of this work is twofold - an extensible framework demonstrating the utility of accurate mapping and a pair of data sets that exhibit the significance of run time and compile time features on the framework estimating the effect of varied input type and size.},
  keywords={},
  doi={10.1109/INCET54531.2022.9825025},
  ISSN={},
  month={May},}
@INPROCEEDINGS{9821002,
  author={Fei, Guan},
  booktitle={2022 2nd Asia-Pacific Conference on Communications Technology and Computer Science (ACCTCS)}, 
  title={Distributed Streaming Computing Mode Based on Fast Message Mechanism}, 
  year={2022},
  volume={},
  number={},
  pages={383-387},
  abstract={The computing mode of distributed streaming computing system depends on the message transmission delay between nodes. Low data processing delay and high system throughput are one of the core indexes of distributed streaming computing system. By analyzing the characteristics of streaming data, the message sending and receiving mode and message processing mode of processing nodes under the application of real-time streaming computing. This paper presents a computing mode suitable for streaming computing applications. The computing mode optimizes the way of sending and receiving data by processing nodes and improves the way of data processing. The test results show that the designed computing mode has the advantages of high data throughput and low message processing delay.},
  keywords={},
  doi={10.1109/ACCTCS53867.2022.00085},
  ISSN={},
  month={Feb},}
@INPROCEEDINGS{9826068,
  author={Paudel, Anmol and Puri, Satish},
  booktitle={2022 22nd IEEE International Symposium on Cluster, Cloud and Internet Computing (CCGrid)}, 
  title={Accelerating Spatial Autocorrelation Computation with Parallelization, Vectorization and Memory Access Optimization: With a focus on rapid recalculation of COVID related spatial statistics for faster geospatial analysis and response}, 
  year={2022},
  volume={},
  number={},
  pages={544-554},
  abstract={Geographic information systems deal with spatial data and its analysis. Spatial data contains many attributes with location information. Spatial autocorrelation is a fundamental concept in spatial analysis. It suggests that similar objects tend to cluster in geographic space. Hotspots, an example of autocorrelation, are statistically significant clusters of spatial data. Other autocorrelation measures like Moran's I are used to quantify spatial dependence. Large scale spatial autocorrelation methods are compute-intensive. Fast methods for hotspots detection and analysis are crucial in recent times of COVID-19 pandemic. Therefore, we have developed parallelization methods on heterogeneous CPU and GPU environments. To the best of our knowledge, this is the first GPU and SIMD-based design and implementation of autocorrelation kernels. Earlier methods in literature intro-duced cluster-based and Map Reduce-based parallelization. We have used Intrinsics to exploit SIMD parallelism on x86 CPU architecture. We have used MPI Graph Topology to minimize inter- process communication. Our benchmarks for CPU/GPU optimizations gain upto 750X relative speedup with a 8 GPU setup when compared to baseline sequential implementation. Compared to the best implementation using OpenMP + R-tree data structure on a single compute node, our accelerated hotspots benchmark gains a 25X speedup. For real world US counties and COVID data evolution calculated over 500 days, we gain upto 110X speedup reducing time from 33 minutes to 0.3 minutes.},
  keywords={},
  doi={10.1109/CCGrid54584.2022.00064},
  ISSN={},
  month={May},}
@INPROCEEDINGS{9828286,
  author={Meng, Wei and Gu, Yidong and Bao, Jianjun and Lian, Zhen and Kong, Zhengmin and Yin, Weijun},
  booktitle={2022 13th Asian Control Conference (ASCC)}, 
  title={Spatially Modulated Sparse Code Multiple Access in Uplink Mine Communications}, 
  year={2022},
  volume={},
  number={},
  pages={1660-1664},
  abstract={The underground coal mining communication sys-tem puts forward higher communication requirements owing to the harsh environment and multiple-user communications in the practical scenario. For improving communication quality such as bit error rate (BER) in the coal mining system, we use the spatial modulation (SM) and sparse code multiple access (SCMA) jointly in the uplink transmission. In this multiple-input multiple-output (MIMO) system, conformal microstrip patch arrays are adopted. By exploiting the message passing algorithm to detect the sparse symbols, the base station is capable of serving multiple users simultaneously and hence solves the system overload problem. Taking the blockages and tunnel geometry into account, we investigate the BER pertaining to distinct distances when different fading distributions are involved. Finally, numerical results are given to verify the efficiency of this scheme.},
  keywords={},
  doi={10.23919/ASCC56756.2022.9828286},
  ISSN={2770-8373},
  month={May},}
@INPROCEEDINGS{9832981,
  author={Raptis, Theofanis P. and Passarella, Andrea},
  booktitle={2022 International Conference on Computer, Information and Telecommunication Systems (CITS)}, 
  title={On Efficiently Partitioning a Topic in Apache Kafka}, 
  year={2022},
  volume={},
  number={},
  pages={1-8},
  abstract={Apache Kafka addresses the general problem of delivering extreme high volume event data to diverse consumers via a publish-subscribe messaging system. It uses partitions to scale a topic across many brokers for producers to write data in parallel, and also to facilitate parallel reading of consumers. Even though Apache Kafka provides some out of the box optimizations, it does not strictly define how each topic shall be efficiently distributed into partitions. The well-formulated fine-tuning that is needed in order to improve an Apache Kafka cluster performance is still an open research problem. In this paper, we first model the Apache Kafka topic partitioning process for a given topic. Then, given the set of brokers, constraints and application requirements on throughput, OS load, replication latency and unavailability, we formulate the optimization problem of finding how many partitions are needed and show that it is computationally intractable, being an integer program. Furthermore, we propose two simple, yet efficient heuristics to solve the problem: the first tries to minimize and the second to maximize the number of brokers used in the cluster. Finally, we evaluate its performance via largescale simulations, considering as benchmarks some Apache Kafka cluster configuration recommendations provided by Microsoft and Confluent. We demonstrate that, unlike the recommendations, the proposed heuristics respect the hard constraints on replication latency and perform better w.r.t. unavailability time and OS load, using the system resources in a more prudent way.},
  keywords={},
  doi={10.1109/CITS55221.2022.9832981},
  ISSN={},
  month={July},}
@INPROCEEDINGS{9832139,
  author={Agarwal, Mansi and Kumar, Chandan and Kumar, Pramod and Verma, Swadesh},
  booktitle={2022 IEEE Women in Technology Conference (WINTECHCON)}, 
  title={AI layer reference generator engine for early enablement of workloads over multiple frameworks}, 
  year={2022},
  volume={},
  number={},
  pages={1-5},
  abstract={Compute operators/kernels (like Convolution, Relu, Gemm etc.) form the backbone of Deep Neural Network (DNN) models. With the advent of AI accelerators, there is a need to have specialized and optimized kernels for these operators to take full advantage of the features provided by the hardware. Kernels are mostly developed at High level languages like C, C++. They should work with almost the same accuracy and functionality as they would work on CPU/GPU machine. There are various ways listed below to check kernel accuracy and functionality. One of the common ways is to use Python interface provided by the different AI/ML frameworks. However, there are certain disadvantages like script level exposure which requires full stack integration and lack of multithreading because of python global interpreter lock. Another way is to develop a reference generator engine based on understanding of operators from frameworks. This strategy requires validating the correctness of the reference generator engine itself. Also, the generated reference could be at times in incompatible format and gets difficult to consume in the kernel validation code. In this paper we propose PyTeNet++ which stands for AI framework Pytorch[1], TensorFlow[2], Mxnet[3] using C++ APIs. The proposed solution is one of its kind and no such reference generator framework exists at the high-level language utilizing listed frameworks as backends. PyTeNet++ sits on top of C++ APIs exposed by these frameworks and helps to generate reference which could be seamlessly integrated with the kernel development/validation stack of the operators. It also helps to achieve maturity while kernel development. It exploits various benefits C++ provides like multithreading, low latency, high performance and OpenMP[4]. All these features are useful for faster kernel maturity. The smarter way of doing validation close to development environment helps in the early enablement (without full stack integration) of the DNN models, leading to quick maturity of the product and improved time-to-market.},
  keywords={},
  doi={10.1109/WINTECHCON55229.2022.9832139},
  ISSN={},
  month={June},}
@INPROCEEDINGS{9833953,
  author={Monsees, Tobias and Wübben, Dirk and Dekorsy, Armin and Griebel, Oliver and Herrmann, Matthias and Wehn, Norbert},
  booktitle={2022 IEEE 23rd International Workshop on Signal Processing Advances in Wireless Communication (SPAWC)}, 
  title={Finite-Alphabet Message Passing using only Integer Operations for Highly Parallel LDPC Decoders}, 
  year={2022},
  volume={},
  number={},
  pages={1-5},
  abstract={In this paper, we present a new design of Finite Alphabet (FA) Message Passing (MP) decoders using only integer operations. We utilize Discrete Density Evolution with a multidimensional Lookup-Table (mLUT) design for Variable Node (VN) updates to consider all input messages jointly for reducing the information loss compared to the frequent sequential LUT design approaches. From this mLUT design, we derive a minimum-integer computation (MIC) decoder that allows for different bit-widths for node operations and message exchanges between nodes. The mLUT operations for VN updates are replaced by low complexity signed integer additions and threshold operations, and the Check Node (CN) updates simplify to a minimum search over integers. For a (816,406) regular LDPC code, we show that our 3-bit MIC decoder achieves the communication performance of the corresponding mLUT decoder and outperforms a 4-bit state-of-the-art Min-Sum (MS) decoder. We show that the node implementations on a 22 nm FD-SOI technology yield an improved area and energy efficiency over the respective MS implementation. To the best of our knowledge, this is the first time that an implementation improvement for the VNs and CNs is shown when using FA MP.},
  keywords={},
  doi={10.1109/SPAWC51304.2022.9833953},
  ISSN={1948-3252},
  month={July},}
@INPROCEEDINGS{9837490,
  author={Chatzigeorgiou, Roza and Alevizos, Panos and Bletsas, Aggelos},
  booktitle={2022 11th International Conference on Modern Circuits and Systems Technologies (MOCAST)}, 
  title={Evaluation of Inference Algorithms for Distributed Channel Allocation in Wireless Networks}, 
  year={2022},
  volume={},
  number={},
  pages={1-4},
  abstract={Resource allocation in wireless networks, i.e., assigning time and frequency slots over specific terminals under spatio-temporal constraints, is a fundamental and challenging problem. Belief Propagation/message passing (inference) algorithms have been proposed for constraint satisfaction problems (CSP), since they are inherently amenable to distributed implementation. This work compares two message passing algorithms for time and frequency allocation, satisfying signal-to-interference-and-noise-ratio, half-duplex-radio operation and routing constraints. The first method periodically checks whether the constraints are satisfied locally and restarts specific messages, when the local constraints (encoded in corresponding factors) are not satisfied. The second method stochastically perturbs Belief Propagation, using Gibbs sampling. The methods are evaluated, based on how often they fail to converge to a valid (i.e., constraint-satisfying) allocation, coined as outage probability. Numerical results demonstrate that, as the maximum number of iterations increase, both methods decrease the outage probability. However, the restarting method offers faster convergence to a valid CSP solution. Future work will focus on next generation 5/6G wireless networks.},
  keywords={},
  doi={10.1109/MOCAST54814.2022.9837490},
  ISSN={},
  month={June},}
@INPROCEEDINGS{9836366,
  author={Khan, Samiha and Hussna, Asma Ul and Shusmita, Sanjida Ali and Rahman, Md. Ashekur and Trisha, Iffat Immami and Hossain, Md Sabbir and Rasel, Annajiat Alim},
  booktitle={2022 International Conference on Advancement in Electrical and Electronic Engineering (ICAEEE)}, 
  title={Performance Analysis of Multi-threaded Sorting for Unsorted Data Using Remote Procedure Call}, 
  year={2022},
  volume={},
  number={},
  pages={1-5},
  abstract={Distributed procedures that use a message-passing approach communicate with one another by transferring bits of information in order to provide unique access to all available tasks. Almost every single modern computer now has a CPU with several cores, which provides additional computing capacity. Moreover, parallel execution is critical in the new age of big data to enhance performance to a reasonable threshold. Indeed, parallelization brings with it additional issues that must be tack-led. However, parallel algorithms are studied and contrasted in comparison to their consecutive equivalents. In our paper, we look at sorting the unsorted numbers in distributed systems. Multi-threaded methods and performance, along with the difficulty of defining time, affect speed as well. Following that, an experiment was conducted in which a set of algorithms was implemented as well as the data was gathered through benchmarking and testing. To establish the validity of parallelization, the data were inspected and analyzed with its associated source code. A review was carried out in order to obtain a better idea of the scope of sorting algorithms and parallel computing. In this paper, a multi-sorting threading algorithm approach has been conducted based on previous work. The primary idea behind the algorithm is simple as well as Remote Procedure Calls (RPCs) approach has been used.},
  keywords={},
  doi={10.1109/ICAEEE54957.2022.9836366},
  ISSN={},
  month={Feb},}
@INPROCEEDINGS{9835377,
  author={Schwarzrock, Janaina and Rocha, Hiago Mayk G. De A. and Lorenzon, Arthur F. and Beck, Antonio Carlos S.},
  booktitle={2022 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)}, 
  title={Smoothing on Dynamic Concurrency Throttling}, 
  year={2022},
  volume={},
  number={},
  pages={962-971},
  abstract={Technology scaling has been allowing a growing number of cores in processors to satisfy the increasing demand of new applications, which need to process huge amounts of data in High-Performance Computing (HPC). However, considering that many parallel applications have limited scalability, not always activating the maximum number of available cores to execute an application will provide the best outcome in energy and performance (represented by the Energy-Delay Product, or EDP). Because of that, many works have already proposed different Dynamic Concurrency Throttling (DCT) techniques to adapt thread count as the application executes. However, dynamically tuning (i.e. increasing or decreasing) thread count implies in overheads related to caches warm-up and thread reallocation across the cores. This overhead may become very significant when thread count changes often during execution, which may overcome the benefits brought by DCT. This problem is further aggravated in Non-Uniform Memory Access (NUMA) systems since some cores are more distant, in terms of latency, than others. With that in mind, in this paper, we propose a smoothing-based strategy to minimize the thread count changes and, consequently, mitigate the aforementioned overhead. Our proposal is generic and aims further to improve the optimization results of any DCT technique. As case-study, we performed experiments on two multicore systems with nine well-known benchmarks, showing that our smoothing technique improves EDP results of offline and online state-of-the-art DCT techniques by up to 93% and 89% (both 22% on mean), respectively.},
  keywords={},
  doi={10.1109/IPDPSW55747.2022.00154},
  ISSN={},
  month={May},}
@INPROCEEDINGS{9835251,
  author={Schwitanski, Simon and Tomski, Felix and Protze, Joachim and Terboven, Christian and Müller, Matthias S.},
  booktitle={2022 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)}, 
  title={An On-the-Fly Method to Exchange Vector Clocks in Distributed-Memory Programs}, 
  year={2022},
  volume={},
  number={},
  pages={530-540},
  abstract={Vector clocks are logical timestamps used in correctness tools to analyze the happened-before relation between events in parallel program executions. In particular, race detectors use them to find concurrent conflicting memory accesses, and replay tools use them to reproduce or find alternative execution paths. To record the happened-before relation with vector clocks, tool developers have to consider the different synchronization concepts of a programming model, e.g., barriers, locks, or message exchanges. Especially in distributed-memory programs, various concepts result in explicit and implicit synchronization between processes. Previously implemented vector clock exchanges are often specific to a single programming model, and a translation to other programming models is not trivial. Consequently, analyses relying on the vector clock exchange remain model-specific. This paper proposes an abstraction layer for on-the-fly vector clock exchanges for distributed-memory programs. Based on the programming models MPI, OpenSHMEM, and GASPI, we define common synchronization primitives and explain how model-specific procedures map to our model-agnostic abstraction layer. The exchange model is general enough also to support synchronization concepts of other parallel programming models. We present our implementation of the vector clock abstraction layer based on the Generic Tool Infrastructure with translators for MPI and OpenSHMEM. In an overhead study using the SPEC MPI 2007 benchmarks, the slowdown of the implemented vector clock exchange ranges from 1.1x to 12.6x for runs with up to 768 processes.},
  keywords={},
  doi={10.1109/IPDPSW55747.2022.00093},
  ISSN={},
  month={May},}
@INPROCEEDINGS{9835375,
  author={Alnaasan, Nawras and Jain, Arpan and Shafi, Aamir and Subramoni, Hari and Panda, Dhabaleswar K},
  booktitle={2022 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)}, 
  title={OMB-Py: Python Micro-Benchmarks for Evaluating Performance of MPI Libraries on HPC Systems}, 
  year={2022},
  volume={},
  number={},
  pages={870-879},
  abstract={Python has become a dominant programming language for emerging areas like Machine Learning (ML), Deep Learning (DL), and Data Science (DS). An attractive feature of Python is that it provides easy-to-use programming interface while allowing library developers to enhance performance of their applications by harnessing the computing power offered by High Performance Computing (HPC) platforms. Efficient communication is key to scaling applications on parallel systems, which is typically enabled by the Message Passing Interface (MPI) standard and compliant libraries on HPC hardware. mpi4py is a Python-based communication library that provides an MPI-like interface for Python applications allowing application developers to utilize parallel processing elements including GPUs. However, there is currently no benchmark suite to evaluate communication performance of mpi4py-and Python MPI codes in general-on modern HPC systems. In order to bridge this gap, we propose OMB-Py-Python extensions to the open-source OSU Micro-Benchmark (OMB) suite-aimed to evaluate communication performance of MPI-based parallel applications in Python. To the best of our knowledge, OMB-Py is the first communication benchmark suite for parallel Python applications. OMB-Py consists of a variety of point-to-point and collective communication benchmark tests that are implemented for a range of popular Python libraries including NumPy, CuPy, Numba, and PyCUDA. Our evaluation reveals that mpi4py introduces a small overhead when compared to native MPI libraries. We plan to publicly release OMB-Py to benefit the Python HPC community.},
  keywords={},
  doi={10.1109/IPDPSW55747.2022.00143},
  ISSN={},
  month={May},}
@INPROCEEDINGS{9835659,
  author={Vardas, Ioannis and Hunold, Sascha and Ajanohoun, Jordy I. and Träff, Jesper Larsson},
  booktitle={2022 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)}, 
  title={mpisee: MPI Profiling for Communication and Communicator Structure}, 
  year={2022},
  volume={},
  number={},
  pages={520-529},
  abstract={Cumulative performance profiling is a fast and lightweight method for gaining summary information about where and how communication time in parallel MPI applications is spent. MPI provides mechanisms for implementing such profilers that can be transparently used with applications. Existing profilers typically profile on a process basis and record the frequency, total time, and volume of MPI operations per process. This can lead to grossly misleading cumulative information for applications that make use of MPI features for partitioning the processes into different communicators. We present a novel MPI profiler, mpisee, for communicator-centric profiling that separates and records collective and point-to-point communication information per communicator in the application. We discuss the implementation of mpisee which makes significant use of the MPI attribute mechanism. We evaluate our tool by measuring its overhead and profiling a number of standard applications. Our measurements with thirteen MPI applications show that the overhead of mpisee is less than 3%. Moreover, using mpisee, we investigate in detail two particular MPI applications, SPLATT and GROMACS, to obtain information on the various MPI operations for the different communicators of these applications. Such information is not available by other, state-of-the-art profilers. We use the communicator-centric information to improve the performance of SPLATT resulting in a significant runtime decrease when run with 1024 processes.},
  keywords={},
  doi={10.1109/IPDPSW55747.2022.00092},
  ISSN={},
  month={May},}
@INPROCEEDINGS{9835283,
  author={Al-Attar, Kinan and Shafi, Aamir and Subramoni, Hari and Panda, Dhabaleswar K.},
  booktitle={2022 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)}, 
  title={Towards Java-based HPC using the MVAPICH2 Library: Early Experiences}, 
  year={2022},
  volume={},
  number={},
  pages={510-519},
  abstract={There has been sporadic interest in using Java for High Performance Computing (HPC) in the past. These earlier efforts have resulted in several Java Message Passing Interface (MPI) [1] libraries including mpiJava [2], FastMPJ [3], MPJ Express [4], and Java Open MPI [5]. In this paper, we present our efforts in designing and implementing Java bindings for the MVAPICH2 [6] library. The MVAPICH2 Java bindings (MVAPICH2-J) follow the same API as the Java Open MPI library. MVAPICH2-J also provides support for communicating direct New I/O (NIO) ByteBuffers and Java arrays. Direct ByteBuffers reside outside JVM heaps and are not subject to the garbage collection. The library implements and utilizes a buffering layer to explicitly manage memory to avoid creating buffers every time a Java array message is communicated. In order to evaluate the performance of MVAPICH2-J and other Java MPI libraries, we also designed and implemented OMB-J that is a Java extension to the popular OSU Micro-Benchmarks suite (OMB) [7]. OMB-J currently supports a range of bench-marks for evaluating point-to-point and collective communication primitives. We also added support for communicating direct ByteBuffers and Java arrays. Our evaluations reveal that at the OMB-J level, ByteBuffers are superior in performance due to the elimination of extra copying between the Java and the Java Native Interface (JNI) layer. MVAPICH2-J achieves similar performance to Java Open MPI for ByteBuffers in point-to-point communication primitives that is evaluated using latency and bandwidth benchmarks. For Java arrays, there is a slight overhead for MVAPICH2-J due to the use of the buffering layer. For the collective communication benchmarks, we observe good performance for MVAPICH2-J. Where, MVAPICH2-J fairs better than Java Open MPI with ByteBuffers by $a$ factor of 6.2 and 2.76 for broadcast and all reduce, respectively, on average for all messages sizes. And, using Java arrays, $2. 2\times$ and $1. 62\times$ on average for broadcast and allreduce, respectively. The collective communication performance is dictated by the performance of the respective native MPI libraries.},
  keywords={},
  doi={10.1109/IPDPSW55747.2022.00091},
  ISSN={},
  month={May},}
@INPROCEEDINGS{9835312,
  author={Bell, Patrick and Suarez, Kae and Fossum, Barbara and Chapp, Dylan and Bhowmick, Sanjukta and Taufer, Michela},
  booktitle={2022 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)}, 
  title={A Research-Based Course Module to Study Non-determinism in High Performance Applications}, 
  year={2022},
  volume={},
  number={},
  pages={346-353},
  abstract={We present a research-based course module to teach computer science students, software developers, and scientists the effects of non-determinism on high performance applications. The course module uses the ANACIN-X software package, a suite of software modules developed by the authors; ANACIN-X provides test cases, analytic tools to run different scenarios (e.g., using different numbers of processes and different communication patterns), and visualization tools for beginner, intermediate, and advanced level understandings in non-determinism. Through our course module, students in computer science, software developers, and scientists gain an understanding of non-determinism, how to measure its occurrence in an execution, and how to identify its root causes within an application's code.},
  keywords={},
  doi={10.1109/IPDPSW55747.2022.00067},
  ISSN={},
  month={May},}
@INPROCEEDINGS{9835343,
  author={Chen, Chen-Chun and Khorassani, Kawthar Shafie and Anthony, Quentin G. and Shafi, Aamir and Subramoni, Hari and Panda, Dhabaleswar K.},
  booktitle={2022 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)}, 
  title={Highly Efficient Alltoall and Alltoallv Communication Algorithms for GPU Systems}, 
  year={2022},
  volume={},
  number={},
  pages={24-33},
  abstract={In recent years, High Performance Computing (HPC) and Deep Learning (DL) applications have been modified to run on top supercomputers and utilize the high compute power of GPUs. While GPUs provide high computational power, communication of data between GPUs and across a network continues to be a bottleneck. In particular, with the increasing amount of FFT compute and sparse matrix transpose operations in these applications, Alltoall MPI collective operations are heavily used. Alltoall communication is considered the heaviest communication pattern compared to other MPI collective calls. Few techniques and algorithms effectively help in optimizing Alltoall communication, much less improving the performance on a dense GPU cluster while exploiting the features of modern inter-connects and topologies. Despite the introduction of Inter-Process Communication (IPC) in CUDA 4.1 by NVIDIA, state-of-the-art MPI libraries have not utilized these IPC-based mechanisms to design novel Alltoall algorithms that exploit the capabilities of modern GPUs. In this paper, we propose hybrid IPC-advanced designs for Alltoall and Alltoallv communication on novel GPU systems. By utilizing zero-copy load-store IPC mechanisms for multi-GPU communication within a node, we are able to overlap the intra-node and inter-node communication, yielding improved performance on GPU systems. We evaluate the benefits of our designs at the benchmark and application layers on the ThetaGPU system at ALCF and the Lassen system at LLNL. Our designs provide up to 13.5x and 71% improvements on 128 GPUs and 64 GPUs at the benchmark-level over state-of-the-art MPI libraries on ThetaGPU and Lassen respectively. At the application level, our designs have up to 59x performance improvement for an HPC application, heFFTe, and 5.7x performance improvement for a Deep Learning application, DeepSpeed, on 64 GPUs on ThetaGPU and 256 GPUs on Lassen.},
  keywords={},
  doi={10.1109/IPDPSW55747.2022.00014},
  ISSN={},
  month={May},}
@INPROCEEDINGS{9834496,
  author={Yacoub, Emna Ben and Matuz, Balázs},
  booktitle={2022 IEEE International Symposium on Information Theory (ISIT)}, 
  title={Analysis of Symbol Message Passing LDPC Decoder for the Poisson PPM Channel}, 
  year={2022},
  volume={},
  number={},
  pages={1193-1198},
  abstract={A simple decoding algorithm, dubbed symbol message passing decoder, is studied for q-ary low-density parity-check codes over the q-ary Poisson pulse-position modulation channel. The messages in the decoder are symbols from the finite field ${\mathbb{F}_q}$. To improve performance, a second decoder with an extended message set $\left\{ {{\text{E}} \cup {\mathbb{F}_q}} \right\}$ is also investigated, where E denotes an erasure. Thresholds within 1.3 dB from the Shannon limit are obtained for low field orders.},
  keywords={},
  doi={10.1109/ISIT50566.2022.9834496},
  ISSN={2157-8117},
  month={June},}
@INPROCEEDINGS{9834360,
  author={Liu, Lei and Liang, Shansuo and Ping, Li},
  booktitle={2022 IEEE International Symposium on Information Theory (ISIT)}, 
  title={Capacity Optimality of OAMP in Coded Large Unitarily Invariant Systems}, 
  year={2022},
  volume={},
  number={},
  pages={1384-1389},
  abstract={This paper investigates a large unitarily invariant system (LUIS) involving a unitarily invariant sensing matrix, an arbitrary fixed signal distribution, and forward error control (FEC) coding. Several area properties are established based on the state evolution of orthogonal approximate message passing (OAMP) in an un-coded LUIS. Under the assumptions that the state evolution for joint OAMP and FEC decoding is correct and the replica method is reliable, we analyze the achievable rate of OAMP. We prove that OAMP reaches the constrained capacity predicted by the replica method of the LUIS with an arbitrary signal distribution based on matched FEC coding. Meanwhile, we elaborate a constrained capacity-achieving coding principle for LUIS, based on which irregular low-density parity-check (LDPC) codes are optimized for binary signaling in the simulation results. We show that OAMP with the optimized codes has significant performance improvement over the un-optimized ones and the well-known Turbo linear MMSE algorithm. For quadrature phase-shift keying (QPSK) modulation, constrained capacity-approaching bit error rate (BER) performances are observed under various channel conditions.},
  keywords={},
  doi={10.1109/ISIT50566.2022.9834360},
  ISSN={2157-8117},
  month={June},}
@INPROCEEDINGS{9834628,
  author={Akbayrak, Semih and Şenöz, İsmail and Vries, Bert de},
  booktitle={2022 IEEE International Symposium on Information Theory (ISIT)}, 
  title={Adaptive Importance Sampling Message Passing}, 
  year={2022},
  volume={},
  number={},
  pages={1199-1204},
  abstract={The aim of Probabilistic Programming (PP) is to automate inference in probabilistic models. One efficient realization of PP-based inference concerns variational message passing-based (VMP) inference in a factor graph. VMP is efficient but in principle only leads to closed-form update rules in case the model consists of conjugate and/or conditionally conjugate factor pairs. Recently, Extended Variational Message Passing (EVMP) has been proposed to broaden the applicability of VMP by importance sampling-based particle methods for non-linear and non-conjugate factor pairs. EVMP automates the importance sampling procedure by employing forward messages as proposal distributions, which unfortunately may lead to inaccurate estimation results and numerical instabilities in case the forward message is not a good representative of the unknown correct posterior. This paper addresses this issue by integrating an adaptive importance sampling procedure with message passing-based inference. The resulting method is a hyperparameter-free approximate inference engine that combines recent advances in stochastic adaptive importance sampling and optimization methods. We provide an implementation for the proposed method in the Julia package ForneyLab.jl.},
  keywords={},
  doi={10.1109/ISIT50566.2022.9834628},
  ISSN={2157-8117},
  month={June},}
@INPROCEEDINGS{9834833,
  author={Chi, Yuhao and Liu, Lei and Song, Guanghui and Li, Ying and Guan, Yong Liang and Yuen, Chau},
  booktitle={2022 IEEE International Symposium on Information Theory (ISIT)}, 
  title={Capacity Optimal Coded Generalized MU-MIMO}, 
  year={2022},
  volume={},
  number={},
  pages={2291-2296},
  abstract={With the complication of future communication scenarios, most conventional signal processing technologies of multi-user multiple-input multiple-output (MU-MIMO) become unreliable, which are designed based on ideal assumptions, such as Gaussian signaling and independent identically distributed (IID) channel matrices. As a result, this paper considers a generalized MU-MIMO (GMU-MIMO) system with more general assumptions, i.e., arbitrarily fixed input distributions, and general unitarily-invariant channel matrices. However, there is still no accurate capacity analysis and capacity optimal transceiver with practical complexity for GMU-MIMO under the constraint of coding. To address these issues, inspired by the replica method, the constrained sum capacity of coded GMU-MIMO with fixed input distribution is calculated by using the celebrated mutual information and minimum mean-square error (MMSE) lemma and the MMSE optimality of orthogonal/vector approximate message passing (OAMP/VAMP). Then, a capacity optimal multi-user OAMP/VAMP receiver is proposed, whose achievable rate is proved to be equal to the constrained sum capacity. Moreover, a design principle of multi-user codes is presented for the multi-user OAMP/VAMP, based on which a kind of practical multi-user low-density parity-check (MU-LDPC) code is designed. Numerical results show that finite-length performances of the proposed MU-LDPC codes with multi-user OAMP/VAMP are about 2 dB away from the constrained sum capacity and outperform those of the existing state-of-art methods.},
  keywords={},
  doi={10.1109/ISIT50566.2022.9834833},
  ISSN={2157-8117},
  month={June},}
@INPROCEEDINGS{9834902,
  author={Beemer, Allison and Kshirsagar, Rutuja and Matthews, Gretchen L.},
  booktitle={2022 IEEE International Symposium on Information Theory (ISIT)}, 
  title={Graph-based codes for hierarchical recovery}, 
  year={2022},
  volume={},
  number={},
  pages={1554-1559},
  abstract={In this paper, we consider approaches to designing Tanner codes to protect against symbol loss from multiple erasures. First, we note that Tanner codes inherit locality and availability from their inner codes, allowing one to design longer codes with specified locality and availability. Availability is desirable in that multiple disjoint repair groups increase the likelihood that symbols are available to repair erased ones. Even so, particular patterns of erasures well-distributed across the repair groups may prevent recovery. Hence, we consider an alternative using hierarchical locality which implements tiered recovery, where the tier utilized depends on the number of erasures. Finally, we define hierarchical stopping sets to characterize local message-passing decoder failure at the various repair levels.},
  keywords={},
  doi={10.1109/ISIT50566.2022.9834902},
  ISSN={2157-8117},
  month={June},}
@INPROCEEDINGS{9838482,
  author={Yang, Tao},
  booktitle={ICC 2022 - IEEE International Conference on Communications}, 
  title={A Simple Approach to Practical Dirty Paper Coding}, 
  year={2022},
  volume={},
  number={},
  pages={2912-2917},
  abstract={This paper presents a simple dirty paper coding (DPC) scheme based on q-ary codes over integer rings. The encoding primarily involves a linear subtraction in the integer ring, for pre-cancellation of interference known at the transmitter. The received signal sequence corrupted by the interference is then guaranteed to belong to the expanded codebook of the ring code. As such, iterative q-ary message passing algorithm over the expanded codebook is employed for decoding of linear DPC, yielding near-capacity performance at the medium-to-high SNR regime for bandwidth efficient communication. The complexity of the proposed linear DPC is almost identical to that of the conventional coding for AWGN channel, and the power penalty is shown to quickly vanish as q increases. We employ a generalize EXIT chart based technique to optimize the degree distributions of the components and the multipliers of the underlying doubly irregular repeat-accumulate ring codes. Numerical results demonstrate that the gaps to capacity limit of the interference-free AWGN channel are only 1.36, 0.91, 0.62 dB for spectral efficiency of 2.0, 2.5, 3.0 bits/symbol, respectively.},
  keywords={},
  doi={10.1109/ICC45855.2022.9838482},
  ISSN={1938-1883},
  month={May},}
@INPROCEEDINGS{9846190,
  author={Chen, Shuping and He, Wangquan and Qi, Fengbin and Zheng, Yan and Yu, Kang},
  booktitle={2022 7th International Conference on Computer and Communication Systems (ICCCS)}, 
  title={Hybrid Approach to Optimize MPI Collectives by In-network-computation and Point-to-Point Messages}, 
  year={2022},
  volume={},
  number={},
  pages={773-783},
  abstract={Using in-network-computation capabilities of the network devices (also called hardware collectives) to optimize MPI collectives has become popular in high-performance computing, and shows significant performance advantages. However, the hardware collectives are not flawless in practical use scenarios. One of the problems is that it is difficult to use. In order to obtain the performance advantage of hardware collectives, the network management software need to create dedicated aggregate tree for each MPI communicator, which is a complicated task. One solution is to make MPI communicators sharing the global imprecise aggregate trees created by the management software when initiating networks, but it leads to heavy interference between MPI communicators and causes significant performance degradation. So we have to make tradeoff between performance and ease of use. We propose a hybrid approach to optimize MPI collectives by in-network-computation and point-to-point messages. On the one hand, we use the pre-created aggregate trees in each super-node, rather than sending requests to the network management software to create dedicated aggregate trees. On the other hand, the hardware collectives are transferred only in the local super-node, so it cannot disturb the jobs running on other super-nodes. We provide a cost model to evaluate the overhead of the hybrid collective algorithms. We also test its performance in the new generation Sunway supercomputer. The results show that our approach reduces the median latency by 18%~74% compared to collectives implemented by point-to-point messages, although the performance decrease slightly compared to the original hardware collectives. In addition, the tail latency of our approach is significantly lower than that of the original hardware collectives in the presence of heavy interference.},
  keywords={},
  doi={10.1109/ICCCS55155.2022.9846190},
  ISSN={},
  month={April},}
@INPROCEEDINGS{9850575,
  author={Han, Yuxia},
  booktitle={2022 International Conference on Inventive Computation Technologies (ICICT)}, 
  title={Hadoop Data Mining Analysis of Network Education Platform based on PDM New Media Data Perspectives}, 
  year={2022},
  volume={},
  number={},
  pages={1144-1147},
  abstract={This paper is based on the Hadoop data mining analysis of the networked education platform of PDM data integration. Research and analyze the architecture system of Hadoop, which focuses on analyzing its two core parts: some characteristics and principles of HDFS (distributed file system) and MapReduce (distributed programming model). The parallel multiple linear regression algorithm and the The principle and implementation of the networked education platform, in which the proposed "message passing model" can effectively solve the problem that MapReduce is difficult to deal with the adjacency matrix. The MYSQL system is used in the process of constructing a large data set, and the efficiency of the system is analyzed and tested. . Through practice and testing, it is found that after the algorithm is improved, the data processing time of the system is greatly reduced by 9.7%, so the overall system efficiency has been improved.},
  keywords={},
  doi={10.1109/ICICT54344.2022.9850575},
  ISSN={2767-7788},
  month={July},}
@INPROCEEDINGS{9867146,
  author={Lidard, Justin and Madhushani, Udari and Leonard, Naomi Ehrich},
  booktitle={2022 American Control Conference (ACC)}, 
  title={Provably Efficient Multi-Agent Reinforcement Learning with Fully Decentralized Communication}, 
  year={2022},
  volume={},
  number={},
  pages={3311-3316},
  abstract={A challenge in reinforcement learning (RL) is minimizing the cost of sampling associated with exploration. Distributed exploration reduces sampling complexity in multi-agent RL (MARL). We investigate the benefits to performance in MARL when exploration is fully decentralized. Specifically, we consider a class of online, episodic, tabular Q-learning problems under time-varying reward and transition dynamics, in which agents can communicate in a decentralized manner. We show that group performance, as measured by the bound on regret, can be significantly improved through communication when each agent uses a decentralized message-passing protocol, even when limited to sending information up to its γ-hop neighbors. We prove regret and sample complexity bounds that depend on the number of agents, communication network structure and γ. We show that incorporating more agents and more information sharing into the group learning scheme speeds up convergence to the optimal policy. Numerical simulations illustrate our results and validate our theoretical claims.},
  keywords={},
  doi={10.23919/ACC53348.2022.9867146},
  ISSN={2378-5861},
  month={June},}
@ARTICLE{9882991,
  author={Courtès, Ludovic},
  journal={Computing in Science & Engineering}, 
  title={Reproducibility and Performance: Why Choose?}, 
  year={2022},
  volume={24},
  number={3},
  pages={77-80},
  abstract={Research processes often rely on high-performance computing (HPC), but HPC is often seen as antithetical to “reproducibility”: one would have to choose between software that achieves high performance and software that can be deployed in a reproducible fashion. However, by giving up on reproducibility we would give up on verifiability, a foundation of the scientific process. How can we conciliate performance and reproducibility? This article looks at two performance-critical aspects of HPC: message passing and CPU microarchitecture tuning. Engineering work that has gone into performance portability has already proved fruitful, but some areas remain unaddressed when it comes to CPU tuning. We propose package multiversioning, a technique developed for GNU Guix, a tool for reproducible software deployment, and show that it allows us to implement CPU tuning without compromising on reproducibility and provenance tracking.},
  keywords={},
  doi={10.1109/MCSE.2022.3165626},
  ISSN={1558-366X},
  month={May},}
@ARTICLE{9895222,
  author={Chi, Yuhao and Liu, Lei and Song, Guanghui and Li, Ying and Guan, Yong Liang and Yuen, Chau},
  journal={IEEE Transactions on Communications}, 
  title={Constrained Capacity Optimal Generalized Multi-User MIMO: A Theoretical and Practical Framework}, 
  year={2022},
  volume={70},
  number={12},
  pages={8086-8104},
  abstract={Conventional multi-user multiple-input multiple-output (MU-MIMO) mainly focused on Gaussian signaling, independent and identically distributed (IID) channels, and a limited number of users. It will be laborious to cope with the heterogeneous requirements in next-generation wireless communications, such as various transmission data, complicated communication scenarios, and unprecedented massive user access. Therefore, this paper studies a generalized MU-MIMO (GMU-MIMO) system with more generalized and practical constraints, i.e., practical channel coding, non-Gaussian signaling, right-unitarily-invariant channels (covering Rayleigh fading channel matrices, certain ill-conditioned and correlated channel matrices, etc.), and massive users and antennas. These generalized assumptions bring new challenges in theory and practice. For example, there is no accurate constrained capacity region analysis for GMU-MIMO. In addition, it is unclear how to achieve constrained-capacity-optimal performance with practical complexity. To address these challenges, a unified framework is proposed to derive the constrained capacity region of GMU-MIMO and design a constrained-capacity-optimal transceiver, which jointly considers encoding, modulation, detection, and decoding. Group asymmetry is developed to group users according to their rates, which makes a tradeoff between user rate allocation and implementation complexity. Specifically, the constrained capacity region of group-asymmetric GMU-MIMO is characterized by using the minimum mean-square error (MMSE) optimality of orthogonal/vector approximate message passing (OAMP/VAMP) and the relationship between mutual information and MMSE. Furthermore, a theoretically optimal multi-user OAMP/VAMP receiver and practical multi-user low-density parity-check (MU-LDPC) codes are proposed to achieve the constrained capacity region of group-asymmetric GMU-MIMO. Numerical results demonstrate that the proposed MU-LDPC coded GMU-MIMO systems achieve asymptotic performance within 0.2 dB from the theoretical sum capacity. Moreover, their finite-length performances are about 1~2 dB away from the associated sum capacity of GMU-MIMO.},
  keywords={},
  doi={10.1109/TCOMM.2022.3207813},
  ISSN={1558-0857},
  month={Dec},}
@INPROCEEDINGS{9878885,
  author={Shen, Yichun and Jiang, Wanli and Xu, Zhen and Li, Rundong and Kwon, Junghyun},
  booktitle={2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Confidence Propagation Cluster: Unleash Full Potential of Object Detectors}, 
  year={2022},
  volume={},
  number={},
  pages={1141-1151},
  abstract={It's been a long history that most object detection methods obtain objects by using the non-maximum suppression (NMS) and its improved versions like Soft-NMS to remove redundant bounding boxes. We challenge those NMS-based methods from three aspects: 1) The bounding box with highest confidence value may not be the true positive having the biggest overlap with the ground-truth box. 2) Not only suppression is required for redundant boxes, but also confidence enhancement is needed for those true positives. 3) Sorting candidate boxes by confidence values is not necessary so that full parallelism is achievable. In this paper, inspired by belief propagation (BP), we propose the Confidence Propagation Cluster (CP-Cluster) to replace NMS-based methods, which is fully parallelizable as well as better in accuracy. In CP-Cluster, we borrow the message passing mechanism from BP to penalize redundant boxes and enhance true positives simultaneously in an iterative way until convergence. We verified the effectiveness of CP-Cluster by applying it to various mainstream detectors such as FasterRCNN, SSD, FCOS, YOLOv3, YOLOv5, Centernet etc. Experiments on MS COCO show that our plug and play method, without retraining detectors, is able to steadily improve average mAP of all those state-of-the-art models with a clear margin from 0.3 to 1.9 respectively when compared with NMS-based methods.},
  keywords={},
  doi={10.1109/CVPR52688.2022.00122},
  ISSN={2575-7075},
  month={June},}
@INPROCEEDINGS{9879211,
  author={Chen, Jun and Agarwal, Aniket and Abdelkarim, Sherif and Zhu, Deyao and Elhoseiny, Mohamed},
  booktitle={2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={RelTransformer: A Transformer-Based Long-Tail Visual Relationship Recognition}, 
  year={2022},
  volume={},
  number={},
  pages={19485-19495},
  abstract={The visual relationship recognition (VRR) task aims at understanding the pairwise visual relationships between interacting objects in an image. These relationships typically have a long-tail distribution due to their compositional nature. This problem gets more severe when the vocabulary becomes large, rendering this task very challenging. This paper shows that modeling an effective message-passing flow through an attention mechanism can be critical to tackling the compositionality and long-tail challenges in VRR. The method, called RelTransformer, represents each image as a fully-connected scene graph and restructures the whole scene into the relation-triplet and global-scene contexts. It directly passes the message from each element in the relation-triplet and global-scene contexts to the target relation via self-attention. We also design a learnable memory to augment the long-tail relation representation learning. Through extensive experiments, we find that our model generalizes well on many VRR benchmarks. Our model outperforms the best-performing models on two large-scale long-tail VRR benchmarks, VG8K-LT (+2.0% overall acc) and GQA-LT (+26.0% overall acc), both having a highly skewed distribution towards the tail. It also achieves strong results on the VG200 relation detection task. Our code is available at https://github.com/Vision-CAIR/ReITransformer.},
  keywords={},
  doi={10.1109/CVPR52688.2022.01890},
  ISSN={2575-7075},
  month={June},}
@INPROCEEDINGS{9896692,
  author={Wang, Bowen and Li, Nanxi and Yang, Shan and Jiang, Zheng and Zhu, Jianchi and She, Xiaoming and Wang, Jianxiu and Chen, Peng},
  booktitle={2022 IEEE/CIC International Conference on Communications in China (ICCC Workshops)}, 
  title={Bit-wise Detection for OTFS Modulation via Message Passing Algorithm}, 
  year={2022},
  volume={},
  number={},
  pages={251-256},
  abstract={The orthogonal time frequency space (OTFS) modulation as a promising signal representation attracts growing attention for integrated sensing and communication. This paper devotes to signal detection for OTFS system. Notice the characteristics of high dimension and sparsity of OTFS channel, we propose a bit-wise message passing (MP) algorithm to support Soft-Input Soft-Output detection. We leverage the channel sparsity to simplify the factor graph, and approximate the discrete messages with continuous Gaussian distribution to facilitate message updating. Simulations in various cases validate the outperformance of the proposed algorithm contrast to existed symbol-wise MP and linear detectors.},
  keywords={},
  doi={10.1109/ICCCWorkshops55477.2022.9896692},
  ISSN={2474-9133},
  month={Aug},}
@INPROCEEDINGS{9905221,
  author={Slock, Dirk},
  booktitle={2022 IEEE 7th Forum on Research and Technologies for Society and Industry Innovation (RTSI)}, 
  title={Convergent Approximate Message Passing by Alternating Constrained Minimization of Bethe Free Energy}, 
  year={2022},
  volume={},
  number={},
  pages={180-185},
  abstract={Approximate Message Passing (AMP) allows for Bayesian inference in linear models with non identically independently distributed (n.i.i.d.) Gaussian priors and measurements of the linear mixture outputs with n.i.i.d. Gaussian noise. It represents an efficient technique for approximate inference which becomes accurate when both rows and columns of the measurement matrix can be treated as sets of independent vectors and both dimensions become large. It has been shown that the fixed points of AMP correspond to extrema of a large system limit of the Bethe Free Energy (LSL-BFE), which represents a meaningful approximation optimization criterion regardless of whether the measurement matrix exhibits the independence properties. However, the convergence of AMP can be notoriously problematic for certain measurement matrices and the only sure fix so far is damping (by a difficult to determine amount). In this paper we revisit the AMP algorithm by rigorously applying an alternating constrained minimization strategy to an appropriately reparameterized LSL-BFE with matched variable and constraint partitioning. This guarantees convergence, and due to convexity in the Gaussian case, to the global optimum. We show that the AMP estimates converge to the Linear Minimum Mean Squared Error (LMMSE) estimates, regardless of the behavior of the variances. In the LSL, the variances also converge to the LMMSE values, and hence to the correct values.},
  keywords={},
  doi={10.1109/RTSI55261.2022.9905221},
  ISSN={2687-6817},
  month={Aug},}
@ARTICLE{9915434,
  author={Tian, Feiyan and Liu, Lei and Chen, Xiaoming},
  journal={IEEE Transactions on Signal Processing}, 
  title={Generalized Memory Approximate Message Passing for Generalized Linear Model}, 
  year={2022},
  volume={70},
  number={},
  pages={6404-6418},
  abstract={For signal reconstruction in a generalized linear model (GLM), generalized approximate message passing (GAMP) is a low-complexity algorithm with many appealing features such as an exact performance characterization in the high-dimensional limit. However, it is viable only when the transformation matrix has independent and identically distributed (IID) entries. Generalized vector AMP (GVAMP) has a wider applicability but with high computational complexity. To overcome the shortcomings of GAMP and GVAMP, we propose a low-complexity and widely applicable generalized memory AMP (GMAMP) framework, including an orthogonal memory linear estimator (MLE) and two orthogonal memory nonlinear estimators (MNLE), which guarantee the asymptotic IID Gaussianity of estimation errors and state evolution (SE) in GMAMP. The proposed GMAMP is universal since the existing AMP, convolutional AMP, orthogonal/vector AMP, GVAMP, and memory AMP (MAMP) are its special instances. More importantly, we provide a principle toward building new advanced AMP-type algorithms based on the proposed GMAMP framework. As an example, we construct a Bayes-optimal GMAMP (BO-GMAMP) algorithm, which adopts a memory match filter estimator to suppress the linear interference, and thus its complexity is comparable to GAMP. Furthermore, we prove that the SE of BO-GMAMP with optimized parameters converges to the same fixed point as that of the high-complexity GVAMP. In other words, BO-GMAMP achieves the replica minimum (i.e., potential Bayes-optimal) mean square error (MSE) if its SE has a unique fixed point. Finally, simulation results are provided to validate the accuracy of the theoretical analysis.},
  keywords={},
  doi={10.1109/TSP.2022.3213414},
  ISSN={1941-0476},
  month={},}
@INPROCEEDINGS{9912701,
  author={Shiina, Shumpei and Taura, Kenjiro},
  booktitle={2022 IEEE International Conference on Cluster Computing (CLUSTER)}, 
  title={Distributed Continuation Stealing is More Scalable than You Might Think}, 
  year={2022},
  volume={},
  number={},
  pages={129-141},
  abstract={The need for load balancing in applications with irregular parallelism has motivated research on work stealing. An important choice in work-stealing schedulers is between child stealing or continuation stealing. In child stealing, a newly created task is made stealable by other processors, whereas in continuation stealing, the caller's continuation is made stealable by executing the newly created task first, which preserves the serial execution order. Although the benefits of continuation stealing have been demonstrated on shared memory by Cilk and other runtime systems, it is rarely employed on distributed memory, presumably because it has been thought to be difficult to implement and inefficient as it involves migration of call stacks across nodes. Akiyama and Taura recently introduced efficient RDMA-based continuation stealing, but the practicality of distributed continuation stealing is still unclear because a comparison of its performance with that of child stealing has not previously been performed. This paper presents the results of a comparative performance analysis of continuation stealing and child stealing on distributed memory. To clarify the full potential of continuation stealing, we first investigated various RDMA-based synchronization (task join) implementations, which had not previously been fully inves-tigated. The results revealed that, when the task synchronization pattern was complicated, continuation stealing performed better than child stealing despite its relatively long steal latency due to stack migration. Notably, our runtime system achieved almost perfect scaling on 110,592 cores in an unbalanced tree search (UTS) benchmark. This scalability is comparable to or even better than that of state-of-the-art bag-of-tasks counterparts.},
  keywords={},
  doi={10.1109/CLUSTER51413.2022.00027},
  ISSN={2168-9253},
  month={Sep.},}
@INPROCEEDINGS{9912687,
  author={Al-Attar, Kinan and Shafi, Aamir and Abduljabbar, Mustafa and Subramoni, Hari and Panda, Dhabaleswar K.},
  booktitle={2022 IEEE International Conference on Cluster Computing (CLUSTER)}, 
  title={Spark Meets MPI: Towards High-Performance Communication Framework for Spark using MPI}, 
  year={2022},
  volume={},
  number={},
  pages={71-81},
  abstract={There are several popular Big Data processing frameworks including Apache Spark, Dask, and Ray. The Apache Spark software provides an easy-to-use high-level API in different languages including Scala, Java, and Python. Spark supports parallel and distributed execution of user workloads by supporting communication using an event-driven framework called Netty. Some efforts - including RDMA-Spark and SparkUCX - were made in the past to optimize Apache Spark on High-Performance Computing (HPC) systems equipped with high-performance interconnects like InfiniBand. In the HPC community, Message Passing Interface (MPI) libraries are widely adopted for parallelizing science and engineering applications. This paper presents MPI4Spark which uses MPI for communication in a parallel and distributed setting on HPC systems. MPI4Spark can launch the Spark ecosystem using MPI launchers to utilize MPI communication inside the Big Data framework. It also maintains isolation for application execution on worker nodes by forking new processes using Dynamic Process Management (DPM). It bridges semantic differences between the event-driven communication in Spark compared to the application-driven communication engine in MPI. MPI4Spark also provides portability and performance benefits as it is capable of utilizing popular HPC interconnects including InfiniBand, Omni-Path, Slingshot, and others. The performance of MPI4Spark is evaluated against RDMA-Spark and Vanilla Spark using OSU HiBD Benchmarks (OHB) and Intel HiBench that contain a variety of Resilient Distributed Dataset (RDD), Graph Processing, and Machine Learning workloads. This evaluation is done on three HPC systems including TACC Frontera, TACC Stampede2, and an internal cluster. MPI4Spark outperforms Vanilla Spark and RDMA-Spark by 4.23x and 2.04x, respectively, on the TACC Frontera system using 448 processing cores (8 Spark workers) for the GroupByTest benchmark in OHB. The communication performance of MPI4Spark is 13.08x and 5.56x better than Vanilla Spark and RDMA-Spark, respectively.},
  keywords={},
  doi={10.1109/CLUSTER51413.2022.00022},
  ISSN={2168-9253},
  month={Sep.},}
@INPROCEEDINGS{9912679,
  author={Wilkins, Michael and Guo, Yanfei and Thakur, Rajeev and Dinda, Peter and Hardavellas, Nikos},
  booktitle={2022 IEEE International Conference on Cluster Computing (CLUSTER)}, 
  title={ACCLAiM: Advancing the Practicality of MPI Collective Communication Autotuning Using Machine Learning}, 
  year={2022},
  volume={},
  number={},
  pages={161-171},
  abstract={MPI collective communication is an omnipresent communication model for high-performance computing (HPC) systems. The performance of a collective operation depends strongly on the algorithm used to implement it. MPI libraries use inaccurate heuristics to select these algorithms, causing applications to suffer unnecessary slowdowns. Machine learning (ML)-based autotuners are a promising alternative. ML autotuners can intelligently select algorithms for individual jobs, resulting in near-optimal performance. However, these approaches currently spend more time training than they save by accelerating applications, rendering them impractical. We make the case that ML-based collective algorithm selection autotuners can be made practical and accelerate production applications on large-scale supercomputers. We identify multiple impracticalities in the existing work, such as inefficient training point selection and ignoring non-power-of-two feature values. We address these issues through variance-based point selection and model testing alongside topology-aware benchmark paral-lelization. Our approach minimizes training time by eliminating unnecessary training points and maximizing machine utilization. We incorporate our improvements in a prototype active learning system, ACCLAiM (Advancing Collective Communication (L) Autotuning using Machine Learning). We show that each of ACCLAiM's advancements significantly reduces training time compared with the best existing machine learning approach. Then we apply ACCLAiM on a leadership-class supercomputer and demonstrate the conditions where ACCLAiM can accelerate HPC applications, proving the advantage of ML autotuners in a production setting for the first time.},
  keywords={},
  doi={10.1109/CLUSTER51413.2022.00030},
  ISSN={2168-9253},
  month={Sep.},}
@INPROCEEDINGS{9912702,
  author={Giordano, Mosè and Klöwer, Milan and Churavy, Valentin},
  booktitle={2022 IEEE International Conference on Cluster Computing (CLUSTER)}, 
  title={Productivity meets Performance: Julia on A64FX}, 
  year={2022},
  volume={},
  number={},
  pages={549-555},
  abstract={The Fujitsu A64FX ARM-based processor is used in supercomputers such as Fugaku in Japan and Isambard 2 in the UK and provides an interesting combination of hardware features such as Scalable Vector Extension (SVE), and native support for reduced-precision floating-point arithmetic. The goal of this paper is to explore performance of the Julia programming language on the A64FX processor, with a particular focus on reduced precision. Here, we present a performance study on axpy to verify the compilation pipeline, demonstrating that Julia can match the performance of tuned libraries. Additionally, we investigate Message Passing Interface (MPI) scalability and throughput analysis on Fugaku showing next to no significant overheads of Julia of its MPI interface. To explore the usability of Julia to target various floating-point precisions, we present results of ShallowWaters. j1, a shallow water model that can be executed a various levels of precision. Even for such complex applications, Julia's type-flexible programming paradigm offers both, productivity and performance.},
  keywords={},
  doi={10.1109/CLUSTER51413.2022.00072},
  ISSN={2168-9253},
  month={Sep.},}
@INPROCEEDINGS{9909828,
  author={Podusenko, Albert and van Erp, Bart and Bagaev, Dmitry and şenöz, Ïsmail and de Vries, Bert},
  booktitle={2022 30th European Signal Processing Conference (EUSIPCO)}, 
  title={Message Passing-based Inference in Switching Autoregressive Models}, 
  year={2022},
  volume={},
  number={},
  pages={1497-1501},
  abstract={The switching autoregressive model is a flexible model for signals generated by non-stationary processes. Unfortunately, evaluation of the exact posterior distributions of the latent variables for a switching autoregressive model is analytically intractable, and this limits the applicability of switching autoregressive models in practical signal processing tasks. In this paper we present a message passing-based approach for computing approximate posterior distributions in the switching autoregressive model. Our solution tracks approximate posterior distributions in a modular way and easily extends to more complicated model variations. The proposed message passing algorithm is verified and validated on synthetic and acoustic data sets respectively.},
  keywords={},
  doi={10.23919/EUSIPCO55093.2022.9909828},
  ISSN={2076-1465},
  month={Aug},}
@INPROCEEDINGS{9912476,
  author={Suresh, Kaushik Kandadi and Khorassani, Kawthar Shafie and Chen, Chen Chun and Ramesh, Bharath and Abduljabbar, Mustafa and Shafi, Aamir and Subramoni, Hari and Panda, Dhabaleswar K.},
  booktitle={2022 IEEE Symposium on High-Performance Interconnects (HOTI)}, 
  title={Network Assisted Non-Contiguous Transfers for GPU-Aware MPI Libraries}, 
  year={2022},
  volume={},
  number={},
  pages={13-20},
  abstract={The importance of GPUs in accelerating HPC applications is evident by the fact that a large number of super-computing clusters are GPU-enabled. Many of these HPC applications use MPI as their programming model. These MPI applications oftentimes exchange data that is non-contiguous in GPU memory. MPI provides Derived Datatypes(DDTs) to represent such data. In the past, researchers have proposed solutions to optimize these MPI DDT based inter-node GPU exchanges. All of these solutions are aimed at optimizing the overheads associated with pack-unpack kernels that facilitate the non-contiguous exchanges. Modern HCAs are capable of gathering/scattering data from/to non-contiguous GPU memory regions. In this work, we analyze the challenges in using HCA's scatter/gather mechanism for GPU-based HPC workloads. We propose a low-overhead HCA-assisted scheme to improve the performance of GPU-based non-contiguous exchanges. We show that the proposed scheme provides up to 2X benefits compared to existing pack-based schemes at the benchmark level. Fur-thermore, on the layouts used by MILC, NASMG, Specfem3D applications, we show that the proposed scheme outperforms the state-of-the MPI libraries such as MVAPICH2-GDR and OpenMPI+UCX.},
  keywords={},
  doi={10.1109/HOTI55740.2022.00018},
  ISSN={2332-5569},
  month={Aug},}
@INPROCEEDINGS{9919212,
  author={Li, Lijuan and Cui, Hangxuan and Zhou, Yangcan and Wang, Zhongfeng},
  booktitle={2022 IEEE Workshop on Signal Processing Systems (SiPS)}, 
  title={A Modified BP Bit-Flipping Algorithm for Polar Codes}, 
  year={2022},
  volume={},
  number={},
  pages={1-6},
  abstract={The belief propagation (BP) algorithm for polar codes has attracted significant attention due to its soft-output property and high parallelism. However, the BP algorithm is not comparable with the successive cancellation list (SCL) algorithm in terms of the error-correction performance. In this paper, we propose a high-stage BP flip (HSBPF) algorithm to further improve the error-correction performance of the BP algorithm by analyzing the distribution of log-likelihood ratio (LLR) values. Simulation results show that the decoding latency can be reduced by 30% with the proposed algorithm. Moreover, benefiting from the simplified message passing of the factor graph, the computational complexity of the proposed algorithm is also significantly reduced compared with the existing algorithms.},
  keywords={},
  doi={10.1109/SiPS55645.2022.9919212},
  ISSN={2374-7390},
  month={Nov},}
@ARTICLE{9927375,
  author={Zhang, Hang and Abdi, Afshin and Fekri, Faramarz},
  journal={IEEE Transactions on Signal Processing}, 
  title={a General Compressive Sensing Construct Using Density Evolution}, 
  year={2022},
  volume={},
  number={},
  pages={1-16},
  abstract={This paper 11Partial preliminary results appeared in 2021 IEEE Information Theory Workshop [1]. proposes a general framework to design a sparse sensing matrix $\mathbf {A}\in \mathbb {R}^{m\times n}$, for a linear measurement system $\mathbf {y} = \mathbf {Ax}^{\natural } + \mathbf {w}$, where $\mathbf {y} \in \mathbb {R}^{m}$, $\mathbf {x}^{\natural }\in \mathbb {R}^{n}$, and $\mathbf {w}\in \mathbb {R}^{m}$ denote the measurements, the signal with certain structures, and the measurement noise, respectively. By viewing the signal reconstruction from the measurements as a message passing algorithm over a graphical model, we leverage tools from coding theory in the design of low density parity check codes, namely the density evolution technique, and provide a framework for the design of matrix $\mathbf {A}$. Two design schemes for the sensing matrix, namely, $(i)$ a regular sensing and $(ii)$ a preferential sensing, are proposed and are incorporated into a single framework. As illustrations, we consider the $\ell _{1}$ regularizer, $\ell _{2}$ regularizer, and their linear combination, which corresponds to Lasso regression, ridge regression, and elastic net regression. After proper distribution approximations, we have shown that our framework can reproduce the classical results on the minimum sensor number, i.e., $m$. In the preferential sensing scenario, we consider the case in which the whole signal is divided into two disjoint parts, namely, high-priority part $x^{\natural }_{\mathsf {H}}$ and low-priority part $x^{\natural }_{\mathsf {L}}$. Then, by formulating the sensing system design as a bi-convex optimization problem, we obtain sensing matrices which can provide a preferential treatment for $x^{\natural }_{\mathsf {H}}$. Numerical experiments with both synthetic data and real-world data are also provided to verify the effectiveness of our design scheme.},
  keywords={},
  doi={10.1109/TSP.2022.3216708},
  ISSN={1941-0476},
  month={},}
@INPROCEEDINGS{9923270,
  author={Neil Shepard, P.E. and Sundararajan, Aditya and Ferrari, Maximiliano and Ollis, Ben},
  booktitle={2022 IEEE 13th International Symposium on Power Electronics for Distributed Generation Systems (PEDG)}, 
  title={Real-Time Hardware-in-the-Loop Testbed to Evaluate FLISR Implemented with OpenFMB}, 
  year={2022},
  volume={},
  number={},
  pages={1-5},
  abstract={With the increasing complexity of the distribution smart grid architecture, algorithms such as the fault location, isolation, and service restoration (FLISR) scheme rely on robust communications that are resilient to natural and man-made adverse conditions and exhibit robustness. Existing communications infrastructure for information exchange are centralized at the distribution management system, with very little autonomy or intelligence at the grid-edge. As a first step towards achieving grid-edge self-healing, this paper aims to bridge this shortcoming by implementing a centrally coordinated rules-based FLISR scheme and integrating it with Open Field Message Bus (OpenFMB), which is a flexible publish-subscribe architecture with the potential to enable point-to-multipoint communications and is more robust and resilient to natural and man-made adverse conditions. A proof of concept is developed to validate the centrally coordinated FLISR and OpenFMB mounted on an SEL-3360 computer that interacts with a simple feeder network of five SEL-651R relays, an SEL-3530 RTAC, and a hardware-in-the-loop testbed. Results demonstrate the efficacy of this approach in enabling direct, low-latency information exchange. OpenFMB’s publish-subscribe data model also opens new ways to enable grid-edge interoperability among devices of different vendors interacting with different protocols.},
  keywords={},
  doi={10.1109/PEDG54999.2022.9923270},
  ISSN={2329-5767},
  month={June},}
@INPROCEEDINGS{9926384,
  author={Brewer, Wesley and Bretheim, Joel and Kaniarz, John and Song, Peilin and Gates, Burhman},
  booktitle={2022 IEEE High Performance Extreme Computing Conference (HPEC)}, 
  title={Scalable Interactive Autonomous Navigation Simulations on HPC}, 
  year={2022},
  volume={},
  number={},
  pages={1-7},
  abstract={We present our work of enabling HPC in an interactive real-time autonomy loop. The workflow consists of many different software components deployed within Singu-larity containers and communicating using both the Robotic Operating System's (ROS) publish-subscribe system and the Message Passing Interface (MPI). We use Singularity's container networking interface (CNI) to enable virtual networking within the containers, so that multiple containers can run the various components using different IP addresses on the same compute node. The Virtual Autonomous Navigation Environment Environmental Sensor Engine (VANE: ESE) is used for physically-realistic simulation of LIDAR along with the Autonomous Navigation Virtual Environment Laboratory (ANVEL) for vehicle simulation. VANE: ESE sends Velodyne UDP LIDAR packets directly to the Robotic Technology Kernel (RTK) and is distributed across multiple compute nodes via MPI along with OpenMP for shared memory parallelism within each compute node. The user interfaces with the navigation environment using an XFCE desk-top with virtual workspaces running over a VNC containerized deployment through a double-hop ssh tunnel, which uses noVNC (a JavaScript-based VNC client) to provide a browser-based client interface. We automate the complete launch process using a custom iLauncher plugin. We benchmark scalable performance with multiple vehicle simulations on four different HPC systems and discuss our findings.},
  keywords={},
  doi={10.1109/HPEC55821.2022.9926384},
  ISSN={2643-1971},
  month={Sep.},}
@INPROCEEDINGS{9926292,
  author={Beebe, Michael and Williams, Brody and Devaney, Stephen and Leidel, John and Chen, Yong and Poole, Steve},
  booktitle={2022 IEEE High Performance Extreme Computing Conference (HPEC)}, 
  title={RaiderSTREAM: Adapting the STREAM Benchmark to Modern HPC Systems}, 
  year={2022},
  volume={},
  number={},
  pages={1-7},
  abstract={Sustaining high memory bandwidth utilization is a common bottleneck to maximizing the performance of scien-tific applications, with the dominating factor of the runtime being the speed at which data can be loaded from memory into the CPU and results can be written back to memory, particularly for increasingly critical data-intensive workloads. The prevalence of irregular memory access patterns within these applications, exemplified by kernels such as those found in sparse matrix and graph applications, significantly degrade the achievable performance of a system's memory hierarchy. As such, it is highly desirable to be able to accurately measure a given memory hierarchy's sustainable memory bandwidth when designing applications as well as future high-performance computing (HPC) systems. STREAM is a de facto standard benchmark for measuring sustained memory bandwidth and has garnered widespread adoption. In this work, we discuss current limitations of the STREAM benchmark in the context of high-performance and scientific computing. We then introduce a new version of STREAM, called RaiderSTREAM, built on the OpenSHMEM and MPI programming models in tandem with OpenMP, that include additional kernels which better model irregular memory access patterns in order to address these shortcomings.},
  keywords={},
  doi={10.1109/HPEC55821.2022.9926292},
  ISSN={2643-1971},
  month={Sep.},}
@ARTICLE{9938978,
  author={Basloom, Huda Saleh and Dahab, Mohamed Yehia and Alghamdi, Ahmed Mohammed and Eassa, Fathy Elbouraey and Al-Ghamdi, Abdullah Saad Al-Malaise and Haridi, Seif},
  journal={IEEE Access}, 
  title={Errors Classification and Static Detection Techniques for Dual-Programming Model (OpenMP and OpenACC)}, 
  year={2022},
  volume={10},
  number={},
  pages={117808-117826},
  abstract={Recently, incorporating more than one programming model into a system designed for high performance computing (HPC) has become a popular solution to implementing parallel systems. Since traditional programming languages, such as C, C++, and Fortran, do not support parallelism at the level of multi-core processors and accelerators, many programmers add one or more programming models to achieve parallelism and accelerate computation efficiently. These models include Open Accelerators (OpenACC) and Open Multi-Processing (OpenMP), which have recently been used with various models, including Message Passing Interface (MPI) and Compute Unified Device Architecture (CUDA). Due to the difficulty of predicting the behavior of threads, runtime errors cannot be predicted. The compiler cannot identify runtime errors such as data races, race conditions, deadlocks, or livelocks. Many studies have been conducted on the development of testing tools to detect runtime errors when using programming models, such as the combinations of OpenACC with MPI models and OpenMP with MPI. Although more applications use OpenACC and OpenMP together, no testing tools have been developed to test these applications to date. This paper presents a testing tool for detecting runtime using a static testing technique. This tool can detect actual and potential runtime errors during the integration of the OpenACC and OpenMP models into systems developed in C++. This tool implement error dependency graphs, which are proposed in this paper. Additionally, a dependency graph of the errors is provided, along with a classification of runtime errors that result from combining the two programming models mentioned earlier.},
  keywords={},
  doi={10.1109/ACCESS.2022.3219406},
  ISSN={2169-3536},
  month={},}
@INPROCEEDINGS{9932828,
  author={Park, Taesoon},
  booktitle={2022 International Symposium on Multidisciplinary Studies and Innovative Technologies (ISMSIT)}, 
  title={Efficient Distributed Snapshot Algorithms with Less Message Overhead}, 
  year={2022},
  volume={},
  number={},
  pages={602-607},
  abstract={Distributed snapshot algorithms to capture the consistent global states of a distributed system are presented. In addition to the state variable (red or white) of a process, the snapshot sequence number is also used to detect the messages crossing the snapshot line and hence, the messages which may cause the inconsistency of the snapshot line are easily detected. As a result, relatively low message overhead is required for the snapshot coordination. We assume non-FIFO communication channels and the normal operations of the processes including message sending and receiving are allowed during the snapshot coordination. The algorithm which includes only the processes which have communicated before the snapshot coordination is also presented.},
  keywords={},
  doi={10.1109/ISMSIT56059.2022.9932828},
  ISSN={2770-7962},
  month={Oct},}
@ARTICLE{9955511,
  author={Zhang, Yu and Yang, Caiyun and Tang, Kexin and Dai, Jinshan},
  journal={IEEE Access}, 
  title={Study on Distributed Consistent Cooperative Control of Multi-ART in Automated Container Terminals}, 
  year={2022},
  volume={10},
  number={},
  pages={122965-122980},
  abstract={In order to address the congestion problem of vehicles in quay of automated container terminal with parallel layout and side-loading operations, the study regards the terminal operation system as a multi-agent system (MAS). Then, A dynamic cooperative speed regulation strategy for a group intelligence-oriented multi-ART (Artificial Intelligence Robot of Transportation) is proposed to realize the smart and distributed traffic control of container terminals. Via the real-time data interchange and message passing with ART group, the individual ART implements the collaborative speed regulation with the combination of the dynamic speed regulation strategy. Through the above-mentioned method, the sequence of ARTs arriving at the quay can be adjusted, which can decrease the waiting time of ARTs at the quay. Considering the consistency problem of individual and group agent among the dynamic speed regulation of ARTs, a novel distributed consensus protocol is established to assure that the individual status of ART will tend to converge basically during the collaborative speed regulation process, and the convergence of system can be guaranteed. Based on the case of automated container terminal of Tianjin Port, the paper establishes a multi-agent based simulation model, and simulates the decision-making process, and validates the effectiveness of mentioned model and strategy. The results demonstrate that the strategy can decrease the waiting time of ARTs under uncertainty environment of terminal and improve the operation efficiency of system.},
  keywords={},
  doi={10.1109/ACCESS.2022.3223360},
  ISSN={2169-3536},
  month={},}
@INPROCEEDINGS{9951493,
  author={Ding, Zhenyao and Dong, Xiaolei and Shen, Jiachen and Cao, Zhenfu},
  booktitle={2022 2nd International Conference on Frontiers of Electronics, Information and Computation Technologies (ICFEICT)}, 
  title={A Hybrid Double-layer BFT Consensus Protocol for Large-Scale IoT Blockchain}, 
  year={2022},
  volume={},
  number={},
  pages={354-361},
  abstract={IoT -blockchain applications are becoming more popular in recent years. Proof-of-Work (PoW) algorithm is not suitable for IoT blockchains due to limited power and computing capability of IoT devices. Practical Byzantine Fault Tolerance (PBFT) protocol is a better choice. However, because of the frequent inter-node connections, the PBFT algorithm has a poor node scalability. In this paper, we propose a hybrid double-layer BFT consensus protocol for large-scale IoT blockchain. We divide the nodes into groups, first reach consensus within the group, and then reach an overall consensus among the groups. This can convert the large-scale point-to-point broadcast into smaller ones and reduce communication overhead. To lower the energy consumption of communication inside the group, we utilize a simple clustering method to classify nodes that are close to each other into one group. It is worth noting that inter-group communication is more susceptible to outside interference. With the wisdom of asynchronous consensus algorithms, we propose weighted asynchronous byzantine agreement (WABA) to resist the influence of the long-distance message transfer time. Moreover, we adopt certificateless aggregate signatures to reduce communication and calculation cost during verification. The results of simulation experiments show that our protocol has substantially less communication overhead and lower latency than PBFT.},
  keywords={},
  doi={10.1109/ICFEICT57213.2022.00071},
  ISSN={},
  month={Aug},}

@ARTICLE{9970348,
  author={Liu, Jiren and Ren, Zhengyong and Xiao, Xiao and Tang, Jingtian and Xu, Jintong and Gu, Yu},
  journal={IEEE Geoscience and Remote Sensing Letters}, 
  title={An Accelerated Algorithm for 3-D Multifrequency CSEM Imaging With Undulating Topography}, 
  year={2022},
  volume={19},
  number={},
  pages={1-5},
  abstract={3-D frequency-domain controlled-source electromagnetic (CSEM) inversion is an essential technology for subsurface conductivity imaging. In this letter, we develop an efficient 3-D inversion scheme for multifrequency CSEM (MFCSEM) data measured on a topographic earth. First, the model is discretized using the unstructured mesh, which has the ability to simulate the undulating topography. Then, we divide the frequency range into two independent frequency intervals and use the rational Krylov (RK) subspace algorithm with the open multiprocessing (OpenMP)/message passing interface (MPI) hybrid parallelization scheme to accelerate the calculations of MFCSEM forward and adjoint forward. Finally, the nonlinear conjugate gradient (NLCG) method is utilized to solve this optimization problem. We invert a synthetic dataset to verify the computational performance, and the results show that our algorithm is efficient and can obtain reliable inversion results. Furthermore, it also indicates that ignoring the effect of topography can cause severe distortion to the inversion results.},
  keywords={},
  doi={10.1109/LGRS.2022.3226859},
  ISSN={1558-0571},
  month={},}
@INPROCEEDINGS{9972245,
  author={Zhao, Haojie and Yao, Wenze and Xu, Hongcheng and Zhang, Siyuan and Yang, Yujie and Zhang, Xin and Liu, Jie},
  booktitle={2022 International Workshop on Advanced Patterning Solutions (IWAPS)}, 
  title={Accurate and Efficient Proximity Effect Correction for Electron Beam Lithography Based on Distributed Parallel Computing}, 
  year={2022},
  volume={},
  number={},
  pages={1-4},
  abstract={This paper proposes an efficient proximity effect correction (PEC) method for electron beam lithography $(E B L)$ based on distributed parallel computing. To facilitate PEC calculations of large-scale layout, this method splits the exposure layout into multiple sub-layouts, and distributes them to different computer nodes for calculation through the message passing interface (MPI) technology. Under the premise of ensuring accuracy of PEC of the same layout, compared to the calculation time of 1 computing node (56 CPU cores per node), the acceleration ratios using $N_{\text {node }}=2,4$ and 6 nodes are $N_{\mathrm{ratio}}=2.28,5.29$, and 8.31, respectively. Given the same PEC calculation case with $N_{\text {pixel }}$ pixels, when $N_{\text {node }}$ is increased, the number of pixels calculated by one node $\left(n=N_{\text {pixel }} / N_{\text {node }}\right)$ decreases, leading to $N_{\text {ratio }} / N_{\text {node }}\gt1$ due to the $O(n \times \log (n))$ time complexity of the fast Fourier transform (FFT) in convolution computation. The proposed distributed parallelization scheme has been implemented in the second version of the $H N U-E B L$ software (http://www.ebeam.com.cn/).},
  keywords={},
  doi={10.1109/IWAPS57146.2022.9972245},
  ISSN={},
  month={Oct},}
@INPROCEEDINGS{9969356,
  author={Wilson, Daniel C. and Al-rawi, Asma H. and Lawson, Lowren H. and Jana, Siddhartha and Ardanaz, Federico and Eastep, Jonathan M. and Coskun, Ayse K.},
  booktitle={2022 IEEE 13th International Green and Sustainable Computing Conference (IGSC)}, 
  title={Guiding Hardware-Driven Turbo with Application Performance Awareness}, 
  year={2022},
  volume={},
  number={},
  pages={1-8},
  abstract={Parallel programming across many CPU cores offers many challenges in software design, such as mitigating performance or efficiency loss in applications that reach synchronization points at varying times across the CPU cores. Existing solutions often aim to resolve this through clever optimizations in application design, or by reacting to the imbalance by throttling the CPU core frequency of the early-finishing cores at application run time. In this work, we propose a method to rebalance bulksynchronous MPI applications by selectively speeding up the latefinishing cores throughout application run time. This algorithm makes use of the new Intel® Speed Select Turbo Frequency feature that enables software to guide the hardware toward increasing the turbo frequency limits of some cores in exchange for decreased turbo frequency limits in other cores. We demonstrate up to 40% energy reduction and 17% execution time reduction in a highly-imbalanced, compute-bound benchmark application and up to 21% energy reduction with 5% execution time reduction in an imbalanced real-world application.},
  keywords={},
  doi={10.1109/IGSC55832.2022.9969356},
  ISSN={},
  month={Oct},}
@INPROCEEDINGS{9975376,
  author={Laguna, Ignacio and Tirpankar, Tanmay and Li, Xinyi and Gopalakrishnan, Ganesh},
  booktitle={2022 IEEE International Symposium on Workload Characterization (IISWC)}, 
  title={FPChecker: Floating-Point Exception Detection Tool and Benchmark for Parallel and Distributed HPC}, 
  year={2022},
  volume={},
  number={},
  pages={39-50},
  abstract={Floating-point arithmetic is fundamental to many areas including high-performance computing and machine learning. In order to ensure the numerical integrity of the overall computation, numerical exceptions (such as NaNs) must be detected and suitably reported to the user. Unfortunately, today’s best available methods and tools are not general-enough. Moreover, there are no comprehensive benchmarks today that can be compiled to intermediate representations such as LLVM and analyzed at that level. In this paper, we contribute the first such benchmark suite that spans five HPC proxy applications plus eight public benchmarks that run on CPU multicores under MPI, OpenMP, and performance portability layers. We also release our tool (also called LLFPX) that is up to 7.9× faster on many important benchmarks and overall more comprehensive with respect to exception variety coverage. This paper presents the tool, its design, and evaluation on our benchmarks, with the tool, benchmarks, and a facility to examine results on the web available for public use upon acceptance. Other result highlights include the effect of compiler optimizations on exceptions.},
  keywords={},
  doi={10.1109/IISWC55918.2022.00014},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{9972737,
  author={Chandrashekar, B. N and Aditya Shastry, K. and Manjunath, B.A and Geetha, V.},
  booktitle={2022 IEEE 2nd Mysore Sub Section International Conference (MysuruCon)}, 
  title={Performance Model of HPC Application On CPU-GPU Platform}, 
  year={2022},
  volume={},
  number={},
  pages={1-6},
  abstract={In recent years, the world of high-performance computing has been developing rapidly with enormous efforts in the integration of information technology and research. The emergence of CPU-GPU platform computing has made this possible in a very efficient manner. Nowadays, the graphic processing unit (GPU) delivers much better performance than the CPU, because of a few cores with lots of cache memory on the CPU that can handle a few software threads at a time. In contrast, a GPU is composed of hundreds of cores that can handle thousands of threads simultaneously. The CPU-GPU hybrid platform is becoming increasingly important in high-performance computing (HPC) domains such as deep learning, artificial intelligence, etc., because of its tremendous computing power. In this work, we have proposed a performance model to accelerate the performance of HPC applications on a hybrid CPU-GPU platform. We have tested and analyzed the proposed performance model using different HPC benchmark applications such as Merge sort and Matrix multiplication on different platforms such as sequential, OpenMP, MPI in a single system, MPI in the cluster, and CUDA. We have observed that parallel computing in a shared and distributed memory architecture gives better performance than sequential computing. After analyzing we have represented it in the terms of graphs for a better view of the results.},
  keywords={},
  doi={10.1109/MysuruCon55714.2022.9972737},
  ISSN={},
  month={Oct},}
@INPROCEEDINGS{9927990,
  author={Zhang, Mei and Li, Hui and Huang, Zuyuan and Huang, Yudou and Bao, Fu},
  booktitle={2022 IEEE Intl Conf on Dependable, Autonomic and Secure Computing, Intl Conf on Pervasive Intelligence and Computing, Intl Conf on Cloud and Big Data Computing, Intl Conf on Cyber Science and Technology Congress (DASC/PiCom/CBDCom/CyberSciTech)}, 
  title={Analyzing Realizability of BPMN Choreographies}, 
  year={2022},
  volume={},
  number={},
  pages={1-6},
  abstract={BPMN choreographies specify a global message order of systems, which enables to build systems by composing a set of interacting peers that communicate with each via exchanging messages. Analyzing the realizability of choreographies is a crucial problem in top-down development. In this paper, we present an approach for analyzing the realizability of choreographies for both synchronous and asynchronous communication, which allows us to 1) encode a choreography into CSP# processes for generating the choreography LTS under the tool support, 2) automatically obtain peers from the generated choreography LTS, 3) check whether the choreography specification is realizable for both synchronous communication and asynchronous communication, where behavior equivalence checking is used to compare the choreography LTS with the LTS of the distributed system that is composed of the generated peers. Finally, experimental results show that our approach is effective.},
  keywords={},
  doi={10.1109/DASC/PiCom/CBDCom/Cy55231.2022.9927990},
  ISSN={},
  month={Sep.},}
@INPROCEEDINGS{9978438,
  author={Ceccato, Rodrigo and Yviquel, Hervé and Pereira, Marcio and Souza, Alan and Araujo, Guido},
  booktitle={2022 International Symposium on Computer Architecture and High Performance Computing Workshops (SBAC-PADW)}, 
  title={Implementing the Broadcast Operation in a Distributed Task-based Runtime}, 
  year={2022},
  volume={},
  number={},
  pages={25-32},
  abstract={Scientific applications that require high performance rely on multi-node and multi-core systems equipped with accelerators. Code for these heterogeneous architectures often mixes different programming paradigms and is hard to read and maintain. Task-based distributed runtimes can improve portability and readability by allowing programmers to write tasks that are automatically scheduled and offloaded for execution. Nevertheless, in large systems, communication can dominate the time spent during execution. To mitigate this, these systems usually implement collective operation algorithms that efficiently execute common data movement patterns across a group of processes. This work studies the usage of different broadcast strategies on the OpenMP Cluster (OMPC) task-based runtime. In addition to OMPC default behavior of on-demand data delivery, we introduce a routine to automatically detect data movement that is equivalent to a broadcast in the task graph and actively send it through a specialized algorithm. Our largest test setup using 64 worker nodes and broadcasting 64GB of data on the Santos Dumont cluster, using an extended version of Task Bench, showed a 2.02x speedup using the Dynamic Broadcast algorithm and 2.49x speedup when using the MPI broadcast routine, when compared to the default on-demand delivery.},
  keywords={},
  doi={10.1109/SBAC-PADW56527.2022.00014},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{9972926,
  author={Ouyang, Ning and Lu, Shuoying and Lin, Leping},
  booktitle={2022 IEEE 10th International Conference on Computer Science and Network Technology (ICCSNT)}, 
  title={A Spectral Line Data Processing Pipeline for SKA Using DALiuGE}, 
  year={2022},
  volume={},
  number={},
  pages={140-144},
  abstract={With the construction of the Square Kilometre Array (SKA), the world's largest radio telescope, a new era in the detection of 21 cm neutral hydrogen (HI) spectral line is about to be ushered in, and the SKA spectral line sciences present tremendous opportunities and unprecedented data processing challenges. In this paper, we propose a fast processing pipeline for spectral line data based on the distribution execution framework Data Activated Liu Graph Engine (DALiuGE), and compare it with the Message Passing Interface (MPI) based method. The proposed pipeline is proved to be more stable and efficient on several comparison experiments. The scalability and execution efficiency performance of SKA spectral line data fast processing pipeline using DALiuGE for data volume changes have been verified, and it is believed that the DALiuGE based pipeline can be a solution for more scientific tasks facing massive data processing on SKA Regional Centre (SRC).},
  keywords={},
  doi={10.1109/ICCSNT56096.2022.9972926},
  ISSN={2690-5892},
  month={Oct},}
@INPROCEEDINGS{9982702,
  author={Moussa, Ziggaf and Imad, Kissami},
  booktitle={2022 6th International Conference on Computer, Software and Modeling (ICCSM)}, 
  title={MPI-Based Simulation of the Shallow Water Model using the Finite Volume Characteristics Scheme}, 
  year={2022},
  volume={},
  number={},
  pages={52-57},
  abstract={A parallel algorithm for solving the 2D shallow water equations coupled with the convection-diffusion equation has been developed, in order to demonstrate the capability and performance of our parallel approach while maintaining very good accuracy of the results obtained. The numerical scheme used is written in a non-uniform triangular grid formalism, which allows for the complexity of the geometry of the computational domain used. This approach is based on both predictor and corrector stages. The predictor one uses the method of characteristics to reconstruct the numerical fluxes, whereas the corrector stage recovers the conservation equations. Numerical results are presented for a pollutant transport in a squared cavity.},
  keywords={},
  doi={10.1109/ICCSM57214.2022.00016},
  ISSN={},
  month={July},}
@INPROCEEDINGS{9980973,
  author={Munhoz, Vanderlei and Castro, Márcio and Mendizabal, Odorico},
  booktitle={2022 IEEE 34th International Symposium on Computer Architecture and High Performance Computing (SBAC-PAD)}, 
  title={Strategies for Fault-Tolerant Tightly-Coupled HPC Workloads Running on Low-Budget Spot Cloud Infrastructures}, 
  year={2022},
  volume={},
  number={},
  pages={263-272},
  abstract={Cloud providers can rent their spare computing capacity at substantial discounts, reclaiming it whenever there is a more profitable higher-priority request - a business model well known as spot infrastructure market. Users can attain significant cloud investment savings using spot machines, however with the caveat of increasing software complexity, given the fault tolerance requirements of this environment. Improvements in virtualization and network technology, combined with the development of key new software tools, may allow the HPC community to effectively take advantage of cheap cloud resources, cutting expensive maintenance costs. This study aims to evaluate the viability of budget-constrained cloud environments for tightly-coupled MPI applications, exploring both spot and traditional low-budget infrastructures from real public cloud platforms. We propose and evaluate two different fault tolerance strategies tailored for unreliable spot cloud environments: system-level rollback restart with Berkeley Labs Checkpoint/Restart (BLCR) and in-memory rollback restart with User-Level Failure Mitigation (ULFM). We also propose a provider-agnostic empirical method for testing and predicting MPI workloads execution times and cloud infrastructure costs. A detailed cost analysis and performance benchmark of a case-study application is provided, with data gathered from experiments with both spot and persistent machines from AWS and Vultr Cloud, respectively. Our results show that: (i) adequate cluster sizing plays an important role in the overall job execution performance and cost-effectiveness, regardless of the type of selected instances; (ii) fault tolerance strategies based on BLCR may have worse performance than ULFM, but still be costeffective considering software migration costs; (iii) the use of spot infrastructure does not guarantee costs savings depending on the chosen machine flavors and discounts, as experiments with persistent low-budget options attained better cost-effectiveness in some conditions.},
  keywords={},
  doi={10.1109/SBAC-PAD55451.2022.00037},
  ISSN={2643-3001},
  month={Nov},}
@INPROCEEDINGS{9982762,
  author={Tatton, Ryan and Ayday, Erman and Yoo, Youngjin and Halimi, Anisa},
  booktitle={2022 IEEE International Conference on E-health Networking, Application & Services (HealthCom)}, 
  title={ShareTrace: Contact Tracing with the Actor Model}, 
  year={2022},
  volume={},
  number={},
  pages={13-18},
  abstract={Proximity-based contact tracing relies on mobile-device interaction to estimate the spread of disease. ShareTrace is one such approach that improves the efficacy of tracking disease spread by considering direct and indirect forms of contact. In this work, we utilize the actor model to provide an efficient and scalable formulation of ShareTrace with asynchronous, concurrent message passing on a temporal contact network. We also introduce message reachability, an extension of temporal reachability that accounts for network topology and message-passing semantics. Our evaluation on both synthetic and real-world contact networks indicates that correct parameter values optimize for algorithmic accuracy and efficiency. In addition, we demonstrate that message reachability can accurately estimate the risk a user poses to their contacts.},
  keywords={},
  doi={10.1109/HealthCom54947.2022.9982762},
  ISSN={},
  month={Oct},}
@INPROCEEDINGS{9983693,
  author={Popovic, Marko and Kordic, Branislav and Basicevic, Ilija and Popovic, Miroslav},
  booktitle={2022 30th Telecommunications Forum (TELFOR)}, 
  title={Distributed Python Software Transactional Memory Supporting Publish-Subscribe Pattern}, 
  year={2022},
  volume={},
  number={},
  pages={1-4},
  abstract={The original Distributed Python Software Transactional Memory (DPSTM) supports transactions on inmemory transactional variables. In this paper, we extended the DPSTM architecture with the Pub/Sub subsystem, in order to additionally support the publish-subscribe pattern. The new architecture, called DPSTM-PS, supports transactions and notifications on consequent transactional variables’ updates. The Pub/Sub subsystem comprises: publish-subscribe server, registrar server, and message broker. The DPSTM-PS was successfully validated on the wired Ethernet and on the wireless WiFi home networks.},
  keywords={},
  doi={10.1109/TELFOR56187.2022.9983693},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{9984909,
  author={Jiang, Zoe L. and Shi, Songjiang and Wang, Hongxiao and Yang, Peng and Wang, Xuan and Wu, Yulin and Zhong, Yantao and Jia, Yan},
  booktitle={2022 4th International Conference on Data Intelligence and Security (ICDIS)}, 
  title={Efficient Mixed-Protocol Secure Four-Party Computation with Private Robustness}, 
  year={2022},
  volume={},
  number={},
  pages={1-8},
  abstract={Secure honest-majority four-party computation (4PC) protocol was proposed for four mutually-distrusting parties to jointly evaluate a complex function on their private inputs with private robustness by cheater identification. This capability has great potential for distributed private computation, such as distributed privacy-preserving machine learning. However, the adoption of secure 4PC is hampered mainly by the computation and communication costs of online phase of protocol. In this work we propose an efficient secure 4PC protocol with private robustness. Specifically, by transferring hash verification operation for cheating detection to the fourth party, and with the help of the mutual constraint between the four parties, the communication rounds and communication costs of joint message passing primitive can be reduced. To further reduce communication cost, this paper proposes to divide the four parties into two groups and applies the method of two-party multiplication with truncation to avoid multiplication overflow. We implement secure 4PC protocol and demonstrate the efficiency of computation and communication in MNIST multi-class classification training. It achieves $2.1\times$ reduction in computation cost and $2.5\times$ reduction in communication cost compared to prior works.},
  keywords={},
  doi={10.1109/ICDIS55630.2022.00008},
  ISSN={},
  month={Aug},}
@INPROCEEDINGS{9981901,
  author={Rhodes, Callum and Liu, Cunjia and Chen, Wen-Hua},
  booktitle={2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, 
  title={Scalable probabilistic gas distribution mapping using Gaussian belief propagation}, 
  year={2022},
  volume={},
  number={},
  pages={9459-9466},
  abstract={This paper advocates the Gaussian belief propagation solver for factor graphs in the case of gas distribution mapping to support an olfactory sensing robot. The local message passing of belief propagation moves away from the standard Cholesky decomposition technique, which avoids solving the entire factor graph at once and allows for only areas of interest to be updated more effectively. Implementing a local solver means that iterative updates to the distribution map can be achieved orders of magnitude quicker than conventional direct solvers which scale computationally to the size of the map. After defining the belief propagation algorithm for gas mapping, several state of the art message scheduling algorithms are tested in simulation against the standard Cholesky solver for their ability to converge to the exact solution. Testing shows that under the wildfire scheduling method for a large urban scenario, that distribution maps can be iterated at least 10 times faster whilst still maintaining exact solutions. This move to an efficient local framework allows future works to consider 3D mapping, predictive utility and multi-robot distributed mapping.},
  keywords={},
  doi={10.1109/IROS47612.2022.9981901},
  ISSN={2153-0866},
  month={Oct},}
@INPROCEEDINGS{9996629,
  author={Alaoui, Ahmed El and Montanari, Andrea and Sellke, Mark},
  booktitle={2022 IEEE 63rd Annual Symposium on Foundations of Computer Science (FOCS)}, 
  title={Sampling from the Sherrington-Kirkpatrick Gibbs measure via algorithmic stochastic localization}, 
  year={2022},
  volume={},
  number={},
  pages={323-334},
  abstract={We consider the Sherrington-Kirkpatrick model of spin glasses at high-temperature and no external field, and study the problem of sampling from the Gibbs distribution $\mu$ in polynomial time. We prove that, for any inverse temperature $\beta\lt 1/2$, there exists an algorithm with complexity $O(n^{2})$ that samples from a distribution $\mu^{\text{als}}$ which is close in normalized Wasserstein distance to $\mu$. Namely, there exists a coupling of $\mu$ and $\mu^{\text{alg}}$ such that if $(x,x^{\text{als}})\in\{-1,+1\}^{n}\times\{-1,+1\}^{n}$ is a pair drawn from this coupling, then $n^{-1}\mathbb{E}\{\|x-x^{\text{ald}}\|_{2}^{2}\}=o_{n}(1)$. The best previous results, by Bauerschmidt and Bodineau [BB19] and by Eldan, Koehler, Zeitouni [EKZ21], implied efficient algorithms to approximately sample (under a stronger metric) for $\beta\lt 1/4$. We complement this result with a negative one, by introducing a suitable “stability” property for sampling algorithms, which is verified by many standard techniques. We prove that no stable algorithm can approximately sample for $\beta$>1, even under the normalized Wasserstein metric. Our sampling method is based on an algorithmic implementation of stochastic localization, which progressively tilts the measure $\mu$ towards a single configuration, together with an approximate message passing algorithm that is used to approximate the mean of the tilted measure.},
  keywords={},
  doi={10.1109/FOCS54457.2022.00038},
  ISSN={2575-8454},
  month={Oct},}
@INPROCEEDINGS{9988402,
  author={Xiaomin, Shang and Qiang, Li and Yongmeng, Qi and Shunan, Tao},
  booktitle={2022 IEEE 2nd International Conference on Computer Systems (ICCS)}, 
  title={SLIC Research and Implementation of a Parallel Optimization Algorithm}, 
  year={2022},
  volume={},
  number={},
  pages={67-74},
  abstract={SLIC is an image segmentation method that clusters picture pixels into superpixel blocks. But it has many flaws, including large amount of computation and high data dependency. In this paper, the reference point of the main computation of the SLIC algorithm is moved from the cluster center to the ordinary pixel point by changing the structure of the algorithm. Although the computation time increased, the paralism of the algorithm improved, and the pixel dependency reduced too. At the same time, the traversal method is changed from a single pixel point to a cluster center when calculating the pixel sum of each cluster center. The parallel optimization method is a hybrid programming paradigm based on OpenMP and MPI. Compared with the standard SLIC method, in this parallel algorithm, the computation time largely reduced in the multi-core computer.},
  keywords={},
  doi={10.1109/ICCS56273.2022.9988402},
  ISSN={},
  month={Sep.},}
@ARTICLE{10004706,
  author={Xiong, Jun and Xiong, Zhi and Zhuang, Yuan and Cheong, Joon Wayn and Dempster, Andrew G.},
  journal={IEEE Signal Processing Letters}, 
  title={Message Passing Enhanced Distributed Kalman Filter for Cooperative Localization}, 
  year={2022},
  volume={29},
  number={},
  pages={2652-2656},
  abstract={This letter proposes a message passing enhanced distributed Kalman filter (MP-KF) for cooperative localization (CL). By simplifying the factor graph (FG) model of the traditional belief propagation (BP) algorithm, MP-KF replaces part of the message passing (MP) process in BP with the distributed Kalman filtering. According to the analysis, the computational complexity of MP-KF is lower than that of the traditional BP estimator. The results based on the experimental data set verify the effectiveness and advantages of MP-KF, it outperforms KF-based methods by fully exploiting the correlation inside a CL system, and is better than the BP-based methods by avoiding the performance loss caused by data smoothing. Results also show that MP-KF is a cost-effective approach for CL systems with an acceptable real-time performance, which is suitable for practical CL systems.},
  keywords={},
  doi={10.1109/LSP.2022.3233497},
  ISSN={1558-2361},
  month={},}
@INPROCEEDINGS{10002148,
  author={Suzuki, Hiroya and Okado, Yuki and Sakai, Toshinari and Miyamoto, Yuki and Kusaka, Taishun and Uchitane, Takeshi and Iwata, Kazunori and Ito, Nobuhiro},
  booktitle={2022 Joint 12th International Conference on Soft Computing and Intelligent Systems and 23rd International Symposium on Advanced Intelligent Systems (SCIS&ISIS)}, 
  title={Implementation of Pseudo-Communication Module for DCOP Algorithms on RRS and Improvement of Binary Max-Sum}, 
  year={2022},
  volume={},
  number={},
  pages={1-7},
  abstract={The RoboCupRescue Simulation (RRS) project is an international academic project that targets research related to disaster relief and has provided a disaster relief simulator as the research platform. We add a new mechanism for the distributed constraint optimization problem (DCOP) algorithm to the RRS simulator and confirm its effectiveness by improving the binary max-sum. Agents can communicate only once within each simulation timestep in the RRS, which adopts synchronous simulation. Therefore, it is difficult to apply the DCOP algorithm because it requires repeated communication to derive a solution. Hence, we introduce a pseudo-communication module to the RRS system in this paper so that the DCOP algorithm can be used on the RRS simulator. This module provides the function of processing many message passings among agents in each simulation timestep. RMAS-Bench, which is a similar approach, agents are not affected by partial situational awareness and communication range limitations. However, our module allows the evaluation of the DCOP algorithm in such scenarios. Additionally, we apply binary max-sum_ADVP, which is an improvement of the binary max-sum, to the RRS using our module. Finally, we confirm the effectiveness of the module by studying binary max-sum ADVP on RRS. The results confirmed the effectiveness of our pseudocommunication module; binary max-sum ADVP converged to a better solution than the binary max-sum. This implies that the extended RRS system worked well for the DCOP algorithm.},
  keywords={},
  doi={10.1109/SCISISIS55246.2022.10002148},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{10000923,
  author={Bariffi, Jessica and Bartz, Hannes and Liva, Gianluigi and Rosenthal, Joachim},
  booktitle={GLOBECOM 2022 - 2022 IEEE Global Communications Conference}, 
  title={Analysis of Low-Density Parity-Check Codes over Finite Integer Rings for the Lee Channel}, 
  year={2022},
  volume={},
  number={},
  pages={1-6},
  abstract={We study the performance of nonbinary low-density parity-check (LDPC) codes over finite integer rings over two channels that arise from the Lee metric. The first channel is a discrete memory-less channel (DMC) matched to the Lee metric. The second channel adds to each codeword an error vector of constant Lee weight, where the error vector is picked uniformly at random from the set of vectors of constant Lee weight. It is shown that the marginal conditional distributions of the two channels coincide, in the limit of large block length. Random coding union bounds on the block error probability are derived for both channels. Moreover, the performance of selected LDPC code ensembles is analyzed by means of density evolution and finite-length simulations, with belief propagation decoding and with a low-complexity symbol message passing algorithm and it is compared to the derived bounds.},
  keywords={},
  doi={10.1109/GLOBECOM48099.2022.10000923},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{10001105,
  author={Bian, Xinyu and Mao, Yuyi and Zhang, Jun},
  booktitle={GLOBECOM 2022 - 2022 IEEE Global Communications Conference}, 
  title={Error Rate Analysis for Grant-free Massive Random Access with Short-Packet Transmission}, 
  year={2022},
  volume={},
  number={},
  pages={4752-4757},
  abstract={Grant-free massive random access (RA) is a promising protocol to support the massive machine-type communications (mMTC) scenario in 5G and beyond networks. In this paper, we focus on the error rate analysis in grant-free massive RA, which is critical for practical deployment but has not been well studied. We consider a two-phase frame structure, with a pilot transmission phase for activity detection and channel estimation, followed by a data transmission phase with coded data symbols. Considering the characteristics of short-packet transmission, we analyze the block error rate (BLER) in the finite blocklength regime to characterize the data transmission performance. The analysis involves characterizing the activity detection and channel estimation errors as well as applying the random matrix theory (RMT) to analyze the distribution of the post-processing signal-to-noise ratio (SNR). As a case study, the derived BLER expression is further simplified to optimize the pilot length. Simulation results verify our analysis and demonstrate its effectiveness in pilot length optimization.},
  keywords={},
  doi={10.1109/GLOBECOM48099.2022.10001105},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{10008412,
  author={Hironaka, Kazuei and Iizuka, Kensuke and Amano, Hideharu},
  booktitle={2022 IEEE 15th International Symposium on Embedded Multicore/Many-core Systems-on-Chip (MCSoC)}, 
  title={A Message Passing Interface Library for High-Level Synthesis on Multi-FPGA Systems}, 
  year={2022},
  volume={},
  number={},
  pages={45-52},
  abstract={One obstacle to application development on multi-FPGA systems with high-level synthesis (HLS) is a lack of support for a programming interface. Implementing and debugging an application on multiple FPGA boards is difficult without a standard interface. Message Passing Interface (MPI) is a standard parallel programming interface commonly used in distributed memory systems. This paper presents a tool-independent MPI library called FiC-MPI that can be used in HLS for multi-FPGA systems in which each FPGA node is connected directly. By using FiC-MPI, various parallel software, including a general-purpose benchmark, can be easily implemented. FiC-MPI was implemented and evaluated on the M-KUBOS cluster consisting of Zynq MPSoC boards connected with a static time-division multiplexing network. By using the FiC-MPI simulator, parallel programs can be debugged before implementing on real machines. As a case study, the Himeno-BMT benchmark was implemented with FiC-MPI. It achieved 178.7 MFLOPS with a single node and scaled to 643.7 MFLOPS with four nodes, and 896.9 MFLOPS with six nodes of the M-KUBOS cluster. Through the implementation, the easiness of developing parallel programs with FiC-MPI on multi-FPGA systems was demonstrated.},
  keywords={},
  doi={10.1109/MCSoC57363.2022.00017},
  ISSN={2771-3075},
  month={Dec},}
@INPROCEEDINGS{10013644,
  author={Misra, Anshuman and Kshemkalyani, Ajay D.},
  booktitle={2022 IEEE 21st International Symposium on Network Computing and Applications (NCA)}, 
  title={Detecting Causality in the Presence of Byzantine Processes: There is No Holy Grail}, 
  year={2022},
  volume={21},
  number={},
  pages={73-80},
  abstract={Detecting causality or the happens before relation between events in an asynchronous distributed system is a fundamental building block for distributed applications. To the best of our knowledge, this problem has not been examined in a system with Byzantine processes. We prove the following results for an asynchronous system with Byzantine processes. (1) We prove that it is impossible to determine causality between events in the presence of even a single Byzantine process when processes communicate by unicasting. (2) We also prove a similar impossibility result when processes communicate by broadcasting. (3) We also prove a similar impossibility result when processes communicate by multicasting. (4) In an execution where there exists a causal path between two events passing through only correct processes, the impossibility result for unicasts remains. (5) However, when processes communicate by broadcasting and there exists a causal path between two events passing through only correct processes, it is possible to detect causality between such a pair of events. (6) In an execution where processes communicate by multicasting and there exists a causal path between two events passing through only correct processes, we prove that the impossibility result for multicasts remains.},
  keywords={},
  doi={10.1109/NCA57778.2022.10013644},
  ISSN={2643-7929},
  month={Dec},}
@INPROCEEDINGS{10013634,
  author={Misra, Anshuman and Kshemkalyani, Ajay D.},
  booktitle={2022 IEEE 21st International Symposium on Network Computing and Applications (NCA)}, 
  title={Causal Ordering Properties of Byzantine Reliable Broadcast Primitives}, 
  year={2022},
  volume={21},
  number={},
  pages={115-122},
  abstract={In this paper, we examine the inherent properties of the Byzantine Reliable Broadcast (BRB) primitive as pertain to the ability to provide causal ordering. We prove the following results. First, we analyze Bracha’s BRB algorithm and show that under the failure-free model, safety is guaranteed across broadcasts. Second, we also prove that Bracha’s BRB algorithm guarantees safety across broadcasts under the crash failure model tolerating any number of crash failures. Third, we prove that Bracha’s BRB algorithm cannot provide weak or strong safety under the Byzantine failure model. Fourth, we prove that neither the Imbs-Raynal BRB protocol nor any (2,*)-round BRB protocol can provide causal order even if all processes are correct, and they must incur additional latency to causally order messages at a higher layer. The inherent causal ordering properties of Bracha’s BRB can be of use under favourable circumstances in practical applications, given the widespread adoption of the protocol.},
  keywords={},
  doi={10.1109/NCA57778.2022.10013634},
  ISSN={2643-7929},
  month={Dec},}
@INPROCEEDINGS{10024609,
  author={Kumar, Mohit and Malakar, Preeti},
  booktitle={2022 IEEE/ACM International Workshop on Hierarchical Parallelism for Exascale Computing (HiPar)}, 
  title={Hierarchical Communication Optimization for FFT}, 
  year={2022},
  volume={},
  number={},
  pages={12-21},
  abstract={Fast Fourier Transforms (FFT) are used to solve various scientific and engineering problems. For example, computational fluid dynamics (CFD) simulations employ a pseudospectral method to solve flow simulations using Fast Fourier transforms (FFT). FFT requires global communications among all parallel processes; this often increases communication times. We present FFTOpt, a communication optimization library that leverages hierarchical communications within a compute node and across nodes of a large-scale system. This is a generic library that may optimize any code or application that uses MPI Alltoall and MPI Sendrecv without any dependency on the system or application. FFTOpt also uses topology information and runtime details about node allocation to aggregate at node and switch levels to reduce communication times. We tested FFTOpt in our department cluster (uses MPICH MPI library and connected by Ethernet) and PARAM Sanganak supercomputer (uses Intel MPI library and connected by Infiniband) of IIT Kanpur using the FFTW, FFTK and P3DFFT libraries. FFTOpt reduces communication time by up to 63%.},
  keywords={},
  doi={10.1109/HiPar56574.2022.00007},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{10024018,
  author={Fridman, Yehonatan and Snir, Yaniv and Levin, Harel and Hendler, Danny and Attiya, Hagit and Oren, Gal},
  booktitle={2022 IEEE/ACM 12th Workshop on Fault Tolerance for HPC at eXtreme Scale (FTXS)}, 
  title={Recovery of Distributed Iterative Solvers for Linear Systems Using Non-Volatile RAM}, 
  year={2022},
  volume={},
  number={},
  pages={11-23},
  abstract={HPC systems are a critical resource for scientific research and advanced industries. The increased demand for computational power and memory ushers in the exascale era, in which supercomputers are designed to provide enormous computing power to meet these needs. These complex supercomputers consist of numerous compute nodes and are consequently expected to experience frequent faults and crashes.Mathematical solvers, in particular, iterative linear solvers are key building block in numerous large-scale scientific applications. Consequently, supporting the recovery of distributed solvers is necessary for scaling scientific applications to exascale platforms. Previous recovery methods for iterative solvers are based on Checkpoint-Restart (CR), which incurs high fault tolerance overhead, or intrinsic fault tolerance, which require extra computation time to converge after failures.Exact state reconstruction (ESR) was proposed as an alternative mechanism to alleviate the impact of frequent failures on long-term computations. ESR has been shown to provide exact reconstruction of the computation state while avoiding the need for costly checkpointing. However, ESR currently relies on volatile memory for fault tolerance, and must therefore maintain redundancies in the RAM of multiple nodes. This not only incurs high memory overhead but also prevents ESR from being fully resilient, that is, resilient against a full system crash.Recent supercomputer designs feature emerging non-volatile RAM (NVRAM) technology, for example, the exascale Aurora that is planned to consist of Intel Optane™ DCPMM. This paper investigates how NVRAM can be utilized to devise an enhanced ESR-based recovery mechanism that is more efficient and provides full resilience. Our mechanism, called in-NVRAM ESR, provides full resiliency while significantly reducing both the memory footprint and the time overhead in comparison with the original ESR design (in-RAM ESR). In-NVRAM ESR is based on a novel MPI One-Sided Communication (OSC) over RDMA implementation, which was optimized and applied for using NVRAM to store recovery data for iterative linear solvers. The source code used in this work, as well as the benchmarks and other relevant sources, are available at: https://github.com/Scientific-Computing-Lab-NRCN/In-NVRAM-ESR.git.},
  keywords={},
  doi={10.1109/FTXS56515.2022.00007},
  ISSN={2831-3941},
  month={Nov},}
@INPROCEEDINGS{10024038,
  author={Bouteiller, Aurelien and Bosilca, George},
  booktitle={2022 IEEE/ACM 12th Workshop on Fault Tolerance for HPC at eXtreme Scale (FTXS)}, 
  title={Implicit Actions and Non-blocking Failure Recovery with MPI}, 
  year={2022},
  volume={},
  number={},
  pages={36-46},
  abstract={Scientific applications have long embraced the MPI as the environment of choice to execute on large distributed systems. The User-Level Failure Mitigation (ULFM) specification extends the MPI standard to address resilience and enable MPI applications to restore their communication capability after a failure. This works builds upon the wide body of experience gained in the field to eliminate a gap between current practice and the ideal, more asynchronous, recovery model in which the fault tolerance activities of multiple components can be carried out simultaneously and overlap. This work proposes to: (1) provide the required consistency in fault reporting to applications (i.e., enable an application to assess the success of a computational phase without incurring an unacceptable performance hit); (2) bring forward the building blocks that permit the effective scoping of fault recovery in an application, so that independent components in an application can recover without interfering with each other, and separate groups of processes in the application can recover independently or in unison; and (3) overlap recovery activities necessary to restore the consistency of the system (e.g., eviction of faulty processes from the communication group) with application recovery activities (e.g., dataset restoration from checkpoints).},
  keywords={},
  doi={10.1109/FTXS56515.2022.00009},
  ISSN={2831-3941},
  month={Nov},}
@INPROCEEDINGS{10024043,
  author={Fang, Bo and Hari, Siva Kumar Sastry and Tsai, Timothy and Li, Xinyi and Gopalakrishnan, Ganesh and Laguna, Ignacio and Barker, Kevin and Li, Ang},
  booktitle={2022 IEEE/ACM 12th Workshop on Fault Tolerance for HPC at eXtreme Scale (FTXS)}, 
  title={Towards Precision-Aware Fault Tolerance Approaches for Mixed-Precision Applications}, 
  year={2022},
  volume={},
  number={},
  pages={47-52},
  abstract={Scientific applications have long embraced the MPI as the environment of choice to execute on large distributed systems. The User-Level Failure Mitigation (ULFM) specification extends the MPI standard to address resilience and enable MPI applications to restore their communication capability after a failure. This works builds upon the wide body of experience gained in the field to eliminate a gap between current practice and the ideal, more asynchronous, recovery model in which the fault tolerance activities of multiple components can be carried out simultaneously and overlap. This work proposes to: (1) provide the required consistency in fault reporting to applications (i.e., enable an application to assess the success of a computational phase without incurring an unacceptable performance hit); (2) bring forward the building blocks that permit the effective scoping of fault recovery in an application, so that independent components in an application can recover without interfering with each other, and separate groups of processes in the application can recover independently or in unison; and (3) overlap recovery activities necessary to restore the consistency of the system (e.g., eviction of faulty processes from the communication group) with application recovery activities (e.g., dataset restoration from checkpoints).},
  keywords={},
  doi={10.1109/FTXS56515.2022.00010},
  ISSN={2831-3941},
  month={Nov},}
@INPROCEEDINGS{10024016,
  author={Hübner, Lukas and Hespe, Demian and Sanders, Peter and Stamatakis, Alexandros},
  booktitle={2022 IEEE/ACM 12th Workshop on Fault Tolerance for HPC at eXtreme Scale (FTXS)}, 
  title={ReStore: In-Memory REplicated STORagE for Rapid Recovery in Fault-Tolerant Algorithms}, 
  year={2022},
  volume={},
  number={},
  pages={24-35},
  abstract={Fault-tolerant distributed applications require mechanisms to recover data lost via a process failure. On modern cluster systems it is typically impractical to request replacement resources after such a failure. Therefore, applications have to continue working with the remaining resources. This requires redistributing the workload and that the non-failed processes reload data. We present an algorithmic framework and its C++ library implementation ReStore for MPI programs that enables recovery of data after process failures. By storing all required data in memory via an appropriate data distribution and replication, recovery is substantially faster than with standard checkpointing schemes that rely on a parallel file system. As the application developer can specify which data to load, we also support shrinking recovery instead of recovery using spare compute nodes. We evaluate ReStore in both controlled, isolated environments and real applications. Our experiments show loading times of lost input data in the range of milliseconds on up to 24 576 processors and a substantial speedup of the recovery time for the fault-tolerant version of a widely used bioinformatics application.},
  keywords={},
  doi={10.1109/FTXS56515.2022.00008},
  ISSN={2831-3941},
  month={Nov},}
@INPROCEEDINGS{10025545,
  author={Cooperman, Gene and Li, Dahong and Zhao, Zhengji},
  booktitle={2022 IEEE/ACM Third International Symposium on Checkpointing for Supercomputing (SuperCheck)}, 
  title={Debugging MPI Implementations via Reduction-to-Primitives}, 
  year={2022},
  volume={},
  number={},
  pages={1-9},
  abstract={Testing correctness of either a new MPI implementation or a transparent checkpointing package for MPI is inherently difficult. A bug is often observed when running a correctly written MPI application, and it produces an error. Tracing the bug to a particular subsystem of the MPI package is difficult due to issues of complex parallelism, race conditions, etc. This work provides tools to decide if the bug is: in the subsystem implementing of collective communication; or in the subsystem implementing point-to-point communication; or in some other subsystem. The tools were produced in the context of testing a new system, MANA. MANA is not a standalone MPI implementation, but rather a package for transparent checkpointing of MPI applications. In addition, a short survey of other debugging tools for MPI is presented. The strategy of transforming the execution for purposes of diagnosing a bug appears to be distinct from most existing debugging approaches.},
  keywords={},
  doi={10.1109/SuperCheck56652.2022.00007},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{10025539,
  author={Esposito, Aniello and Haine, Christopher and Mohammed, Ali},
  booktitle={2022 IEEE/ACM Third International Symposium on Checkpointing for Supercomputing (SuperCheck)}, 
  title={Emergency Backup for Scientific Applications}, 
  year={2022},
  volume={},
  number={},
  pages={1-8},
  abstract={A framework for the efficient in-network data transfer between a parallel application and an independent storage server is proposed. The case of an unexpected and unrecoverable interruption of the application is considered, where the server takes the role of an emergency backup service preventing the unnecessary loss of valuable information. Workload managers such as SLURM provide a time buffer between the interruption and the termination of an application which can be optimally exploited by the framework making use of RDMA transport and redistribution of data by means of the Maestro middleware. An alternative could consist in a state-of-the-art checkpoint restart mechanism relying on a possibly shared storage hierarchy which suffers from variability and is not scalable in general or in-memory checkpointing which increases memory consumption considerably. Experiments are performed on a HPE/Cray EX system to construct a heuristics for amounts of data that can realistically be backed up during a given time buffer. The method proves to be faster than VELOC and plain MPI-IO using one server node already, for a number of user ranks up to a hundred, with the promise of also better scalability in the long run due to the in-network approach as opposed to filesystem transport.},
  keywords={},
  doi={10.1109/SuperCheck56652.2022.00008},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{10026970,
  author={Guaitero, Rafael A. Herrera and Diaz, Jose M Monsalve and Applencourt, Thomas and Li, Xiaoming and Doerfert, Johannes},
  booktitle={2022 IEEE/ACM Eighth Workshop on the LLVM Compiler Infrastructure in HPC (LLVM-HPC)}, 
  title={Automatic Asynchronous Execution of Synchronously Offloaded OpenMP Target Regions}, 
  year={2022},
  volume={},
  number={},
  pages={23-33},
  abstract={Use of heterogeneous architectures has steadily increased during the past decade. However, non-homogeneous systems present a challenge to the programming model as the execution models between CPU and accelerator might differ considerably. OpenMP, since version 4.0, has been trying to bridge this gap by allowing to offload a code block to a target device. Among the additions to the OpenMP offloading API since, the most notably probably is asynchronous execution between device and host. By default, offloaded regions are executed synchronously, thus the host thread blocks until their completion. The nowait clause allows work to overlap between the host and target device. However, nowait must be manually added by the user, along with the tasks data dependencies and appropriate synchronization to avoid race conditions, increasing the program complexity and developer burden. In this work, we present automatic asynchronous execution for OpenMP offloaded regions. By taking advantage of the distinct host and target data environments, we discover opportunities that allow them to overlap execution without any need for user intervention. We also describe the necessary changes in the LLVM/OpenMP runtime. We evaluate our implementation through multiple HPC proxy applications and well known parallel benchmarks executed on GPUs. The measured performance can double for an ideal test case while real application exhibit speedups between 5% and 34%.},
  keywords={},
  doi={10.1109/LLVM-HPC56686.2022.00008},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{10026975,
  author={Tian, Shilei and Huber, Joseph and Parasyris, Konstantinos and Chapman, Barbara and Doerfert, Johannes},
  booktitle={2022 IEEE/ACM Eighth Workshop on the LLVM Compiler Infrastructure in HPC (LLVM-HPC)}, 
  title={Direct GPU Compilation and Execution for Host Applications with OpenMP Parallelism}, 
  year={2022},
  volume={},
  number={},
  pages={43-51},
  abstract={Currently, offloading to accelerators requires users to identify which regions are to be executed on the device, what memory needs to be transferred, and how synchronization is to be resolved. On top of these manual tasks, many standard (C/ C++ library) functions, such as file I/O or memory manipulation, cannot be directly executed on the device and need to be worked around by the user explicitly. This makes it challenging to port programs in the first place and hinders developers from testing features on the GPU and within the GPU compilation pipeline. Existing tests and test suites for the host are effectively unusable for accelerators and need to be manually ported to provide the same benefits for the devices as they do on the host. In this paper, we propose a direct GPU compilation scheme that leverages the portable target offloading interface provided by LLVM/OpenMP. Utilizing this infrastructure allows us to compile an existing host application for the GPU and execute it there with only a minimal wrapper layer for the user code, command line arguments, and a compiler provided GPU implementation of C/ C++ standard library functions. The C/ C++ library functions are partially implemented for direct device execution and otherwise fallback to remote procedure call (RPC) to call host functions transparently. Our proposed prototype will allow users to quickly compile for, and test on, the GPU without explicitly handling kernel launches, data mapping, or host-device synchronization. We evaluate our implementation using three proxy applications with host OpenMP parallelism and three microbenchmarks to test the correctness of our prototype GPU compilation.},
  keywords={},
  doi={10.1109/LLVM-HPC56686.2022.00010},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{10024020,
  author={Groves, Taylor and Daley, Chris and Gayatri, Rahulkumar and Nam, Hai Ah and Ding, Nan and Oliker, Lenny and Wright, Nicholas J. and Williams, Samuel},
  booktitle={2022 IEEE/ACM International Workshop on Performance Modeling, Benchmarking and Simulation of High Performance Computer Systems (PMBS)}, 
  title={A Methodology for Evaluating Tightly-integrated and Disaggregated Accelerated Architectures}, 
  year={2022},
  volume={},
  number={},
  pages={71-81},
  abstract={Tighter integration of computational resources can foster superior application performance by mitigating communication bottlenecks. Unfortunately, not every application can use every compute or accelerator all the time. As a result, co-locating resources often leads to under-utilization of resources. To mitigate this challenge, architects have proposed disaggregation and ad hoc pooling of computational resources. In the next five years, HPC system architects will be presented with a spectrum of accelerated solutions ranging from tightly coupled, single package APUs to a sea of disaggregated GPUs interconnected by a global network. In this paper, we detail NEthing, our methodology and tool for evaluating the potential performance implications of such diverse architectural paradigms. We demonstrate our methodology on today’s and projected 2026 technologies for three distinct workloads: a compute-intensive kernel, a tightly-coupled HPC simulation, and an ensemble of loosely-coupled HPC simulations. Our results leverage NEthing to quantify the increased utilization disaggregated systems must achieve in order to match superior performance of APUs and on-board GPUs.},
  keywords={},
  doi={10.1109/PMBS56514.2022.00012},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{10024672,
  author={Budanaz, Yakup and Wille, Mario and Bader, Michael},
  booktitle={2022 IEEE/ACM Parallel Applications Workshop: Alternatives To MPI+X (PAW-ATM)}, 
  title={Asynchronous Workload Balancing through Persistent Work-Stealing and Offloading for a Distributed Actor Model Library}, 
  year={2022},
  volume={},
  number={},
  pages={39-51},
  abstract={With dynamic imbalances caused by both software and ever more complex hardware, applications and runtime systems must adapt to dynamic load imbalances. We present a diffusion-based, reactive, fully asynchronous, and decentralized dynamic load balancer for a distributed actor library. With the asynchronous execution model, features such as remote procedure calls, and support for serialization of arbitrary types, UPC++ is especially feasible for the implementation of the actor model. While providing a substantial speedup for small- to medium-sized jobs with both predictable and unpredictable workload imbalances, the scalability of the diffusion-based approaches remains below expectations in most presented test cases.},
  keywords={},
  doi={10.1109/PAW-ATM56565.2022.00009},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{10027593,
  author={Yu, Lechen and Jin, Feiyang and Protze, Joachim and Sarkar, Vivek},
  booktitle={2022 IEEE/ACM Sixth International Workshop on Software Correctness for HPC Applications (Correctness)}, 
  title={Leveraging the Dynamic Program Structure Tree to Detect Data Races in OpenMP Programs}, 
  year={2022},
  volume={},
  number={},
  pages={54-62},
  abstract={OpenMP provides a rich set of constructs to support multiple paradigms of parallelization, e.g., single program multiple data (SPMD) and task parallelism. Integrating these disparate paradigms in a single execution model increases the complexity of OpenMP, making OpenMP programs prone to concurrency bugs such as data races. Inspired by the task-oriented execution model in the OpenMP spec, we extended SPD3, a data race detection algorithm designed for async-finish task parallelism to support OpenMP programs. We found that by extending SPD3's key data structure, the Dynamic Program Structure Tree (DPST), SPD3 can support the majority of OpenMP constructs. We have implemented a prototype, TSan-spd3, on top of Google's ThreadSanitizer (TSan). To conduct an apples-to-apples comparison with Archer, the state-of-the-art dynamic race detector for OpenMP programs, we compared TSan-spd3 with an Archer implementation that executes on the same version of TSan. In addition, we evaluated Archer in two modes, the default mode using the original TSan and the accelerated mode enabling the use of SIMD instructions in TSan. The evaluation was conducted on nine benchmarks from the BOTS and SPEC OMP2012 benchmark suites. The evaluation results show that in eight out of nine benchmarks TSan-spd3 achieved similar overhead with Archer, while TSan-spd3 can identify more potential races than Archer.},
  keywords={},
  doi={10.1109/Correctness56720.2022.00012},
  ISSN={2831-3925},
  month={Nov},}
@INPROCEEDINGS{10027512,
  author={Saillard, Emmanuelle and Sergent, Marc and Ait Kaci, Célia Tassadit and Barthou, Denis},
  booktitle={2022 IEEE/ACM Sixth International Workshop on Software Correctness for HPC Applications (Correctness)}, 
  title={Static Local Concurrency Errors Detection in MPI-RMA Programs}, 
  year={2022},
  volume={},
  number={},
  pages={18-26},
  abstract={Communications are a critical part of HPC simulations, and one of the main focuses of application developers when scaling on supercomputers. While classical message passing (also called two-sided communications) is the dominant communication paradigm, one-sided communications are often praised to be efficient to overlap communications with computations, but challenging to program. Their usage is then generally abstracted through languages and memory abstractions to ease programming (e.g. PGAS). Therefore, little work has been done to help programmers use intermediate runtime layers, such as MPI-RMA, that is often reserved to expert programmers. Indeed, programming with MPI - RMA presents several challenges that require handling the asynchronous nature of one-sided communications to ensure the proper semantics of the program while ensuring its memory consistency. To help programmers detect memory errors such as race conditions as early as possible, this paper proposes a new static analysis of MPI - RMA codes that shows to the programmer the errors that can be detected at compile time. The detection is based on a novel local concurrency errors detection algorithm that tracks accesses through BFS searches on the Control Flow Graphs of a program. We show on several tests and an MPI-RMA variant of the GUPS benchmark that the static analysis allows to detect such errors on user codes. The error codes are integrated in the MPI Bugs Initiative open-source test suite.},
  keywords={},
  doi={10.1109/Correctness56720.2022.00008},
  ISSN={2831-3925},
  month={Nov},}
@INPROCEEDINGS{10027515,
  author={Schwitanski, Simon and Jenke, Joachim and Tomski, Felix and Terboven, Christian and Müller, Matthias S.},
  booktitle={2022 IEEE/ACM Sixth International Workshop on Software Correctness for HPC Applications (Correctness)}, 
  title={On-the-Fly Data Race Detection for MPI RMA Programs with MUST}, 
  year={2022},
  volume={},
  number={},
  pages={27-36},
  abstract={MPI Remote Memory Access (RMA) provides a one-sided communication model for MPI applications. Ensuring consistency between RMA operations with synchronization calls is a key requirement when writing correct RMA codes. Wrong API usage may lead to concurrent modifications of the same memory location without proper synchronization resulting in data races across processes. Due to their non-deterministic nature, such data races are hard to detect. This paper presents MUST-RMA, an on-the-fly data race detector for MPI RMA applications. MUST-RMA uses a race detection model based on happened-before and consistency analysis. It combines the MPI correctness tool MUST with the race detector ThreadSanitizer to detect races across processes in RMA applications. A classification quality study on MUST-RMA with different test cases shows a precision and recall of 0.95. An overhead study on a stencil and a matrix transpose kernel shows runtime slowdowns of 3x to 20x for up to 192 processes.},
  keywords={},
  doi={10.1109/Correctness56720.2022.00009},
  ISSN={2831-3925},
  month={Nov},}
@INPROCEEDINGS{10027109,
  author={Jammer, Tim and Bischof, Christian},
  booktitle={2022 IEEE/ACM International Workshop on Exascale MPI (ExaMPI)}, 
  title={Compiler-enabled optimization of persistent MPI Operations}, 
  year={2022},
  volume={},
  number={},
  pages={1-10},
  abstract={MPI is widely used for programming large HPC clusters. MPI also includes persistent operations, which specify recurring communication patterns. The idea is that the usage of those operations can result in a performance benefit compared to the standard non-blocking communication. But in current MPI implementations, this performance benefit is not really observable. We determine the message envelope matching as one of the causes of overhead. Unfortunately, this matching can only hardly be overlapped with computation. In this work, we explore how compiler knowledge can be used to extract more performance benefit from the usage of persistent operations. We find that the compiler can do some of the required matching work for persistent MPI operations. As persistent MPI requests can be used multiple times, the compiler can, in some cases, prove that message matching is only needed for the first occurrence and can be entirely skipped for subsequent instances. In this paper, we present the required compiler analysis, as well as an implementation of a communication scheme that skips the message envelope matching and directly transfers the data via RDMA instead. This allows us to substantially reduce the communication overhead that cannot be overlapped with computation. Using the Intel IMB-ASYNC Benchmark, we can see a communication overhead reduction of up to 95 percent for larger message sizes.},
  keywords={},
  doi={10.1109/ExaMPI56604.2022.00006},
  ISSN={2831-3372},
  month={Nov},}
@INPROCEEDINGS{10026924,
  author={Agrawal, Tushar and Malakar, Preeti},
  booktitle={2022 IEEE/ACM International Workshop on Exascale MPI (ExaMPI)}, 
  title={IPMPI: Improved MPI Communication Logger}, 
  year={2022},
  volume={},
  number={},
  pages={31-40},
  abstract={Most parallel profilers reveal only the MPI point-to-point communication patterns in a communication matrix. However, this may lead to sub-optimal process mapping due to incomplete information about the application communications. In this work, we have developed a profiler, IPMPI, that reveals the complete communication information including collective communications. We compare the results of two recent process mapping tools, TopoMatch and LPMS, with and without the input from IPMPI. We have run six applications and benchmarks such as ROMS, LAMMPS, DFT, HPCG, miniAMR and miniFE on two supercomputers and our shared department cluster. We observed a maximum average gain between 5.7 - 8.6% across these systems.},
  keywords={},
  doi={10.1109/ExaMPI56604.2022.00009},
  ISSN={2831-3372},
  month={Nov},}
@INPROCEEDINGS{10029965,
  author={Madonna, Alberto and Aliaga, Tomas},
  booktitle={2022 IEEE/ACM 4th International Workshop on Containers and New Orchestration Paradigms for Isolated Environments in HPC (CANOPIE-HPC)}, 
  title={Libfabric-based Injection Solutions for Portable Containerized MPI Applications}, 
  year={2022},
  volume={},
  number={},
  pages={45-56},
  abstract={Linux containers bring several advantages for the deployment of High Performance Computing applications using the Message Passing Interface (MPI). However, efficiently leveraging high-speed network resources when employing portable container images able to work on different systems remains a challenging goal. Often, the adopted approach to combine image portability with performance is to replace at runtime the container's MPI libraries with a native implementation. While effective, such practice is heavily constrained by the requirement of binary compatibility between host and container libraries. This work presents two techniques based on libfabric which overcome the limitations of MPI replacement, while still granting containerized applications near-native communication performance and portability. These techniques were validated experimentally with synthetic benchmarks, demonstrating their effectiveness and, in the case of one technique, revealing a notable degree of flexibility at runtime. Two scale-out experiments also showed the capability to closely match native results using both synthetic and real-world benchmarks.},
  keywords={},
  doi={10.1109/CANOPIE-HPC56864.2022.00010},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{10029991,
  author={Milroy, Daniel J. and Misale, Claudia and Georgakoudis, Giorgis and Elengikal, Tonia and Sarkar, Abhik and Drocco, Maurizio and Patki, Tapasya and Yeom, Jae-Seung and Gutierrez, Carlos Eduardo Arango and Ahn, Dong H. and Park, Yoonho},
  booktitle={2022 IEEE/ACM 4th International Workshop on Containers and New Orchestration Paradigms for Isolated Environments in HPC (CANOPIE-HPC)}, 
  title={One Step Closer to Converged Computing: Achieving Scalability with Cloud-Native HPC}, 
  year={2022},
  volume={},
  number={},
  pages={57-70},
  abstract={As High Performance Computing (HPC) workflows increase in complexity, their designers seek to enable automation and flexibility offered by cloud technologies. Container orchestration through Kubernetes enables highly desirable capabilities but does not satisfy the performance demands of HPC. Kubernetes tools that automate the lifecycle of Message Passing Interface (MPI)-based applications do not scale, and the Kubernetes scheduler does not provide crucial scheduling capabilities. In this work, we detail our efforts to port CORAL-2 benchmark codes to Kubernetes on IBM Cloud and AWS EKS. We describe contributions to the MPI Operator to achieve 3,000-rank scale, a two-orders-of-magnitude improvement to state of the art. We discuss enhancements to Fluence, our scheduler plugin for Kubernetes based on the next-generation, cloud-ready Flux framework. Finally, we compare the placement decisions of Fluence with those of the Kubernetes scheduler and demonstrate that Fluence allows simulated scientific workflows to achieve up to 3× higher performance.},
  keywords={},
  doi={10.1109/CANOPIE-HPC56864.2022.00011},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{10029384,
  author={Jin, Yu and JaJa, Joseph F.},
  booktitle={2022 IEEE International Conference on Data Mining Workshops (ICDMW)}, 
  title={Improving Graph Neural Network with Learnable Permutation Pooling}, 
  year={2022},
  volume={},
  number={},
  pages={682-689},
  abstract={Graph neural networks (GNN) have achieved great success in various graph-related applications. Most existing graph neural network models follow the message-passing neural network (MPNN) paradigm where the graph pooling function forms a critical component that directly determines the model effectiveness. In this paper, we propose PermPool, a new graph pooling function that provably improves the GNN model expressiveness. The method is based on the insight that the distribution of node permuations, when defined properly, forms characteristic encoding of graphs. We propose to express graph representations as the expectation of node permutations with a general pooling function. We show that the graph representation remains invariant to node-reordering and has strong expressive power than MPNN models. In addition, we propose novel permutation modeling and sampling techniques that integrate PermPool into the differentiable neural network models. Empirical results show that our method outperformed other pooling methods in benchmark graph classification tasks.},
  keywords={},
  doi={10.1109/ICDMW58026.2022.00094},
  ISSN={2375-9259},
  month={Nov},}
@INPROCEEDINGS{10039629,
  author={Fadhil, Heba Mohammed and Abdulnasser, Zainab and Mohammed, Shahad},
  booktitle={2022 International Conference on Computer and Applications (ICCA)}, 
  title={Improve Data Mining Techniques with a High-Performance Cluster}, 
  year={2022},
  volume={},
  number={},
  pages={1-5},
  abstract={People's reliance on computers and the computing power they provide is growing by the minute. An ever-increasing amount of data is being created each day, and the power to analyze this data requires the use of cluster computers to process and calculate data. It has been discovered that data clustering is a beneficial data mining approach. There have been a number of recent attempts to cluster data mining methods. Using a Raspberry Pi cluster, this study employs the Apriori algorithm, which is the most generally used algorithm, to extract frequent itemsets from large data sets. The fundamental aim is to build a cluster and provide data analysis capabilities based on an examination of the major clustering phases in order to illustrate the power of cluster computing and the applications of data analytics. Each Raspberry Pi uses the MPI standard and Python multiprocessing to share a large task and then coordinate their findings among a group of four or more MPICH systems at the conclusion of the processing. At the data partitioning stage, the issue of load balancing must be taken into account. According to our testing results, clustering accelerates sequential classification by a factor of 10. There is a noticeable increase in performance when there are additional processors installed. Additionally, we discovered that item count had a bigger effect on clustering performance than transaction count.},
  keywords={},
  doi={10.1109/ICCA56443.2022.10039629},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{10047718,
  author={Mishra, Vinay Kumar and Pundir, Avdesh Singh},
  booktitle={2022 Second International Conference on Advanced Technologies in Intelligent Control, Environment, Computing & Communication Engineering (ICATIECE)}, 
  title={Large-scale Information Management using Hadoop Platform}, 
  year={2022},
  volume={},
  number={},
  pages={1-6},
  abstract={The information produced today is enormous and is increasing more quickly than computer speeds can keep up. As a result, it is no longer advantageous and often takes a long time to maintain or process information using traditional methods, or as we may say, a single machine. Under the terms of the Apache License, In the cloud hardware of the distributed file system, this research also covers optimizing the number of computing nodes and the message passing pathways. According to HIVE.apache.org, the Apache HIVE data storage software makes it easier to read, write, and manage huge datasets that are stored in distributed storage using SQL. The installation and launch of Hadoop and HIVE, setting up the rules in a Hadoop cluster, and a few use cases for performance testing are all covered at the end of the chapter.},
  keywords={},
  doi={10.1109/ICATIECE56365.2022.10047718},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{10056508,
  author={Vargas-Pérez, Sandino},
  booktitle={2022 IEEE 29th International Conference on High Performance Computing, Data and Analytics Workshop (HiPCW)}, 
  title={Designing an Independent Study to Create HPC Learning Experiences for Undergraduates}, 
  year={2022},
  volume={},
  number={},
  pages={6-11},
  abstract={This paper aims to present a multi-tiered approach to designing learning experiences in HPC for undergraduate students that significantly reinforce comprehension of CS topics while working with new concepts in parallel and distributed computing. The paper will detail the experience of students working in the design, construction, and testing of a computing cluster including budgeting, hardware purchase and setup, software installation and configuration, interconnection networks, communication, benchmarking, and running parallel code using MPI and OpenMP. The case study of building a relatively low-cost, small-scale computing cluster that can be used as a template for CS senior projects or independent studies, also yielded an opportunity to involve students in the creation of teaching tools for parallel computing at many levels of the CS curriculum.},
  keywords={},
  doi={10.1109/HiPCW57629.2022.00006},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{10070699,
  author={Zhang, Baoming and Xu, Ming and Chen, Mingcai and Chen, Mingyuan and Wang, Chongjun},
  booktitle={2022 IEEE Intl Conf on Parallel & Distributed Processing with Applications, Big Data & Cloud Computing, Sustainable Computing & Communications, Social Computing & Networking (ISPA/BDCloud/SocialCom/SustainCom)}, 
  title={CopGAT: Co-propagation Self-supervised Graph Attention Network}, 
  year={2022},
  volume={},
  number={},
  pages={18-25},
  abstract={Graph Attention Network (GAT) is one of the state-of-the-art architectures for Graph Neural Networks (GNNs). In this paper, we first propose Label Purity to explore the relationship between the graph attention and the node labels. By tracking the label purity of graph attention, we observe that graph attention suppresses message passing between inter-class nodes in the graph with homophily. Upon such basis, we further improve graph attention's capability to capture label information by designing a self-supervised graph attention loss. We propose a novel approach based on self-supervised graph attention loss, Co-propagation Self-supervised Graph Attention Network (CopGAT), which explicitly restrains message passing between inter-class nodes. The Co-propagation means propagating node representations in Euclidean space and pseudo labels in probability simplex via the shared attention matrix, combining Message Passing Neural Networks and Label Propagation Algorithm under the graph attention framework. Constrained with the self-supervised graph attention loss generated by co-propagation, our CopGAT enhances the ability of GAT to attenuate the influence of structural noise. Furthermore, our self-supervised graph attention loss can be extended to other graph attention models in a plug-and-play manner. Experimental results demonstrate that our Cop GAT outperforms previous state-of-the-art methods on five benchmark datasets for the semi-supervised node classification task.},
  keywords={},
  doi={10.1109/ISPA-BDCloud-SocialCom-SustainCom57177.2022.00010},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{10074760,
  author={Xu, Yusen and Shen, Sijie and Han, Mingcong and Chen, Rong},
  booktitle={2022 IEEE 24th Int Conf on High Performance Computing & Communications; 8th Int Conf on Data Science & Systems; 20th Int Conf on Smart City; 8th Int Conf on Dependability in Sensor, Cloud & Big Data Systems & Application (HPCC/DSS/SmartCity/DependSys)}, 
  title={FNotify: A Low-Latency and Scalable Publish/Subscribe System using RDMA}, 
  year={2022},
  volume={},
  number={},
  pages={327-336},
  abstract={Publish/subscribe systems are widely used as messaging middleware in various scenarios, such as online business, financial trading, and social media. However, the network overhead intro-duced by the pub/sub system can severely impact application performance. Especially in the latency-sensitive applications of the data center, optimizing the latency of publishing or delivering messages of the pub/sub system is particularly important. RDMA network has gained popularity in relevant applications due to its low latency, high bandwidth and ability to bypass the CPU. Never-theless, it is still challenging to design and optimize the pub/sub system using RDMA. Through an in-depth analysis of RDMA features, we design and implement FNotify, a high-performance RDMA-accelerated pub/sub system. FNotify optimizes latency and CPU load using in-memory message management and one-sided RDMA primitives for message collection. FNotify also proposes a topic-based partitioning scheme to achieve good scal-ability. We conducted a comprehensive evaluation and analysis on an 8-node RDMA cluster to verify the validity of our design by comparing the performance of FNotify with Apache Kafka (a state-of-the-art pub/sub system) in a typical pub/sub application scenario and various micro-benchmarks. Experimental results show that FNotify improves overall performance by $1.5\times$ to $3.9\times$ and reduces end-to-end latency by more than $20\times$ compared to Apache Kafka.},
  keywords={},
  doi={10.1109/HPCC-DSS-SmartCity-DependSys57074.2022.00074},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{10080112,
  author={Mahto, Dinesh Kumar and Saini, Vikash Kumar and Mathur, Akhilesh and Kumar, Rajesh and Verma, Seema},
  booktitle={2022 IEEE International Conference on Power Electronics, Drives and Energy Systems (PEDES)}, 
  title={MPGCN-OPF: A Message Passing Graph Convolution Approach for Optimal Power Flow for Distribution Network}, 
  year={2022},
  volume={},
  number={},
  pages={1-6},
  abstract={Optimal power flow (OPF) i s t he nonlinear, non convex optimization setpoint problem of power and voltage due to the complex relation between system operating status and the OPF solutions with satisfying load demand. The recent advancement in machine learning computation models with unforeseen data availability witnessed a significant transition into data-driven approaches due to information and a feature mapping property. In this paper, we proposed the Message passing graph convolution (MPGCN) model into a unified framework for OPF solutions. The proposed methodology is based on graph convolution property and message passing interface to take advantage of both techniques. The proposed model is an effective alternative to the existing popular DNN technique in terms of model loss function & performance evalu-ation indices with the IEEE-33 bus power distribution network. The simulation results validate that the proposed MPGCN-OPF model outperforms the DNN model. The performance evaluation indices of the proposed model include MSE, RMSE, and MAE are 0.0664, 0.2576, and 0.0719 respectively.},
  keywords={},
  doi={10.1109/PEDES56012.2022.10080112},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{10106286,
  author={Suresh, Kaushik Kandadi and Guptha, Akshay Paniraja and Michalowicz, Benjamin and Ramesh, Bharath and Abduljabbar, Mustafa and Shafi, Aamir and Subramoni, Hari and Panda, Dhabaleswar},
  booktitle={2022 IEEE 29th International Conference on High Performance Computing, Data, and Analytics (HiPC)}, 
  title={Efficient Personalized and Non-Personalized Alltoall Communication for Modern Multi-HCA GPU-Based Clusters}, 
  year={2022},
  volume={},
  number={},
  pages={100-104},
  abstract={Graphics Processing Units (GPUs) have become ubiquitous in today’s supercomputing clusters primarily because of their high compute capability and power efficiency. Message Passing Interface (MPI) is a widely adopted programming model for large-scale GPU-based applications used in such clusters. Modern GPU-based systems have multiple HCAs. Previously, scientists have leveraged multi-HCA systems to accelerate inter-node transfers between CPUs using point-to-point primitives. In this work, we show the need for collective-level, multi-rail aware algorithms using MPI_Allgather as an example. We then propose an efficient multi-rail MPI_Allgather algorithm and extend it to MPI_Alltoall. We analyze the performance of this algorithm using OMB benchmark suite. We demonstrate approximately 30% and 43% improvement in non-personalized and personalized communication benchmarks respectively when compared with the state-of-the-art MPI libraries on 128 GPUs},
  keywords={},
  doi={10.1109/HiPC56025.2022.00025},
  ISSN={2640-0316},
  month={Dec},}
@INPROCEEDINGS{10106309,
  author={Zhou, Qinghua and Anthony, Quentin and Shafi, Aamir and Subramoni, Hari and Panda, Dhabaleswar K. DK},
  booktitle={2022 IEEE 29th International Conference on High Performance Computing, Data, and Analytics (HiPC)}, 
  title={Accelerating Broadcast Communication with GPU Compression for Deep Learning Workloads}, 
  year={2022},
  volume={},
  number={},
  pages={22-31},
  abstract={With the rapidly increasing model sizes, state-of-the-art Deep Learning (DL) models rely on multiple GPU nodes to run distributed training. Large message communication of GPU data between the GPUs is becoming a performance bottleneck in the overall training performance. GPU-Aware MPI libraries are widely adopted for state-of-the-art DL frameworks to improve communication performance. In the existing optimization solutions for Distributed Data-Parallel (DDP) training, the broadcast operation is often utilized to sync up the updated model parameters among all the GPUs. However, for state-of-the-art GPU-Aware MPI libraries, broadcasting large GPU data turns to overburden the training performance due to the limited bandwidth of interconnect between the GPU nodes. On the other hand, the recent research on using GPU-based compression libraries to lower the pressure on the nearly saturated interconnection and co-designing online compression with the communication pattern provides a new perspective to optimize the performance of broadcast on modern GPU clusters.In this paper, we redesign the GPU-Aware MPI library to enable efficient collective-level online compression with an optimized chunked-chain scheme for large message broadcast communication. The proposed design is evaluated to show benefits at both microbenchmark and application levels. At the microbenchmark level, the proposed design can reduce the broadcast communication latency by up to 80.9% compared to the baseline using a state-of-the-art MPI library and 55.1% compared to the existing point-to-point-based compression on modern GPU clusters. For DDP training with PyTorch, the proposed design reduces the training time by up to 15.0% and 6.4% compared to the existing chunked-chain scheme and point-to-point-based compression, respectively, while keeping similar training accuracy. To the best of our knowledge, this is the first work that leverages online GPU-based compression techniques to significantly accelerate broadcast communication for DL workloads.},
  keywords={},
  doi={10.1109/HiPC56025.2022.00016},
  ISSN={2640-0316},
  month={Dec},}
@INPROCEEDINGS{10180952,
  author={Gamazo-Real, Jose-Carlos and Fernández, Raúl Torres and Armas, Adrián Murillo},
  booktitle={2022 2nd International Seminar on Machine Learning, Optimization, and Data Science (ISMODE)}, 
  title={Estimation of Air Quality Parameters using Lightweight Machine Learning on Low-cost Edge-IoT Architectures}, 
  year={2022},
  volume={},
  number={},
  pages={348-352},
  abstract={The vast increase in connected Internet of Things (IoT) devices have revolutionised how data are processed. This fact, coupled with the current trend from cloud to edge computing paradigms, has resulted in the need for efficient and reliable data processing near to data sources using resource-constrained devices. In this article, low-cost edge-IoT architectures are implemented to deploy lightweight Machine Learning (ML) models for air quality estimation, such as Polynomial Regression and Artificial Neural Networks (ANN). ML models are deployed in wireless centralised and distributed parallel architectures with common modules such as sensor fusion for luminosity, temperature, humidity, CO2, and other gases. The centralised architecture uses a Graphic Processing Unit (GPU) and the Message Queuing Telemetry Transport (MQTT) protocol, but low-performance processing devices and the Message Passing Interface (MPI) protocol are used in the distributed one. The training and testing of models are attained with appropriate datasets obtained from multiple peak, step, and transient test cases for each air quality parameter. The results for temperature forecasting, and similar ones for other parameters, supports that the distributed parallel architecture could achieve a slightly better estimation metrics and a better performance in power consumption compared to the centralised architecture despite using low-cost general purpose devices.},
  keywords={},
  doi={10.1109/ISMODE56940.2022.10180952},
  ISSN={},
  month={Dec},}
@ARTICLE{9665288,
  author={Huang, Zhicong and Hong, Cheng and Weng, Chenkai and Lu, Wen-jie and Qu, Hunter},
  journal={IEEE Transactions on Dependable and Secure Computing}, 
  title={More Efficient Secure Matrix Multiplication for Unbalanced Recommender Systems}, 
  year={2023},
  volume={20},
  number={1},
  pages={551-562},
  abstract={With recent advances in homomorphic encryption (HE), it becomes feasible to run non-interactive machine learning (ML) algorithms on encrypted data without decryption. In this work, we propose novel encoding methods to pack matrix in a compact way and more efficient methods to perform matrix multiplication on homomorphically encrypted data, leading to a speed boost of $1.5\times - 20\times$1.5×-20× for slim rectangular matrix multiplication compared with state-of-the-art. Moreover, we integrate our optimized secure matrix arithmetic with the MPI distributed computing framework, achieving scalable parallel secure matrix computation. Equipped with the optimized matrix multiplication, we propose uSCORE, a privacy-preserving cross-domain recommendation system for the unbalanced scenario, where a big data owner provides recommendation as a service to a client who has less data and computation power. Our design delegates most of the computation to the service provider, and has a low communication cost, which previous works failed to achieve. For a client who has 16 million user-item pairs to update, it only needs about 3 minutes (in the LAN setting) to prepare the encrypted data. The server can finish the update process on the encrypted data in less than half an hour, effectively reducing the client's test error from 0.72 to 0.62.},
  keywords={},
  doi={10.1109/TDSC.2021.3139318},
  ISSN={1941-0018},
  month={Jan},}
@ARTICLE{9697343,
  author={Chen, Yufu and Lei, Zhiqi and Rao, Yanghui and Xie, Haoran and Wang, Fu Lee and Yin, Jian and Li, Qing},
  journal={IEEE Transactions on Knowledge and Data Engineering}, 
  title={Parallel Non-Negative Matrix Tri-Factorization for Text Data Co-Clustering}, 
  year={2023},
  volume={35},
  number={5},
  pages={5132-5146},
  abstract={As a novel paradigm for data mining and dimensionality reduction, Non-negative Matrix Tri-Factorization (NMTF) has attracted much attention due to its notable performance and elegant mathematical derivation, and it has been applied to a plethora of real-world applications, such as text data co-clustering. However, the existing NMTF-based methods usually involve intensive matrix multiplications, which exhibits a major limitation of high computational complexity. With the explosion at both the size and the feature dimension of texts, there is a growing need to develop a parallel and scalable NMTF-based algorithm for text data co-clustering. To this end, we first show in this paper how to theoretically derive the original optimization problem of NMTF by introducing the Lagrangian multipliers. Then, we propose to solve the Lagrange dual objective function in parallel through an efficient distributed implementation. Extensive experiments on five benchmark corpora validate the effectiveness, efficiency, and scalability of our distributed parallel update algorithm for an NMTF-based text data co-clustering method.},
  keywords={},
  doi={10.1109/TKDE.2022.3145489},
  ISSN={1558-2191},
  month={May},}
@ARTICLE{9767623,
  author={Asheralieva, Alia and Niyato, Dusit},
  journal={IEEE Transactions on Mobile Computing}, 
  title={Secure and Efficient Coded Multi-Access Edge Computing With Generalized Graph Neural Networks}, 
  year={2023},
  volume={22},
  number={9},
  pages={5504-5524},
  abstract={We formulate a novel framework to improve security and utility of the coded multi-access edge computing (MEC) network for Internet of Things (IoT) applications where multiple edge servers (ESs) jointly process raw IoT data to obtain the final network output. To correctly recover the final output even when some processing outputs produced by malicious or malfunctioning ESs are erroneous, the network utilizes coded distributed computing (CDC) that enhances security by adding computational redundancy to the data processed by ESs. Within the framework, we propose an advanced approach to address limitations of contemporary CDC-based systems related to their inability to guarantee security when the number of malicious ESs is large and reduced network utility due to redundant computations. In this approach, the processing loads are allocated to ESs based on deep learning (DL) algorithms to identify the unknown ESs’ types (faithful or malicious) and minimize the load of malicious ESs, thereby optimizing security and utility. The proposed DL algorithms adopt the message passing neural network (NN) – a generalized graph NN with lower complexity and faster convergence than conventional NNs. We prove that our framework yields the optimal security and utility, and verify its superior performance compared with the state-of-the-art schemes.},
  keywords={},
  doi={10.1109/TMC.2022.3172117},
  ISSN={1558-0660},
  month={Sep.},}
@ARTICLE{9882379,
  author={Li, Guancheng and Cao, Songhui and Zhao, Chuyi and Zhang, Siyuan and Ji, Yuchen and Jing, Haotian and Li, Zecheng and Cheng, Jiajun and Yang, Yiwei and Yin, Shu},
  journal={IEEE Transactions on Parallel and Distributed Systems}, 
  title={Critique of “A Parallel Framework for Constraint-Based Bayesian Network Learning via Markov Blanket Discovery” by SCC Team From ShanghaiTech University}, 
  year={2023},
  volume={34},
  number={6},
  pages={1716-1719},
  abstract={In SC20, (Srivastava et al. 2020) proposed a Parallel Framework for Bayesian Learning, or ramBLe, for short, which is a highly parallel and efficient framework for learning the structure of Bayesian Networks (BNs) from samples, There was a discrepancy in Bibliography in the PDF and the source file. We have followed the source file. ?> particularly large genome-scale networks. As part of our participation in the SC21 Student Cluster Competition, our task was to verify conclusions from the original work (Srivastava et al. 2020). Here we present the outcome of our experiments, which were performed on a four-node cluster from the Oracle Cloud HPC platform. We reproduce the numerical results from (Srivastava et al. 2020), namely the algorithm's performance and scaling behavior using MPI and different Python and Boost libraries on the Oracle cloud.},
  keywords={},
  doi={10.1109/TPDS.2022.3205479},
  ISSN={1558-2183},
  month={June},}
@ARTICLE{9920218,
  author={Hao, Xiaoyu and Fang, Tao and Chen, Junshi and Gu, Jun and Feng, Jiawang and An, Hong and Zhao, Chun},
  journal={IEEE Transactions on Parallel and Distributed Systems}, 
  title={swMPAS-A: Scaling MPAS-A to 39 Million Heterogeneous Cores on the New Generation Sunway Supercomputer}, 
  year={2023},
  volume={34},
  number={1},
  pages={141-153},
  abstract={With the computing power of High-Performance Computing (HPC) systems having stepped into the exascale era, more complex problems can be solved with scientific applications on a large scale. However, due to the significant performance gap between computing nodes and storage subsystems, suboptimal design for the Input/Output (I/O) module will significantly impede the efficiency of scientific applications, especially for the ubiquitous atmosphere applications. Two-phase I/O implemented in N-to-1 mode creates a serious bottleneck that hinders the scalability for the Model for Prediction Across Scales-Atmosphere (MPAS-A) on the new generation Sunway supercomputer. To address the I/O problem, we apply a custom data reorganization method to enable N-to-M I/O mode to exploit the parallel file system's performance and limit the data transfer among MPI ranks to a restricted scope to alleviate communication overhead. Moreover, we have conducted several methods to accelerate the computations, including the redesign for tracer transport, a hybrid buffering scheme, and a three-level parallelization scheme, which allows MPAS-A to use all heterogeneous computing resources efficiently. Experimental results show admirable scalability and efficiency of our I/O method, which achieves speedups of 41× and 58.9× for input and output compared with the raw I/O method on 30,000 MPI ranks. By scaling MPAS-A to 39 million heterogeneous cores, we demonstrate the necessity of a well-constructed I/O module for a real-world atmosphere application. Speed tests show that our optimization methods obtain good results for computations, and MPAS-A achieves a speed of 0.82 Simulated Day per Hour (SDPH) and 0.76 parallel efficiency of strong scaling with 600,000 MPI ranks.},
  keywords={},
  doi={10.1109/TPDS.2022.3215002},
  ISSN={1558-2183},
  month={Jan},}
@ARTICLE{9933641,
  author={Huang, Yu and Wang, Tao and Yin, Zihui and Mercer, Eric and Ogles, Benjamin},
  journal={IEEE Transactions on Parallel and Distributed Systems}, 
  title={Improving the Efficiency of Deadlock Detection in MPI Programs Through Trace Compression}, 
  year={2023},
  volume={34},
  number={1},
  pages={400-415},
  abstract={This article presents a static deadlock analysis for single-path MPI programs. Deadlock is when processes are blocked indefinitely by a circular communication dependency. A single path program is one that does not decode messages for control flow. The analysis records a program execution in the form of a trace and then determines from that trace whether there exists any feasible deadlocking schedules. The primary contribution is the combining of identical consecutive sends or receives into single macro actions. This simplified trace is analyzed for potential deadlock cycles. An abstract machine identifies infeasible cycles, and those not identified by the machine are encoded as satisfiability problems for an SMT solver to resolve. The action combination reduces the complexity of identifying and filtering cycles before needing the costly SMT solver. This article shows the effectiveness of the action combination in experiments on a benchmark suite comparing to traces without action combination and other state-of-the-art deadlock analyses.},
  keywords={},
  doi={10.1109/TPDS.2022.3218346},
  ISSN={1558-2183},
  month={Jan},}
@ARTICLE{9938376,
  author={Li, Yichen and Yu, Wenbin and Guan, Xinping},
  journal={IEEE/CAA Journal of Automatica Sinica}, 
  title={Current-Aided Multiple-AUV Cooperative Localization and Target Tracking in Anchor-Free Environments}, 
  year={2023},
  volume={10},
  number={3},
  pages={792-806},
  abstract={In anchor-free environments, where no devices with known positions are available, the error growth of autonomous underwater vehicle (AUV) localization and target tracking is unbounded due to the lack of references and the accumulated errors in inertial measurements. This paper aims to improve the localization and tracking accuracy by involving current information as extra references. We first integrate current measurements and maps with belief propagation and design a distributed current-aided message-passing scheme that theoretically solves the localization and tracking problems. Based on this scheme, we propose particle-based cooperative localization and target tracking algorithms, named CaCL and CaTT, respectively. In AUV localization, CaCL uses the current measurements to correct the predicted and transmitted position information and alleviates the impact of the accumulated errors in inertial measurements. With target tracking, the current maps are applied in CaTT to modify the position prediction of the target which is calculated through historical estimates. The effectiveness and robustness of the proposed methods are validated through various simulations by comparisons with alternative methods under different trajectories and current conditions.},
  keywords={},
  doi={10.1109/JAS.2022.105989},
  ISSN={2329-9274},
  month={March},}
@ARTICLE{9942818,
  author={Liu, Hangjin and Rush, Cynthia and Baron, Dror},
  journal={IEEE Transactions on Information Theory}, 
  title={Rigorous State Evolution Analysis for Approximate Message Passing With Side Information}, 
  year={2023},
  volume={69},
  number={6},
  pages={3989-4013},
  abstract={A common goal in many research areas is to reconstruct an unknown signal  $\mathbf {x}$  from noisy linear measurements. Approximate message passing (AMP) is a class of low-complexity algorithms that can be used for efficiently solving such high-dimensional regression tasks. Often, it is the case that side information (SI) is available during reconstruction, for example in online learning applications. For this reason, a novel algorithmic framework that incorporates SI into AMP, referred to as approximate message passing with side information (AMP-SI), has been recently introduced. In this work, we provide rigorous performance guarantees for AMP-SI when there are statistical dependencies between the signal and SI pairs and the entries of the measurement matrix are independent and identically distributed (i.i.d.) Gaussian. We also allow for statistical dependencies within the elements of the signal itself, by considering a flexible AMP-SI framework incorporating both separable and non-separable denoisers. The AMP-SI performance is shown to be provably tracked by a scalar iteration referred to as state evolution (SE). Moreover, we provide numerical examples that demonstrate empirically that the SE can predict the AMP-SI mean square error accurately.},
  keywords={},
  doi={10.1109/TIT.2022.3220046},
  ISSN={1557-9654},
  month={June},}
@ARTICLE{9954059,
  author={Gerbelot, Cedric and Abbara, Alia and Krzakala, Florent},
  journal={IEEE Transactions on Information Theory}, 
  title={Asymptotic Errors for Teacher-Student Convex Generalized Linear Models (Or: How to Prove Kabashima’s Replica Formula)}, 
  year={2023},
  volume={69},
  number={3},
  pages={1824-1852},
  abstract={There has been a recent surge of interest in the study of asymptotic reconstruction performance in various cases of generalized linear estimation problems in the teacher-student setting, especially for the case of i.i.d standard normal matrices. Here, we go beyond these matrices, and prove an analytical formula for the reconstruction performance of convex generalized linear models with rotationally-invariant data matrices with arbitrary bounded spectrum, rigorously confirming, under suitable assumptions, a conjecture originally derived using the replica method from statistical physics. The proof is achieved by leveraging on message passing algorithms and the statistical properties of their iterates, allowing to characterize the asymptotic empirical distribution of the estimator. For sufficiently strongly convex problems, we show that the two-layer vector approximate message passing algorithm (2-MLVAMP) converges, where the convergence analysis is done by checking the stability of an equivalent dynamical system, which gives the result for such problems. We then show that, under a concentration assumption, an analytical continuation may be carried out to extend the result to convex (non-strongly) problems. We illustrate our claim with numerical examples on mainstream learning methods such as sparse logistic regression and linear support vector classifiers, showing excellent agreement between moderate size simulation and the asymptotic prediction.},
  keywords={},
  doi={10.1109/TIT.2022.3222913},
  ISSN={1557-9654},
  month={March},}
@ARTICLE{9960831,
  author={Mu, Chenggang and Ding, Tao and Huang, Yuhan and Zhu, Shanying and Siano, Pierluigi and Shahidehpour, Mohammad},
  journal={IEEE Transactions on Smart Grid}, 
  title={Sponge Grid With Numerous Virtual Energy Storage Systems: Concept, Model, and Decentralized Control}, 
  year={2023},
  volume={14},
  number={4},
  pages={2986-2998},
  abstract={High proportion of energy storage systems (ESSs) and flexible loads signify the main features of a modern power system. ESS with its bi-directional flow characteristic can flexibly change power network operations, thus providing a new solution for voltage regulation and control. However, since ESS resources are dispersed throughout the power system, it is necessary to design an effective aggregation scheme to achieve a concise voltage regulation. In this paper, a novel sponge grid is proposed, which is capable of both local and global tasks to offer greater flexibility and initiative in power system operations. On the one hand, it constructs the source and forms virtual energy storage (VES) systems to satisfy local demands. On the other hand, the sponge grid applies the superposition of a large number of VES systems spontaneous effects to present a collective voltage regulation behavior. Then, a message passing-based decentralized algorithm is proposed and designed for the local voltage regulation in the sponge grid. Various constraints including those representing inequality boundary, state of charge, and complex line flows, are expressed analytically and computed fast by the proposed portable projection approach. The proposed sponge grid model is tested on a modified IEEE 33-bus system to verify its effectiveness and superior performance.},
  keywords={},
  doi={10.1109/TSG.2022.3224080},
  ISSN={1949-3061},
  month={July},}
@ARTICLE{10015803,
  author={Zuo, Sheng and Lin, Zhongchao and Doñoro, Daniel García and Zhao, Xunwang and Zhang, Yu},
  journal={IEEE Antennas and Wireless Propagation Letters}, 
  title={A Massively Parallel Preconditioned FEM–BEM Method for Accurate Analysis of Complex Electromagnetic Field Problems}, 
  year={2023},
  volume={22},
  number={5},
  pages={1194-1198},
  abstract={In this letter, a parallel preconditioned finite element method–boundary element method (FEM–BEM) method is presented for the solution of challenging electromagnetic (EM) field problems, especially for calculating the radiation characteristics of electrically large radome antenna systems. A preconditioner that combining the absorbing boundary condition with the improved additive Schwarz method is first proposed for the FEM–BEM system to improve the convergence. Then, an efficient parallel framework based on message passing interface and open multiprocessing is designed to achieve massively distributed parallelization of the method. Numerical results demonstrate the benefits of the proposed preconditioner over traditional additive Schwarz method, as well as the accuracy and parallel scalability of the implemented method. Finally, a complex EM system consisting of a waveguide slot antenna array and a dielectric radome with more than 127 medium wavelengths is simulated to verify the capability and effectiveness of the presented method.},
  keywords={},
  doi={10.1109/LAWP.2023.3236373},
  ISSN={1548-5757},
  month={May},}
@ARTICLE{10038842,
  author={Li, Haoyang and Li, Bin and Zhang, Tingting and Feng, Yuan and Wu, Nan},
  journal={China Communications}, 
  title={Iterative receiver for orthogonal time frequency space with index modulation via structured prior-based hybrid belief and expectation propagation}, 
  year={2023},
  volume={20},
  number={1},
  pages={66-78},
  abstract={Orthogonal Time Frequency Space (OTFS) signaling with index modulation (IM) is a promising transmission scheme characterized by high transmission efficiency for high mobility scenarios. In this paper, we study the receiver for coded OTFS-IM system. First, we construct the corresponding factor graph, on which the structured prior incorporating activation pattern constraint and channel coding is devised. Then we develop a iterative receiver via structured prior-based hybrid belief propagation (BP) and expectation propagation (EP) algorithm, named as Str-BP-EP, for the coded OTFS-IM system. To reduce the computational complexity of discrete distribution introduced by structured prior, Gaussian approximation conducted by EP is adopted. To further reduce the complexity, we derive two variations of the proposed algorithm by using some approximations. Simulation results validate the superior performance of the proposed algorithm.},
  keywords={},
  doi={10.23919/JCC.2023.01.006},
  ISSN={1673-5447},
  month={Jan},}
@ARTICLE{10061674,
  author={Song, Liyuan and Yu, Shuyan and Huang, Qin},
  journal={China Communications}, 
  title={Low-density parity-check codes: Highway to channel capacity}, 
  year={2023},
  volume={20},
  number={2},
  pages={235-256},
  abstract={Low-density parity-check (LDPC) codes are not only capacity-approaching, but also greatly suitable for high-throughput implementation. Thus, they are the most popular codes for high-speed data transmission in the past two decades. Thanks to the low-density property of their parity-check matrices, the optimal maximum a posteriori probability decoding of LDPC codes can be approximated by message-passing decoding with linear complexity and highly parallel nature. Then, it reveals that the approximation has to carry on Tanner graphs without short cycles and small trapping sets. Last, it demonstrates that well-designed LDPC codes with the aid of computer simulation and asymptotic analysis tools are able to approach the channel capacity. Moreover, quasi-cyclic (QC) structure is introduced to significantly facilitate their high-throughput implementation. In fact, compared to the other capacity-approaching codes, QC-LDPC codes can provide better area-efficiency and energy-efficiency. As a result, they are widely applied in numerous communication systems, e.g., Landsat satellites, Chang'e Chinese Lunar mission, 5G mobile communications and so on. What's more, its extension to non-binary Galois fields has been adopted as the channel coding scheme for BeiDou navigation satellite system.},
  keywords={},
  doi={10.23919/JCC.2023.02.016},
  ISSN={1673-5447},
  month={Feb},}
@ARTICLE{10064099,
  author={Balty, Pierre and Chatelain, Philippe and Gillis, Thomas},
  journal={IEEE Transactions on Parallel and Distributed Systems}, 
  title={FLUPS - A Flexible and Performant Massively Parallel Fourier Transform Library}, 
  year={2023},
  volume={34},
  number={7},
  pages={2011-2024},
  abstract={Massively parallel Fourier transforms are widely used in computational sciences, and specifically in computational fluid dynamics which involves unbounded Poisson problems. In practice the latter is usually the most time-consuming operation due to its inescapable all-to-all communication pattern. The original flups library tackles that issue with an implementation of the distributed Fourier transform tailor-made for successive resolutions of unbounded Poisson problems. However the proposed implementation lacks of flexibility as it only supports cell-centered data layout and features a plain communication strategy. This work extends the library along two directions. First, flups’ implementation is generalized to support a node-centered data layout. Second, three distinct approaches are provided to handle the communications: one all-to-all, and two non-blocking implementations relying on manual packing and MPI_Datatype to communicate over the network. The proposed software is validated against analytical solutions for unbounded, semi-unbounded, and periodic domains. The performance of the approaches is then compared against accFFT, another distributed FFT implementation, using a periodic case. Finally the performance metrics of each implementation are analyzed and detailed on various top-tier European facilities up to 49,152 cores. This work brings flups up to a fully production-ready and performant distributed FFT library, featuring all the possible types of FFTs and with flexibility in the data-layout.},
  keywords={},
  doi={10.1109/TPDS.2023.3254302},
  ISSN={1558-2183},
  month={July},}
@ARTICLE{10064025,
  author={Thune, Andreas and Reinemo, Sven-Arne and Skeie, Tor and Cai, Xing},
  journal={IEEE Transactions on Parallel and Distributed Systems}, 
  title={Detailed Modeling of Heterogeneous and Contention-Constrained Point-to-Point MPI Communication}, 
  year={2023},
  volume={34},
  number={5},
  pages={1580-1593},
  abstract={The network topology of modern parallel computing systems is inherently heterogeneous, with a variety of latency and bandwidth values. Moreover, contention for the bandwidth can exist on different levels when many processes communicate with each other. Many-pair, point-to-point MPI communication is thus characterized by heterogeneity and contention, even on a cluster of homogeneous multicore CPU nodes. To get a detailed understanding of the individual communication cost per MPI process, we propose a new modeling methodology that incorporates both heterogeneity and contention. First, we improve the standard max-rate model to better quantify the actually achievable bandwidth depending on the number of MPI processes in competition. Then, we make a further extension that more detailedly models the bandwidth contention when the competing MPI processes have different numbers of neighbors, with also non-uniform message sizes. Thereafter, we include more flexibility by considering interactions between intra-socket and inter-socket messaging. Through a series of experiments done on different processor architectures, we show that the new heterogeneous and contention-constrained performance models can adequately explain the individual communication cost associated with each MPI process. The largest test of realistic point-to-point MPI communication involves 8,192 processes and in total 2,744,632 simultaneous messages over 64 dual-socket AMD Epyc Rome compute nodes connected by InfiniBand, for which the overall prediction accuracy achieved is 84%.},
  keywords={},
  doi={10.1109/TPDS.2023.3253881},
  ISSN={1558-2183},
  month={May},}
@ARTICLE{10068338,
  author={Gu, Yifan and She, Changyang and Quan, Zhi and Qiu, Chen and Xu, Xiaodong},
  journal={IEEE Transactions on Wireless Communications}, 
  title={Graph Neural Networks for Distributed Power Allocation in Wireless Networks: Aggregation Over-the-Air}, 
  year={2023},
  volume={},
  number={},
  pages={1-1},
  abstract={Distributed power allocation is important for interference-limited wireless networks with dense transceiver pairs. In this paper, we aim to design low signaling overhead distributed power allocation schemes by using graph neural networks (GNNs), which are scalable to the number of wireless links. We first apply the message passing neural network (MPNN), a unified framework of GNN, to solve the problem. We show that the signaling overhead grows quadratically as the network size increases. Inspired from the over-the-air computation (AirComp), we then propose an Air-MPNN framework, where the messages from neighboring nodes are represented by the transmit power of pilots and can be aggregated efficiently by evaluating the total interference power. The signaling overhead of Air-MPNN grows linearly as the network size increases, and we prove that Air-MPNN is permutation invariant. To further reduce the signaling overhead, we propose the Air message passing recurrent neural network (Air-MPRNN), where each node utilizes the graph embedding and local state in the previous frame to update the graph embedding in the current frame. Since existing communication systems send a pilot during each frame, Air-MPRNN can be integrated into the existing standards by adjusting pilot power. Simulation results validate the scalability of the proposed frameworks, and show that they outperform the existing power allocation algorithms in terms of sum-rate for various system parameters.},
  keywords={},
  doi={10.1109/TWC.2023.3253126},
  ISSN={1558-2248},
  month={},}
@INPROCEEDINGS{10071015,
  author={Sarkar, Rishov and Abi-Karam, Stefan and He, Yuqi and Sathidevi, Lakshmi and Hao, Cong},
  booktitle={2023 IEEE International Symposium on High-Performance Computer Architecture (HPCA)}, 
  title={FlowGNN: A Dataflow Architecture for Real-Time Workload-Agnostic Graph Neural Network Inference}, 
  year={2023},
  volume={},
  number={},
  pages={1099-1112},
  abstract={Graph neural networks (GNNs) have recently exploded in popularity thanks to their broad applicability to graph-related problems such as quantum chemistry, drug discovery, and high energy physics. However, meeting demand for novel GNN models and fast inference simultaneously is challenging due to the gap between developing efficient accelerators and the rapid creation of new GNN models. Prior art focuses on accelerating specific classes of GNNs, such as Graph Convolutional Networks (GCN), but lacks generality to support a wide range of existing or new GNN models. Furthermore, most works rely on graph pre-processing to exploit data locality, making them unsuitable for real-time applications. To address these limitations, in this work, we propose a generic dataflow architecture for GNN acceleration, named FlowGNN, which is generalizable to the majority of message-passing GNNs. The contributions are three-fold. First, we propose a novel and scalable dataflow architecture, which generally supports a wide range of GNN models with message-passing mechanism. The architecture features a configurable dataflow optimized for simultaneous computation of node embedding, edge embedding, and message passing, which is generally applicable to all models. We also propose a rich library of model-specific components. Second, we deliver ultra-fast real-time GNN inference without any graph pre-processing, making it agnostic to dynamically changing graph structures. Third, we verify our architecture on the Xilinx Alveo U50 FPGA board and measure the on-board end-to-end performance. We achieve a speed-up of up to 24–254× against CPU (6226R) and 1.3–477× against GPU (A6000) (with batch sizes 1 through 1024); we also outperform the SOTA GNN accelerator I-GCN by 1.26× speedup and 1.55× energy efficiency over four datasets. Our implementation code and on-board measurement are publicly available on GitHub.1},
  keywords={},
  doi={10.1109/HPCA56546.2023.10071015},
  ISSN={2378-203X},
  month={Feb},}
@ARTICLE{10083276,
  author={Asheralieva, Alia and Niyato, Dusit and Miyanaga, Yoshikazu},
  journal={IEEE Transactions on Mobile Computing}, 
  title={Efficient Dynamic Distributed Resource Slicing in 6G Multi-Access Edge Computing Networks with Online ADMM and Message Passing Graph Neural Networks}, 
  year={2023},
  volume={},
  number={},
  pages={1-18},
  abstract={We consider the problem of resource slicing in the 6th generation multi-access edge computing (6G-MEC) network. The network includes many non-stationary space-air-ground-sea nodes with dynamic, unstable connections and resources, where any node can be in one of two hidden states: i) reliable – when the node generates/propagates no data errors; ii) unreliable – when the node can generate/propagate random errors. We show that solving this problem is challenging, since it represents a non-deterministic polynomial-time (NP) hard dynamic combinatorial optimization problem depending on the unknown distribution of hidden nodes' states and time-varying parameters (connections and resources of nodes) which can only be observed locally. To tackle these challenges, we develop a new deep learning (DL) model based on the message passing graph neural network (MPNN) to estimate hidden nodes' states in dynamic network environments. We then propose a novel algorithm based on the integration of MPNN-based DL and online alternating direction method of multipliers (ADMM) – extension of the well-known classical “static” ADMM to dynamic settings, where the slicing problem is solved distributedly, in real time, based on local information. We prove that our algorithm converges to a global optimum of our problem with a superior performance even in the highly-dynamic, unreliable scenarios.},
  keywords={},
  doi={10.1109/TMC.2023.3262514},
  ISSN={1558-0660},
  month={},}
@INPROCEEDINGS{10084902,
  author={Simsek, Irfan},
  booktitle={2023 6th Conference on Cloud and Internet of Things (CIoT)}, 
  title={Zero-Knowledge and Identity-Based Authentication, Authorization, Access Control, and Key Exchange for Publish/Subscribe in Internet of Things}, 
  year={2023},
  volume={},
  number={},
  pages={47-54},
  abstract={Clients and brokers have to communicate via secure channels in the broker-based publish/subscribe model which can be regarded as one of the communication models usually used in the Internet of Things (IoT). A secure channel setup needs an authentic key exchange which in turn requires an authentication process. Moreover, it is required to verify that clients publish or subscribe only to authorized topics managed by authorized brokers. Additionally, IoT includes its own security requirements. This paper introduces a novel handshake protocol providing authentication, authorization, and access control with key exchange for the broker-based publish/subscribe model in IoT. In contrast to related work, realizations of these security goals are not disjunct processes and are integrated with each other in our approach combining zero-knowledge and identitybased schemes while meeting the IoT security requirements. Thus, it supports autonomy in IoT and does not require any public data pre-distribution or secret pre-sharing between communicating entities. Moreover, no third party has to hold any entity-specific authentication and authorization data. While being independent of publish/subscribe protocols without requiring additional components and procedures, our handshake protocol is resistant to active man in the middle attacks and does not include costly cryptographic operations. This paper also evaluates the performance of our approach with regard to multiple affecting factors.},
  keywords={},
  doi={10.1109/CIoT57267.2023.10084902},
  ISSN={2159-6972},
  month={March},}
@INPROCEEDINGS{10101321,
  author={Zhang, Fengxi},
  booktitle={2023 2nd International Conference for Innovation in Technology (INOCON)}, 
  title={Ant Colony Algorithm for Distributed Constrained Optimization}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={This paper proposes a distributed constraint solving algorithm based on ant colony optimization. In view of the asymmetry of distributed constraints and the characteristics of the model, this paper mainly studies the problems of two-way solution, privacy, construction graph and transition probability in distributed constraints. The distributed constraint uses depth first pseudo tree as the structure of construction graph. To solve the problem of bidirectional constraint solving in distributed constraints, this paper introduces a tree based reverse detection mechanism, and the message passing is only related to the cumulative cost, which ensures the privacy of the agent. In addition, a local cost estimation mechanism is introduced in the heuristic part of the transition probability, that is, the heuristic information not only considers the real cost caused by the current solution and the high priority neighbor, but also considers the cost estimation value of the current solution and the neighbor, which can better evaluate the local benefits. Finally, this paper verifies that the distributed constraint algorithm outperforms the existing distributed incomplete algorithm.},
  keywords={},
  doi={10.1109/INOCON57975.2023.10101321},
  ISSN={},
  month={March},}
@INPROCEEDINGS{10113442,
  author={Usatyuk, Vasiliy S.},
  booktitle={2023 25th International Conference on Digital Signal Processing and its Applications (DSPA)}, 
  title={Low Error Floor QC-LDPC Codes Construction Using Modified Cole's Trapping Sets Enumerating}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={In order to count the number of trapping sets (TS), we changed Cole's Importance Sampling (IS) approach, which led to a message-passing decoder problem. Several concepts have been combined to suggest improvements to Cole's IS: utilizing short cycles and simultaneous TS impulse tree decomposition, un-wrapping of message passing iterations Tanner Graph/Forney's Normal Graph symmetry's Graph Authomorphism is a complex yet simple concept. Superior Velasquez-Subramani and Karimi-Banihashemi TS enumerating techniques were supported. The proposed technique under PEG (1008, 504) Mackay code for single thread implementation is 43 times quicker than the original Cole's method and 5027 times (71463 times, multi-thread) faster than the Velasquez-Subramani LP method. For the TS enumerating problem at (2640, 1320), Margulis's code is 37958 times quicker than the suggested Velasquez-Subramani LP approach for single thread implementation, 82 times faster than Karimi-Banihashemi, and 134 times faster than Cole's original solution. On the basis of the creation of QC-LDPC codes, we demonstrate the effects of improved EMD spectrum and increased hamming distance on the TS spectrum and BER/FER error-floor level.},
  keywords={},
  doi={10.1109/DSPA57594.2023.10113442},
  ISSN={},
  month={March},}
@ARTICLE{10124987,
  author={Wu, Zhenguo and Dai, Liang Yuan and Novick, Asher and Glick, Madeleine and Zhu, Ziyi and Rumley, Sébastien and Michelogiannakis, George and Shalf, John and Bergman, Keren},
  journal={Journal of Lightwave Technology}, 
  title={Peta-Scale Embedded Photonics Architecture for Distributed Deep Learning Applications}, 
  year={2023},
  volume={41},
  number={12},
  pages={3737-3749},
  abstract={As Deep Learning (DL) models grow larger and more complex, training jobs are increasingly distributed across multiple Computing Units (CU) such as GPUs and TPUs. Each CU processes a sub-part of the model and synchronizes results with others. Communication among these CUs has emerged as a key bottleneck in the training process. In this work, we present SiPAC, a Silicon Photonic Accelerated Compute cluster. SiPAC accelerates distributed DL training by means of two co-designed components: a photonic physical layer and a novel collective algorithm. The physical layer exploits embedded photonics to bring peta-scale I/O directly to the CUs of a DL optimized cluster and uses resonator-based optical wavelength selectivity to realize hardware multi-casting. The collective algorithm builds on the hardware multi-casting primitive. This combination expedites a variety of collective communications commonly employed in DL training and has the potential to drastically ease the communication bottlenecks. We demonstrate the feasibility of realizing the SiPAC architecture through 1) an optical testbed experiment where an array of comb laser wavelengths are shuffled by a cascaded ring switch, with each ring selecting and forwarding multiple wavelengths to increase the effective communication bandwidth and hence demonstrating the hardware multicasting primitive, and 2) a four-GPU testbed running a realistic DL workload that achieves 22% system-level performance improvement relative to a similarly-sized leaf-spine topology. Large scale simulations show that SiPAC achieves a 1.4× to 5.9× communication time reduction compared to state-of-the-art compute clusters for representative collective communications.},
  keywords={},
  doi={10.1109/JLT.2023.3276588},
  ISSN={1558-2213},
  month={June},}
@INPROCEEDINGS{10136969,
  author={Hirasawa, Shoichi and Koibuchi, Michihiro},
  booktitle={2023 31st Euromicro International Conference on Parallel, Distributed and Network-Based Processing (PDP)}, 
  title={An Auto-Tuning Method for High-Bandwidth Low-Latency Approximate Interconnection Networks}, 
  year={2023},
  volume={},
  number={},
  pages={9-16},
  abstract={Ahstract-The next-generation interconnection networks, such as 400 GbE specification, impose Forwarding Error Correction (FEC) operation, such as RS-FEC (544,514), to incoming packets at every switch. The significant FEC latency increases the end-to-end communication latency that degrades the application performance in parallel computers. To resolve the FEC latency problem, a prior work presented error-prone high-bandwidth low-latency networks that do not perform the FEC operation. They enable high-bandwidth approximate data transfer and low-bandwidth perfect data transfer to support various kinds of parallel applications subject to different levels of probability of bit-flip occurrence. As the number of approximate data transfers increases, the parallel applications can obtain a significant speedup of their execution at the expense of the moderate degraded quality of results (QoRs). However, it is difficult for users to identify whether each communication should be approximate or not, so as to obtain the shortest execution time with enough QoRs for a given parallel application. In this study, we apply an auto-tuning framework for approximate interconnection networks; it automatically identifies whether each communication should be approximate data transfer or not, by attempting thousands executions of a given parallel application. An auto-tuning attempts a large number of program executions by varying the possible communication parameters to find out the best execution configuration of the program. The multiple executions would generate different positions of bit flips on communication data that may provide different qualities of results even if the same parameters are taken. Although this uncertainty introduces difficulties in the optimization of the auto-tuning, many offline trials lead to a high probability of the program's success execution. Evaluation results show that high-performance MPI applications with our auto-tuning method result in 1.30 average performance improvement on error-prone high-performance approximate networks.},
  keywords={},
  doi={10.1109/PDP59025.2023.00011},
  ISSN={2377-5750},
  month={March},}
@ARTICLE{10141595,
  author={Hu, Yao},
  journal={IEEE Access}, 
  title={Exploring Approximate Communication Using Lossy Bitwise Compression on Interconnection Networks}, 
  year={2023},
  volume={11},
  number={},
  pages={59238-59249},
  abstract={The use of approximate communication has emerged as a promising approach for enhancing the efficiency of communication in parallel computer systems. By sending incomplete or imprecise messages, approximate communication can significantly reduce communication time. In this study, we examine application-level techniques for approximate communication to enable high portability on high-performance interconnection networks. Specifically, we focus on lossy compression of floating-point data, which is frequently exchanged between compute nodes in parallel applications. Our approach involves a simple application scenario where a source process compresses a communication dataset and a destination process decompresses it in an MPI parallel program. We use two bitwise procedures for compression: lossy bit-zip compression and lossless bit-mask compression. Our aim is to transmit the largest possible amount of approximate data with the least possible compression overhead. Additionally, we explore error check and correction techniques to ensure bit-flip fault tolerance for the compressed data during transmission. We implement our scheme in several communication-intensive MPI applications and demonstrate that our approximate communication approach effectively speeds up total execution time while staying within a specified quality-of-result error bound.},
  keywords={},
  doi={10.1109/ACCESS.2023.3281834},
  ISSN={2169-3536},
  month={},}
@INPROCEEDINGS{10142582,
  author={Guo, Hengliang and Zhang, Long and Zhang, Yi and Li, Jianan},
  booktitle={2023 5th International Conference on Communications, Information System and Computer Engineering (CISCE)}, 
  title={Data transfer management policy optimization for unified memory}, 
  year={2023},
  volume={},
  number={},
  pages={447-453},
  abstract={OpenMP 4.5 refines the offload feature to better support heterogeneous computing. Explicit specification programming is currently required to optimize data transfer in OpenMP offload programs, but manual programming is not efficient or performant. Although DCU-supported unified memory provides a scheme for compilers to implicitly manage data transfers, target offload programs using unified memory perform poorly when program requests exceed the physical memory size. Therefore, this paper proposes a UMAT scheme for automatically optimizing unified memory-based data transfer management, which guides runtime management of data transfers by calculating the access frequency of data objects in the unified memory space. Test results show that the scheme has significant performance improvement for target offload programs using unified memory.},
  keywords={},
  doi={10.1109/CISCE58541.2023.10142582},
  ISSN={2833-2423},
  month={April},}
@ARTICLE{10151880,
  author={Al-Johany, Norah Abdullah and Eassa, Fathy Elbouraey and Sharaf, Sanaa Abdullah and Noaman, Amin Y. and Ahmed, Asaad},
  journal={IEEE Access}, 
  title={Prediction and Correction of Software Defects in Message-Passing Interfaces Using a Static Analysis Tool and Machine Learning}, 
  year={2023},
  volume={11},
  number={},
  pages={60668-60680},
  abstract={The Software Defect Prediction (SDP) method forecasts the occurrence of defects at the beginning of the software development process. Early fault detection will decrease the overall cost of software and improve its dependability. However, no effort has been made in high-performance software to address it. The contribution of this paper is predicting and correcting software defects in the Message Passing Interface (MPI) based on machine learning (ML). This system predicts defects including deadlock, race conditions, and mismatch, by dividing the model into three stages: training, testing, and prediction. The training phase extracts and combines the features as well as the label and then trains on classification. During the testing phase, these features are extracted and classified. The prediction phase inputs the MPI code and determines whether it includes defects. If it discovers a defect, the correction subsystem corrects it. We collected 40 MPI codes in C++, including all MPI communication. Results show the NB classifiers have high accuracy, precision, and recall, which are about 1.},
  keywords={},
  doi={10.1109/ACCESS.2023.3285598},
  ISSN={2169-3536},
  month={},}
@ARTICLE{10155151,
  author={Bernaschi, Massimo and Celestini, Alessandro and Vella, Flavio and D'Ambra, Pasqua},
  journal={IEEE Transactions on Parallel and Distributed Systems}, 
  title={A Multi-GPU Aggregation-Based AMG Preconditioner for Iterative Linear Solvers}, 
  year={2023},
  volume={34},
  number={8},
  pages={2365-2376},
  abstract={We present and release in open source format a sparse linear solver which efficiently exploits heterogeneous parallel computers. The solver can be easily integrated into scientific applications that need to solve large and sparse linear systems on modern parallel computers made of hybrid nodes hosting Nvidia Graphics Processing Unit (GPU) accelerators. The work extends previous efforts of some of the authors in the exploitation of a single GPU accelerator and proposes an implementation, based on the hybrid MPI-CUDA software environment, of a Krylov-type linear solver relying on an efficient Algebraic MultiGrid (AMG) preconditioner already available in the BootCMatchG library. Our design for the hybrid implementation has been driven by the best practices for minimizing data communication overhead when multiple GPUs are employed, yet preserving the efficiency of the GPU kernels. Strong and weak scalability results of the new version of the library on well-known benchmark test cases are discussed. Comparisons with the Nvidia AmgX solution show a speedup, in the solve phase, up to 2.0x.},
  keywords={},
  doi={10.1109/TPDS.2023.3287238},
  ISSN={1558-2183},
  month={Aug},}
@INPROCEEDINGS{10154743,
  author={Yaothanee, Jumpol and Chanchio, Kasidit},
  booktitle={2023 8th International Conference on Cloud Computing and Big Data Analytics (ICCCBDA)}, 
  title={A Pipelined Multi-level Checkpoint Storage System for Virtual Cluster Checkpointing}, 
  year={2023},
  volume={},
  number={},
  pages={239-246},
  abstract={Checkpoint-Restart (CR) is an important mechanism to provide fault tolerance for long-running applications in the cloud. Virtual Cluster (VC) checkpointing is the mechanism to perform CR operations on a cluster of Virtual Machines (VMs). However, saving of state of every VM in a VC directly to a shared storage, such as a SAN storage, simultaneously can cause high checkpoint overheads due to I/O contentions. This paper presents a novel Pipedlined Multi-Level Checkpoint Storage (PMLCS) system that allows users to schedule the saving of VM checkpoints on multiple storage devices to avoid I/O contention. We propose a novel conceptual diagram called the Backup Chain (BC) diagram to describe the scheduled saving and backing up of VM checkpoint files on various storage devices. We have implemented the PMLCS prototype and integrated it with two hypervisor-level VC checkpointing systems. We conducted experiments by checkpointing a VC running an MPI program from NAS parallel benchmark. Experimental results show that the PMLCS system using the BC diagram that represents a combination of SSD and SAN storage is an efficient and scalable checkpoint storage solution.},
  keywords={},
  doi={10.1109/ICCCBDA56900.2023.10154743},
  ISSN={2832-3734},
  month={April},}
@ARTICLE{10168235,
  author={Khalid, Haris M. and Qasaymeh, M. M. and Muyeen, S. M. and Moursi, Mohamed S. El and Foley, Aoife M. and Sweidan, Tha'er O. and Sanjeevikumar, P.},
  journal={IEEE Systems Journal}, 
  title={WAMS Operations in Power Grids: A Track Fusion-Based Mixture Density Estimation-Driven Grid Resilient Approach Toward Cyberattacks}, 
  year={2023},
  volume={17},
  number={3},
  pages={3950-3961},
  abstract={Synchrophasor-based wide-area monitoring system (WAMS) applications are vital for acquiring the real-time grid information under ambient and nonlinear conditions. The high dependence on sensor data and signal-processing software for daily grid operation is becoming a concern in an era prone to cyberattacks. To resolve this issue, a mixture density-based maximum likelihood (MDML) estimation was proposed to detect attack vectors. The algorithm was deployed at each monitoring node using a track-level fusion (TLF)-based architecture. A parallelized message passing interface (MPI)-based computing was processed to reduce its computational burden. This work adopted a mature application known as oscillation detection as an example of a monitoring candidate to demonstrate the proposed method. Two test cases were generated to examine the resilience and scalability of the proposed scheme. The tests were conducted in severe data-injection attacks and multiple system disturbances. Results show that the proposed TLF-based MDML estimation method can accurately extract the oscillatory parameters from the contaminated measurements.},
  keywords={},
  doi={10.1109/JSYST.2023.3285492},
  ISSN={1937-9234},
  month={Sep.},}
@INPROCEEDINGS{10171511,
  author={Chen, Chen-Chun and Khorassani, Kawthar Shafie and Kuncham, Goutham Kalikrishna Reddy and Vaidya, Rahul and Abduljabbar, Mustafa and Shafi, Aamir and Subramoni, Hari and Panda, Dhabaleswar K.},
  booktitle={2023 IEEE/ACM 23rd International Symposium on Cluster, Cloud and Internet Computing (CCGrid)}, 
  title={Implementing and Optimizing a GPU-aware MPI Library for Intel GPUs: Early Experiences}, 
  year={2023},
  volume={},
  number={},
  pages={131-140},
  abstract={As the demand for computing power from High-Performance Computing (HPC) and Deep Learning (DL) applications increase, there is a growing trend of equipping modern exascale clusters with accelerators, such as NVIDIA and AMD GPUs. GPU-aware MPI libraries allow the applications to communicate between GPUs in a parallel environment with high productivity and performance. Although NVIDIA and AMD GPUs have dominated the accelerator market for top supercomputers over the past several years, Intel has recently developed and released its GPUs and associated software stack, and provided a unified programming model to program their GPUs, referred to as oneAPI. The emergence of Intel GPUs drives the need for initial MPI-level GPU-aware support that utilizes the underlying software stack specific to these GPUs and a thorough evaluation of communication. In this paper, we propose a GPU-aware MPI library for Intel GPUs using oneAPI and an SYCL backend. We delve into our experiments using Intel GPUs and the challenges to consider at the MPI layer when adding GPU-aware support using the software stack provided by Intel for their GPUs. We explore different memory allocation approaches and benchmark the memory copy performance with Intel GPUs. We propose implementations based on our experiments on Intel GPUs to support point-to-point GPU-aware MPI operations and show the high adaptability of our approach by extending the implementations to MPI collective operations, such as MPI_Bcast and MPI_Reduce. We evaluate the benefits of our implementations at the benchmark level by extending support for Intel GPU buffers over OSU Micro-Benchmarks. Our implementations provide up to 1.8x and 2.2x speedups on point-to-point latency using device buffers at small messages compared to Intel MPI and a naive benchmark, respectively; and have up to 1.3x and 1.5x speedups at large message sizes. At collective MPI operations, our implementations show 8x and 5x speedups for MPI_Allreduce and MPI_Allgather at large messages. At the application-level evaluation, our implementations provide up to 40% improvement for 3DStencil compared to Intel MPI.},
  keywords={},
  doi={10.1109/CCGrid57682.2023.00022},
  ISSN={},
  month={May},}
@INPROCEEDINGS{10171546,
  author={Beni, Majid Salimi and Crisci, Luigi and Cosenza, Biagio},
  booktitle={2023 IEEE/ACM 23rd International Symposium on Cluster, Cloud and Internet Computing (CCGrid)}, 
  title={EMPI: Enhanced Message Passing Interface in Modern C++}, 
  year={2023},
  volume={},
  number={},
  pages={141-153},
  abstract={Message Passing Interface (MPI) is a well-known standard for programming distributed and HPC systems. While the community has been continuously improving MPI to address the requirements of next-generation architectures and applications, its interface has not substantially evolved. In fact, MPI only provides an interface to C and Fortran and does not support recent features of modern C++. Moreover, MPI programs are error-prone and subject to different syntactic and semantic errors. This paper introduces EMPI, an Enhanced Message Passing Interface based on modern C++, which is directly mapped to the OpenMPI implementation and exploits modern C++ for safe and efficient distributed programming. EMPI proposes novel C++RAII-based semantics and constant specialization to prevent error-prone code patterns such as parameter mismatch, and reduce the overhead of handling multiple objects and perinvocation time. Consequently, EMPI programs are safer: six out of nine well-known MPI error patterns do not occur while correctly using EMPI semantics. Experimental results on five microbenchmarks and two applications on a large-scale cluster using up to 1024 processes show that EMPI's performance is very similar to native MPI and considerably faster than the MPL C++ interface.},
  keywords={},
  doi={10.1109/CCGrid57682.2023.00023},
  ISSN={},
  month={May},}
@ARTICLE{10183372,
  author={Wang, Yanhong and Guan, Tianchan and Niu, Dimin and Zou, Qiaosha and Zheng, Hongzhong and Shi, C.-J. Richard and Xie, Yuan},
  journal={IEEE Transactions on Parallel and Distributed Systems}, 
  title={Accelerating Distributed GNN Training by Codes}, 
  year={2023},
  volume={34},
  number={9},
  pages={2598-2614},
  abstract={Emerging graph neural network (GNN) has recently attracted much attention and has been used extensively in many real-world applications thanks to its powerful expression ability of unstructured data. The real-world graph datasets are very large-scale, which can contain up to billions of nodes and tens of billions of edges. It usually requires distributed system to train GNN on such huge datasets. As a result, the data communication overheads between machines become the bottleneck of GNN computation. Our profiling results show that getting attributes from remote machines during sampling phase in GNN occupies $> $>75% of the time of the training process. To address this issue, in this article, we propose Coded Neighbor Sampling (CNS) framework, which introduces codes technique to reduce the communication overheads of GNN. In the proposed CNS framework, the codes technique is coupled with GNN sampling method to exploit the data excess among different machines caused by unstructured nature of graph data. An analytical performance model is built for the proposed CNS framework, whose results are corroborated by the simulation and validate the benefit of the proposed CNS framework over both conventional GNN training method and conventional codes technique. Performance metrics, such as communication overheads, runtime, and throughput, of the proposed CNS framework are evaluated on a distributed GNN training simulation system implemented on MPI4py platform. The results show that, on average, the proposed CNS framework can save communication overhead by 40.6%, 35.5%, and 16.5%, reduce the runtime by 12.1%, 17.0%, and 10.0%, and improve the throughput by 16.2%, 24.4%, and 11.2%, respectively, when training GNN models with Cora, PubMed, and Large Taobao.},
  keywords={},
  doi={10.1109/TPDS.2023.3295184},
  ISSN={1558-2183},
  month={Sep.},}
@INPROCEEDINGS{10177415,
  author={Peterka, Tom and Morozov, Dmitriy and Nigmetov, Arnur and Yildiz, Orcun and Nicolae, Bogdan and Davis, Philip E.},
  booktitle={2023 IEEE International Parallel and Distributed Processing Symposium (IPDPS)}, 
  title={LowFive: In Situ Data Transport for High-Performance Workflows}, 
  year={2023},
  volume={},
  number={},
  pages={985-995},
  abstract={We describe LowFive, a new data transport layer based on the HDF5 data model, for in situ workflows. Executables using LowFive can communicate in situ (using in-memory data and MPI message passing), reading and writing traditional HDF5 files to physical storage, and combining the two modes. Minimal and often no source-code modification is needed for programs that already use HDF5. LowFive maintains deep copies or shallow references of datasets, configurable by the user. More than one task can produce (write) data, and more than one task can consume (read) data, accommodating fan-in and fan-out in the workflow task graph. LowFive supports data redistribution from n producer processes to m consumer processes. We demonstrate the above features in a series of experiments featuring both synthetic benchmarks as well as a representative use case from a scientific workflow, and we also compare with other data transport solutions in the literature.},
  keywords={},
  doi={10.1109/IPDPS54959.2023.00102},
  ISSN={1530-2075},
  month={May},}
@ARTICLE{10190568,
  author={Danielsson, Luis Miguel and Sánchez, César},
  journal={IEEE Access}, 
  title={Decentralized Stream Runtime Verification for Timed Asynchronous Networks}, 
  year={2023},
  volume={11},
  number={},
  pages={84091-84112},
  abstract={Problem: We study the problem of monitoring distributed systems such as smart buildings, ambient living, wide area networks and other distributed systems that get monitored periodically in human scale times. In these systems computers communicate using message passing and share an almost synchronized clock. This is a realistic scenario for networks where the speed of the monitoring is sufficiently slow (like seconds or tens of seconds) to permit efficient clock synchronization, where clock deviations are small compared to the time precision and frequency required by the monitoring. Solution: More concretely, we propose a solution to monitor decentralized systems where monitors are expressed as stream runtime verification specifications. We solve the problem for “timed asynchronous networks”, where computational nodes where the monitors run have a synchronized clock with a small bounded maximum drift. These nodes communicate using a network, where messages can take arbitrarily long but cannot be duplicated or lost. This setting is common in many cyber-physical systems like smart buildings and ambient living. This assumption generalizes the synchronous monitoring case. Previous approaches to decentralized monitoring were limited to synchronous networks, which are not easily implemented in practice because of network failures. Even when network failures are unusual, they can require several monitoring cycles to be repaired. Methodology: We describe formally the monitoring problem for timed-asynchronous networks, we describe a decentralized algorithm and provide proofs of its correctness. Afterwards, we formally analyze the complexity of our solutions and provide two analysis techniques to approximate the memory requirements. Finally, we implement the algorithm and perform an empirical evaluation with real data extracted from four different datasets. Contributions: We propose a solution to the timed asynchronous decentralized monitoring problem. We study the specifications and conditions on the network behavior that allow the monitoring to take place with bounded resources, independently of the trace length. Finally, we report the results of an empirical evaluation of an implementation and verify the theoretical results in terms of effectiveness and efficiency.},
  keywords={},
  doi={10.1109/ACCESS.2023.3298329},
  ISSN={2169-3536},
  month={},}
@ARTICLE{10198710,
  author={Li, Yichen and Yu, Wenbin and Guan, Xinping},
  journal={IEEE/CAA Journal of Automatica Sinica}, 
  title={3D localization for multiple AUVs in anchor-free environments by exploring the use of depth information}, 
  year={2023},
  volume={},
  number={},
  pages={1-3},
  abstract={Dear Editor, This letter investigates the cooperative localization problem for multiple autonomous underwater vehicles (AUVs) in underwater anchor-free environments, where AUV localization errors grow without bound due to the accumulated errors in inertial measurements (termed accumulated errors hereafter) and the lack of anchors (with known positions). Different from previous works, this letter is based on a message-passing distributed framework and the designed algorithm improves the localization accuracy mainly by the cooperation among AUVs and the use of depth information to mitigate the influence of the accumulated errors and harsh environments. Through simulations, the advantages of the proposed algorithm are verified by comparisons with different state-of-the-art alternative methods.},
  keywords={},
  doi={10.1109/JAS.2023.123261},
  ISSN={2329-9274},
  month={},}
@INPROCEEDINGS{10196592,
  author={Bienz, Amanda},
  booktitle={2023 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)}, 
  title={Invited Paper: Benchmarking and Optimizing Data Movement on Emerging Heterogeneous Architectures}, 
  year={2023},
  volume={},
  number={},
  pages={611-614},
  abstract={As supercomputers evolve, nodes are continually increasing in complexity. As a result, each generation of parallel systems brings new performance challenges. For instance, on recent systems inter-node communication has outperformed inter-socket, resulting in poor performance of many node-aware communication optimizations. Communication optimizations are critical for the performance and scalability of parallel applications, but are dependent on the parallel architecture, which varies significantly among recent generations of supercomputers. This paper investigates the performance of various paths of data movement on recent generations of systems, and analyzes the increased complexity of communication, particularly on recent heterogeneous systems. The paper also introduces MPI Advance, a communication library that enables optimizations to be created based on benchmark analysis of each emerging system.},
  keywords={},
  doi={10.1109/IPDPSW59300.2023.00104},
  ISSN={},
  month={May},}
@INPROCEEDINGS{10196613,
  author={Bhattacharjee, Arijit and Daley, Christopher S. and Jannesari, Ali},
  booktitle={2023 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)}, 
  title={OpenMP Offload Features and Strategies for High Performance across Architectures and Compilers}, 
  year={2023},
  volume={},
  number={},
  pages={564-573},
  abstract={High performance accelerated computing has dawned in a new era of highly specialized code that depends on the target architecture. All the latest pre-exascale and exascale class supercomputers are accelerated systems. Efficient exploitation of the target architecture requires programming approaches that can take advantage of the characteristics of the hardware. OpenMP 4 introduced directives designed with the parallel architecture of GPUs in mind, but these directives are often different from those required for highest performance on CPUs. We demonstrate that by using newer OpenMP 5.0 offload features such as the loop directive and metadirective as well as profile guided strategies, we can achieve performance benefits with productivity gains. In this paper we experiment with HPGMG, a benchmark in the SPEChpc 2021 suite, to evaluate these newer directives versus OpenMP 4.5 directives, comparing performance, productivity and portability across architectural targets and production compilers on NERSC-9 Perlmutter. Our implementation gives up to a $2.74\times$ speedup compared to the baseline performance on GPUs and a $4.4\times$ speedup while running in host fallback mode. In addition, our implementation requires 66% fewer lines of code in the key kernels.},
  keywords={},
  doi={10.1109/IPDPSW59300.2023.00098},
  ISSN={},
  month={May},}
@INPROCEEDINGS{10196513,
  author={Wilkins, Michael and Weil, Garrett and Arnold, Luke and Hardavellas, Nikos and Dinda, Peter},
  booktitle={2023 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)}, 
  title={Evaluating Functional Memory-Managed Parallel Languages for HPC using the NAS Parallel Benchmarks}, 
  year={2023},
  volume={},
  number={},
  pages={413-422},
  abstract={Functiona1, memory-managed parallel languages (FMPLs) are a recent innovative approach to shared-memory parallel programming. Despite their rising prevalence in other areas, FMPLs have yet to gain traction in HPC. In this work, we explore the utility of FMPLs for HPC by re-implementing the NAS Parallel Benchmarks in an FMPL.For this study, we ported the benchmarks into the Parallel ML language. We discuss the advantages and disadvantages of using Parallel ML for HPC applications based on our development experience. We compare the performance of our Parallel ML implementation to the existing C/OpenMP version. The FMPL implementations are $1.02 \times -5.76 \times$ slower compared to OpenMP. Our positive development experience combined with some competitive performance results suggest that FMPLs have the potential to become a viable choice for HPC applications. We conclude by describing our future work to automatically manage distributed memory within an FMPL, creating a compelling new programming model for HPC.},
  keywords={},
  doi={10.1109/IPDPSW59300.2023.00072},
  ISSN={},
  month={May},}
@INPROCEEDINGS{10208025,
  author={Apostolakis, Georgios and Bletsas, Aggelos},
  booktitle={2023 IEEE Statistical Signal Processing Workshop (SSP)}, 
  title={Arithmetic Mean May Offer Fixed Points When Expected Mean Fails in Probabilistic Asynchronous Affine Inference}, 
  year={2023},
  volume={},
  number={},
  pages={245-249},
  abstract={Distributed computing over multiple terminals is recently regaining increased popularity. This work studies the probabilistic asynchronous affine model, which can be applied in a vast range of message passing (inference) algorithms; moreover, the probability of a terminal failing to exchange messages can be also modeled. This work complements recent prior art by analyzing the state vector’s arithmetic mean instead of the expected mean, since there are cases where valid fixed points can be retrieved from the arithmetic mean (exploiting a finite number of experiments), even if the expected mean diverges. This work highlights this fact and offers a sufficient criterion for arithmetic mean convergence to a fixed point, for the first time in the literature; the criterion also covers cases where the individual experiments do not converge but their arithmetic mean does. Simulation results verify the theoretical findings.},
  keywords={},
  doi={10.1109/SSP53291.2023.10208025},
  ISSN={2693-3551},
  month={July},}
@INPROCEEDINGS{10210800,
  author={Li, Ruoxiang and Dong, Zheng and Wu, Jen-Ming and Xue, Chun Jason and Guan, Nan},
  booktitle={2023 IEEE International Conference on Mobility, Operations, Services and Technologies (MOST)}, 
  title={Modeling and Property Analysis of the Message Synchronization Policy in ROS}, 
  year={2023},
  volume={},
  number={},
  pages={71-82},
  abstract={Sensor fusion plays a significant role in autonomous driving (AD) systems. In reality, the sensor data sent to the fusion algorithm may have substantially different sampling times, especially when different sensors are deployed in a distributed way (e.g., in V2X systems). Without proper management, this could lead to poor sensor fusion quality. ROS is the most popular robotic software framework, which provides a sophisticated message synchronization component to manage the temporal inconsistency in sensor fusion. However, although widely used, there is little information about how the ROS synchronization policy works exactly, and people have to use it as a blackbox. In this paper, we formally model the message synchronization policy in ROS and analyze its important properties, including the uniqueness property, disjunction property, continuity property, optimum property, and delay-dependent property, which were discussed on the ROS website but without formal proofs. Our analysis reveals that some of these properties indeed hold but some only hold under certain conditions. We conducted experiments to validate our formal model’s correctness and evaluate the synchronization policy’s performance in terms of time disparity.},
  keywords={},
  doi={10.1109/MOST57249.2023.00016},
  ISSN={},
  month={May},}
@INPROCEEDINGS{10211558,
  author={An, Xia and Zhang, Chao and Peng, Kewu and He, Zhitong and Song, Jian},
  booktitle={2023 IEEE International Symposium on Broadband Multimedia Systems and Broadcasting (BMSB)}, 
  title={Adaptive Quantized and Normalized MSA and Its Application for DTMB-A LDPC Codes}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={In practical implementation, the input and intermediate signals of Low-Density Parity-Check (LDPC) message passing decoders are quantized into fixed-point messages with finite bit-width. The quantization operation with limited bit-width enhances the data throughput and reduces the computation and storage overhead of LDPC decoder, but confronts the problem of performance degradation. Existing improved algorithms of min-sum algorithm (MSA) generally do not consider the effect of quantization, and thus lack the optimization of the quantization strategy. To fill this gap, we first propose adaptive asymmetric quantization strategy. Then, based on the proposed quantization strategy, combined with conventional adaptive normalization technique, we propose adaptive quantized and normalized MSA (AQNMSA), which significantly alleviates the performance degradation of fixed quantized and normalized MSA (NMSA) with negligible increment of computational complexity. Concurrently, we provide a novel look-up table design algorithm for AQNMSA based on the tool of multi-edge-type density evolution (MET-DE). Finally, we apply AQNMSA to DTMB-A LDPC codes with a very low quantization bit-width of 4 bits, and observe a superior threshold performance and lower error floor compared with its non-adaptive float-point counterparts.},
  keywords={},
  doi={10.1109/BMSB58369.2023.10211558},
  ISSN={2155-5052},
  month={June},}
@INPROCEEDINGS{10206816,
  author={Liu, Lei and Chi, Yuhao and Li, Ying and Zhang, Zhaoyang},
  booktitle={2023 IEEE International Symposium on Information Theory (ISIT)}, 
  title={Generalized Linear Systems with OAMP/VAMP Receiver: Achievable Rate and Coding Principle}, 
  year={2023},
  volume={},
  number={},
  pages={519-524},
  abstract={The generalized linear system (GLS) has been widely used in wireless communications to evaluate the effect of nonlinear preprocessing on receiver performance. Generalized approximation message passing (AMP) is a state-of-the-art algorithm for the signal recovery of GLS, but it was limited to measurement matrices with independent and identically distributed (IID) elements. To relax this restriction, generalized orthogonal/vector AMP (GOAMP/GVAMP) for unitarily-invariant measurement matrices was established, which has been proven to be replica Bayes optimal in uncoded GLS. However, the information-theoretic limit of GOAMP/GVAMP is still an open challenge for arbitrary input distributions due to its complex state evolution (SE). To address this issue, in this paper, we provide the achievable rate analysis of GOAMP/GVAMP in GLS, establishing its information-theoretic limit (i.e., maximum achievable rate). Specifically, we transform the fully-unfolded state evolution (SE) of GOAMP/GVAMP into an equivalent single-input single-output variational SE (VSE). Using the VSE and the mutual information and minimum mean-square error (I-MMSE) lemma, the achievable rate of GOAMP/GVAMP is derived. Moreover, the optimal coding principle for maximizing the achievable rate is proposed, based on which a kind of low-density parity-check (LDPC) code is designed. Numerical results verify the achievable rate advantages of GOAMP/GVAMP over the conventional maximum ratio combining (MRC) receiver based on the linearized model and the BER performance gains of the optimized LDPC codes (0.8 ~ 2.8 dB) compared to the existing methods.},
  keywords={},
  doi={10.1109/ISIT54713.2023.10206816},
  ISSN={2157-8117},
  month={June},}
@INPROCEEDINGS{10204349,
  author={Nagata, Jun and Sekikawa, Yusuke},
  booktitle={2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Tangentially Elongated Gaussian Belief Propagation for Event-Based Incremental Optical Flow Estimation}, 
  year={2023},
  volume={},
  number={},
  pages={21940-21949},
  abstract={Optical flow estimation is a fundamental functionality in computer vision. An event-based camera, which asynchronously detects sparse intensity changes, is an ideal device for realizing low-latency estimation of the optical flow owing to its low-latency sensing mechanism. An existing method using local plane fitting of events could utilize the sparsity to realize incremental updates for low-latency estimation; however, its output is merely a normal component of the full optical flow. An alternative approach using a frame-based deep neural network could estimate the full flow; however, its intensive non-incremental dense operation prohibits the low-latency estimation. We propose tangentially elongated Gaussian (TEG) belief propagation (BP) that realizes incremental full-flow estimation. We model the probability of full flow as the joint distribution of TEGs from the normal flow measurements, such that the marginal of this distribution with correct prior equals the full flow. We formulate the marginalization using a message-passing based on the BP to realize efficient incremental updates using sparse measurements. In addition to the theoretical justification, we evaluate the effectiveness of the TEGBP in real-world datasets; it outperforms SOTA incremental quasi-full flow method by a large margin. (The code is available at https://github.com/DensoITLab/tegbp/).},
  keywords={},
  doi={10.1109/CVPR52729.2023.02101},
  ISSN={2575-7075},
  month={June},}
@INPROCEEDINGS{10228968,
  author={Tang, Jian and Wang, Xiaoliang and Dai, Huichen},
  booktitle={IEEE INFOCOM 2023 - IEEE Conference on Computer Communications}, 
  title={Scalable RDMA Transport with Efficient Connection Sharing}, 
  year={2023},
  volume={},
  number={},
  pages={1-10},
  abstract={RDMA provides extremely low-latency and high- throughput data transmission as its protocol stack is entirely offloaded into the RDMA NIC. However, the increasing scale of RDMA networks requires hosts to establish a large number of connections, e.g., process-level full mesh, which easily overwhelms the limited resource on RNICs and hence significantly degrades performance. This paper presents SRM, a scalable transport mode for RDMA that remarkably alleviates resource exhaustion on RNICs. SRM proposes a kernel-based solution to multiplex workloads from different applications over the same connection. Meanwhile, to preserve RDMA’s performance benefits, SRM 1) avoids syscall overhead by sharing the working memory between user-space and kernel; 2) maintains high resource utilization through lock-free approach to avoid contention; 3) adopts multiple optimizations to mitigate the head-of-line blocking issue; 4) implements a rapid recovery mechanism to provide high system robustness. We evaluate SRM using extensive experiments and simulations. Testbed experiments reveal that SRM outperforms existing transports, including DCT, RC, and XRC, by 4x to 20x in latency for all-to-all communication pattern. Simulations of large-scale networks show that, compared with DCT, RC, and XRC, SRM achieves up to 4.42x/4.0x/3.7x speedups respectively in flow completion time while consuming the least memory.},
  keywords={},
  doi={10.1109/INFOCOM53939.2023.10228968},
  ISSN={2641-9874},
  month={May},}
@INPROCEEDINGS{10229604,
  author={Nava, Judah and Lee, Hanku},
  booktitle={2023 6th International Conference on Information and Computer Technologies (ICICT)}, 
  title={mpiPython: Prospects for Node Performance}, 
  year={2023},
  volume={},
  number={},
  pages={182-187},
  abstract={Python as an interpreted language is limited in performance by its ability to optimize code. With it being a high-level programming language, it’s still a strong choice for data scientists to learn and use. If Python could be optimized for parallel programming, its full potential in parallel and cloud computing environments could be achieved. mpiPython is a message-passing module that gives Python the ability to be used in SPMD (Single Program Multiple Data) environments. In this paper, we review basic features of mpiPython, including its runtime communication libraries and design strategies. mpiPython also has new features to help mpiPython programmers, that includes simplifying traditional MPI initialization. During the development of mpiPython, we realized that individual node performance of mpiPython is uncertain and critical. mpiPython node performance will be analyzed within the benchmarks.},
  keywords={},
  doi={10.1109/ICICT58900.2023.00038},
  ISSN={2769-4542},
  month={March},}
@INPROCEEDINGS{10248229,
  author={Zou, Guobing and Lin, Shiyi and Hu, Shengxiang and Gan, Yanglan and Zhang, Bofeng and Chen, Yixin},
  booktitle={2023 IEEE International Conference on Web Services (ICWS)}, 
  title={MVGCL: Multi-View Graph Contrastive Learning for Service Recommendation}, 
  year={2023},
  volume={},
  number={},
  pages={677-686},
  abstract={In service recommender system, graph neural networks (GNNs) perform message passing through diffusion mechanism based on user-service relationship graph. However, existing GNN-based service recommendation models suffer from two limitations: ❨1❩ message passing is only carried out at firstorder neighbors, as higher-order may cause over-smoothing phenomenon, confining feature propagation in GNNs; and ❨2❩ due to sparse and noisy interactions, the distribution of embedding vectors is nonuniform in the latent space, resulting in unsatisfactory performance for downstream applications. To this end, we propose a fixed global graph diffusion view that is independent of the original user-service observed local view to form a multi-view learning by building contrastive learning (CL) relationship, named as Multi-View Graph Contrastive Learning (MVGCL). Specifically, it enhances the capability of message passing through constructed local and global multi-view graphs, and alleviates the sparse and noisy influences by performing intra-CL within local/global view and inter-CL between multi-view to obtain a more uniform distribution of user and service node representations. Extensive experiments are conducted on three benchmark datasets within different scales, and the results demonstrate that our proposed MVGCL can remarkably outperforms state-of-the-art competing baselines on various evaluation metrics.},
  keywords={},
  doi={10.1109/ICWS60048.2023.00086},
  ISSN={2836-3868},
  month={July},}
@INPROCEEDINGS{10253607,
  author={Thilakarathna, Dinindu and Dissanayake, Heshan and Perera, Buddhi and Ragel, Roshan and Dasanayake, Isuru and Wickramasinghe, Mahanama and Nawinne, Isuru},
  booktitle={2023 IEEE 17th International Conference on Industrial and Information Systems (ICIIS)}, 
  title={RV32IMF Five-Stage Pipeline Implementation with Interrupt and Random Number Generation Units}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={In this paper, a five-stage pipeline implementation of the RV32IMF instruction set is presented for distributed event-driven random calculations. The system consists of a network interface and an interrupt controller to handle the data communication within the Network-on-Chip, which connects multiple core processing units. The Network on Chip (NoC) architecture enhances the scalability of the system in terms of core count, which is hard to achieve with a bus-based architecture. Further, interrupts offer the advantage of facilitating time-critical message passing among cores. The proposed architecture was implemented and tested with Altera DE2 and DE5 FPGA boards.},
  keywords={},
  doi={10.1109/ICIIS58898.2023.10253607},
  ISSN={2164-7011},
  month={Aug},}
@INPROCEEDINGS{10256790,
  author={Li, Qing and Gan, Runze and Godsill, Simon},
  booktitle={2023 Sensor Signal Processing for Defence Conference (SSPD)}, 
  title={Consensus-based Distributed Variational Multi-object Tracker in Multi-Sensor Network}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={The growing need for accurate and reliable tracking systems has driven significant progress in sensor fusion and object tracking techniques. In this paper, we design two variational Bayesian trackers that effectively track multiple targets in cluttered environments within a sensor network. We first present a centralised sensor fusion scheme, which involves transmitting sensor data to a fusion center. Then, we develop a distributed version leveraging the average consensus algorithm, which is theoretically equivalent to the centralised sensor fusion tracker and requires only local message passing with neighbouring sensors. In addition, we empirically verify that our proposed distributed variational tracker performs on par with the centralised version with equal tracking accuracy. Simulation results show that our distributed multi-target tracker outperforms the suboptimal distributed sensor fusion strategy that fuses each sensor’s posterior based on arithmetic sensor fusion and an average consensus strategy.},
  keywords={},
  doi={10.1109/SSPD57945.2023.10256790},
  ISSN={},
  month={Sep.},}
@INPROCEEDINGS{10253416,
  author={Joseph, Francis C and Gurrala, Gurunath},
  booktitle={2023 IEEE Power & Energy Society General Meeting (PESGM)}, 
  title={Multi Area Thevenin Equivalent based Transient Stability Simulations in Shared Memory Paradigm}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={Space parallelization of transient stability simulation involves breaking the network into subnetworks and solving each part independently while making sure of the convergence of the original network. Multi Area Thevenin Equivalent (MATE) converts the network solution into two parallel sections with a sequential step in between. While the original method was devised in master-slave paradigm and implemented via Message Passing Interface (MPI), this paper provides a distributed algorithm in a shared memory paradigm. The proposed modifications removes the dependency of number of processors and partitions. In addition, task level parallelization of the algorithm is also proposed to further improve computational speed without dividing the processors. The proposed methods are tested for speedup on large systems, where full order generator models with saturation effects and composite load models are used. It is shown that the ideal speedup can be closely matched by space parallelism and exceeded by space + task parallelism, while the network is well-partitioned.},
  keywords={},
  doi={10.1109/PESGM52003.2023.10253416},
  ISSN={1944-9933},
  month={July},}

@ARTICLE{10265128,
  author={Wang, Hao and Wang, Zhiyu and Niu, Yunlong and Liu, Zhaoran and Li, Haozhe and Liao, Yilin and Huang, Yuxin and Liu, Xinggao},
  journal={IEEE Transactions on Artificial Intelligence}, 
  title={An Accurate and Interpretable Framework for Trustworthy Process Monitoring}, 
  year={2023},
  volume={},
  number={},
  pages={1-12},
  abstract={Trustworthy process monitoring seeks to build an accurate and interpretable monitoring framework, which is critical for ensuring the safety of energy conversion plant (ECP) that operates under extreme working conditions such as high pressure and temperature. Contemporary self-attentive models, however, fall short in this domain for two main reasons. First, they rely on step- wise correlations that fail to involve physically meaningful semantics in ECP logs, resulting in suboptimal accuracy and interpretability. Second, attention matrices are frequently cluttered with spurious correlations that obscure physically meaningful ones, further impeding effective interpretation. To overcome these issues, we propose AttentionMixer, a framework aimed at improving both accuracy and interpretability of existing methods and establish a trustworthy ECP monitoring framework. Specifically, to tackle the first issue, we employ a spatial adaptive message passing block to capture variate- wise correlations. This block is coupled with a temporal adaptive message passing block through an mixing operator, yielding a multi-faceted representation of ECP logs accounting for both step- wise and variate- wise correlations. Concurrently, to tackle the second issue, we employ a sparse message passing regularizer to filter out spurious correlations. We validate the efficacy of AttentionMixer using two real-world datasets from the radiation monitoring network for Chinese nuclear power plants.},
  keywords={},
  doi={10.1109/TAI.2023.3319606},
  ISSN={2691-4581},
  month={},}
@INPROCEEDINGS{10260650,
  author={Qiu, Yiding and Christensen, Henrik I.},
  booktitle={2023 IEEE 19th International Conference on Automation Science and Engineering (CASE)}, 
  title={3D Scene Graph Prediction on Point Clouds Using Knowledge Graphs}, 
  year={2023},
  volume={},
  number={},
  pages={1-7},
  abstract={3D scene graph prediction is a task that aims to concurrently predict object classes and their relationships within a 3D environment. As these environments are primarily designed by and for humans, incorporating commonsense knowledge regarding objects and their relationships can signifi-cantly constrain and enhance the prediction of the scene graph. In this paper, we investigate the application of commonsense knowledge graphs for 3D scene graph prediction on point clouds of indoor scenes. Through experiments conducted on a real-world indoor dataset, we demonstrate that integrating external commonsense knowledge via the message passing method leads to a 15.0% improvement in scene graph prediction accuracy with external knowledge and 7.96% with internal knowledge when compared to state-of-the-art algorithms. We also tested in the real world with 10 frames per second for scene graph generation to show the usage of the model in a more realistic robotics setting.},
  keywords={},
  doi={10.1109/CASE56687.2023.10260650},
  ISSN={2161-8089},
  month={Aug},}
@INPROCEEDINGS{10273477,
  author={Du Crest, Julien and Garcia-Herrero, Francisco and Mhalla, Mehdi and Savin, Valentin and Valls, Javier},
  booktitle={2023 12th International Symposium on Topics in Coding (ISTC)}, 
  title={Layered Decoding of Quantum LDPC Codes}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={We address the problem of doing message passing based decoding of quantum LDPC codes under hardware latency limitations. We propose a novel way to do layered decoding that suits quantum constraints and outperforms flooded scheduling, the usual scheduling on parallel architectures. A generic construction is given to construct layers of hypergraph product codes. In the process, we introduce two new notions, t-covering layers which is a generalization of the usual layer decomposition, and a modified scheduling called random order scheduling. Numerical simulations show that the random ordering is of independent interest as it helps relieve the high error floor typical of message passing decoders on quantum codes for both layered and serial decoding without the need of post-processing.},
  keywords={},
  doi={10.1109/ISTC57237.2023.10273477},
  ISSN={},
  month={Sep.},}
@INPROCEEDINGS{10272538,
  author={Ye, Jiancheng and Lin, Dong and Cai, Kechao and Zhou, Chao and He, Jianfei and Lui, John C.S.},
  booktitle={2023 IEEE 43rd International Conference on Distributed Computing Systems (ICDCS)}, 
  title={Data-Driven Rate Control for RDMA Networks: A Lightweight Online Learning Approach}, 
  year={2023},
  volume={},
  number={},
  pages={1-11},
  abstract={Link speed in datacenter networks (DCNs) keeps growing rapidly, inducing an increasingly large portion of network flows to become short flows which can be finished within one round-trip time (RTT). This phenomenon makes many existing congestion control schemes ineffective because they iteratively adjust the sending rate based on the latest congestion feedback in multiple rounds. We find that the representative DCQCN scheme for RDMA exhibits substantial performance degradation when there are many short flows, and this is specially true in High Performance Computing (HPC) scenarios where most of Message Passing Interface (MPI) messages are small. In this paper, we propose a data-driven rate control framework which can learn from long-term online data about past rate control decisions via a lightweight online learning technique named Multi-Armed Bandit (MAB) which has a provable performance guarantee. Utilizing the framework, we devise a rate control scheme named Dolce-RC, which dynamically controls the rate increase and reduction by learning from online data. We implement Dolce-RC in commodity smart NICs, and show via testbed experiments and large-scale simulations that compared to DCQCN, Dolce-RC reduces average completion time of MPI messages by up to 68%, while not requiring any modification to switches.},
  keywords={},
  doi={10.1109/ICDCS57875.2023.00085},
  ISSN={2575-8411},
  month={July},}
@INPROCEEDINGS{10286007,
  author={Zhao, Zilu and Slock, Dirk},
  booktitle={2023 IEEE 33rd International Workshop on Machine Learning for Signal Processing (MLSP)}, 
  title={Improved Variance Predictions in Approximate Message Passing}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={In the Generalized Linear Model (GLM), the unknowns may be non-identically independent distributed (niid), as for instance in the Sparse Bayesian Learning (SBL) problem. The Generalized Approximate Message Passing (GAMP) algorithm performs computationally efficient belief propagation for Bayesian inference. The GAMP algorithms predicts the posterior variances correctly in the case of measurement matrices with (n)iid entries. In order to cover more ill-conditioned measurement matrices, the (right) rotationally invariant (RRI) model was introduced in which the (right) singular vectors are Haar distributed, leading to Vector AMP VAMP however assumes iid priors and posteriors. Here we introduce a convergent version of AMB (AMBAMP) applied to Unitarily transformed data, with a variance correction based on Haar Large System Analysis (LSA). The recently introduced reVAMP perspective shows that the resulting AMBUAMP algorithm has an underlying multivariate Gaussian posterior approximation, that does not get computed but that allows the LSA. The individual variance predictions are exact asymptotically in the RRI setting, as illustrated by a Gaussian Mixture Model example.},
  keywords={},
  doi={10.1109/MLSP55844.2023.10286007},
  ISSN={2161-0371},
  month={Sep.},}
@INPROCEEDINGS{10279123,
  author={Chatzigeorgiou, Roza and Bletsas, Aggelos},
  booktitle={ICC 2023 - IEEE International Conference on Communications}, 
  title={Distributed, Inference-Based, Energy Efficient User Association with Convergence Guarantees}, 
  year={2023},
  volume={},
  number={},
  pages={3228-3233},
  abstract={This work establishes a relaxed formulation for the problem of user association with energy efficiency (EE) in the downlink of heterogeneous networks. A distributed solver is offered, based on belief propagation (BP)-based message passing between (micro or macro) base stations. In addition, correctness and convergence guarantees are provided for the employed loopy BP and computation load is analyzed and reduced (with careful precomputations). Numerical results indicate that the proposed approach offers higher EE geometric mean, while not sacrificing spectral efficiency, compared to prior art.},
  keywords={},
  doi={10.1109/ICC45041.2023.10279123},
  ISSN={1938-1883},
  month={May},}
@INPROCEEDINGS{10278761,
  author={Colavolpe, Giulio and Conti, Elisa and Piemontese, Amina and Vannucci, Armando},
  booktitle={ICC 2023 - IEEE International Conference on Communications}, 
  title={The Difficult Road of Expectation Propagation Towards Phase Noise Detection}, 
  year={2023},
  volume={},
  number={},
  pages={4640-4645},
  abstract={Expectation Propagation (EP) is a promising framework in message-passing algorithms based on factor-graphs. The inherent ability to combine prior (partial) knowledge of system variables with channel observations suggests that an effective estimation of random channel parameters can be achieved even with a very limited number of pilot symbols, thus increasing the payload efficiency. Yet, the way in which the probability distributions of latent variables (both data and parameters) are combined and projected often requires ad-hoc adjustments to reach satisfactory performance. Here, we apply EP to a classical problem of LDPC-coded transmission on a strong Wiener phase noise channel and discuss how and why, even in the simple case of binary modulation, EP can fail or succeed.},
  keywords={},
  doi={10.1109/ICC45041.2023.10278761},
  ISSN={1938-1883},
  month={May},}
@ARTICLE{10258152,
  author={Kouatly, Rand and Khan, Talha Ali},
  journal={Tsinghua Science and Technology}, 
  title={Performance of Text-Independent Automatic Speaker Recognition on a Multicore System}, 
  year={2024},
  volume={29},
  number={2},
  pages={447-456},
  abstract={This paper studies a high-speed text-independent Automatic Speaker Recognition (ASR) algorithm based on a multicore system's Gaussian Mixture Model (GMM). The high speech is achieved using parallel implementation of the feature's extraction and aggregation methods during training and testing procedures. Shared memory parallel programming techniques using both OpenMP and PThreads libraries are developed to accelerate the code and improve the performance of the ASR algorithm. The experimental results show speed-up improvements of around 3.2 on a personal laptop with Intel i5-6300HQ (2.3 GHz, four cores without hyper-threading, and 8 GB of RAM). In addition, a remarkable 100% speaker recognition accuracy is achieved.},
  keywords={},
  doi={10.26599/TST.2023.9010018},
  ISSN={1007-0214},
  month={April},}
@ARTICLE{1327584,
  author={Anastasi, G. and Bartoli, A. and Giannini, G.},
  journal={IEEE Transactions on Computers}, 
  title={On causal broadcasting with positive acknowledgments and bounded-length counters}, 
  year={2004},
  volume={53},
  number={10},
  pages={1355-1358},
  abstract={A causal broadcast protocol was proposed earlier in [R. Baldoni (1998)]. Two extensions of the protocol were also proposed in order to improve its throughput and bandwidth utilization. We show that both extensions are not live, i.e., there may be execution patterns in which processes stop delivering messages. We also show that the algorithm for the second extension does not satisfy the requirements on which its correctness was established. Finally, we provide fixed versions of both extensions and prove their correctness.},
  keywords={},
  doi={10.1109/TC.2004.82},
  ISSN={1557-9956},
  month={Oct},}
@ARTICLE{8188205,
  author={Meléndez, A. and Korenaga, J. and Sallares, V. and Miniussi, A. and Ranero, C.R.},
  journal={Geophysical Journal International}, 
  title={TOMO3D: 3-D joint refraction and reflection traveltime tomography parallel code for active-source seismic data—synthetic test}, 
  year={2015},
  volume={203},
  number={1},
  pages={158-174},
  abstract={We present a new 3-D traveltime tomography code (TOMO3D) for the modelling of active-source seismic data that uses the arrival times of both refracted and reflected seismic phases to derive the velocity distribution and the geometry of reflecting boundaries in the subsurface. This code is based on its popular 2-D version TOMO2D from which it inherited the methods to solve the forward and inverse problems. The traveltime calculations are done using a hybrid ray-tracing technique combining the graph and bending methods. The LSQR algorithm is used to perform the iterative regularized inversion to improve the initial velocity and depth models. In order to cope with an increased computational demand due to the incorporation of the third dimension, the forward problem solver, which takes most of the run time (∼90 per cent in the test presented here), has been parallelized with a combination of multi-processing and message passing interface standards. This parallelization distributes the ray-tracing and traveltime calculations among available computational resources. The code's performance is illustrated with a realistic synthetic example, including a checkerboard anomaly and two reflectors, which simulates the geometry of a subduction zone. The code is designed to invert for a single reflector at a time. A data-driven layer-stripping strategy is proposed for cases involving multiple reflectors, and it is tested for the successive inversion of the two reflectors. Layers are bound by consecutive reflectors, and an initial velocity model for each inversion step incorporates the results from previous steps. This strategy poses simpler inversion problems at each step, allowing the recovery of strong velocity discontinuities that would otherwise be smoothened.},
  keywords={},
  doi={10.1093/gji/ggv292},
  ISSN={1365-246X},
  month={Aug},}
@INPROCEEDINGS{8638404,
  author={},
  booktitle={2018 IEEE/ACM 2nd International Workshop on Software Correctness for HPC Applications (Correctness)}, 
  title={Workshop overview}, 
  year={2018},
  volume={},
  number={},
  pages={5-6},
  abstract={The goal of this workshop is to bring together researchers and developers to present and discuss novel ideas to address the problem of correctness in high-performance computing (HPC). The workshop features contributed papers and invited talks in this area. The program committee carefully reviewed each submission; each paper received between 3-4 reviews. The program committee accepted 7 papers and conditionally accepted 2 papers, which followed a shepherding process. The papers cover several topics of interest for the workshop, including correctness and verification techniques for HPC application, parallel tasking, OpenMP (data race detection), and message-passing applications. The program includes talks of the accepted papers and two invited keynote speakers. The first speaker is Ganesh L. Gopalakrishnan (Professor, School of Computing, University of Utah); his talk is titled "Making Formal Methods for HPC Disappear". The second speaker is James Demmel (Dr. Richard Carl Dehmel Distinguished Professor of Computer Science and Mathematics, University of California at Berkeley); his talk is titled "Correctness of Floating Point Programs - Exception Handling and Reproducibility". The program also includes a panel on "Facilitating the Adoption of Correctness Tools in HPC Applications".},
  keywords={},
  doi={10.1109/Correctness.2018.00004},
  ISSN={},
  month={Nov},}
@INPROCEEDINGS{336915,
  author={},
  booktitle={Proceedings of IEEE 13th Symposium on Reliable Distributed Systems}, 
  title={Proceedings of IEEE 13th Symposium on Reliable Distributed Systems}, 
  year={1994},
  volume={},
  number={},
  pages={0_1-},
  abstract={Presents the front cover of the proceedings record.},
  keywords={},
  doi={10.1109/RELDIS.1994.336915},
  ISSN={},
  month={Oct},}
@INPROCEEDINGS{504334,
  author={},
  booktitle={Programming Models for Massively Parallel Computers}, 
  title={Programming Models for Massively Parallel Computers}, 
  year={1995},
  volume={},
  number={},
  pages={i-},
  abstract={Presents the front cover of the proceedings record.},
  keywords={},
  doi={10.1109/PMMPC.1995.504334},
  ISSN={},
  month={Oct},}
@INPROCEEDINGS{1181490,
  author={},
  booktitle={Eighth IEEE International Conference on Engineering of Complex Computer Systems, 2002. Proceedings.}, 
  title={Proceedings Eighth IEEE International Conference on Engineering of Complex Computer Systems}, 
  year={2002},
  volume={},
  number={},
  pages={},
  abstract={},
  keywords={},
  doi={10.1109/ICECCS.2002.1181490},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{6118524,
  author={},
  booktitle={2011 12th International Conference on Parallel and Distributed Computing, Applications and Technologies}, 
  title={Table of contents}, 
  year={2011},
  volume={},
  number={},
  pages={v-x},
  abstract={The following topics are dealt with: fast incremental spectral clustering for large data sets; access control through program transformation; distributed task migration scheme for mesh-based chip-multiprocessors; network threat assessment based on alert verification; GPGPU; social network-based information dissemination scheme; runtime fault detection method; prestack Kirchhoff time migration; multicore applications; multithreaded applications; Linux kernel; virtual machines; IP traffic forecasts; diffusion wavelets-based analysis; traffic matrices; P2P DHT; Barycentric coordinates based distributed localization; wireless sensor networks; Gaussian mixture model parameters; Loongson-3A quad-core SMP system; mobile element path planning; maximum temperature minimization; leakage aware scheduling; peer-to-peer databases; routing queries; mining association rules; ant colony algorithm; handover delay in mobile WiMAX; VolP; UMTS; MPI applications; automatic energy status controlling; dynamic voltage scaling ; cloud computing; social engineering botnets; XML data placement strategy; and parallel query.},
  keywords={},
  doi={10.1109/PDCAT.2011.78},
  ISSN={2379-5352},
  month={Oct},}
@INPROCEEDINGS{6874782,
  author={},
  booktitle={2014 IEEE International Symposium on Information Theory}, 
  title={Table of contents}, 
  year={2014},
  volume={},
  number={},
  pages={1-51},
  abstract={The following topics are dealt with: information theory; lossy source coding; wiretap channel; wireless communication; caching; ad-hoc networks; network coding; polar coding; quantum channels; entropy; MIMO wiretap channel; message passing; wireless networks; index coding; quantum sensing; f-divergence; degrees of freedom; secrecy; communication theory; network delay; network stability; quantum protocols; hypothesis testing; multiterminal source coding; relay networks; locally repairable codes; Shannon theory; network security; sequential detection; energy harvesting; interference channels; quantum error control codes; Turbo codes; statistics; algebraic coding; multiple access channel; fading channels; channel capacity; optical communications; cellular systems; relay channels; signal processing; Gaussian channel; iterative decoding algorithms; lossless compression; information measures; distributed storage; lattice codes; dirty paper coding; data privacy; distributed information processing; dimensionality reduction; flash memories; compressed sensing; broadcast channels; space-time codes; relaying schemes; finite block length capacity; Reed-Solomon codes; cryptography; biometrics; modulation; demodulation; quantum communication; cognitive radio; bioinformatics; neuroscience; and wireless network protocols.},
  keywords={},
  doi={10.1109/ISIT.2014.6874782},
  ISSN={2157-8117},
  month={June},}
@INPROCEEDINGS{7012186,
  author={},
  booktitle={SC '14: Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis}, 
  title={Table of contents}, 
  year={2014},
  volume={},
  number={},
  pages={v-xiv},
  abstract={The following topics are dealt with: high-performance computing; networking; file storage; ACM Gordon Bell finalist; application scaling; application heterogeneity; microarchitecture; performance measurement; performance accelerators; file systems; earth sciences; space sciences; compiler analysis; compiler optimization; parallel algorithms; Big Data analysis; high-performance genomics; MPI; cloud computing; graph algorithms; hardware vulnerability; hardware recovery; I/O; dynamic optimization; quantum simulations; resilience analysis; machine learning; data analytics; numerical kernels; power efficiency; data locality; load balancing; optimized checkpointing; sparse solvers; large-scale visualization; and memory system energy efficiency.},
  keywords={},
  doi={10.1109/SC.2014.5},
  ISSN={2167-4337},
  month={Nov},}
@INPROCEEDINGS{7541042,
  author={},
  booktitle={2016 IEEE International Symposium on Information Theory (ISIT)}, 
  title={[Title page]}, 
  year={2016},
  volume={},
  number={},
  pages={i-i},
  abstract={The following topics are dealt with: lossless source coding; change-point detection; polar codes; distributed storage; matrix completion; sequences; index coding; multiterminal source coding; broadcast channels; approximate message passing; constrained coding; wireless communications; feedback; multiple antennas; multiple access channels; point process channels; coded caching; energy harvesting; lossy compression; telecommunication security; information measures; compressed sensing; belief propagation; cryptography; clustering; channel uncertainty and CSI; channel capacity; Reed-Solomon codes; statistical inference; BCH codes-quasicyclic codes; superposition codes-group testing; data compression; heterogeneous networks; combinatorial coding theory; network structures; telecommunication scheduling; lattice codes; error exponents; LDPC codes; deletion channel; game theory; relay channels; quantum capacity and quantum channels; RM codes; network coding; source-channel coding; community detection; channel estimation; rate-distortion; random matrix theory; interference channels; covert communications; quantum information theory; data exchange problems; finite blocklength; physical layer security; learning; wireless sensor networks; secret keys and secret sharing; Gabidulin codes; Shannon theory; DNA-based storage; wiretap channels; MIMO and space-time coding; and graphical methods-weight distribution.},
  keywords={},
  doi={10.1109/ISIT.2016.7541042},
  ISSN={2157-8117},
  month={July},}
